file_path,api_count,code
setup.py,1,"b'import io\nimport os\nimport re\n\nfrom setuptools import find_packages, setup\n\n\ndef read(*names, **kwargs):\n    with io.open(os.path.join(os.path.dirname(__file__), *names), encoding=kwargs.get(""encoding"", ""utf8"")) as fp:\n        return fp.read()\n\n\ndef find_version(*file_paths):\n    version_file = read(*file_paths)\n    version_match = re.search(r""^__version__ = [\'\\""]([^\'\\""]*)[\'\\""]"", version_file, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(""Unable to find version string."")\n\n\nreadme = read(""README.md"")\n\nVERSION = find_version(""ignite"", ""__init__.py"")\n\nrequirements = [\n    ""torch>=1.0,<2"",\n]\n\nsetup(\n    # Metadata\n    name=""pytorch-ignite"",\n    version=VERSION,\n    author=""PyTorch Core Team"",\n    author_email=""soumith@pytorch.org"",\n    url=""https://github.com/pytorch/ignite"",\n    description=""A lightweight library to help with training neural networks in PyTorch."",\n    long_description_content_type=""text/markdown"",\n    long_description=readme,\n    license=""BSD"",\n    # Package info\n    packages=find_packages(exclude=(""tests"", ""tests.*"",)),\n    zip_safe=True,\n    install_requires=requirements,\n)\n'"
ignite/__init__.py,0,"b'import ignite.contrib\nimport ignite.distributed\nimport ignite.engine\nimport ignite.exceptions\nimport ignite.handlers\nimport ignite.metrics\nimport ignite.utils\n\n__version__ = ""0.4.0""\n'"
ignite/_utils.py,0,"b'from typing import Tuple, Union\n\n# For compatibilty\nfrom ignite.utils import apply_to_tensor, apply_to_type, convert_tensor, to_onehot\n\n\ndef _to_hours_mins_secs(time_taken: Union[float, int]) -> Tuple[int, int, int]:\n    """"""Convert seconds to hours, mins, and seconds.""""""\n    mins, secs = divmod(time_taken, 60)\n    hours, mins = divmod(mins, 60)\n    return round(hours), round(mins), round(secs)\n'"
ignite/exceptions.py,0,"b'__all__ = [""NotComputableError""]\n\n\nclass NotComputableError(RuntimeError):\n    """"""\n    Exception class to raise if Metric cannot be computed.\n    """"""\n'"
ignite/utils.py,10,"b'import collections.abc as collections\nimport logging\nimport random\nfrom typing import Any, Callable, Optional, Tuple, Type, Union\n\nimport torch\n\n__all__ = [""convert_tensor"", ""apply_to_tensor"", ""apply_to_type"", ""to_onehot"", ""setup_logger""]\n\n\ndef convert_tensor(\n    input_: Union[torch.Tensor, collections.Sequence, collections.Mapping, str, bytes],\n    device: Optional[Union[str, torch.device]] = None,\n    non_blocking: bool = False,\n) -> Union[torch.Tensor, collections.Sequence, collections.Mapping, str, bytes]:\n    """"""Move tensors to relevant device.""""""\n\n    def _func(tensor: torch.Tensor) -> torch.Tensor:\n        return tensor.to(device=device, non_blocking=non_blocking) if device is not None else tensor\n\n    return apply_to_tensor(input_, _func)\n\n\ndef apply_to_tensor(\n    input_: Union[torch.Tensor, collections.Sequence, collections.Mapping, str, bytes], func: Callable\n) -> Union[torch.Tensor, collections.Sequence, collections.Mapping, str, bytes]:\n    """"""Apply a function on a tensor or mapping, or sequence of tensors.\n    """"""\n    return apply_to_type(input_, torch.Tensor, func)\n\n\ndef apply_to_type(\n    input_: Union[Any, collections.Sequence, collections.Mapping, str, bytes],\n    input_type: Union[Type, Tuple[Type[Any], Any]],\n    func: Callable,\n) -> Union[Any, collections.Sequence, collections.Mapping, str, bytes]:\n    """"""Apply a function on a object of `input_type` or mapping, or sequence of objects of `input_type`.\n    """"""\n    if isinstance(input_, input_type):\n        return func(input_)\n    elif isinstance(input_, (str, bytes)):\n        return input_\n    elif isinstance(input_, collections.Mapping):\n        return type(input_)({k: apply_to_type(sample, input_type, func) for k, sample in input_.items()})\n    elif isinstance(input_, tuple) and hasattr(input_, ""_fields""):  # namedtuple\n        return type(input_)(*(apply_to_type(sample, input_type, func) for sample in input_))\n    elif isinstance(input_, collections.Sequence):\n        return type(input_)([apply_to_type(sample, input_type, func) for sample in input_])\n    else:\n        raise TypeError((""input must contain {}, dicts or lists; found {}"".format(input_type, type(input_))))\n\n\ndef to_onehot(indices: torch.Tensor, num_classes: int) -> torch.Tensor:\n    """"""Convert a tensor of indices of any shape `(N, ...)` to a\n    tensor of one-hot indicators of shape `(N, num_classes, ...) and of type uint8. Output\'s device is equal to the\n    input\'s device`.\n    """"""\n    onehot = torch.zeros(indices.shape[0], num_classes, *indices.shape[1:], dtype=torch.uint8, device=indices.device)\n    return onehot.scatter_(1, indices.unsqueeze(1), 1)\n\n\ndef setup_logger(\n    name: Optional[str] = None,\n    level: int = logging.INFO,\n    format: str = ""%(asctime)s %(name)s %(levelname)s: %(message)s"",\n    filepath: Optional[str] = None,\n    distributed_rank: Optional[int] = None,\n) -> logging.Logger:\n    """"""Setups logger: name, level, format etc.\n\n    Args:\n        name (str, optional): new name for the logger. If None, the standard logger is used.\n        level (int): logging level, e.g. CRITICAL, ERROR, WARNING, INFO, DEBUG\n        format (str): logging format. By default, `%(asctime)s %(name)s %(levelname)s: %(message)s`\n        filepath (str, optional): Optional logging file path. If not None, logs are written to the file.\n        distributed_rank (int, optional): Optional, rank in distributed configuration to avoid logger setup for workers.\n        If None, distributed_rank is initialized to the rank of process.\n\n    Returns:\n        logging.Logger\n\n    For example, to improve logs readability when training with a trainer and evaluator:\n\n    .. code-block:: python\n\n        from ignite.utils import setup_logger\n\n        trainer = ...\n        evaluator = ...\n\n        trainer.logger = setup_logger(""trainer"")\n        evaluator.logger = setup_logger(""evaluator"")\n\n        trainer.run(data, max_epochs=10)\n\n        # Logs will look like\n        # 2020-01-21 12:46:07,356 trainer INFO: Engine run starting with max_epochs=5.\n        # 2020-01-21 12:46:07,358 trainer INFO: Epoch[1] Complete. Time taken: 00:5:23\n        # 2020-01-21 12:46:07,358 evaluator INFO: Engine run starting with max_epochs=1.\n        # 2020-01-21 12:46:07,358 evaluator INFO: Epoch[1] Complete. Time taken: 00:01:02\n        # ...\n\n    """"""\n    logger = logging.getLogger(name)\n\n    # don\'t propagate to ancestors\n    # the problem here is to attach handlers to loggers\n    # should we provide a default configuration less open ?\n    if name is not None:\n        logger.propagate = False\n\n    # Remove previous handlers\n    if logger.hasHandlers():\n        for h in list(logger.handlers):\n            logger.removeHandler(h)\n\n    formatter = logging.Formatter(format)\n\n    if distributed_rank is None:\n        import ignite.distributed as idist\n\n        distributed_rank = idist.get_rank()\n\n    if distributed_rank > 0:\n        logger.addHandler(logging.NullHandler())\n    else:\n        logger.setLevel(level)\n\n        ch = logging.StreamHandler()\n        ch.setLevel(level)\n        ch.setFormatter(formatter)\n        logger.addHandler(ch)\n\n        if filepath is not None:\n            fh = logging.FileHandler(filepath)\n            fh.setLevel(level)\n            fh.setFormatter(formatter)\n            logger.addHandler(fh)\n\n    return logger\n\n\ndef manual_seed(seed: int) -> None:\n    """"""Setup random state from a seed for `torch`, `random` and optionally `numpy` (if can be imported).\n\n    Args:\n        seed (int): Random state seed\n\n    """"""\n    random.seed(seed)\n    torch.manual_seed(seed)\n    try:\n        import numpy as np\n\n        np.random.seed(seed)\n    except ImportError:\n        pass\n'"
tests/__init__.py,0,b'# Needed to collect coverage data\n'
docs/source/conf.py,1,"b'# -*- coding: utf-8 -*-\n#\n# Configuration file for the Sphinx documentation builder.\n#\n# This file does only contain a selection of the most common options. For a\n# full list see the documentation:\n# http://www.sphinx-doc.org/en/stable/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\n\nsys.path.insert(0, os.path.abspath(""../..""))\nimport ignite\nimport pytorch_sphinx_theme\n\n# -- Project information -----------------------------------------------------\n\nproject = ""ignite""\ncopyright = ""2020, PyTorch-Ignite Contributors""\nauthor = ""PyTorch-Ignite Contributors""\n\n# The short X.Y version\ntry:\n    version = os.environ[""code_version""]\n    if ""master"" in version:\n        version = ""master ("" + ignite.__version__ + "")""\n    else:\n        version = version.replace(""v"", """")\nexcept KeyError:\n    version = ignite.__version__\n\n# The full version, including alpha/beta/rc tags\nrelease = ""master""\n\n\n# -- General configuration ---------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    ""sphinx.ext.autosummary"",\n    ""sphinx.ext.doctest"",\n    ""sphinx.ext.intersphinx"",\n    ""sphinx.ext.todo"",\n    ""sphinx.ext.coverage"",\n    ""sphinx.ext.mathjax"",\n    ""sphinx.ext.napoleon"",\n    ""sphinx.ext.viewcode"",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [""_templates""]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\n# source_suffix = [\'.rst\', \'.md\']\nsource_suffix = "".rst""\n\n# The master toctree document.\nmaster_doc = ""index""\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path .\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = ""sphinx""\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = ""pytorch_sphinx_theme""\nhtml_theme_path = [pytorch_sphinx_theme.get_html_theme_path()]\n\nhtml_theme_options = {\n    ""canonical_url"": ""https://pytorch.org/ignite/index.html"",\n    ""collapse_navigation"": False,\n    ""display_version"": True,\n    ""logo_only"": True,\n}\n\nhtml_logo = ""_static/img/ignite-logo-dark.svg""\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\n# html_theme_options = {}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [""_static"", ""_templates/_static""]\n\nhtml_context = {\n    ""css_files"": [\n        # \'https://fonts.googleapis.com/css?family=Lato\',\n        # \'_static/css/pytorch_theme.css\'\n        ""_static/css/ignite_theme.css""\n    ],\n}\n\n\n# -- Options for HTMLHelp output ---------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = ""ignitedoc""\n\n\n# -- Options for LaTeX output ------------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, ""ignite.tex"", ""ignite Documentation"", ""Torch Contributors"", ""manual""),\n]\n\n\n# -- Options for manual page output ------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, ""ignite"", ""ignite Documentation"", [author], 1)]\n\n\n# -- Options for Texinfo output ----------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        ""ignite"",\n        ""ignite Documentation"",\n        author,\n        ""ignite"",\n        ""One line description of project."",\n        ""Miscellaneous"",\n    ),\n]\n\n\n# -- Extension configuration -------------------------------------------------\n\n# -- Options for intersphinx extension ---------------------------------------\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {""https://docs.python.org/"": None}\n\n# -- Options for todo extension ----------------------------------------------\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n'"
examples/fast_neural_style/handlers.py,0,"b'import sys\n\n\nclass Progbar(object):\n    def __init__(self, loader, metrics):\n        self.num_iterations = len(loader)\n        self.output_stream = sys.stdout\n        self.metrics = metrics\n        self.alpha = 0.98\n\n    def _calc_running_avg(self, engine):\n        for k, v in engine.state.output.items():\n            old_v = self.metrics.get(k, v)\n            new_v = self.alpha * old_v + (1 - self.alpha) * v\n            self.metrics[k] = new_v\n\n    def __call__(self, engine):\n        self._calc_running_avg(engine)\n        num_seen = engine.state.iteration - self.num_iterations * (engine.state.epoch - 1)\n\n        percent_seen = 100 * float(num_seen) / self.num_iterations\n        equal_to = int(percent_seen / 10)\n        done = int(percent_seen) == 100\n\n        bar = ""["" + ""="" * equal_to + "">"" * (not done) + "" "" * (10 - equal_to) + ""]""\n        message = ""Epoch {epoch} | {percent_seen:.2f}% | {bar}"".format(\n            epoch=engine.state.epoch, percent_seen=percent_seen, bar=bar\n        )\n        for key, value in self.metrics.items():\n            message += "" | {name}: {value:.2e}"".format(name=key, value=value)\n\n        message += ""\\r""\n\n        self.output_stream.write(message)\n        self.output_stream.flush()\n\n        if done:\n            self.output_stream.write(""\\n"")\n'"
examples/fast_neural_style/neural_style.py,9,"b'# coding: utf-8\nimport argparse\nimport os\nimport sys\n\nimport numpy as np\nimport random\nimport torch\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision import transforms\n\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import ModelCheckpoint\n\nimport utils\nfrom transformer_net import TransformerNet\nfrom vgg import Vgg16\nfrom handlers import Progbar\n\nfrom collections import OrderedDict\n\n\ndef check_paths(args):\n    try:\n        if args.checkpoint_model_dir is not None and not (os.path.exists(args.checkpoint_model_dir)):\n            os.makedirs(args.checkpoint_model_dir)\n    except OSError as e:\n        raise OSError(e)\n\n\ndef check_manual_seed(args):\n    seed = args.seed or random.randint(1, 10000)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n\n\ndef check_dataset(args):\n    transform = transforms.Compose(\n        [\n            transforms.Resize(args.image_size),\n            transforms.CenterCrop(args.image_size),\n            transforms.ToTensor(),\n            transforms.Lambda(lambda x: x.mul(255)),\n        ]\n    )\n\n    if args.dataset in {""folder"", ""mscoco""}:\n        train_dataset = datasets.ImageFolder(args.dataroot, transform)\n    elif args.dataset == ""test"":\n        train_dataset = datasets.FakeData(\n            size=args.batch_size, image_size=(3, 32, 32), num_classes=1, transform=transform\n        )\n    else:\n        raise RuntimeError(""Invalid dataset name: {}"".format(args.dataset))\n\n    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=0)\n\n    return train_loader\n\n\ndef train(args):\n    device = torch.device(""cuda"" if args.cuda else ""cpu"")\n\n    train_loader = check_dataset(args)\n    transformer = TransformerNet().to(device)\n    optimizer = Adam(transformer.parameters(), args.lr)\n    mse_loss = torch.nn.MSELoss()\n\n    vgg = Vgg16(requires_grad=False).to(device)\n    style_transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.mul(255))])\n\n    style = utils.load_image(args.style_image, size=args.style_size)\n    style = style_transform(style)\n    style = style.repeat(args.batch_size, 1, 1, 1).to(device)\n\n    features_style = vgg(utils.normalize_batch(style))\n    gram_style = [utils.gram_matrix(y) for y in features_style]\n\n    running_avgs = OrderedDict()\n\n    def step(engine, batch):\n\n        x, _ = batch\n        x = x.to(device)\n\n        n_batch = len(x)\n\n        optimizer.zero_grad()\n\n        y = transformer(x)\n\n        x = utils.normalize_batch(x)\n        y = utils.normalize_batch(y)\n\n        features_x = vgg(x)\n        features_y = vgg(y)\n\n        content_loss = args.content_weight * mse_loss(features_y.relu2_2, features_x.relu2_2)\n\n        style_loss = 0.0\n        for ft_y, gm_s in zip(features_y, gram_style):\n            gm_y = utils.gram_matrix(ft_y)\n            style_loss += mse_loss(gm_y, gm_s[:n_batch, :, :])\n        style_loss *= args.style_weight\n\n        total_loss = content_loss + style_loss\n        total_loss.backward()\n        optimizer.step()\n\n        return {""content_loss"": content_loss.item(), ""style_loss"": style_loss.item(), ""total_loss"": total_loss.item()}\n\n    trainer = Engine(step)\n    checkpoint_handler = ModelCheckpoint(\n        args.checkpoint_model_dir, ""checkpoint"", n_saved=10, require_empty=False, create_dir=True\n    )\n    progress_bar = Progbar(loader=train_loader, metrics=running_avgs)\n\n    trainer.add_event_handler(\n        event_name=Events.EPOCH_COMPLETED(every=args.checkpoint_interval),\n        handler=checkpoint_handler,\n        to_save={""net"": transformer},\n    )\n    trainer.add_event_handler(event_name=Events.ITERATION_COMPLETED, handler=progress_bar)\n    trainer.run(train_loader, max_epochs=args.epochs)\n\n\ndef stylize(args):\n    device = torch.device(""cuda"" if args.cuda else ""cpu"")\n\n    content_transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.mul(255))])\n\n    content_image = utils.load_image(args.content_image, scale=args.content_scale)\n    content_image = content_transform(content_image)\n    content_image = content_image.unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        style_model = torch.load(args.model)\n        style_model.to(device)\n        output = style_model(content_image).cpu()\n        utils.save_image(args.output_image, output[0])\n\n\ndef main():\n    main_arg_parser = argparse.ArgumentParser(description=""parser for fast-neural-style"")\n    subparsers = main_arg_parser.add_subparsers(title=""subcommands"", dest=""subcommand"")\n\n    train_arg_parser = subparsers.add_parser(""train"", help=""parser for training arguments"")\n    train_arg_parser.add_argument(""--epochs"", type=int, default=2, help=""number of training epochs, default is 2"")\n    train_arg_parser.add_argument(""--batch_size"", type=int, default=8, help=""batch size for training, default is 8"")\n    train_arg_parser.add_argument(\n        ""--dataset"", type=str, required=True, choices={""test"", ""folder"", ""mscoco""}, help=""type of dataset to be used.""\n    )\n    train_arg_parser.add_argument(\n        ""--dataroot"",\n        type=str,\n        required=True,\n        help=""path to training dataset, the path should point to a folder ""\n        ""containing another folder with all the training images"",\n    )\n    train_arg_parser.add_argument(""--style_image"", type=str, default=""test"", help=""path to style-image"")\n    train_arg_parser.add_argument(""--test_image"", type=str, default=""test"", help=""path to test-image"")\n    train_arg_parser.add_argument(\n        ""--checkpoint_model_dir"",\n        type=str,\n        default=""/tmp/checkpoints"",\n        help=""path to folder where checkpoints of trained models will be saved"",\n    )\n    train_arg_parser.add_argument(\n        ""--checkpoint_interval"",\n        type=int,\n        default=1,\n        help=""number of batches after which a checkpoint of trained model will be created"",\n    )\n    train_arg_parser.add_argument(\n        ""--image_size"", type=int, default=256, help=""size of training images, default is 256 X 256""\n    )\n    train_arg_parser.add_argument(\n        ""--style_size"", type=int, default=None, help=""size of style-image, default is the original size of style image""\n    )\n    train_arg_parser.add_argument(""--cuda"", type=int, default=1, help=""set it to 1 for running on GPU, 0 for CPU"")\n    train_arg_parser.add_argument(""--seed"", type=int, default=42, help=""random seed for training"")\n    train_arg_parser.add_argument(\n        ""--content_weight"", type=float, default=1e5, help=""weight for content-loss, default is 1e5""\n    )\n    train_arg_parser.add_argument(\n        ""--style_weight"", type=float, default=1e10, help=""weight for style-loss, default is 1e10""\n    )\n    train_arg_parser.add_argument(""--lr"", type=float, default=1e-3, help=""learning rate, default is 1e-3"")\n\n    eval_arg_parser = subparsers.add_parser(""eval"", help=""parser for evaluation/stylizing arguments"")\n    eval_arg_parser.add_argument(\n        ""--content_image"", type=str, required=True, help=""path to content image you want to stylize""\n    )\n    eval_arg_parser.add_argument(\n        ""--content_scale"", type=float, default=None, help=""factor for scaling down the content image""\n    )\n    eval_arg_parser.add_argument(""--output_image"", type=str, required=True, help=""path for saving the output image"")\n    eval_arg_parser.add_argument(\n        ""--model"", type=str, required=True, help=""saved model to be used for stylizing the image.""\n    )\n    eval_arg_parser.add_argument(""--cuda"", type=int, required=True, help=""set it to 1 for running on GPU, 0 for CPU"")\n\n    args = main_arg_parser.parse_args()\n\n    if args.subcommand is None:\n        raise ValueError(""ERROR: specify either train or eval"")\n    if args.cuda and not torch.cuda.is_available():\n        raise ValueError(""ERROR: cuda is not available, try running on CPU"")\n\n    if args.subcommand == ""train"":\n        check_manual_seed(args)\n        check_paths(args)\n        train(args)\n    else:\n        stylize(args)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
examples/fast_neural_style/transformer_net.py,19,"b'import torch\n\n\nclass TransformerNet(torch.nn.Module):\n    def __init__(self):\n        super(TransformerNet, self).__init__()\n        # Initial convolution layers\n        self.conv1 = ConvLayer(3, 32, kernel_size=9, stride=1)\n        self.in1 = torch.nn.InstanceNorm2d(32, affine=True)\n        self.conv2 = ConvLayer(32, 64, kernel_size=3, stride=2)\n        self.in2 = torch.nn.InstanceNorm2d(64, affine=True)\n        self.conv3 = ConvLayer(64, 128, kernel_size=3, stride=2)\n        self.in3 = torch.nn.InstanceNorm2d(128, affine=True)\n        # Residual layers\n        self.res1 = ResidualBlock(128)\n        self.res2 = ResidualBlock(128)\n        self.res3 = ResidualBlock(128)\n        self.res4 = ResidualBlock(128)\n        self.res5 = ResidualBlock(128)\n        # Upsampling Layers\n        self.deconv1 = UpsampleConvLayer(128, 64, kernel_size=3, stride=1, upsample=2)\n        self.in4 = torch.nn.InstanceNorm2d(64, affine=True)\n        self.deconv2 = UpsampleConvLayer(64, 32, kernel_size=3, stride=1, upsample=2)\n        self.in5 = torch.nn.InstanceNorm2d(32, affine=True)\n        self.deconv3 = ConvLayer(32, 3, kernel_size=9, stride=1)\n        # Non-linearities\n        self.relu = torch.nn.ReLU()\n\n    def forward(self, X):\n        y = self.relu(self.in1(self.conv1(X)))\n        y = self.relu(self.in2(self.conv2(y)))\n        y = self.relu(self.in3(self.conv3(y)))\n        y = self.res1(y)\n        y = self.res2(y)\n        y = self.res3(y)\n        y = self.res4(y)\n        y = self.res5(y)\n        y = self.relu(self.in4(self.deconv1(y)))\n        y = self.relu(self.in5(self.deconv2(y)))\n        y = self.deconv3(y)\n        return y\n\n\nclass ConvLayer(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride):\n        super(ConvLayer, self).__init__()\n        reflection_padding = kernel_size // 2\n        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n\n    def forward(self, x):\n        out = self.reflection_pad(x)\n        out = self.conv2d(out)\n        return out\n\n\nclass ResidualBlock(torch.nn.Module):\n    """"""ResidualBlock\n    introduced in: https://arxiv.org/abs/1512.03385\n    recommended architecture: http://torch.ch/blog/2016/02/04/resnets.html\n    """"""\n\n    def __init__(self, channels):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n        self.in1 = torch.nn.InstanceNorm2d(channels, affine=True)\n        self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n        self.in2 = torch.nn.InstanceNorm2d(channels, affine=True)\n        self.relu = torch.nn.ReLU()\n\n    def forward(self, x):\n        residual = x\n        out = self.relu(self.in1(self.conv1(x)))\n        out = self.in2(self.conv2(out))\n        out = out + residual\n        return out\n\n\nclass UpsampleConvLayer(torch.nn.Module):\n    """"""UpsampleConvLayer\n    Upsamples the input and then does a convolution. This method gives better results\n    compared to ConvTranspose2d.\n    ref: http://distill.pub/2016/deconv-checkerboard/\n    """"""\n\n    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n        super(UpsampleConvLayer, self).__init__()\n        self.upsample = upsample\n        reflection_padding = kernel_size // 2\n        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n\n    def forward(self, x):\n        x_in = x\n        if self.upsample:\n            x_in = torch.nn.functional.interpolate(x_in, mode=""nearest"", scale_factor=self.upsample)\n        out = self.reflection_pad(x_in)\n        out = self.conv2d(out)\n        return out\n'"
examples/fast_neural_style/utils.py,0,"b'import torch\nfrom PIL import Image\n\n\ndef load_image(filename, size=None, scale=None):\n    img = Image.open(filename)\n    if size is not None:\n        img = img.resize((size, size), Image.ANTIALIAS)\n    elif scale is not None:\n        img = img.resize((int(img.size[0] / scale), int(img.size[1] / scale)), Image.ANTIALIAS)\n    return img\n\n\ndef save_image(filename, data):\n    img = data.clone().clamp(0, 255).numpy()\n    img = img.transpose(1, 2, 0).astype(""uint8"")\n    img = Image.fromarray(img)\n    img.save(filename)\n\n\ndef gram_matrix(y):\n    (b, ch, h, w) = y.size()\n    features = y.view(b, ch, w * h)\n    features_t = features.transpose(1, 2)\n    gram = features.bmm(features_t) / (ch * h * w)\n    return gram\n\n\ndef normalize_batch(batch):\n    # normalize using imagenet mean and std\n    mean = batch.new_tensor([0.485, 0.456, 0.406]).view(-1, 1, 1)\n    std = batch.new_tensor([0.229, 0.224, 0.225]).view(-1, 1, 1)\n    batch = batch.div_(255.0)\n    return (batch - mean) / std\n'"
examples/fast_neural_style/vgg.py,5,"b'from collections import namedtuple\n\nimport torch\nfrom torchvision import models\n\n\nclass Vgg16(torch.nn.Module):\n    def __init__(self, requires_grad=False):\n        super(Vgg16, self).__init__()\n        vgg_pretrained_features = models.vgg16(pretrained=True).features\n        self.slice1 = torch.nn.Sequential()\n        self.slice2 = torch.nn.Sequential()\n        self.slice3 = torch.nn.Sequential()\n        self.slice4 = torch.nn.Sequential()\n        for x in range(4):\n            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n        for x in range(4, 9):\n            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n        for x in range(9, 16):\n            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n        for x in range(16, 23):\n            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n        if not requires_grad:\n            for param in self.parameters():\n                param.requires_grad = False\n\n    def forward(self, X):\n        h = self.slice1(X)\n        h_relu1_2 = h\n        h = self.slice2(h)\n        h_relu2_2 = h\n        h = self.slice3(h)\n        h_relu3_3 = h\n        h = self.slice4(h)\n        h_relu4_3 = h\n        vgg_outputs = namedtuple(""VggOutputs"", [""relu1_2"", ""relu2_2"", ""relu3_3"", ""relu4_3""])\n        out = vgg_outputs(h_relu1_2, h_relu2_2, h_relu3_3, h_relu4_3)\n        return out\n'"
examples/gan/dcgan.py,11,"b'import argparse\nimport os\nimport random\nimport warnings\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\n\nfrom ignite.contrib.handlers import ProgressBar\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import ModelCheckpoint, Timer\nfrom ignite.metrics import RunningAverage\n\ntry:\n    import torchvision.datasets as dset\n    import torchvision.transforms as transforms\n    import torchvision.utils as vutils\n\nexcept ImportError:\n    raise ImportError(\n        ""Please install torchvision to run this example, for example ""\n        ""via conda by running \'conda install -c pytorch torchvision\'. ""\n    )\n\n\nPRINT_FREQ = 100\nFAKE_IMG_FNAME = ""fake_sample_epoch_{:04d}.png""\nREAL_IMG_FNAME = ""real_sample_epoch_{:04d}.png""\nLOGS_FNAME = ""logs.tsv""\nPLOT_FNAME = ""plot.svg""\nSAMPLES_FNAME = ""samples.svg""\nCKPT_PREFIX = ""networks""\n\n\nclass Net(nn.Module):\n    """""" A base class for both generator and the discriminator.\n    Provides a common weight initialization scheme.\n\n    """"""\n\n    def weights_init(self):\n        for m in self.modules():\n            classname = m.__class__.__name__\n\n            if ""Conv"" in classname:\n                m.weight.data.normal_(0.0, 0.02)\n\n            elif ""BatchNorm"" in classname:\n                m.weight.data.normal_(1.0, 0.02)\n                m.bias.data.fill_(0)\n\n    def forward(self, x):\n        return x\n\n\nclass Generator(Net):\n    """""" Generator network.\n\n    Args:\n        nf (int): Number of filters in the second-to-last deconv layer\n    """"""\n\n    def __init__(self, z_dim, nf, nc):\n        super(Generator, self).__init__()\n\n        self.net = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(in_channels=z_dim, out_channels=nf * 8, kernel_size=4, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(nf * 8),\n            nn.ReLU(inplace=True),\n            # state size. (nf*8) x 4 x 4\n            nn.ConvTranspose2d(in_channels=nf * 8, out_channels=nf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nf * 4),\n            nn.ReLU(inplace=True),\n            # state size. (nf*4) x 8 x 8\n            nn.ConvTranspose2d(in_channels=nf * 4, out_channels=nf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nf * 2),\n            nn.ReLU(inplace=True),\n            # state size. (nf*2) x 16 x 16\n            nn.ConvTranspose2d(in_channels=nf * 2, out_channels=nf, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nf),\n            nn.ReLU(inplace=True),\n            # state size. (nf) x 32 x 32\n            nn.ConvTranspose2d(in_channels=nf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n        self.weights_init()\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass Discriminator(Net):\n    """""" Discriminator network.\n\n    Args:\n        nf (int): Number of filters in the first conv layer.\n    """"""\n\n    def __init__(self, nc, nf):\n        super(Discriminator, self).__init__()\n\n        self.net = nn.Sequential(\n            # input is (nc) x 64 x 64\n            nn.Conv2d(in_channels=nc, out_channels=nf, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (nf) x 32 x 32\n            nn.Conv2d(in_channels=nf, out_channels=nf * 2, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (nf*2) x 16 x 16\n            nn.Conv2d(in_channels=nf * 2, out_channels=nf * 4, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (nf*4) x 8 x 8\n            nn.Conv2d(in_channels=nf * 4, out_channels=nf * 8, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(nf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (nf*8) x 4 x 4\n            nn.Conv2d(in_channels=nf * 8, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False),\n            nn.Sigmoid(),\n        )\n\n        self.weights_init()\n\n    def forward(self, x):\n        output = self.net(x)\n        return output.view(-1, 1).squeeze(1)\n\n\ndef check_manual_seed(seed):\n    """""" If manual seed is not specified, choose a random one and communicate it to the user.\n\n    """"""\n\n    seed = seed or random.randint(1, 10000)\n    random.seed(seed)\n    torch.manual_seed(seed)\n\n    print(""Using manual seed: {seed}"".format(seed=seed))\n\n\ndef check_dataset(dataset, dataroot):\n    """"""\n\n    Args:\n        dataset (str): Name of the dataset to use. See CLI help for details\n        dataroot (str): root directory where the dataset will be stored.\n\n    Returns:\n        dataset (data.Dataset): torchvision Dataset object\n\n    """"""\n    resize = transforms.Resize(64)\n    crop = transforms.CenterCrop(64)\n    to_tensor = transforms.ToTensor()\n    normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n\n    if dataset in {""imagenet"", ""folder"", ""lfw""}:\n        dataset = dset.ImageFolder(root=dataroot, transform=transforms.Compose([resize, crop, to_tensor, normalize]))\n        nc = 3\n\n    elif dataset == ""lsun"":\n        dataset = dset.LSUN(\n            root=dataroot, classes=[""bedroom_train""], transform=transforms.Compose([resize, crop, to_tensor, normalize])\n        )\n        nc = 3\n\n    elif dataset == ""cifar10"":\n        dataset = dset.CIFAR10(\n            root=dataroot, download=True, transform=transforms.Compose([resize, to_tensor, normalize])\n        )\n        nc = 3\n\n    elif dataset == ""mnist"":\n        dataset = dset.MNIST(root=dataroot, download=True, transform=transforms.Compose([resize, to_tensor, normalize]))\n        nc = 1\n\n    elif dataset == ""fake"":\n        dataset = dset.FakeData(size=256, image_size=(3, 64, 64), transform=to_tensor)\n        nc = 3\n\n    else:\n        raise RuntimeError(""Invalid dataset name: {}"".format(dataset))\n\n    return dataset, nc\n\n\ndef main(\n    dataset,\n    dataroot,\n    z_dim,\n    g_filters,\n    d_filters,\n    batch_size,\n    epochs,\n    learning_rate,\n    beta_1,\n    saved_G,\n    saved_D,\n    seed,\n    n_workers,\n    device,\n    alpha,\n    output_dir,\n):\n\n    # seed\n    check_manual_seed(seed)\n\n    # data\n    dataset, num_channels = check_dataset(dataset, dataroot)\n    loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers, drop_last=True)\n\n    # netowrks\n    netG = Generator(z_dim, g_filters, num_channels).to(device)\n    netD = Discriminator(num_channels, d_filters).to(device)\n\n    # criterion\n    bce = nn.BCELoss()\n\n    # optimizers\n    optimizerG = optim.Adam(netG.parameters(), lr=learning_rate, betas=(beta_1, 0.999))\n    optimizerD = optim.Adam(netD.parameters(), lr=learning_rate, betas=(beta_1, 0.999))\n\n    # load pre-trained models\n    if saved_G:\n        netG.load_state_dict(torch.load(saved_G))\n\n    if saved_D:\n        netD.load_state_dict(torch.load(saved_D))\n\n    # misc\n    real_labels = torch.ones(batch_size, device=device)\n    fake_labels = torch.zeros(batch_size, device=device)\n    fixed_noise = torch.randn(batch_size, z_dim, 1, 1, device=device)\n\n    def get_noise():\n        return torch.randn(batch_size, z_dim, 1, 1, device=device)\n\n    # The main function, processing a batch of examples\n    def step(engine, batch):\n\n        # unpack the batch. It comes from a dataset, so we have <images, labels> pairs. Discard labels.\n        real, _ = batch\n        real = real.to(device)\n\n        # -----------------------------------------------------------\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        netD.zero_grad()\n\n        # train with real\n        output = netD(real)\n        errD_real = bce(output, real_labels)\n        D_x = output.mean().item()\n\n        errD_real.backward()\n\n        # get fake image from generator\n        noise = get_noise()\n        fake = netG(noise)\n\n        # train with fake\n        output = netD(fake.detach())\n        errD_fake = bce(output, fake_labels)\n        D_G_z1 = output.mean().item()\n\n        errD_fake.backward()\n\n        # gradient update\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        # -----------------------------------------------------------\n        # (2) Update G network: maximize log(D(G(z)))\n        netG.zero_grad()\n\n        # Update generator. We want to make a step that will make it more likely that discriminator outputs ""real""\n        output = netD(fake)\n        errG = bce(output, real_labels)\n        D_G_z2 = output.mean().item()\n\n        errG.backward()\n\n        # gradient update\n        optimizerG.step()\n\n        return {""errD"": errD.item(), ""errG"": errG.item(), ""D_x"": D_x, ""D_G_z1"": D_G_z1, ""D_G_z2"": D_G_z2}\n\n    # ignite objects\n    trainer = Engine(step)\n    checkpoint_handler = ModelCheckpoint(output_dir, CKPT_PREFIX, n_saved=10, require_empty=False)\n    timer = Timer(average=True)\n\n    # attach running average metrics\n    monitoring_metrics = [""errD"", ""errG"", ""D_x"", ""D_G_z1"", ""D_G_z2""]\n    RunningAverage(alpha=alpha, output_transform=lambda x: x[""errD""]).attach(trainer, ""errD"")\n    RunningAverage(alpha=alpha, output_transform=lambda x: x[""errG""]).attach(trainer, ""errG"")\n    RunningAverage(alpha=alpha, output_transform=lambda x: x[""D_x""]).attach(trainer, ""D_x"")\n    RunningAverage(alpha=alpha, output_transform=lambda x: x[""D_G_z1""]).attach(trainer, ""D_G_z1"")\n    RunningAverage(alpha=alpha, output_transform=lambda x: x[""D_G_z2""]).attach(trainer, ""D_G_z2"")\n\n    # attach progress bar\n    pbar = ProgressBar()\n    pbar.attach(trainer, metric_names=monitoring_metrics)\n\n    @trainer.on(Events.ITERATION_COMPLETED(every=PRINT_FREQ))\n    def print_logs(engine):\n        fname = os.path.join(output_dir, LOGS_FNAME)\n        columns = [""iteration"",] + list(engine.state.metrics.keys())\n        values = [str(engine.state.iteration),] + [str(round(value, 5)) for value in engine.state.metrics.values()]\n\n        with open(fname, ""a"") as f:\n            if f.tell() == 0:\n                print(""\\t"".join(columns), file=f)\n            print(""\\t"".join(values), file=f)\n\n        message = ""[{epoch}/{max_epoch}][{i}/{max_i}]"".format(\n            epoch=engine.state.epoch, max_epoch=epochs, i=(engine.state.iteration % len(loader)), max_i=len(loader)\n        )\n        for name, value in zip(columns, values):\n            message += "" | {name}: {value}"".format(name=name, value=value)\n\n        pbar.log_message(message)\n\n    # adding handlers using `trainer.on` decorator API\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def save_fake_example(engine):\n        fake = netG(fixed_noise)\n        path = os.path.join(output_dir, FAKE_IMG_FNAME.format(engine.state.epoch))\n        vutils.save_image(fake.detach(), path, normalize=True)\n\n    # adding handlers using `trainer.on` decorator API\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def save_real_example(engine):\n        img, y = engine.state.batch\n        path = os.path.join(output_dir, REAL_IMG_FNAME.format(engine.state.epoch))\n        vutils.save_image(img, path, normalize=True)\n\n    # adding handlers using `trainer.add_event_handler` method API\n    trainer.add_event_handler(\n        event_name=Events.EPOCH_COMPLETED, handler=checkpoint_handler, to_save={""netG"": netG, ""netD"": netD}\n    )\n\n    # automatically adding handlers via a special `attach` method of `Timer` handler\n    timer.attach(\n        trainer,\n        start=Events.EPOCH_STARTED,\n        resume=Events.ITERATION_STARTED,\n        pause=Events.ITERATION_COMPLETED,\n        step=Events.ITERATION_COMPLETED,\n    )\n\n    # adding handlers using `trainer.on` decorator API\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def print_times(engine):\n        pbar.log_message(""Epoch {} done. Time per batch: {:.3f}[s]"".format(engine.state.epoch, timer.value()))\n        timer.reset()\n\n    # adding handlers using `trainer.on` decorator API\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def create_plots(engine):\n        try:\n            import matplotlib as mpl\n\n            mpl.use(""agg"")\n\n            import numpy as np\n            import pandas as pd\n            import matplotlib.pyplot as plt\n\n        except ImportError:\n            warnings.warn(""Loss plots will not be generated -- pandas or matplotlib not found"")\n\n        else:\n            df = pd.read_csv(os.path.join(output_dir, LOGS_FNAME), delimiter=""\\t"", index_col=""iteration"")\n            _ = df.plot(subplots=True, figsize=(20, 20))\n            _ = plt.xlabel(""Iteration number"")\n            fig = plt.gcf()\n            path = os.path.join(output_dir, PLOT_FNAME)\n\n            fig.savefig(path)\n\n    # adding handlers using `trainer.on` decorator API\n    @trainer.on(Events.EXCEPTION_RAISED)\n    def handle_exception(engine, e):\n        if isinstance(e, KeyboardInterrupt) and (engine.state.iteration > 1):\n            engine.terminate()\n            warnings.warn(""KeyboardInterrupt caught. Exiting gracefully."")\n\n            create_plots(engine)\n            checkpoint_handler(engine, {""netG_exception"": netG, ""netD_exception"": netD})\n\n        else:\n            raise e\n\n    # Setup is done. Now let\'s run the training\n    trainer.run(loader, epochs)\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        ""--dataset"",\n        required=True,\n        choices={""cifar10"", ""lsun"", ""imagenet"", ""folder"", ""lfw"", ""fake"", ""mnist""},\n        help=""Type of the dataset to be used."",\n    )\n\n    parser.add_argument(""--dataroot"", required=True, help=""path to dataset"")\n\n    parser.add_argument(""--workers"", type=int, default=2, help=""number of data loading workers"")\n\n    parser.add_argument(""--batch-size"", type=int, default=64, help=""input batch size"")\n\n    parser.add_argument(""--z-dim"", type=int, default=100, help=""size of the latent z vector"")\n\n    parser.add_argument(\n        ""--g-filters"", type=int, default=64, help=""Number of filters in the second-to-last generator deconv layer""\n    )\n\n    parser.add_argument(""--d-filters"", type=int, default=64, help=""Number of filters in first discriminator conv layer"")\n\n    parser.add_argument(""--epochs"", type=int, default=25, help=""number of epochs to train for"")\n\n    parser.add_argument(""--lr"", type=float, default=0.0002, help=""learning rate"")\n\n    parser.add_argument(""--beta-1"", type=float, default=0.5, help=""beta_1 for adam"")\n\n    parser.add_argument(""--no-cuda"", action=""store_true"", help=""disables cuda"")\n\n    parser.add_argument(""--saved-G"", default="""", help=""path to pickled generator (to continue training)"")\n\n    parser.add_argument(""--saved-D"", default="""", help=""path to pickled discriminator (to continue training)"")\n\n    parser.add_argument(""--output-dir"", default=""."", help=""directory to output images and model checkpoints"")\n\n    parser.add_argument(""--seed"", type=int, help=""manual seed"")\n\n    parser.add_argument(""--alpha"", type=float, default=0.98, help=""smoothing constant for exponential moving averages"")\n\n    args = parser.parse_args()\n    dev = ""cpu"" if (not torch.cuda.is_available() or args.no_cuda) else ""cuda:0""\n\n    try:\n        os.makedirs(args.output_dir)\n    except FileExistsError:\n        if (not os.path.isdir(args.output_dir)) or (len(os.listdir(args.output_dir)) > 0):\n            raise FileExistsError(""Please provide a path to a non-existing or empty directory."")\n\n    main(\n        dataset=args.dataset,\n        dataroot=args.dataroot,\n        z_dim=args.z_dim,\n        g_filters=args.g_filters,\n        d_filters=args.d_filters,\n        batch_size=args.batch_size,\n        epochs=args.epochs,\n        learning_rate=args.lr,\n        beta_1=args.beta_1,\n        saved_D=args.saved_D,\n        saved_G=args.saved_G,\n        seed=args.seed,\n        device=dev,\n        n_workers=args.workers,\n        alpha=args.alpha,\n        output_dir=args.output_dir,\n    )\n'"
examples/mnist/mnist.py,4,"b'from argparse import ArgumentParser\n\nimport torch\nfrom torch import nn\nfrom torch.optim import SGD\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nfrom torchvision.transforms import Compose, ToTensor, Normalize\nfrom torchvision.datasets import MNIST\n\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.utils import setup_logger\n\nfrom tqdm import tqdm\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n    trainer.logger = setup_logger(""trainer"")\n    evaluator = create_supervised_evaluator(\n        model, metrics={""accuracy"": Accuracy(), ""nll"": Loss(F.nll_loss)}, device=device\n    )\n    evaluator.logger = setup_logger(""evaluator"")\n\n    desc = ""ITERATION - loss: {:.2f}""\n    pbar = tqdm(initial=0, leave=False, total=len(train_loader), desc=desc.format(0))\n\n    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n    def log_training_loss(engine):\n        pbar.desc = desc.format(engine.state.output)\n        pbar.update(log_interval)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_training_results(engine):\n        pbar.refresh()\n        evaluator.run(train_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        tqdm.write(\n            ""Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_validation_results(engine):\n        evaluator.run(val_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        tqdm.write(\n            ""Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n\n        pbar.n = pbar.last_print_n = 0\n\n    @trainer.on(Events.EPOCH_COMPLETED | Events.COMPLETED)\n    def log_time(engine):\n        tqdm.write(\n            ""{} took {} seconds"".format(trainer.last_event_name.name, trainer.state.times[trainer.last_event_name.name])\n        )\n\n    trainer.run(train_loader, max_epochs=epochs)\n    pbar.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n    parser.add_argument(\n        ""--log_interval"", type=int, default=10, help=""how many batches to wait before logging training status""\n    )\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_interval)\n'"
examples/mnist/mnist_save_resume_engine.py,9,"b'from pathlib import Path\nfrom argparse import ArgumentParser\n\nimport torch\nfrom torch import nn\nfrom torch.optim import SGD\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n\nfrom torchvision.transforms import Compose, ToTensor, Normalize\nfrom torchvision.datasets import MNIST\n\nfrom tqdm import tqdm\n\ntry:\n    from tensorboardX import SummaryWriter\nexcept ImportError:\n    try:\n        from torch.utils.tensorboard import SummaryWriter\n    except ImportError:\n        raise RuntimeError(\n            ""This module requires either tensorboardX or torch >= 1.2.0. ""\n            ""You may install tensorboardX with command: \\n pip install tensorboardX \\n""\n            ""or upgrade PyTorch using your package manager of choice (pip or conda).""\n        )\n\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import Checkpoint, DiskSaver\nfrom ignite.utils import manual_seed\n\n\n# Basic model\'s definition\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    """"""Method to setup data loaders: train_loader and val_loader\n    """"""\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True),\n        batch_size=train_batch_size,\n        shuffle=True,\n        num_workers=4,\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False),\n        batch_size=val_batch_size,\n        shuffle=False,\n        num_workers=4,\n    )\n    return train_loader, val_loader\n\n\ndef log_model_weights(engine, model=None, fp=None, **kwargs):\n    """"""Helper method to log norms of model weights: print and dump into a file\n    """"""\n    assert model and fp\n    output = {""total"": 0.0}\n    max_counter = 5\n    for name, p in model.named_parameters():\n        name = name.replace(""."", ""/"")\n        n = torch.norm(p)\n        if max_counter > 0:\n            output[name] = n\n        output[""total""] += n\n        max_counter -= 1\n\n    msg = ""{} | {}: {}"".format(\n        engine.state.epoch, engine.state.iteration, "" - "".join([""{}:{:.4f}"".format(m, v) for m, v in output.items()])\n    )\n\n    with open(fp, ""a"") as h:\n        h.write(msg)\n        h.write(""\\n"")\n\n\ndef log_model_grads(engine, model=None, fp=None, **kwargs):\n    """"""Helper method to log norms of model gradients: print and dump into a file\n    """"""\n    assert model and fp\n    output = {""grads/total"": 0.0}\n    max_counter = 5\n    for name, p in model.named_parameters():\n        if p.grad is None:\n            continue\n        name = name.replace(""."", ""/"")\n        n = torch.norm(p.grad)\n        if max_counter > 0:\n            output[""grads/{}"".format(name)] = n\n        output[""grads/total""] += n\n        max_counter -= 1\n\n    msg = ""{} | {}: {}"".format(\n        engine.state.epoch, engine.state.iteration, "" - "".join([""{}:{:.4f}"".format(m, v) for m, v in output.items()])\n    )\n\n    with open(fp, ""a"") as h:\n        h.write(msg)\n        h.write(""\\n"")\n\n\ndef log_data_stats(engine, fp=None, **kwargs):\n    """"""Helper method to log mean/std of input batch of images and median of batch of targets.\n    """"""\n    assert fp\n    x, y = engine.state.batch\n    output = {\n        ""batch xmean"": x.mean().item(),\n        ""batch xstd"": x.std().item(),\n        ""batch ymedian"": y.median().item(),\n    }\n\n    msg = ""{} | {}: {}"".format(\n        engine.state.epoch, engine.state.iteration, "" - "".join([""{}:{:.7f}"".format(m, v) for m, v in output.items()])\n    )\n\n    with open(fp, ""a"") as h:\n        h.write(msg)\n        h.write(""\\n"")\n\n\ndef run(\n    train_batch_size,\n    val_batch_size,\n    epochs,\n    lr,\n    momentum,\n    log_interval,\n    log_dir,\n    checkpoint_every,\n    resume_from,\n    crash_iteration=-1,\n    deterministic=False,\n):\n    # Setup seed to have same model\'s initialization:\n    manual_seed(75)\n\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    writer = SummaryWriter(log_dir=log_dir)\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    criterion = nn.NLLLoss()\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    lr_scheduler = StepLR(optimizer, step_size=1, gamma=0.5)\n\n    # Setup trainer and evaluator\n    if deterministic:\n        tqdm.write(""Setup deterministic trainer"")\n    trainer = create_supervised_trainer(model, optimizer, criterion, device=device, deterministic=deterministic)\n\n    evaluator = create_supervised_evaluator(\n        model, metrics={""accuracy"": Accuracy(), ""nll"": Loss(criterion)}, device=device\n    )\n\n    # Apply learning rate scheduling\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def lr_step(engine):\n        lr_scheduler.step()\n\n    desc = ""Epoch {} - loss: {:.4f} - lr: {:.4f}""\n    pbar = tqdm(initial=0, leave=False, total=len(train_loader), desc=desc.format(0, 0, lr))\n\n    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n    def log_training_loss(engine):\n        lr = optimizer.param_groups[0][""lr""]\n        pbar.desc = desc.format(engine.state.epoch, engine.state.output, lr)\n        pbar.update(log_interval)\n        writer.add_scalar(""training/loss"", engine.state.output, engine.state.iteration)\n        writer.add_scalar(""lr"", lr, engine.state.iteration)\n\n    if crash_iteration > 0:\n\n        @trainer.on(Events.ITERATION_COMPLETED(once=crash_iteration))\n        def _(engine):\n            raise Exception(""STOP at {}"".format(engine.state.iteration))\n\n    if resume_from is not None:\n\n        @trainer.on(Events.STARTED)\n        def _(engine):\n            pbar.n = engine.state.iteration % engine.state.epoch_length\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_training_results(engine):\n        pbar.refresh()\n        evaluator.run(train_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        tqdm.write(\n            ""Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n        writer.add_scalar(""training/avg_loss"", avg_nll, engine.state.epoch)\n        writer.add_scalar(""training/avg_accuracy"", avg_accuracy, engine.state.epoch)\n\n    # Compute and log validation metrics\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_validation_results(engine):\n        evaluator.run(val_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        tqdm.write(\n            ""Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n        pbar.n = pbar.last_print_n = 0\n        writer.add_scalar(""valdation/avg_loss"", avg_nll, engine.state.epoch)\n        writer.add_scalar(""valdation/avg_accuracy"", avg_accuracy, engine.state.epoch)\n\n    # Setup object to checkpoint\n    objects_to_checkpoint = {""trainer"": trainer, ""model"": model, ""optimizer"": optimizer, ""lr_scheduler"": lr_scheduler}\n    training_checkpoint = Checkpoint(\n        to_save=objects_to_checkpoint,\n        save_handler=DiskSaver(log_dir, require_empty=False),\n        n_saved=None,\n        global_step_transform=lambda *_: trainer.state.epoch,\n    )\n    trainer.add_event_handler(Events.EPOCH_COMPLETED(every=checkpoint_every), training_checkpoint)\n\n    # Setup logger to print and dump into file: model weights, model grads and data stats\n    # - first 3 iterations\n    # - 4 iterations after checkpointing\n    # This helps to compare resumed training with checkpointed training\n    def log_event_filter(e, event):\n        if event in [1, 2, 3]:\n            return True\n        elif 0 <= (event % (checkpoint_every * e.state.epoch_length)) < 5:\n            return True\n        return False\n\n    fp = Path(log_dir) / (""run.log"" if resume_from is None else ""resume_run.log"")\n    fp = fp.as_posix()\n    for h in [log_data_stats, log_model_weights, log_model_grads]:\n        trainer.add_event_handler(Events.ITERATION_COMPLETED(event_filter=log_event_filter), h, model=model, fp=fp)\n\n    if resume_from is not None:\n        tqdm.write(""Resume from the checkpoint: {}"".format(resume_from))\n        checkpoint = torch.load(resume_from)\n        Checkpoint.load_objects(to_load=objects_to_checkpoint, checkpoint=checkpoint)\n\n    try:\n        # Synchronize random states\n        manual_seed(15)\n        trainer.run(train_loader, max_epochs=epochs)\n    except Exception as e:\n        import traceback\n\n        print(traceback.format_exc())\n\n    pbar.close()\n    writer.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n    parser.add_argument(\n        ""--log_interval"", type=int, default=10, help=""how many batches to wait before logging training status""\n    )\n    parser.add_argument(\n        ""--log_dir"", type=str, default=""/tmp/mnist_save_resume"", help=""log directory for Tensorboard log output""\n    )\n    parser.add_argument(""--checkpoint_every"", type=int, default=1, help=""Checkpoint training every X epochs"")\n    parser.add_argument(\n        ""--resume_from"", type=str, default=None, help=""Path to the checkpoint .pt file to resume training from""\n    )\n    parser.add_argument(""--crash_iteration"", type=int, default=-1, help=""Iteration at which to raise an exception"")\n    parser.add_argument(\n        ""--deterministic"", action=""store_true"", help=""Deterministic training with dataflow synchronization""\n    )\n\n    args = parser.parse_args()\n\n    run(\n        args.batch_size,\n        args.val_batch_size,\n        args.epochs,\n        args.lr,\n        args.momentum,\n        args.log_interval,\n        args.log_dir,\n        args.checkpoint_every,\n        args.resume_from,\n        args.crash_iteration,\n        args.deterministic,\n    )\n'"
examples/mnist/mnist_with_tensorboard.py,5,"b'""""""\n MNIST example with training and validation monitoring using Tensorboard.\n Requirements:\n    TensorboardX (https://github.com/lanpa/tensorboard-pytorch): `pip install tensorboardX`\n    or PyTorch >= 1.2 which supports Tensorboard\n    Tensorboard: `pip install tensorflow` (or just install tensorboard without the rest of tensorflow)\n Usage:\n    Start tensorboard:\n    ```bash\n    tensorboard --logdir=/tmp/tensorboard_logs/\n    ```\n    Run the example:\n    ```bash\n    python mnist_with_tensorboard.py --log_dir=/tmp/tensorboard_logs\n    ```\n""""""\n\nfrom argparse import ArgumentParser\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.optim import SGD\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import Compose, ToTensor, Normalize\n\ntry:\n    from tensorboardX import SummaryWriter\nexcept ImportError:\n    try:\n        from torch.utils.tensorboard import SummaryWriter\n    except ImportError:\n        raise RuntimeError(\n            ""This module requires either tensorboardX or torch >= 1.2.0. ""\n            ""You may install tensorboardX with command: \\n pip install tensorboardX \\n""\n            ""or upgrade PyTorch using your package manager of choice (pip or conda).""\n        )\n\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef create_summary_writer(model, data_loader, log_dir):\n    writer = SummaryWriter(log_dir=log_dir)\n    data_loader_iter = iter(data_loader)\n    x, y = next(data_loader_iter)\n    try:\n        writer.add_graph(model, x)\n    except Exception as e:\n        print(""Failed to save model graph: {}"".format(e))\n    return writer\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval, log_dir):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    writer = create_summary_writer(model, train_loader, log_dir)\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n    evaluator = create_supervised_evaluator(\n        model, metrics={""accuracy"": Accuracy(), ""nll"": Loss(F.nll_loss)}, device=device\n    )\n\n    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n    def log_training_loss(engine):\n        print(\n            ""Epoch[{}] Iteration[{}/{}] Loss: {:.2f}""\n            """".format(engine.state.epoch, engine.state.iteration, len(train_loader), engine.state.output)\n        )\n        writer.add_scalar(""training/loss"", engine.state.output, engine.state.iteration)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_training_results(engine):\n        evaluator.run(train_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        print(\n            ""Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n        writer.add_scalar(""training/avg_loss"", avg_nll, engine.state.epoch)\n        writer.add_scalar(""training/avg_accuracy"", avg_accuracy, engine.state.epoch)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_validation_results(engine):\n        evaluator.run(val_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        print(\n            ""Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n        writer.add_scalar(""valdation/avg_loss"", avg_nll, engine.state.epoch)\n        writer.add_scalar(""valdation/avg_accuracy"", avg_accuracy, engine.state.epoch)\n\n    # kick everything off\n    trainer.run(train_loader, max_epochs=epochs)\n\n    writer.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n    parser.add_argument(\n        ""--log_interval"", type=int, default=10, help=""how many batches to wait before logging training status""\n    )\n    parser.add_argument(\n        ""--log_dir"", type=str, default=""tensorboard_logs"", help=""log directory for Tensorboard log output""\n    )\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_interval, args.log_dir)\n'"
examples/mnist/mnist_with_tensorboard_on_tpu.py,4,"b'""""""\n MNIST example with training and validation monitoring using Tensorboard on TPU\n Requirements:\n    - PyTorch >= 1.5\n    - PyTorch XLA >= 1.5\n    - Tensorboard: `pip install tensorflow` (or just install tensorboard without the rest of tensorflow)\n Usage:\n    Start tensorboard:\n    ```bash\n    tensorboard --logdir=/tmp/tensorboard_logs/\n    ```\n    Run the example:\n    ```bash\n    python mnist_with_tensorboard_on_tpu.py --log_dir=/tmp/tensorboard_logs\n    ```\n""""""\n\nfrom argparse import ArgumentParser\n\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.optim import SGD\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import Compose, ToTensor, Normalize\n\ntry:\n    import torch_xla.core.xla_model as xm\nexcept ImportError:\n    raise RuntimeError(\n        ""In order to run PyTorch on TPU we need to install PyTorch XLA:""\n        ""\\n\\t- curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o xla-setup.py""\n        ""\\n\\t- python xla-setup.py --version 1.5""\n    )\n\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss, RunningAverage\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval, log_dir):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    writer = SummaryWriter(log_dir=log_dir)\n\n    # Use TPU device\n    device = xm.xla_device()\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n\n    # Create trainer and evaluator\n    trainer = create_supervised_trainer(\n        model, optimizer, F.nll_loss, device=device, output_transform=lambda x, y, y_pred, loss: [loss.item(),]\n    )\n\n    evaluator = create_supervised_evaluator(\n        model, metrics={""accuracy"": Accuracy(), ""nll"": Loss(F.nll_loss)}, device=device\n    )\n\n    tracker = xm.RateTracker()\n\n    # Add RateTracker as an output of the training step\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def add_rate_tracker(engine):\n        tracker.add(len(engine.state.batch))\n        engine.state.output.append(tracker.global_rate())\n\n    # Setup output values of the training step as EMA metrics\n    RunningAverage(output_transform=lambda x: x[0]).attach(trainer, ""batch_loss"")\n    RunningAverage(output_transform=lambda x: x[1]).attach(trainer, ""global_rate"")\n\n    # Let\'s log the EMA metrics every `log_interval` iterations\n    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n    def log_training_loss(engine):\n        writer.add_scalar(""training/batch_loss"", engine.state.metrics[""batch_loss""], engine.state.iteration)\n        writer.add_scalar(""training/global_rate"", engine.state.metrics[""global_rate""], engine.state.iteration)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_training_results(engine):\n        evaluator.run(train_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        print(\n            ""Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n        writer.add_scalar(""training/avg_loss"", avg_nll, engine.state.epoch)\n        writer.add_scalar(""training/avg_accuracy"", avg_accuracy, engine.state.epoch)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_validation_results(engine):\n        evaluator.run(val_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        print(\n            ""Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n        writer.add_scalar(""valdation/avg_loss"", avg_nll, engine.state.epoch)\n        writer.add_scalar(""valdation/avg_accuracy"", avg_accuracy, engine.state.epoch)\n\n    # kick everything off\n    trainer.run(train_loader, max_epochs=epochs)\n\n    writer.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n    parser.add_argument(\n        ""--log_interval"", type=int, default=10, help=""how many batches to wait before logging training status""\n    )\n    parser.add_argument(\n        ""--log_dir"", type=str, default=""tensorboard_logs"", help=""log directory for Tensorboard log output""\n    )\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_interval, args.log_dir)\n'"
examples/mnist/mnist_with_visdom.py,4,"b'from argparse import ArgumentParser\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.optim import SGD\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import Compose, ToTensor, Normalize\nimport numpy as np\n\ntry:\n    import visdom\nexcept ImportError:\n    raise RuntimeError(""No visdom package is found. Please install it with command: \\n pip install visdom"")\n\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef create_plot_window(vis, xlabel, ylabel, title):\n    return vis.line(X=np.array([1]), Y=np.array([np.nan]), opts=dict(xlabel=xlabel, ylabel=ylabel, title=title))\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):\n    vis = visdom.Visdom()\n\n    # if not vis.check_connection():\n    #     raise RuntimeError(""Visdom server not running. Please run python -m visdom.server"")\n\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n    evaluator = create_supervised_evaluator(\n        model, metrics={""accuracy"": Accuracy(), ""nll"": Loss(F.nll_loss)}, device=device\n    )\n\n    train_loss_window = create_plot_window(vis, ""#Iterations"", ""Loss"", ""Training Loss"")\n    train_avg_loss_window = create_plot_window(vis, ""#Iterations"", ""Loss"", ""Training Average Loss"")\n    train_avg_accuracy_window = create_plot_window(vis, ""#Iterations"", ""Accuracy"", ""Training Average Accuracy"")\n    val_avg_loss_window = create_plot_window(vis, ""#Epochs"", ""Loss"", ""Validation Average Loss"")\n    val_avg_accuracy_window = create_plot_window(vis, ""#Epochs"", ""Accuracy"", ""Validation Average Accuracy"")\n\n    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n    def log_training_loss(engine):\n        print(\n            ""Epoch[{}] Iteration[{}/{}] Loss: {:.2f}""\n            """".format(engine.state.epoch, engine.state.iteration, len(train_loader), engine.state.output)\n        )\n        vis.line(\n            X=np.array([engine.state.iteration]),\n            Y=np.array([engine.state.output]),\n            update=""append"",\n            win=train_loss_window,\n        )\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_training_results(engine):\n        evaluator.run(train_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        print(\n            ""Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n        vis.line(\n            X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]), win=train_avg_accuracy_window, update=""append""\n        )\n        vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_nll]), win=train_avg_loss_window, update=""append"")\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_validation_results(engine):\n        evaluator.run(val_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        print(\n            ""Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n        vis.line(\n            X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]), win=val_avg_accuracy_window, update=""append""\n        )\n        vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_nll]), win=val_avg_loss_window, update=""append"")\n\n    # kick everything off\n    trainer.run(train_loader, max_epochs=epochs)\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n    parser.add_argument(\n        ""--log_interval"", type=int, default=10, help=""how many batches to wait before logging training status""\n    )\n    parser.add_argument(""--log_file"", type=str, default=None, help=""log file to log output to"")\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_interval)\n'"
examples/reinforcement_learning/actor_critic.py,9,"b'import argparse\nfrom collections import namedtuple\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.distributions import Categorical\n\ntry:\n    import gym\nexcept ImportError:\n    raise RuntimeError(""Please install opengym: pip install gym"")\n\n\nfrom ignite.engine import Engine, Events\n\n\nSavedAction = namedtuple(""SavedAction"", [""log_prob"", ""value""])\n\n\nclass Policy(nn.Module):\n    def __init__(self):\n        super(Policy, self).__init__()\n        self.affine1 = nn.Linear(4, 128)\n        self.action_head = nn.Linear(128, 2)\n        self.value_head = nn.Linear(128, 1)\n\n        self.saved_actions = []\n        self.rewards = []\n\n    def forward(self, x):\n        x = F.relu(self.affine1(x))\n        action_scores = self.action_head(x)\n        state_values = self.value_head(x)\n        return F.softmax(action_scores, dim=-1), state_values\n\n\ndef select_action(model, observation):\n    observation = torch.from_numpy(observation).float()\n    probs, observation_value = model(observation)\n    m = Categorical(probs)\n    action = m.sample()\n    model.saved_actions.append(SavedAction(m.log_prob(action), observation_value))\n    return action.item()\n\n\ndef finish_episode(model, optimizer, gamma, eps):\n    R = 0\n    saved_actions = model.saved_actions\n    policy_losses = []\n    value_losses = []\n    rewards = []\n    for r in model.rewards[::-1]:\n        R = r + gamma * R\n        rewards.insert(0, R)\n    rewards = torch.tensor(rewards)\n    rewards = (rewards - rewards.mean()) / (rewards.std() + eps)\n    for (log_prob, value), r in zip(saved_actions, rewards):\n        reward = r - value.item()\n        policy_losses.append(-log_prob * reward)\n        value_losses.append(F.smooth_l1_loss(value, torch.tensor([r])))\n    optimizer.zero_grad()\n    loss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()\n    loss.backward()\n    optimizer.step()\n    del model.rewards[:]\n    del model.saved_actions[:]\n\n\nEPISODE_STARTED = Events.EPOCH_STARTED\nEPISODE_COMPLETED = Events.EPOCH_COMPLETED\n\n\ndef main(env, args):\n\n    model = Policy()\n    optimizer = optim.Adam(model.parameters(), lr=3e-2)\n    eps = np.finfo(np.float32).eps.item()\n    timesteps = list(range(10000))\n\n    def run_single_timestep(engine, timestep):\n        observation = engine.state.observation\n        action = select_action(model, observation)\n        engine.state.observation, reward, done, _ = env.step(action)\n        if args.render:\n            env.render()\n        model.rewards.append(reward)\n\n        if done:\n            engine.terminate_epoch()\n            engine.state.timestep = timestep\n\n    trainer = Engine(run_single_timestep)\n\n    @trainer.on(Events.STARTED)\n    def initialize(engine):\n        engine.state.running_reward = 10\n\n    @trainer.on(EPISODE_STARTED)\n    def reset_environment_state(engine):\n        engine.state.observation = env.reset()\n\n    @trainer.on(EPISODE_COMPLETED)\n    def update_model(engine):\n        t = engine.state.timestep\n        engine.state.running_reward = engine.state.running_reward * 0.99 + t * 0.01\n        finish_episode(model, optimizer, args.gamma, eps)\n\n    @trainer.on(EPISODE_COMPLETED(every=args.log_interval))\n    def log_episode(engine):\n        i_episode = engine.state.epoch\n        print(\n            ""Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}"".format(\n                i_episode, engine.state.timestep, engine.state.running_reward\n            )\n        )\n\n    @trainer.on(EPISODE_COMPLETED)\n    def should_finish_training(engine):\n        running_reward = engine.state.running_reward\n        if running_reward > env.spec.reward_threshold:\n            print(\n                ""Solved! Running reward is now {} and ""\n                ""the last episode runs to {} time steps!"".format(running_reward, engine.state.timestep)\n            )\n            engine.should_terminate = True\n\n    trainer.run(timesteps, max_epochs=args.max_episodes)\n\n\nif __name__ == ""__main__"":\n\n    parser = argparse.ArgumentParser(description=""Ignite actor-critic example"")\n    parser.add_argument(""--gamma"", type=float, default=0.99, metavar=""G"", help=""discount factor (default: 0.99)"")\n    parser.add_argument(""--seed"", type=int, default=543, metavar=""N"", help=""random seed (default: 1)"")\n    parser.add_argument(""--render"", action=""store_true"", help=""render the environment"")\n    parser.add_argument(\n        ""--log-interval"", type=int, default=10, metavar=""N"", help=""interval between training status logs (default: 10)""\n    )\n    parser.add_argument(\n        ""--max-episodes"",\n        type=int,\n        default=1000000,\n        metavar=""N"",\n        help=""Number of episodes for the training (default: 1000000)"",\n    )\n    args = parser.parse_args()\n\n    env = gym.make(""CartPole-v0"")\n    env.seed(args.seed)\n    torch.manual_seed(args.seed)\n\n    main(env, args)\n'"
examples/reinforcement_learning/reinforce.py,8,"b'import argparse\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.distributions import Categorical\n\ntry:\n    import gym\nexcept ImportError:\n    raise RuntimeError(""Please install opengym: pip install gym"")\n\n\nfrom ignite.engine import Engine, Events\n\n\nclass Policy(nn.Module):\n    def __init__(self):\n        super(Policy, self).__init__()\n        self.affine1 = nn.Linear(4, 128)\n        self.affine2 = nn.Linear(128, 2)\n\n        self.saved_log_probs = []\n        self.rewards = []\n\n    def forward(self, x):\n        x = F.relu(self.affine1(x))\n        action_scores = self.affine2(x)\n        return F.softmax(action_scores, dim=1)\n\n\ndef select_action(model, observation):\n    state = torch.from_numpy(observation).float().unsqueeze(0)\n    probs = model(state)\n    m = Categorical(probs)\n    action = m.sample()\n    model.saved_log_probs.append(m.log_prob(action))\n    return action.item()\n\n\ndef finish_episode(model, optimizer, gamma, eps):\n    R = 0\n    policy_loss = []\n    rewards = []\n    for r in model.rewards[::-1]:\n        R = r + gamma * R\n        rewards.insert(0, R)\n    rewards = torch.tensor(rewards)\n    rewards = (rewards - rewards.mean()) / (rewards.std() + eps)\n    for log_prob, reward in zip(model.saved_log_probs, rewards):\n        policy_loss.append(-log_prob * reward)\n    optimizer.zero_grad()\n    policy_loss = torch.cat(policy_loss).sum()\n    policy_loss.backward()\n    optimizer.step()\n    del model.rewards[:]\n    del model.saved_log_probs[:]\n\n\nEPISODE_STARTED = Events.EPOCH_STARTED\nEPISODE_COMPLETED = Events.EPOCH_COMPLETED\n\n\ndef main(env, args):\n\n    model = Policy()\n    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n    eps = np.finfo(np.float32).eps.item()\n    timesteps = list(range(10000))\n\n    def run_single_timestep(engine, timestep):\n        observation = engine.state.observation\n        action = select_action(model, observation)\n        engine.state.observation, reward, done, _ = env.step(action)\n        if args.render:\n            env.render()\n        model.rewards.append(reward)\n\n        if done:\n            engine.terminate_epoch()\n            engine.state.timestep = timestep\n\n    trainer = Engine(run_single_timestep)\n\n    @trainer.on(Events.STARTED)\n    def initialize(engine):\n        engine.state.running_reward = 10\n\n    @trainer.on(EPISODE_STARTED)\n    def reset_environment_state(engine):\n        engine.state.observation = env.reset()\n\n    @trainer.on(EPISODE_COMPLETED)\n    def update_model(engine):\n        t = engine.state.timestep\n        engine.state.running_reward = engine.state.running_reward * 0.99 + t * 0.01\n        finish_episode(model, optimizer, args.gamma, eps)\n\n    @trainer.on(EPISODE_COMPLETED(every=args.log_interval))\n    def log_episode(engine):\n        i_episode = engine.state.epoch\n        print(\n            ""Episode {}\\tLast length: {:5d}\\tAverage length: {:.2f}"".format(\n                i_episode, engine.state.timestep, engine.state.running_reward\n            )\n        )\n\n    @trainer.on(EPISODE_COMPLETED)\n    def should_finish_training(engine):\n        running_reward = engine.state.running_reward\n        if running_reward > env.spec.reward_threshold:\n            print(\n                ""Solved! Running reward is now {} and ""\n                ""the last episode runs to {} time steps!"".format(running_reward, engine.state.timestep)\n            )\n            engine.should_terminate = True\n\n    trainer.run(timesteps, max_epochs=args.max_episodes)\n\n\nif __name__ == ""__main__"":\n\n    parser = argparse.ArgumentParser(description=""PyTorch REINFORCE example"")\n    parser.add_argument(""--gamma"", type=float, default=0.99, metavar=""G"", help=""discount factor (default: 0.99)"")\n    parser.add_argument(""--seed"", type=int, default=543, metavar=""N"", help=""random seed (default: 543)"")\n    parser.add_argument(""--render"", action=""store_true"", help=""render the environment"")\n    parser.add_argument(\n        ""--log-interval"", type=int, default=10, metavar=""N"", help=""interval between training status logs (default: 10)""\n    )\n    parser.add_argument(\n        ""--max-episodes"",\n        type=int,\n        default=1000000,\n        metavar=""N"",\n        help=""Number of episodes for the training (default: 1000000)"",\n    )\n    args = parser.parse_args()\n\n    env = gym.make(""CartPole-v0"")\n    env.seed(args.seed)\n    torch.manual_seed(args.seed)\n\n    main(env, args)\n'"
ignite/base/__init__.py,0,b'from ignite.base.mixins import Serializable\n'
ignite/base/mixins.py,0,"b'from collections import OrderedDict\nfrom collections.abc import Mapping\n\n\nclass Serializable:\n\n    _state_dict_all_req_keys = ()\n    _state_dict_one_of_opt_keys = ()\n\n    def state_dict(self) -> OrderedDict:\n        pass\n\n    def load_state_dict(self, state_dict: Mapping) -> None:\n        if not isinstance(state_dict, Mapping):\n            raise TypeError(""Argument state_dict should be a dictionary, but given {}"".format(type(state_dict)))\n\n        for k in self._state_dict_all_req_keys:\n            if k not in state_dict:\n                raise ValueError(\n                    ""Required state attribute \'{}\' is absent in provided state_dict \'{}\'"".format(k, state_dict.keys())\n                )\n        opts = [k in state_dict for k in self._state_dict_one_of_opt_keys]\n        if len(opts) > 0 and ((not any(opts)) or (all(opts))):\n            raise ValueError(""state_dict should contain only one of \'{}\' keys"".format(self._state_dict_one_of_opt_keys))\n'"
ignite/contrib/__init__.py,0,b''
ignite/distributed/__init__.py,0,b'from ignite.distributed.utils import *\n'
ignite/distributed/utils.py,23,"b'import socket\nfrom functools import wraps\nfrom numbers import Number\nfrom typing import Callable, List, Mapping, Optional, Tuple, Union\n\nimport torch\nimport torch.distributed as dist\n\nfrom ignite.distributed.comp_models import (\n    _SerialModel,\n    has_native_dist_support,\n    has_xla_support,\n    registered_computation_models,\n)\nfrom ignite.utils import setup_logger\n\n__all__ = [\n    ""backend"",\n    ""device"",\n    ""available_backends"",\n    ""model_name"",\n    ""get_world_size"",\n    ""get_rank"",\n    ""get_local_rank"",\n    ""get_ntasks_per_node"",\n    ""get_node_rank"",\n    ""get_num_nodes"",\n    ""spawn"",\n    ""initialize"",\n    ""finalize"",\n    ""show_config"",\n    ""set_local_rank"",\n    ""all_reduce"",\n    ""all_gather"",\n    ""barrier"",\n    ""hostname"",\n    ""has_xla_support"",\n    ""has_native_dist_support"",\n    ""sync"",\n    ""registered_computation_models"",\n    ""one_rank_only"",\n]\n\n_model = _SerialModel()\n\n_need_to_sync = True\n\n\ndef _sync_model_wrapper(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if isinstance(_model, _SerialModel) and _need_to_sync:\n            sync()\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\ndef sync():\n    """"""Helper method to force this module to synchronize with current distributed context.\n    This method should be used when distributed context is manually created or destroyed.\n    """"""\n    global _model\n\n    for comp_model_cls in registered_computation_models:\n        if comp_model_cls == _SerialModel:\n            continue\n        model = comp_model_cls.create_from_context()\n        if model is not None:\n            _model = model\n            return\n\n    _model = _SerialModel()\n\n\n@_sync_model_wrapper\ndef device() -> torch.device:\n    """"""Returns current device according to current distributed configuration.\n\n    - `torch.device(""cpu"")` if no distributed configuration or native gloo distributed configuration\n    - `torch.device(""cuda:local_rank"")` if native nccl distributed configuration\n    - `torch.device(""xla:index"")` if XLA distributed configuration\n\n    Returns:\n        torch.device\n    """"""\n    return _model.device()\n\n\n@_sync_model_wrapper\ndef backend() -> Optional[str]:\n    """"""Returns computation model\'s backend.\n\n    - `None` for no distributed configuration\n    - ""nccl"" or ""gloo"" or ""mpi"" for native torch distributed configuration\n    - ""xla-tpu"" for XLA distributed configuration\n\n    Returns:\n        str or None\n    """"""\n    return _model.backend()\n\n\ndef available_backends() -> Tuple[str]:\n    """"""Returns available backends.\n    """"""\n    out = ()\n    for m in registered_computation_models:\n        out += m.available_backends\n    return out\n\n\n@_sync_model_wrapper\ndef model_name() -> str:\n    """"""Returns distributed configuration name (given by ignite)\n\n    - `serial` for no distributed configuration\n    - `native-dist` for native torch distributed configuration\n    - `xla-dist` for XLA distributed configuration\n\n    """"""\n    return _model.name\n\n\n@_sync_model_wrapper\ndef get_world_size() -> int:\n    """"""Returns world size of current distributed configuration. Returns 1 if no distributed configuration.\n    """"""\n    return _model.get_world_size()\n\n\n@_sync_model_wrapper\ndef get_rank() -> int:\n    """"""Returns process rank within current distributed configuration. Returns 0 if no distributed configuration.\n    """"""\n    return _model.get_rank()\n\n\n@_sync_model_wrapper\ndef get_local_rank() -> int:\n    """"""Returns local process rank within current distributed configuration. Returns 0 if no distributed configuration.\n    """"""\n    return _model.get_local_rank()\n\n\n@_sync_model_wrapper\ndef get_ntasks_per_node() -> int:\n    """"""Returns number of processes (or tasks) per node within current distributed configuration.\n    Returns 1 if no distributed configuration.\n    """"""\n    return _model.get_ntasks_per_node()\n\n\n@_sync_model_wrapper\ndef get_num_nodes() -> int:\n    """"""Returns number of nodes within current distributed configuration.\n    Returns 1 if no distributed configuration.\n    """"""\n    return _model.get_num_nodes()\n\n\n@_sync_model_wrapper\ndef get_node_rank() -> int:\n    """"""Returns node rank within current distributed configuration.\n    Returns 0 if no distributed configuration.\n    """"""\n    return _model.get_node_rank()\n\n\ndef hostname() -> str:\n    """"""Returns host name for current process within current distributed configuration.\n    """"""\n    return socket.gethostname()\n\n\ndef spawn(\n    backend: str,\n    fn: Callable,\n    args: Tuple,\n    kwargs_dict: Optional[Mapping] = None,\n    num_procs_per_node: int = 1,\n    **kwargs\n):\n    """"""Spawns ``num_procs_per_node`` processes that run ``fn`` with ``args``/``kwargs_dict`` and initialize\n    distributed configuration defined by ``backend``.\n\n    Examples:\n\n        1) Launch single node multi-GPU training\n\n        .. code-block:: python\n\n            # >>> python main.py\n\n            # main.py\n\n            import ignite.distributed as idist\n\n            def train_fn(local_rank, a, b, c, d=12):\n                import torch.distributed as dist\n                assert dist.is_available() and dist.is_initialized()\n                assert dist.get_world_size() == 4\n\n                device = idist.device()\n                assert device == torch.device(""cuda:{}"".format(local_rank))\n\n\n            idist.spawn(""nccl"", train_fn, args=(a, b, c), kwargs_dict={""d"": 23}, num_procs_per_node=4)\n\n\n        2) Launch multi-node multi-GPU training\n\n        .. code-block:: python\n\n            # >>> (node 0): python main.py --node_rank=0 --num_nodes=8 --master_addr=master --master_port=2222\n            # >>> (node 1): python main.py --node_rank=1 --num_nodes=8 --master_addr=master --master_port=2222\n            # >>> ...\n            # >>> (node 7): python main.py --node_rank=7 --num_nodes=8 --master_addr=master --master_port=2222\n\n            # main.py\n\n            import torch\n            import ignite.distributed as idist\n\n            def train_fn(local_rank, num_nodes, num_procs_per_node):\n                import torch.distributed as dist\n                assert dist.is_available() and dist.is_initialized()\n                assert dist.get_world_size() == num_nodes * num_procs_per_node\n\n                device = idist.device()\n                assert device == torch.device(""cuda:{}"".format(local_rank))\n\n            idist.spawn(\n                ""nccl"",\n                train_fn,\n                args=(num_nodes, num_procs_per_node),\n                num_procs_per_node=num_procs_per_node,\n                num_nodes=num_nodes,\n                node_rank=node_rank,\n                master_addr=master_addr,\n                master_port=master_port\n            )\n\n        3) Launch single node multi-TPU training (for example on Google Colab)\n\n        .. code-block:: python\n\n            # >>> python main.py\n\n            # main.py\n\n            import ignite.distributed as idist\n\n            def train_fn(local_rank, a, b, c, d=12):\n                import torch_xla.core.xla_model as xm\n                assert xm.get_world_size() == 8\n\n                device = idist.device()\n                assert ""xla"" in device.type\n\n\n            idist.spawn(""xla-tpu"", train_fn, args=(a, b, c), kwargs_dict={""d"": 23}, num_procs_per_node=8)\n\n    Args:\n        backend (str): backend to use: `nccl`, `gloo`, `xla-tpu`\n        fn (function): function to called as the entrypoint of the spawned process.\n            This function must be defined at the top level of a module so it can be pickled and spawned.\n            This is a requirement imposed by multiprocessing. The function is called as ``fn(i, *args, **kwargs_dict)``,\n            where `i` is the process index and args is the passed through tuple of arguments.\n        args (tuple): arguments passed to `fn`.\n        kwargs_dict (Mapping): kwargs passed to `fn`.\n        num_procs_per_node (int): number of processes to spawn on a single node. Default, 1.\n        **kwargs: acceptable kwargs according to provided backend:\n\n            - | ""nccl"" or ""gloo"" : `num_nodes` (default, 1), `node_rank` (default, 0), `master_addr`\n              | (default, ""127.0.0.1""), `master_port` (default, 2222), `timeout` to `dist.init_process_group`_ function\n              | and kwargs for `mp.spawn`_ function.\n\n            - ""xla-tpu"" : `num_nodes` (default, 1), `node_rank` (default, 0) and kwargs to `xmp.spawn`_ function.\n\n    .. _dist.init_process_group: https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group\n    .. _mp.spawn: https://pytorch.org/docs/stable/multiprocessing.html#torch.multiprocessing.spawn\n    .. _xmp.spawn: http://pytorch.org/xla/release/1.5/index.html#torch_xla.distributed.xla_multiprocessing.spawn\n\n    """"""\n    _assert_backend(backend)\n\n    if kwargs_dict is None:\n        kwargs_dict = {}\n\n    for comp_model_cls in registered_computation_models:\n        if backend not in comp_model_cls.available_backends:\n            continue\n        comp_model_cls.spawn(\n            fn, args=args, kwargs_dict=kwargs_dict, num_procs_per_node=num_procs_per_node, backend=backend, **kwargs\n        )\n\n\n@_sync_model_wrapper\ndef all_reduce(tensor: Union[torch.Tensor, Number], op: str = ""SUM"") -> Union[torch.Tensor, Number]:\n    """"""Helper method to perform all reduce operation.\n\n    Args:\n        tensor (torch.Tensor or number): tensor or number to collect across participating processes.\n        op (str): reduction operation, ""SUM"" by default. Possible values: ""SUM"", ""PRODUCT"", ""MIN"", ""MAX"", ""AND"", ""OR"".\n\n    Returns:\n        torch.Tensor or number\n\n    """"""\n    return _model.all_reduce(tensor, op)\n\n\n@_sync_model_wrapper\ndef all_gather(tensor: Union[torch.Tensor, Number, str]) -> Union[torch.Tensor, Number, List[str]]:\n    """"""Helper method to perform all gather operation.\n\n    Args:\n        tensor (torch.Tensor or number or str): tensor or number or str to collect across participating processes.\n\n    Returns:\n        torch.Tensor of shape `(world_size * tensor.shape[0], tensor.shape[1], ...)` or\n        List of strings\n\n    """"""\n    return _model.all_gather(tensor)\n\n\n@_sync_model_wrapper\ndef barrier():\n    """"""Helper method to synchronize all processes.\n    """"""\n    _model.barrier()\n\n\ndef set_local_rank(index: int):\n    """"""Method to hint the local rank in case if torch native distributed context is created by user\n    without using :meth:`~ignite.distributed.initialize` or :meth:`~ignite.distributed.spawn`.\n\n    Usage:\n\n        User set up torch native distributed process group\n\n        .. code-block:: python\n\n            import ignite.distributed as idist\n\n            def run(local_rank, *args, **kwargs):\n\n                idist.set_local_rank(local_rank)\n                # ...\n                dist.init_process_group(**dist_info)\n                # ...\n\n    Args:\n        index (int): local rank or current process index\n\n    """"""\n    from ignite.distributed.comp_models.base import ComputationModel\n\n    ComputationModel._ext_local_rank = index\n\n\ndef _set_model(model):\n    global _model, _need_to_sync\n    _model = model\n    _need_to_sync = True\n    if not isinstance(_model, _SerialModel):\n        _need_to_sync = False\n\n\ndef _assert_backend(backend):\n    backends = available_backends()\n    if backend not in backends:\n        raise ValueError(""Backend should be one of \'{}\'"".format(backends))\n\n\ndef initialize(backend: str, **kwargs):\n    """"""Initializes distributed configuration according to provided ``backend``\n\n    Examples:\n\n        Launch single node multi-GPU training with ``torch.distributed.launch`` utility.\n\n        .. code-block:: python\n\n            # >>> python -m torch.distributed.launch --nproc_per_node=4 main.py\n\n            # main.py\n\n            import ignite.distributed as idist\n\n            def train_fn(local_rank, a, b, c):\n                import torch.distributed as dist\n                assert dist.is_available() and dist.is_initialized()\n                assert dist.get_world_size() == 4\n\n                device = idist.device()\n                assert device == torch.device(""cuda:{}"".format(local_rank))\n\n\n            idist.initialize(""nccl"")\n            local_rank = idist.get_local_rank()\n            train_fn(local_rank, a, b, c)\n            idist.finalize()\n\n\n    Args:\n        backend (str, optional): backend: `nccl`, `gloo`, `xla-tpu`.\n        **kwargs: acceptable kwargs according to provided backend:\n\n            - ""nccl"" or ""gloo"" : timeout(=timedelta(minutes=30))\n\n\n    """"""\n    if not (has_xla_support or dist.is_available()):\n        # nothing to do => serial model\n        # maybe warn about this\n        return\n\n    _assert_backend(backend)\n\n    for comp_model_cls in registered_computation_models:\n        if backend not in comp_model_cls.available_backends:\n            continue\n        _set_model(comp_model_cls(backend, **kwargs))\n\n\ndef finalize():\n    """"""Finalizes distributed configuration. For example, in case of native pytorch distributed configuration,\n    it calls ``dist.destroy_process_group()``.\n    """"""\n    _model.finalize()\n    _set_model(_SerialModel())\n\n\ndef show_config():\n    """"""Helper method to display distributed configuration via ``logging``.\n    """"""\n\n    # setup parallel logger\n    logger = setup_logger(__name__)\n\n    logger.info(""distributed configuration: {}"".format(model_name()))\n    logger.info(""backend: {}"".format(backend()))\n    logger.info(""device: {}"".format(device().type))\n    logger.info(""hostname: {}"".format(hostname()))\n    logger.info(""world size: {}"".format(get_world_size()))\n    logger.info(""rank: {}"".format(get_rank()))\n    logger.info(""local rank: {}"".format(get_local_rank()))\n    logger.info(""num tasks per_node: {}"".format(get_ntasks_per_node()))\n    logger.info(""num nodes: {}"".format(get_num_nodes()))\n    logger.info(""node rank: {}"".format(get_node_rank()))\n\n\ndef one_rank_only(rank: int = 0, with_barrier: bool = False):\n    """"""Decorator to filter handlers wrt a rank number\n\n    Args:\n        rank (int): rank number of the handler (default: 0).\n        with_barrier (bool): synchronisation with a barrier (default: False).\n\n    .. code-block:: python\n\n        engine = ...\n\n        @engine.on(...)\n        @one_rank_only() # means @one_rank_only(rank=0)\n        def some_handler(_):\n            ...\n\n        @engine.on(...)\n        @one_rank_only(rank=1)\n        def some_handler(_):\n            ...\n    """"""\n\n    def _one_rank_only(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            ret = None\n            if get_rank() == rank:\n                ret = func(*args, **kwargs)\n            if with_barrier:\n                barrier()\n            return ret\n\n        return wrapper\n\n    return _one_rank_only\n'"
ignite/engine/__init__.py,17,"b'from typing import Any, Callable, Dict, Optional, Sequence, Tuple, Union\n\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.engine.deterministic import DeterministicEngine\nfrom ignite.engine.engine import Engine\nfrom ignite.engine.events import CallableEventWithFilter, EventEnum, Events, State\nfrom ignite.metrics import Metric\nfrom ignite.utils import convert_tensor\n\nif idist.has_xla_support:\n    import torch_xla.core.xla_model as xm\n\n\n__all__ = [\n    ""State"",\n    ""create_supervised_trainer"",\n    ""create_supervised_evaluator"",\n    ""Engine"",\n    ""DeterministicEngine"",\n    ""Events"",\n    ""EventEnum"",\n    ""CallableEventWithFilter"",\n]\n\n\ndef _prepare_batch(\n    batch: Sequence[torch.Tensor], device: Optional[Union[str, torch.device]] = None, non_blocking: bool = False\n):\n    """"""Prepare batch for training: pass to a device with options.\n\n    """"""\n    x, y = batch\n    return (\n        convert_tensor(x, device=device, non_blocking=non_blocking),\n        convert_tensor(y, device=device, non_blocking=non_blocking),\n    )\n\n\ndef create_supervised_trainer(\n    model: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    loss_fn: Union[Callable, torch.nn.Module],\n    device: Optional[Union[str, torch.device]] = None,\n    non_blocking: bool = False,\n    prepare_batch: Callable = _prepare_batch,\n    output_transform: Callable = lambda x, y, y_pred, loss: loss.item(),\n    deterministic: bool = False,\n) -> Engine:\n    """"""\n    Factory function for creating a trainer for supervised models.\n    Args:\n        model (`torch.nn.Module`): the model to train.\n        optimizer (`torch.optim.Optimizer`): the optimizer to use.\n        loss_fn (torch.nn loss function): the loss function to use.\n        device (str, optional): device type specification (default: None).\n            Applies to batches after starting the engine. Model *will not* be moved.\n            Device can be CPU, GPU or TPU.\n        non_blocking (bool, optional): if True and this copy is between CPU and GPU, the copy may occur asynchronously\n            with respect to the host. For other cases, this argument has no effect.\n        prepare_batch (callable, optional): function that receives `batch`, `device`, `non_blocking` and outputs\n            tuple of tensors `(batch_x, batch_y)`.\n        output_transform (callable, optional): function that receives \'x\', \'y\', \'y_pred\', \'loss\' and returns value\n            to be assigned to engine\'s state.output after each iteration. Default is returning `loss.item()`.\n        deterministic (bool, optional): if True, returns deterministic engine of type\n            :class:`~ignite.engine.deterministic.DeterministicEngine`, otherwise :class:`~ignite.engine.Engine`\n            (default: False).\n    Note:\n        `engine.state.output` for this engine is defined by `output_transform` parameter and is the loss\n        of the processed batch by default.\n    .. warning::\n        The internal use of `device` has changed.\n        `device` will now *only* be used to move the input data to the correct device.\n        The `model` should be moved by the user before creating an optimizer.\n        For more information see:\n        * `PyTorch Documentation <https://pytorch.org/docs/stable/optim.html#constructing-it>`_\n        * `PyTorch\'s Explanation <https://github.com/pytorch/pytorch/issues/7844#issuecomment-503713840>`_\n    Returns:\n        Engine: a trainer engine with supervised update function.\n    """"""\n\n    device_type = device.type if isinstance(device, torch.device) else device\n    on_tpu = ""xla"" in device_type if device_type is not None else False\n\n    if on_tpu and not idist.has_xla_support:\n        raise RuntimeError(""In order to run on TPU, please install PyTorch XLA"")\n\n    def _update(engine: Engine, batch: Sequence[torch.Tensor]) -> Union[Any, Tuple[torch.Tensor]]:\n        model.train()\n        optimizer.zero_grad()\n        x, y = prepare_batch(batch, device=device, non_blocking=non_blocking)\n        y_pred = model(x)\n        loss = loss_fn(y_pred, y)\n        loss.backward()\n\n        if on_tpu:\n            xm.optimizer_step(optimizer, barrier=True)\n        else:\n            optimizer.step()\n\n        return output_transform(x, y, y_pred, loss)\n\n    trainer = Engine(_update) if not deterministic else DeterministicEngine(_update)\n\n    return trainer\n\n\ndef create_supervised_evaluator(\n    model: torch.nn.Module,\n    metrics: Optional[Dict[str, Metric]] = None,\n    device: Optional[Union[str, torch.device]] = None,\n    non_blocking: bool = False,\n    prepare_batch: Callable = _prepare_batch,\n    output_transform: Callable = lambda x, y, y_pred: (y_pred, y),\n) -> Engine:\n    """"""\n    Factory function for creating an evaluator for supervised models.\n\n    Args:\n        model (`torch.nn.Module`): the model to train.\n        metrics (dict of str - :class:`~ignite.metrics.Metric`): a map of metric names to Metrics.\n        device (str, optional): device type specification (default: None).\n            Applies to batches after starting the engine. Model *will not* be moved.\n        non_blocking (bool, optional): if True and this copy is between CPU and GPU, the copy may occur asynchronously\n            with respect to the host. For other cases, this argument has no effect.\n        prepare_batch (callable, optional): function that receives `batch`, `device`, `non_blocking` and outputs\n            tuple of tensors `(batch_x, batch_y)`.\n        output_transform (callable, optional): function that receives \'x\', \'y\', \'y_pred\' and returns value\n            to be assigned to engine\'s state.output after each iteration. Default is returning `(y_pred, y,)` which fits\n            output expected by metrics. If you change it you should use `output_transform` in metrics.\n\n    Note:\n        `engine.state.output` for this engine is defind by `output_transform` parameter and is\n        a tuple of `(batch_pred, batch_y)` by default.\n\n    .. warning::\n\n        The internal use of `device` has changed.\n        `device` will now *only* be used to move the input data to the correct device.\n        The `model` should be moved by the user before creating an optimizer.\n\n        For more information see:\n\n        * `PyTorch Documentation <https://pytorch.org/docs/stable/optim.html#constructing-it>`_\n        * `PyTorch\'s Explanation <https://github.com/pytorch/pytorch/issues/7844#issuecomment-503713840>`_\n\n    Returns:\n        Engine: an evaluator engine with supervised inference function.\n    """"""\n    metrics = metrics or {}\n\n    def _inference(engine: Engine, batch: Sequence[torch.Tensor]) -> Union[Any, Tuple[torch.Tensor]]:\n        model.eval()\n        with torch.no_grad():\n            x, y = prepare_batch(batch, device=device, non_blocking=non_blocking)\n            y_pred = model(x)\n            return output_transform(x, y, y_pred)\n\n    evaluator = Engine(_inference)\n\n    for name, metric in metrics.items():\n        metric.attach(evaluator, name)\n\n    return evaluator\n'"
ignite/engine/deterministic.py,17,"b'import random\nimport warnings\nfrom collections import OrderedDict\nfrom functools import wraps\nfrom typing import Callable, Generator, Iterator, Optional\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import BatchSampler\n\nfrom ignite.engine.engine import Engine\nfrom ignite.engine.events import Events\nfrom ignite.utils import manual_seed\n\n__all__ = [""update_dataloader"", ""keep_random_state"", ""ReproducibleBatchSampler"", ""DeterministicEngine""]\n\n\ndef update_dataloader(dataloader: DataLoader, new_batch_sampler: BatchSampler) -> DataLoader:\n    """"""Helper function to replace current batch sampler of the dataloader by a new batch sampler. Function returns new\n    dataloader with new batch sampler.\n\n    Args:\n        dataloader (torch.utils.data.DataLoader): input dataloader\n        new_batch_sampler (torch.utils.data.sampler.BatchSampler): new batch sampler to use\n\n    Returns:\n        DataLoader\n    """"""\n    params_keys = [k for k in dataloader.__dict__.keys() if not k.startswith(""_"")]\n    for k in [""batch_size"", ""sampler"", ""drop_last"", ""batch_sampler"", ""dataset_kind""]:\n        if k in params_keys:\n            params_keys.remove(k)\n    params = {k: getattr(dataloader, k) for k in params_keys}\n    params[""batch_sampler""] = new_batch_sampler\n    return type(dataloader)(**params)\n\n\nclass ReproducibleBatchSampler(BatchSampler):\n    """"""Reproducible batch sampler. This class internally iterates and stores indices of the input batch sampler.\n    This helps to start providing data batches from an iteration in a deterministic way.\n\n    Usage:\n\n        Setup dataloader with `ReproducibleBatchSampler` and start providing data batches from an iteration:\n\n        .. code-block:: python\n\n            from ignite.engine.deterministic import update_dataloader\n\n            dataloader = update_dataloader(dataloader, ReproducibleBatchSampler(dataloader.batch_sampler))\n            # rewind dataloader to a specific iteration:\n            dataloader.batch_sampler.start_iteration = start_iteration\n\n    Args:\n        batch_sampler (torch.utils.data.sampler.BatchSampler): batch sampler same as used with\n            `torch.utils.data.DataLoader`\n        start_iteration (int, optional): optional start iteration\n    """"""\n\n    def __init__(self, batch_sampler: BatchSampler, start_iteration: Optional[int] = None):\n        if not isinstance(batch_sampler, BatchSampler):\n            raise TypeError(""Argument batch_sampler should be torch.utils.data.sampler.BatchSampler"")\n\n        self.batch_indices = None\n        self.batch_sampler = batch_sampler\n        self.start_iteration = start_iteration\n        self.sampler = self.batch_sampler.sampler\n\n    def setup_batch_indices(self) -> None:\n        self.batch_indices = []\n        for batch in self.batch_sampler:\n            self.batch_indices.append(batch)\n\n        if self.start_iteration is not None:\n            self.batch_indices = self.batch_indices[self.start_iteration :]\n            self.start_iteration = None\n\n    def __iter__(self) -> Generator:\n        self.setup_batch_indices()\n        for batch in self.batch_indices:\n            yield batch\n\n    def __len__(self) -> int:\n        return len(self.batch_sampler)\n\n\ndef _get_rng_states():\n    output = [random.getstate(), torch.get_rng_state()]\n    try:\n        import numpy as np\n\n        output.append(np.random.get_state())\n    except ImportError:\n        pass\n\n    return output\n\n\ndef _set_rng_states(rng_states):\n    random.setstate(rng_states[0])\n    torch.set_rng_state(rng_states[1])\n    try:\n        import numpy as np\n\n        np.random.set_state(rng_states[2])\n    except ImportError:\n        pass\n\n\ndef _repr_rng_state(rng_states):\n    from hashlib import md5\n\n    out = "" "".join([md5(str(list(s)).encode(""utf-8"")).hexdigest() for s in rng_states])\n    return out\n\n\ndef keep_random_state(func: Callable):\n    """"""Helper decorator to keep random state of torch, numpy and random intact\n    while executing a function. For more details on usage, please see\n    `""Concepts/Dataflow synchronization"" <https://pytorch.org/ignite/concepts.html#dataflow-synchronization>`_.\n\n    Args:\n        func (callable): function to decorate\n    """"""\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        rng_states = _get_rng_states()\n        func(*args, **kwargs)\n        _set_rng_states(rng_states)\n\n    return wrapper\n\n\nclass DeterministicEngine(Engine):\n    """"""Deterministic engine derived from :class:`~ignite.engine.Engine`.\n\n    ""Deterministic"" run is done by adding additional handlers to synchronize the dataflow and overriding some methods of\n    :class:`~ignite.engine.Engine`:\n\n    .. code-block:: python\n\n        for e in range(num_epochs):\n            set_seed(seed_offset + e)\n            if resume:\n                setup_saved_rng_states()\n            do_single_epoch_iterations(dataloader)\n\n    If input data provider is `DataLoader`, its batch sampler is replaced by\n    :class:`~ignite.engine.deterministic.ReproducibleBatchSampler`.\n\n    .. code-block:: python\n\n        for e in range(num_epochs):\n            set_seed(seed_offset + e)\n            setup_sampling(dataloader)\n            if resume:\n                setup_saved_rng_states()\n            do_single_epoch_iterations(dataloader)\n\n    Internally, `torch.backends.cudnn.deterministic = True` and `torch.backends.cudnn.benchmark = False` are also\n    applied.\n\n    For more details about dataflow synchronization, please see\n    `""Concepts/Dataflow synchronization"" <https://pytorch.org/ignite/concepts.html#dataflow-synchronization>`_.\n\n    .. Note ::\n\n        This class can produce exactly the same dataflow when resuming the run from an epoch (or more precisely from\n        dataflow restart) and using torch `DataLoader` with `num_workers > 1` as data provider.\n\n    """"""\n\n    def __init__(self, process_function: Callable):\n        super(DeterministicEngine, self).__init__(process_function)\n        self.state_dict_user_keys.append(""rng_states"")\n        self.add_event_handler(Events.STARTED, self._init_run)\n        self.add_event_handler(Events.DATALOADER_STOP_ITERATION | Events.TERMINATE_SINGLE_EPOCH, self._setup_seed)\n\n    def state_dict(self) -> OrderedDict:\n        state_dict = super(DeterministicEngine, self).state_dict()\n        state_dict[""rng_states""] = _get_rng_states()\n        return state_dict\n\n    def _init_run(self) -> None:\n        seed = torch.randint(0, int(1e9), (1,)).item()\n        self.state.seed = seed\n        if not hasattr(self.state, ""rng_states""):\n            self.state.rng_states = None\n\n        if torch.cuda.is_available():\n            torch.backends.cudnn.deterministic = True\n            torch.backends.cudnn.benchmark = False\n\n    def _setup_engine(self) -> None:\n        self._dataloader_len = self._get_data_length(self.state.dataloader)\n\n        # if input data is torch dataloader we replace batch sampler by a batch sampler\n        # such that its random sampling indices are reproducible by prefetching them before data iteration\n        if isinstance(self.state.dataloader, DataLoader):\n            # attribute _dataset_kind is introduced since 1.3.0 => before 1.3.0 all datasets are map-like\n            can_patch_dataloader = True\n            if hasattr(self.state.dataloader, ""_dataset_kind""):\n                from torch.utils.data.dataloader import _DatasetKind\n\n                _dataloader_kind = self.state.dataloader._dataset_kind\n                can_patch_dataloader = _dataloader_kind == _DatasetKind.Map\n            if can_patch_dataloader:\n                if (self._dataloader_len is not None) and hasattr(self.state.dataloader.sampler, ""epoch""):\n                    if self._dataloader_len != self.state.epoch_length:\n                        warnings.warn(\n                            ""When defined engine\'s epoch length is different of input dataloader length, ""\n                            ""distributed sampler indices can not be setup in a reproducible manner""\n                        )\n\n                batch_sampler = self.state.dataloader.batch_sampler\n                if not (batch_sampler is None or isinstance(batch_sampler, ReproducibleBatchSampler)):\n                    self.state.dataloader = update_dataloader(\n                        self.state.dataloader, ReproducibleBatchSampler(batch_sampler)\n                    )\n\n        iteration = self.state.iteration\n        self._dataloader_iter = self._from_iteration(iteration)\n\n        # Below we define initial counter value for _run_once_on_dataset to measure a single epoch\n        if self.state.epoch_length is not None:\n            iteration %= self.state.epoch_length\n        self._init_iter.append(iteration)\n\n        # restore rng state if in the middle\n        in_the_middle = self.state.iteration % self._dataloader_len > 0 if self._dataloader_len is not None else False\n        if (getattr(self.state, ""rng_states"", None) is not None) and in_the_middle:\n            _set_rng_states(self.state.rng_states)\n            self.state.rng_states = None\n\n    def _from_iteration(self, iteration: int) -> Iterator:\n        data = self.state.dataloader\n        if isinstance(data, DataLoader):\n            try:\n                # following is unsafe for IterableDatasets\n                iteration %= len(data.batch_sampler)\n                # Synchronize dataflow according to state.iteration\n                self._setup_seed()\n                if iteration > 0:\n                    # batch sampler is ReproducibleBatchSampler\n                    data.batch_sampler.start_iteration = iteration\n                return iter(data)\n            except TypeError as e:\n                # Probably we can do nothing with DataLoader built upon IterableDatasets\n                pass\n\n        self.logger.info(""Resuming from iteration for provided data will fetch data until required iteration ..."")\n        if hasattr(data, ""__len__""):\n            iteration %= len(data)\n        # Synchronize dataflow from the begining\n        self._setup_seed(iteration=0)\n        data_iter = iter(data)\n        counter = 0\n        while counter < iteration:\n            try:\n                next(data_iter)\n                counter += 1\n            except StopIteration:\n                data_iter = iter(data)\n\n        return data_iter\n\n    def _setup_seed(self, _=None, iter_counter=None, iteration=None):\n        if iter_counter is None:\n            le = self._dataloader_len if self._dataloader_len is not None else 1\n        else:\n            le = iter_counter\n        if iteration is None:\n            iteration = self.state.iteration\n        manual_seed(self.state.seed + iteration // le)\n'"
ignite/engine/engine.py,8,"b'import functools\nimport logging\nimport time\nimport warnings\nimport weakref\nfrom collections import OrderedDict, defaultdict\nfrom collections.abc import Mapping\nfrom typing import Any, Callable, Iterable, List, Optional\n\nfrom ignite._utils import _to_hours_mins_secs\nfrom ignite.base import Serializable\nfrom ignite.engine.events import CallableEventWithFilter, Events, EventsList, RemovableEventHandle, State\nfrom ignite.engine.utils import _check_signature\n\n__all__ = [""Engine""]\n\n\nclass Engine(Serializable):\n    """"""Runs a given `process_function` over each batch of a dataset, emitting events as it goes.\n\n    Args:\n        process_function (callable): A function receiving a handle to the engine and the current batch\n            in each iteration, and returns data to be stored in the engine\'s state.\n\n    Attributes:\n        state (State): object that is used to pass internal and user-defined state between event handlers.\n            It is created with the engine and its attributes (e.g. `state.iteration`, `state.epoch` etc) are reset\n            on every :meth:`~ignite.engine.Engine.run`.\n        last_event_name (Events): last event name triggered by the engine.\n\n    Examples:\n\n        Create a basic trainer\n\n        .. code-block:: python\n\n            def update_model(engine, batch):\n                inputs, targets = batch\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                loss.backward()\n                optimizer.step()\n                return loss.item()\n\n            trainer = Engine(update_model)\n\n            @trainer.on(Events.ITERATION_COMPLETED(every=100))\n            def log_training(engine):\n                batch_loss = engine.state.output\n                lr = optimizer.param_groups[0][\'lr\']\n                e = engine.state.epoch\n                n = engine.state.max_epochs\n                i = engine.state.iteration\n                print(""Epoch {}/{} : {} - batch loss: {}, lr: {}"".format(e, n, i, batch_loss, lr))\n\n            trainer.run(data_loader, max_epochs=5)\n\n            > Epoch 1/5 : 100 - batch loss: 0.10874069479016124, lr: 0.01\n            > ...\n            > Epoch 2/5 : 1700 - batch loss: 0.4217900575859437, lr: 0.01\n\n        Create a basic evaluator to compute metrics\n\n        .. code-block:: python\n\n            from ignite.metrics import Accuracy\n\n            def predict_on_batch(engine, batch)\n                model.eval()\n                with torch.no_grad():\n                    x, y = prepare_batch(batch, device=device, non_blocking=non_blocking)\n                    y_pred = model(x)\n\n                return y_pred, y\n\n            evaluator = Engine(predict_on_batch)\n            Accuracy().attach(evaluator, ""val_acc"")\n            evaluator.run(val_dataloader)\n\n        Compute image mean/std on training dataset\n\n        .. code-block:: python\n\n            from ignite.metrics import Average\n\n            def compute_mean_std(engine, batch):\n                b, c, *_ = batch[\'image\'].shape\n                data = batch[\'image\'].reshape(b, c, -1).to(dtype=torch.float64)\n                mean = torch.mean(data, dim=-1).sum(dim=0)\n                mean2 = torch.mean(data ** 2, dim=-1).sum(dim=0)\n                return {""mean"": mean, ""mean^2"": mean2}\n\n            compute_engine = Engine(compute_mean_std)\n            img_mean = Average(output_transform=lambda output: output[\'mean\'])\n            img_mean.attach(compute_engine, \'mean\')\n            img_mean2 = Average(output_transform=lambda output: output[\'mean^2\'])\n            img_mean2.attach(compute_engine, \'mean2\')\n            state = compute_engine.run(train_loader)\n            state.metrics[\'std\'] = torch.sqrt(state.metrics[\'mean2\'] - state.metrics[\'mean\'] ** 2)\n            mean = state.metrics[\'mean\'].tolist()\n            std = state.metrics[\'std\'].tolist()\n\n        Resume engine\'s run from a state. User can load a `state_dict` and run engine starting from loaded state :\n\n        .. code-block:: python\n\n            # Restore from an epoch\n            state_dict = {""epoch"": 3, ""max_epochs"": 100, ""epoch_length"": len(data_loader)}\n            # or an iteration\n            # state_dict = {""iteration"": 500, ""max_epochs"": 100, ""epoch_length"": len(data_loader)}\n\n            trainer = Engine(...)\n            trainer.load_state_dict(state_dict)\n            trainer.run(data)\n\n    """"""\n\n    _state_dict_all_req_keys = (""epoch_length"", ""max_epochs"")\n    _state_dict_one_of_opt_keys = (""iteration"", ""epoch"")\n\n    def __init__(self, process_function: Callable):\n        self._event_handlers = defaultdict(list)\n        self.logger = logging.getLogger(__name__ + ""."" + self.__class__.__name__)\n        self._process_function = process_function\n        self.last_event_name = None\n        self.should_terminate = False\n        self.should_terminate_single_epoch = False\n        self.state = State()\n        self._state_dict_user_keys = []\n        self._allowed_events = []\n\n        self._dataloader_iter = None\n        self._init_iter = []\n\n        self.register_events(*Events)\n\n        if self._process_function is None:\n            raise ValueError(""Engine must be given a processing function in order to run."")\n\n        _check_signature(process_function, ""process_function"", self, None)\n\n    def register_events(self, *event_names: Any, event_to_attr: Optional[dict] = None) -> None:\n        """"""Add events that can be fired.\n\n        Registering an event will let the user fire these events at any point.\n        This opens the door to make the :meth:`~ignite.engine.Engine.run` loop even more\n        configurable.\n\n        By default, the events from :class:`~ignite.engine.Events` are registered.\n\n        Args:\n            *event_names: An object (ideally a string or int) to define the\n                name of the event being supported.\n            event_to_attr (dict, optional): A dictionary to map an event to a state attribute.\n\n        Example usage:\n\n        .. code-block:: python\n\n            from ignite.engine import Engine, EventEnum\n\n            class CustomEvents(EventEnum):\n                FOO_EVENT = ""foo_event""\n                BAR_EVENT = ""bar_event""\n\n            engine = Engine(process_function)\n            engine.register_events(*CustomEvents)\n\n\n        Example with State Attribute:\n\n        .. code-block:: python\n\n            from enum import Enum\n            from ignite.engine import Engine, EventEnum\n\n            class TBPTT_Events(EventEnum):\n                TIME_ITERATION_STARTED = ""time_iteration_started""\n                TIME_ITERATION_COMPLETED = ""time_iteration_completed""\n\n            TBPTT_event_to_attr = {\n                TBPTT_Events.TIME_ITERATION_STARTED: \'time_iteration\',\n                TBPTT_Events.TIME_ITERATION_COMPLETED: \'time_iteration\'\n            }\n\n            engine = Engine(process_function)\n            engine.register_events(*TBPTT_Events, event_to_attr=TBPTT_event_to_attr)\n            engine.run(data)\n            # engine.state contains an attribute time_iteration, which can be accessed using engine.state.time_iteration\n        """"""\n        if not (event_to_attr is None or isinstance(event_to_attr, dict)):\n            raise ValueError(""Expected event_to_attr to be dictionary. Got {}."".format(type(event_to_attr)))\n\n        for e in event_names:\n            self._allowed_events.append(e)\n            if event_to_attr and e in event_to_attr:\n                State.event_to_attr[e] = event_to_attr[e]\n        # we need to update state attributes associated with new custom events\n        self.state._update_attrs()\n\n    def _handler_wrapper(self, handler: Callable, event_name: Any, event_filter: Callable) -> Callable:\n        # signature of the following wrapper will be inspected during registering to check if engine is necessary\n        # we have to build a wrapper with relevant signature : solution is functools.wraps\n        @functools.wraps(handler)\n        def wrapper(*args, **kwargs) -> Any:\n            event = self.state.get_event_attrib_value(event_name)\n            if event_filter(self, event):\n                return handler(*args, **kwargs)\n\n        # setup input handler as parent to make has_event_handler work\n        wrapper._parent = weakref.ref(handler)\n        return wrapper\n\n    def add_event_handler(self, event_name: Any, handler: Callable, *args, **kwargs):\n        """"""Add an event handler to be executed when the specified event is fired.\n\n        Args:\n            event_name: An event or a list of events to attach the handler. Valid events are\n                from :class:`~ignite.engine.Events` or any `event_name` added by\n                :meth:`~ignite.engine.Engine.register_events`.\n            handler (callable): the callable event handler that should be invoked. No restrictions on its signature.\n                The first argument can be optionally `engine`, the :class:`~ignite.engine.Engine` object, handler is\n                bound to.\n            *args: optional args to be passed to `handler`.\n            **kwargs: optional keyword args to be passed to `handler`.\n\n        Note:\n            Note that other arguments can be passed to the handler in addition to the `*args` and  `**kwargs`\n            passed here, for example during :attr:`~ignite.engine.Events.EXCEPTION_RAISED`.\n\n        Returns:\n            :class:`~ignite.engine.RemovableEventHandle`, which can be used to remove the handler.\n\n        Example usage:\n\n        .. code-block:: python\n\n            engine = Engine(process_function)\n\n            def print_epoch(engine):\n                print(""Epoch: {}"".format(engine.state.epoch))\n\n            engine.add_event_handler(Events.EPOCH_COMPLETED, print_epoch)\n\n            events_list = Events.EPOCH_COMPLETED | Events.COMPLETED\n\n            def execute_something():\n                # do some thing not related to engine\n                pass\n\n            engine.add_event_handler(events_list, execute_something)\n\n        Note:\n            Since v0.3.0, Events become more flexible and allow to pass an event filter to the Engine.\n            See :class:`~ignite.engine.Events` for more details.\n\n        """"""\n        if isinstance(event_name, EventsList):\n            for e in event_name:\n                self.add_event_handler(e, handler, *args, **kwargs)\n            return RemovableEventHandle(event_name, handler, self)\n        if (\n            isinstance(event_name, CallableEventWithFilter)\n            and event_name.filter != CallableEventWithFilter.default_event_filter\n        ):\n            event_filter = event_name.filter\n            handler = self._handler_wrapper(handler, event_name, event_filter)\n\n        if event_name not in self._allowed_events:\n            self.logger.error(""attempt to add event handler to an invalid event %s."", event_name)\n            raise ValueError(""Event {} is not a valid event for this Engine."".format(event_name))\n\n        event_args = (Exception(),) if event_name == Events.EXCEPTION_RAISED else ()\n        try:\n            _check_signature(handler, ""handler"", self, *(event_args + args), **kwargs)\n            self._event_handlers[event_name].append((handler, (self,) + args, kwargs))\n        except ValueError:\n            _check_signature(handler, ""handler"", *(event_args + args), **kwargs)\n            self._event_handlers[event_name].append((handler, args, kwargs))\n        self.logger.debug(""added handler for event %s."", event_name)\n\n        return RemovableEventHandle(event_name, handler, self)\n\n    @staticmethod\n    def _assert_non_filtered_event(event_name: Any):\n        if (\n            isinstance(event_name, CallableEventWithFilter)\n            and event_name.filter != CallableEventWithFilter.default_event_filter\n        ):\n            raise TypeError(\n                ""Argument event_name should not be a filtered event, "" ""please use event without any event filtering""\n            )\n\n    def has_event_handler(self, handler: Callable, event_name: Optional[Any] = None):\n        """"""Check if the specified event has the specified handler.\n\n        Args:\n            handler (callable): the callable event handler.\n            event_name: The event the handler attached to. Set this\n                to ``None`` to search all events.\n        """"""\n        if event_name is not None:\n            if event_name not in self._event_handlers:\n                return False\n            events = [event_name]\n        else:\n            events = self._event_handlers\n        for e in events:\n            for h, _, _ in self._event_handlers[e]:\n                if self._compare_handlers(handler, h):\n                    return True\n        return False\n\n    @staticmethod\n    def _compare_handlers(user_handler: Callable, registered_handler: Callable) -> bool:\n        if hasattr(registered_handler, ""_parent""):\n            registered_handler = registered_handler._parent()\n        return registered_handler == user_handler\n\n    def remove_event_handler(self, handler: Callable, event_name: Any):\n        """"""Remove event handler `handler` from registered handlers of the engine\n\n        Args:\n            handler (callable): the callable event handler that should be removed\n            event_name: The event the handler attached to.\n\n        """"""\n        if event_name not in self._event_handlers:\n            raise ValueError(""Input event name \'{}\' does not exist"".format(event_name))\n\n        new_event_handlers = [\n            (h, args, kwargs)\n            for h, args, kwargs in self._event_handlers[event_name]\n            if not self._compare_handlers(handler, h)\n        ]\n        if len(new_event_handlers) == len(self._event_handlers[event_name]):\n            raise ValueError(""Input handler \'{}\' is not found among registered event handlers"".format(handler))\n        self._event_handlers[event_name] = new_event_handlers\n\n    def on(self, event_name, *args, **kwargs):\n        """"""Decorator shortcut for add_event_handler.\n\n        Args:\n            event_name: An event to attach the handler to. Valid events are from :class:`~ignite.engine.Events` or\n                any `event_name` added by :meth:`~ignite.engine.Engine.register_events`.\n            *args: optional args to be passed to `handler`.\n            **kwargs: optional keyword args to be passed to `handler`.\n\n        Example usage:\n\n        .. code-block:: python\n\n            engine = Engine(process_function)\n\n            @engine.on(Events.EPOCH_COMPLETED)\n            def print_epoch():\n                print(""Epoch: {}"".format(engine.state.epoch))\n\n            @engine.on(Events.EPOCH_COMPLETED | Events.COMPLETED)\n            def execute_something():\n                # do some thing not related to engine\n                pass\n        """"""\n\n        def decorator(f: Callable) -> Callable:\n            self.add_event_handler(event_name, f, *args, **kwargs)\n            return f\n\n        return decorator\n\n    def _fire_event(self, event_name: Any, *event_args, **event_kwargs) -> None:\n        """"""Execute all the handlers associated with given event.\n\n        This method executes all handlers associated with the event\n        `event_name`. Optional positional and keyword arguments can be used to\n        pass arguments to **all** handlers added with this event. These\n        arguments updates arguments passed using :meth:`~ignite.engine.Engine.add_event_handler`.\n\n        Args:\n            event_name: event for which the handlers should be executed. Valid\n                events are from :class:`~ignite.engine.Events` or any `event_name` added by\n                :meth:`~ignite.engine.Engine.register_events`.\n            *event_args: optional args to be passed to all handlers.\n            **event_kwargs: optional keyword args to be passed to all handlers.\n\n        """"""\n        if event_name in self._allowed_events:\n            self.logger.debug(""firing handlers for event %s "", event_name)\n            self.last_event_name = event_name\n            for func, args, kwargs in self._event_handlers[event_name]:\n                kwargs.update(event_kwargs)\n                first, others = ((args[0],), args[1:]) if (args and args[0] == self) else ((), args)\n                func(*first, *(event_args + others), **kwargs)\n\n    def fire_event(self, event_name: Any) -> None:\n        """"""Execute all the handlers associated with given event.\n\n        This method executes all handlers associated with the event\n        `event_name`. This is the method used in :meth:`~ignite.engine.Engine.run` to call the\n        core events found in :class:`~ignite.engine.Events`.\n\n        Custom events can be fired if they have been registered before with\n        :meth:`~ignite.engine.Engine.register_events`. The engine `state` attribute should be used\n        to exchange ""dynamic"" data among `process_function` and handlers.\n\n        This method is called automatically for core events. If no custom\n        events are used in the engine, there is no need for the user to call\n        the method.\n\n        Args:\n            event_name: event for which the handlers should be executed. Valid\n                events are from :class:`~ignite.engine.Events` or any `event_name` added by\n                :meth:`~ignite.engine.Engine.register_events`.\n\n        """"""\n        return self._fire_event(event_name)\n\n    def terminate(self) -> None:\n        """"""Sends terminate signal to the engine, so that it terminates completely the run after the current iteration.\n        """"""\n        self.logger.info(""Terminate signaled. Engine will stop after current iteration is finished."")\n        self.should_terminate = True\n\n    def terminate_epoch(self) -> None:\n        """"""Sends terminate signal to the engine, so that it terminates the current epoch after the current iteration.\n        """"""\n        self.logger.info(\n            ""Terminate current epoch is signaled. ""\n            ""Current epoch iteration will stop after current iteration is finished.""\n        )\n        self.should_terminate_single_epoch = True\n\n    def _handle_exception(self, e: Exception) -> None:\n        if Events.EXCEPTION_RAISED in self._event_handlers:\n            self._fire_event(Events.EXCEPTION_RAISED, e)\n        else:\n            raise e\n\n    @property\n    def state_dict_user_keys(self) -> List:\n        return self._state_dict_user_keys\n\n    def state_dict(self) -> OrderedDict:\n        """"""Returns a dictionary containing engine\'s state: ""seed"", ""epoch_length"", ""max_epochs"" and ""iteration"" and\n        other state values defined by `engine.state_dict_user_keys`\n\n        .. code-block:: python\n\n            engine = Engine(...)\n            engine.state_dict_user_keys.append(""alpha"")\n            engine.state_dict_user_keys.append(""beta"")\n            ...\n\n            @engine.on(Events.STARTED)\n            def init_user_value(_):\n                 engine.state.alpha = 0.1\n                 engine.state.beta = 1.0\n\n            @engine.on(Events.COMPLETED)\n            def save_engine(_):\n                state_dict = engine.state_dict()\n                assert ""alpha"" in state_dict and ""beta"" in state_dict\n                torch.save(state_dict, ""/tmp/engine.pt"")\n\n        Returns:\n            OrderedDict:\n                a dictionary containing engine\'s state\n\n        """"""\n        keys = self._state_dict_all_req_keys + (self._state_dict_one_of_opt_keys[0],)\n        keys += tuple(self._state_dict_user_keys)\n        return OrderedDict([(k, getattr(self.state, k)) for k in keys])\n\n    def load_state_dict(self, state_dict: Mapping) -> None:\n        """"""Setups engine from `state_dict`.\n\n        State dictionary should contain keys: `iteration` or `epoch` and `max_epochs`, `epoch_length` and\n        `seed`. If `engine.state_dict_user_keys` contains keys, they should be also present in the state dictionary.\n        Iteration and epoch values are 0-based: the first iteration or epoch is zero.\n\n        This method does not remove any custom attributs added by user.\n\n        Args:\n            state_dict (Mapping): a dict with parameters\n\n        .. code-block:: python\n\n            # Restore from the 4rd epoch\n            state_dict = {""epoch"": 3, ""max_epochs"": 100, ""epoch_length"": len(data_loader)}\n            # or 500th iteration\n            # state_dict = {""iteration"": 499, ""max_epochs"": 100, ""epoch_length"": len(data_loader)}\n\n            trainer = Engine(...)\n            trainer.load_state_dict(state_dict)\n            trainer.run(data)\n\n        """"""\n        super(Engine, self).load_state_dict(state_dict)\n\n        for k in self._state_dict_user_keys:\n            if k not in state_dict:\n                raise ValueError(\n                    ""Required user state attribute \'{}\' is absent in provided state_dict \'{}\'"".format(\n                        k, state_dict.keys()\n                    )\n                )\n        self.state.max_epochs = state_dict[""max_epochs""]\n        self.state.epoch_length = state_dict[""epoch_length""]\n        for k in self._state_dict_user_keys:\n            setattr(self.state, k, state_dict[k])\n\n        if ""iteration"" in state_dict:\n            self.state.iteration = state_dict[""iteration""]\n            self.state.epoch = 0\n            if self.state.epoch_length is not None:\n                self.state.epoch = self.state.iteration // self.state.epoch_length\n        elif ""epoch"" in state_dict:\n            self.state.epoch = state_dict[""epoch""]\n            if self.state.epoch_length is None:\n                raise ValueError(\n                    ""If epoch is provided in the state dict, epoch_length should not be None. ""\n                    ""Input state_dict: {}"".format(state_dict)\n                )\n            self.state.iteration = self.state.epoch_length * self.state.epoch\n\n    @staticmethod\n    def _is_done(state: State) -> bool:\n        return state.iteration == state.epoch_length * state.max_epochs\n\n    def set_data(self, data):\n        """"""Method to set data. After calling the method the next batch passed to `processing_function` is\n        from newly provided data. Please, note that epoch length is not modified.\n\n        Args:\n            data (Iterable): Collection of batches allowing repeated iteration (e.g., list or `DataLoader`).\n\n        Example usage:\n            User can switch data provider during the training:\n\n            .. code-block:: python\n\n                data1 = ...\n                data2 = ...\n\n                switch_iteration = 5000\n\n                def train_step(e, batch):\n                    # when iteration <= switch_iteration\n                    # batch is from data1\n                    # when iteration > switch_iteration\n                    # batch is from data2\n                    ...\n\n                trainer = Engine(train_step)\n\n                @trainer.on(Events.ITERATION_COMPLETED(once=switch_iteration))\n                def switch_dataloader():\n                    trainer.set_data(data2)\n\n                trainer.run(data1, max_epochs=100)\n\n        """"""\n        self.state.dataloader = data\n        self._dataloader_iter = iter(self.state.dataloader)\n\n    def run(\n        self,\n        data: Iterable,\n        max_epochs: Optional[int] = None,\n        epoch_length: Optional[int] = None,\n        seed: Optional[int] = None,\n    ) -> State:\n        """"""Runs the `process_function` over the passed data.\n\n        Engine has a state and the following logic is applied in this function:\n\n        - At the first call, new state is defined by `max_epochs`, `epoch_length`, `seed` if provided. A timer for\n            total and per-epoch time is initialized when Events.STARTED is handled.\n        - If state is already defined such that there are iterations to run until `max_epochs` and no input arguments\n            provided, state is kept and used in the function.\n        - If state is defined and engine is ""done"" (no iterations to run until `max_epochs`), a new state is defined.\n        - If state is defined, engine is NOT ""done"", then input arguments if provided override defined state.\n\n        Args:\n            data (Iterable): Collection of batches allowing repeated iteration (e.g., list or `DataLoader`).\n            max_epochs (int, optional): Max epochs to run for (default: None).\n                If a new state should be created (first run or run again from ended engine), it\'s default value is 1.\n                If run is resuming from a state, provided `max_epochs` will be taken into account and should be larger\n                than `engine.state.max_epochs`.\n            epoch_length (int, optional): Number of iterations to count as one epoch. By default, it can be set as\n                `len(data)`. If `data` is an iterator and `epoch_length` is not set, then it will be automatically\n                determined as the iteration on which data iterator raises `StopIteration`.\n                This argument should not change if run is resuming from a state.\n            seed (int, optional): Deprecated argument. Please, use `torch.manual_seed` or\n                :meth:`~ignite.utils.manual_seed`.\n\n        Returns:\n            State: output state.\n\n        Note:\n            User can dynamically preprocess input batch at :attr:`~ignite.engine.Events.ITERATION_STARTED` and store\n            output batch in `engine.state.batch`. Latter is passed as usually to `process_function` as argument:\n\n            .. code-block:: python\n\n                trainer = ...\n\n                @trainer.on(Events.ITERATION_STARTED)\n                def switch_batch(engine):\n                    engine.state.batch = preprocess_batch(engine.state.batch)\n\n        """"""\n        if seed is not None:\n            warnings.warn(\n                ""Argument seed is deprecated. It will be removed in 0.5.0. ""\n                ""Please, use torch.manual_seed or ignite.utils.manual_seed""\n            )\n\n        if self.state.max_epochs is not None:\n            # Check and apply overridden parameters\n            if max_epochs is not None:\n                if max_epochs < self.state.epoch:\n                    raise ValueError(\n                        ""Argument max_epochs should be larger than the start epoch ""\n                        ""defined in the state: {} vs {}"".format(max_epochs, self.state.epoch)\n                    )\n                self.state.max_epochs = max_epochs\n            if epoch_length is not None:\n                if epoch_length != self.state.epoch_length:\n                    raise ValueError(\n                        ""Argument epoch_length should be same as in the state, given {} vs {}"".format(\n                            epoch_length, self.state.epoch_length\n                        )\n                    )\n\n        if self.state.max_epochs is None or self._is_done(self.state):\n            # Create new state\n            if max_epochs is None:\n                max_epochs = 1\n            if epoch_length is None:\n                epoch_length = self._get_data_length(data)\n                if epoch_length is not None and epoch_length < 1:\n                    raise ValueError(""Input data has zero size. Please provide non-empty data"")\n\n            self.state.iteration = 0\n            self.state.epoch = 0\n            self.state.max_epochs = max_epochs\n            self.state.epoch_length = epoch_length\n            self.logger.info(""Engine run starting with max_epochs={}."".format(max_epochs))\n        else:\n            self.logger.info(\n                ""Engine run resuming from iteration {}, epoch {} until {} epochs"".format(\n                    self.state.iteration, self.state.epoch, self.state.max_epochs\n                )\n            )\n\n        self.state.dataloader = data\n        return self._internal_run()\n\n    @staticmethod\n    def _init_timers(state: State):\n        state.times[Events.EPOCH_COMPLETED.name] = 0.0\n        state.times[Events.COMPLETED.name] = 0.0\n\n    def _get_data_length(self, data):\n        data_length = None\n        try:\n            if hasattr(data, ""__len__""):\n                data_length = len(data)\n        except TypeError:\n            # _InfiniteConstantSampler can raise a TypeError on DataLoader length of a IterableDataset\n            pass\n        return data_length\n\n    def _setup_engine(self) -> None:\n        iteration = self.state.iteration\n        self._dataloader_iter = iter(self.state.dataloader)\n\n        # Below we define initial counter value for _run_once_on_dataset to measure a single epoch\n        if self.state.epoch_length is not None:\n            iteration %= self.state.epoch_length\n        self._init_iter.append(iteration)\n\n    def _internal_run(self) -> State:\n        self.should_terminate = self.should_terminate_single_epoch = False\n        self._init_timers(self.state)\n        try:\n            start_time = time.time()\n            self._fire_event(Events.STARTED)\n            while self.state.epoch < self.state.max_epochs and not self.should_terminate:\n                self.state.epoch += 1\n                self._fire_event(Events.EPOCH_STARTED)\n\n                if self._dataloader_iter is None:\n                    self._setup_engine()\n\n                time_taken = self._run_once_on_dataset()\n                self.state.times[Events.EPOCH_COMPLETED.name] = time_taken\n                hours, mins, secs = _to_hours_mins_secs(time_taken)\n                elapsed_time_message = ""Epoch[%s] Complete. Time taken: %02d:%02d:%02d"" % (\n                    self.state.epoch,\n                    hours,\n                    mins,\n                    secs,\n                )\n                if self.should_terminate:\n                    self._fire_event(Events.TERMINATE)\n                    self.logger.info(elapsed_time_message)\n                    break\n                self._fire_event(Events.EPOCH_COMPLETED)\n                self.logger.info(elapsed_time_message)\n\n            time_taken = time.time() - start_time\n            hours, mins, secs = _to_hours_mins_secs(time_taken)\n            self.state.times[Events.COMPLETED.name] = time_taken\n            self._fire_event(Events.COMPLETED)\n            self.logger.info(""Engine run complete. Time taken: %02d:%02d:%02d"" % (hours, mins, secs))\n\n        except BaseException as e:\n            self._dataloader_iter = None\n            self.logger.error(""Engine run is terminating due to exception: %s."", str(e))\n            self._handle_exception(e)\n\n        self._dataloader_iter = None\n        return self.state\n\n    def _run_once_on_dataset(self) -> float:\n        start_time = time.time()\n\n        # We need to setup iter_counter > 0 if we resume from an iteration\n        iter_counter = self._init_iter.pop() if len(self._init_iter) > 0 else 0\n        should_exit = False\n        try:\n            while True:\n                try:\n                    # Avoid Events.GET_BATCH_STARTED triggered twice when data iter is restarted\n                    if self.last_event_name != Events.DATALOADER_STOP_ITERATION:\n                        self._fire_event(Events.GET_BATCH_STARTED)\n                    self.state.batch = next(self._dataloader_iter)\n                    self._fire_event(Events.GET_BATCH_COMPLETED)\n                    iter_counter += 1\n                    should_exit = False\n                except StopIteration:\n                    # Define self.state.epoch_length if it is not yet set\n                    if self.state.epoch_length is None:\n                        # Define epoch length and stop the epoch\n                        self.state.epoch_length = iter_counter\n                        break\n\n                    # Should exit while loop if we can not iterate\n                    if should_exit:\n                        if not self._is_done(self.state):\n                            warnings.warn(\n                                ""Data iterator can not provide data anymore but required total number of ""\n                                ""iterations to run is not reached. ""\n                                ""Current iteration: {} vs Total iterations to run : {}"".format(\n                                    self.state.iteration, self.state.epoch_length * self.state.max_epochs\n                                )\n                            )\n                        break\n\n                    self._fire_event(Events.DATALOADER_STOP_ITERATION)\n                    self.set_data(self.state.dataloader)\n\n                    should_exit = True\n\n                    continue\n\n                self.state.iteration += 1\n                self._fire_event(Events.ITERATION_STARTED)\n                self.state.output = self._process_function(self, self.state.batch)\n                self._fire_event(Events.ITERATION_COMPLETED)\n\n                # TODO: remove refs on batch to avoid high mem consumption ? -> need verification\n                # self.state.batch = None\n\n                if self.should_terminate or self.should_terminate_single_epoch:\n                    self._fire_event(Events.TERMINATE_SINGLE_EPOCH, iter_counter=iter_counter)\n                    self.should_terminate_single_epoch = False\n                    self.set_data(self.state.dataloader)\n                    break\n\n                if self.state.epoch_length is not None and iter_counter == self.state.epoch_length:\n                    break\n\n        except Exception as e:\n            self.logger.error(""Current run is terminating due to exception: %s."", str(e))\n            self._handle_exception(e)\n\n        return time.time() - start_time\n'"
ignite/engine/events.py,0,"b'import numbers\nimport warnings\nimport weakref\nfrom enum import Enum\nfrom types import DynamicClassAttribute\nfrom typing import Callable, Optional, Union\n\nfrom ignite.engine.utils import _check_signature\n\n__all__ = [""CallableEventWithFilter"", ""EventEnum"", ""Events"", ""State""]\n\n\nclass CallableEventWithFilter:\n    """"""Single Event containing a filter, specifying whether the event should\n    be run at the current event (if the event type is correct)\n\n    Args:\n        value (str): The actual enum value. Only needed for internal use. Do not touch!\n        event_filter (callable): A function taking the engine and the current event value as input and returning a\n            boolean to indicate whether this event should be executed. Defaults to None, which will result to a\n            function that always returns `True`\n        name (str, optional): The enum-name of the current object. Only needed for internal use. Do not touch!\n\n    """"""\n\n    def __init__(self, value: str, event_filter: Optional[Callable] = None, name=None):\n        if event_filter is None:\n            event_filter = CallableEventWithFilter.default_event_filter\n        self.filter = event_filter\n\n        if not hasattr(self, ""_value_""):\n            self._value_ = value\n\n        if not hasattr(self, ""_name_"") and name is not None:\n            self._name_ = name\n\n    # copied to be compatible to enum\n    @DynamicClassAttribute\n    def name(self):\n        """"""The name of the Enum member.""""""\n        return self._name_\n\n    @DynamicClassAttribute\n    def value(self):\n        """"""The value of the Enum member.""""""\n        return self._value_\n\n    def __call__(\n        self, event_filter: Optional[Callable] = None, every: Optional[int] = None, once: Optional[int] = None\n    ) -> ""CallableEventWithFilter"":\n        """"""\n        Makes the event class callable and accepts either an arbitrary callable as filter\n        (which must take in the engine and current event value and return a boolean) or an every or once value\n\n        Args:\n            event_filter (callable, optional): a filter function to check if the event should be executed when\n                the event type was fired\n            every (int, optional): a value specifying how often the event should be fired\n            once (int, optional): a value specifying when the event should be fired (if only once)\n\n        Returns:\n            CallableEventWithFilter: A new event having the same value but a different filter function\n        """"""\n\n        if not ((event_filter is not None) ^ (every is not None) ^ (once is not None)):\n            raise ValueError(""Only one of the input arguments should be specified"")\n\n        if (event_filter is not None) and not callable(event_filter):\n            raise TypeError(""Argument event_filter should be a callable"")\n\n        if (every is not None) and not (isinstance(every, numbers.Integral) and every > 0):\n            raise ValueError(""Argument every should be integer and greater than zero"")\n\n        if (once is not None) and not (isinstance(once, numbers.Integral) and once > 0):\n            raise ValueError(""Argument every should be integer and positive"")\n\n        if every is not None:\n            if every == 1:\n                # Just return the event itself\n                event_filter = None\n            else:\n                event_filter = self.every_event_filter(every)\n\n        if once is not None:\n            event_filter = self.once_event_filter(once)\n\n        # check signature:\n        if event_filter is not None:\n            _check_signature(event_filter, ""event_filter"", ""engine"", ""event"")\n\n        return CallableEventWithFilter(self.value, event_filter, self.name)\n\n    @staticmethod\n    def every_event_filter(every: int) -> Callable:\n        def wrapper(engine, event: int) -> bool:\n            if event % every == 0:\n                return True\n            return False\n\n        return wrapper\n\n    @staticmethod\n    def once_event_filter(once: int) -> Callable:\n        def wrapper(engine, event: int) -> bool:\n            if event == once:\n                return True\n            return False\n\n        return wrapper\n\n    @staticmethod\n    def default_event_filter(engine, event: int) -> bool:\n        return True\n\n    def __str__(self) -> str:\n        return ""<event=%s, filter=%r>"" % (self.name, self.filter)\n\n    def __eq__(self, other):\n        if isinstance(other, CallableEventWithFilter):\n            return self.name == other.name\n        elif isinstance(other, str):\n            return self.name == other\n        else:\n            raise NotImplementedError\n\n    def __hash__(self):\n        return hash(self._name_)\n\n    def __or__(self, other):\n        return EventsList() | self | other\n\n\nclass CallableEvents(CallableEventWithFilter):\n    # For backward compatibility\n    def __init__(self, *args, **kwargs):\n        super(CallableEvents, self).__init__(*args, **kwargs)\n        warnings.warn(\n            ""Class ignite.engine.events.CallableEvents is deprecated. It will be removed in 0.5.0. ""\n            ""Please, use ignite.engine.EventEnum instead"",\n            DeprecationWarning,\n        )\n\n\nclass EventEnum(CallableEventWithFilter, Enum):\n    pass\n\n\nclass Events(EventEnum):\n    """"""Events that are fired by the :class:`~ignite.engine.Engine` during execution. Built-in events:\n\n    - STARTED : triggered when engine\'s run is started\n    - EPOCH_STARTED : triggered when the epoch is started\n    - GET_BATCH_STARTED : triggered before next batch is fetched\n    - GET_BATCH_COMPLETED : triggered after the batch is fetched\n    - ITERATION_STARTED : triggered when an iteration is started\n    - ITERATION_COMPLETED : triggered when the iteration is ended\n\n    - DATALOADER_STOP_ITERATION : engine\'s specific event triggered when dataloader has no more data to provide\n\n    - EXCEPTION_RAISED : triggered when an exception is encountered\n    - TERMINATE_SINGLE_EPOCH : triggered when the run is about to end the current epoch,\n      after receiving :meth:`~ignite.engine.Engine.terminate_epoch()` call.\n\n    - TERMINATE : triggered when the run is about to end completely,\n      after receiving :meth:`~ignite.engine.Engine.terminate()` call.\n\n    - EPOCH_COMPLETED : triggered when the epoch is ended\n    - COMPLETED : triggered when engine\'s run is completed\n\n    Since v0.3.0, Events become more flexible and allow to pass an event filter to the Engine:\n\n    .. code-block:: python\n\n        engine = Engine()\n\n        # a) custom event filter\n        def custom_event_filter(engine, event):\n            if event in [1, 2, 5, 10, 50, 100]:\n                return True\n            return False\n\n        @engine.on(Events.ITERATION_STARTED(event_filter=custom_event_filter))\n        def call_on_special_event(engine):\n            # do something on 1, 2, 5, 10, 50, 100 iterations\n\n        # b) ""every"" event filter\n        @engine.on(Events.ITERATION_STARTED(every=10))\n        def call_every(engine):\n            # do something every 10th iteration\n\n        # c) ""once"" event filter\n        @engine.on(Events.ITERATION_STARTED(once=50))\n        def call_once(engine):\n            # do something on 50th iteration\n\n    Event filter function `event_filter` accepts as input `engine` and `event` and should return True/False.\n    Argument `event` is the value of iteration or epoch, depending on which type of Events the function is passed.\n\n    Since v0.4.0, user can also combine events with `|`-operator:\n\n    .. code-block:: python\n\n        events = Events.STARTED | Events.COMPLETED | Events.ITERATION_STARTED(every=3)\n        engine = ...\n\n        @engine.on(events)\n        def call_on_events(engine):\n            # do something\n\n    """"""\n\n    EPOCH_STARTED = ""epoch_started""\n    EPOCH_COMPLETED = ""epoch_completed""\n\n    STARTED = ""started""\n    COMPLETED = ""completed""\n\n    ITERATION_STARTED = ""iteration_started""\n    ITERATION_COMPLETED = ""iteration_completed""\n    EXCEPTION_RAISED = ""exception_raised""\n\n    GET_BATCH_STARTED = ""get_batch_started""\n    GET_BATCH_COMPLETED = ""get_batch_completed""\n\n    DATALOADER_STOP_ITERATION = ""dataloader_stop_iteration""\n    TERMINATE = ""terminate""\n    TERMINATE_SINGLE_EPOCH = ""terminate_single_epoch""\n\n    def __or__(self, other):\n        return EventsList() | self | other\n\n\nclass EventsList:\n    """"""Collection of events stacked by operator `__or__`.\n\n    .. code-block:: python\n\n        events = Events.STARTED | Events.COMPLETED\n        events |= Events.ITERATION_STARTED(every=3)\n\n        engine = ...\n\n        @engine.on(events)\n        def call_on_events(engine):\n            # do something\n\n    or\n\n     .. code-block:: python\n\n        @engine.on(Events.STARTED | Events.COMPLETED | Events.ITERATION_STARTED(every=3))\n        def call_on_events(engine):\n            # do something\n\n    """"""\n\n    def __init__(self):\n        self._events = []\n\n    def _append(self, event: Union[Events, CallableEventWithFilter]):\n        if not isinstance(event, (Events, CallableEventWithFilter)):\n            raise ValueError(""Argument event should be Events or CallableEventWithFilter, got: {}"".format(type(event)))\n        self._events.append(event)\n\n    def __getitem__(self, item):\n        return self._events[item]\n\n    def __iter__(self):\n        return iter(self._events)\n\n    def __len__(self):\n        return len(self._events)\n\n    def __or__(self, other: Union[Events, CallableEventWithFilter]):\n        self._append(event=other)\n        return self\n\n\nclass State:\n    """"""An object that is used to pass internal and user-defined state between event handlers. By default, state\n    contains the following attributes:\n\n    .. code-block:: python\n\n        state.iteration         # 1-based, the first iteration is 1\n        state.epoch             # 1-based, the first epoch is 1\n        state.seed              # seed to set at each epoch\n        state.dataloader        # data passed to engine\n        state.epoch_length      # optional length of an epoch\n        state.max_epochs        # number of epochs to run\n        state.batch             # batch passed to `process_function`\n        state.output            # output of `process_function` after a single iteration\n        state.metrics           # dictionary with defined metrics if any\n        state.times             # dictionary with total and per-epoch times fetched on\n                                # keys: Events.EPOCH_COMPLETED.name and Events.COMPLETED.name\n\n    """"""\n\n    event_to_attr = {\n        Events.GET_BATCH_STARTED: ""iteration"",\n        Events.GET_BATCH_COMPLETED: ""iteration"",\n        Events.ITERATION_STARTED: ""iteration"",\n        Events.ITERATION_COMPLETED: ""iteration"",\n        Events.EPOCH_STARTED: ""epoch"",\n        Events.EPOCH_COMPLETED: ""epoch"",\n        Events.STARTED: ""epoch"",\n        Events.COMPLETED: ""epoch"",\n    }\n\n    def __init__(self, **kwargs):\n        self.iteration = 0\n        self.epoch = 0\n        self.epoch_length = None\n        self.max_epochs = None\n        self.output = None\n        self.batch = None\n        self.metrics = {}\n        self.dataloader = None\n        self.seed = None\n        self.times = {Events.EPOCH_COMPLETED.name: None, Events.COMPLETED.name: None}\n\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n\n        self._update_attrs()\n\n    def _update_attrs(self):\n        for value in self.event_to_attr.values():\n            if not hasattr(self, value):\n                setattr(self, value, 0)\n\n    def get_event_attrib_value(self, event_name: Union[CallableEventWithFilter, Enum]) -> int:\n        if event_name not in State.event_to_attr:\n            raise RuntimeError(""Unknown event name \'{}\'"".format(event_name))\n        return getattr(self, State.event_to_attr[event_name])\n\n    def __repr__(self) -> str:\n        s = ""State:\\n""\n        for attr, value in self.__dict__.items():\n            if not isinstance(value, (numbers.Number, str)):\n                value = type(value)\n            s += ""\\t{}: {}\\n"".format(attr, value)\n        return s\n\n\nclass RemovableEventHandle:\n    """"""A weakref handle to remove a registered event.\n\n    A handle that may be used to remove a registered event handler via the\n    remove method, with-statement, or context manager protocol. Returned from\n    :meth:`~ignite.engine.Engine.add_event_handler`.\n\n\n    Args:\n        event_name: Registered event name.\n        handler: Registered event handler, stored as weakref.\n        engine: Target engine, stored as weakref.\n\n    Example usage:\n\n    .. code-block:: python\n\n        engine = Engine()\n\n        def print_epoch(engine):\n            print(""Epoch: {}"".format(engine.state.epoch))\n\n        with engine.add_event_handler(Events.EPOCH_COMPLETED, print_epoch):\n            # print_epoch handler registered for a single run\n            engine.run(data)\n\n        # print_epoch handler is now unregistered\n    """"""\n\n    def __init__(self, event_name: Union[CallableEventWithFilter, Enum, EventsList], handler: Callable, engine):\n        self.event_name = event_name\n        self.handler = weakref.ref(handler)\n        self.engine = weakref.ref(engine)\n\n    def remove(self) -> None:\n        """"""Remove handler from engine.""""""\n        handler = self.handler()\n        engine = self.engine()\n\n        if handler is None or engine is None:\n            return\n\n        if isinstance(self.event_name, EventsList):\n            for e in self.event_name:\n                if engine.has_event_handler(handler, e):\n                    engine.remove_event_handler(handler, e)\n        else:\n            if engine.has_event_handler(handler, self.event_name):\n                engine.remove_event_handler(handler, self.event_name)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args, **kwargs) -> None:\n        self.remove()\n'"
ignite/engine/utils.py,0,"b'import inspect\nfrom typing import Callable\n\n\ndef _check_signature(fn: Callable, fn_description: str, *args, **kwargs) -> None:\n    # if handler with filter, check the handler rather than the decorator\n    if hasattr(fn, ""_parent""):\n        signature = inspect.signature(fn._parent())\n    else:\n        signature = inspect.signature(fn)\n    try:  # try without engine\n        signature.bind(*args, **kwargs)\n    except TypeError as exc:\n        fn_params = list(signature.parameters)\n        exception_msg = str(exc)\n        passed_params = list(args) + list(kwargs)\n        raise ValueError(\n            ""Error adding {} \'{}\': ""\n            ""takes parameters {} but will be called with {}""\n            ""({})."".format(fn, fn_description, fn_params, passed_params, exception_msg)\n        )\n'"
ignite/handlers/__init__.py,0,"b'from typing import Any, Callable, Union\n\nfrom ignite.engine import Engine\nfrom ignite.engine.events import CallableEventWithFilter, EventEnum\nfrom ignite.handlers.checkpoint import Checkpoint, DiskSaver, ModelCheckpoint\nfrom ignite.handlers.early_stopping import EarlyStopping\nfrom ignite.handlers.terminate_on_nan import TerminateOnNan\nfrom ignite.handlers.timing import Timer\n\n__all__ = [\n    ""ModelCheckpoint"",\n    ""Checkpoint"",\n    ""DiskSaver"",\n    ""Timer"",\n    ""EarlyStopping"",\n    ""TerminateOnNan"",\n    ""global_step_from_engine"",\n]\n\n\ndef global_step_from_engine(engine: Engine, custom_event_name=None) -> Callable:\n    """"""Helper method to setup `global_step_transform` function using another engine.\n    This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.\n\n    Args:\n        engine (Engine): engine which state is used to provide the global step\n        custom_event_name (optional): registered event name. Optional argument, event name to use.\n\n    Returns:\n        global step\n    """"""\n\n    def wrapper(_: Any, event_name: Union[EventEnum, CallableEventWithFilter]):\n        if custom_event_name is not None:\n            event_name = custom_event_name\n        return engine.state.get_event_attrib_value(event_name)\n\n    return wrapper\n'"
ignite/handlers/checkpoint.py,12,"b'import collections.abc as collections\nimport numbers\nimport os\nimport tempfile\nimport warnings\nfrom abc import ABCMeta, abstractmethod\nfrom collections import namedtuple\nfrom typing import Callable, Mapping, Optional, Union\n\nimport torch\nimport torch.nn as nn\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events\n\n__all__ = [""Checkpoint"", ""DiskSaver"", ""ModelCheckpoint"", ""BaseSaveHandler""]\n\n\nclass BaseSaveHandler(metaclass=ABCMeta):\n    """"""Base class for save handlers\n\n    Methods to override:\n\n    - :meth:`~ignite.handlers.checkpoint.BaseSaveHandler.__call__`\n    - :meth:`~ignite.handlers.checkpoint.BaseSaveHandler.remove`\n\n\n    Note:\n        In derived class, please, make sure that in distributed configuration overridden methods are called by a single\n        process. Distributed configuration on XLA devices should be treated slightly differently: for saving checkpoint\n        with `xm.save() <https://pytorch.org/xla/release/1.5/index.html#torch_xla.core.xla_model.save>`_  all processes\n        should pass into the function. Otherwise, application gets stuck.\n\n    """"""\n\n    @abstractmethod\n    def __call__(self, checkpoint: Mapping, filename: str, metadata: Optional[Mapping] = None) -> None:\n        """"""Method to save `checkpoint` with `filename`. Additionally, metadata dictionary is provided.\n\n        Metadata contains:\n\n        - `basename`: file prefix (if provided) with checkpoint name, e.g. `epoch_checkpoint`.\n        - `score_name`: score name if provided, e.g `val_acc`.\n        - `priority`: checkpoint priority value (higher is better), e.g. `12` or `0.6554435`\n\n        Args:\n            checkpoint (Mapping): checkpoint dictionary to save.\n            filename (str): filename associated with checkpoint.\n            metadata (Mapping, optional): metadata on checkpoint to save.\n\n        """"""\n        pass\n\n    @abstractmethod\n    def remove(self, filename: str) -> None:\n        """"""Method to remove saved checkpoint.\n\n        Args:\n            filename (str): filename associated with checkpoint.\n\n        """"""\n        pass\n\n\nclass Checkpoint:\n    """"""Checkpoint handler can be used to periodically save and load objects which have attribute\n    `state_dict`/`load_state_dict`. This class can use specific save handlers to store on the disk or a cloud\n    storage, etc. The Checkpoint handler (if used with :class:`~ignite.handlers.DiskSaver`) also handles automatically\n    moving data on TPU to CPU before writing the checkpoint.\n\n    Args:\n        to_save (Mapping): Dictionary with the objects to save. Objects should have implemented `state_dict` and `\n            load_state_dict` methods. If contains objects of type torch `DistributedDataParallel`_ or\n            `DataParallel`_, their internal wrapped model is automatically saved (to avoid additional key ``module.`` in\n            the state dictionary).\n        save_handler (callable or :class:`~ignite.handlers.checkpoint.BaseSaveHandler`): Method or callable class to\n            use to save engine and other provided objects. Function receives two objects: checkpoint as a dictionary\n            and filename. If `save_handler` is callable class, it can\n            inherit of :class:`~ignite.handlers.checkpoint.BaseSaveHandler` and optionally implement `remove` method to\n            keep a fixed number of saved checkpoints. In case if user needs to save engine\'s checkpoint on a disk,\n            `save_handler` can be defined with :class:`~ignite.handlers.DiskSaver`.\n        filename_prefix (str, optional): Prefix for the filename to which objects will be saved. See Note for details.\n        score_function (callable, optional): If not None, it should be a function taking a single argument,\n            :class:`~ignite.engine.Engine` object, and returning a score (`float`). Objects with highest scores will be\n            retained.\n        score_name (str, optional): If `score_function` not None, it is possible to store its value using\n            `score_name`. See Notes for more details.\n        n_saved (int, optional): Number of objects that should be kept on disk. Older files will be removed. If set to\n            `None`, all objects are kept.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided, uses function output as global_step.\n            To setup global step from another engine, please use :meth:`~ignite.handlers.global_step_from_engine`.\n        archived (bool, optional): Deprecated argument as models saved by `torch.save` are already compressed.\n\n    .. _DistributedDataParallel: https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel\n    .. _DataParallel: https://pytorch.org/docs/stable/nn.html#torch.nn.DataParallel\n\n    Note:\n        This class stores a single file as a dictionary of provided objects to save.\n        The filename has the following structure: `{filename_prefix}_{name}_{suffix}.{ext}` where\n\n        - `filename_prefix` is the argument passed to the constructor,\n        - `name` is the key in `to_save` if a single object is to store, otherwise `name` is ""checkpoint"".\n        - `suffix` is composed as following `{global_step}_{score_name}={score}`.\n\n        Above `global_step` defined by the output of `global_step_transform` and `score` defined by the output\n        of `score_function`.\n\n        By default, none of `score_function`, `score_name`, `global_step_transform` is defined, then suffix is\n        setup by attached engine\'s current iteration. The filename will be\n        `{filename_prefix}_{name}_{engine.state.iteration}.{ext}`.\n\n        If defined a `score_function`, but without `score_name`, then suffix is defined by provided score.\n        The filename will be `{filename_prefix}_{name}_{global_step}_{score}.pt`.\n\n        If defined `score_function` and `score_name`, then the filename will\n        be `{filename_prefix}_{name}_{score_name}={score}.{ext}`. If `global_step_transform` is provided, then\n        the filename will be `{filename_prefix}_{name}_{global_step}_{score_name}={score}.{ext}`\n\n        For example, `score_name=""neg_val_loss""` and `score_function` that returns `-loss` (as objects with highest\n        scores will be retained), then saved filename will be `{filename_prefix}_{name}_neg_val_loss=-0.1234.pt`.\n\n        To get the last stored filename, handler exposes attribute `last_checkpoint`:\n\n        .. code-block:: python\n\n            handler = Checkpoint(...)\n            ...\n            print(handler.last_checkpoint)\n            > checkpoint_12345.pt\n\n    Note:\n        This class is distributed configuration-friendly: it is not required to instantiate the class in rank 0 only\n        process. This class supports automatically distributed configuration and if used with\n        :class:`~ignite.handlers.DiskSaver`, checkpoint is stored by rank 0 process.\n\n    .. warning::\n\n        When running on TPUs, it should be run in all processes, otherwise application can get stuck on saving the\n        checkpoint.\n\n        .. code-block:: python\n\n            # Wrong:\n            # if idist.get_rank() == 0:\n            #     handler = Checkpoint(...)\n            #     trainer.add_event_handler(Events.ITERATION_COMPLETED(every=1000), handler)\n\n            # Correct:\n            handler = Checkpoint(...)\n            trainer.add_event_handler(Events.ITERATION_COMPLETED(every=1000), handler)\n\n    Examples:\n\n        Attach the handler to make checkpoints during training:\n\n        .. code-block:: python\n\n            from ignite.engine import Engine, Events\n            from ignite.handlers import Checkpoint, DiskSaver\n\n            trainer = ...\n            model = ...\n            optimizer = ...\n            lr_scheduler = ...\n\n            to_save = {\'model\': model, \'optimizer\': optimizer, \'lr_scheduler\': lr_scheduler, \'trainer\': trainer}\n            handler = Checkpoint(to_save, DiskSaver(\'/tmp/models\', create_dir=True), n_saved=2)\n            trainer.add_event_handler(Events.ITERATION_COMPLETED(every=1000), handler)\n            trainer.run(data_loader, max_epochs=6)\n            > [""checkpoint_7000.pt"", ""checkpoint_8000.pt"", ]\n\n        Attach the handler to an evaluator to save best model during the training\n        according to computed validation metric:\n\n        .. code-block:: python\n\n            from ignite.engine import Engine, Events\n            from ignite.handlers import Checkpoint, DiskSaver, global_step_from_engine\n\n            trainer = ...\n            evaluator = ...\n            # Setup Accuracy metric computation on evaluator\n            # Run evaluation on epoch completed event\n            # ...\n\n            def score_function(engine):\n                return engine.state.metrics[\'accuracy\']\n\n            to_save = {\'model\': model}\n            handler = Checkpoint(to_save, DiskSaver(\'/tmp/models\', create_dir=True), n_saved=2,\n                                 filename_prefix=\'best\', score_function=score_function, score_name=""val_acc"",\n                                 global_step_transform=global_step_from_engine(trainer))\n\n            evaluator.add_event_handler(Events.COMPLETED, handler)\n\n            trainer.run(data_loader, max_epochs=10)\n            > [""best_model_9_val_acc=0.77.pt"", ""best_model_10_val_acc=0.78.pt"", ]\n\n    """"""\n\n    Item = namedtuple(""Item"", [""priority"", ""filename""])\n\n    def __init__(\n        self,\n        to_save: Mapping,\n        save_handler: Union[Callable, BaseSaveHandler],\n        filename_prefix: str = """",\n        score_function: Optional[Callable] = None,\n        score_name: Optional[str] = None,\n        n_saved: Optional[int] = 1,\n        global_step_transform: Callable = None,\n        archived: bool = False,\n    ):\n\n        if to_save is not None:  # for compatibility with ModelCheckpoint\n            if not isinstance(to_save, collections.Mapping):\n                raise TypeError(""Argument `to_save` should be a dictionary, but given {}"".format(type(to_save)))\n\n            if len(to_save) < 1:\n                raise ValueError(""No objects to checkpoint."")\n\n            self._check_objects(to_save, ""state_dict"")\n\n        if not (callable(save_handler) or isinstance(save_handler, BaseSaveHandler)):\n            raise TypeError(""Argument `save_handler` should be callable or inherit from BaseSaveHandler"")\n\n        if score_function is None and score_name is not None:\n            raise ValueError(""If `score_name` is provided, then `score_function` "" ""should be also provided."")\n\n        if global_step_transform is not None and not callable(global_step_transform):\n            raise TypeError(\n                ""global_step_transform should be a function, got {} instead."".format(type(global_step_transform))\n            )\n        if archived:\n            warnings.warn(""Argument archived is deprecated and will be removed in 0.5.0"")\n\n        self.to_save = to_save\n        self._fname_prefix = filename_prefix + ""_"" if len(filename_prefix) > 0 else filename_prefix\n        self.save_handler = save_handler\n        self._score_function = score_function\n        self._score_name = score_name\n        self._n_saved = n_saved\n        self._saved = []\n        self._ext = "".pt""\n        self.global_step_transform = global_step_transform\n\n    @property\n    def last_checkpoint(self) -> Optional[str]:\n        if len(self._saved) < 1:\n            return None\n        return self._saved[-1].filename\n\n    def _check_lt_n_saved(self, or_equal=False):\n        if self._n_saved is None:\n            return True\n        return len(self._saved) < self._n_saved + int(or_equal)\n\n    def __call__(self, engine: Engine) -> None:\n\n        suffix = """"\n        if self.global_step_transform is not None:\n            global_step = self.global_step_transform(engine, engine.last_event_name)\n            suffix = ""{}"".format(global_step)\n\n        if self._score_function is not None:\n            priority = self._score_function(engine)\n            if not isinstance(priority, numbers.Number):\n                raise ValueError(""Output of score_function should be a number"")\n        else:\n            priority = engine.state.get_event_attrib_value(Events.ITERATION_COMPLETED)\n\n        if self._check_lt_n_saved() or self._saved[0].priority < priority:\n\n            priority_str = (\n                ""{}"".format(priority) if isinstance(priority, numbers.Integral) else ""{:.4f}"".format(priority)\n            )\n\n            if self._score_name is not None:\n                if len(suffix) > 0:\n                    suffix += ""_""\n                suffix = ""{}{}={}"".format(suffix, self._score_name, priority_str)\n            elif self._score_function is not None:\n                if len(suffix) > 0:\n                    suffix += ""_""\n                suffix = ""{}{}"".format(suffix, priority_str)\n            elif len(suffix) == 0:\n                suffix = ""{}"".format(priority_str)\n\n            checkpoint = self._setup_checkpoint()\n\n            name = ""checkpoint""\n            if len(checkpoint) == 1:\n                for k in checkpoint:\n                    name = k\n                checkpoint = checkpoint[name]\n            filename = ""{}{}_{}{}"".format(self._fname_prefix, name, suffix, self._ext)\n\n            if any(item.filename == filename for item in self._saved):\n                return\n\n            metadata = {\n                ""basename"": ""{}{}"".format(self._fname_prefix, name),\n                ""score_name"": self._score_name,\n                ""priority"": priority,\n            }\n\n            try:\n                self.save_handler(checkpoint, filename, metadata)\n            except TypeError:\n                self.save_handler(checkpoint, filename)\n\n            self._saved.append(Checkpoint.Item(priority, filename))\n            self._saved.sort(key=lambda item: item[0])\n\n        if not self._check_lt_n_saved(or_equal=True):\n            item = self._saved.pop(0)\n            if isinstance(self.save_handler, BaseSaveHandler):\n                self.save_handler.remove(item.filename)\n\n    def _setup_checkpoint(self) -> dict:\n        checkpoint = {}\n        for k, obj in self.to_save.items():\n            if isinstance(obj, (nn.DataParallel, nn.parallel.DistributedDataParallel)):\n                obj = obj.module\n            checkpoint[k] = obj.state_dict()\n        return checkpoint\n\n    @staticmethod\n    def _check_objects(objs: Mapping, attr: str) -> None:\n        for k, obj in objs.items():\n            if not hasattr(obj, attr):\n                raise TypeError(""Object {} should have `{}` method"".format(type(obj), attr))\n\n    @staticmethod\n    def load_objects(to_load: Mapping, checkpoint: Mapping, **kwargs) -> None:\n        """"""Helper method to apply `load_state_dict` on the objects from `to_load` using states from `checkpoint`.\n\n        Exemples:\n\n        .. code-block:: python\n\n            import torch\n            from ignite.engine import Engine, Events\n            from ignite.handlers import ModelCheckpoint, Checkpoint\n            trainer = Engine(lambda engine, batch: None)\n            handler = ModelCheckpoint(\'/tmp/models\', \'myprefix\', n_saved=None, create_dir=True)\n            model = torch.nn.Linear(3, 3)\n            optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n            to_save = {""weights"": model, ""optimizer"": optimizer}\n            trainer.add_event_handler(Events.EPOCH_COMPLETED(every=2), handler, to_save)\n            trainer.run(torch.randn(10, 1), 5)\n\n            to_load = to_save\n            checkpoint_fp = ""/tmp/models/myprefix_checkpoint_40.pth""\n            checkpoint = torch.load(checkpoint_fp)\n            Checkpoint.load_objects(to_load=to_load, checkpoint=checkpoint)\n\n        Args:\n            to_load (Mapping): a dictionary with objects, e.g. `{""model"": model, ""optimizer"": optimizer, ...}`\n            checkpoint (Mapping): a dictionary with state_dicts to load, e.g. `{""model"": model_state_dict,\n                ""optimizer"": opt_state_dict}`. If `to_load` contains a single key, then checkpoint can contain directly\n                corresponding state_dict.\n            **kwargs: Keyword arguments accepted for `nn.Module.load_state_dict()`. Passing `strict=False` enables\n                the user to load part of the pretrained model (useful for example, in Transfer Learning)\n        """"""\n        Checkpoint._check_objects(to_load, ""load_state_dict"")\n        if not isinstance(checkpoint, collections.Mapping):\n            raise TypeError(""Argument checkpoint should be a dictionary, but given {}"".format(type(checkpoint)))\n\n        if len(kwargs) > 1 or any(k for k in kwargs.keys() if k not in [""strict""]):\n            warnings.warn(""kwargs contains keys other than strict and these will be ignored"")\n\n        is_state_dict_strict = kwargs.get(""strict"", True)\n        if len(to_load) == 1:\n            # single object and checkpoint is directly a state_dict\n            key, obj = list(to_load.items())[0]\n            if key not in checkpoint:\n                obj.load_state_dict(checkpoint, strict=is_state_dict_strict)\n                return\n\n        # multiple objects to load\n        for k, obj in to_load.items():\n            if k not in checkpoint:\n                raise ValueError(""Object labeled by \'{}\' from `to_load` is not found in the checkpoint"".format(k))\n            if isinstance(obj, torch.nn.Module):\n                obj.load_state_dict(checkpoint[k], strict=is_state_dict_strict)\n            else:\n                obj.load_state_dict(checkpoint[k])\n\n\nclass DiskSaver(BaseSaveHandler):\n    """"""Handler that saves input checkpoint on a disk.\n\n    Args:\n        dirname (str): Directory path where the checkpoint will be saved\n        atomic (bool, optional): if True, checkpoint is serialized to a temporary file, and then\n            moved to final destination, so that files are guaranteed to not be damaged\n            (for example if exception occurs during saving).\n        create_dir (bool, optional): if True, will create directory \'dirname\' if it doesnt exist.\n        require_empty (bool, optional): If True, will raise exception if there are any files in the directory \'dirname\'.\n    """"""\n\n    def __init__(\n        self, dirname: str, atomic: bool = True, create_dir: bool = True, require_empty: bool = True,\n    ):\n        self.dirname = os.path.expanduser(dirname)\n        self._atomic = atomic\n        self._check_and_setup(dirname, create_dir, require_empty)\n\n    @staticmethod\n    @idist.one_rank_only()\n    def _check_and_setup(dirname, create_dir, require_empty):\n        if create_dir:\n            if not os.path.exists(dirname):\n                os.makedirs(dirname)\n        # Ensure that dirname exists\n        if not os.path.exists(dirname):\n            raise ValueError(""Directory path \'{}\' is not found"".format(dirname))\n\n        if require_empty:\n            matched = [fname for fname in os.listdir(dirname) if fname.endswith("".pt"")]\n            if len(matched) > 0:\n                raise ValueError(\n                    ""Files {} with extension \'.pt\' are already present ""\n                    ""in the directory {}. If you want to use this ""\n                    ""directory anyway, pass `require_empty=False`.""\n                    """".format(matched, dirname)\n                )\n\n    def __call__(self, checkpoint: Mapping, filename: str, metadata: Optional[Mapping] = None) -> None:\n        path = os.path.join(self.dirname, filename)\n\n        if idist.has_xla_support:\n            self._save_xla(checkpoint, path)\n        else:\n            self._save_native(checkpoint, path)\n\n    @idist.one_rank_only()\n    def _save_native(self, checkpoint: Mapping, path: str):\n        self._save_func(checkpoint, path, torch.save)\n\n    def _save_xla(self, checkpoint: Mapping, path: str):\n        import torch_xla.core.xla_model as xm\n\n        # all tpu procs should enter here as internally performs sync across device\n        self._save_func(checkpoint, path, xm.save, rank=idist.get_rank())\n\n    def _save_func(self, checkpoint: Mapping, path: str, func: Callable, rank: int = 0):\n        if not self._atomic:\n            func(checkpoint, path)\n        else:\n            tmp_file = None\n            tmp_name = None\n            tmp = None\n            if rank == 0:\n                tmp = tempfile.NamedTemporaryFile(delete=False, dir=self.dirname)\n                tmp_file = tmp.file\n                tmp_name = tmp.name\n            try:\n                func(checkpoint, tmp_file)\n            except BaseException:\n                if tmp is not None:\n                    tmp.close()\n                    os.remove(tmp_name)\n                    raise\n            else:\n                if tmp is not None:\n                    tmp.close()\n                    os.rename(tmp.name, path)\n\n    @idist.one_rank_only()\n    def remove(self, filename: str) -> None:\n        path = os.path.join(self.dirname, filename)\n        os.remove(path)\n\n\nclass ModelCheckpoint(Checkpoint):\n    """"""ModelCheckpoint handler can be used to periodically save objects to disk only. If needed to store checkpoints to\n    another storage type, please consider :class:`~ignite.handlers.checkpoint.Checkpoint`.\n\n    This handler expects two arguments:\n\n        - an :class:`~ignite.engine.Engine` object\n        - a `dict` mapping names (`str`) to objects that should be saved to disk.\n\n    See Examples for further details.\n\n    .. warning::\n\n        Behaviour of this class has been changed since v0.3.0.\n\n        Argument `save_as_state_dict` is deprecated and should not be used. It is considered as True.\n\n        Argument `save_interval` is deprecated and should not be used. Please, use events filtering instead, e.g.\n        :attr:`~ignite.engine.Events.ITERATION_STARTED(every=1000)`\n\n        There is no more internal counter that has been used to indicate the number of save actions. User could\n        see its value `step_number` in the filename, e.g. `{filename_prefix}_{name}_{step_number}.pt`. Actually,\n        `step_number` is replaced by current engine\'s epoch if `score_function` is specified and current iteration\n        otherwise.\n\n        A single `pt` file is created instead of multiple files.\n\n    Args:\n        dirname (str): Directory path where objects will be saved.\n        filename_prefix (str): Prefix for the filenames to which objects will be saved. See Notes of\n            :class:`~ignite.handlers.Checkpoint` for more details.\n        score_function (callable, optional): if not None, it should be a function taking a single argument, an\n            :class:`~ignite.engine.Engine` object, and return a score (`float`). Objects with highest scores will be\n            retained.\n        score_name (str, optional): if `score_function` not None, it is possible to store its value using\n            `score_name`. See Notes for more details.\n        n_saved (int, optional): Number of objects that should be kept on disk. Older files will be removed. If set to\n            `None`, all objects are kept.\n        atomic (bool, optional): If True, objects are serialized to a temporary file, and then moved to final\n            destination, so that files are guaranteed to not be damaged (for example if exception\n            occurs during saving).\n        require_empty (bool, optional): If True, will raise exception if there are any files starting with\n            `filename_prefix` in the directory \'dirname\'.\n        create_dir (bool, optional): If True, will create directory \'dirname\' if it doesnt exist.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided, uses function output as global_step.\n            To setup global step from another engine, please use :meth:`~ignite.handlers.global_step_from_engine`.\n        archived (bool, optional): Deprecated argument as models saved by `torch.save` are already compressed.\n\n    Examples:\n        >>> import os\n        >>> from ignite.engine import Engine, Events\n        >>> from ignite.handlers import ModelCheckpoint\n        >>> from torch import nn\n        >>> trainer = Engine(lambda batch: None)\n        >>> handler = ModelCheckpoint(\'/tmp/models\', \'myprefix\', n_saved=2, create_dir=True)\n        >>> model = nn.Linear(3, 3)\n        >>> trainer.add_event_handler(Events.EPOCH_COMPLETED(every=2), handler, {\'mymodel\': model})\n        >>> trainer.run([0], max_epochs=6)\n        >>> os.listdir(\'/tmp/models\')\n        [\'myprefix_mymodel_4.pt\', \'myprefix_mymodel_6.pt\']\n        >>> handler.last_checkpoint\n        [\'/tmp/models/myprefix_mymodel_6.pt\']\n    """"""\n\n    def __init__(\n        self,\n        dirname: str,\n        filename_prefix: str,\n        save_interval: Optional[Callable] = None,\n        score_function: Optional[Callable] = None,\n        score_name: Optional[str] = None,\n        n_saved: Union[int, None] = 1,\n        atomic: bool = True,\n        require_empty: bool = True,\n        create_dir: bool = True,\n        save_as_state_dict: bool = True,\n        global_step_transform: Optional[Callable] = None,\n        archived: bool = False,\n    ):\n\n        if not save_as_state_dict:\n            raise ValueError(\n                ""Argument save_as_state_dict is deprecated and should be True.""\n                ""This argument will be removed in 0.5.0.""\n            )\n        if save_interval is not None:\n            msg = (\n                ""Argument save_interval is deprecated and should be None. This argument will be removed in 0.5.0.""\n                ""Please, use events filtering instead, e.g. Events.ITERATION_STARTED(every=1000)""\n            )\n            if save_interval == 1:\n                # Do not break for old version who used `save_interval=1`\n                warnings.warn(msg)\n            else:\n                # No choice\n                raise ValueError(msg)\n\n        disk_saver = DiskSaver(dirname, atomic=atomic, create_dir=create_dir, require_empty=require_empty,)\n\n        super(ModelCheckpoint, self).__init__(\n            to_save=None,\n            save_handler=disk_saver,\n            filename_prefix=filename_prefix,\n            score_function=score_function,\n            score_name=score_name,\n            n_saved=n_saved,\n            global_step_transform=global_step_transform,\n            archived=archived,\n        )\n\n    @property\n    def last_checkpoint(self) -> Union[str, None]:\n        if len(self._saved) < 1:\n            return None\n        return os.path.join(self.save_handler.dirname, self._saved[-1].filename)\n\n    def __call__(self, engine: Engine, to_save: Mapping) -> None:\n\n        if len(to_save) == 0:\n            raise RuntimeError(""No objects to checkpoint found."")\n\n        self._check_objects(to_save, ""state_dict"")\n        self.to_save = to_save\n        super(ModelCheckpoint, self).__call__(engine)\n'"
ignite/handlers/early_stopping.py,0,"b'import logging\nfrom typing import Callable\n\nfrom ignite.engine import Engine\n\n__all__ = [""EarlyStopping""]\n\n\nclass EarlyStopping:\n    """"""EarlyStopping handler can be used to stop the training if no improvement after a given number of events.\n\n    Args:\n        patience (int):\n            Number of events to wait if no improvement and then stop the training.\n        score_function (callable):\n            It should be a function taking a single argument, an :class:`~ignite.engine.Engine` object,\n            and return a score `float`. An improvement is considered if the score is higher.\n        trainer (Engine):\n            trainer engine to stop the run if no improvement.\n        min_delta (float, optional):\n            A minimum increase in the score to qualify as an improvement,\n            i.e. an increase of less than or equal to `min_delta`, will count as no improvement.\n        cumulative_delta (bool, optional):\n            It True, `min_delta` defines an increase since the last `patience` reset, otherwise,\n            it defines an increase after the last event. Default value is False.\n\n    Examples:\n\n    .. code-block:: python\n\n        from ignite.engine import Engine, Events\n        from ignite.handlers import EarlyStopping\n\n        def score_function(engine):\n            val_loss = engine.state.metrics[\'nll\']\n            return -val_loss\n\n        handler = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n        # Note: the handler is attached to an *Evaluator* (runs one epoch on validation dataset).\n        evaluator.add_event_handler(Events.COMPLETED, handler)\n\n    """"""\n\n    def __init__(\n        self,\n        patience: int,\n        score_function: Callable,\n        trainer: Engine,\n        min_delta: float = 0.0,\n        cumulative_delta: bool = False,\n    ):\n\n        if not callable(score_function):\n            raise TypeError(""Argument score_function should be a function."")\n\n        if patience < 1:\n            raise ValueError(""Argument patience should be positive integer."")\n\n        if min_delta < 0.0:\n            raise ValueError(""Argument min_delta should not be a negative number."")\n\n        if not isinstance(trainer, Engine):\n            raise TypeError(""Argument trainer should be an instance of Engine."")\n\n        self.score_function = score_function\n        self.patience = patience\n        self.min_delta = min_delta\n        self.cumulative_delta = cumulative_delta\n        self.trainer = trainer\n        self.counter = 0\n        self.best_score = None\n        self.logger = logging.getLogger(__name__ + ""."" + self.__class__.__name__)\n\n    def __call__(self, engine: Engine) -> None:\n        score = self.score_function(engine)\n\n        if self.best_score is None:\n            self.best_score = score\n        elif score <= self.best_score + self.min_delta:\n            if not self.cumulative_delta and score > self.best_score:\n                self.best_score = score\n            self.counter += 1\n            self.logger.debug(""EarlyStopping: %i / %i"" % (self.counter, self.patience))\n            if self.counter >= self.patience:\n                self.logger.info(""EarlyStopping: Stop training"")\n                self.trainer.terminate()\n        else:\n            self.best_score = score\n            self.counter = 0\n'"
ignite/handlers/terminate_on_nan.py,7,"b'import logging\nimport numbers\nfrom typing import Callable, Union\n\nimport torch\n\nfrom ignite.engine import Engine\nfrom ignite.utils import apply_to_type\n\n__all__ = [""TerminateOnNan""]\n\n\nclass TerminateOnNan:\n    """"""TerminateOnNan handler can be used to stop the training if the `process_function`\'s output\n    contains a NaN or infinite number or `torch.tensor`.\n    The output can be of type: number, tensor or collection of them. The training is stopped if\n    there is at least a single number/tensor have NaN or Infinite value. For example, if the output is\n    `[1.23, torch.tensor(...), torch.tensor(float(\'nan\'))]` the handler will stop the training.\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into a number or `torch.tensor`\n            or collection of them. This can be useful if, for example, you have a multi-output model and\n            you want to check one or multiple values of the output.\n\n\n    Examples:\n\n    .. code-block:: python\n\n        trainer.add_event_handler(Events.ITERATION_COMPLETED, TerminateOnNan())\n\n    """"""\n\n    def __init__(self, output_transform: Callable = lambda x: x):\n        self.logger = logging.getLogger(__name__ + ""."" + self.__class__.__name__)\n        self.logger.addHandler(logging.StreamHandler())\n        self._output_transform = output_transform\n\n    def __call__(self, engine: Engine) -> None:\n        output = self._output_transform(engine.state.output)\n\n        def raise_error(x: Union[numbers.Number, torch.Tensor]) -> None:\n\n            if isinstance(x, numbers.Number):\n                x = torch.tensor(x)\n\n            if isinstance(x, torch.Tensor) and not bool(torch.isfinite(x).all()):\n                raise RuntimeError(""Infinite or NaN tensor found."")\n\n        try:\n            apply_to_type(output, (numbers.Number, torch.Tensor), raise_error)\n        except RuntimeError:\n            self.logger.warning(\n                ""{}: Output \'{}\' contains NaN or Inf. Stop training"".format(self.__class__.__name__, output)\n            )\n            engine.terminate()\n'"
ignite/handlers/timing.py,0,"b'from time import perf_counter\nfrom typing import Optional\n\nfrom ignite.engine import Engine, Events\n\n__all__ = [""Timer""]\n\n\nclass Timer:\n    """""" Timer object can be used to measure (average) time between events.\n\n    Args:\n        average (bool, optional): if True, then when ``.value()`` method is called, the returned value\n            will be equal to total time measured, divided by the value of internal counter.\n\n    Attributes:\n        total (float): total time elapsed when the Timer was running (in seconds).\n        step_count (int): internal counter, usefull to measure average time, e.g. of processing a single batch.\n            Incremented with the ``.step()`` method.\n        running (bool): flag indicating if timer is measuring time.\n\n    Note:\n        When using ``Timer(average=True)`` do not forget to call ``timer.step()`` every time an event occurs. See\n        the examples below.\n\n    Examples:\n\n        Measuring total time of the epoch:\n\n        >>> from ignite.handlers import Timer\n        >>> import time\n        >>> work = lambda : time.sleep(0.1)\n        >>> idle = lambda : time.sleep(0.1)\n        >>> t = Timer(average=False)\n        >>> for _ in range(10):\n        ...    work()\n        ...    idle()\n        ...\n        >>> t.value()\n        2.003073937026784\n\n        Measuring average time of the epoch:\n\n        >>> t = Timer(average=True)\n        >>> for _ in range(10):\n        ...    work()\n        ...    idle()\n        ...    t.step()\n        ...\n        >>> t.value()\n        0.2003182829997968\n\n        Measuring average time it takes to execute a single ``work()`` call:\n\n        >>> t = Timer(average=True)\n        >>> for _ in range(10):\n        ...    t.resume()\n        ...    work()\n        ...    t.pause()\n        ...    idle()\n        ...    t.step()\n        ...\n        >>> t.value()\n        0.10016545779653825\n\n        Using the Timer to measure average time it takes to process a single batch of examples:\n\n        >>> from ignite.engine import Engine, Events\n        >>> from ignite.handlers import Timer\n        >>> trainer = Engine(training_update_function)\n        >>> timer = Timer(average=True)\n        >>> timer.attach(trainer,\n        ...              start=Events.EPOCH_STARTED,\n        ...              resume=Events.ITERATION_STARTED,\n        ...              pause=Events.ITERATION_COMPLETED,\n        ...              step=Events.ITERATION_COMPLETED)\n    """"""\n\n    def __init__(self, average: bool = False):\n        self._average = average\n        self._t0 = perf_counter()\n\n        self.total = 0.0\n        self.step_count = 0.0\n        self.running = True\n\n    def attach(\n        self,\n        engine: Engine,\n        start: Events = Events.STARTED,\n        pause: Events = Events.COMPLETED,\n        resume: Optional[Events] = None,\n        step: Optional[Events] = None,\n    ):\n        """""" Register callbacks to control the timer.\n\n        Args:\n            engine (Engine):\n                Engine that this timer will be attached to.\n            start (Events):\n                Event which should start (reset) the timer.\n            pause (Events):\n                Event which should pause the timer.\n            resume (Events, optional):\n                Event which should resume the timer.\n            step (Events, optional):\n                Event which should call the `step` method of the counter.\n\n        Returns:\n            self (Timer)\n\n        """"""\n\n        engine.add_event_handler(start, self.reset)\n        engine.add_event_handler(pause, self.pause)\n\n        if resume is not None:\n            engine.add_event_handler(resume, self.resume)\n\n        if step is not None:\n            engine.add_event_handler(step, self.step)\n\n        return self\n\n    def reset(self, *args):\n        self.__init__(self._average)\n        return self\n\n    def pause(self, *args) -> None:\n        if self.running:\n            self.total += self._elapsed()\n            self.running = False\n\n    def resume(self, *args) -> None:\n        if not self.running:\n            self.running = True\n            self._t0 = perf_counter()\n\n    def value(self) -> float:\n        total = self.total\n        if self.running:\n            total += self._elapsed()\n\n        if self._average:\n            denominator = max(self.step_count, 1.0)\n        else:\n            denominator = 1.0\n\n        return total / denominator\n\n    def step(self, *args) -> None:\n        self.step_count += 1.0\n\n    def _elapsed(self) -> float:\n        return perf_counter() - self._t0\n'"
ignite/metrics/__init__.py,0,"b'from ignite.metrics.accumulation import Average, GeometricAverage, VariableAccumulation\nfrom ignite.metrics.accuracy import Accuracy\nfrom ignite.metrics.confusion_matrix import ConfusionMatrix, DiceCoefficient, IoU, mIoU\nfrom ignite.metrics.epoch_metric import EpochMetric\nfrom ignite.metrics.fbeta import Fbeta\nfrom ignite.metrics.frequency import Frequency\nfrom ignite.metrics.loss import Loss\nfrom ignite.metrics.mean_absolute_error import MeanAbsoluteError\nfrom ignite.metrics.mean_pairwise_distance import MeanPairwiseDistance\nfrom ignite.metrics.mean_squared_error import MeanSquaredError\nfrom ignite.metrics.metric import BatchFiltered, BatchWise, EpochWise, Metric, MetricUsage\nfrom ignite.metrics.metrics_lambda import MetricsLambda\nfrom ignite.metrics.precision import Precision\nfrom ignite.metrics.recall import Recall\nfrom ignite.metrics.root_mean_squared_error import RootMeanSquaredError\nfrom ignite.metrics.running_average import RunningAverage\nfrom ignite.metrics.top_k_categorical_accuracy import TopKCategoricalAccuracy\n\n__all__ = [\n    ""Metric"",\n    ""Accuracy"",\n    ""Loss"",\n    ""MetricsLambda"",\n    ""MeanAbsoluteError"",\n    ""MeanPairwiseDistance"",\n    ""MeanSquaredError"",\n    ""ConfusionMatrix"",\n    ""TopKCategoricalAccuracy"",\n    ""Average"",\n    ""DiceCoefficient"",\n    ""EpochMetric"",\n    ""Fbeta"",\n    ""GeometricAverage"",\n    ""IoU"",\n    ""mIoU"",\n    ""Precision"",\n    ""Recall"",\n    ""RootMeanSquaredError"",\n    ""RunningAverage"",\n    ""VariableAccumulation"",\n    ""Frequency"",\n]\n'"
ignite/metrics/accumulation.py,32,"b'import numbers\nfrom typing import Any, Callable, Optional, Union\n\nimport torch\n\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n__all__ = [""VariableAccumulation"", ""GeometricAverage"", ""Average""]\n\n\nclass VariableAccumulation(Metric):\n    """"""Single variable accumulator helper to compute (arithmetic, geometric, harmonic) average of a single variable.\n\n    - `update` must receive output of the form `x`.\n    - `x` can be a number or `torch.Tensor`.\n\n    Note:\n\n        The class stores input into two public variables: `accumulator` and `num_examples`.\n        Number of samples is updated following the rule:\n\n        - `+1` if input is a number\n        - `+1` if input is a 1D `torch.Tensor`\n        - `+batch_size` if input is a ND `torch.Tensor`. Batch size is the first dimension (`shape[0]`).\n\n    Args:\n        op (callable): a callable to update accumulator. Method\'s signature is `(accumulator, output)`.\n            For example, to compute arithmetic mean value, `op = lambda a, x: a + x`.\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n        device (str of torch.device, optional): optional device specification for internal storage.\n\n    """"""\n\n    _required_output_keys = None\n\n    def __init__(\n        self, op: Callable, output_transform: Callable = lambda x: x, device: Optional[Union[str, torch.device]] = None\n    ):\n        if not callable(op):\n            raise TypeError(""Argument op should be a callable, but given {}"".format(type(op)))\n        self.accumulator = None\n        self.num_examples = None\n        self._op = op\n\n        super(VariableAccumulation, self).__init__(output_transform=output_transform, device=device)\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        self.accumulator = torch.tensor(0.0, dtype=torch.float64, device=self._device)\n        self.num_examples = torch.tensor(0, dtype=torch.long, device=self._device)\n\n    def _check_output_type(self, output: Union[Any, torch.Tensor, numbers.Number]) -> None:\n        if not (isinstance(output, numbers.Number) or isinstance(output, torch.Tensor)):\n            raise TypeError(""Output should be a number or torch.Tensor, but given {}"".format(type(output)))\n\n    @reinit__is_reduced\n    def update(self, output: Union[Any, torch.Tensor, numbers.Number]) -> None:\n        self._check_output_type(output)\n\n        if self._device is not None:\n            # Put output to the metric\'s device\n            if isinstance(output, torch.Tensor) and (output.device != self._device):\n                output = output.to(self._device)\n\n        self.accumulator = self._op(self.accumulator, output)\n        if hasattr(output, ""shape""):\n            self.num_examples += output.shape[0] if len(output.shape) > 1 else 1\n        else:\n            self.num_examples += 1\n\n    @sync_all_reduce(""accumulator"", ""num_examples"")\n    def compute(self) -> list:\n        return [self.accumulator, self.num_examples]\n\n\nclass Average(VariableAccumulation):\n    """"""Helper class to compute arithmetic average of a single variable.\n\n    - `update` must receive output of the form `x`.\n    - `x` can be a number or `torch.Tensor`.\n\n    Note:\n\n        Number of samples is updated following the rule:\n\n        - `+1` if input is a number\n        - `+1` if input is a 1D `torch.Tensor`\n        - `+batch_size` if input is an ND `torch.Tensor`. Batch size is the first dimension (`shape[0]`).\n\n        For input `x` being an ND `torch.Tensor` with N > 1, the first dimension is seen as the number of samples and\n        is summed up and added to the accumulator: `accumulator += x.sum(dim=0)`\n\n    Examples:\n\n    .. code-block:: python\n\n        evaluator = ...\n\n        custom_var_mean = Average(output_transform=lambda output: output[\'custom_var\'])\n        custom_var_mean.attach(evaluator, \'mean_custom_var\')\n\n        state = evaluator.run(dataset)\n        # state.metrics[\'mean_custom_var\'] -> average of output[\'custom_var\']\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n        device (str of torch.device, optional): optional device specification for internal storage.\n\n    """"""\n\n    def __init__(self, output_transform: Callable = lambda x: x, device: Optional[Union[str, torch.device]] = None):\n        def _mean_op(a, x):\n            if isinstance(x, torch.Tensor) and x.ndim > 1:\n                x = x.sum(dim=0)\n            return a + x\n\n        super(Average, self).__init__(op=_mean_op, output_transform=output_transform, device=device)\n\n    @sync_all_reduce(""accumulator"", ""num_examples"")\n    def compute(self) -> Union[Any, torch.Tensor, numbers.Number]:\n        if self.num_examples < 1:\n            raise NotComputableError(\n                ""{} must have at least one example before"" "" it can be computed."".format(self.__class__.__name__)\n            )\n\n        return self.accumulator / self.num_examples\n\n\nclass GeometricAverage(VariableAccumulation):\n    """"""Helper class to compute geometric average of a single variable.\n\n    - `update` must receive output of the form `x`.\n    - `x` can be a positive number or a positive `torch.Tensor`, such that `torch.log(x)` is not `nan`.\n\n    Note:\n\n        Number of samples is updated following the rule:\n\n        - `+1` if input is a number\n        - `+1` if input is a 1D `torch.Tensor`\n        - `+batch_size` if input is a ND `torch.Tensor`. Batch size is the first dimension (`shape[0]`).\n\n        For input `x` being an ND `torch.Tensor` with N > 1, the first dimension is seen as the number of samples and\n        is aggregated and added to the accumulator: `accumulator *= prod(x, dim=0)`\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n        device (str of torch.device, optional): optional device specification for internal storage.\n\n    """"""\n\n    def __init__(self, output_transform: Callable = lambda x: x, device: Optional[Union[str, torch.device]] = None):\n        def _geom_op(a: torch.Tensor, x: Union[Any, numbers.Number, torch.Tensor]) -> torch.Tensor:\n            if not isinstance(x, torch.Tensor):\n                x = torch.tensor(x)\n            x = torch.log(x)\n            if x.ndim > 1:\n                x = x.sum(dim=0)\n            return a + x\n\n        super(GeometricAverage, self).__init__(op=_geom_op, output_transform=output_transform, device=device)\n\n    @sync_all_reduce(""accumulator"", ""num_examples"")\n    def compute(self) -> torch.Tensor:\n        if self.num_examples < 1:\n            raise NotComputableError(\n                ""{} must have at least one example before"" "" it can be computed."".format(self.__class__.__name__)\n            )\n\n        return torch.exp(self.accumulator / self.num_examples)\n'"
ignite/metrics/accuracy.py,18,"b'from typing import Callable, Optional, Sequence, Union\n\nimport torch\n\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n__all__ = [""Accuracy""]\n\n\nclass _BaseClassification(Metric):\n    def __init__(\n        self,\n        output_transform: Callable = lambda x: x,\n        is_multilabel: bool = False,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        self._is_multilabel = is_multilabel\n        self._type = None\n        self._num_classes = None\n        super(_BaseClassification, self).__init__(output_transform=output_transform, device=device)\n\n    def reset(self) -> None:\n        self._type = None\n        self._num_classes = None\n\n    def _check_shape(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n\n        if not (y.ndimension() == y_pred.ndimension() or y.ndimension() + 1 == y_pred.ndimension()):\n            raise ValueError(\n                ""y must have shape of (batch_size, ...) and y_pred must have ""\n                ""shape of (batch_size, num_categories, ...) or (batch_size, ...), ""\n                ""but given {} vs {}."".format(y.shape, y_pred.shape)\n            )\n\n        y_shape = y.shape\n        y_pred_shape = y_pred.shape\n\n        if y.ndimension() + 1 == y_pred.ndimension():\n            y_pred_shape = (y_pred_shape[0],) + y_pred_shape[2:]\n\n        if not (y_shape == y_pred_shape):\n            raise ValueError(""y and y_pred must have compatible shapes."")\n\n        if self._is_multilabel and not (y.shape == y_pred.shape and y.ndimension() > 1 and y.shape[1] != 1):\n            raise ValueError(""y and y_pred must have same shape of (batch_size, num_categories, ...)."")\n\n    def _check_binary_multilabel_cases(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n\n        if not torch.equal(y, y ** 2):\n            raise ValueError(""For binary cases, y must be comprised of 0\'s and 1\'s."")\n\n        if not torch.equal(y_pred, y_pred ** 2):\n            raise ValueError(""For binary cases, y_pred must be comprised of 0\'s and 1\'s."")\n\n    def _check_type(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n\n        if y.ndimension() + 1 == y_pred.ndimension():\n            num_classes = y_pred.shape[1]\n            if num_classes == 1:\n                update_type = ""binary""\n                self._check_binary_multilabel_cases((y_pred, y))\n            else:\n                update_type = ""multiclass""\n        elif y.ndimension() == y_pred.ndimension():\n            self._check_binary_multilabel_cases((y_pred, y))\n\n            if self._is_multilabel:\n                update_type = ""multilabel""\n                num_classes = y_pred.shape[1]\n            else:\n                update_type = ""binary""\n                num_classes = 1\n        else:\n            raise RuntimeError(\n                ""Invalid shapes of y (shape={}) and y_pred (shape={}), check documentation.""\n                "" for expected shapes of y and y_pred."".format(y.shape, y_pred.shape)\n            )\n        if self._type is None:\n            self._type = update_type\n            self._num_classes = num_classes\n        else:\n            if self._type != update_type:\n                raise RuntimeError(""Input data type has changed from {} to {}."".format(self._type, update_type))\n            if self._num_classes != num_classes:\n                raise ValueError(\n                    ""Input data number of classes has changed from {} to {}"".format(self._num_classes, num_classes)\n                )\n\n\nclass Accuracy(_BaseClassification):\n    """"""\n    Calculates the accuracy for binary, multiclass and multilabel data.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y_pred` must be in the following shape (batch_size, num_categories, ...) or (batch_size, ...).\n    - `y` must be in the following shape (batch_size, ...).\n    - `y` and `y_pred` must be in the following shape of (batch_size, num_categories, ...) for multilabel cases.\n\n    In binary and multilabel cases, the elements of `y` and `y_pred` should have 0 or 1 values. Thresholding of\n    predictions can be done as below:\n\n    .. code-block:: python\n\n        def thresholded_output_transform(output):\n            y_pred, y = output\n            y_pred = torch.round(y_pred)\n            return y_pred, y\n\n        binary_accuracy = Accuracy(thresholded_output_transform)\n\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n        is_multilabel (bool, optional): flag to use in multilabel case. By default, False.\n        device (str of torch.device, optional): unused argument.\n\n    """"""\n\n    def __init__(\n        self,\n        output_transform: Callable = lambda x: x,\n        is_multilabel: bool = False,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        self._num_correct = None\n        self._num_examples = None\n        super(Accuracy, self).__init__(output_transform=output_transform, is_multilabel=is_multilabel, device=device)\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        self._num_correct = 0\n        self._num_examples = 0\n        super(Accuracy, self).reset()\n\n    @reinit__is_reduced\n    def update(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n        self._check_shape((y_pred, y))\n        self._check_type((y_pred, y))\n\n        if self._type == ""binary"":\n            correct = torch.eq(y_pred.view(-1).to(y), y.view(-1))\n        elif self._type == ""multiclass"":\n            indices = torch.argmax(y_pred, dim=1)\n            correct = torch.eq(indices, y).view(-1)\n        elif self._type == ""multilabel"":\n            # if y, y_pred shape is (N, C, ...) -> (N x ..., C)\n            num_classes = y_pred.size(1)\n            last_dim = y_pred.ndimension()\n            y_pred = torch.transpose(y_pred, 1, last_dim - 1).reshape(-1, num_classes)\n            y = torch.transpose(y, 1, last_dim - 1).reshape(-1, num_classes)\n            correct = torch.all(y == y_pred.type_as(y), dim=-1)\n\n        self._num_correct += torch.sum(correct).item()\n        self._num_examples += correct.shape[0]\n\n    @sync_all_reduce(""_num_examples"", ""_num_correct"")\n    def compute(self) -> torch.Tensor:\n        if self._num_examples == 0:\n            raise NotComputableError(""Accuracy must have at least one example before it can be computed."")\n        return self._num_correct / self._num_examples\n'"
ignite/metrics/confusion_matrix.py,14,"b'import numbers\nfrom typing import Any, Callable, Optional, Sequence, Union\n\nimport torch\n\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\nfrom ignite.metrics.metrics_lambda import MetricsLambda\n\n__all__ = [""ConfusionMatrix"", ""mIoU"", ""IoU"", ""DiceCoefficient"", ""cmAccuracy"", ""cmPrecision"", ""cmRecall""]\n\n\nclass ConfusionMatrix(Metric):\n    """"""Calculates confusion matrix for multi-class data.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y_pred` must contain logits and has the following shape (batch_size, num_categories, ...)\n    - `y` should have the following shape (batch_size, ...) and contains ground-truth class indices\n        with or without the background class. During the computation, argmax of `y_pred` is taken to determine\n        predicted classes.\n\n    Args:\n        num_classes (int): number of classes. See notes for more details.\n        average (str, optional): confusion matrix values averaging schema: None, ""samples"", ""recall"", ""precision"".\n            Default is None. If `average=""samples""` then confusion matrix values are normalized by the number of seen\n            samples. If `average=""recall""` then confusion matrix values are normalized such that diagonal values\n            represent class recalls. If `average=""precision""` then confusion matrix values are normalized such that\n            diagonal values represent class precisions.\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n        device (str of torch.device, optional): optional device specification for internal storage.\n\n    Note:\n        In case of the targets `y` in `(batch_size, ...)` format, target indices between 0 and `num_classes` only\n        contribute to the confusion matrix and others are neglected. For example, if `num_classes=20` and target index\n        equal 255 is encountered, then it is filtered out.\n\n    """"""\n\n    def __init__(\n        self,\n        num_classes: int,\n        average: Optional[str] = None,\n        output_transform: Callable = lambda x: x,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        if average is not None and average not in (""samples"", ""recall"", ""precision""):\n            raise ValueError(""Argument average can None or one of [\'samples\', \'recall\', \'precision\']"")\n\n        self.num_classes = num_classes\n        self._num_examples = 0\n        self.average = average\n        self.confusion_matrix = None\n        super(ConfusionMatrix, self).__init__(output_transform=output_transform, device=device)\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        self.confusion_matrix = torch.zeros(self.num_classes, self.num_classes, dtype=torch.int64, device=self._device)\n        self._num_examples = 0\n\n    def _check_shape(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n\n        if y_pred.ndimension() < 2:\n            raise ValueError(\n                ""y_pred must have shape (batch_size, num_categories, ...), "" ""but given {}"".format(y_pred.shape)\n            )\n\n        if y_pred.shape[1] != self.num_classes:\n            raise ValueError(\n                ""y_pred does not have correct number of categories: {} vs {}"".format(y_pred.shape[1], self.num_classes)\n            )\n\n        if not (y.ndimension() + 1 == y_pred.ndimension()):\n            raise ValueError(\n                ""y_pred must have shape (batch_size, num_categories, ...) and y must have ""\n                ""shape of (batch_size, ...), ""\n                ""but given {} vs {}."".format(y.shape, y_pred.shape)\n            )\n\n        y_shape = y.shape\n        y_pred_shape = y_pred.shape\n\n        if y.ndimension() + 1 == y_pred.ndimension():\n            y_pred_shape = (y_pred_shape[0],) + y_pred_shape[2:]\n\n        if y_shape != y_pred_shape:\n            raise ValueError(""y and y_pred must have compatible shapes."")\n\n    @reinit__is_reduced\n    def update(self, output: Sequence[torch.Tensor]) -> None:\n        self._check_shape(output)\n        y_pred, y = output\n\n        self._num_examples += y_pred.shape[0]\n\n        # target is (batch_size, ...)\n        y_pred = torch.argmax(y_pred, dim=1).flatten()\n        y = y.flatten()\n\n        target_mask = (y >= 0) & (y < self.num_classes)\n        y = y[target_mask]\n        y_pred = y_pred[target_mask]\n\n        indices = self.num_classes * y + y_pred\n        m = torch.bincount(indices, minlength=self.num_classes ** 2).reshape(self.num_classes, self.num_classes)\n        self.confusion_matrix += m.to(self.confusion_matrix)\n\n    @sync_all_reduce(""confusion_matrix"", ""_num_examples"")\n    def compute(self) -> torch.Tensor:\n        if self._num_examples == 0:\n            raise NotComputableError(""Confusion matrix must have at least one example before it can be computed."")\n        if self.average:\n            self.confusion_matrix = self.confusion_matrix.float()\n            if self.average == ""samples"":\n                return self.confusion_matrix / self._num_examples\n            elif self.average == ""recall"":\n                return self.confusion_matrix / (self.confusion_matrix.sum(dim=1).unsqueeze(1) + 1e-15)\n            elif self.average == ""precision"":\n                return self.confusion_matrix / (self.confusion_matrix.sum(dim=0) + 1e-15)\n        return self.confusion_matrix\n\n\ndef IoU(cm: ConfusionMatrix, ignore_index: Optional[int] = None) -> MetricsLambda:\n    """"""Calculates Intersection over Union using :class:`~ignite.metrics.ConfusionMatrix` metric.\n\n    Args:\n        cm (ConfusionMatrix): instance of confusion matrix metric\n        ignore_index (int, optional): index to ignore, e.g. background index\n\n    Returns:\n        MetricsLambda\n\n    Examples:\n\n    .. code-block:: python\n\n        train_evaluator = ...\n\n        cm = ConfusionMatrix(num_classes=num_classes)\n        IoU(cm, ignore_index=0).attach(train_evaluator, \'IoU\')\n\n        state = train_evaluator.run(train_dataset)\n        # state.metrics[\'IoU\'] -> tensor of shape (num_classes - 1, )\n\n    """"""\n    if not isinstance(cm, ConfusionMatrix):\n        raise TypeError(""Argument cm should be instance of ConfusionMatrix, but given {}"".format(type(cm)))\n\n    if ignore_index is not None:\n        if not (isinstance(ignore_index, numbers.Integral) and 0 <= ignore_index < cm.num_classes):\n            raise ValueError(""ignore_index should be non-negative integer, but given {}"".format(ignore_index))\n\n    # Increase floating point precision and pass to CPU\n    cm = cm.type(torch.DoubleTensor)\n    iou = cm.diag() / (cm.sum(dim=1) + cm.sum(dim=0) - cm.diag() + 1e-15)\n    if ignore_index is not None:\n\n        def ignore_index_fn(iou_vector):\n            if ignore_index >= len(iou_vector):\n                raise ValueError(\n                    ""ignore_index {} is larger than the length of IoU vector {}"".format(ignore_index, len(iou_vector))\n                )\n            indices = list(range(len(iou_vector)))\n            indices.remove(ignore_index)\n            return iou_vector[indices]\n\n        return MetricsLambda(ignore_index_fn, iou)\n    else:\n        return iou\n\n\ndef mIoU(cm: ConfusionMatrix, ignore_index: Optional[int] = None) -> MetricsLambda:\n    """"""Calculates mean Intersection over Union using :class:`~ignite.metrics.ConfusionMatrix` metric.\n\n    Args:\n        cm (ConfusionMatrix): instance of confusion matrix metric\n        ignore_index (int, optional): index to ignore, e.g. background index\n\n    Returns:\n        MetricsLambda\n\n    Examples:\n\n    .. code-block:: python\n\n        train_evaluator = ...\n\n        cm = ConfusionMatrix(num_classes=num_classes)\n        mIoU(cm, ignore_index=0).attach(train_evaluator, \'mean IoU\')\n\n        state = train_evaluator.run(train_dataset)\n        # state.metrics[\'mean IoU\'] -> scalar\n\n\n    """"""\n    return IoU(cm=cm, ignore_index=ignore_index).mean()\n\n\ndef cmAccuracy(cm: ConfusionMatrix) -> MetricsLambda:\n    """"""Calculates accuracy using :class:`~ignite.metrics.ConfusionMatrix` metric.\n\n    Args:\n        cm (ConfusionMatrix): instance of confusion matrix metric\n\n    Returns:\n        MetricsLambda\n    """"""\n    # Increase floating point precision and pass to CPU\n    cm = cm.type(torch.DoubleTensor)\n    return cm.diag().sum() / (cm.sum() + 1e-15)\n\n\ndef cmPrecision(cm: ConfusionMatrix, average: bool = True) -> MetricsLambda:\n    """"""Calculates precision using :class:`~ignite.metrics.ConfusionMatrix` metric.\n\n    Args:\n        cm (ConfusionMatrix): instance of confusion matrix metric\n        average (bool, optional): if True metric value is averaged over all classes\n    Returns:\n        MetricsLambda\n    """"""\n\n    # Increase floating point precision and pass to CPU\n    cm = cm.type(torch.DoubleTensor)\n    precision = cm.diag() / (cm.sum(dim=0) + 1e-15)\n    if average:\n        return precision.mean()\n    return precision\n\n\ndef cmRecall(cm: ConfusionMatrix, average: bool = True) -> MetricsLambda:\n    """"""\n    Calculates recall using :class:`~ignite.metrics.ConfusionMatrix` metric.\n    Args:\n        cm (ConfusionMatrix): instance of confusion matrix metric\n        average (bool, optional): if True metric value is averaged over all classes\n    Returns:\n        MetricsLambda\n    """"""\n\n    # Increase floating point precision and pass to CPU\n    cm = cm.type(torch.DoubleTensor)\n    recall = cm.diag() / (cm.sum(dim=1) + 1e-15)\n    if average:\n        return recall.mean()\n    return recall\n\n\ndef DiceCoefficient(cm: ConfusionMatrix, ignore_index: Optional[int] = None) -> MetricsLambda:\n    """"""Calculates Dice Coefficient for a given :class:`~ignite.metrics.ConfusionMatrix` metric.\n\n    Args:\n        cm (ConfusionMatrix): instance of confusion matrix metric\n        ignore_index (int, optional): index to ignore, e.g. background index\n    """"""\n\n    if not isinstance(cm, ConfusionMatrix):\n        raise TypeError(""Argument cm should be instance of ConfusionMatrix, but given {}"".format(type(cm)))\n\n    if ignore_index is not None:\n        if not (isinstance(ignore_index, numbers.Integral) and 0 <= ignore_index < cm.num_classes):\n            raise ValueError(""ignore_index should be non-negative integer, but given {}"".format(ignore_index))\n\n    # Increase floating point precision and pass to CPU\n    cm = cm.type(torch.DoubleTensor)\n    dice = 2.0 * cm.diag() / (cm.sum(dim=1) + cm.sum(dim=0) + 1e-15)\n\n    if ignore_index is not None:\n\n        def ignore_index_fn(dice_vector: torch.Tensor) -> torch.Tensor:\n            if ignore_index >= len(dice_vector):\n                raise ValueError(\n                    ""ignore_index {} is larger than the length of Dice vector {}"".format(ignore_index, len(dice_vector))\n                )\n            indices = list(range(len(dice_vector)))\n            indices.remove(ignore_index)\n            return dice_vector[indices]\n\n        return MetricsLambda(ignore_index_fn, dice)\n    else:\n        return dice\n'"
ignite/metrics/epoch_metric.py,5,"b'import warnings\nfrom typing import Callable, Sequence\n\nimport torch\n\nfrom ignite.metrics.metric import Metric\n\n__all__ = [""EpochMetric""]\n\n\nclass EpochMetric(Metric):\n    """"""Class for metrics that should be computed on the entire output history of a model.\n    Model\'s output and targets are restricted to be of shape `(batch_size, n_classes)`. Output\n    datatype should be `float32`. Target datatype should be `long`.\n\n    .. warning::\n\n        Current implementation stores all input data (output and target) in as tensors before computing a metric.\n        This can potentially lead to a memory error if the input data is larger than available RAM.\n\n    .. warning::\n\n        Current implementation does not work with distributed computations. Results are not gather across all devices\n        and computed results are valid for a single device only.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n\n    If target shape is `(batch_size, n_classes)` and `n_classes > 1` than it should be binary: e.g. `[[0, 1, 0, 1], ]`.\n\n    Args:\n        compute_fn (callable): a callable with the signature (`torch.tensor`, `torch.tensor`) takes as the input\n            `predictions` and `targets` and returns a scalar.\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n\n    """"""\n\n    def __init__(self, compute_fn: Callable, output_transform: Callable = lambda x: x):\n\n        if not callable(compute_fn):\n            raise TypeError(""Argument compute_fn should be callable."")\n\n        super(EpochMetric, self).__init__(output_transform=output_transform, device=""cpu"")\n        self.compute_fn = compute_fn\n\n    def reset(self) -> None:\n        self._predictions = []\n        self._targets = []\n\n    def _check_shape(self, output):\n        y_pred, y = output\n        if y_pred.ndimension() not in (1, 2):\n            raise ValueError(""Predictions should be of shape (batch_size, n_classes) or (batch_size, )."")\n\n        if y.ndimension() not in (1, 2):\n            raise ValueError(""Targets should be of shape (batch_size, n_classes) or (batch_size, )."")\n\n        if y.ndimension() == 2:\n            if not torch.equal(y ** 2, y):\n                raise ValueError(""Targets should be binary (0 or 1)."")\n\n    def _check_type(self, output):\n        y_pred, y = output\n        if len(self._predictions) < 1:\n            return\n        dtype_preds = self._predictions[-1].type()\n        if dtype_preds != y_pred.type():\n            raise ValueError(\n                ""Incoherent types between input y_pred and stored predictions: ""\n                ""{} vs {}"".format(dtype_preds, y_pred.type())\n            )\n\n        dtype_targets = self._targets[-1].type()\n        if dtype_targets != y.type():\n            raise ValueError(\n                ""Incoherent types between input y and stored targets: "" ""{} vs {}"".format(dtype_targets, y.type())\n            )\n\n    def update(self, output: Sequence[torch.Tensor]) -> None:\n        self._check_shape(output)\n        y_pred, y = output\n        if y_pred.ndimension() == 2 and y_pred.shape[1] == 1:\n            y_pred = y_pred.squeeze(dim=-1)\n\n        if y.ndimension() == 2 and y.shape[1] == 1:\n            y = y.squeeze(dim=-1)\n\n        y_pred = y_pred.cpu().clone()\n        y = y.cpu().clone()\n\n        self._check_type((y_pred, y))\n        self._predictions.append(y_pred)\n        self._targets.append(y)\n\n        # Check once the signature and execution of compute_fn\n        if len(self._predictions) == 1:\n            try:\n                self.compute_fn(self._predictions[0], self._targets[0])\n            except Exception as e:\n                warnings.warn(""Probably, there can be a problem with `compute_fn`:\\n {}."".format(e), EpochMetricWarning)\n\n    def compute(self) -> None:\n        _prediction_tensor = torch.cat(self._predictions, dim=0)\n        _target_tensor = torch.cat(self._targets, dim=0)\n        return self.compute_fn(_prediction_tensor, _target_tensor)\n\n\nclass EpochMetricWarning(UserWarning):\n    pass\n'"
ignite/metrics/fbeta.py,2,"b'from typing import Callable, Optional, Union\n\nimport torch\n\nfrom ignite.metrics.metrics_lambda import MetricsLambda\nfrom ignite.metrics.precision import Precision\nfrom ignite.metrics.recall import Recall\n\n__all__ = [""Fbeta""]\n\n\ndef Fbeta(\n    beta: float,\n    average: bool = True,\n    precision: Optional[Precision] = None,\n    recall: Optional[Recall] = None,\n    output_transform: Optional[Callable] = None,\n    device: Optional[Union[str, torch.device]] = None,\n) -> MetricsLambda:\n    """"""Calculates F-beta score\n\n    Args:\n        beta (float): weight of precision in harmonic mean\n        average (bool, optional): if True, F-beta score is computed as the unweighted average (across all classes\n            in multiclass case), otherwise, returns a tensor with F-beta score for each class in multiclass case.\n        precision (Precision, optional): precision object metric with `average=False` to compute F-beta score\n        recall (Precision, optional): recall object metric with `average=False` to compute F-beta score\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. It is used only if precision or recall are not provided.\n        device (str of torch.device, optional): optional device specification for internal storage.\n\n    Returns:\n        MetricsLambda, F-beta metric\n    """"""\n    if not (beta > 0):\n        raise ValueError(""Beta should be a positive integer, but given {}"".format(beta))\n\n    if precision is not None and output_transform is not None:\n        raise ValueError(""If precision argument is provided, output_transform should be None"")\n\n    if recall is not None and output_transform is not None:\n        raise ValueError(""If recall argument is provided, output_transform should be None"")\n\n    if precision is None:\n        precision = Precision(\n            output_transform=(lambda x: x) if output_transform is None else output_transform,\n            average=False,\n            device=device,\n        )\n    elif precision._average:\n        raise ValueError(""Input precision metric should have average=False"")\n\n    if recall is None:\n        recall = Recall(\n            output_transform=(lambda x: x) if output_transform is None else output_transform,\n            average=False,\n            device=device,\n        )\n    elif recall._average:\n        raise ValueError(""Input recall metric should have average=False"")\n\n    fbeta = (1.0 + beta ** 2) * precision * recall / (beta ** 2 * precision + recall + 1e-15)\n\n    if average:\n        fbeta = fbeta.mean().item()\n\n    return fbeta\n'"
ignite/metrics/frequency.py,1,"b'import torch\n\nimport ignite.distributed as idist\nfrom ignite.engine import Events\nfrom ignite.handlers.timing import Timer\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n\nclass Frequency(Metric):\n    """"""Provides metrics for the number of examples processed per second.\n\n    Examples:\n\n        .. code-block:: python\n\n            # Compute number of tokens processed\n            wps_metric = Frequency(output_transform=lambda x: x[\'ntokens\'])\n            wps_metric.attach(trainer, name=\'wps\')\n            # Logging with TQDM\n            ProgressBar(persist=True).attach(trainer, metric_names=[\'wps\'])\n            # Progress bar will look like\n            # Epoch [2/10]: [12/24]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88      , wps=400 [00:17<1:23]\n\n\n        To compute examples processed per second every 50th iteration:\n\n        .. code-block:: python\n\n            # Compute number of tokens processed\n            wps_metric = Frequency(output_transform=lambda x: x[\'ntokens\'])\n            wps_metric.attach(trainer, name=\'wps\', event_name=Events.ITERATION_COMPLETED(every=50))\n            # Logging with TQDM\n            ProgressBar(persist=True).attach(trainer, metric_names=[\'wps\'])\n            # Progress bar will look like\n            # Epoch [2/10]: [50/100]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88      , wps=400 [00:17<00:35]\n    """"""\n\n    def __init__(self, output_transform=lambda x: x, device=None):\n        self._timer = None\n        self._acc = None\n        self._n = None\n        self._elapsed = None\n        super(Frequency, self).__init__(output_transform=output_transform, device=device)\n\n    @reinit__is_reduced\n    def reset(self):\n        self._timer = Timer()\n        self._acc = 0\n        self._n = 0\n        self._elapsed = 0.0\n        super(Frequency, self).reset()\n\n    @reinit__is_reduced\n    def update(self, output):\n        self._acc += output\n        self._n = self._acc\n        self._elapsed = torch.tensor(self._timer.value(), device=self._device)\n\n    @sync_all_reduce(""_n"", ""_elapsed"")\n    def compute(self):\n        time_divisor = 1.0\n\n        if idist.get_world_size() > 1:\n            time_divisor *= idist.get_world_size()\n\n        # Returns the average processed objects per second across all workers\n        return self._n / self._elapsed.item() * time_divisor\n\n    def completed(self, engine, name):\n        engine.state.metrics[name] = int(self.compute())\n\n    def attach(self, engine, name, event_name=Events.ITERATION_COMPLETED):\n        engine.add_event_handler(Events.EPOCH_STARTED, self.started)\n        engine.add_event_handler(Events.ITERATION_COMPLETED, self.iteration_completed)\n        engine.add_event_handler(event_name, self.completed, name)\n'"
ignite/metrics/loss.py,3,"b'from typing import Callable, Optional, Sequence, Union\n\nimport torch\n\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n__all__ = [""Loss""]\n\n\nclass Loss(Metric):\n    """"""\n    Calculates the average loss according to the passed loss_fn.\n\n    Args:\n        loss_fn (callable): a callable taking a prediction tensor, a target\n            tensor, optionally other arguments, and returns the average loss\n            over all observations in the batch.\n        output_transform (callable): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric.\n            This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n            The output is expected to be a tuple `(prediction, target)` or\n            (prediction, target, kwargs) where kwargs is a dictionary of extra\n            keywords arguments. If extra keywords arguments are provided they are passed to `loss_fn`.\n        batch_size (callable): a callable taking a target tensor that returns the\n            first dimension size (usually the batch size).\n        device (str of torch.device, optional): unused argument.\n\n    """"""\n\n    _required_output_keys = None\n\n    def __init__(\n        self,\n        loss_fn: Callable,\n        output_transform: Callable = lambda x: x,\n        batch_size: Callable = lambda x: len(x),\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        super(Loss, self).__init__(output_transform, device=device)\n        self._loss_fn = loss_fn\n        self._batch_size = batch_size\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        self._sum = 0\n        self._num_examples = 0\n\n    @reinit__is_reduced\n    def update(self, output: Sequence[Union[torch.Tensor, dict]]) -> None:\n        if len(output) == 2:\n            y_pred, y = output\n            kwargs = {}\n        else:\n            y_pred, y, kwargs = output\n        average_loss = self._loss_fn(y_pred, y, **kwargs)\n\n        if len(average_loss.shape) != 0:\n            raise ValueError(""loss_fn did not return the average loss."")\n\n        n = self._batch_size(y)\n        self._sum += average_loss.item() * n\n        self._num_examples += n\n\n    @sync_all_reduce(""_sum"", ""_num_examples"")\n    def compute(self) -> None:\n        if self._num_examples == 0:\n            raise NotComputableError(""Loss must have at least one example before it can be computed."")\n        return self._sum / self._num_examples\n'"
ignite/metrics/mean_absolute_error.py,4,"b'from typing import Sequence, Union\n\nimport torch\n\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n__all__ = [""MeanAbsoluteError""]\n\n\nclass MeanAbsoluteError(Metric):\n    """"""\n    Calculates the mean absolute error.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    """"""\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        self._sum_of_absolute_errors = 0.0\n        self._num_examples = 0\n\n    @reinit__is_reduced\n    def update(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n        absolute_errors = torch.abs(y_pred - y.view_as(y_pred))\n        self._sum_of_absolute_errors += torch.sum(absolute_errors).item()\n        self._num_examples += y.shape[0]\n\n    @sync_all_reduce(""_sum_of_absolute_errors"", ""_num_examples"")\n    def compute(self) -> Union[float, torch.Tensor]:\n        if self._num_examples == 0:\n            raise NotComputableError(""MeanAbsoluteError must have at least one example before it can be computed."")\n        return self._sum_of_absolute_errors / self._num_examples\n'"
ignite/metrics/mean_pairwise_distance.py,5,"b'from typing import Callable, Optional, Sequence, Union\n\nimport torch\nfrom torch.nn.functional import pairwise_distance\n\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n__all__ = [""MeanPairwiseDistance""]\n\n\nclass MeanPairwiseDistance(Metric):\n    """"""\n    Calculates the mean pairwise distance: average of pairwise distances computed on provided batches.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    """"""\n\n    def __init__(\n        self,\n        p: int = 2,\n        eps: float = 1e-6,\n        output_transform: Callable = lambda x: x,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        super(MeanPairwiseDistance, self).__init__(output_transform, device=device)\n        self._p = p\n        self._eps = eps\n\n    @reinit__is_reduced\n    def reset(self):\n        self._sum_of_distances = 0.0\n        self._num_examples = 0\n\n    @reinit__is_reduced\n    def update(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n        distances = pairwise_distance(y_pred, y, p=self._p, eps=self._eps)\n        self._sum_of_distances += torch.sum(distances).item()\n        self._num_examples += y.shape[0]\n\n    @sync_all_reduce(""_sum_of_distances"", ""_num_examples"")\n    def compute(self) -> Union[float, torch.Tensor]:\n        if self._num_examples == 0:\n            raise NotComputableError(""MeanAbsoluteError must have at least one example before it can be computed."")\n        return self._sum_of_distances / self._num_examples\n'"
ignite/metrics/mean_squared_error.py,4,"b'from typing import Sequence, Union\n\nimport torch\n\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n__all__ = [""MeanSquaredError""]\n\n\nclass MeanSquaredError(Metric):\n    """"""\n    Calculates the mean squared error.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    """"""\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        self._sum_of_squared_errors = 0.0\n        self._num_examples = 0\n\n    @reinit__is_reduced\n    def update(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n        squared_errors = torch.pow(y_pred - y.view_as(y_pred), 2)\n        self._sum_of_squared_errors += torch.sum(squared_errors).item()\n        self._num_examples += y.shape[0]\n\n    @sync_all_reduce(""_sum_of_squared_errors"", ""_num_examples"")\n    def compute(self) -> Union[float, torch.Tensor]:\n        if self._num_examples == 0:\n            raise NotComputableError(""MeanSquaredError must have at least one example before it can be computed."")\n        return self._sum_of_squared_errors / self._num_examples\n'"
ignite/metrics/metric.py,4,"b'import warnings\nfrom abc import ABCMeta, abstractmethod\nfrom collections.abc import Mapping\nfrom functools import wraps\nfrom typing import Any, Callable, Optional, Union\n\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events\n\n__all__ = [""Metric"", ""MetricUsage"", ""EpochWise"", ""BatchWise"", ""BatchFiltered""]\n\n\nclass MetricUsage:\n    """"""\n    Base class for all usages of metrics.\n\n    A usage of metric defines the events when a metric starts to compute, updates and completes.\n    Valid events are from :class:`~ignite.engine.Events`.\n\n    Args:\n        started: event when the metric starts to compute. This event will be associated to\n            :meth:`~ignite.metrics.Metric.started`.\n        completed: event when the metric completes. This event will be associated to\n            :meth:`~ignite.metrics.Metric.completed`.\n        iteration_completed: event when the metric updates. This event will be associated to\n            :meth:`~ignite.metrics.Metric.iteration_completed`.\n    """"""\n\n    def __init__(self, started, completed, iteration_completed):\n        self.__started = started\n        self.__completed = completed\n        self.__iteration_completed = iteration_completed\n\n    @property\n    def STARTED(self):\n        return self.__started\n\n    @property\n    def COMPLETED(self):\n        return self.__completed\n\n    @property\n    def ITERATION_COMPLETED(self):\n        return self.__iteration_completed\n\n\nclass EpochWise(MetricUsage):\n    """"""\n    Epoch-wise usage of Metrics. It\'s the default and most common usage of metrics.\n\n    Metric\'s methods are triggered on the following engine events:\n\n    - :meth:`~ignite.metrics.Metric.started` on every :attr:`~ignite.engine.Events.EPOCH_STARTED`.\n    - :meth:`~ignite.metrics.Metric.iteration_completed` on every :attr:`~ignite.engine.Events.ITERATION_COMPLETED`.\n    - :meth:`~ignite.metrics.Metric.completed` on every :attr:`~ignite.engine.Events.EPOCH_COMPLETED`.\n    """"""\n\n    usage_name = ""epoch_wise""\n\n    def __init__(self):\n        super(EpochWise, self).__init__(\n            started=Events.EPOCH_STARTED,\n            completed=Events.EPOCH_COMPLETED,\n            iteration_completed=Events.ITERATION_COMPLETED,\n        )\n\n\nclass BatchWise(MetricUsage):\n    """"""\n    Batch-wise usage of Metrics.\n\n    Metric\'s methods are triggered on the following engine events:\n\n    - :meth:`~ignite.metrics.Metric.started` on every :attr:`~ignite.engine.Events.ITERATION_STARTED`.\n    - :meth:`~ignite.metrics.Metric.iteration_completed` on every :attr:`~ignite.engine.Events.ITERATION_COMPLETED`.\n    - :meth:`~ignite.metrics.Metric.completed` on every :attr:`~ignite.engine.Events.ITERATION_COMPLETED`.\n    """"""\n\n    usage_name = ""batch_wise""\n\n    def __init__(self):\n        super(BatchWise, self).__init__(\n            started=Events.ITERATION_STARTED,\n            completed=Events.ITERATION_COMPLETED,\n            iteration_completed=Events.ITERATION_COMPLETED,\n        )\n\n\nclass BatchFiltered(MetricUsage):\n    """"""\n    Batch filtered usage of Metrics. This usage is similar to epoch-wise but update event is filtered.\n\n    Metric\'s methods are triggered on the following engine events:\n\n    - :meth:`~ignite.metrics.Metric.started` on every :attr:`~ignite.engine.Events.EPOCH_STARTED`.\n    - :meth:`~ignite.metrics.Metric.iteration_completed` on filtered :attr:`~ignite.engine.Events.ITERATION_COMPLETED`.\n    - :meth:`~ignite.metrics.Metric.completed` on every :attr:`~ignite.engine.Events.EPOCH_COMPLETED`.\n\n    Args:\n        args (sequence): arguments for the setup of :attr:`~ignite.engine.Events.ITERATION_COMPLETED` handled by\n            :meth:`~ignite.metrics.Metric.iteration_completed`.\n\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        super(BatchFiltered, self).__init__(\n            started=Events.EPOCH_STARTED,\n            completed=Events.EPOCH_COMPLETED,\n            iteration_completed=Events.ITERATION_COMPLETED(*args, **kwargs),\n        )\n\n\nclass Metric(metaclass=ABCMeta):\n    """"""\n    Base class for all Metrics.\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n            By default, metrics require the output as `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n        device (str of torch.device, optional): optional device specification for internal storage.\n\n    """"""\n\n    _required_output_keys = (""y_pred"", ""y"")\n\n    def __init__(\n        self, output_transform: Callable = lambda x: x, device: Optional[Union[str, torch.device]] = None,\n    ):\n        self._output_transform = output_transform\n\n        # Check device if distributed is initialized:\n        if idist.get_world_size() > 1:\n\n            # check if reset and update methods are decorated. Compute may not be decorated\n            if not (hasattr(self.reset, ""_decorated"") and hasattr(self.update, ""_decorated"")):\n                warnings.warn(\n                    ""{} class does not support distributed setting. Computed result is not collected ""\n                    ""across all computing devices"".format(self.__class__.__name__),\n                    RuntimeWarning,\n                )\n        self._device = device\n        self._is_reduced = False\n        self.reset()\n\n    @abstractmethod\n    def reset(self) -> None:\n        """"""\n        Resets the metric to it\'s initial state.\n\n        By default, this is called at the start of each epoch.\n        """"""\n        pass\n\n    @abstractmethod\n    def update(self, output) -> None:\n        """"""\n        Updates the metric\'s state using the passed batch output.\n\n        By default, this is called once for each batch.\n\n        Args:\n            output: the is the output from the engine\'s process function.\n        """"""\n        pass\n\n    @abstractmethod\n    def compute(self) -> Any:\n        """"""\n        Computes the metric based on it\'s accumulated state.\n\n        By default, this is called at the end of each epoch.\n\n        Returns:\n            Any: the actual quantity of interest. However, if a :class:`~collections.abc.Mapping` is returned,\n                 it will be (shallow) flattened into `engine.state.metrics` when\n                 :func:`~ignite.metrics.Metric.completed` is called.\n\n        Raises:\n            NotComputableError: raised when the metric cannot be computed.\n        """"""\n        pass\n\n    def started(self, engine: Engine) -> None:\n        """"""Helper method to start data gathering for metric\'s computation. It is automatically attached to the\n        `engine` with :meth:`~ignite.metrics.Metric.attach`.\n\n        Args:\n            engine (Engine): the engine to which the metric must be attached\n        """"""\n        self.reset()\n\n    @torch.no_grad()\n    def iteration_completed(self, engine: Engine) -> None:\n        """"""Helper method to update metric\'s computation. It is automatically attached to the\n        `engine` with :meth:`~ignite.metrics.Metric.attach`.\n\n        Args:\n            engine (Engine): the engine to which the metric must be attached\n        """"""\n\n        output = self._output_transform(engine.state.output)\n        if isinstance(output, Mapping):\n            if self._required_output_keys is None:\n                raise TypeError(\n                    ""Transformed engine output for {} metric should be a tuple/list, but given {}"".format(\n                        self.__class__.__name__, type(output)\n                    )\n                )\n            if not all([k in output for k in self._required_output_keys]):\n                raise ValueError(\n                    ""When transformed engine\'s output is a mapping, ""\n                    ""it should contain {} keys, but given {}"".format(self._required_output_keys, list(output.keys()))\n                )\n            output = tuple(output[k] for k in self._required_output_keys)\n        self.update(output)\n\n    def completed(self, engine: Engine, name: str) -> None:\n        """"""Helper method to compute metric\'s value and put into the engine. It is automatically attached to the\n        `engine` with :meth:`~ignite.metrics.Metric.attach`.\n\n        Args:\n            engine (Engine): the engine to which the metric must be attached\n        """"""\n        result = self.compute()\n        if isinstance(result, Mapping):\n            for key, value in result.items():\n                engine.state.metrics[key] = value\n        else:\n            if isinstance(result, torch.Tensor) and len(result.size()) == 0:\n                result = result.item()\n\n            engine.state.metrics[name] = result\n\n    def _check_usage(self, usage: Union[str, MetricUsage]) -> MetricUsage:\n        if isinstance(usage, str):\n            if usage == EpochWise.usage_name:\n                usage = EpochWise()\n            elif usage == BatchWise.usage_name:\n                usage = BatchWise()\n            else:\n                raise ValueError(\n                    ""usage should be \'EpochWise.usage_name\' or \'BatchWise.usage_name\', get {}"".format(usage)\n                )\n        if not isinstance(usage, MetricUsage):\n            raise TypeError(""Unhandled usage type {}"".format(type(usage)))\n        return usage\n\n    def attach(self, engine: Engine, name: str, usage: Union[str, MetricUsage] = EpochWise()) -> None:\n        """"""\n        Attaches current metric to provided engine. On the end of engine\'s run, `engine.state.metrics` dictionary will\n        contain computed metric\'s value under provided name.\n\n        Args:\n            engine (Engine): the engine to which the metric must be attached\n            name (str): the name of the metric to attach\n            usage (str or MetricUsage, optional): the usage of the metric. Valid string values should be\n                \'EpochWise.usage_name\' (default) or \'BatchWise.usage_name\'.\n\n        Example:\n\n        .. code-block:: python\n\n            metric = ...\n            metric.attach(engine, ""mymetric"")\n\n            assert ""mymetric"" in engine.run(data).metrics\n\n            assert metric.is_attached(engine)\n\n        Example with usage:\n\n        .. code-block:: python\n\n            metric = ...\n            metric.attach(engine, ""mymetric"", usage=BatchWise.usage_name)\n\n            assert ""mymetric"" in engine.run(data).metrics\n\n            assert metric.is_attached(engine, usage=BatchWise.usage_name)\n        """"""\n        usage = self._check_usage(usage)\n        if not engine.has_event_handler(self.started, usage.STARTED):\n            engine.add_event_handler(usage.STARTED, self.started)\n        if not engine.has_event_handler(self.iteration_completed, usage.ITERATION_COMPLETED):\n            engine.add_event_handler(usage.ITERATION_COMPLETED, self.iteration_completed)\n        engine.add_event_handler(usage.COMPLETED, self.completed, name)\n\n    def detach(self, engine: Engine, usage: Union[str, MetricUsage] = EpochWise()) -> None:\n        """"""\n        Detaches current metric from the engine and no metric\'s computation is done during the run.\n        This method in conjunction with :meth:`~ignite.metrics.Metric.attach` can be useful if several\n        metrics need to be computed with different periods. For example, one metric is computed every training epoch\n        and another metric (e.g. more expensive one) is done every n-th training epoch.\n\n        Args:\n            engine (Engine): the engine from which the metric must be detached\n            usage (str or MetricUsage, optional): the usage of the metric. Valid string values should be\n                \'epoch_wise\' (default) or \'batch_wise\'.\n\n        Example:\n\n        .. code-block:: python\n\n            metric = ...\n            engine = ...\n            metric.detach(engine)\n\n            assert ""mymetric"" not in engine.run(data).metrics\n\n            assert not metric.is_attached(engine)\n\n        Example with usage:\n\n        .. code-block:: python\n\n            metric = ...\n            engine = ...\n            metric.detach(engine, usage=""batch_wise"")\n\n            assert ""mymetric"" not in engine.run(data).metrics\n\n            assert not metric.is_attached(engine, usage=""batch_wise"")\n        """"""\n        usage = self._check_usage(usage)\n        if engine.has_event_handler(self.completed, usage.COMPLETED):\n            engine.remove_event_handler(self.completed, usage.COMPLETED)\n        if engine.has_event_handler(self.started, usage.STARTED):\n            engine.remove_event_handler(self.started, usage.STARTED)\n        if engine.has_event_handler(self.iteration_completed, usage.ITERATION_COMPLETED):\n            engine.remove_event_handler(self.iteration_completed, usage.ITERATION_COMPLETED)\n\n    def is_attached(self, engine: Engine, usage: Union[str, MetricUsage] = EpochWise()) -> bool:\n        """"""\n        Checks if current metric is attached to provided engine. If attached, metric\'s computed\n        value is written to `engine.state.metrics` dictionary.\n\n        Args:\n            engine (Engine): the engine checked from which the metric should be attached\n            usage (str or MetricUsage, optional): the usage of the metric. Valid string values should be\n                \'epoch_wise\' (default) or \'batch_wise\'.\n        """"""\n        usage = self._check_usage(usage)\n        return engine.has_event_handler(self.completed, usage.COMPLETED)\n\n    def __add__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x + y, self, other)\n\n    def __radd__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x + y, other, self)\n\n    def __sub__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x - y, self, other)\n\n    def __rsub__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x - y, other, self)\n\n    def __mul__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x * y, self, other)\n\n    def __rmul__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x * y, other, self)\n\n    def __pow__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x ** y, self, other)\n\n    def __rpow__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x ** y, other, self)\n\n    def __mod__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x % y, self, other)\n\n    def __div__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x.__div__(y), self, other)\n\n    def __rdiv__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x.__div__(y), other, self)\n\n    def __truediv__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x.__truediv__(y), self, other)\n\n    def __rtruediv__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x.__truediv__(y), other, self)\n\n    def __floordiv__(self, other):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x, y: x // y, self, other)\n\n    def __getattr__(self, attr: str) -> Callable:\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        def fn(x, *args, **kwargs):\n            return getattr(x, attr)(*args, **kwargs)\n\n        def wrapper(*args, **kwargs):\n            return MetricsLambda(fn, self, *args, **kwargs)\n\n        return wrapper\n\n    def __getitem__(self, index: Any):\n        from ignite.metrics.metrics_lambda import MetricsLambda\n\n        return MetricsLambda(lambda x: x[index], self)\n\n    def __getstate__(self):\n        return self.__dict__\n\n    def __setstate__(self, d):\n        self.__dict__.update(d)\n\n\ndef sync_all_reduce(*attrs) -> Callable:\n    def wrapper(func: Callable) -> Callable:\n        @wraps(func)\n        def another_wrapper(self: Metric, *args, **kwargs) -> Callable:\n            if not isinstance(self, Metric):\n                raise RuntimeError(\n                    ""Decorator sync_all_reduce should be used on ignite.metric.Metric class methods only""\n                )\n\n            if len(attrs) > 0 and not self._is_reduced:\n                for attr in attrs:\n                    t = getattr(self, attr, None)\n                    if t is not None and idist.get_world_size() > 1:\n                        t = idist.all_reduce(t)\n                        self._is_reduced = True\n                        setattr(self, attr, t)\n\n            return func(self, *args, **kwargs)\n\n        return another_wrapper\n\n    wrapper._decorated = True\n    return wrapper\n\n\ndef reinit__is_reduced(func: Callable) -> Callable:\n    @wraps(func)\n    def wrapper(self, *args, **kwargs):\n        func(self, *args, **kwargs)\n        self._is_reduced = False\n\n    wrapper._decorated = True\n    return wrapper\n'"
ignite/metrics/metrics_lambda.py,1,"b'import itertools\nfrom typing import Any, Callable, Union\n\nfrom ignite.engine import Engine, Events\nfrom ignite.metrics.metric import EpochWise, Metric, MetricUsage, reinit__is_reduced\n\n__all__ = [""MetricsLambda""]\n\n\nclass MetricsLambda(Metric):\n    """"""\n    Apply a function to other metrics to obtain a new metric.\n    The result of the new metric is defined to be the result\n    of applying the function to the result of argument metrics.\n\n    When update, this metric does not recursively update the metrics\n    it depends on. When reset, all its dependency metrics would be\n    resetted. When attach, all its dependency metrics would be attached\n    automatically (but partially, e.g `is_attached()` will return False).\n\n    Args:\n        f (callable): the function that defines the computation\n        args (sequence): Sequence of other metrics or something\n            else that will be fed to ``f`` as arguments.\n\n    Example:\n\n    .. code-block:: python\n\n        precision = Precision(average=False)\n        recall = Recall(average=False)\n\n        def Fbeta(r, p, beta):\n            return torch.mean((1 + beta ** 2) * p * r / (beta ** 2 * p + r + 1e-20)).item()\n\n        F1 = MetricsLambda(Fbeta, recall, precision, 1)\n        F2 = MetricsLambda(Fbeta, recall, precision, 2)\n        F3 = MetricsLambda(Fbeta, recall, precision, 3)\n        F4 = MetricsLambda(Fbeta, recall, precision, 4)\n\n    When check if the metric is attached, if one of its dependency\n    metrics is detached, the metric is considered detached too.\n\n    .. code-block:: python\n\n        engine = ...\n        precision = Precision(average=False)\n\n        aP = precision.mean()\n\n        aP.attach(engine, ""aP"")\n\n        assert aP.is_attached(engine)\n        # partially attached\n        assert not precision.is_attached(engine)\n\n        precision.detach(engine)\n\n        assert not aP.is_attached(engine)\n        # fully attached\n        assert not precision.is_attached(engine)\n\n    """"""\n\n    def __init__(self, f: Callable, *args, **kwargs):\n        self.function = f\n        self.args = args\n        self.kwargs = kwargs\n        self.engine = None\n        super(MetricsLambda, self).__init__(device=""cpu"")\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        for i in itertools.chain(self.args, self.kwargs.values()):\n            if isinstance(i, Metric):\n                i.reset()\n\n    @reinit__is_reduced\n    def update(self, output) -> None:\n        # NB: this method does not recursively update dependency metrics,\n        # which might cause duplicate update issue. To update this metric,\n        # users should manually update its dependencies.\n        pass\n\n    def compute(self) -> Any:\n        materialized = [i.compute() if isinstance(i, Metric) else i for i in self.args]\n        materialized_kwargs = {k: (v.compute() if isinstance(v, Metric) else v) for k, v in self.kwargs.items()}\n        return self.function(*materialized, **materialized_kwargs)\n\n    def _internal_attach(self, engine: Engine, usage: MetricUsage) -> None:\n        self.engine = engine\n        for index, metric in enumerate(itertools.chain(self.args, self.kwargs.values())):\n            if isinstance(metric, MetricsLambda):\n                metric._internal_attach(engine, usage)\n            elif isinstance(metric, Metric):\n                # NB : metrics is attached partially\n                # We must not use is_attached() but rather if these events exist\n                if not engine.has_event_handler(metric.started, usage.STARTED):\n                    engine.add_event_handler(usage.STARTED, metric.started)\n                if not engine.has_event_handler(metric.iteration_completed, usage.ITERATION_COMPLETED):\n                    engine.add_event_handler(usage.ITERATION_COMPLETED, metric.iteration_completed)\n\n    def attach(self, engine: Engine, name: str, usage: Union[str, MetricUsage] = EpochWise()) -> None:\n        usage = self._check_usage(usage)\n        # recursively attach all its dependencies (partially)\n        self._internal_attach(engine, usage)\n        # attach only handler on EPOCH_COMPLETED\n        engine.add_event_handler(usage.COMPLETED, self.completed, name)\n\n    def detach(self, engine: Engine, usage: Union[str, MetricUsage] = EpochWise()) -> None:\n        usage = self._check_usage(usage)\n        # remove from engine\n        super(MetricsLambda, self).detach(engine, usage)\n        self.engine = None\n\n    def is_attached(self, engine: Engine, usage: Union[str, MetricUsage] = EpochWise()) -> bool:\n        usage = self._check_usage(usage)\n        # check recursively the dependencies\n        return super(MetricsLambda, self).is_attached(engine, usage) and self._internal_is_attached(engine, usage)\n\n    def _internal_is_attached(self, engine: Engine, usage: MetricUsage) -> bool:\n        # if no engine, metrics is not attached\n        if engine is None:\n            return False\n        # check recursively if metrics are attached\n        is_detached = False\n        for metric in itertools.chain(self.args, self.kwargs.values()):\n            if isinstance(metric, MetricsLambda):\n                if not metric._internal_is_attached(engine, usage):\n                    is_detached = True\n            elif isinstance(metric, Metric):\n                if not engine.has_event_handler(metric.started, usage.STARTED):\n                    is_detached = True\n                if not engine.has_event_handler(metric.iteration_completed, usage.ITERATION_COMPLETED):\n                    is_detached = True\n        return not is_detached\n'"
ignite/metrics/precision.py,20,"b'import warnings\nfrom typing import Callable, Optional, Sequence, Union\n\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.accuracy import _BaseClassification\nfrom ignite.metrics.metric import reinit__is_reduced\nfrom ignite.utils import to_onehot\n\n__all__ = [""Precision""]\n\n\nclass _BasePrecisionRecall(_BaseClassification):\n    def __init__(\n        self,\n        output_transform: Callable = lambda x: x,\n        average: bool = False,\n        is_multilabel: bool = False,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        if idist.get_world_size() > 1:\n            if (not average) and is_multilabel:\n                warnings.warn(\n                    ""Precision/Recall metrics do not work in distributed setting when average=False ""\n                    ""and is_multilabel=True. Results are not reduced across computing devices. Computed result ""\n                    ""corresponds to the local rank\'s (single process) result."",\n                    RuntimeWarning,\n                )\n\n        self._average = average\n        self._true_positives = None\n        self._positives = None\n        self.eps = 1e-20\n        super(_BasePrecisionRecall, self).__init__(\n            output_transform=output_transform, is_multilabel=is_multilabel, device=device\n        )\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        dtype = torch.float64\n        self._true_positives = torch.tensor([], dtype=dtype) if (self._is_multilabel and not self._average) else 0\n        self._positives = torch.tensor([], dtype=dtype) if (self._is_multilabel and not self._average) else 0\n        super(_BasePrecisionRecall, self).reset()\n\n    def compute(self) -> torch.Tensor:\n        if not (isinstance(self._positives, torch.Tensor) or self._positives > 0):\n            raise NotComputableError(\n                ""{} must have at least one example before"" "" it can be computed."".format(self.__class__.__name__)\n            )\n\n        if not (self._type == ""multilabel"" and not self._average):\n            if not self._is_reduced:\n                self._true_positives = idist.all_reduce(self._true_positives)\n                self._positives = idist.all_reduce(self._positives)\n                self._is_reduced = True\n\n        result = self._true_positives / (self._positives + self.eps)\n\n        if self._average:\n            return result.mean().item()\n        else:\n            return result\n\n\nclass Precision(_BasePrecisionRecall):\n    """"""\n    Calculates precision for binary and multiclass data.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y_pred` must be in the following shape (batch_size, num_categories, ...) or (batch_size, ...).\n    - `y` must be in the following shape (batch_size, ...).\n\n    In binary and multilabel cases, the elements of `y` and `y_pred` should have 0 or 1 values. Thresholding of\n    predictions can be done as below:\n\n    .. code-block:: python\n\n        def thresholded_output_transform(output):\n            y_pred, y = output\n            y_pred = torch.round(y_pred)\n            return y_pred, y\n\n        precision = Precision(output_transform=thresholded_output_transform)\n\n    In multilabel cases, average parameter should be True. However, if user would like to compute F1 metric, for\n    example, average parameter should be False. This can be done as shown below:\n\n    .. code-block:: python\n\n        precision = Precision(average=False, is_multilabel=True)\n        recall = Recall(average=False, is_multilabel=True)\n        F1 = precision * recall * 2 / (precision + recall + 1e-20)\n        F1 = MetricsLambda(lambda t: torch.mean(t).item(), F1)\n\n    .. warning::\n\n        In multilabel cases, if average is False, current implementation stores all input data (output and target) in\n        as tensors before computing a metric. This can potentially lead to a memory error if the input data is larger\n        than available RAM.\n\n    .. warning::\n\n        In multilabel cases, if average is False, current implementation does not work with distributed computations.\n        Results are not reduced across the GPUs. Computed result corresponds to the local rank\'s (single GPU) result.\n\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n        average (bool, optional): if True, precision is computed as the unweighted average (across all classes\n            in multiclass case), otherwise, returns a tensor with the precision (for each class in multiclass case).\n        is_multilabel (bool, optional) flag to use in multilabel case. By default, value is False. If True, average\n            parameter should be True and the average is computed across samples, instead of classes.\n        device (str of torch.device, optional): unused argument.\n\n    """"""\n\n    def __init__(\n        self,\n        output_transform: Callable = lambda x: x,\n        average: bool = False,\n        is_multilabel: bool = False,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        super(Precision, self).__init__(\n            output_transform=output_transform, average=average, is_multilabel=is_multilabel, device=device\n        )\n\n    @reinit__is_reduced\n    def update(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n        self._check_shape(output)\n        self._check_type((y_pred, y))\n\n        if self._type == ""binary"":\n            y_pred = y_pred.view(-1)\n            y = y.view(-1)\n        elif self._type == ""multiclass"":\n            num_classes = y_pred.size(1)\n            if y.max() + 1 > num_classes:\n                raise ValueError(\n                    ""y_pred contains less classes than y. Number of predicted classes is {}""\n                    "" and element in y has invalid class = {}."".format(num_classes, y.max().item() + 1)\n                )\n            y = to_onehot(y.view(-1), num_classes=num_classes)\n            indices = torch.argmax(y_pred, dim=1).view(-1)\n            y_pred = to_onehot(indices, num_classes=num_classes)\n        elif self._type == ""multilabel"":\n            # if y, y_pred shape is (N, C, ...) -> (C, N x ...)\n            num_classes = y_pred.size(1)\n            y_pred = torch.transpose(y_pred, 1, 0).reshape(num_classes, -1)\n            y = torch.transpose(y, 1, 0).reshape(num_classes, -1)\n\n        y = y.to(y_pred)\n        correct = y * y_pred\n        all_positives = y_pred.sum(dim=0).type(torch.DoubleTensor)  # Convert from int cuda/cpu to double cpu\n\n        if correct.sum() == 0:\n            true_positives = torch.zeros_like(all_positives)\n        else:\n            true_positives = correct.sum(dim=0)\n        # Convert from int cuda/cpu to double cpu\n        # We need double precision for the division true_positives / all_positives\n        true_positives = true_positives.type(torch.DoubleTensor)\n\n        if self._type == ""multilabel"":\n            if not self._average:\n                self._true_positives = torch.cat([self._true_positives, true_positives], dim=0)\n                self._positives = torch.cat([self._positives, all_positives], dim=0)\n            else:\n                self._true_positives += torch.sum(true_positives / (all_positives + self.eps))\n                self._positives += len(all_positives)\n        else:\n            self._true_positives += true_positives\n            self._positives += all_positives\n'"
ignite/metrics/recall.py,14,"b'from typing import Callable, Optional, Sequence, Union\n\nimport torch\n\nfrom ignite.metrics.metric import reinit__is_reduced\nfrom ignite.metrics.precision import _BasePrecisionRecall\nfrom ignite.utils import to_onehot\n\n__all__ = [""Recall""]\n\n\nclass Recall(_BasePrecisionRecall):\n    """"""\n    Calculates recall for binary and multiclass data.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y_pred` must be in the following shape (batch_size, num_categories, ...) or (batch_size, ...).\n    - `y` must be in the following shape (batch_size, ...).\n\n    In binary and multilabel cases, the elements of `y` and `y_pred` should have 0 or 1 values. Thresholding of\n    predictions can be done as below:\n\n    .. code-block:: python\n\n        def thresholded_output_transform(output):\n            y_pred, y = output\n            y_pred = torch.round(y_pred)\n            return y_pred, y\n\n        recall = Recall(output_transform=thresholded_output_transform)\n\n    In multilabel cases, average parameter should be True. However, if user would like to compute F1 metric, for\n    example, average parameter should be False. This can be done as shown below:\n\n    .. code-block:: python\n\n        precision = Precision(average=False, is_multilabel=True)\n        recall = Recall(average=False, is_multilabel=True)\n        F1 = precision * recall * 2 / (precision + recall + 1e-20)\n        F1 = MetricsLambda(lambda t: torch.mean(t).item(), F1)\n\n    .. warning::\n\n        In multilabel cases, if average is False, current implementation stores all input data (output and target) in\n        as tensors before computing a metric. This can potentially lead to a memory error if the input data is larger\n        than available RAM.\n\n    .. warning::\n\n        In multilabel cases, if average is False, current implementation does not work with distributed computations.\n        Results are not reduced across the GPUs. Computed result corresponds to the local rank\'s (single GPU) result.\n\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n        average (bool, optional): if True, precision is computed as the unweighted average (across all classes\n            in multiclass case), otherwise, returns a tensor with the precision (for each class in multiclass case).\n        is_multilabel (bool, optional) flag to use in multilabel case. By default, value is False. If True, average\n            parameter should be True and the average is computed across samples, instead of classes.\n        device (str of torch.device, optional): unused argument.\n\n    """"""\n\n    def __init__(\n        self,\n        output_transform: Callable = lambda x: x,\n        average: bool = False,\n        is_multilabel: bool = False,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        super(Recall, self).__init__(\n            output_transform=output_transform, average=average, is_multilabel=is_multilabel, device=device\n        )\n\n    @reinit__is_reduced\n    def update(self, output: Sequence[torch.Tensor]) -> None:\n        y_pred, y = output\n        self._check_shape(output)\n        self._check_type((y_pred, y))\n\n        if self._type == ""binary"":\n            y_pred = y_pred.view(-1)\n            y = y.view(-1)\n        elif self._type == ""multiclass"":\n            num_classes = y_pred.size(1)\n            if y.max() + 1 > num_classes:\n                raise ValueError(\n                    ""y_pred contains less classes than y. Number of predicted classes is {}""\n                    "" and element in y has invalid class = {}."".format(num_classes, y.max().item() + 1)\n                )\n            y = to_onehot(y.view(-1), num_classes=num_classes)\n            indices = torch.argmax(y_pred, dim=1).view(-1)\n            y_pred = to_onehot(indices, num_classes=num_classes)\n        elif self._type == ""multilabel"":\n            # if y, y_pred shape is (N, C, ...) -> (C, N x ...)\n            num_classes = y_pred.size(1)\n            y_pred = torch.transpose(y_pred, 1, 0).reshape(num_classes, -1)\n            y = torch.transpose(y, 1, 0).reshape(num_classes, -1)\n\n        y = y.type_as(y_pred)\n        correct = y * y_pred\n        actual_positives = y.sum(dim=0).type(torch.DoubleTensor)  # Convert from int cuda/cpu to double cpu\n\n        if correct.sum() == 0:\n            true_positives = torch.zeros_like(actual_positives)\n        else:\n            true_positives = correct.sum(dim=0)\n\n        # Convert from int cuda/cpu to double cpu\n        # We need double precision for the division true_positives / actual_positives\n        true_positives = true_positives.type(torch.DoubleTensor)\n\n        if self._type == ""multilabel"":\n            if not self._average:\n                self._true_positives = torch.cat([self._true_positives, true_positives], dim=0)\n                self._positives = torch.cat([self._positives, actual_positives], dim=0)\n            else:\n                self._true_positives += torch.sum(true_positives / (actual_positives + self.eps))\n                self._positives += len(actual_positives)\n        else:\n            self._true_positives += true_positives\n            self._positives += actual_positives\n'"
ignite/metrics/root_mean_squared_error.py,1,"b'import math\nfrom typing import Union\n\nimport torch\n\nfrom ignite.metrics.mean_squared_error import MeanSquaredError\n\n__all__ = [""RootMeanSquaredError""]\n\n\nclass RootMeanSquaredError(MeanSquaredError):\n    """"""\n    Calculates the root mean squared error.\n\n    - `update` must receive output of the form (y_pred, y) or `{\'y_pred\': y_pred, \'y\': y}`.\n    """"""\n\n    def compute(self) -> Union[torch.Tensor, float]:\n        mse = super(RootMeanSquaredError, self).compute()\n        return math.sqrt(mse)\n'"
ignite/metrics/running_average.py,7,"b'from typing import Callable, Optional, Sequence, Union\n\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n__all__ = [""RunningAverage""]\n\n\nclass RunningAverage(Metric):\n    """"""Compute running average of a metric or the output of process function.\n\n    Args:\n        src (Metric or None): input source: an instance of :class:`~ignite.metrics.Metric` or None. The latter\n            corresponds to `engine.state.output` which holds the output of process function.\n        alpha (float, optional): running average decay factor, default 0.98\n        output_transform (callable, optional): a function to use to transform the output if `src` is None and\n            corresponds the output of process function. Otherwise it should be None.\n        epoch_bound (boolean, optional): whether the running average should be reset after each epoch (defaults\n            to True).\n        device (str of torch.device, optional): unused argument.\n\n    Examples:\n\n    .. code-block:: python\n\n        alpha = 0.98\n        acc_metric = RunningAverage(Accuracy(output_transform=lambda x: [x[1], x[2]]), alpha=alpha)\n        acc_metric.attach(trainer, \'running_avg_accuracy\')\n\n        avg_output = RunningAverage(output_transform=lambda x: x[0], alpha=alpha)\n        avg_output.attach(trainer, \'running_avg_loss\')\n\n        @trainer.on(Events.ITERATION_COMPLETED)\n        def log_running_avg_metrics(engine):\n            print(""running avg accuracy:"", engine.state.metrics[\'running_avg_accuracy\'])\n            print(""running avg loss:"", engine.state.metrics[\'running_avg_loss\'])\n\n    """"""\n\n    _required_output_keys = None\n\n    def __init__(\n        self,\n        src: Optional[Metric] = None,\n        alpha: float = 0.98,\n        output_transform: Optional[Callable] = None,\n        epoch_bound: bool = True,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        if not (isinstance(src, Metric) or src is None):\n            raise TypeError(""Argument src should be a Metric or None."")\n        if not (0.0 < alpha <= 1.0):\n            raise ValueError(""Argument alpha should be a float between 0.0 and 1.0."")\n\n        if isinstance(src, Metric):\n            if output_transform is not None:\n                raise ValueError(""Argument output_transform should be None if src is a Metric."")\n            if device is not None:\n                raise ValueError(""Argument device should be None if src is a Metric."")\n            self.src = src\n            self._get_src_value = self._get_metric_value\n            self.iteration_completed = self._metric_iteration_completed\n        else:\n            if output_transform is None:\n                raise ValueError(\n                    ""Argument output_transform should not be None if src corresponds ""\n                    ""to the output of process function.""\n                )\n            self._get_src_value = self._get_output_value\n            self.update = self._output_update\n\n        self.alpha = alpha\n        self.epoch_bound = epoch_bound\n        super(RunningAverage, self).__init__(output_transform=output_transform, device=device)\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        self._value = None\n\n    @reinit__is_reduced\n    def update(self, output: Sequence) -> None:\n        # Implement abstract method\n        pass\n\n    def compute(self) -> Union[torch.Tensor, float]:\n        if self._value is None:\n            self._value = self._get_src_value()\n        else:\n            self._value = self._value * self.alpha + (1.0 - self.alpha) * self._get_src_value()\n\n        return self._value\n\n    def attach(self, engine: Engine, name: str):\n        if self.epoch_bound:\n            # restart average every epoch\n            engine.add_event_handler(Events.EPOCH_STARTED, self.started)\n        # compute metric\n        engine.add_event_handler(Events.ITERATION_COMPLETED, self.iteration_completed)\n        # apply running average\n        engine.add_event_handler(Events.ITERATION_COMPLETED, self.completed, name)\n\n    def _get_metric_value(self) -> Union[torch.Tensor, float]:\n        return self.src.compute()\n\n    @sync_all_reduce(""src"")\n    def _get_output_value(self) -> Union[torch.Tensor, float]:\n        # we need to compute average instead of sum produced by @sync_all_reduce(""src"")\n        output = self.src / idist.get_world_size()\n        return output\n\n    def _metric_iteration_completed(self, engine: Engine) -> None:\n        self.src.started(engine)\n        self.src.iteration_completed(engine)\n\n    @reinit__is_reduced\n    def _output_update(self, output: Union[torch.Tensor, float]) -> None:\n        if isinstance(output, torch.Tensor):\n            output = output.detach().clone()\n        self.src = output\n'"
ignite/metrics/top_k_categorical_accuracy.py,5,"b'from typing import Callable, Optional, Sequence, Union\n\nimport torch\n\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.metric import Metric, reinit__is_reduced, sync_all_reduce\n\n__all__ = [""TopKCategoricalAccuracy""]\n\n\nclass TopKCategoricalAccuracy(Metric):\n    """"""\n    Calculates the top-k categorical accuracy.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    """"""\n\n    def __init__(\n        self, k=5, output_transform: Callable = lambda x: x, device: Optional[Union[str, torch.device]] = None\n    ):\n        super(TopKCategoricalAccuracy, self).__init__(output_transform, device=device)\n        self._k = k\n\n    @reinit__is_reduced\n    def reset(self) -> None:\n        self._num_correct = 0\n        self._num_examples = 0\n\n    @reinit__is_reduced\n    def update(self, output: Sequence) -> None:\n        y_pred, y = output\n        sorted_indices = torch.topk(y_pred, self._k, dim=1)[1]\n        expanded_y = y.view(-1, 1).expand(-1, self._k)\n        correct = torch.sum(torch.eq(sorted_indices, expanded_y), dim=1)\n        self._num_correct += torch.sum(correct).item()\n        self._num_examples += correct.shape[0]\n\n    @sync_all_reduce(""_num_correct"", ""_num_examples"")\n    def compute(self) -> Union[float, torch.Tensor]:\n        if self._num_examples == 0:\n            raise NotComputableError(\n                ""TopKCategoricalAccuracy must have at"" ""least one example before it can be computed.""\n            )\n        return self._num_correct / self._num_examples\n'"
tests/ignite/__init__.py,0,b'# Needed to collect coverage data\n'
tests/ignite/conftest.py,3,"b'import shutil\nimport tempfile\n\nimport pytest\nimport torch\nimport torch.distributed as dist\n\n\n@pytest.fixture()\ndef dirname():\n    path = tempfile.mkdtemp()\n    yield path\n    shutil.rmtree(path)\n\n\n@pytest.fixture()\ndef get_rank_zero_dirname(dirname):\n    def func():\n        import ignite.distributed as idist\n\n        zero_rank_dirname = idist.all_gather(dirname)[0]\n        return zero_rank_dirname\n\n    yield func\n\n\n@pytest.fixture()\ndef local_rank(worker_id):\n    """""" use a different account in each xdist worker """"""\n    import os\n\n    if ""gw"" in worker_id:\n        lrank = int(worker_id.replace(""gw"", """"))\n    elif ""master"" == worker_id:\n        lrank = 0\n    else:\n        raise RuntimeError(""Can not get rank from worker_id={}"".format(worker_id))\n\n    os.environ[""LOCAL_RANK""] = ""{}"".format(lrank)\n\n    yield lrank\n\n    del os.environ[""LOCAL_RANK""]\n\n\n@pytest.fixture()\ndef world_size():\n    import os\n\n    remove_env_var = False\n\n    if ""WORLD_SIZE"" not in os.environ:\n        os.environ[""WORLD_SIZE""] = ""1""\n        remove_env_var = True\n\n    yield int(os.environ[""WORLD_SIZE""])\n\n    if remove_env_var:\n        del os.environ[""WORLD_SIZE""]\n\n\n@pytest.fixture()\ndef clean_env():\n    import os\n\n    for k in [""RANK"", ""LOCAL_RANK"", ""WORLD_SIZE""]:\n        if k in os.environ:\n            del os.environ[k]\n\n\ndef _create_dist_context(dist_info, lrank):\n\n    dist.init_process_group(**dist_info)\n    dist.barrier()\n    if dist_info[""backend""] == ""nccl"":\n        torch.cuda.set_device(lrank)\n\n    return {""local_rank"": lrank}\n\n\ndef _destroy_dist_context():\n\n    dist.barrier()\n    dist.destroy_process_group()\n\n    from ignite.distributed.utils import _SerialModel, _set_model\n\n    # We need to set synced model to initial state\n    _set_model(_SerialModel())\n\n\n@pytest.fixture()\ndef distributed_context_single_node_nccl(local_rank, world_size):\n\n    dist_info = {\n        ""backend"": ""nccl"",\n        ""world_size"": world_size,\n        ""rank"": local_rank,\n        ""init_method"": ""tcp://localhost:2223"",\n    }\n    yield _create_dist_context(dist_info, local_rank)\n    _destroy_dist_context()\n\n\n@pytest.fixture()\ndef distributed_context_single_node_gloo(local_rank, world_size):\n\n    from datetime import timedelta\n\n    dist_info = {\n        ""backend"": ""gloo"",\n        ""world_size"": world_size,\n        ""rank"": local_rank,\n        ""init_method"": ""tcp://localhost:2222"",\n        ""timeout"": timedelta(seconds=60),\n    }\n    yield _create_dist_context(dist_info, local_rank)\n    _destroy_dist_context()\n\n\n@pytest.fixture()\ndef multi_node_conf(local_rank):\n    import os\n\n    assert ""node_id"" in os.environ\n    assert ""nnodes"" in os.environ\n    assert ""nproc_per_node"" in os.environ\n\n    node_id = int(os.environ[""node_id""])\n    nnodes = int(os.environ[""nnodes""])\n    nproc_per_node = int(os.environ[""nproc_per_node""])\n    out = {\n        ""world_size"": nnodes * nproc_per_node,\n        ""rank"": local_rank + node_id * nproc_per_node,\n        ""local_rank"": local_rank,\n    }\n    return out\n\n\ndef _create_mnodes_dist_context(dist_info, mnodes_conf):\n\n    dist.init_process_group(**dist_info)\n    dist.barrier()\n    if dist_info[""backend""] == ""nccl"":\n        torch.cuda.device(mnodes_conf[""local_rank""])\n    return mnodes_conf\n\n\ndef _destroy_mnodes_dist_context():\n    dist.barrier()\n    dist.destroy_process_group()\n\n    from ignite.distributed.utils import _SerialModel, _set_model\n\n    # We need to set synced model to initial state\n    _set_model(_SerialModel())\n\n\n@pytest.fixture()\ndef distributed_context_multi_node_gloo(multi_node_conf):\n\n    import os\n\n    assert ""MASTER_ADDR"" in os.environ\n    assert ""MASTER_PORT"" in os.environ\n\n    dist_info = {\n        ""backend"": ""gloo"",\n        ""init_method"": ""env://"",\n        ""world_size"": multi_node_conf[""world_size""],\n        ""rank"": multi_node_conf[""rank""],\n    }\n    yield _create_mnodes_dist_context(dist_info, multi_node_conf)\n    _destroy_mnodes_dist_context()\n\n\n@pytest.fixture()\ndef distributed_context_multi_node_nccl(multi_node_conf):\n\n    import os\n\n    assert ""MASTER_ADDR"" in os.environ\n    assert ""MASTER_PORT"" in os.environ\n\n    dist_info = {\n        ""backend"": ""nccl"",\n        ""init_method"": ""env://"",\n        ""world_size"": multi_node_conf[""world_size""],\n        ""rank"": multi_node_conf[""rank""],\n    }\n    yield _create_mnodes_dist_context(dist_info, multi_node_conf)\n    _destroy_mnodes_dist_context()\n\n\ndef _xla_template_worker_task(index, fn, args):\n    import torch_xla.core.xla_model as xm\n\n    xm.rendezvous(""init"")\n    fn(index, *args)\n\n\ndef _xla_execute(fn, args, nprocs):\n    import os\n    import torch_xla.distributed.xla_multiprocessing as xmp\n\n    spawn_kwargs = {}\n    if ""COLAB_TPU_ADDR"" in os.environ:\n        spawn_kwargs[""start_method""] = ""fork""\n\n    try:\n        xmp.spawn(_xla_template_worker_task, args=(fn, args), nprocs=nprocs, **spawn_kwargs)\n    except SystemExit as ex_:\n        assert ex_.code == 0, ""Didn\'t successfully exit in XLA test""\n\n\n@pytest.fixture()\ndef xmp_executor():\n    yield _xla_execute\n'"
tests/ignite/test_utils.py,26,"b'import logging\nimport os\nfrom collections import namedtuple\n\nimport pytest\nimport torch\n\nfrom ignite.engine import Engine, Events\nfrom ignite.utils import convert_tensor, setup_logger, to_onehot\n\n\ndef test_convert_tensor():\n    x = torch.tensor([0.0])\n    tensor = convert_tensor(x)\n    assert torch.is_tensor(tensor)\n\n    x = torch.tensor([0.0])\n    tensor = convert_tensor(x, device=""cpu"", non_blocking=True)\n    assert torch.is_tensor(tensor)\n\n    x = torch.tensor([0.0])\n    tensor = convert_tensor(x, device=""cpu"", non_blocking=False)\n    assert torch.is_tensor(tensor)\n\n    x = [torch.tensor([0.0]), torch.tensor([0.0])]\n    list_ = convert_tensor(x)\n    assert isinstance(list_, list)\n    assert torch.is_tensor(list_[0])\n    assert torch.is_tensor(list_[1])\n\n    x = (torch.tensor([0.0]), torch.tensor([0.0]))\n    tuple_ = convert_tensor(x)\n    assert isinstance(tuple_, tuple)\n    assert torch.is_tensor(tuple_[0])\n    assert torch.is_tensor(tuple_[1])\n\n    Point = namedtuple(""Point"", [""x"", ""y""])\n    x = Point(torch.tensor([0.0]), torch.tensor([0.0]))\n    tuple_ = convert_tensor(x)\n    assert isinstance(tuple_, Point)\n    assert torch.is_tensor(tuple_[0])\n    assert torch.is_tensor(tuple_[1])\n\n    x = {""a"": torch.tensor([0.0]), ""b"": torch.tensor([0.0])}\n    dict_ = convert_tensor(x)\n    assert isinstance(dict_, dict)\n    assert torch.is_tensor(dict_[""a""])\n    assert torch.is_tensor(dict_[""b""])\n\n    assert convert_tensor(""a"") == ""a""\n\n    with pytest.raises(TypeError):\n        convert_tensor(12345)\n\n\ndef test_to_onehot():\n    indices = torch.tensor([0, 1, 2, 3], dtype=torch.long)\n    actual = to_onehot(indices, 4)\n    expected = torch.eye(4, dtype=torch.uint8)\n    assert actual.equal(expected)\n\n    y = torch.randint(0, 21, size=(1000,))\n    y_ohe = to_onehot(y, num_classes=21)\n    y2 = torch.argmax(y_ohe, dim=1)\n    assert y.equal(y2)\n\n    y = torch.randint(0, 21, size=(4, 250, 255))\n    y_ohe = to_onehot(y, num_classes=21)\n    y2 = torch.argmax(y_ohe, dim=1)\n    assert y.equal(y2)\n\n    y = torch.randint(0, 21, size=(4, 150, 155, 4, 6))\n    y_ohe = to_onehot(y, num_classes=21)\n    y2 = torch.argmax(y_ohe, dim=1)\n    assert y.equal(y2)\n\n\ndef test_dist_setup_logger():\n\n    logger = setup_logger(""trainer"", level=logging.CRITICAL, distributed_rank=1)\n    assert logger.level != logging.CRITICAL\n\n\ndef test_setup_logger(capsys, dirname):\n\n    trainer = Engine(lambda e, b: None)\n    evaluator = Engine(lambda e, b: None)\n\n    fp = os.path.join(dirname, ""log"")\n    assert len(trainer.logger.handlers) == 0\n    trainer.logger.addHandler(logging.NullHandler())\n    trainer.logger.addHandler(logging.NullHandler())\n    trainer.logger.addHandler(logging.NullHandler())\n\n    trainer.logger = setup_logger(""trainer"", filepath=fp)\n    evaluator.logger = setup_logger(""evaluator"", filepath=fp)\n\n    assert len(trainer.logger.handlers) == 2\n    assert len(evaluator.logger.handlers) == 2\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def _(_):\n        evaluator.run([0, 1, 2])\n\n    trainer.run([0, 1, 2, 3, 4, 5], max_epochs=5)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\n"")\n\n    with open(fp, ""r"") as h:\n        data = h.readlines()\n\n    for source in [err, data]:\n        assert ""trainer INFO: Engine run starting with max_epochs=5."" in source[0]\n        assert ""evaluator INFO: Engine run starting with max_epochs=1."" in source[1]\n\n    # Needed by windows to release FileHandler in the loggers\n    logging.shutdown()\n'"
examples/contrib/cifar10/fastresnet.py,3,"b'# Network from https://github.com/davidcpage/cifar10-fast\n# Adapted to python < 3.6\n\nimport torch.nn as nn\n\n\ndef fastresnet():\n    return FastResnet()\n\n\ndef batch_norm(num_channels, bn_bias_init=None, bn_bias_freeze=False, bn_weight_init=None, bn_weight_freeze=False):\n    m = nn.BatchNorm2d(num_channels)\n    if bn_bias_init is not None:\n        m.bias.data.fill_(bn_bias_init)\n    if bn_bias_freeze:\n        m.bias.requires_grad = False\n    if bn_weight_init is not None:\n        m.weight.data.fill_(bn_weight_init)\n    if bn_weight_freeze:\n        m.weight.requires_grad = False\n\n    return m\n\n\ndef seq_conv_bn(in_channels, out_channels, conv_kwargs, bn_kwargs):\n    if ""padding"" not in conv_kwargs:\n        conv_kwargs[""padding""] = 1\n    if ""stride"" not in conv_kwargs:\n        conv_kwargs[""stride""] = 1\n    if ""bias"" not in conv_kwargs:\n        conv_kwargs[""bias""] = False\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=3, **conv_kwargs),\n        batch_norm(out_channels, **bn_kwargs),\n        nn.ReLU(inplace=True),\n    )\n\n\ndef conv_bn_elu(in_channels, out_channels, conv_kwargs, bn_kwargs, alpha=1.0):\n    if ""padding"" not in conv_kwargs:\n        conv_kwargs[""padding""] = 1\n    if ""stride"" not in conv_kwargs:\n        conv_kwargs[""stride""] = 1\n    if ""bias"" not in conv_kwargs:\n        conv_kwargs[""bias""] = False\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=3, **conv_kwargs),\n        batch_norm(out_channels, **bn_kwargs),\n        nn.ELU(alpha=alpha, inplace=True),\n    )\n\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.size(0), x.size(1))\n\n\nclass FastResnet(nn.Module):\n    def __init__(self, conv_kwargs=None, bn_kwargs=None, conv_bn_fn=seq_conv_bn, final_weight=0.125):\n        super(FastResnet, self).__init__()\n\n        conv_kwargs = {} if conv_kwargs is None else conv_kwargs\n        bn_kwargs = {} if bn_kwargs is None else bn_kwargs\n\n        self.prep = conv_bn_fn(3, 64, conv_kwargs, bn_kwargs)\n\n        self.layer1 = nn.Sequential(\n            conv_bn_fn(64, 128, conv_kwargs, bn_kwargs),\n            nn.MaxPool2d(kernel_size=2),\n            IdentityResidualBlock(128, 128, conv_kwargs, bn_kwargs, conv_bn_fn=conv_bn_fn),\n        )\n\n        self.layer2 = nn.Sequential(conv_bn_fn(128, 256, conv_kwargs, bn_kwargs), nn.MaxPool2d(kernel_size=2))\n\n        self.layer3 = nn.Sequential(\n            conv_bn_fn(256, 512, conv_kwargs, bn_kwargs),\n            nn.MaxPool2d(kernel_size=2),\n            IdentityResidualBlock(512, 512, conv_kwargs, bn_kwargs, conv_bn_fn=conv_bn_fn),\n        )\n\n        self.head = nn.Sequential(nn.AdaptiveMaxPool2d(1), Flatten(),)\n\n        self.final_weight = final_weight\n\n        self.features = nn.Sequential(self.prep, self.layer1, self.layer2, self.layer3, self.head)\n\n        self.classifier = nn.Linear(512, 10, bias=False)\n\n    def forward(self, x):\n        f = self.features(x)\n\n        y = self.classifier(f)\n        y = y * self.final_weight\n        return y\n\n\nclass IdentityResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, conv_kwargs, bn_kwargs, conv_bn_fn=seq_conv_bn):\n        super(IdentityResidualBlock, self).__init__()\n        self.conv1 = conv_bn_fn(in_channels, out_channels, conv_kwargs, bn_kwargs)\n        self.conv2 = conv_bn_fn(out_channels, out_channels, conv_kwargs, bn_kwargs)\n\n    def forward(self, x):\n        residual = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return x + residual\n\n\nif __name__ == ""__main__"":\n\n    import torch\n\n    torch.manual_seed(12)\n\n    model = FastResnet(bn_kwargs={""bn_weight_init"": 1.0})\n\n    x = torch.rand(4, 3, 32, 32)\n    y = model(x)\n    print(y.shape)\n'"
examples/contrib/cifar10/main.py,8,"b'import argparse\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nimport torch.distributed as dist\n\n\nimport ignite\nfrom ignite.engine import Events, Engine, create_supervised_evaluator\nfrom ignite.engine.deterministic import DeterministicEngine\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import Checkpoint, global_step_from_engine\nfrom ignite.utils import convert_tensor, manual_seed\n\nfrom ignite.contrib.engines import common\nfrom ignite.contrib.handlers import TensorboardLogger, ProgressBar\nfrom ignite.contrib.handlers.tensorboard_logger import OutputHandler, OptimizerParamsHandler, GradsHistHandler\nfrom ignite.contrib.handlers import PiecewiseLinear\n\nimport utils\n\n\ndef run(output_path, config):\n\n    distributed = dist.is_available() and dist.is_initialized()\n    rank = dist.get_rank() if distributed else 0\n\n    manual_seed(config[""seed""] + rank)\n\n    # Setup dataflow, model, optimizer, criterion\n    train_loader, test_loader = utils.get_dataflow(config, distributed)\n    model, optimizer = utils.get_model_optimizer(config, distributed)\n    criterion = nn.CrossEntropyLoss().to(utils.device)\n\n    le = len(train_loader)\n    milestones_values = [\n        (0, 0.0),\n        (le * config[""num_warmup_epochs""], config[""learning_rate""]),\n        (le * config[""num_epochs""], 0.0),\n    ]\n    lr_scheduler = PiecewiseLinear(optimizer, param_name=""lr"", milestones_values=milestones_values)\n\n    # Setup Ignite trainer:\n    # - let\'s define training step\n    # - add other common handlers:\n    #    - TerminateOnNan,\n    #    - handler to setup learning rate scheduling,\n    #    - ModelCheckpoint\n    #    - RunningAverage` on `train_step` output\n    #    - Two progress bars on epochs and optionally on iterations\n\n    def train_step(engine, batch):\n\n        x = convert_tensor(batch[0], device=utils.device, non_blocking=True)\n        y = convert_tensor(batch[1], device=utils.device, non_blocking=True)\n\n        model.train()\n        # Supervised part\n        y_pred = model(x)\n        loss = criterion(y_pred, y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        return {\n            ""batch loss"": loss.item(),\n        }\n\n    if config[""deterministic""] and rank == 0:\n        print(""Setup deterministic trainer"")\n    trainer = Engine(train_step) if not config[""deterministic""] else DeterministicEngine(train_step)\n    train_sampler = train_loader.sampler if distributed else None\n    to_save = {""trainer"": trainer, ""model"": model, ""optimizer"": optimizer, ""lr_scheduler"": lr_scheduler}\n    metric_names = [\n        ""batch loss"",\n    ]\n    common.setup_common_training_handlers(\n        trainer,\n        train_sampler=train_sampler,\n        to_save=to_save,\n        save_every_iters=config[""checkpoint_every""],\n        output_path=output_path,\n        lr_scheduler=lr_scheduler,\n        output_names=metric_names,\n        with_pbar_on_iters=config[""display_iters""],\n        log_every_iters=10,\n    )\n\n    if rank == 0:\n        # Setup Tensorboard logger - wrapper on SummaryWriter\n        tb_logger = TensorboardLogger(log_dir=output_path)\n        # Attach logger to the trainer and log trainer\'s metrics (stored in trainer.state.metrics) every iteration\n        tb_logger.attach(\n            trainer,\n            log_handler=OutputHandler(tag=""train"", metric_names=metric_names),\n            event_name=Events.ITERATION_COMPLETED,\n        )\n        # log optimizer\'s parameters: ""lr"" every iteration\n        tb_logger.attach(\n            trainer, log_handler=OptimizerParamsHandler(optimizer, param_name=""lr""), event_name=Events.ITERATION_STARTED\n        )\n\n    # Let\'s now setup evaluator engine to perform model\'s validation and compute metrics\n    metrics = {\n        ""accuracy"": Accuracy(device=utils.device if distributed else None),\n        ""loss"": Loss(criterion, device=utils.device if distributed else None),\n    }\n\n    # We define two evaluators as they wont have exactly similar roles:\n    # - `evaluator` will save the best model based on validation score\n    evaluator = create_supervised_evaluator(model, metrics=metrics, device=utils.device, non_blocking=True)\n    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=utils.device, non_blocking=True)\n\n    def run_validation(engine):\n        train_evaluator.run(train_loader)\n        evaluator.run(test_loader)\n\n    trainer.add_event_handler(Events.EPOCH_STARTED(every=config[""validate_every""]), run_validation)\n    trainer.add_event_handler(Events.COMPLETED, run_validation)\n\n    if rank == 0:\n        # Setup progress bar on evaluation engines\n        if config[""display_iters""]:\n            ProgressBar(persist=False, desc=""Train evaluation"").attach(train_evaluator)\n            ProgressBar(persist=False, desc=""Test evaluation"").attach(evaluator)\n\n        # Let\'s log metrics of `train_evaluator` stored in `train_evaluator.state.metrics` when validation run is done\n        tb_logger.attach(\n            train_evaluator,\n            log_handler=OutputHandler(\n                tag=""train"", metric_names=""all"", global_step_transform=global_step_from_engine(trainer)\n            ),\n            event_name=Events.COMPLETED,\n        )\n\n        # Let\'s log metrics of `evaluator` stored in `evaluator.state.metrics` when validation run is done\n        tb_logger.attach(\n            evaluator,\n            log_handler=OutputHandler(\n                tag=""test"", metric_names=""all"", global_step_transform=global_step_from_engine(trainer)\n            ),\n            event_name=Events.COMPLETED,\n        )\n\n        # Store 3 best models by validation accuracy:\n        common.save_best_model_by_val_score(\n            output_path, evaluator, model=model, metric_name=""accuracy"", n_saved=3, trainer=trainer, tag=""test""\n        )\n\n        # Optionally log model gradients\n        if config[""log_model_grads_every""] is not None:\n            tb_logger.attach(\n                trainer,\n                log_handler=GradsHistHandler(model, tag=model.__class__.__name__),\n                event_name=Events.ITERATION_COMPLETED(every=config[""log_model_grads_every""]),\n            )\n\n    # In order to check training resuming we can emulate a crash\n    if config[""crash_iteration""] is not None:\n\n        @trainer.on(Events.ITERATION_STARTED(once=config[""crash_iteration""]))\n        def _(engine):\n            raise Exception(""STOP at iteration: {}"".format(engine.state.iteration))\n\n    resume_from = config[""resume_from""]\n    if resume_from is not None:\n        checkpoint_fp = Path(resume_from)\n        assert checkpoint_fp.exists(), ""Checkpoint \'{}\' is not found"".format(checkpoint_fp.as_posix())\n        print(""Resume from a checkpoint: {}"".format(checkpoint_fp.as_posix()))\n        checkpoint = torch.load(checkpoint_fp.as_posix())\n        Checkpoint.load_objects(to_load=to_save, checkpoint=checkpoint)\n\n    try:\n        trainer.run(train_loader, max_epochs=config[""num_epochs""])\n    except Exception as e:\n        import traceback\n\n        print(traceback.format_exc())\n\n    if rank == 0:\n        tb_logger.close()\n\n\nif __name__ == ""__main__"":\n\n    parser = argparse.ArgumentParser(""Training a CNN on CIFAR10 dataset"")\n    parser.add_argument(\n        ""--params"",\n        type=str,\n        help=""Override default configuration with parameters: ""\n        ""data_path=/path/to/dataset;batch_size=64;num_workers=12 ..."",\n    )\n    parser.add_argument(""--local_rank"", type=int, default=0, help=""Local process rank in distributed computation"")\n\n    args = parser.parse_args()\n\n    assert torch.cuda.is_available()\n    torch.backends.cudnn.benchmark = True\n\n    config = utils.get_default_config()\n    config[""local_rank""] = args.local_rank\n\n    # Override config:\n    if args.params is not None:\n        for param in args.params.split("";""):\n            key, value = param.split(""="")\n            if ""/"" not in value:\n                value = eval(value)\n            config[key] = value\n\n    backend = config[""dist_backend""]\n    distributed = backend is not None\n\n    if distributed:\n        dist.init_process_group(backend, init_method=config[""dist_url""])\n        # let each node print the info\n        if config[""local_rank""] == 0:\n            print(""\\nDistributed setting:"")\n            print(""\\tbackend: {}"".format(dist.get_backend()))\n            print(""\\tworld size: {}"".format(dist.get_world_size()))\n            print(""\\trank: {}"".format(dist.get_rank()))\n            print(""\\n"")\n\n    output_path = None\n    # let each node print the info\n    if config[""local_rank""] == 0:\n        print(""Train {} on CIFAR10"".format(config[""model""]))\n        print(""- PyTorch version: {}"".format(torch.__version__))\n        print(""- Ignite version: {}"".format(ignite.__version__))\n        print(""- CUDA version: {}"".format(torch.version.cuda))\n\n        print(""\\n"")\n        print(""Configuration:"")\n        for key, value in config.items():\n            print(""\\t{}: {}"".format(key, value))\n        print(""\\n"")\n\n        # create log directory only by 1 node\n        if (not distributed) or (dist.get_rank() == 0):\n            from datetime import datetime\n\n            now = datetime.now().strftime(""%Y%m%d-%H%M%S"")\n            gpu_conf = ""-single-gpu""\n            if distributed:\n                ngpus_per_node = torch.cuda.device_count()\n                nnodes = dist.get_world_size() // ngpus_per_node\n                gpu_conf = ""-distributed-{}nodes-{}gpus"".format(nnodes, ngpus_per_node)\n\n            output_path = Path(config[""output_path""]) / ""{}{}"".format(now, gpu_conf)\n            if not output_path.exists():\n                output_path.mkdir(parents=True)\n            output_path = output_path.as_posix()\n            print(""Output path: {}"".format(output_path))\n\n    try:\n        run(output_path, config)\n    except KeyboardInterrupt:\n        print(""Catched KeyboardInterrupt -> exit"")\n    except Exception as e:\n        if distributed:\n            dist.destroy_process_group()\n        raise e\n\n    if distributed:\n        dist.destroy_process_group()\n'"
examples/contrib/cifar10/utils.py,9,"b'import os\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nimport torch.distributed as dist\nimport torch.optim as optim\n\nfrom torchvision import models\nfrom torchvision import datasets\nfrom torchvision.transforms import Compose, ToTensor, Normalize, Pad, RandomCrop, RandomHorizontalFlip\n\nimport fastresnet\n\n\ndevice = ""cuda""\n\n\ndef get_train_test_loaders(path, batch_size, num_workers, distributed=False, pin_memory=True):\n\n    train_transform = Compose(\n        [\n            Pad(4),\n            RandomCrop(32, fill=128),\n            RandomHorizontalFlip(),\n            ToTensor(),\n            Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ]\n    )\n\n    test_transform = Compose([ToTensor(), Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),])\n\n    if not os.path.exists(path):\n        os.makedirs(path)\n        download = True\n    else:\n        download = True if len(os.listdir(path)) < 1 else False\n\n    train_ds = datasets.CIFAR10(root=path, train=True, download=download, transform=train_transform)\n    test_ds = datasets.CIFAR10(root=path, train=False, download=False, transform=test_transform)\n\n    train_sampler = None\n    test_sampler = None\n    if distributed:\n        train_sampler = DistributedSampler(train_ds)\n        test_sampler = DistributedSampler(test_ds, shuffle=False)\n\n    train_labelled_loader = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        sampler=train_sampler,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        drop_last=True,\n    )\n\n    test_loader = DataLoader(\n        test_ds, batch_size=batch_size * 2, sampler=test_sampler, num_workers=num_workers, pin_memory=pin_memory\n    )\n\n    return train_labelled_loader, test_loader\n\n\ndef get_model(name):\n    if name in models.__dict__:\n        fn = models.__dict__[name]\n    elif name in fastresnet.__dict__:\n        fn = fastresnet.__dict__[name]\n    else:\n        raise RuntimeError(""Unknown model name {}"".format(name))\n\n    return fn()\n\n\ndef get_model_optimizer(config, distributed=False):\n    local_rank = config[""local_rank""]\n    if distributed:\n        torch.cuda.set_device(local_rank)\n\n    model = get_model(config[""model""])\n    model = model.to(device)\n\n    optimizer = optim.SGD(\n        model.parameters(),\n        lr=config[""learning_rate""],\n        momentum=config[""momentum""],\n        weight_decay=config[""weight_decay""],\n        nesterov=True,\n    )\n\n    if distributed:\n        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank,])\n    elif torch.cuda.device_count() > 0:\n        model = nn.parallel.DataParallel(model)\n\n    return model, optimizer\n\n\ndef get_dataflow(config, distributed=False):\n\n    # Rescale batch_size and num_workers\n    ngpus_per_node = torch.cuda.device_count() if distributed else 1\n    ngpus = dist.get_world_size() if distributed else 1\n    batch_size = config[""batch_size""] // ngpus\n    num_workers = int((config[""num_workers""] + ngpus_per_node - 1) / ngpus_per_node)\n\n    train_loader, test_loader = get_train_test_loaders(\n        path=config[""data_path""], batch_size=batch_size, distributed=distributed, num_workers=num_workers\n    )\n    return train_loader, test_loader\n\n\ndef get_default_config():\n    batch_size = 512\n    num_epochs = 24\n    # Default configuration dictionary\n    config = {\n        ""seed"": 12,\n        ""data_path"": ""/tmp/cifar10"",\n        ""output_path"": ""/tmp/output-cifar10"",\n        ""model"": ""fastresnet"",\n        ""batch_size"": batch_size,\n        ""num_workers"": 10,\n        ""momentum"": 0.9,\n        ""weight_decay"": 1e-4,\n        ""num_epochs"": num_epochs,\n        ""learning_rate"": 0.04,\n        ""num_warmup_epochs"": 4,\n        ""validate_every"": 3,\n        # distributed settings\n        ""dist_url"": ""env://"",\n        ""dist_backend"": None,  # if None distributed option is disabled, set to ""nccl"" to enable\n        # Logging:\n        ""display_iters"": True,\n        ""log_model_grads_every"": None,\n        ""checkpoint_every"": 200,\n        # Crash/Resume training:\n        ""resume_from"": None,  # Path to checkpoint file .pt\n        ""crash_iteration"": None,\n        # Deterministic training: replace Engine by DeterministicEngine\n        ""deterministic"": False,\n    }\n    return config\n'"
examples/contrib/cifar100_amp_benchmark/benchmark_fp32.py,5,"b'import fire\n\nimport torch\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import SGD\n\nfrom torchvision.models import wide_resnet50_2\n\nfrom ignite.engine import Events, Engine, create_supervised_evaluator, convert_tensor\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import Timer\nfrom ignite.contrib.handlers import ProgressBar\n\nfrom utils import get_train_eval_loaders\n\n\ndef main(dataset_path, batch_size=256, max_epochs=10):\n    assert torch.cuda.is_available()\n    assert torch.backends.cudnn.enabled, ""NVIDIA/Apex:Amp requires cudnn backend to be enabled.""\n    torch.backends.cudnn.benchmark = True\n\n    device = ""cuda""\n\n    train_loader, test_loader, eval_train_loader = get_train_eval_loaders(dataset_path, batch_size=batch_size)\n\n    model = wide_resnet50_2(num_classes=100).to(device)\n    optimizer = SGD(model.parameters(), lr=0.01)\n    criterion = CrossEntropyLoss().to(device)\n\n    def train_step(engine, batch):\n        x = convert_tensor(batch[0], device, non_blocking=True)\n        y = convert_tensor(batch[1], device, non_blocking=True)\n\n        optimizer.zero_grad()\n\n        y_pred = model(x)\n        loss = criterion(y_pred, y)\n        loss.backward()\n\n        optimizer.step()\n\n        return loss.item()\n\n    trainer = Engine(train_step)\n    timer = Timer(average=True)\n    timer.attach(trainer, step=Events.EPOCH_COMPLETED)\n    ProgressBar(persist=True).attach(trainer, output_transform=lambda out: {""batch loss"": out})\n\n    metrics = {""Accuracy"": Accuracy(), ""Loss"": Loss(criterion)}\n\n    evaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)\n\n    def log_metrics(engine, title):\n        for name in metrics:\n            print(""\\t{} {}: {:.2f}"".format(title, name, engine.state.metrics[name]))\n\n    @trainer.on(Events.COMPLETED)\n    def run_validation(_):\n        print(""- Mean elapsed time for 1 epoch: {}"".format(timer.value()))\n        print(""- Metrics:"")\n        with evaluator.add_event_handler(Events.COMPLETED, log_metrics, ""Train""):\n            evaluator.run(eval_train_loader)\n\n        with evaluator.add_event_handler(Events.COMPLETED, log_metrics, ""Test""):\n            evaluator.run(test_loader)\n\n    trainer.run(train_loader, max_epochs=max_epochs)\n\n\nif __name__ == ""__main__"":\n    fire.Fire(main)\n'"
examples/contrib/cifar100_amp_benchmark/benchmark_nvidia_apex.py,5,"b'import fire\n\nimport torch\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import SGD\n\nfrom torchvision.models import wide_resnet50_2\n\nfrom apex import amp\n\nfrom ignite.engine import Events, Engine, create_supervised_evaluator, convert_tensor\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import Timer\nfrom ignite.contrib.handlers import ProgressBar\n\nfrom utils import get_train_eval_loaders\n\n\ndef main(dataset_path, batch_size=256, max_epochs=10, opt=""O1""):\n    assert torch.cuda.is_available()\n    assert torch.backends.cudnn.enabled, ""NVIDIA/Apex:Amp requires cudnn backend to be enabled.""\n    torch.backends.cudnn.benchmark = True\n\n    device = ""cuda""\n\n    train_loader, test_loader, eval_train_loader = get_train_eval_loaders(dataset_path, batch_size=batch_size)\n\n    model = wide_resnet50_2(num_classes=100).to(device)\n    optimizer = SGD(model.parameters(), lr=0.01)\n    criterion = CrossEntropyLoss().to(device)\n\n    model, optimizer = amp.initialize(model, optimizer, opt_level=opt)\n\n    def train_step(engine, batch):\n        x = convert_tensor(batch[0], device, non_blocking=True)\n        y = convert_tensor(batch[1], device, non_blocking=True)\n\n        optimizer.zero_grad()\n\n        y_pred = model(x)\n        loss = criterion(y_pred, y)\n\n        # Runs the forward pass with autocasting.\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()\n\n        optimizer.step()\n\n        return loss.item()\n\n    trainer = Engine(train_step)\n    timer = Timer(average=True)\n    timer.attach(trainer, step=Events.EPOCH_COMPLETED)\n    ProgressBar(persist=True).attach(trainer, output_transform=lambda out: {""batch loss"": out})\n\n    metrics = {""Accuracy"": Accuracy(), ""Loss"": Loss(criterion)}\n\n    evaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)\n\n    def log_metrics(engine, title):\n        for name in metrics:\n            print(""\\t{} {}: {:.2f}"".format(title, name, engine.state.metrics[name]))\n\n    @trainer.on(Events.COMPLETED)\n    def run_validation(_):\n        print(""- Mean elapsed time for 1 epoch: {}"".format(timer.value()))\n        print(""- Metrics:"")\n        with evaluator.add_event_handler(Events.COMPLETED, log_metrics, ""Train""):\n            evaluator.run(eval_train_loader)\n\n        with evaluator.add_event_handler(Events.COMPLETED, log_metrics, ""Test""):\n            evaluator.run(test_loader)\n\n    trainer.run(train_loader, max_epochs=max_epochs)\n\n\nif __name__ == ""__main__"":\n    fire.Fire(main)\n'"
examples/contrib/cifar100_amp_benchmark/benchmark_torch_cuda_amp.py,6,"b'import fire\n\nimport torch\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import SGD\n\n# Creates a GradScaler once at the beginning of training.\nfrom torch.cuda.amp import GradScaler, autocast\n\nfrom torchvision.models import wide_resnet50_2\n\nfrom ignite.engine import Events, Engine, create_supervised_evaluator, convert_tensor\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import Timer\nfrom ignite.contrib.handlers import ProgressBar\n\nfrom utils import get_train_eval_loaders\n\n\ndef main(dataset_path, batch_size=256, max_epochs=10):\n    assert torch.cuda.is_available()\n    assert torch.backends.cudnn.enabled, ""NVIDIA/Apex:Amp requires cudnn backend to be enabled.""\n    torch.backends.cudnn.benchmark = True\n\n    device = ""cuda""\n\n    train_loader, test_loader, eval_train_loader = get_train_eval_loaders(dataset_path, batch_size=batch_size)\n\n    model = wide_resnet50_2(num_classes=100).to(device)\n    optimizer = SGD(model.parameters(), lr=0.01)\n    criterion = CrossEntropyLoss().to(device)\n\n    scaler = GradScaler()\n\n    def train_step(engine, batch):\n        x = convert_tensor(batch[0], device, non_blocking=True)\n        y = convert_tensor(batch[1], device, non_blocking=True)\n\n        optimizer.zero_grad()\n\n        # Runs the forward pass with autocasting.\n        with autocast():\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n\n        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n        # Backward passes under autocast are not recommended.\n        # Backward ops run in the same precision that autocast used for corresponding forward ops.\n        scaler.scale(loss).backward()\n\n        # scaler.step() first unscales the gradients of the optimizer\'s assigned params.\n        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n        # otherwise, optimizer.step() is skipped.\n        scaler.step(optimizer)\n\n        # Updates the scale for next iteration.\n        scaler.update()\n\n        return loss.item()\n\n    trainer = Engine(train_step)\n    timer = Timer(average=True)\n    timer.attach(trainer, step=Events.EPOCH_COMPLETED)\n    ProgressBar(persist=True).attach(trainer, output_transform=lambda out: {""batch loss"": out})\n\n    metrics = {""Accuracy"": Accuracy(), ""Loss"": Loss(criterion)}\n\n    evaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)\n\n    def log_metrics(engine, title):\n        for name in metrics:\n            print(""\\t{} {}: {:.2f}"".format(title, name, engine.state.metrics[name]))\n\n    @trainer.on(Events.COMPLETED)\n    def run_validation(_):\n        print(""- Mean elapsed time for 1 epoch: {}"".format(timer.value()))\n        print(""- Metrics:"")\n        with evaluator.add_event_handler(Events.COMPLETED, log_metrics, ""Train""):\n            evaluator.run(eval_train_loader)\n\n        with evaluator.add_event_handler(Events.COMPLETED, log_metrics, ""Test""):\n            evaluator.run(test_loader)\n\n    trainer.run(train_loader, max_epochs=max_epochs)\n\n\nif __name__ == ""__main__"":\n    fire.Fire(main)\n'"
examples/contrib/cifar100_amp_benchmark/utils.py,1,"b'import random\n\nfrom torchvision.datasets.cifar import CIFAR100\nfrom torchvision.transforms import Compose, RandomCrop, Pad, RandomHorizontalFlip\nfrom torchvision.transforms import ToTensor, Normalize, RandomErasing\n\nfrom torch.utils.data import Subset, DataLoader\n\n\ndef get_train_eval_loaders(path, batch_size=256):\n    """"""Setup the dataflow:\n        - load CIFAR100 train and test datasets\n        - setup train/test image transforms\n            - horizontally flipped randomly and augmented using cutout.\n            - each mini-batch contained 256 examples\n        - setup train/test data loaders\n\n    Returns:\n        train_loader, test_loader, eval_train_loader\n    """"""\n    train_transform = Compose(\n        [\n            Pad(4),\n            RandomCrop(32),\n            RandomHorizontalFlip(),\n            ToTensor(),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            RandomErasing(),\n        ]\n    )\n\n    test_transform = Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n    train_dataset = CIFAR100(root=path, train=True, transform=train_transform, download=True)\n    test_dataset = CIFAR100(root=path, train=False, transform=test_transform, download=False)\n\n    train_eval_indices = [random.randint(0, len(train_dataset) - 1) for i in range(len(test_dataset))]\n    train_eval_dataset = Subset(train_dataset, train_eval_indices)\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=batch_size, num_workers=12, shuffle=True, drop_last=True, pin_memory=True\n    )\n\n    test_loader = DataLoader(\n        test_dataset, batch_size=batch_size, num_workers=12, shuffle=False, drop_last=False, pin_memory=True\n    )\n\n    eval_train_loader = DataLoader(\n        train_eval_dataset, batch_size=batch_size, num_workers=12, shuffle=False, drop_last=False, pin_memory=True\n    )\n\n    return train_loader, test_loader, eval_train_loader\n'"
examples/contrib/mnist/mnist_with_neptune_logger.py,4,"b'""""""\n MNIST example with training and validation monitoring using Neptune.\n\n Requirements:\n    Neptune: `pip install neptune-client`\n\n Usage:\n\n    Run the example:\n    ```bash\n    python mnist_with_neptune_logger.py\n    ```\n\n    Go to https://neptune.ai and explore your experiment.\n\nNote:\n    You can see an example experiment here:\n    https://ui.neptune.ai/o/shared/org/pytorch-ignite-integration/e/PYTOR-26/charts\n""""""\nfrom argparse import ArgumentParser\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.optim import SGD\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import Compose, ToTensor, Normalize\n\nfrom ignite.contrib.handlers.neptune_logger import *\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import Checkpoint\nfrom ignite.utils import setup_logger\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    criterion = nn.CrossEntropyLoss()\n    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n    trainer.logger = setup_logger(""Trainer"")\n\n    metrics = {""accuracy"": Accuracy(), ""loss"": Loss(criterion)}\n\n    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    train_evaluator.logger = setup_logger(""Train Evaluator"")\n    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    validation_evaluator.logger = setup_logger(""Val Evaluator"")\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def compute_metrics(engine):\n        train_evaluator.run(train_loader)\n        validation_evaluator.run(val_loader)\n\n    npt_logger = NeptuneLogger(\n        api_token=""ANONYMOUS"",\n        project_name=""shared/pytorch-ignite-integration"",\n        name=""ignite-mnist-example"",\n        params={\n            ""train_batch_size"": train_batch_size,\n            ""val_batch_size"": val_batch_size,\n            ""epochs"": epochs,\n            ""lr"": lr,\n            ""momentum"": momentum,\n        },\n    )\n\n    npt_logger.attach_output_handler(\n        trainer,\n        event_name=Events.ITERATION_COMPLETED(every=100),\n        tag=""training"",\n        output_transform=lambda loss: {""batchloss"": loss},\n    )\n\n    for tag, evaluator in [(""training"", train_evaluator), (""validation"", validation_evaluator)]:\n        npt_logger.attach_output_handler(\n            evaluator,\n            event_name=Events.EPOCH_COMPLETED,\n            tag=tag,\n            metric_names=[""loss"", ""accuracy""],\n            global_step_transform=global_step_from_engine(trainer),\n        )\n\n    npt_logger.attach_opt_params_handler(trainer, event_name=Events.ITERATION_COMPLETED(every=100), optimizer=optimizer)\n\n    npt_logger.attach(\n        trainer, log_handler=WeightsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100)\n    )\n\n    npt_logger.attach(trainer, log_handler=GradsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100))\n\n    def score_function(engine):\n        return engine.state.metrics[""accuracy""]\n\n    handler = Checkpoint(\n        {""model"": model},\n        NeptuneSaver(npt_logger),\n        n_saved=2,\n        filename_prefix=""best"",\n        score_function=score_function,\n        score_name=""validation_accuracy"",\n        global_step_transform=global_step_from_engine(trainer),\n    )\n    validation_evaluator.add_event_handler(Events.COMPLETED, handler)\n\n    # kick everything off\n    trainer.run(train_loader, max_epochs=epochs)\n\n    npt_logger.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum)\n'"
examples/contrib/mnist/mnist_with_tensorboard_logger.py,4,"b'""""""\n MNIST example with training and validation monitoring using TensorboardX and Tensorboard.\n\n Requirements:\n    Optionally TensorboardX (https://github.com/lanpa/tensorboard-pytorch): `pip install tensorboardX`\n    Tensorboard: `pip install tensorflow` (or just install tensorboard without the rest of tensorflow)\n\n Usage:\n\n    Start tensorboard:\n    ```bash\n    tensorboard --logdir=/tmp/tensorboard_logs/\n    ```\n\n    Run the example:\n    ```bash\n    python mnist_with_tensorboard_logger.py --log_dir=/tmp/tensorboard_logs\n    ```\n""""""\nimport sys\nfrom argparse import ArgumentParser\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.optim import SGD\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import Compose, ToTensor, Normalize\n\nfrom ignite.contrib.handlers.tensorboard_logger import *\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import ModelCheckpoint\nfrom ignite.utils import setup_logger\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum, log_dir):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    criterion = nn.CrossEntropyLoss()\n    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n    trainer.logger = setup_logger(""Trainer"")\n\n    if sys.version_info > (3,):\n        from ignite.contrib.metrics.gpu_info import GpuInfo\n\n        try:\n            GpuInfo().attach(trainer)\n        except RuntimeError:\n            print(\n                ""INFO: By default, in this example it is possible to log GPU information (used memory, utilization). ""\n                ""As there is no pynvml python package installed, GPU information won\'t be logged. Otherwise, please ""\n                ""install it : `pip install pynvml`""\n            )\n\n    metrics = {""accuracy"": Accuracy(), ""loss"": Loss(criterion)}\n\n    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    train_evaluator.logger = setup_logger(""Train Evaluator"")\n    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    validation_evaluator.logger = setup_logger(""Val Evaluator"")\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def compute_metrics(engine):\n        train_evaluator.run(train_loader)\n        validation_evaluator.run(val_loader)\n\n    tb_logger = TensorboardLogger(log_dir=log_dir)\n\n    tb_logger.attach_output_handler(\n        trainer,\n        event_name=Events.ITERATION_COMPLETED(every=100),\n        tag=""training"",\n        output_transform=lambda loss: {""batchloss"": loss},\n        metric_names=""all"",\n    )\n\n    for tag, evaluator in [(""training"", train_evaluator), (""validation"", validation_evaluator)]:\n        tb_logger.attach_output_handler(\n            evaluator,\n            event_name=Events.EPOCH_COMPLETED,\n            tag=tag,\n            metric_names=[""loss"", ""accuracy""],\n            global_step_transform=global_step_from_engine(trainer),\n        )\n\n    tb_logger.attach_opt_params_handler(trainer, event_name=Events.ITERATION_COMPLETED(every=100), optimizer=optimizer)\n\n    tb_logger.attach(trainer, log_handler=WeightsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100))\n\n    tb_logger.attach(trainer, log_handler=WeightsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n\n    tb_logger.attach(trainer, log_handler=GradsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100))\n\n    tb_logger.attach(trainer, log_handler=GradsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n\n    def score_function(engine):\n        return engine.state.metrics[""accuracy""]\n\n    model_checkpoint = ModelCheckpoint(\n        log_dir,\n        n_saved=2,\n        filename_prefix=""best"",\n        score_function=score_function,\n        score_name=""validation_accuracy"",\n        global_step_transform=global_step_from_engine(trainer),\n    )\n    validation_evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {""model"": model})\n\n    # kick everything off\n    trainer.run(train_loader, max_epochs=epochs)\n\n    tb_logger.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n    parser.add_argument(\n        ""--log_dir"", type=str, default=""tensorboard_logs"", help=""log directory for Tensorboard log output""\n    )\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_dir)\n'"
examples/contrib/mnist/mnist_with_tqdm_logger.py,4,"b'from argparse import ArgumentParser\n\nfrom torch import nn\nfrom torch.optim import SGD\nfrom torch.utils.data import DataLoader\nimport torch\nimport torch.nn.functional as F\nfrom torchvision.transforms import Compose, ToTensor, Normalize\nfrom torchvision.datasets import MNIST\n\nfrom ignite.contrib.handlers import ProgressBar\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss, RunningAverage\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum, display_gpu_info):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n    evaluator = create_supervised_evaluator(\n        model, metrics={""accuracy"": Accuracy(), ""nll"": Loss(F.nll_loss)}, device=device\n    )\n\n    RunningAverage(output_transform=lambda x: x).attach(trainer, ""loss"")\n\n    if display_gpu_info:\n        from ignite.contrib.metrics import GpuInfo\n\n        GpuInfo().attach(trainer, name=""gpu"")\n\n    pbar = ProgressBar(persist=True)\n    pbar.attach(trainer, metric_names=""all"")\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_training_results(engine):\n        evaluator.run(train_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        pbar.log_message(\n            ""Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_validation_results(engine):\n        evaluator.run(val_loader)\n        metrics = evaluator.state.metrics\n        avg_accuracy = metrics[""accuracy""]\n        avg_nll = metrics[""nll""]\n        pbar.log_message(\n            ""Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}"".format(\n                engine.state.epoch, avg_accuracy, avg_nll\n            )\n        )\n\n        pbar.n = pbar.last_print_n = 0\n\n    trainer.run(train_loader, max_epochs=epochs)\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n    parser.add_argument(\n        ""--display_gpu_info"",\n        action=""store_true"",\n        help=""Display gpu usage info. This needs python 3.X and pynvml package"",\n    )\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.display_gpu_info)\n'"
examples/contrib/mnist/mnist_with_trains_logger.py,4,"b'""""""\n MNIST example with training and validation monitoring using Trains.\n\n Requirements:\n    Trains: `pip install trains`\n\n Usage:\n\n    Run the example:\n    ```bash\n    python mnist_with_trains_logger.py\n    ```\n""""""\nfrom argparse import ArgumentParser\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.optim import SGD\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import Compose, ToTensor, Normalize\n\nfrom ignite.contrib.handlers.trains_logger import *\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.handlers import Checkpoint\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.utils import setup_logger\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    criterion = nn.CrossEntropyLoss()\n    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n    trainer.logger = setup_logger(""Trainer"")\n\n    metrics = {""accuracy"": Accuracy(), ""loss"": Loss(criterion)}\n\n    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    train_evaluator.logger = setup_logger(""Train Evaluator"")\n    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    validation_evaluator.logger = setup_logger(""Val Evaluator"")\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def compute_metrics(engine):\n        train_evaluator.run(train_loader)\n        validation_evaluator.run(val_loader)\n\n    trains_logger = TrainsLogger(project_name=""examples"", task_name=""ignite"")\n\n    trains_logger.attach_output_handler(\n        trainer,\n        event_name=Events.ITERATION_COMPLETED(every=100),\n        tag=""training"",\n        output_transform=lambda loss: {""batchloss"": loss},\n    )\n\n    for tag, evaluator in [(""training metrics"", train_evaluator), (""validation metrics"", validation_evaluator)]:\n        trains_logger.attach_output_handler(\n            evaluator,\n            event_name=Events.EPOCH_COMPLETED,\n            tag=tag,\n            metric_names=[""loss"", ""accuracy""],\n            global_step_transform=global_step_from_engine(trainer),\n        )\n\n    trains_logger.attach_opt_params_handler(\n        trainer, event_name=Events.ITERATION_COMPLETED(every=100), optimizer=optimizer\n    )\n\n    trains_logger.attach(\n        trainer, log_handler=WeightsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100)\n    )\n\n    trains_logger.attach(trainer, log_handler=WeightsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n\n    trains_logger.attach(\n        trainer, log_handler=GradsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100)\n    )\n\n    trains_logger.attach(trainer, log_handler=GradsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n\n    handler = Checkpoint(\n        {""model"": model},\n        TrainsSaver(trains_logger, dirname=""~/.trains/cache/""),\n        n_saved=1,\n        score_function=lambda e: e.state.metrics[""accuracy""],\n        score_name=""val_acc"",\n        filename_prefix=""best"",\n        global_step_transform=global_step_from_engine(trainer),\n    )\n    validation_evaluator.add_event_handler(Events.EPOCH_COMPLETED, handler)\n\n    # kick everything off\n    trainer.run(train_loader, max_epochs=epochs)\n\n    trains_logger.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum)\n'"
examples/contrib/mnist/mnist_with_visdom_logger.py,4,"b'""""""\n MNIST example with training and validation monitoring using Visdom.\n\n Requirements:\n    Visdom (https://github.com/facebookresearch/visdom.git):\n    `pip install git+https://github.com/facebookresearch/visdom.git`\n\n Usage:\n\n    Start visdom server:\n    ```bash\n    visdom -logging_level 30\n    ```\n\n    Run the example:\n    ```bash\n    python mnist_with_visdom_logger.py\n    ```\n""""""\nfrom argparse import ArgumentParser\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.optim import SGD\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import Compose, ToTensor, Normalize\n\nfrom ignite.contrib.handlers.visdom_logger import *\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import ModelCheckpoint\nfrom ignite.utils import setup_logger\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum, log_dir):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    criterion = nn.CrossEntropyLoss()\n    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n    trainer.logger = setup_logger(""Trainer"")\n\n    metrics = {""accuracy"": Accuracy(), ""loss"": Loss(criterion)}\n\n    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    train_evaluator.logger = setup_logger(""Train Evaluator"")\n    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    validation_evaluator.logger = setup_logger(""Val Evaluator"")\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def compute_metrics(engine):\n        train_evaluator.run(train_loader)\n        validation_evaluator.run(val_loader)\n\n    vd_logger = VisdomLogger(env=""mnist_training"")\n\n    vd_logger.attach_output_handler(\n        trainer,\n        event_name=Events.ITERATION_COMPLETED(every=100),\n        tag=""training"",\n        output_transform=lambda loss: {""batchloss"": loss},\n    )\n\n    for tag, evaluator in [(""training"", train_evaluator), (""validation"", validation_evaluator)]:\n        vd_logger.attach_output_handler(\n            evaluator,\n            event_name=Events.EPOCH_COMPLETED,\n            tag=tag,\n            metric_names=[""loss"", ""accuracy""],\n            global_step_transform=global_step_from_engine(trainer),\n        )\n\n    vd_logger.attach_opt_params_handler(trainer, event_name=Events.ITERATION_COMPLETED(every=100), optimizer=optimizer)\n\n    vd_logger.attach(trainer, log_handler=WeightsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100))\n\n    vd_logger.attach(trainer, log_handler=GradsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100))\n\n    def score_function(engine):\n        return engine.state.metrics[""accuracy""]\n\n    model_checkpoint = ModelCheckpoint(\n        log_dir,\n        n_saved=2,\n        filename_prefix=""best"",\n        score_function=score_function,\n        score_name=""validation_accuracy"",\n        global_step_transform=global_step_from_engine(trainer),\n    )\n    validation_evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {""model"": model})\n\n    # kick everything off\n    trainer.run(train_loader, max_epochs=epochs)\n\n    vd_logger.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n    parser.add_argument(""--log_dir"", type=str, default=""mnist_visdom_logs"", help=""log directory for training output"")\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_dir)\n'"
examples/contrib/mnist/mnist_with_wandb_logger.py,4,"b'""""""\n MNIST example with training and validation monitoring using Weights & Biases\n\n Requirements:\n    Weights & Biases: `pip install wandb`\n\n Usage:\n\n    Make sure you are logged into Weights & Biases (use the `wandb` command).\n\n    Run the example:\n    ```bash\n    python mnist_with_wandb_logger.py\n    ```\n\n    Go to https://wandb.com and explore your experiment.\n""""""\nfrom argparse import ArgumentParser\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.optim import SGD\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import Compose, ToTensor, Normalize\n\nfrom ignite.contrib.handlers.wandb_logger import *\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss\nfrom ignite.handlers import ModelCheckpoint\nfrom ignite.utils import setup_logger\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=-1)\n\n\ndef get_data_loaders(train_batch_size, val_batch_size):\n    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n\n    train_loader = DataLoader(\n        MNIST(download=True, root=""."", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n    )\n\n    val_loader = DataLoader(\n        MNIST(download=False, root=""."", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n    )\n    return train_loader, val_loader\n\n\ndef run(train_batch_size, val_batch_size, epochs, lr, momentum):\n    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n    model = Net()\n    device = ""cpu""\n\n    if torch.cuda.is_available():\n        device = ""cuda""\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n    criterion = nn.CrossEntropyLoss()\n    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n    trainer.logger = setup_logger(""Trainer"")\n\n    metrics = {""accuracy"": Accuracy(), ""loss"": Loss(criterion)}\n\n    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    train_evaluator.logger = setup_logger(""Train Evaluator"")\n    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n    validation_evaluator.logger = setup_logger(""Val Evaluator"")\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def compute_metrics(engine):\n        train_evaluator.run(train_loader)\n        validation_evaluator.run(val_loader)\n\n    wandb_logger = WandBLogger(\n        project=""pytorch-ignite-integration"",\n        name=""ignite-mnist-example"",\n        config={\n            ""train_batch_size"": train_batch_size,\n            ""val_batch_size"": val_batch_size,\n            ""epochs"": epochs,\n            ""lr"": lr,\n            ""momentum"": momentum,\n        },\n    )\n\n    wandb_logger.attach_output_handler(\n        trainer,\n        event_name=Events.ITERATION_COMPLETED(every=100),\n        tag=""training"",\n        output_transform=lambda loss: {""batchloss"": loss},\n    )\n\n    for tag, evaluator in [(""training"", train_evaluator), (""validation"", validation_evaluator)]:\n        wandb_logger.attach_output_handler(\n            evaluator,\n            event_name=Events.EPOCH_COMPLETED,\n            tag=tag,\n            metric_names=[""loss"", ""accuracy""],\n            global_step_transform=lambda *_: trainer.state.iteration,\n        )\n\n    wandb_logger.attach_opt_params_handler(\n        trainer, event_name=Events.ITERATION_COMPLETED(every=100), optimizer=optimizer\n    )\n    wandb_logger.watch(model, log=""all"")\n\n    def score_function(engine):\n        return engine.state.metrics[""accuracy""]\n\n    model_checkpoint = ModelCheckpoint(\n        wandb_logger.run.dir,\n        n_saved=2,\n        filename_prefix=""best"",\n        score_function=score_function,\n        score_name=""validation_accuracy"",\n        global_step_transform=global_step_from_engine(trainer),\n    )\n    validation_evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {""model"": model})\n\n    # kick everything off\n    trainer.run(train_loader, max_epochs=epochs)\n\n    wandb_logger.close()\n\n\nif __name__ == ""__main__"":\n    parser = ArgumentParser()\n    parser.add_argument(""--batch_size"", type=int, default=64, help=""input batch size for training (default: 64)"")\n    parser.add_argument(\n        ""--val_batch_size"", type=int, default=1000, help=""input batch size for validation (default: 1000)""\n    )\n    parser.add_argument(""--epochs"", type=int, default=10, help=""number of epochs to train (default: 10)"")\n    parser.add_argument(""--lr"", type=float, default=0.01, help=""learning rate (default: 0.01)"")\n    parser.add_argument(""--momentum"", type=float, default=0.5, help=""SGD momentum (default: 0.5)"")\n\n    args = parser.parse_args()\n\n    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum)\n'"
ignite/contrib/engines/__init__.py,0,"b'from ignite.contrib.engines.tbptt import Tbptt_Events, create_supervised_tbptt_trainer\n'"
ignite/contrib/engines/common.py,17,"b'import numbers\nimport warnings\nfrom collections.abc import Mapping, Sequence\nfrom functools import partial\n\nimport torch\nfrom torch.utils.data.distributed import DistributedSampler\n\nimport ignite.distributed as idist\nfrom ignite.contrib.handlers import (\n    LRScheduler,\n    MLflowLogger,\n    NeptuneLogger,\n    PolyaxonLogger,\n    ProgressBar,\n    TensorboardLogger,\n    TrainsLogger,\n    VisdomLogger,\n    WandBLogger,\n    global_step_from_engine,\n)\nfrom ignite.contrib.metrics import GpuInfo\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import Checkpoint, DiskSaver, EarlyStopping, TerminateOnNan\nfrom ignite.metrics import RunningAverage\n\n\ndef setup_common_training_handlers(\n    trainer,\n    train_sampler=None,\n    to_save=None,\n    save_every_iters=1000,\n    output_path=None,\n    lr_scheduler=None,\n    with_gpu_stats=False,\n    output_names=None,\n    with_pbars=True,\n    with_pbar_on_iters=True,\n    log_every_iters=100,\n    device=None,\n    stop_on_nan=True,\n    clear_cuda_cache=True,\n):\n    """"""Helper method to setup trainer with common handlers (it also supports distributed configuration):\n        - :class:`~ignite.handlers.TerminateOnNan`\n        - handler to setup learning rate scheduling\n        - :class:`~ignite.handlers.ModelCheckpoint`\n        - :class:`~ignite.metrics.RunningAverage` on `update_function` output\n        - Two progress bars on epochs and optionally on iterations\n\n    Args:\n        trainer (Engine): trainer engine. Output of trainer\'s `update_function` should be a dictionary\n            or sequence or a single tensor.\n        train_sampler (torch.utils.data.DistributedSampler, optional): Optional distributed sampler used to call\n            `set_epoch` method on epoch started event.\n        to_save (dict, optional): dictionary with objects to save in the checkpoint. This argument is passed to\n            :class:`~ignite.handlers.Checkpoint` instance.\n        save_every_iters (int, optional): saving interval. By default, `to_save` objects are stored\n            each 1000 iterations.\n        output_path (str, optional): output path to indicate where `to_save` objects are stored.\n        lr_scheduler (ParamScheduler or subclass of `torch.optim.lr_scheduler._LRScheduler`): learning rate scheduler\n            as native torch LRScheduler or ignite\'s parameter scheduler.\n        with_gpu_stats (bool, optional): if True, :class:`~ignite.contrib.metrics.handlers.GpuInfo` is attached to the\n            trainer. This requires `pynvml` package to be installed.\n        output_names (list/tuple, optional): list of names associated with `update_function` output dictionary.\n        with_pbars (bool, optional): if True, two progress bars on epochs and optionally on iterations are attached.\n            Default, True.\n        with_pbar_on_iters (bool, optional): if True, a progress bar on iterations is attached to the trainer.\n            Default, True.\n        log_every_iters (int, optional): logging interval for :class:`~ignite.contrib.metrics.handlers.GpuInfo` and for\n            epoch-wise progress bar. Default, 100.\n        stop_on_nan (bool, optional): if True, :class:`~ignite.handlers.TerminateOnNan` handler is added to the trainer.\n            Default, True.\n        clear_cuda_cache (bool, optional): if True, `torch.cuda.empty_cache()` is called every end of epoch.\n            Default, True.\n        device (str of torch.device, optional): deprecated argument, it will be removed in v0.5.0.\n    """"""\n    if device is not None:\n        warnings.warn(""Argument device is unused and deprecated. It will be removed in v0.5.0"")\n\n    kwargs = dict(\n        to_save=to_save,\n        save_every_iters=save_every_iters,\n        output_path=output_path,\n        lr_scheduler=lr_scheduler,\n        with_gpu_stats=with_gpu_stats,\n        output_names=output_names,\n        with_pbars=with_pbars,\n        with_pbar_on_iters=with_pbar_on_iters,\n        log_every_iters=log_every_iters,\n        stop_on_nan=stop_on_nan,\n        clear_cuda_cache=clear_cuda_cache,\n    )\n\n    if idist.get_world_size() > 1:\n        _setup_common_distrib_training_handlers(trainer, train_sampler=train_sampler, **kwargs)\n    else:\n        if train_sampler is not None and isinstance(train_sampler, DistributedSampler):\n            warnings.warn(\n                ""Argument train_sampler is a distributed sampler,""\n                "" but either there is no distributed setting or world size is < 2. ""\n                ""Train sampler argument will be ignored"",\n                UserWarning,\n            )\n        _setup_common_training_handlers(trainer, **kwargs)\n\n\nsetup_common_distrib_training_handlers = setup_common_training_handlers\n\n\ndef _setup_common_training_handlers(\n    trainer,\n    to_save=None,\n    save_every_iters=1000,\n    output_path=None,\n    lr_scheduler=None,\n    with_gpu_stats=False,\n    output_names=None,\n    with_pbars=True,\n    with_pbar_on_iters=True,\n    log_every_iters=100,\n    stop_on_nan=True,\n    clear_cuda_cache=True,\n):\n    if stop_on_nan:\n        trainer.add_event_handler(Events.ITERATION_COMPLETED, TerminateOnNan())\n\n    if lr_scheduler is not None:\n        if isinstance(lr_scheduler, torch.optim.lr_scheduler._LRScheduler):\n            trainer.add_event_handler(Events.ITERATION_COMPLETED, lambda engine: lr_scheduler.step())\n        elif isinstance(lr_scheduler, LRScheduler):\n            trainer.add_event_handler(Events.ITERATION_COMPLETED, lr_scheduler)\n        else:\n            trainer.add_event_handler(Events.ITERATION_STARTED, lr_scheduler)\n\n    if torch.cuda.is_available() and clear_cuda_cache:\n        trainer.add_event_handler(Events.EPOCH_COMPLETED, empty_cuda_cache)\n\n    if to_save is not None:\n        if output_path is None:\n            raise ValueError(""If to_save argument is provided then output_path argument should be also defined"")\n        checkpoint_handler = Checkpoint(\n            to_save, DiskSaver(dirname=output_path, require_empty=False), filename_prefix=""training"",\n        )\n        trainer.add_event_handler(Events.ITERATION_COMPLETED(every=save_every_iters), checkpoint_handler)\n\n    if with_gpu_stats:\n        GpuInfo().attach(trainer, name=""gpu"", event_name=Events.ITERATION_COMPLETED(every=log_every_iters))\n\n    if output_names is not None:\n\n        def output_transform(x, index, name):\n            if isinstance(x, Mapping):\n                return x[name]\n            elif isinstance(x, Sequence):\n                return x[index]\n            elif isinstance(x, (torch.Tensor, numbers.Number)):\n                return x\n            else:\n                raise ValueError(\n                    ""Unhandled type of update_function\'s output. ""\n                    ""It should either mapping or sequence, but given {}"".format(type(x))\n                )\n\n        for i, n in enumerate(output_names):\n            RunningAverage(output_transform=partial(output_transform, index=i, name=n), epoch_bound=False).attach(\n                trainer, n\n            )\n\n    if with_pbars:\n        if with_pbar_on_iters:\n            ProgressBar(persist=False).attach(\n                trainer, metric_names=""all"", event_name=Events.ITERATION_COMPLETED(every=log_every_iters)\n            )\n\n        ProgressBar(persist=True, bar_format="""").attach(\n            trainer, event_name=Events.EPOCH_STARTED, closing_event_name=Events.COMPLETED\n        )\n\n\ndef _setup_common_distrib_training_handlers(\n    trainer,\n    train_sampler=None,\n    to_save=None,\n    save_every_iters=1000,\n    output_path=None,\n    lr_scheduler=None,\n    with_gpu_stats=False,\n    output_names=None,\n    with_pbars=True,\n    with_pbar_on_iters=True,\n    log_every_iters=100,\n    stop_on_nan=True,\n    clear_cuda_cache=True,\n):\n\n    _setup_common_training_handlers(\n        trainer,\n        to_save=to_save,\n        output_path=output_path,\n        save_every_iters=save_every_iters,\n        lr_scheduler=lr_scheduler,\n        with_gpu_stats=with_gpu_stats,\n        output_names=output_names,\n        with_pbars=(idist.get_rank() == 0) and with_pbars,\n        with_pbar_on_iters=with_pbar_on_iters,\n        log_every_iters=log_every_iters,\n        stop_on_nan=stop_on_nan,\n        clear_cuda_cache=clear_cuda_cache,\n    )\n\n    if train_sampler is not None:\n        if not isinstance(train_sampler, DistributedSampler):\n            raise TypeError(""Train sampler should be torch DistributedSampler and have `set_epoch` method"")\n\n        @trainer.on(Events.EPOCH_STARTED)\n        def distrib_set_epoch(engine):\n            train_sampler.set_epoch(engine.state.epoch - 1)\n\n\ndef empty_cuda_cache(_):\n    torch.cuda.empty_cache()\n    import gc\n\n    gc.collect()\n\n\ndef setup_any_logging(logger, logger_module, trainer, optimizers, evaluators, log_every_iters):\n    raise DeprecationWarning(\n        ""ignite.contrib.engines.common.setup_any_logging is deprecated since 0.4.0. ""\n        ""Please use ignite.contrib.engines.common._setup_logging instead.""\n    )\n\n\ndef _setup_logging(logger, trainer, optimizers, evaluators, log_every_iters):\n    if optimizers is not None:\n        from torch.optim.optimizer import Optimizer\n\n        if not isinstance(optimizers, (Optimizer, Mapping)):\n            raise TypeError(""Argument optimizers should be either a single optimizer or a dictionary or optimizers"")\n\n    if evaluators is not None:\n        if not isinstance(evaluators, (Engine, Mapping)):\n            raise TypeError(""Argument evaluators should be either a single engine or a dictionary or engines"")\n\n    if log_every_iters is None:\n        log_every_iters = 1\n\n    logger.attach_output_handler(\n        trainer, event_name=Events.ITERATION_COMPLETED(every=log_every_iters), tag=""training"", metric_names=""all""\n    )\n\n    if optimizers is not None:\n        # Log optimizer parameters\n        if isinstance(optimizers, Optimizer):\n            optimizers = {None: optimizers}\n\n        for k, optimizer in optimizers.items():\n            logger.attach_opt_params_handler(\n                trainer, Events.ITERATION_STARTED(every=log_every_iters), optimizer, param_name=""lr"", tag=k\n            )\n\n    if evaluators is not None:\n        # Log evaluation metrics\n        if isinstance(evaluators, Engine):\n            evaluators = {""validation"": evaluators}\n\n        event_name = Events.ITERATION_COMPLETED if isinstance(logger, WandBLogger) else None\n        gst = global_step_from_engine(trainer, custom_event_name=event_name)\n        for k, evaluator in evaluators.items():\n            logger.attach_output_handler(\n                evaluator, event_name=Events.COMPLETED, tag=k, metric_names=""all"", global_step_transform=gst\n            )\n\n\ndef setup_tb_logging(output_path, trainer, optimizers=None, evaluators=None, log_every_iters=100, **kwargs):\n    """"""Method to setup TensorBoard logging on trainer and a list of evaluators. Logged metrics are:\n        - Training metrics, e.g. running average loss values\n        - Learning rate(s)\n        - Evaluation metrics\n\n    Args:\n        output_path (str): logging directory path\n        trainer (Engine): trainer engine\n        optimizers (torch.optim.Optimizer or dict of torch.optim.Optimizer, optional): single or dictionary of\n            torch optimizers. If a dictionary, keys are used as tags arguments for logging.\n        evaluators (Engine or dict of Engine, optional): single or dictionary of evaluators. If a dictionary,\n            keys are used as tags arguments for logging.\n        log_every_iters (int, optional): interval for loggers attached to iteration events. To log every iteration,\n            value can be set to 1 or None.\n        **kwargs: optional keyword args to be passed to construct the logger.\n\n    Returns:\n        TensorboardLogger\n    """"""\n    logger = TensorboardLogger(log_dir=output_path, **kwargs)\n    _setup_logging(logger, trainer, optimizers, evaluators, log_every_iters)\n    return logger\n\n\ndef setup_visdom_logging(trainer, optimizers=None, evaluators=None, log_every_iters=100, **kwargs):\n    """"""Method to setup Visdom logging on trainer and a list of evaluators. Logged metrics are:\n        - Training metrics, e.g. running average loss values\n        - Learning rate(s)\n        - Evaluation metrics\n\n    Args:\n        trainer (Engine): trainer engine\n        optimizers (torch.optim.Optimizer or dict of torch.optim.Optimizer, optional): single or dictionary of\n            torch optimizers. If a dictionary, keys are used as tags arguments for logging.\n        evaluators (Engine or dict of Engine, optional): single or dictionary of evaluators. If a dictionary,\n            keys are used as tags arguments for logging.\n        log_every_iters (int, optional): interval for loggers attached to iteration events. To log every iteration,\n            value can be set to 1 or None.\n        **kwargs: optional keyword args to be passed to construct the logger.\n\n    Returns:\n        VisdomLogger\n    """"""\n    logger = VisdomLogger(**kwargs)\n    _setup_logging(logger, trainer, optimizers, evaluators, log_every_iters)\n    return logger\n\n\ndef setup_mlflow_logging(trainer, optimizers=None, evaluators=None, log_every_iters=100, **kwargs):\n    """"""Method to setup MLflow logging on trainer and a list of evaluators. Logged metrics are:\n        - Training metrics, e.g. running average loss values\n        - Learning rate(s)\n        - Evaluation metrics\n\n    Args:\n        trainer (Engine): trainer engine\n        optimizers (torch.optim.Optimizer or dict of torch.optim.Optimizer, optional): single or dictionary of\n            torch optimizers. If a dictionary, keys are used as tags arguments for logging.\n        evaluators (Engine or dict of Engine, optional): single or dictionary of evaluators. If a dictionary,\n            keys are used as tags arguments for logging.\n        log_every_iters (int, optional): interval for loggers attached to iteration events. To log every iteration,\n            value can be set to 1 or None.\n        **kwargs: optional keyword args to be passed to construct the logger.\n\n    Returns:\n        MLflowLogger\n    """"""\n    logger = MLflowLogger(**kwargs)\n    _setup_logging(logger, trainer, optimizers, evaluators, log_every_iters)\n    return logger\n\n\ndef setup_neptune_logging(trainer, optimizers=None, evaluators=None, log_every_iters=100, **kwargs):\n    """"""Method to setup Neptune logging on trainer and a list of evaluators. Logged metrics are:\n        - Training metrics, e.g. running average loss values\n        - Learning rate(s)\n        - Evaluation metrics\n\n    Args:\n        trainer (Engine): trainer engine\n        optimizers (torch.optim.Optimizer or dict of torch.optim.Optimizer, optional): single or dictionary of\n            torch optimizers. If a dictionary, keys are used as tags arguments for logging.\n        evaluators (Engine or dict of Engine, optional): single or dictionary of evaluators. If a dictionary,\n            keys are used as tags arguments for logging.\n        log_every_iters (int, optional): interval for loggers attached to iteration events. To log every iteration,\n            value can be set to 1 or None.\n        **kwargs: optional keyword args to be passed to construct the logger.\n\n    Returns:\n        NeptuneLogger\n    """"""\n    logger = NeptuneLogger(**kwargs)\n    _setup_logging(logger, trainer, optimizers, evaluators, log_every_iters)\n    return logger\n\n\ndef setup_wandb_logging(trainer, optimizers=None, evaluators=None, log_every_iters=100, **kwargs):\n    """"""Method to setup WandB logging on trainer and a list of evaluators. Logged metrics are:\n        - Training metrics, e.g. running average loss values\n        - Learning rate(s)\n        - Evaluation metrics\n\n    Args:\n        trainer (Engine): trainer engine\n        optimizers (torch.optim.Optimizer or dict of torch.optim.Optimizer, optional): single or dictionary of\n            torch optimizers. If a dictionary, keys are used as tags arguments for logging.\n        evaluators (Engine or dict of Engine, optional): single or dictionary of evaluators. If a dictionary,\n            keys are used as tags arguments for logging.\n        log_every_iters (int, optional): interval for loggers attached to iteration events. To log every iteration,\n            value can be set to 1 or None.\n        **kwargs: optional keyword args to be passed to construct the logger.\n\n    Returns:\n        WandBLogger\n    """"""\n    logger = WandBLogger(**kwargs)\n    _setup_logging(logger, trainer, optimizers, evaluators, log_every_iters)\n    return logger\n\n\ndef setup_plx_logging(trainer, optimizers=None, evaluators=None, log_every_iters=100, **kwargs):\n    """"""Method to setup Polyaxon logging on trainer and a list of evaluators. Logged metrics are:\n        - Training metrics, e.g. running average loss values\n        - Learning rate(s)\n        - Evaluation metrics\n\n    Args:\n        trainer (Engine): trainer engine\n        optimizers (torch.optim.Optimizer or dict of torch.optim.Optimizer, optional): single or dictionary of\n            torch optimizers. If a dictionary, keys are used as tags arguments for logging.\n        evaluators (Engine or dict of Engine, optional): single or dictionary of evaluators. If a dictionary,\n            keys are used as tags arguments for logging.\n        log_every_iters (int, optional): interval for loggers attached to iteration events. To log every iteration,\n            value can be set to 1 or None.\n        **kwargs: optional keyword args to be passed to construct the logger.\n\n    Returns:\n        PolyaxonLogger\n    """"""\n    logger = PolyaxonLogger(**kwargs)\n    _setup_logging(logger, trainer, optimizers, evaluators, log_every_iters)\n    return logger\n\n\ndef setup_trains_logging(trainer, optimizers=None, evaluators=None, log_every_iters=100, **kwargs):\n    """"""Method to setup Trains logging on trainer and a list of evaluators. Logged metrics are:\n        - Training metrics, e.g. running average loss values\n        - Learning rate(s)\n        - Evaluation metrics\n\n    Args:\n        trainer (Engine): trainer engine\n        optimizers (torch.optim.Optimizer or dict of torch.optim.Optimizer, optional): single or dictionary of\n            torch optimizers. If a dictionary, keys are used as tags arguments for logging.\n        evaluators (Engine or dict of Engine, optional): single or dictionary of evaluators. If a dictionary,\n            keys are used as tags arguments for logging.\n        log_every_iters (int, optional): interval for loggers attached to iteration events. To log every iteration,\n            value can be set to 1 or None.\n        **kwargs: optional keyword args to be passed to construct the logger.\n\n    Returns:\n        TrainsLogger\n    """"""\n    logger = TrainsLogger(**kwargs)\n    _setup_logging(logger, trainer, optimizers, evaluators, log_every_iters)\n    return logger\n\n\ndef get_default_score_fn(metric_name):\n    def wrapper(engine):\n        score = engine.state.metrics[metric_name]\n        return score\n\n    return wrapper\n\n\ndef save_best_model_by_val_score(output_path, evaluator, model, metric_name, n_saved=3, trainer=None, tag=""val""):\n    """"""Method adds a handler to `evaluator` to save best models based on the score (named by `metric_name`)\n    provided by `evaluator`.\n\n    Args:\n        output_path (str): output path to indicate where to save best models\n        evaluator (Engine): evaluation engine used to provide the score\n        model (nn.Module): model to store\n        metric_name (str): metric name to use for score evaluation. This metric should be present in\n            `evaluator.state.metrics`.\n        n_saved (int, optional): number of best models to store\n        trainer (Engine, optional): trainer engine to fetch the epoch when saving the best model.\n        tag (str, optional): score name prefix: `{tag}_{metric_name}`. By default, tag is ""val"".\n\n    Returns:\n        A :class:`~ignite.handlers.checkpoint.Checkpoint` handler.\n    """"""\n    global_step_transform = None\n    if trainer is not None:\n        global_step_transform = global_step_from_engine(trainer)\n\n    best_model_handler = Checkpoint(\n        {""model"": model,},\n        DiskSaver(dirname=output_path, require_empty=False),\n        filename_prefix=""best"",\n        n_saved=n_saved,\n        global_step_transform=global_step_transform,\n        score_name=""{}_{}"".format(tag, metric_name.lower()),\n        score_function=get_default_score_fn(metric_name),\n    )\n    evaluator.add_event_handler(\n        Events.COMPLETED, best_model_handler,\n    )\n\n    return best_model_handler\n\n\ndef add_early_stopping_by_val_score(patience, evaluator, trainer, metric_name):\n    """"""Method setups early stopping handler based on the score (named by `metric_name`) provided by `evaluator`.\n\n    Args:\n        patience (int): number of events to wait if no improvement and then stop the training.\n        evaluator (Engine): evaluation engine used to provide the score\n        trainer (Engine): trainer engine to stop the run if no improvement.\n        metric_name (str): metric name to use for score evaluation. This metric should be present in\n            `evaluator.state.metrics`.\n\n    Returns:\n        A :class:`~ignite.handlers.early_stopping.EarlyStopping` handler.\n    """"""\n    es_handler = EarlyStopping(patience=patience, score_function=get_default_score_fn(metric_name), trainer=trainer)\n    evaluator.add_event_handler(Events.COMPLETED, es_handler)\n\n    return es_handler\n'"
ignite/contrib/engines/tbptt.py,5,"b'# coding: utf-8\n\nimport torch\n\nfrom ignite.engine import Engine, EventEnum, _prepare_batch\nfrom ignite.utils import apply_to_tensor\n\n\nclass Tbptt_Events(EventEnum):\n    """"""Aditional tbptt events.\n\n    Additional events for truncated backpropagation throught time dedicated\n    trainer.\n    """"""\n\n    TIME_ITERATION_STARTED = ""time_iteration_started""\n    TIME_ITERATION_COMPLETED = ""time_iteration_completed""\n\n\ndef _detach_hidden(hidden):\n    """"""Cut backpropagation graph.\n\n    Auxillary function to cut the backpropagation graph by detaching the hidden\n    vector.\n    """"""\n    return apply_to_tensor(hidden, torch.Tensor.detach)\n\n\ndef create_supervised_tbptt_trainer(\n    model, optimizer, loss_fn, tbtt_step, dim=0, device=None, non_blocking=False, prepare_batch=_prepare_batch\n):\n    """"""Create a trainer for truncated backprop through time supervised models.\n\n    Training recurrent model on long sequences is computationally intensive as\n    it requires to process the whole sequence before getting a gradient.\n    However, when the training loss is computed over many outputs\n    (`X to many <https://karpathy.github.io/2015/05/21/rnn-effectiveness/>`_),\n    there is an opportunity to compute a gradient over a subsequence. This is\n    known as\n    `truncated backpropagation through time <https://machinelearningmastery.com/\n    gentle-introduction-backpropagation-time/>`_.\n    This supervised trainer apply gradient optimization step every `tbtt_step`\n    time steps of the sequence, while backpropagating through the same\n    `tbtt_step` time steps.\n\n    Args:\n        model (`torch.nn.Module`): the model to train.\n        optimizer (`torch.optim.Optimizer`): the optimizer to use.\n        loss_fn (torch.nn loss function): the loss function to use.\n        tbtt_step (int): the length of time chunks (last one may be smaller).\n        dim (int): axis representing the time dimension.\n        device (str, optional): device type specification (default: None).\n            Applies to batches.\n        non_blocking (bool, optional): if True and this copy is between CPU and GPU,\n            the copy may occur asynchronously with respect to the host. For other cases,\n            this argument has no effect.\n        prepare_batch (callable, optional): function that receives `batch`, `device`,\n            `non_blocking` and outputs tuple of tensors `(batch_x, batch_y)`.\n\n    .. warning::\n\n        The internal use of `device` has changed.\n        `device` will now *only* be used to move the input data to the correct device.\n        The `model` should be moved by the user before creating an optimizer.\n\n        For more information see:\n\n        * `PyTorch Documentation <https://pytorch.org/docs/stable/optim.html#constructing-it>`_\n        * `PyTorch\'s Explanation <https://github.com/pytorch/pytorch/issues/7844#issuecomment-503713840>`_\n\n    Returns:\n        Engine: a trainer engine with supervised update function.\n\n    """"""\n\n    def _update(engine, batch):\n        loss_list = []\n        hidden = None\n\n        x, y = batch\n        for batch_t in zip(x.split(tbtt_step, dim=dim), y.split(tbtt_step, dim=dim)):\n            x_t, y_t = prepare_batch(batch_t, device=device, non_blocking=non_blocking)\n            # Fire event for start of iteration\n            engine.fire_event(Tbptt_Events.TIME_ITERATION_STARTED)\n            # Forward, backward and\n            model.train()\n            optimizer.zero_grad()\n            if hidden is None:\n                y_pred_t, hidden = model(x_t)\n            else:\n                hidden = _detach_hidden(hidden)\n                y_pred_t, hidden = model(x_t, hidden)\n            loss_t = loss_fn(y_pred_t, y_t)\n            loss_t.backward()\n            optimizer.step()\n\n            # Setting state of engine for consistent behaviour\n            engine.state.output = loss_t.item()\n            loss_list.append(loss_t.item())\n\n            # Fire event for end of iteration\n            engine.fire_event(Tbptt_Events.TIME_ITERATION_COMPLETED)\n\n        # return average loss over the time splits\n        return sum(loss_list) / len(loss_list)\n\n    engine = Engine(_update)\n    engine.register_events(*Tbptt_Events)\n    return engine\n'"
ignite/contrib/handlers/__init__.py,0,"b'from ignite.contrib.handlers.custom_events import CustomPeriodicEvent\nfrom ignite.contrib.handlers.lr_finder import FastaiLRFinder\nfrom ignite.contrib.handlers.mlflow_logger import MLflowLogger\nfrom ignite.contrib.handlers.neptune_logger import NeptuneLogger\nfrom ignite.contrib.handlers.param_scheduler import (\n    ConcatScheduler,\n    CosineAnnealingScheduler,\n    LinearCyclicalScheduler,\n    LRScheduler,\n    ParamGroupScheduler,\n    PiecewiseLinear,\n    create_lr_scheduler_with_warmup,\n)\nfrom ignite.contrib.handlers.polyaxon_logger import PolyaxonLogger\nfrom ignite.contrib.handlers.tensorboard_logger import TensorboardLogger\nfrom ignite.contrib.handlers.time_profilers import BasicTimeProfiler\nfrom ignite.contrib.handlers.tqdm_logger import ProgressBar\nfrom ignite.contrib.handlers.trains_logger import TrainsLogger\nfrom ignite.contrib.handlers.visdom_logger import VisdomLogger\nfrom ignite.contrib.handlers.wandb_logger import WandBLogger\nfrom ignite.handlers import global_step_from_engine  # ref\n'"
ignite/contrib/handlers/base_logger.py,9,"b'import numbers\nimport warnings\nfrom abc import ABCMeta, abstractmethod\nfrom typing import Any, Mapping\n\nimport torch\n\nfrom ignite.engine import Engine, State\n\n\nclass BaseHandler(metaclass=ABCMeta):\n    @abstractmethod\n    def __call__(self, engine, logger, event_name):\n        pass\n\n\nclass BaseOptimizerParamsHandler(BaseHandler):\n    """"""\n    Base handler for logging optimizer parameters\n    """"""\n\n    def __init__(self, optimizer, param_name=""lr"", tag=None):\n        if not isinstance(optimizer, torch.optim.Optimizer):\n            raise TypeError(\n                ""Argument optimizer should be of type torch.optim.Optimizer, "" ""but given {}"".format(type(optimizer))\n            )\n\n        self.optimizer = optimizer\n        self.param_name = param_name\n        self.tag = tag\n\n\nclass BaseOutputHandler(BaseHandler):\n    """"""\n    Helper handler to log engine\'s output and/or metrics\n    """"""\n\n    def __init__(self, tag, metric_names=None, output_transform=None, global_step_transform=None):\n\n        if metric_names is not None:\n            if not (isinstance(metric_names, list) or (isinstance(metric_names, str) and metric_names == ""all"")):\n                raise TypeError(\n                    ""metric_names should be either a list or equal \'all\', "" ""got {} instead."".format(type(metric_names))\n                )\n\n        if output_transform is not None and not callable(output_transform):\n            raise TypeError(""output_transform should be a function, got {} instead."".format(type(output_transform)))\n\n        if output_transform is None and metric_names is None:\n            raise ValueError(""Either metric_names or output_transform should be defined"")\n\n        if global_step_transform is not None and not callable(global_step_transform):\n            raise TypeError(\n                ""global_step_transform should be a function, got {} instead."".format(type(global_step_transform))\n            )\n\n        if global_step_transform is None:\n\n            def global_step_transform(engine, event_name):\n                return engine.state.get_event_attrib_value(event_name)\n\n        self.tag = tag\n        self.metric_names = metric_names\n        self.output_transform = output_transform\n        self.global_step_transform = global_step_transform\n\n    def _setup_output_metrics(self, engine):\n        """"""Helper method to setup metrics to log\n        """"""\n        metrics = {}\n        if self.metric_names is not None:\n            if isinstance(self.metric_names, str) and self.metric_names == ""all"":\n                metrics = engine.state.metrics\n            else:\n                for name in self.metric_names:\n                    if name not in engine.state.metrics:\n                        warnings.warn(\n                            ""Provided metric name \'{}\' is missing ""\n                            ""in engine\'s state metrics: {}"".format(name, list(engine.state.metrics.keys()))\n                        )\n                        continue\n                    metrics[name] = engine.state.metrics[name]\n\n        if self.output_transform is not None:\n            output_dict = self.output_transform(engine.state.output)\n\n            if not isinstance(output_dict, dict):\n                output_dict = {""output"": output_dict}\n\n            metrics.update({name: value for name, value in output_dict.items()})\n        return metrics\n\n\nclass BaseWeightsScalarHandler(BaseHandler):\n    """"""\n    Helper handler to log model\'s weights as scalars.\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None):\n        if not isinstance(model, torch.nn.Module):\n            raise TypeError(""Argument model should be of type torch.nn.Module, "" ""but given {}"".format(type(model)))\n\n        if not callable(reduction):\n            raise TypeError(""Argument reduction should be callable, "" ""but given {}"".format(type(reduction)))\n\n        def _is_0D_tensor(t):\n            return isinstance(t, torch.Tensor) and t.ndimension() == 0\n\n        # Test reduction function on a tensor\n        o = reduction(torch.ones(4, 2))\n        if not (isinstance(o, numbers.Number) or _is_0D_tensor(o)):\n            raise ValueError(""Output of the reduction function should be a scalar, but got {}"".format(type(o)))\n\n        self.model = model\n        self.reduction = reduction\n        self.tag = tag\n\n\nclass BaseWeightsHistHandler(BaseHandler):\n    """"""\n    Helper handler to log model\'s weights as histograms.\n    """"""\n\n    def __init__(self, model, tag=None):\n        if not isinstance(model, torch.nn.Module):\n            raise TypeError(""Argument model should be of type torch.nn.Module, "" ""but given {}"".format(type(model)))\n\n        self.model = model\n        self.tag = tag\n\n\nclass BaseLogger(metaclass=ABCMeta):\n    """"""\n    Base logger handler. See implementations: TensorboardLogger, VisdomLogger, PolyaxonLogger, MLflowLogger, ...\n\n    """"""\n\n    def attach(self, engine, log_handler, event_name):\n        """"""Attach the logger to the engine and execute `log_handler` function at `event_name` events.\n\n        Args:\n            engine (Engine): engine object.\n            log_handler (callable): a logging handler to execute\n            event_name: event to attach the logging handler to. Valid events are from :class:`~ignite.engine.Events`\n                or any `event_name` added by :meth:`~ignite.engine.Engine.register_events`.\n\n        Returns:\n            :class:`~ignite.engine.RemovableEventHandle`, which can be used to remove the handler.\n        """"""\n        name = event_name\n\n        if name not in State.event_to_attr:\n            raise RuntimeError(""Unknown event name \'{}\'"".format(name))\n\n        return engine.add_event_handler(event_name, log_handler, self, name)\n\n    def attach_output_handler(self, engine: Engine, event_name: Any, *args: Any, **kwargs: Mapping):\n        """"""Shortcut method to attach `OutputHandler` to the logger.\n\n        Args:\n            engine (Engine): engine object.\n            event_name: event to attach the logging handler to. Valid events are from :class:`~ignite.engine.Events`\n                or any `event_name` added by :meth:`~ignite.engine.Engine.register_events`.\n            *args: args to initialize `OutputHandler`\n            **kwargs: kwargs to initialize `OutputHandler`\n\n        Returns:\n            :class:`~ignite.engine.RemovableEventHandle`, which can be used to remove the handler.\n        """"""\n        return self.attach(engine, self._create_output_handler(*args, **kwargs), event_name=event_name)\n\n    def attach_opt_params_handler(self, engine: Engine, event_name: Any, *args: Any, **kwargs: Mapping):\n        """"""Shortcut method to attach `OptimizerParamsHandler` to the logger.\n\n        Args:\n            engine (Engine): engine object.\n            event_name: event to attach the logging handler to. Valid events are from :class:`~ignite.engine.Events`\n                or any `event_name` added by :meth:`~ignite.engine.Engine.register_events`.\n            *args: args to initialize `OptimizerParamsHandler`\n            **kwargs: kwargs to initialize `OptimizerParamsHandler`\n\n        Returns:\n            :class:`~ignite.engine.RemovableEventHandle`, which can be used to remove the handler.\n        """"""\n        self.attach(engine, self._create_opt_params_handler(*args, **kwargs), event_name=event_name)\n\n    @abstractmethod\n    def _create_output_handler(self, engine, *args, **kwargs):\n        pass\n\n    @abstractmethod\n    def _create_opt_params_handler(self, *args, **kwargs):\n        pass\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type, value, traceback):\n        self.close()\n\n    def close(self):\n        pass\n'"
ignite/contrib/handlers/custom_events.py,0,"b'import warnings\n\nfrom ignite.engine import EventEnum, Events, State\n\n\nclass CustomPeriodicEvent:\n    """"""DEPRECATED. Use filtered events instead.\n    Handler to define a custom periodic events as a number of elapsed iterations/epochs\n    for an engine.\n\n    When custom periodic event is created and attached to an engine, the following events are fired:\n    1) K iterations is specified:\n    - `Events.ITERATIONS_<K>_STARTED`\n    - `Events.ITERATIONS_<K>_COMPLETED`\n\n    1) K epochs is specified:\n    - `Events.EPOCHS_<K>_STARTED`\n    - `Events.EPOCHS_<K>_COMPLETED`\n\n\n    Examples:\n\n    .. code-block:: python\n\n        from ignite.engine import Engine, Events\n        from ignite.contrib.handlers import CustomPeriodicEvent\n\n        # Let\'s define an event every 1000 iterations\n        cpe1 = CustomPeriodicEvent(n_iterations=1000)\n        cpe1.attach(trainer)\n\n        # Let\'s define an event every 10 epochs\n        cpe2 = CustomPeriodicEvent(n_epochs=10)\n        cpe2.attach(trainer)\n\n        @trainer.on(cpe1.Events.ITERATIONS_1000_COMPLETED)\n        def on_every_1000_iterations(engine):\n            # run a computation after 1000 iterations\n            # ...\n            print(engine.state.iterations_1000)\n\n        @trainer.on(cpe2.Events.EPOCHS_10_STARTED)\n        def on_every_10_epochs(engine):\n            # run a computation every 10 epochs\n            # ...\n            print(engine.state.epochs_10)\n\n\n    Args:\n        n_iterations (int, optional): number iterations of the custom periodic event\n        n_epochs (int, optional): number iterations of the custom periodic event. Argument is optional, but only one,\n            either n_iterations or n_epochs should defined.\n\n    """"""\n\n    def __init__(self, n_iterations=None, n_epochs=None):\n\n        warnings.warn(\n            ""CustomPeriodicEvent is deprecated since 0.4.0 and will be removed in 0.5.0. Use filtered events instead."",\n            DeprecationWarning,\n        )\n\n        if n_iterations is not None and (not isinstance(n_iterations, int) or n_iterations < 1):\n            raise ValueError(""Argument n_iterations should be positive integer number"")\n\n        if n_epochs is not None and (not isinstance(n_epochs, int) or n_epochs < 1):\n            raise ValueError(""Argument n_epochs should be positive integer number"")\n\n        if (n_iterations is None and n_epochs is None) or (n_iterations and n_epochs):\n            raise ValueError(""Either n_iterations or n_epochs should be defined"")\n\n        if n_iterations:\n            prefix = ""iterations""\n            self.state_attr = ""iteration""\n            self.period = n_iterations\n\n        if n_epochs:\n            prefix = ""epochs""\n            self.state_attr = ""epoch""\n            self.period = n_epochs\n\n        self.custom_state_attr = ""{}_{}"".format(prefix, self.period)\n        event_name = ""{}_{}"".format(prefix.upper(), self.period)\n        setattr(\n            self,\n            ""Events"",\n            EventEnum(""Events"", "" "".join([""{}_STARTED"".format(event_name), ""{}_COMPLETED"".format(event_name)])),\n        )\n\n        # Update State.event_to_attr\n        for e in self.Events:\n            State.event_to_attr[e] = self.custom_state_attr\n\n        # Create aliases\n        self._periodic_event_started = getattr(self.Events, ""{}_STARTED"".format(event_name))\n        self._periodic_event_completed = getattr(self.Events, ""{}_COMPLETED"".format(event_name))\n\n    def _on_started(self, engine):\n        setattr(engine.state, self.custom_state_attr, 0)\n\n    def _on_periodic_event_started(self, engine):\n        if getattr(engine.state, self.state_attr) % self.period == 1:\n            setattr(engine.state, self.custom_state_attr, getattr(engine.state, self.custom_state_attr) + 1)\n            engine.fire_event(self._periodic_event_started)\n\n    def _on_periodic_event_completed(self, engine):\n        if getattr(engine.state, self.state_attr) % self.period == 0:\n            engine.fire_event(self._periodic_event_completed)\n\n    def attach(self, engine):\n        engine.register_events(*self.Events)\n\n        engine.add_event_handler(Events.STARTED, self._on_started)\n        engine.add_event_handler(\n            getattr(Events, ""{}_STARTED"".format(self.state_attr.upper())), self._on_periodic_event_started\n        )\n        engine.add_event_handler(\n            getattr(Events, ""{}_COMPLETED"".format(self.state_attr.upper())), self._on_periodic_event_completed\n        )\n'"
ignite/contrib/handlers/lr_finder.py,6,"b'# coding: utf-8\nimport contextlib\nimport logging\nimport tempfile\nimport warnings\nfrom collections.abc import Mapping\nfrom pathlib import Path\n\nimport torch\nfrom torch.optim.lr_scheduler import _LRScheduler\n\nfrom ignite.contrib.handlers.param_scheduler import LRScheduler, PiecewiseLinear\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import Checkpoint\n\n\nclass FastaiLRFinder:\n    """"""Learning rate finder handler for supervised trainers.\n\n    While attached, the handler increases the learning rate in between two\n    boundaries in a linear or exponential manner. It provides valuable\n    information on how well the network can be trained over a range of learning\n    rates and what can be an optimal learning rate.\n\n    Examples:\n\n    .. code-block:: python\n\n        from ignite.contrib.handlers import FastaiLRFinder\n\n        trainer = ...\n        model = ...\n        optimizer = ...\n\n        lr_finder = FastaiLRFinder()\n        to_save = {""model"": model, ""optimizer"": optimizer}\n\n        with lr_finder.attach(trainer, to_save=to_save) as trainer_with_lr_finder:\n            trainer_with_lr_finder.run(dataloader)\n\n        # Get lr_finder results\n        lr_finder.get_results()\n\n        # Plot lr_finder results (requires matplotlib)\n        lr_finder.plot()\n\n        # get lr_finder suggestion for lr\n        lr_finder.lr_suggestion()\n\n\n    Note:\n        When context manager is exited all LR finder\'s handlers are removed.\n\n    Note:\n        Please, also keep in mind that all other handlers attached the trainer will be executed during LR finder\'s run.\n\n    Note:\n        This class may require `matplotlib` package to be installed to plot learning rate range test:\n\n        .. code-block:: bash\n\n            pip install matplotlib\n\n\n    References:\n\n        Cyclical Learning Rates for Training Neural Networks:\n        https://arxiv.org/abs/1506.01186\n\n        fastai/lr_find: https://github.com/fastai/fastai\n    """"""\n\n    def __init__(self):\n        self._diverge_flag = False\n        self._history = None\n        self._best_loss = None\n        self._lr_schedule = None\n        self.logger = logging.getLogger(__name__)\n\n    def _run(self, trainer, optimizer, output_transform, num_iter, end_lr, step_mode, smooth_f, diverge_th):\n\n        self._history = {""lr"": [], ""loss"": []}\n        self._best_loss = None\n        self._diverge_flag = False\n\n        # attach LRScheduler to trainer.\n        if num_iter is None:\n            num_iter = trainer.state.epoch_length * trainer.state.max_epochs\n        else:\n            max_iter = trainer.state.epoch_length * trainer.state.max_epochs\n            if num_iter > max_iter:\n                warnings.warn(\n                    ""Desired num_iter {} is unreachable with the current run setup of {} iteration ""\n                    ""({} epochs)"".format(num_iter, max_iter, trainer.state.max_epochs),\n                    UserWarning,\n                )\n\n        if not trainer.has_event_handler(self._reached_num_iterations):\n            trainer.add_event_handler(Events.ITERATION_COMPLETED, self._reached_num_iterations, num_iter)\n\n        # attach loss and lr logging\n        if not trainer.has_event_handler(self._log_lr_and_loss):\n            trainer.add_event_handler(\n                Events.ITERATION_COMPLETED, self._log_lr_and_loss, output_transform, smooth_f, diverge_th\n            )\n\n        self.logger.debug(""Running LR finder for {} iterations"".format(num_iter))\n        # Initialize the proper learning rate policy\n        if step_mode.lower() == ""exp"":\n            self._lr_schedule = LRScheduler(_ExponentialLR(optimizer, end_lr, num_iter))\n        else:\n            start_lr = optimizer.param_groups[0][""lr""]\n            self._lr_schedule = PiecewiseLinear(\n                optimizer, param_name=""lr"", milestones_values=[(0, start_lr), (num_iter, end_lr)]\n            )\n        if not trainer.has_event_handler(self._lr_schedule):\n            trainer.add_event_handler(Events.ITERATION_COMPLETED, self._lr_schedule, num_iter)\n\n    def _reset(self, trainer):\n        self.logger.debug(""Completed LR finder run"")\n        trainer.remove_event_handler(self._lr_schedule, Events.ITERATION_COMPLETED)\n        trainer.remove_event_handler(self._log_lr_and_loss, Events.ITERATION_COMPLETED)\n        trainer.remove_event_handler(self._reached_num_iterations, Events.ITERATION_COMPLETED)\n\n    def _log_lr_and_loss(self, trainer, output_transform, smooth_f, diverge_th):\n        output = trainer.state.output\n        loss = output_transform(output)\n        lr = self._lr_schedule.get_param()\n        self._history[""lr""].append(lr)\n        if trainer.state.iteration == 1:\n            self._best_loss = loss\n        else:\n            if smooth_f > 0:\n                loss = smooth_f * loss + (1 - smooth_f) * self._history[""loss""][-1]\n            if loss < self._best_loss:\n                self._best_loss = loss\n        self._history[""loss""].append(loss)\n\n        # Check if the loss has diverged; if it has, stop the trainer\n        if self._history[""loss""][-1] > diverge_th * self._best_loss:\n            self._diverge_flag = True\n            self.logger.info(""Stopping early, the loss has diverged"")\n            trainer.terminate()\n\n    def _reached_num_iterations(self, trainer, num_iter):\n        if trainer.state.iteration > num_iter:\n            trainer.terminate()\n\n    def _warning(self, _):\n        if not self._diverge_flag:\n            warnings.warn(\n                ""Run completed without loss diverging, increase end_lr, decrease diverge_th or look""\n                "" at lr_finder.plot()"",\n                UserWarning,\n            )\n\n    def _detach(self, trainer):\n        """"""\n        Detaches lr_finder from trainer.\n\n        Args:\n            trainer: the trainer to detach form.\n        """"""\n\n        if trainer.has_event_handler(self._run, Events.STARTED):\n            trainer.remove_event_handler(self._run, Events.STARTED)\n        if trainer.has_event_handler(self._warning, Events.COMPLETED):\n            trainer.remove_event_handler(self._warning, Events.COMPLETED)\n        if trainer.has_event_handler(self._reset, Events.COMPLETED):\n            trainer.remove_event_handler(self._reset, Events.COMPLETED)\n\n    def get_results(self):\n        """"""\n        Returns: dictionary with loss and lr logs fromm the previous run\n        """"""\n        return self._history\n\n    def plot(self, skip_start=10, skip_end=5, log_lr=True):\n        """"""Plots the learning rate range test.\n\n        This method requires `matplotlib` package to be installed:\n\n        .. code-block:: bash\n\n            pip install matplotlib\n\n        Args:\n            skip_start (int, optional): number of batches to trim from the start.\n                Default: 10.\n            skip_end (int, optional): number of batches to trim from the start.\n                Default: 5.\n            log_lr (bool, optional): True to plot the learning rate in a logarithmic\n                scale; otherwise, plotted in a linear scale. Default: True.\n        """"""\n        try:\n            from matplotlib import pyplot as plt\n        except ImportError:\n            raise RuntimeError(\n                ""This method requires matplotlib to be installed. ""\n                ""Please install it with command: \\n pip install matplotlib""\n            )\n\n        if self._history is None:\n            raise RuntimeError(""learning rate finder didn\'t run yet so results can\'t be plotted"")\n\n        if skip_start < 0:\n            raise ValueError(""skip_start cannot be negative"")\n        if skip_end < 0:\n            raise ValueError(""skip_end cannot be negative"")\n\n        # Get the data to plot from the history dictionary. Also, handle skip_end=0\n        # properly so the behaviour is the expected\n\n        lrs = self._history[""lr""]\n        losses = self._history[""loss""]\n        if skip_end == 0:\n            lrs = lrs[skip_start:]\n            losses = losses[skip_start:]\n        else:\n            lrs = lrs[skip_start:-skip_end]\n            losses = losses[skip_start:-skip_end]\n\n        # Plot loss as a function of the learning rate\n        plt.plot(lrs, losses)\n        if log_lr:\n            plt.xscale(""log"")\n        plt.xlabel(""Learning rate"")\n        plt.ylabel(""Loss"")\n        plt.show()\n\n    def lr_suggestion(self):\n        """"""\n        Returns: learning rate at the minimum numerical gradient\n        """"""\n        if self._history is None:\n            raise RuntimeError(""learning rate finder didn\'t run yet so lr_suggestion can\'t be returned"")\n        loss = self._history[""loss""]\n        grads = torch.tensor([loss[i] - loss[i - 1] for i in range(1, len(loss))])\n        min_grad_idx = grads.argmin() + 1\n        return self._history[""lr""][int(min_grad_idx)]\n\n    @contextlib.contextmanager\n    def attach(\n        self,\n        trainer,\n        to_save,\n        output_transform=lambda output: output,\n        num_iter=None,\n        end_lr=10.0,\n        step_mode=""exp"",\n        smooth_f=0.05,\n        diverge_th=5.0,\n    ):\n        """"""Attaches lr_finder to a given trainer. It also resets model and optimizer at the end of the run.\n\n        Usage:\n\n        .. code-block:: python\n\n            to_save = {""model"": model, ""optimizer"": optimizer}\n            with lr_finder.attach(trainer, to_save=to_save) as trainer_with_lr_finder:\n                trainer_with_lr_finder.run(dataloader)`\n\n        Args:\n            trainer (Engine): lr_finder is attached to this trainer. Please, keep in mind that all attached handlers\n                will be executed.\n            to_save (Mapping): dictionary with optimizer and other objects that needs to be restored after running\n                the LR finder. For example, `to_save={\'optimizer\': optimizer, \'model\': model}`. All objects should\n                implement `state_dict` and `load_state_dict` methods.\n            output_transform (callable, optional): function that transforms the trainer\'s `state.output` after each\n                iteration. It must return the loss of that iteration.\n            num_iter (int, optional): number of iterations for lr schedule between base lr and end_lr. Default, it will\n                run for `trainer.state.epoch_length * trainer.state.max_epochs`.\n            end_lr (float, optional): upper bound for lr search. Default, 10.0.\n            step_mode (str, optional): ""exp"" or ""linear"", which way should the lr be increased from optimizer\'s initial\n                lr to `end_lr`. Default, ""exp"".\n            smooth_f (float, optional): loss smoothing factor in range `[0, 1)`. Default, 0.05\n            diverge_th (float, optional): Used for stopping the search when `current loss > diverge_th * best_loss`.\n                Default, 5.0.\n\n        Notes:\n            lr_finder cannot be attached to more than one trainer at a time\n\n        Returns:\n            trainer_with_lr_finder: trainer used for finding the lr\n        """"""\n        if not isinstance(to_save, Mapping):\n            raise TypeError(""Argument to_save should be a mapping, but given {}"".format(type(to_save)))\n\n        Checkpoint._check_objects(to_save, ""state_dict"")\n        Checkpoint._check_objects(to_save, ""load_state_dict"")\n\n        if ""optimizer"" not in to_save:\n            raise ValueError(""Mapping to_save should contain \'optimizer\' key"")\n\n        if not isinstance(to_save[""optimizer""], torch.optim.Optimizer):\n            raise ValueError(\n                ""Object to_save[\'optimizer\'] should be torch optimizer, but given {}"".format(type(to_save[""optimizer""]))\n            )\n\n        if smooth_f < 0 or smooth_f >= 1:\n            raise ValueError(""smooth_f is outside the range [0, 1]"")\n        if diverge_th < 1:\n            raise ValueError(""diverge_th should be larger than 1"")\n        if step_mode not in [""exp"", ""linear""]:\n            raise ValueError(""step_mode should be \'exp\' or \'linear\', but given {}"".format(step_mode))\n        if num_iter is not None and (not isinstance(num_iter, int) or num_iter <= 0):\n            raise ValueError(""if provided, num_iter should be a positive integer, but given {}"".format(num_iter))\n\n        # store to_save\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            obj = {k: o.state_dict() for k, o in to_save.items()}\n            # add trainer\n            obj[""trainer""] = trainer.state_dict()\n            cache_filepath = Path(tmpdirname) / ""ignite_lr_finder_cache.pt""\n            torch.save(obj, cache_filepath.as_posix())\n\n            optimizer = to_save[""optimizer""]\n            # Attach handlers\n            if not trainer.has_event_handler(self._run):\n                trainer.add_event_handler(\n                    Events.STARTED,\n                    self._run,\n                    optimizer,\n                    output_transform,\n                    num_iter,\n                    end_lr,\n                    step_mode,\n                    smooth_f,\n                    diverge_th,\n                )\n            if not trainer.has_event_handler(self._warning):\n                trainer.add_event_handler(Events.COMPLETED, self._warning)\n            if not trainer.has_event_handler(self._reset):\n                trainer.add_event_handler(Events.COMPLETED, self._reset)\n\n            yield trainer\n            self._detach(trainer)\n            # restore to_save and reset trainer\'s state\n            obj = torch.load(cache_filepath.as_posix())\n            trainer.load_state_dict(obj[""trainer""])\n            for k, o in obj.items():\n                if k in to_save:\n                    to_save[k].load_state_dict(o)\n\n\nclass _ExponentialLR(_LRScheduler):\n    """"""Exponentially increases the learning rate between two boundaries over a number of\n    iterations.\n\n    Arguments:\n        optimizer (torch.optim.Optimizer): wrapped optimizer.\n        end_lr (float, optional): the initial learning rate which is the lower\n            boundary of the test. Default: 10.\n        num_iter (int, optional): the number of iterations over which the test\n            occurs. Default: 100.\n        last_epoch (int): the index of last epoch. Default: -1.\n\n    """"""\n\n    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n        self.end_lr = end_lr\n        self.num_iter = num_iter\n        super(_ExponentialLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        curr_iter = self.last_epoch + 1\n        r = curr_iter / self.num_iter\n        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n'"
ignite/contrib/handlers/mlflow_logger.py,6,"b'import numbers\nimport warnings\n\nimport torch\n\nfrom ignite.contrib.handlers.base_logger import BaseLogger, BaseOptimizerParamsHandler, BaseOutputHandler\nfrom ignite.handlers import global_step_from_engine\n\n__all__ = [""MLflowLogger"", ""OutputHandler"", ""OptimizerParamsHandler"", ""global_step_from_engine""]\n\n\nclass OutputHandler(BaseOutputHandler):\n    """"""Helper handler to log engine\'s output and/or metrics.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.mlflow_logger import *\n\n            # Create a logger\n            mlflow_logger = MLflowLogger()\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer`:\n            mlflow_logger.attach(\n                evaluator,\n                log_handler=OutputHandler(\n                    tag=""validation"",\n                    metric_names=[""nll"", ""accuracy""],\n                    global_step_transform=global_step_from_engine(trainer)\n                ),\n                event_name=Events.EPOCH_COMPLETED\n            )\n            # or equivalently\n            mlflow_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)\n            )\n\n        Another example, where model is evaluated every 500 iterations:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.mlflow_logger import *\n\n            @trainer.on(Events.ITERATION_COMPLETED(every=500))\n            def evaluate(engine):\n                evaluator.run(validation_set, max_epochs=1)\n\n            mlflow_logger = MLflowLogger()\n\n            def global_step_transform(*args, **kwargs):\n                return trainer.state.iteration\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we\n            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time\n            # evaluator metrics are plotted on MLflow.\n\n            mlflow_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metrics=[""nll"", ""accuracy""],\n                global_step_transform=global_step_transform\n            )\n\n    Args:\n        tag (str): common title for all produced plots. For example, \'training\'\n        metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n            metrics.\n        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.\n            For example, `output_transform = lambda output: output`\n            This function can also return a dictionary, e.g `{\'loss\': loss1, \'another_loss\': loss2}` to label the plot\n            with corresponding keys.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided,\n            uses function output as global_step. To setup global step from another engine, please use\n            :meth:`~ignite.contrib.handlers.mlflow_logger.global_step_from_engine`.\n\n    Note:\n\n        Example of `global_step_transform`:\n\n        .. code-block:: python\n\n            def global_step_transform(engine, event_name):\n                return engine.state.get_event_attrib_value(event_name)\n\n    """"""\n\n    def __init__(self, tag, metric_names=None, output_transform=None, global_step_transform=None):\n        super(OutputHandler, self).__init__(tag, metric_names, output_transform, global_step_transform)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, MLflowLogger):\n            raise RuntimeError(""Handler \'OutputHandler\' works only with MLflowLogger"")\n\n        metrics = self._setup_output_metrics(engine)\n\n        global_step = self.global_step_transform(engine, event_name)\n\n        if not isinstance(global_step, int):\n            raise TypeError(\n                ""global_step must be int, got {}.""\n                "" Please check the output of global_step_transform."".format(type(global_step))\n            )\n\n        rendered_metrics = {}\n        for key, value in metrics.items():\n            if isinstance(value, numbers.Number):\n                rendered_metrics[""{} {}"".format(self.tag, key)] = value\n            elif isinstance(value, torch.Tensor) and value.ndimension() == 0:\n                rendered_metrics[""{} {}"".format(self.tag, key)] = value.item()\n            elif isinstance(value, torch.Tensor) and value.ndimension() == 1:\n                for i, v in enumerate(value):\n                    rendered_metrics[""{} {} {}"".format(self.tag, key, i)] = v.item()\n            else:\n                warnings.warn(""MLflowLogger output_handler can not log "" ""metrics value type {}"".format(type(value)))\n\n        # Additionally recheck metric names as MLflow rejects non-valid names with MLflowException\n        from mlflow.utils.validation import _VALID_PARAM_AND_METRIC_NAMES\n\n        for key in list(rendered_metrics.keys()):\n            if not _VALID_PARAM_AND_METRIC_NAMES.match(key):\n                warnings.warn(\n                    ""MLflowLogger output_handler encountered an invalid metric name \'{}\' that ""\n                    ""will be ignored and not logged to MLflow"".format(key)\n                )\n                del rendered_metrics[key]\n\n        logger.log_metrics(rendered_metrics, step=global_step)\n\n\nclass OptimizerParamsHandler(BaseOptimizerParamsHandler):\n    """"""Helper handler to log optimizer parameters\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.mlflow_logger import *\n\n            # Create a logger\n            mlflow_logger = MLflowLogger()\n            # Optionally, user can specify tracking_uri with corresponds to MLFLOW_TRACKING_URI\n            # mlflow_logger = MLflowLogger(tracking_uri=""uri"")\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            mlflow_logger.attach(\n                trainer,\n                log_handler=OptimizerParamsHandler(optimizer),\n                event_name=Events.ITERATION_STARTED\n            )\n            # or equivalently\n            mlflow_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer\n            )\n\n    Args:\n        optimizer (torch.optim.Optimizer): torch optimizer which parameters to log\n        param_name (str): parameter name\n        tag (str, optional): common title for all produced plots. For example, \'generator\'\n    """"""\n\n    def __init__(self, optimizer, param_name=""lr"", tag=None):\n        super(OptimizerParamsHandler, self).__init__(optimizer, param_name, tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, MLflowLogger):\n            raise RuntimeError(""Handler OptimizerParamsHandler works only with MLflowLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{} "".format(self.tag) if self.tag else """"\n        params = {\n            ""{}{} group_{}"".format(tag_prefix, self.param_name, i): float(param_group[self.param_name])\n            for i, param_group in enumerate(self.optimizer.param_groups)\n        }\n\n        logger.log_metrics(params, step=global_step)\n\n\nclass MLflowLogger(BaseLogger):\n    """"""\n    `MLflow <https://mlflow.org>`_ tracking client handler to log parameters and metrics during the training\n    and validation.\n\n    This class requires `mlflow package <https://github.com/mlflow/mlflow/>`_ to be installed:\n\n    .. code-block:: bash\n\n        pip install mlflow\n\n    Args:\n        tracking_uri (str): MLflow tracking uri. See MLflow docs for more details\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.mlflow_logger import *\n\n            # Create a logger\n            mlflow_logger = MLflowLogger()\n\n            # Log experiment parameters:\n            mlflow_logger.log_params({\n                ""seed"": seed,\n                ""batch_size"": batch_size,\n                ""model"": model.__class__.__name__,\n\n                ""pytorch version"": torch.__version__,\n                ""ignite version"": ignite.__version__,\n                ""cuda version"": torch.version.cuda,\n                ""device name"": torch.cuda.get_device_name(0)\n            })\n\n            # Attach the logger to the trainer to log training loss at each iteration\n            mlflow_logger.attach_output_handler(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                tag=""training"",\n                output_transform=lambda loss: {\'loss\': loss}\n            )\n\n            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch\n            # We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer` instead of `train_evaluator`.\n            mlflow_logger.attach_output_handler(\n                train_evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""training"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer),\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the\n            # `trainer` instead of `evaluator`.\n            mlflow_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)),\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            mlflow_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer,\n                param_name=\'lr\'  # optional\n            )\n    """"""\n\n    def __init__(self, tracking_uri=None):\n        try:\n            import mlflow\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires mlflow to be installed. ""\n                ""Please install it with command: \\n pip install mlflow""\n            )\n\n        if tracking_uri is not None:\n            mlflow.set_tracking_uri(tracking_uri)\n\n        self.active_run = mlflow.active_run()\n        if self.active_run is None:\n            self.active_run = mlflow.start_run()\n\n    def __getattr__(self, attr):\n\n        import mlflow\n\n        return getattr(mlflow, attr)\n\n    def close(self):\n        import mlflow\n\n        mlflow.end_run()\n\n    def _create_output_handler(self, *args, **kwargs):\n        return OutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        return OptimizerParamsHandler(*args, **kwargs)\n'"
ignite/contrib/handlers/neptune_logger.py,10,"b'import numbers\nimport tempfile\nimport warnings\nfrom typing import Mapping, Optional\n\nimport torch\n\nimport ignite\nimport ignite.distributed as idist\nfrom ignite.contrib.handlers.base_logger import (\n    BaseLogger,\n    BaseOptimizerParamsHandler,\n    BaseOutputHandler,\n    BaseWeightsScalarHandler,\n)\nfrom ignite.handlers import global_step_from_engine\nfrom ignite.handlers.checkpoint import BaseSaveHandler\n\n__all__ = [\n    ""NeptuneLogger"",\n    ""NeptuneSaver"",\n    ""OptimizerParamsHandler"",\n    ""OutputHandler"",\n    ""WeightsScalarHandler"",\n    ""GradsScalarHandler"",\n    ""global_step_from_engine"",\n]\n\n\nclass OutputHandler(BaseOutputHandler):\n    """"""Helper handler to log engine\'s output and/or metrics\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.neptune_logger import *\n\n            # Create a logger\n            # We are using the api_token for the anonymous user neptuner but you can use your own.\n\n            npt_logger = NeptuneLogger(\n                api_token=""ANONYMOUS"",\n                project_name=""shared/pytorch-ignite-integration"",\n                experiment_name=""cnn-mnist"", # Optional,\n                params={""max_epochs"": 10}, # Optional,\n                tags=[""pytorch-ignite"",""minst""] # Optional\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer`:\n            npt_logger.attach(\n                evaluator,\n                log_handler=OutputHandler(\n                    tag=""validation"",\n                    metric_names=[""nll"", ""accuracy""],\n                    global_step_transform=global_step_from_engine(trainer)\n                ),\n                event_name=Events.EPOCH_COMPLETED\n            )\n            # or equivalently\n            npt_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)\n            )\n\n        Another example, where model is evaluated every 500 iterations:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.neptune_logger import *\n\n            @trainer.on(Events.ITERATION_COMPLETED(every=500))\n            def evaluate(engine):\n                evaluator.run(validation_set, max_epochs=1)\n\n            # We are using the api_token for the anonymous user neptuner but you can use your own.\n\n            npt_logger = NeptuneLogger(\n                api_token=""ANONYMOUS"",\n                project_name=""shared/pytorch-ignite-integration"",\n                experiment_name=""cnn-mnist"", # Optional,\n                params={""max_epochs"": 10}, # Optional,\n                tags=[""pytorch-ignite"", ""minst""] # Optional\n            )\n\n            def global_step_transform(*args, **kwargs):\n                return trainer.state.iteration\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we\n            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time\n            # evaluator metrics are plotted on NeptuneML.\n\n            npt_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metrics=[""nll"", ""accuracy""],\n                global_step_transform=global_step_transform\n            )\n\n    Args:\n        tag (str): common title for all produced plots. For example, ""training""\n        metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n            metrics.\n        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.\n            For example, `output_transform = lambda output: output`\n            This function can also return a dictionary, e.g `{""loss"": loss1, ""another_loss"": loss2}` to label the plot\n            with corresponding keys.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided,\n            uses function output as global_step. To setup global step from another engine, please use\n            :meth:`~ignite.contrib.handlers.neptune_logger.global_step_from_engine`.\n\n    Note:\n\n        Example of `global_step_transform`:\n\n        .. code-block:: python\n\n            def global_step_transform(engine, event_name):\n                return engine.state.get_event_attrib_value(event_name)\n\n    """"""\n\n    def __init__(self, tag, metric_names=None, output_transform=None, global_step_transform=None):\n        super(OutputHandler, self).__init__(tag, metric_names, output_transform, global_step_transform)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, NeptuneLogger):\n            raise RuntimeError(""Handler OutputHandler works only with NeptuneLogger"")\n\n        metrics = self._setup_output_metrics(engine)\n\n        global_step = self.global_step_transform(engine, event_name)\n\n        if not isinstance(global_step, int):\n            raise TypeError(\n                ""global_step must be int, got {}.""\n                "" Please check the output of global_step_transform."".format(type(global_step))\n            )\n\n        for key, value in metrics.items():\n            if isinstance(value, numbers.Number) or isinstance(value, torch.Tensor) and value.ndimension() == 0:\n                logger.log_metric(""{}/{}"".format(self.tag, key), x=global_step, y=value)\n            elif isinstance(value, torch.Tensor) and value.ndimension() == 1:\n                for i, v in enumerate(value):\n                    logger.log_metric(""{}/{}/{}"".format(self.tag, key, i), x=global_step, y=v.item())\n            else:\n                warnings.warn(""NeptuneLogger output_handler can not log metrics value type {}"".format(type(value)))\n\n\nclass OptimizerParamsHandler(BaseOptimizerParamsHandler):\n    """"""Helper handler to log optimizer parameters\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.neptune_logger import *\n\n            # Create a logger\n            # We are using the api_token for the anonymous user neptuner but you can use your own.\n\n            npt_logger = NeptuneLogger(\n                api_token=""ANONYMOUS"",\n                project_name=""shared/pytorch-ignite-integration"",\n                experiment_name=""cnn-mnist"", # Optional,\n                params={""max_epochs"": 10}, # Optional,\n                tags=[""pytorch-ignite"",""minst""] # Optional\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            npt_logger.attach(\n                trainer,\n                log_handler=OptimizerParamsHandler(optimizer),\n                event_name=Events.ITERATION_STARTED\n            )\n            # or equivalently\n            npt_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer\n            )\n\n    Args:\n        optimizer (torch.optim.Optimizer): torch optimizer which parameters to log\n        param_name (str): parameter name\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n    """"""\n\n    def __init__(self, optimizer, param_name=""lr"", tag=None):\n        super(OptimizerParamsHandler, self).__init__(optimizer, param_name, tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, NeptuneLogger):\n            raise RuntimeError(""Handler OptimizerParamsHandler works only with NeptuneLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        params = {\n            ""{}{}/group_{}"".format(tag_prefix, self.param_name, i): float(param_group[self.param_name])\n            for i, param_group in enumerate(self.optimizer.param_groups)\n        }\n\n        for k, v in params.items():\n            logger.log_metric(k, x=global_step, y=v)\n\n\nclass WeightsScalarHandler(BaseWeightsScalarHandler):\n    """"""Helper handler to log model\'s weights as scalars.\n    Handler iterates over named parameters of the model, applies reduction function to each parameter\n    produce a scalar and then logs the scalar.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.neptune_logger import *\n\n            # Create a logger\n            # We are using the api_token for the anonymous user neptuner but you can use your own.\n\n            npt_logger = NeptuneLogger(\n                api_token=""ANONYMOUS"",\n                project_name=""shared/pytorch-ignite-integration"",\n                experiment_name=""cnn-mnist"", # Optional,\n                params={""max_epochs"": 10}, # Optional,\n                tags=[""pytorch-ignite"",""minst""] # Optional\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            npt_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsScalarHandler(model, reduction=torch.norm)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        reduction (callable): function to reduce parameters into scalar\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None):\n        super(WeightsScalarHandler, self).__init__(model, reduction, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, NeptuneLogger):\n            raise RuntimeError(""Handler WeightsScalarHandler works only with NeptuneLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            name = name.replace(""."", ""/"")\n            logger.log_metric(\n                ""{}weights_{}/{}"".format(tag_prefix, self.reduction.__name__, name),\n                x=global_step,\n                y=self.reduction(p.data),\n            )\n\n\nclass GradsScalarHandler(BaseWeightsScalarHandler):\n    """"""Helper handler to log model\'s gradients as scalars.\n    Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter\n    produce a scalar and then logs the scalar.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.neptune_logger import *\n\n            # Create a logger\n            # We are using the api_token for the anonymous user neptuner but you can use your own.\n\n            npt_logger = NeptuneLogger(\n                api_token=""ANONYMOUS"",\n                project_name=""shared/pytorch-ignite-integration"",\n                experiment_name=""cnn-mnist"", # Optional,\n                params={""max_epochs"": 10}, # Optional,\n                tags=[""pytorch-ignite"",""minst""] # Optional\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            npt_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=GradsScalarHandler(model, reduction=torch.norm)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        reduction (callable): function to reduce parameters into scalar\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None):\n        super(GradsScalarHandler, self).__init__(model, reduction, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, NeptuneLogger):\n            raise RuntimeError(""Handler GradsScalarHandler works only with NeptuneLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            name = name.replace(""."", ""/"")\n            logger.log_metric(\n                ""{}grads_{}/{}"".format(tag_prefix, self.reduction.__name__, name),\n                x=global_step,\n                y=self.reduction(p.grad),\n            )\n\n\nclass NeptuneLogger(BaseLogger):\n    """"""\n    `Neptune <https://neptune.ai/>`_ handler to log metrics, model/optimizer parameters, gradients during the training\n    and validation. It can also log model checkpoints to Neptune server.\n\n    .. code-block:: bash\n\n        pip install neptune-client\n\n    Args:\n        api_token (str | None): Required in online mode. Neputne API token, found on https://neptune.ai.\n            Read how to get your API key\n            https://docs.neptune.ai/python-api/tutorials/get-started.html#copy-api-token.\n        project_name (str): Required in online mode. Qualified name of a project in a form of\n           ""namespace/project_name"" for example ""tom/minst-classification"".\n           If None, the value of NEPTUNE_PROJECT environment variable will be taken.\n           You need to create the project in https://neptune.ai first.\n        offline_mode (bool): Optional default False. If offline_mode=True no logs will be send to neptune.\n           Usually used for debug purposes.\n        experiment_name (str, optional): Optional. Editable name of the experiment.\n           Name is displayed in the experiment\xe2\x80\x99s Details (Metadata section) and in experiments view as a column.\n        upload_source_files (list, optional): Optional. List of source files to be uploaded.\n           Must be list of str or single str. Uploaded sources are displayed in the experiment\xe2\x80\x99s Source code tab.\n           If None is passed, Python file from which experiment was created will be uploaded.\n           Pass empty list (`[]`) to upload no files. Unix style pathname pattern expansion is supported.\n           For example, you can pass `*.py` to upload all python source files from the current directory.\n           For recursion lookup use `**/*.py` (for Python 3.5 and later). For more information see glob library.\n        params (dict, optional): Optional. Parameters of the experiment. After experiment creation params are read-only.\n           Parameters are displayed in the experiment\xe2\x80\x99s Parameters section and each key-value pair can be\n           viewed in experiments view as a column.\n        properties (dict, optional): Optional default is `{}`. Properties of the experiment.\n           They are editable after experiment is created. Properties are displayed in the experiment\xe2\x80\x99s Details and\n           each key-value pair can be viewed in experiments view as a column.\n        tags (list, optional): Optional default `[]`. Must be list of str. Tags of the experiment.\n           Tags are displayed in the experiment\xe2\x80\x99s Details and can be viewed in experiments view as a column.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.neptune_logger import *\n\n            # Create a logger\n            # We are using the api_token for the anonymous user neptuner but you can use your own.\n\n            npt_logger = NeptuneLogger(\n                api_token=""ANONYMOUS"",\n                project_name=""shared/pytorch-ignite-integration"",\n                experiment_name=""cnn-mnist"", # Optional,\n                params={""max_epochs"": 10}, # Optional,\n                tags=[""pytorch-ignite"",""minst""] # Optional\n            )\n\n            # Attach the logger to the trainer to log training loss at each iteration\n            npt_logger.attach_output_handler(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                tag=""training"",\n                output_transform=lambda loss: {\'loss\': loss}\n            )\n\n            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch\n            # We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer` instead of `train_evaluator`.\n            npt_logger.attach_output_handler(\n                train_evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""training"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer),\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the\n            # `trainer` instead of `evaluator`.\n            npt_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)),\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            npt_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer,\n                param_name=\'lr\'  # optional\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            npt_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsScalarHandler(model)\n            )\n\n        Explore an experiment with neptune tracking here:\n        https://ui.neptune.ai/o/shared/org/pytorch-ignite-integration/e/PYTOR1-18/charts\n        You can save model checkpoints to a Neptune server:\n\n        .. code-block:: python\n\n            from ignite.handlers import Checkpoint\n\n            def score_function(engine):\n                return engine.state.metrics[""accuracy""]\n\n            to_save = {""model"": model}\n            handler = Checkpoint(\n                to_save,\n                NeptuneSaver(npt_logger), n_saved=2,\n                filename_prefix=""best"",\n                score_function=score_function,\n                score_name=""validation_accuracy"",\n                global_step_transform=global_step_from_engine(trainer)\n            )\n            validation_evaluator.add_event_handler(Events.COMPLETED, handler)\n\n        It is also possible to use the logger as context manager:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.neptune_logger import *\n\n            # We are using the api_token for the anonymous user neptuner but you can use your own.\n\n            with NeptuneLogger(api_token=""ANONYMOUS"",\n                               project_name=""shared/pytorch-ignite-integration"",\n                               experiment_name=""cnn-mnist"", # Optional,\n                               params={""max_epochs"": 10}, # Optional,\n                               tags=[""pytorch-ignite"",""minst""] # Optional\n                               ) as npt_logger:\n\n                trainer = Engine(update_fn)\n                # Attach the logger to the trainer to log training loss at each iteration\n                npt_logger.attach_output_handler(\n                    trainer,\n                    event_name=Events.ITERATION_COMPLETED,\n                    tag=""training"",\n                    output_transform=lambda loss: {""loss"": loss}\n                )\n\n    """"""\n\n    def __getattr__(self, attr):\n\n        import neptune\n\n        return getattr(neptune, attr)\n\n    def __init__(self, *args, **kwargs):\n        try:\n            import neptune\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires neptune-client to be installed. ""\n                ""You may install neptune with command: \\n pip install neptune-client \\n""\n            )\n\n        if kwargs.get(""offline_mode"", False):\n            self.mode = ""offline""\n            neptune.init(project_qualified_name=""dry-run/project"", backend=neptune.OfflineBackend())\n        else:\n            self.mode = ""online""\n            neptune.init(api_token=kwargs.get(""api_token""), project_qualified_name=kwargs.get(""project_name""))\n\n        kwargs[""name""] = kwargs.pop(""experiment_name"", None)\n        self._experiment_kwargs = {\n            k: v for k, v in kwargs.items() if k not in [""api_token"", ""project_name"", ""offline_mode""]\n        }\n\n        self.experiment = neptune.create_experiment(**self._experiment_kwargs)\n\n    def close(self):\n        self.stop()\n\n    def _create_output_handler(self, *args, **kwargs):\n        return OutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        return OptimizerParamsHandler(*args, **kwargs)\n\n\nclass NeptuneSaver(BaseSaveHandler):\n    """"""Handler that saves input checkpoint to the Neptune server.\n\n    Args:\n        neptune_logger (ignite.contrib.handlers.neptune_logger.NeptuneLogger): an instance of\n            NeptuneLogger class.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.neptune_logger import *\n\n            # Create a logger\n            # We are using the api_token for the anonymous user neptuner but you can use your own.\n\n            npt_logger = NeptuneLogger(\n                api_token=""ANONYMOUS"",\n                project_name=""shared/pytorch-ignite-integration"",\n                experiment_name=""cnn-mnist"", # Optional,\n                params={""max_epochs"": 10}, # Optional,\n                tags=[""pytorch-ignite"",""minst""] # Optional\n            )\n\n            ...\n            evaluator = create_supervised_evaluator(model, metrics=metrics, ...)\n            ...\n\n            from ignite.handlers import Checkpoint\n\n            def score_function(engine):\n                return engine.state.metrics[""accuracy""]\n\n            to_save = {""model"": model}\n\n            # pass neptune logger to NeptuneServer\n\n            handler = Checkpoint(\n                to_save,\n                NeptuneSaver(npt_logger), n_saved=2,\n                filename_prefix=""best"", score_function=score_function,\n                score_name=""validation_accuracy"",\n                global_step_transform=global_step_from_engine(trainer)\n            )\n\n            evaluator.add_event_handler(Events.COMPLETED, handler)\n\n        # We need to close the logger when we are done\n            npt_logger.close()\n\n    For example, you can access model checkpoints and download them from here:\n    https://ui.neptune.ai/o/shared/org/pytorch-ignite-integration/e/PYTOR1-18/charts\n\n    """"""\n\n    @idist.one_rank_only()\n    def __init__(self, neptune_logger: NeptuneLogger):\n        self._logger = neptune_logger\n\n    @idist.one_rank_only()\n    def __call__(self, checkpoint: Mapping, filename: str, metadata: Optional[Mapping] = None) -> None:\n        # wont work on XLA\n\n        with tempfile.NamedTemporaryFile() as tmp:\n            # we can not use tmp.name to open tmp.file twice on Win32\n            # https://docs.python.org/3/library/tempfile.html#tempfile.NamedTemporaryFile\n            torch.save(checkpoint, tmp.file)\n            self._logger.log_artifact(tmp.name, filename)\n\n    @idist.one_rank_only(with_barrier=True)\n    def remove(self, filename: str) -> None:\n        self._logger.delete_artifacts(filename)\n'"
ignite/contrib/handlers/param_scheduler.py,28,"b'import math\nimport numbers\nimport tempfile\nfrom abc import ABCMeta, abstractmethod\nfrom collections import OrderedDict\nfrom collections.abc import Mapping, Sequence\nfrom copy import copy\nfrom pathlib import Path\nfrom typing import List, Optional, Union\n\nimport torch\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.optimizer import Optimizer\n\n\nclass ParamScheduler(metaclass=ABCMeta):\n    """"""An abstract class for updating an optimizer\'s parameter value during\n    training.\n\n    Args:\n        optimizer (`torch.optim.Optimizer`): optimizer\n        param_name (str): name of optimizer\'s parameter to update.\n        save_history (bool, optional): whether to log the parameter values to\n            `engine.state.param_history`, (default=False).\n        param_group_index (int, optional): optimizer\'s parameters group to use\n\n    Note:\n        Parameter scheduler works independently of the internal state of the attached optimizer.\n        More precisely, whatever the state of the optimizer (newly created or used by another scheduler) the scheduler\n        sets defined absolute values.\n\n    """"""\n\n    def __init__(self, optimizer, param_name, save_history=False, param_group_index=None):\n\n        if not isinstance(optimizer, Optimizer):\n            raise TypeError(""Argument optimizer should be torch.optim.Optimizer"")\n\n        self.optimizer = optimizer\n        self.param_group_index = param_group_index\n        self.param_name = param_name\n        self.save_history = save_history\n        self.event_index = 0\n        self._state_attrs = [""event_index"", ""param_name"", ""save_history"", ""param_group_index""]\n\n    def __call__(self, engine, name=None):\n\n        value = self.get_param()\n\n        if isinstance(value, list):\n            if len(value) != len(self.optimizer_param_groups):\n                raise RuntimeError(\n                    ""size of value is different than optimizer_param_groups {} != {}"".format(\n                        len(value), len(self.optimizer_param_groups)\n                    )\n                )\n\n            for i, param_group in enumerate(self.optimizer_param_groups):\n                param_group[self.param_name] = value[i]\n        else:\n            for i, param_group in enumerate(self.optimizer_param_groups):\n                param_group[self.param_name] = value\n\n        if name is None:\n            name = self.param_name\n\n        if self.save_history:\n            if not hasattr(engine.state, ""param_history"") or engine.state.param_history is None:\n                setattr(engine.state, ""param_history"", {})\n            engine.state.param_history.setdefault(name, [])\n            values = [pg[self.param_name] for pg in self.optimizer_param_groups]\n            engine.state.param_history[name].append(values)\n        self.event_index += 1\n\n    @property\n    def optimizer_param_groups(self):\n        if self.param_group_index is None:\n            return self.optimizer.param_groups\n        return [\n            self.optimizer.param_groups[self.param_group_index],\n        ]\n\n    def state_dict(self):\n        """"""Returns a dictionary containing a whole state of ParamScheduler.\n\n        Returns:\n            dict:\n                a dictionary containing a whole state of ParamScheduler\n        """"""\n        destination = OrderedDict()\n        for name in self._state_attrs:\n            if hasattr(self, name):\n                val = getattr(self, name)\n                if hasattr(val, ""state_dict""):\n                    val = val.state_dict()\n                destination[name] = copy(val)\n        return destination\n\n    def load_state_dict(self, state_dict):\n        """"""Copies parameters from :attr:`state_dict` into this ParamScheduler.\n\n        Args:\n            state_dict (dict): a dict containing parameters.\n        """"""\n        if not isinstance(state_dict, Mapping):\n            raise TypeError(""Argument state_dict should be a dictionary, but given {}"".format(type(state_dict)))\n\n        for name in self._state_attrs:\n            if name not in state_dict:\n                raise ValueError(\n                    ""Required state attribute \'{}\' is absent in provided state_dict \'{}\'"".format(\n                        name, state_dict.keys()\n                    )\n                )\n            val = state_dict[name]\n            obj = getattr(self, name)\n            if isinstance(val, Mapping) and hasattr(obj, ""load_state_dict""):\n                obj.load_state_dict(val)\n            else:\n                setattr(self, name, val)\n\n    @abstractmethod\n    def get_param(self) -> Union[List[float], float]:\n        """"""Method to get current optimizer\'s parameter values\n\n        Returns:\n            list of params, or scalar param\n        """"""\n        pass\n\n    @classmethod\n    def simulate_values(cls, num_events, **scheduler_kwargs):\n        """"""Method to simulate scheduled values during `num_events` events.\n\n        Args:\n            num_events (int): number of events during the simulation.\n            **scheduler_kwargs : parameter scheduler configuration kwargs.\n\n        Returns:\n            list of pairs: [event_index, value]\n\n        Examples:\n\n        .. code-block:: python\n\n            lr_values = np.array(LinearCyclicalScheduler.simulate_values(num_events=50, param_name=\'lr\',\n                                                                         start_value=1e-1, end_value=1e-3,\n                                                                         cycle_size=10))\n\n            plt.plot(lr_values[:, 0], lr_values[:, 1], label=""learning rate"")\n            plt.xlabel(""events"")\n            plt.ylabel(""values"")\n            plt.legend()\n\n        """"""\n        keys_to_remove = [""optimizer"", ""save_history""]\n        for key in keys_to_remove:\n            if key in scheduler_kwargs:\n                del scheduler_kwargs[key]\n        values = []\n        scheduler = cls(optimizer=_get_fake_optimizer(), save_history=False, **scheduler_kwargs)\n        for i in range(num_events):\n            scheduler(engine=None)\n            values.append([i, scheduler.optimizer_param_groups[0][scheduler.param_name]])\n        return values\n\n    @classmethod\n    def plot_values(cls, num_events, **scheduler_kwargs):\n        """"""Method to plot simulated scheduled values during `num_events` events.\n\n        This class requires `matplotlib package <https://matplotlib.org/>`_ to be installed:\n\n        .. code-block:: bash\n\n            pip install matplotlib\n\n        Args:\n            num_events (int): number of events during the simulation.\n            **scheduler_kwargs : parameter scheduler configuration kwargs.\n\n        Returns:\n            matplotlib.lines.Line2D\n\n        Examples:\n\n            .. code-block:: python\n\n                import matplotlib.pylab as plt\n\n                plt.figure(figsize=(10, 7))\n                LinearCyclicalScheduler.plot_values(num_events=50, param_name=\'lr\',\n                                                    start_value=1e-1, end_value=1e-3, cycle_size=10))\n        """"""\n        try:\n            import matplotlib.pylab as plt\n        except ImportError:\n            raise RuntimeError(\n                ""This method requires matplotlib to be installed. ""\n                ""Please install it with command: \\n pip install matplotlib""\n            )\n\n        values = cls.simulate_values(num_events=num_events, **scheduler_kwargs)\n        label = scheduler_kwargs.get(""param_name"", ""learning rate"")\n        ax = plt.plot([e for e, _ in values], [v for _, v in values], label=label)\n        plt.legend()\n        plt.grid(which=""both"")\n        return ax\n\n\nclass CyclicalScheduler(ParamScheduler):\n    """"""An abstract class for updating an optimizer\'s parameter value over a\n    cycle of some size.\n\n    Args:\n        optimizer (`torch.optim.Optimizer`): optimizer\n        param_name (str): name of optimizer\'s parameter to update.\n        start_value (float): value at start of cycle.\n        end_value (float): value at the middle of the cycle.\n        cycle_size (int): length of cycle, value should be larger than 1.\n        cycle_mult (float, optional): ratio by which to change the cycle_size.\n            at the end of each cycle (default=1.0).\n        start_value_mult (float, optional): ratio by which to change the start value at the\n            end of each cycle (default=1.0).\n        end_value_mult (float, optional): ratio by which to change the end value at the\n            end of each cycle (default=1.0).\n        save_history (bool, optional): whether to log the parameter values to\n            `engine.state.param_history`, (default=False).\n        param_group_index (int, optional): optimizer\'s parameters group to use.\n\n    Note:\n        If the scheduler is bound to an \'ITERATION_*\' event, \'cycle_size\' should\n        usually be the number of batches in an epoch.\n    """"""\n\n    def __init__(\n        self,\n        optimizer,\n        param_name,\n        start_value,\n        end_value,\n        cycle_size,\n        cycle_mult=1.0,\n        start_value_mult=1.0,\n        end_value_mult=1.0,\n        save_history=False,\n        param_group_index=None,\n    ):\n        super(CyclicalScheduler, self).__init__(\n            optimizer, param_name, save_history=save_history, param_group_index=param_group_index\n        )\n        self.start_value = start_value\n        self.end_value = end_value\n        self.cycle_size = int(cycle_size)  # Ensure cycle_size is integer\n        self.cycle_mult = cycle_mult\n        self.cycle = 0\n        self.start_value_mult = start_value_mult\n        self.end_value_mult = end_value_mult\n\n        if self.cycle_size < 2:\n            raise ValueError(\n                ""Argument cycle_size should be positive and larger than 1, "" ""but given {}"".format(cycle_size)\n            )\n\n        self._state_attrs += [\n            ""start_value"",\n            ""end_value"",\n            ""cycle_size"",\n            ""cycle_mult"",\n            ""cycle"",\n            ""start_value_mult"",\n            ""end_value_mult"",\n        ]\n\n    def __call__(self, engine, name=None):\n        if self.event_index != 0 and self.event_index % self.cycle_size == 0:\n            self.event_index = 0\n            self.cycle_size *= self.cycle_mult\n            self.cycle += 1\n            self.start_value *= self.start_value_mult\n            self.end_value *= self.end_value_mult\n\n        return super(CyclicalScheduler, self).__call__(engine, name)\n\n\nclass LinearCyclicalScheduler(CyclicalScheduler):\n    """"""Linearly adjusts param value to \'end_value\' for a half-cycle, then linearly\n    adjusts it back to \'start_value\' for a half-cycle.\n\n    Args:\n        optimizer (`torch.optim.Optimizer`): optimizer\n        param_name (str): name of optimizer\'s parameter to update.\n        start_value (float): value at start of cycle.\n        end_value (float): value at the middle of the cycle.\n        cycle_size (int): length of cycle.\n        cycle_mult (float, optional): ratio by which to change the cycle_size\n            at the end of each cycle (default=1).\n        start_value_mult (float, optional): ratio by which to change the start value at the\n            end of each cycle (default=1.0).\n        end_value_mult (float, optional): ratio by which to change the end value at the\n            end of each cycle (default=1.0).\n        save_history (bool, optional): whether to log the parameter values to\n            `engine.state.param_history`, (default=False).\n        param_group_index (int, optional): optimizer\'s parameters group to use.\n\n    Note:\n        If the scheduler is bound to an \'ITERATION_*\' event, \'cycle_size\' should\n        usually be the number of batches in an epoch.\n\n    Examples:\n\n    .. code-block:: python\n\n        from ignite.contrib.handlers.param_scheduler import LinearCyclicalScheduler\n\n        scheduler = LinearCyclicalScheduler(optimizer, \'lr\', 1e-3, 1e-1, len(train_loader))\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n        #\n        # Linearly increases the learning rate from 1e-3 to 1e-1 and back to 1e-3\n        # over the course of 1 epoch\n        #\n    """"""\n\n    def get_param(self):\n        cycle_progress = self.event_index / self.cycle_size\n        return self.end_value + (self.start_value - self.end_value) * abs(cycle_progress - 0.5) * 2\n\n\nclass CosineAnnealingScheduler(CyclicalScheduler):\n    """"""Anneals \'start_value\' to \'end_value\' over each cycle.\n\n    The annealing takes the form of the first half of a cosine\n    wave (as suggested in [Smith17]_).\n\n    Args:\n        optimizer (`torch.optim.Optimizer`): optimizer\n        param_name (str): name of optimizer\'s parameter to update.\n        start_value (float): value at start of cycle.\n        end_value (float): value at the end of the cycle.\n        cycle_size (int): length of cycle.\n        cycle_mult (float, optional): ratio by which to change the cycle_size\n            at the end of each cycle (default=1).\n        start_value_mult (float, optional): ratio by which to change the start value at the\n            end of each cycle (default=1.0).\n        end_value_mult (float, optional): ratio by which to change the end value at the\n            end of each cycle (default=1.0).\n        save_history (bool, optional): whether to log the parameter values to\n            `engine.state.param_history`, (default=False).\n        param_group_index (int, optional): optimizer\'s parameters group to use.\n\n    Note:\n        If the scheduler is bound to an \'ITERATION_*\' event, \'cycle_size\' should\n        usually be the number of batches in an epoch.\n\n    Examples:\n\n    .. code-block:: python\n\n        from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n\n        scheduler = CosineAnnealingScheduler(optimizer, \'lr\', 1e-1, 1e-3, len(train_loader))\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n        #\n        # Anneals the learning rate from 1e-1 to 1e-3 over the course of 1 epoch.\n        #\n\n    .. code-block:: python\n\n        from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n        from ignite.contrib.handlers.param_scheduler import LinearCyclicalScheduler\n\n        optimizer = SGD(\n            [\n                {""params"": model.base.parameters(), \'lr\': 0.001),\n                {""params"": model.fc.parameters(), \'lr\': 0.01),\n            ]\n        )\n\n        scheduler1 = LinearCyclicalScheduler(optimizer, \'lr\', 1e-7, 1e-5, len(train_loader), param_group_index=0)\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler1, ""lr (base)"")\n\n        scheduler2 = CosineAnnealingScheduler(optimizer, \'lr\', 1e-5, 1e-3, len(train_loader), param_group_index=1)\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler2, ""lr (fc)"")\n\n    .. [Smith17] Smith, Leslie N. ""Cyclical learning rates for training neural networks.""\n                 Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on. IEEE, 2017\n    """"""\n\n    def get_param(self):\n        """"""Method to get current optimizer\'s parameter value\n        """"""\n        cycle_progress = self.event_index / self.cycle_size\n        return self.start_value + ((self.end_value - self.start_value) / 2) * (1 - math.cos(math.pi * cycle_progress))\n\n\nclass ConcatScheduler(ParamScheduler):\n    """"""Concat a list of parameter schedulers.\n\n    The `ConcatScheduler` goes through a list of schedulers given by `schedulers`. Duration of each\n    scheduler is defined by `durations` list of integers.\n\n    Args:\n        schedulers (list of ParamScheduler): list of parameter schedulers.\n        durations (list of int): list of number of events that lasts a parameter scheduler from schedulers.\n        save_history (bool, optional): whether to log the parameter values to\n            `engine.state.param_history`, (default=False).\n\n    Examples:\n\n    .. code-block:: python\n\n        from ignite.contrib.handlers.param_scheduler import ConcatScheduler\n        from ignite.contrib.handlers.param_scheduler import LinearCyclicalScheduler\n        from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n\n        scheduler_1 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=0.1, end_value=0.5, cycle_size=60)\n        scheduler_2 = CosineAnnealingScheduler(optimizer, ""lr"", start_value=0.5, end_value=0.01, cycle_size=60)\n\n        combined_scheduler = ConcatScheduler(schedulers=[scheduler_1, scheduler_2], durations=[30, ])\n        trainer.add_event_handler(Events.ITERATION_STARTED, combined_scheduler)\n        #\n        # Sets the Learning rate linearly from 0.1 to 0.5 over 30 iterations. Then\n        # starts an annealing schedule from 0.5 to 0.01 over 60 iterations.\n        # The annealing cycles are repeated indefinitely.\n        #\n\n    """"""\n\n    def __init__(self, schedulers, durations, save_history=False):\n\n        if not isinstance(schedulers, Sequence) or len(schedulers) < 2:\n            raise ValueError(\n                ""Argument schedulers should be a sequence of more than one parameter schedulers, ""\n                ""but given {}"".format(schedulers)\n            )\n\n        if not isinstance(durations, Sequence) or not all([isinstance(t, numbers.Integral) for t in durations]):\n            raise ValueError(""Argument durations should be list/tuple of integers, "" ""but given {}"".format(durations))\n\n        if len(schedulers) != len(durations) + 1:\n            raise ValueError(\n                ""Incorrect number schedulers or duration values, ""\n                ""given {} and {}"".format(len(schedulers), len(durations))\n            )\n\n        for i, scheduler in enumerate(schedulers):\n            if not isinstance(scheduler, ParamScheduler):\n                raise TypeError(\n                    ""Value at index {} of schedulers should be a parameter scheduler, ""\n                    ""but given {}"".format(i, type(scheduler))\n                )\n\n        self.schedulers = schedulers\n        self.durations = durations\n\n        self.optimizer = self.schedulers[0].optimizer\n        if not (all(id(s.optimizer) == id(self.optimizer) for s in self.schedulers)):\n            raise ValueError(""schedulers should be related to same optimizer"")\n\n        # schedulers should have save_history sync with ParamGroupScheduler\n        for s in schedulers:\n            s.save_history = save_history\n\n        super(ConcatScheduler, self).__init__(optimizer=self.optimizer, param_name="""", save_history=save_history)\n\n        self._scheduler_index = 0\n        self._current_scheduler = None\n        self._current_duration = None\n        self._setup_scheduler()\n        self._state_attrs += [""_current_duration"", ""durations"", ""_scheduler_index""]\n\n    def state_dict(self):\n        """"""Returns a dictionary containing a whole state of ConcatScheduler.\n\n        Returns:\n            dict:\n                a dictionary containing a whole state of ConcatScheduler\n        """"""\n\n        state_dict = super(ConcatScheduler, self).state_dict()\n        state_dict[""schedulers""] = []\n        for s in self.schedulers:\n            state_dict[""schedulers""].append(s.state_dict())\n        return state_dict\n\n    def load_state_dict(self, state_dict):\n        """"""Copies parameters from :attr:`state_dict` into this ConcatScheduler.\n\n        Args:\n            state_dict (dict): a dict containing parameters.\n        """"""\n        if not isinstance(state_dict, Mapping):\n            raise TypeError(""Argument state_dict should be a dictionary, but given {}"".format(type(state_dict)))\n\n        if ""schedulers"" not in state_dict:\n            raise ValueError(\n                ""Required state attribute \'{}\' is absent in provided state_dict \'{}\'"".format(\n                    ""schedulers"", state_dict.keys()\n                )\n            )\n        sds = state_dict[""schedulers""]\n        if len(sds) != len(self.schedulers):\n            raise ValueError(\n                ""Input state_dict contains {} state_dicts of concatenated schedulers, ""\n                ""but {} needed"".format(len(sds), len(self.schedulers))\n            )\n\n        for s, sd in zip(self.schedulers, sds):\n            s.load_state_dict(sd)\n        super(ConcatScheduler, self).load_state_dict(state_dict)\n        self._setup_scheduler()\n\n    def _setup_scheduler(self):\n        self._current_scheduler = self.schedulers[self._scheduler_index]\n        self._current_duration = (\n            self.durations[self._scheduler_index] if self._scheduler_index < len(self.durations) else -1\n        )\n        self.param_name = self._current_scheduler.param_name\n        self.optimizer = self._current_scheduler.optimizer\n\n    def __call__(self, engine, name=None):\n        if self._current_duration == 0:\n            self._scheduler_index += 1\n            self._setup_scheduler()\n        self._current_scheduler(engine, name)\n        self._current_duration -= 1\n\n    @property\n    def optimizer_param_groups(self):\n        # We need to setup optimizer_param_groups as property\n        # to synchonize with the latest _current_scheduler and its internal optimizer_param_groups\n        return self._current_scheduler.optimizer_param_groups\n\n    @property\n    def save_history(self):\n        return self._current_scheduler.save_history\n\n    @save_history.setter\n    def save_history(self, value):\n        for s in self.schedulers:\n            s.save_history = value\n\n    def get_param(self):\n        return self._current_scheduler.get_param()\n\n    @classmethod\n    def simulate_values(cls, num_events, schedulers, durations, param_names=None, **kwargs):\n        """"""Method to simulate scheduled values during num_events events.\n\n        Args:\n            num_events (int): number of events during the simulation.\n            schedulers (list of ParamScheduler): list of parameter schedulers.\n            durations (list of int): list of number of events that lasts a parameter scheduler from schedulers.\n            param_names (list or tuple of str, optional): parameter name or list of parameter names to simulate values.\n                By default, the first scheduler\'s parameter name is taken.\n\n        Returns:\n            list of [event_index, value_0, value_1, ...], where values correspond to `param_names`.\n\n        """"""\n        if param_names is not None and not isinstance(param_names, (list, tuple)):\n            raise ValueError(""Argument param_names should be list or tuple of strings"")\n\n        # This scheduler uses `ParamScheduler` which\n        # should be replicated in order to simulate LR values and\n        # not perturb original scheduler.\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            cache_filepath = Path(tmpdirname) / ""ignite_lr_scheduler_cache.pt""\n            objs = {""lr_scheduler_{}"".format(i): s.state_dict() for i, s in enumerate(schedulers)}\n            # all schedulers should be related to the same optimizer\n            objs[""optimizer""] = schedulers[0].optimizer.state_dict()\n\n            torch.save(objs, cache_filepath.as_posix())\n\n            # do not save_history\n            for s in schedulers:\n                s.save_history = False\n\n            output = []\n            scheduler = cls(schedulers=schedulers, save_history=False, durations=durations, **kwargs)\n            if param_names is None:\n                param_names = [scheduler.param_name]\n            for i in range(num_events):\n                scheduler(engine=None)\n                values = [i]\n                for param_name in param_names:\n                    params = [p[param_name] for p in scheduler.optimizer_param_groups]\n                    values = values + params\n                output.append(values)\n\n            objs = torch.load(cache_filepath.as_posix())\n            for i, s in enumerate(schedulers):\n                s.load_state_dict(objs[""lr_scheduler_{}"".format(i)])\n                s.optimizer.load_state_dict(objs[""optimizer""])\n\n            return output\n\n\nclass LRScheduler(ParamScheduler):\n    """"""A wrapper class to call `torch.optim.lr_scheduler` objects as `ignite` handlers.\n\n    Args:\n        lr_scheduler (subclass of `torch.optim.lr_scheduler._LRScheduler`): lr_scheduler object to wrap.\n        save_history (bool, optional): whether to log the parameter values to\n            `engine.state.param_history`, (default=False).\n\n    .. code-block:: python\n\n        from ignite.contrib.handlers.param_scheduler import LRScheduler\n        from torch.optim.lr_scheduler import StepLR\n\n        step_scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n        scheduler = LRScheduler(step_scheduler)\n\n        # In this example, we assume to have installed PyTorch>=1.1.0\n        # (with new `torch.optim.lr_scheduler` behaviour) and\n        # we attach scheduler to Events.ITERATION_COMPLETED\n        # instead of Events.ITERATION_STARTED to make sure to use\n        # the first lr value from the optimizer, otherwise it is will be skipped:\n        trainer.add_event_handler(Events.ITERATION_COMPLETED, scheduler)\n    """"""\n\n    def __init__(self, lr_scheduler, save_history=False, **kwargs):\n\n        if not isinstance(lr_scheduler, _LRScheduler):\n            raise TypeError(\n                ""Argument lr_scheduler should be a subclass of torch.optim.lr_scheduler._LRScheduler, ""\n                ""but given {}"".format(type(lr_scheduler))\n            )\n\n        self.lr_scheduler = lr_scheduler\n        super(LRScheduler, self).__init__(\n            optimizer=self.lr_scheduler.optimizer, param_name=""lr"", save_history=save_history\n        )\n        self._state_attrs += [\n            ""lr_scheduler"",\n        ]\n\n    def __call__(self, engine, name=None):\n        self.lr_scheduler.last_epoch += 1\n        super(LRScheduler, self).__call__(engine, name)\n\n    def get_param(self) -> Union[float, List[float]]:\n        """"""Method to get current optimizer\'s parameter value\n        """"""\n        # Emulate context manager for pytorch>=1.4\n        self.lr_scheduler._get_lr_called_within_step = True\n        lr_list = self.lr_scheduler.get_lr()\n        self.lr_scheduler._get_lr_called_within_step = False\n        if len(lr_list) == 1:\n            return lr_list[0]\n        else:\n            return lr_list\n\n    @classmethod\n    def simulate_values(cls, num_events, lr_scheduler, **kwargs):\n        """"""Method to simulate scheduled values during num_events events.\n\n        Args:\n            num_events (int): number of events during the simulation.\n            lr_scheduler (subclass of `torch.optim.lr_scheduler._LRScheduler`): lr_scheduler object to wrap.\n\n        Returns:\n            list of pairs: [event_index, value]\n\n        """"""\n\n        if not isinstance(lr_scheduler, _LRScheduler):\n            raise TypeError(\n                ""Argument lr_scheduler should be a subclass of torch.optim.lr_scheduler._LRScheduler, ""\n                ""but given {}"".format(type(lr_scheduler))\n            )\n\n        # This scheduler uses `torch.optim.lr_scheduler._LRScheduler` which\n        # should be replicated in order to simulate LR values and\n        # not perturb original scheduler.\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            cache_filepath = Path(tmpdirname) / ""ignite_lr_scheduler_cache.pt""\n            obj = {\n                ""lr_scheduler"": lr_scheduler.state_dict(),\n                ""optimizer"": lr_scheduler.optimizer.state_dict(),\n            }\n            torch.save(obj, cache_filepath.as_posix())\n\n            values = []\n            scheduler = cls(save_history=False, lr_scheduler=lr_scheduler, **kwargs)\n            for i in range(num_events):\n                params = [p[scheduler.param_name] for p in scheduler.optimizer_param_groups]\n                values.append([i] + params)\n                scheduler(engine=None)\n\n            obj = torch.load(cache_filepath.as_posix())\n            lr_scheduler.load_state_dict(obj[""lr_scheduler""])\n            lr_scheduler.optimizer.load_state_dict(obj[""optimizer""])\n\n            return values\n\n\ndef create_lr_scheduler_with_warmup(\n    lr_scheduler,\n    warmup_start_value,\n    warmup_duration,\n    warmup_end_value=None,\n    save_history=False,\n    output_simulated_values=None,\n):\n    """"""\n    Helper method to create a learning rate scheduler with a linear warm-up.\n\n    Args:\n        lr_scheduler (ParamScheduler or subclass of `torch.optim.lr_scheduler._LRScheduler`): learning rate scheduler\n            after the warm-up.\n        warmup_start_value (float): learning rate start value of the warm-up phase.\n        warmup_duration (int): warm-up phase duration, number of events.\n        warmup_end_value (float): learning rate end value of the warm-up phase, (default=None). If None,\n             warmup_end_value is set to optimizer initial lr.\n        save_history (bool, optional): whether to log the parameter values to\n            `engine.state.param_history`, (default=False).\n        output_simulated_values (list, optional): optional output of simulated learning rate values.\n            If output_simulated_values is a list of None, e.g. `[None] * 100`, after the execution it will be filled\n            by 100 simulated learning rate values.\n\n    Returns:\n        ConcatScheduler: learning rate scheduler with linear warm-up.\n\n    Note:\n        If the first learning rate value provided by `lr_scheduler` is different from `warmup_end_value`, an additional\n        event is added after the warm-up phase such that the warm-up ends with `warmup_end_value` value and then\n        `lr_scheduler` provides its learning rate values as normally.\n\n    Examples:\n\n        .. code-block:: python\n\n            torch_lr_scheduler = ExponentialLR(optimizer=optimizer, gamma=0.98)\n            lr_values = [None] * 100\n            scheduler = create_lr_scheduler_with_warmup(torch_lr_scheduler,\n                                                        warmup_start_value=0.0,\n                                                        warmup_end_value=0.1,\n                                                        warmup_duration=10,\n                                                        output_simulated_values=lr_values)\n            lr_values = np.array(lr_values)\n            # Plot simulated values\n            plt.plot(lr_values[:, 0], lr_values[:, 1], label=""learning rate"")\n\n            # Attach to the trainer\n            trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n\n    """"""\n    if not isinstance(lr_scheduler, (ParamScheduler, _LRScheduler)):\n        raise TypeError(\n            ""Argument lr_scheduler should be a subclass of torch.optim.lr_scheduler._LRScheduler or ""\n            ""ParamScheduler, but given {}"".format(type(lr_scheduler))\n        )\n\n    if not (isinstance(warmup_duration, numbers.Integral) and warmup_duration > 1):\n        raise ValueError(""Argument warmup_duration should be at least 2 events, but given {}"".format(warmup_duration))\n\n    warmup_schedulers = []\n\n    for param_group_index, param_group in enumerate(lr_scheduler.optimizer.param_groups):\n\n        if warmup_end_value is None:\n            param_group_warmup_end_value = param_group[""lr""]\n        else:\n            param_group_warmup_end_value = warmup_end_value\n\n        milestones_values = [(0, warmup_start_value), (warmup_duration - 1, param_group_warmup_end_value)]\n\n        if isinstance(lr_scheduler, _LRScheduler):\n            init_lr = param_group[""lr""]\n\n            if init_lr != param_group_warmup_end_value:\n                milestones_values.append((warmup_duration, init_lr))\n\n            lr_scheduler = LRScheduler(lr_scheduler, save_history=save_history)\n        else:\n            init_lr = lr_scheduler.get_param()\n            if init_lr == param_group_warmup_end_value:\n                if warmup_duration > 2:\n                    d = (param_group_warmup_end_value - warmup_start_value) / (warmup_duration - 1)\n                    milestones_values[-1] = (warmup_duration - 2, param_group_warmup_end_value - d)\n                else:\n                    milestones_values.pop(-1)\n\n        warmup_scheduler = PiecewiseLinear(\n            lr_scheduler.optimizer,\n            param_name=""lr"",\n            milestones_values=milestones_values,\n            param_group_index=param_group_index,\n            save_history=save_history,\n        )\n\n        warmup_schedulers.append(warmup_scheduler)\n\n    warmup_scheduler = ParamGroupScheduler(warmup_schedulers, save_history=save_history)\n\n    schedulers = [warmup_scheduler, lr_scheduler]\n    durations = [\n        milestones_values[-1][0] + 1,\n    ]\n    combined_scheduler = ConcatScheduler(schedulers, durations=durations, save_history=save_history)\n\n    if output_simulated_values is not None:\n        if not isinstance(output_simulated_values, list):\n            raise TypeError(\n                ""Argument output_simulated_values should be a list of None, e.g. `[None] * 100`, ""\n                ""but given {}."".format(type(output_simulated_values))\n            )\n        num_events = len(output_simulated_values)\n        result = ConcatScheduler.simulate_values(num_events=num_events, schedulers=schedulers, durations=durations)\n        for i in range(num_events):\n            output_simulated_values[i] = result[i]\n    return combined_scheduler\n\n\nclass PiecewiseLinear(ParamScheduler):\n    """"""\n    Piecewise linear parameter scheduler\n\n    Args:\n        optimizer (`torch.optim.Optimizer`): optimizer.\n        param_name (str): name of optimizer\'s parameter to update.\n        milestones_values (list of tuples (int, float)): list of tuples (event index, parameter value)\n            represents milestones and parameter. Milestones should be increasing integers.\n        save_history (bool, optional): whether to log the parameter values to\n            `engine.state.param_history`, (default=False).\n        param_group_index (int, optional): optimizer\'s parameters group to use.\n\n    Returns:\n        PiecewiseLinear: piecewise linear scheduler\n\n\n    .. code-block:: python\n\n        scheduler = PiecewiseLinear(optimizer, ""lr"",\n                                    milestones_values=[(10, 0.5), (20, 0.45), (21, 0.3), (30, 0.1), (40, 0.1)])\n        # Attach to the trainer\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n        #\n        # Sets the learning rate to 0.5 over the first 10 iterations, then decreases linearly from 0.5 to 0.45 between\n        # 10th and 20th iterations. Next there is a jump to 0.3 at the 21st iteration and LR decreases linearly\n        # from 0.3 to 0.1 between 21st and 30th iterations and remains 0.1 until the end of the iterations.\n        #\n    """"""\n\n    def __init__(self, optimizer, param_name, milestones_values, save_history=False, param_group_index=None):\n        super(PiecewiseLinear, self).__init__(optimizer, param_name, save_history, param_group_index=param_group_index)\n\n        if not isinstance(milestones_values, Sequence) or len(milestones_values) < 1:\n            raise ValueError(\n                ""Argument milestones_values should be a list or tuple with at least one value, ""\n                ""but given {}"".format(type(milestones_values))\n            )\n\n        values = []\n        milestones = []\n        for pair in milestones_values:\n            if not isinstance(pair, Sequence) or len(pair) != 2:\n                raise ValueError(""Argument milestones_values should be a list of pairs (milestone, param_value)"")\n            if not isinstance(pair[0], numbers.Integral):\n                raise ValueError(""Value of a milestone should be integer, but given {}"".format(type(pair[0])))\n            if len(milestones) > 0 and pair[0] < milestones[-1]:\n                raise ValueError(\n                    ""Milestones should be increasing integers, but given {} is smaller ""\n                    ""than the previous milestone {}"".format(pair[0], milestones[-1])\n                )\n            milestones.append(pair[0])\n            values.append(pair[1])\n\n        self.values = values\n        self.milestones = milestones\n        self._index = 0\n        self._state_attrs += [""values"", ""milestones"", ""_index""]\n\n    def _get_start_end(self):\n        if self.milestones[0] > self.event_index:\n            return self.event_index - 1, self.event_index, self.values[0], self.values[0]\n        elif self.milestones[-1] <= self.event_index:\n            return (\n                self.event_index,\n                self.event_index + 1,\n                self.values[-1],\n                self.values[-1],\n            )\n        elif self.milestones[self._index] <= self.event_index < self.milestones[self._index + 1]:\n            return (\n                self.milestones[self._index],\n                self.milestones[self._index + 1],\n                self.values[self._index],\n                self.values[self._index + 1],\n            )\n        else:\n            self._index += 1\n            return self._get_start_end()\n\n    def get_param(self):\n        start_index, end_index, start_value, end_value = self._get_start_end()\n        return start_value + (end_value - start_value) * (self.event_index - start_index) / (end_index - start_index)\n\n\nclass ParamGroupScheduler(ParamScheduler):\n    """"""\n    Scheduler helper to group multiple schedulers into one.\n\n    Args:\n        schedulers (list/tuple of ParamScheduler): list/tuple of parameter schedulers.\n        names (list of str): list of names of schedulers.\n\n    .. code-block:: python\n\n        optimizer = SGD(\n            [\n                {""params"": model.base.parameters(), \'lr\': 0.001),\n                {""params"": model.fc.parameters(), \'lr\': 0.01),\n            ]\n        )\n\n        scheduler1 = LinearCyclicalScheduler(optimizer, \'lr\', 1e-7, 1e-5, len(train_loader), param_group_index=0)\n        scheduler2 = CosineAnnealingScheduler(optimizer, \'lr\', 1e-5, 1e-3, len(train_loader), param_group_index=1)\n        lr_schedulers = [scheduler1, scheduler2]\n        names = [""lr (base)"", ""lr (fc)""]\n\n        scheduler = ParamGroupScheduler(schedulers=lr_schedulers, names=names)\n        # Attach single scheduler to the trainer\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n\n    """"""\n\n    def __init__(self, schedulers: List[ParamScheduler], names: Optional[List[str]] = None, save_history=False):\n        if not (\n            isinstance(schedulers, Sequence) and all(isinstance(scheduler, ParamScheduler) for scheduler in schedulers)\n        ):\n            raise ValueError(""Argument schedulers should be a list/tuple of parameter schedulers"")\n\n        if names is None:\n            names = [s.param_name for s in schedulers]\n\n        if not (isinstance(names, (list, tuple)) and all(isinstance(n, str) for n in names)):\n            raise ValueError(""Argument names should be a list/tuple of parameter scheduler\'s names"")\n\n        if len(names) != len(schedulers):\n            raise ValueError(""{} should be equal {}"".format(len(schedulers), len(names)))\n\n        self.schedulers = schedulers\n        self.names = names\n\n        self.optimizer = self.schedulers[0].optimizer\n        if not (all(id(s.optimizer) == id(self.optimizer) for s in schedulers)):\n            raise ValueError(""schedulers should be related to same optimizer"")\n\n        # schedulers should have save_history sync with ParamGroupScheduler\n        for s in schedulers:\n            s.save_history = save_history\n\n        super(ParamGroupScheduler, self).__init__(optimizer=self.optimizer, param_name=""lr"", save_history=save_history)\n\n    def __call__(self, engine, name=None):\n        for scheduler, name in zip(self.schedulers, self.names):\n            scheduler(engine, name)\n\n    @property\n    def save_history(self):\n        return self.schedulers[0].save_history\n\n    @save_history.setter\n    def save_history(self, value):\n        for s in self.schedulers:\n            s.save_history = value\n\n    def get_param(self) -> Union[List[float], float]:\n        return [scheduler.get_param() for scheduler in self.schedulers]\n\n    def state_dict(self):\n        """"""Returns a dictionary containing a whole state of ParamGroupScheduler.\n\n        Returns:\n            dict:\n                a dictionary containing a whole state of ParamGroupScheduler\n        """"""\n        state_dict = OrderedDict()\n        state_dict[""schedulers""] = []\n        for n, s in zip(self.names, self.schedulers):\n            state_dict[""schedulers""].append((n, s.state_dict()))\n        return state_dict\n\n    def load_state_dict(self, state_dict):\n        """"""Copies parameters from :attr:`state_dict` into this ParamScheduler.\n\n        Args:\n            state_dict (dict): a dict containing parameters.\n        """"""\n        if not isinstance(state_dict, Mapping):\n            raise TypeError(""Argument state_dict should be a dictionary, but given {}"".format(type(state_dict)))\n\n        if ""schedulers"" not in state_dict:\n            raise ValueError(\n                ""Required state attribute \'{}\' is absent in provided state_dict \'{}\'"".format(\n                    ""schedulers"", state_dict.keys()\n                )\n            )\n        sds = state_dict[""schedulers""]\n        if len(sds) != len(self.schedulers):\n            raise ValueError(\n                ""Input state_dict contains {} state_dicts of param group schedulers, ""\n                ""but {} needed"".format(len(sds), len(self.schedulers))\n            )\n\n        for req_n, s, (n, sd) in zip(self.names, self.schedulers, sds):\n            if req_n != n:\n                raise ValueError(\n                    ""Name of scheduler from input state dict does not correspond to required one,""\n                    "" {} vs {}"".format(n, req_n)\n                )\n            s.load_state_dict(sd)\n\n    @classmethod\n    def simulate_values(cls, num_events, schedulers, **kwargs):\n        """"""Method to simulate scheduled values during num_events events.\n\n        Args:\n            num_events (int): number of events during the simulation.\n            lr_schedulers (subclass of `torch.optim.lr_scheduler._LRScheduler`): lr_scheduler object to wrap.\n\n        Returns:\n            list of pairs: [event_index, value]\n\n        """"""\n\n        # This scheduler uses `torch.optim.lr_scheduler._LRScheduler` which\n        # should be replicated in order to simulate LR values and\n        # not perturb original scheduler.\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            cache_filepath = Path(tmpdirname) / ""ignite_lr_scheduler_cache.pt""\n            objs = {""lr_scheduler_{}"".format(i): s.state_dict() for i, s in enumerate(schedulers)}\n            # all schedulers should be related to the same optimizer\n            objs[""optimizer""] = schedulers[0].optimizer.state_dict()\n\n            torch.save(objs, cache_filepath.as_posix())\n\n            values = []\n            scheduler = cls(schedulers=schedulers, **kwargs)\n            for i in range(num_events):\n                params = scheduler.get_param()\n                values.append([i] + params)\n                scheduler(engine=None)\n\n            objs = torch.load(cache_filepath.as_posix())\n            for i, s in enumerate(schedulers):\n                s.load_state_dict(objs[""lr_scheduler_{}"".format(i)])\n                s.optimizer.load_state_dict(objs[""optimizer""])\n\n            return values\n\n\ndef _get_fake_optimizer(optimizer_cls=None, **kwargs):\n    t = torch.zeros([1], requires_grad=True)\n    if optimizer_cls is None:\n        optimizer_cls = torch.optim.SGD\n        kwargs[""lr""] = 0.01\n    return optimizer_cls([t], **kwargs)\n'"
ignite/contrib/handlers/polyaxon_logger.py,6,"b'import numbers\nimport warnings\n\nimport torch\n\nfrom ignite.contrib.handlers.base_logger import BaseLogger, BaseOptimizerParamsHandler, BaseOutputHandler\nfrom ignite.handlers import global_step_from_engine\n\n__all__ = [""PolyaxonLogger"", ""OutputHandler"", ""OptimizerParamsHandler"", ""global_step_from_engine""]\n\n\nclass OutputHandler(BaseOutputHandler):\n    """"""Helper handler to log engine\'s output and/or metrics.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.polyaxon_logger import *\n\n            # Create a logger\n            plx_logger = PolyaxonLogger()\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer`:\n            plx_logger.attach(\n                evaluator,\n                log_handler=OutputHandler(\n                    tag=""validation"",\n                    metric_names=[""nll"", ""accuracy""],\n                    global_step_transform=global_step_from_engine(trainer)\n                ),\n                event_name=Events.EPOCH_COMPLETED\n            )\n            # or equivalently\n            plx_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)\n            )\n\n        Another example, where model is evaluated every 500 iterations:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.polyaxon_logger import *\n\n            @trainer.on(Events.ITERATION_COMPLETED(every=500))\n            def evaluate(engine):\n                evaluator.run(validation_set, max_epochs=1)\n\n            plx_logger = PolyaxonLogger()\n\n            def global_step_transform(*args, **kwargs):\n                return trainer.state.iteration\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we\n            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time\n            # evaluator metrics are plotted on Polyaxon.\n\n            plx_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metrics=[""nll"", ""accuracy""],\n                global_step_transform=global_step_transform\n            )\n\n    Args:\n        tag (str): common title for all produced plots. For example, ""training""\n        metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n            metrics.\n        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.\n            For example, `output_transform = lambda output: output`\n            This function can also return a dictionary, e.g `{""loss"": loss1, ""another_loss"": loss2}` to label the plot\n            with corresponding keys.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided,\n            uses function output as global_step. To setup global step from another engine, please use\n            :meth:`~ignite.contrib.handlers.polyaxon_logger.global_step_from_engine`.\n\n    Note:\n\n        Example of `global_step_transform`:\n\n        .. code-block:: python\n\n            def global_step_transform(engine, event_name):\n                return engine.state.get_event_attrib_value(event_name)\n\n    """"""\n\n    def __init__(self, tag, metric_names=None, output_transform=None, global_step_transform=None):\n        super(OutputHandler, self).__init__(tag, metric_names, output_transform, global_step_transform)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, PolyaxonLogger):\n            raise RuntimeError(""Handler \'OutputHandler\' works only with PolyaxonLogger"")\n\n        metrics = self._setup_output_metrics(engine)\n\n        global_step = self.global_step_transform(engine, event_name)\n\n        if not isinstance(global_step, int):\n            raise TypeError(\n                ""global_step must be int, got {}.""\n                "" Please check the output of global_step_transform."".format(type(global_step))\n            )\n\n        rendered_metrics = {""step"": global_step}\n        for key, value in metrics.items():\n            if isinstance(value, numbers.Number):\n                rendered_metrics[""{}/{}"".format(self.tag, key)] = value\n            elif isinstance(value, torch.Tensor) and value.ndimension() == 0:\n                rendered_metrics[""{}/{}"".format(self.tag, key)] = value.item()\n            elif isinstance(value, torch.Tensor) and value.ndimension() == 1:\n                for i, v in enumerate(value):\n                    rendered_metrics[""{}/{}/{}"".format(self.tag, key, i)] = v.item()\n            else:\n                warnings.warn(""PolyaxonLogger output_handler can not log "" ""metrics value type {}"".format(type(value)))\n\n        logger.log_metrics(**rendered_metrics)\n\n\nclass OptimizerParamsHandler(BaseOptimizerParamsHandler):\n    """"""Helper handler to log optimizer parameters\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.polyaxon_logger import *\n\n            # Create a logger\n            plx_logger = PolyaxonLogger()\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            plx_logger.attach(\n                trainer,\n                log_handler=OptimizerParamsHandler(optimizer),\n                event_name=Events.ITERATION_STARTED\n            )\n            # or equivalently\n            plx_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer\n            )\n\n    Args:\n        optimizer (torch.optim.Optimizer): torch optimizer which parameters to log\n        param_name (str): parameter name\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n    """"""\n\n    def __init__(self, optimizer, param_name=""lr"", tag=None):\n        super(OptimizerParamsHandler, self).__init__(optimizer, param_name, tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, PolyaxonLogger):\n            raise RuntimeError(""Handler OptimizerParamsHandler works only with PolyaxonLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        params = {\n            ""{}{}/group_{}"".format(tag_prefix, self.param_name, i): float(param_group[self.param_name])\n            for i, param_group in enumerate(self.optimizer.param_groups)\n        }\n        params[""step""] = global_step\n        logger.log_metrics(**params)\n\n\nclass PolyaxonLogger(BaseLogger):\n    """"""\n    `Polyaxon <https://polyaxon.com/>`_ tracking client handler to log parameters and metrics during the training\n    and validation.\n\n    This class requires `polyaxon-client <https://github.com/polyaxon/polyaxon-client/>`_ package to be installed:\n\n    .. code-block:: bash\n\n        pip install polyaxon-client\n\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.polyaxon_logger import *\n\n            # Create a logger\n            plx_logger = PolyaxonLogger()\n\n            # Log experiment parameters:\n            plx_logger.log_params(**{\n                ""seed"": seed,\n                ""batch_size"": batch_size,\n                ""model"": model.__class__.__name__,\n\n                ""pytorch version"": torch.__version__,\n                ""ignite version"": ignite.__version__,\n                ""cuda version"": torch.version.cuda,\n                ""device name"": torch.cuda.get_device_name(0)\n            })\n\n            # Attach the logger to the trainer to log training loss at each iteration\n            plx_logger.attach_output_handler(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                tag=""training"",\n                output_transform=lambda loss: {""loss"": loss}\n            )\n\n            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch\n            # We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer` instead of `train_evaluator`.\n            plx_logger.attach_output_handler(\n                train_evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""training"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer),\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the\n            # `trainer` instead of `evaluator`.\n            plx_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)),\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            plx_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer,\n                param_name=\'lr\'  # optional\n            )\n\n    Args:\n        *args: Positional arguments accepted from\n            `Experiment <https://docs.polyaxon.com/references/polyaxon-tracking-api/experiments/>`_.\n        **kwargs: Keyword arguments accepted from\n            `Experiment <https://docs.polyaxon.com/references/polyaxon-tracking-api/experiments/>`_.\n\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        try:\n            from polyaxon_client.tracking import Experiment\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires polyaxon-client to be installed. ""\n                ""Please install it with command: \\n pip install polyaxon-client""\n            )\n\n        self.experiment = Experiment(*args, **kwargs)\n\n    def __getattr__(self, attr):\n        return getattr(self.experiment, attr)\n\n    def _create_output_handler(self, *args, **kwargs):\n        return OutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        return OptimizerParamsHandler(*args, **kwargs)\n'"
ignite/contrib/handlers/tensorboard_logger.py,15,"b'import numbers\nimport warnings\n\nimport torch\n\nfrom ignite.contrib.handlers.base_logger import (\n    BaseLogger,\n    BaseOptimizerParamsHandler,\n    BaseOutputHandler,\n    BaseWeightsHistHandler,\n    BaseWeightsScalarHandler,\n)\nfrom ignite.handlers import global_step_from_engine\n\n__all__ = [\n    ""TensorboardLogger"",\n    ""OptimizerParamsHandler"",\n    ""OutputHandler"",\n    ""WeightsScalarHandler"",\n    ""WeightsHistHandler"",\n    ""GradsScalarHandler"",\n    ""GradsHistHandler"",\n    ""global_step_from_engine"",\n]\n\n\nclass OutputHandler(BaseOutputHandler):\n    """"""Helper handler to log engine\'s output and/or metrics\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            # Create a logger\n            tb_logger = TensorboardLogger(log_dir=""experiments/tb_logs"")\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer`:\n            tb_logger.attach(\n                evaluator,\n                log_handler=OutputHandler(\n                    tag=""validation"",\n                    metric_names=[""nll"", ""accuracy""],\n                    global_step_transform=global_step_from_engine(trainer)\n                ),\n                event_name=Events.EPOCH_COMPLETED\n            )\n            # or equivalently\n            tb_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)\n            )\n\n        Another example, where model is evaluated every 500 iterations:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            @trainer.on(Events.ITERATION_COMPLETED(every=500))\n            def evaluate(engine):\n                evaluator.run(validation_set, max_epochs=1)\n\n            tb_logger = TensorboardLogger(log_dir=""experiments/tb_logs"")\n\n            def global_step_transform(*args, **kwargs):\n                return trainer.state.iteration\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we\n            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time\n            # evaluator metrics are plotted on Tensorboard.\n\n            tb_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metrics=[""nll"", ""accuracy""],\n                global_step_transform=global_step_transform\n            )\n\n    Args:\n        tag (str): common title for all produced plots. For example, ""training""\n        metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n            metrics.\n        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.\n            For example, `output_transform = lambda output: output`\n            This function can also return a dictionary, e.g `{""loss"": loss1, ""another_loss"": loss2}` to label the plot\n            with corresponding keys.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided,\n            uses function output as global_step. To setup global step from another engine, please use\n            :meth:`~ignite.contrib.handlers.tensorboard_logger.global_step_from_engine`.\n\n    Note:\n\n        Example of `global_step_transform`:\n\n        .. code-block:: python\n\n            def global_step_transform(engine, event_name):\n                return engine.state.get_event_attrib_value(event_name)\n\n    """"""\n\n    def __init__(self, tag, metric_names=None, output_transform=None, global_step_transform=None):\n        super(OutputHandler, self).__init__(tag, metric_names, output_transform, global_step_transform)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, TensorboardLogger):\n            raise RuntimeError(""Handler \'OutputHandler\' works only with TensorboardLogger"")\n\n        metrics = self._setup_output_metrics(engine)\n\n        global_step = self.global_step_transform(engine, event_name)\n        if not isinstance(global_step, int):\n            raise TypeError(\n                ""global_step must be int, got {}.""\n                "" Please check the output of global_step_transform."".format(type(global_step))\n            )\n\n        for key, value in metrics.items():\n            if isinstance(value, numbers.Number) or isinstance(value, torch.Tensor) and value.ndimension() == 0:\n                logger.writer.add_scalar(""{}/{}"".format(self.tag, key), value, global_step)\n            elif isinstance(value, torch.Tensor) and value.ndimension() == 1:\n                for i, v in enumerate(value):\n                    logger.writer.add_scalar(""{}/{}/{}"".format(self.tag, key, i), v.item(), global_step)\n            else:\n                warnings.warn(""TensorboardLogger output_handler can not log metrics value type {}"".format(type(value)))\n\n\nclass OptimizerParamsHandler(BaseOptimizerParamsHandler):\n    """"""Helper handler to log optimizer parameters\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            # Create a logger\n            tb_logger = TensorboardLogger(log_dir=""experiments/tb_logs"")\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            tb_logger.attach(\n                trainer,\n                log_handler=OptimizerParamsHandler(optimizer),\n                event_name=Events.ITERATION_STARTED\n            )\n            # or equivalently\n            tb_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer\n            )\n\n    Args:\n        optimizer (torch.optim.Optimizer): torch optimizer which parameters to log\n        param_name (str): parameter name\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n    """"""\n\n    def __init__(self, optimizer, param_name=""lr"", tag=None):\n        super(OptimizerParamsHandler, self).__init__(optimizer, param_name, tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, TensorboardLogger):\n            raise RuntimeError(""Handler OptimizerParamsHandler works only with TensorboardLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        params = {\n            ""{}{}/group_{}"".format(tag_prefix, self.param_name, i): float(param_group[self.param_name])\n            for i, param_group in enumerate(self.optimizer.param_groups)\n        }\n\n        for k, v in params.items():\n            logger.writer.add_scalar(k, v, global_step)\n\n\nclass WeightsScalarHandler(BaseWeightsScalarHandler):\n    """"""Helper handler to log model\'s weights as scalars.\n    Handler iterates over named parameters of the model, applies reduction function to each parameter\n    produce a scalar and then logs the scalar.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            # Create a logger\n            tb_logger = TensorboardLogger(log_dir=""experiments/tb_logs"")\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            tb_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsScalarHandler(model, reduction=torch.norm)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        reduction (callable): function to reduce parameters into scalar\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None):\n        super(WeightsScalarHandler, self).__init__(model, reduction, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, TensorboardLogger):\n            raise RuntimeError(""Handler \'WeightsScalarHandler\' works only with TensorboardLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            name = name.replace(""."", ""/"")\n            logger.writer.add_scalar(\n                ""{}weights_{}/{}"".format(tag_prefix, self.reduction.__name__, name), self.reduction(p.data), global_step\n            )\n\n\nclass WeightsHistHandler(BaseWeightsHistHandler):\n    """"""Helper handler to log model\'s weights as histograms.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            # Create a logger\n            tb_logger = TensorboardLogger(log_dir=""experiments/tb_logs"")\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            tb_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsHistHandler(model)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n\n    """"""\n\n    def __init__(self, model, tag=None):\n        super(WeightsHistHandler, self).__init__(model, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, TensorboardLogger):\n            raise RuntimeError(""Handler \'WeightsHistHandler\' works only with TensorboardLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            name = name.replace(""."", ""/"")\n            logger.writer.add_histogram(\n                tag=""{}weights/{}"".format(tag_prefix, name),\n                values=p.data.detach().cpu().numpy(),\n                global_step=global_step,\n            )\n\n\nclass GradsScalarHandler(BaseWeightsScalarHandler):\n    """"""Helper handler to log model\'s gradients as scalars.\n    Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter\n    produce a scalar and then logs the scalar.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            # Create a logger\n            tb_logger = TensorboardLogger(log_dir=""experiments/tb_logs"")\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            tb_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=GradsScalarHandler(model, reduction=torch.norm)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        reduction (callable): function to reduce parameters into scalar\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None):\n        super(GradsScalarHandler, self).__init__(model, reduction, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, TensorboardLogger):\n            raise RuntimeError(""Handler \'GradsScalarHandler\' works only with TensorboardLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            name = name.replace(""."", ""/"")\n            logger.writer.add_scalar(\n                ""{}grads_{}/{}"".format(tag_prefix, self.reduction.__name__, name), self.reduction(p.grad), global_step\n            )\n\n\nclass GradsHistHandler(BaseWeightsHistHandler):\n    """"""Helper handler to log model\'s gradients as histograms.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            # Create a logger\n            tb_logger = TensorboardLogger(log_dir=""experiments/tb_logs"")\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            tb_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=GradsHistHandler(model)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n\n    """"""\n\n    def __init__(self, model, tag=None):\n        super(GradsHistHandler, self).__init__(model, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, TensorboardLogger):\n            raise RuntimeError(""Handler \'GradsHistHandler\' works only with TensorboardLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            name = name.replace(""."", ""/"")\n            logger.writer.add_histogram(\n                tag=""{}grads/{}"".format(tag_prefix, name), values=p.grad.detach().cpu().numpy(), global_step=global_step\n            )\n\n\nclass TensorboardLogger(BaseLogger):\n    """"""\n    TensorBoard handler to log metrics, model/optimizer parameters, gradients during the training and validation.\n\n    By default, this class favors `tensorboardX <https://github.com/lanpa/tensorboardX>`_ package if installed:\n\n    .. code-block:: bash\n\n        pip install tensorboardX\n\n    otherwise, it falls back to using\n    `PyTorch\'s SummaryWriter\n    <https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter>`_\n    (>=v1.2.0).\n\n    Args:\n        *args: Positional arguments accepted from\n            `SummaryWriter\n            <https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter>`_.\n        **kwargs: Keyword arguments accepted from\n            `SummaryWriter\n            <https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter>`_.\n            For example, `log_dir` to setup path to the directory where to log.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            # Create a logger\n            tb_logger = TensorboardLogger(log_dir=""experiments/tb_logs"")\n\n            # Attach the logger to the trainer to log training loss at each iteration\n            tb_logger.attach_output_handler(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                tag=""training"",\n                output_transform=lambda loss: {""loss"": loss}\n            )\n\n            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch\n            # We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer` instead of `train_evaluator`.\n            tb_logger.attach_output_handler(\n                train_evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""training"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer),\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the\n            # `trainer` instead of `evaluator`.\n            tb_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)),\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            tb_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer,\n                param_name=\'lr\'  # optional\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            tb_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsScalarHandler(model)\n            )\n\n            # Attach the logger to the trainer to log model\'s weights as a histogram after each epoch\n            tb_logger.attach(\n                trainer,\n                event_name=Events.EPOCH_COMPLETED,\n                log_handler=WeightsHistHandler(model)\n            )\n\n            # Attach the logger to the trainer to log model\'s gradients norm after each iteration\n            tb_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=GradsScalarHandler(model)\n            )\n\n            # Attach the logger to the trainer to log model\'s gradients as a histogram after each epoch\n            tb_logger.attach(\n                trainer,\n                event_name=Events.EPOCH_COMPLETED,\n                log_handler=GradsHistHandler(model)\n            )\n\n            # We need to close the logger with we are done\n            tb_logger.close()\n\n        It is also possible to use the logger as context manager:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.tensorboard_logger import *\n\n            with TensorboardLogger(log_dir=""experiments/tb_logs"") as tb_logger:\n\n                trainer = Engine(update_fn)\n                # Attach the logger to the trainer to log training loss at each iteration\n                tb_logger.attach_output_handler(\n                    trainer,\n                    event_name=Events.ITERATION_COMPLETED,\n                    tag=""training"",\n                    output_transform=lambda loss: {""loss"": loss}\n                )\n\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        try:\n            from tensorboardX import SummaryWriter\n        except ImportError:\n            try:\n                from torch.utils.tensorboard import SummaryWriter\n            except ImportError:\n                raise RuntimeError(\n                    ""This contrib module requires either tensorboardX or torch >= 1.2.0. ""\n                    ""You may install tensorboardX with command: \\n pip install tensorboardX \\n""\n                    ""or upgrade PyTorch using your package manager of choice (pip or conda).""\n                )\n\n        self.writer = SummaryWriter(*args, **kwargs)\n\n    def close(self):\n        self.writer.close()\n\n    def _create_output_handler(self, *args, **kwargs):\n        return OutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        return OptimizerParamsHandler(*args, **kwargs)\n'"
ignite/contrib/handlers/time_profilers.py,18,"b'from collections import OrderedDict\n\nimport torch\n\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import Timer\n\n\nclass BasicTimeProfiler:\n    """"""\n    BasicTimeProfiler can be used to profile the handlers,\n    events, data loading and data processing times.\n\n    Examples:\n\n    .. code-block:: python\n\n        from ignite.contrib.handlers import BasicTimeProfiler\n\n        trainer = Engine(train_updater)\n\n        # Create an object of the profiler and attach an engine to it\n        profiler = BasicTimeProfiler()\n        profiler.attach(trainer)\n\n        @trainer.on(Events.EPOCH_COMPLETED)\n        def log_intermediate_results():\n            profiler.print_results(profiler.get_results())\n\n        trainer.run(dataloader, max_epochs=3)\n\n        profiler.write_results(\'path_to_dir/time_profiling.csv\')\n\n    """"""\n\n    events_to_ignore = [\n        Events.EXCEPTION_RAISED,\n        Events.TERMINATE,\n        Events.TERMINATE_SINGLE_EPOCH,\n        Events.DATALOADER_STOP_ITERATION,\n    ]\n\n    def __init__(self):\n        self._dataflow_timer = Timer()\n        self._processing_timer = Timer()\n        self._event_handlers_timer = Timer()\n\n        self.dataflow_times = None\n        self.processing_times = None\n        self.event_handlers_times = None\n\n        self._events = [\n            Events.EPOCH_STARTED,\n            Events.EPOCH_COMPLETED,\n            Events.ITERATION_STARTED,\n            Events.ITERATION_COMPLETED,\n            Events.GET_BATCH_STARTED,\n            Events.GET_BATCH_COMPLETED,\n            Events.COMPLETED,\n        ]\n        self._fmethods = [\n            self._as_first_epoch_started,\n            self._as_first_epoch_completed,\n            self._as_first_iter_started,\n            self._as_first_iter_completed,\n            self._as_first_get_batch_started,\n            self._as_first_get_batch_completed,\n            self._as_first_completed,\n        ]\n        self._lmethods = [\n            self._as_last_epoch_started,\n            self._as_last_epoch_completed,\n            self._as_last_iter_started,\n            self._as_last_iter_completed,\n            self._as_last_get_batch_started,\n            self._as_last_get_batch_completed,\n            self._as_last_completed,\n        ]\n\n    def _reset(self, num_epochs, total_num_iters):\n        self.dataflow_times = torch.zeros(total_num_iters)\n        self.processing_times = torch.zeros(total_num_iters)\n        self.event_handlers_times = {\n            Events.STARTED: torch.zeros(1),\n            Events.COMPLETED: torch.zeros(1),\n            Events.EPOCH_STARTED: torch.zeros(num_epochs),\n            Events.EPOCH_COMPLETED: torch.zeros(num_epochs),\n            Events.ITERATION_STARTED: torch.zeros(total_num_iters),\n            Events.ITERATION_COMPLETED: torch.zeros(total_num_iters),\n            Events.GET_BATCH_COMPLETED: torch.zeros(total_num_iters),\n            Events.GET_BATCH_STARTED: torch.zeros(total_num_iters),\n        }\n\n    def _as_first_started(self, engine):\n        if hasattr(engine.state.dataloader, ""__len__""):\n            num_iters_per_epoch = len(engine.state.dataloader)\n        else:\n            num_iters_per_epoch = engine.state.epoch_length\n\n        self.max_epochs = engine.state.max_epochs\n        self.total_num_iters = self.max_epochs * num_iters_per_epoch\n        self._reset(self.max_epochs, self.total_num_iters)\n\n        self.event_handlers_names = {\n            e: [\n                h.__qualname__ if hasattr(h, ""__qualname__"") else h.__class__.__name__\n                for (h, _, _) in engine._event_handlers[e]\n                if ""BasicTimeProfiler."" not in repr(h)  # avoid adding internal handlers into output\n            ]\n            for e in Events\n            if e not in self.events_to_ignore\n        }\n\n        # Setup all other handlers:\n        engine._event_handlers[Events.STARTED].append((self._as_last_started, (engine,), {}))\n\n        for e, m in zip(self._events, self._fmethods):\n            engine._event_handlers[e].insert(0, (m, (engine,), {}))\n\n        for e, m in zip(self._events, self._lmethods):\n            engine._event_handlers[e].append((m, (engine,), {}))\n\n        # Let\'s go\n        self._event_handlers_timer.reset()\n\n    def _as_last_started(self, engine):\n        self.event_handlers_times[Events.STARTED][0] = self._event_handlers_timer.value()\n\n    def _as_first_epoch_started(self, engine):\n        self._event_handlers_timer.reset()\n\n    def _as_last_epoch_started(self, engine):\n        t = self._event_handlers_timer.value()\n        e = engine.state.epoch - 1\n        self.event_handlers_times[Events.EPOCH_STARTED][e] = t\n\n    def _as_first_get_batch_started(self, engine):\n        self._event_handlers_timer.reset()\n        self._dataflow_timer.reset()\n\n    def _as_last_get_batch_started(self, engine):\n        t = self._event_handlers_timer.value()\n        i = engine.state.iteration - 1\n        self.event_handlers_times[Events.GET_BATCH_STARTED][i] = t\n\n    def _as_first_get_batch_completed(self, engine):\n        self._event_handlers_timer.reset()\n\n    def _as_last_get_batch_completed(self, engine):\n        t = self._event_handlers_timer.value()\n        i = engine.state.iteration - 1\n        self.event_handlers_times[Events.GET_BATCH_COMPLETED][i] = t\n\n        d = self._dataflow_timer.value()\n        self.dataflow_times[i] = d\n\n        self._dataflow_timer.reset()\n\n    def _as_first_iter_started(self, engine):\n        self._event_handlers_timer.reset()\n\n    def _as_last_iter_started(self, engine):\n        t = self._event_handlers_timer.value()\n        i = engine.state.iteration - 1\n        self.event_handlers_times[Events.ITERATION_STARTED][i] = t\n\n        self._processing_timer.reset()\n\n    def _as_first_iter_completed(self, engine):\n        t = self._processing_timer.value()\n        i = engine.state.iteration - 1\n        self.processing_times[i] = t\n\n        self._event_handlers_timer.reset()\n\n    def _as_last_iter_completed(self, engine):\n        t = self._event_handlers_timer.value()\n        i = engine.state.iteration - 1\n        self.event_handlers_times[Events.ITERATION_COMPLETED][i] = t\n\n    def _as_first_epoch_completed(self, engine):\n        self._event_handlers_timer.reset()\n\n    def _as_last_epoch_completed(self, engine):\n        t = self._event_handlers_timer.value()\n        e = engine.state.epoch - 1\n        self.event_handlers_times[Events.EPOCH_COMPLETED][e] = t\n\n    def _as_first_completed(self, engine):\n        self._event_handlers_timer.reset()\n\n    def _as_last_completed(self, engine):\n        self.event_handlers_times[Events.COMPLETED][0] = self._event_handlers_timer.value()\n\n        # Remove added handlers:\n        engine.remove_event_handler(self._as_last_started, Events.STARTED)\n\n        for e, m in zip(self._events, self._fmethods):\n            engine.remove_event_handler(m, e)\n\n        for e, m in zip(self._events, self._lmethods):\n            engine.remove_event_handler(m, e)\n\n    def attach(self, engine):\n        if not isinstance(engine, Engine):\n            raise TypeError(""Argument engine should be ignite.engine.Engine, "" ""but given {}"".format(type(engine)))\n\n        if not engine.has_event_handler(self._as_first_started):\n            engine._event_handlers[Events.STARTED].insert(0, (self._as_first_started, (engine,), {}))\n\n    @staticmethod\n    def _compute_basic_stats(data):\n        # compute on non-zero data:\n        data = data[data > 0]\n        out = [(""total"", torch.sum(data).item() if len(data) > 0 else ""not yet triggered"")]\n        if len(data) > 1:\n            out += [\n                (""min/index"", (torch.min(data).item(), torch.argmin(data).item())),\n                (""max/index"", (torch.max(data).item(), torch.argmax(data).item())),\n                (""mean"", torch.mean(data).item()),\n                (""std"", torch.std(data).item()),\n            ]\n        return OrderedDict(out)\n\n    def get_results(self):\n        """"""\n        Method to fetch the aggregated profiler results after the engine is run\n\n        .. code-block:: python\n\n            results = profiler.get_results()\n\n        """"""\n        total_eh_time = sum([(self.event_handlers_times[e]).sum() for e in Events if e not in self.events_to_ignore])\n\n        return OrderedDict(\n            [\n                (""processing_stats"", self._compute_basic_stats(self.processing_times)),\n                (""dataflow_stats"", self._compute_basic_stats(self.dataflow_times)),\n                (\n                    ""event_handlers_stats"",\n                    dict(\n                        [\n                            (str(e.name).replace(""."", ""_""), self._compute_basic_stats(self.event_handlers_times[e]))\n                            for e in Events\n                            if e not in self.events_to_ignore\n                        ]\n                        + [(""total_time"", total_eh_time)]\n                    ),\n                ),\n                (\n                    ""event_handlers_names"",\n                    {str(e.name).replace(""."", ""_"") + ""_names"": v for e, v in self.event_handlers_names.items()},\n                ),\n            ]\n        )\n\n    def write_results(self, output_path):\n        """"""\n        Method to store the unaggregated profiling results to a csv file\n\n        .. code-block:: python\n\n            profiler.write_results(\'path_to_dir/awesome_filename.csv\')\n\n        Example output:\n\n        .. code-block:: text\n\n            -----------------------------------------------------------------\n            epoch iteration processing_stats dataflow_stats Event_STARTED ...\n            1.0     1.0        0.00003         0.252387        0.125676\n            1.0     2.0        0.00029         0.252342        0.125123\n\n        """"""\n        try:\n            import pandas as pd\n        except ImportError:\n            print(""Need pandas to write results as files"")\n            return\n\n        iters_per_epoch = self.total_num_iters // self.max_epochs\n\n        epochs = torch.arange(self.max_epochs, dtype=torch.float32).repeat_interleave(iters_per_epoch) + 1\n        iterations = torch.arange(self.total_num_iters, dtype=torch.float32) + 1\n        processing_stats = self.processing_times\n        dataflow_stats = self.dataflow_times\n\n        event_started = self.event_handlers_times[Events.STARTED].repeat_interleave(self.total_num_iters)\n        event_completed = self.event_handlers_times[Events.COMPLETED].repeat_interleave(self.total_num_iters)\n        event_epoch_started = self.event_handlers_times[Events.EPOCH_STARTED].repeat_interleave(iters_per_epoch)\n        event_epoch_completed = self.event_handlers_times[Events.EPOCH_COMPLETED].repeat_interleave(iters_per_epoch)\n\n        event_iter_started = self.event_handlers_times[Events.ITERATION_STARTED]\n        event_iter_completed = self.event_handlers_times[Events.ITERATION_COMPLETED]\n        event_batch_started = self.event_handlers_times[Events.GET_BATCH_STARTED]\n        event_batch_completed = self.event_handlers_times[Events.GET_BATCH_COMPLETED]\n\n        results_dump = torch.stack(\n            [\n                epochs,\n                iterations,\n                processing_stats,\n                dataflow_stats,\n                event_started,\n                event_completed,\n                event_epoch_started,\n                event_epoch_completed,\n                event_iter_started,\n                event_iter_completed,\n                event_batch_started,\n                event_batch_completed,\n            ],\n            dim=1,\n        ).numpy()\n\n        results_df = pd.DataFrame(\n            data=results_dump,\n            columns=[\n                ""epoch"",\n                ""iteration"",\n                ""processing_stats"",\n                ""dataflow_stats"",\n                ""Event_STARTED"",\n                ""Event_COMPLETED"",\n                ""Event_EPOCH_STARTED"",\n                ""Event_EPOCH_COMPLETED"",\n                ""Event_ITERATION_STARTED"",\n                ""Event_ITERATION_COMPLETED"",\n                ""Event_GET_BATCH_STARTED"",\n                ""Event_GET_BATCH_COMPLETED"",\n            ],\n        )\n        results_df.to_csv(output_path, index=False)\n\n    @staticmethod\n    def print_results(results):\n        """"""\n        Method to print the aggregated results from the profiler\n\n        .. code-block:: python\n\n            profiler.print_results(results)\n\n        Example output:\n\n        .. code-block:: text\n\n             ----------------------------------------------------\n            | Time profiling stats (in seconds):                 |\n             ----------------------------------------------------\n            total  |  min/index  |  max/index  |  mean  |  std\n\n            Processing function:\n            157.46292 | 0.01452/1501 | 0.26905/0 | 0.07730 | 0.01258\n\n            Dataflow:\n            6.11384 | 0.00008/1935 | 0.28461/1551 | 0.00300 | 0.02693\n\n            Event handlers:\n            2.82721\n\n            - Events.STARTED: []\n            0.00000\n\n            - Events.EPOCH_STARTED: []\n            0.00006 | 0.00000/0 | 0.00000/17 | 0.00000 | 0.00000\n\n            - Events.ITERATION_STARTED: [\'PiecewiseLinear\']\n            0.03482 | 0.00001/188 | 0.00018/679 | 0.00002 | 0.00001\n\n            - Events.ITERATION_COMPLETED: [\'TerminateOnNan\']\n            0.20037 | 0.00006/866 | 0.00089/1943 | 0.00010 | 0.00003\n\n            - Events.EPOCH_COMPLETED: [\'empty_cuda_cache\', \'training.<locals>.log_elapsed_time\', ]\n            2.57860 | 0.11529/0 | 0.14977/13 | 0.12893 | 0.00790\n\n            - Events.COMPLETED: []\n            not yet triggered\n\n        """"""\n\n        def to_str(v):\n            if isinstance(v, str):\n                return v\n            elif isinstance(v, tuple):\n                return ""{:.5f}/{}"".format(v[0], v[1])\n            return ""{:.5f}"".format(v)\n\n        def odict_to_str(d):\n            out = "" | "".join([to_str(v) for v in d.values()])\n            return out\n\n        others = {\n            k: odict_to_str(v) if isinstance(v, OrderedDict) else v for k, v in results[""event_handlers_stats""].items()\n        }\n\n        others.update(results[""event_handlers_names""])\n\n        output_message = """"""\n ----------------------------------------------------\n| Time profiling stats (in seconds):                 |\n ----------------------------------------------------\ntotal  |  min/index  |  max/index  |  mean  |  std\n\nProcessing function:\n{processing_stats}\n\nDataflow:\n{dataflow_stats}\n\nEvent handlers:\n{total_time:.5f}\n\n- Events.STARTED: {STARTED_names}\n{STARTED}\n\n- Events.EPOCH_STARTED: {EPOCH_STARTED_names}\n{EPOCH_STARTED}\n\n- Events.ITERATION_STARTED: {ITERATION_STARTED_names}\n{ITERATION_STARTED}\n\n- Events.ITERATION_COMPLETED: {ITERATION_COMPLETED_names}\n{ITERATION_COMPLETED}\n\n- Events.EPOCH_COMPLETED: {EPOCH_COMPLETED_names}\n{EPOCH_COMPLETED}\n\n- Events.COMPLETED: {COMPLETED_names}\n{COMPLETED}\n"""""".format(\n            processing_stats=odict_to_str(results[""processing_stats""]),\n            dataflow_stats=odict_to_str(results[""dataflow_stats""]),\n            **others,\n        )\n        print(output_message)\n        return output_message\n'"
ignite/contrib/handlers/tqdm_logger.py,1,"b'# -*- coding: utf-8 -*-\nimport warnings\nfrom typing import Any, Mapping\n\nimport torch\n\nfrom ignite.contrib.handlers.base_logger import BaseLogger, BaseOutputHandler\nfrom ignite.engine import Engine, Events\nfrom ignite.engine.events import CallableEventWithFilter\n\n\nclass _OutputHandler(BaseOutputHandler):\n    """"""Helper handler to log engine\'s output and/or metrics\n\n    Args:\n        description (str): progress bar description.\n        metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n            metrics.\n        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.\n            For example, `output_transform = lambda output: output`\n            This function can also return a dictionary, e.g `{\'loss\': loss1, \'another_loss\': loss2}` to label the plot\n            with corresponding keys.\n        closing_event_name: event\'s name on which the progress bar is closed. Valid events are from\n            :class:`~ignite.engine.Events` or any `event_name` added by\n            :meth:`~ignite.engine.Engine.register_events`.\n\n    """"""\n\n    def __init__(\n        self, description, metric_names=None, output_transform=None, closing_event_name=Events.EPOCH_COMPLETED\n    ):\n        if metric_names is None and output_transform is None:\n            # This helps to avoid \'Either metric_names or output_transform should be defined\' of BaseOutputHandler\n            metric_names = []\n        super(_OutputHandler, self).__init__(description, metric_names, output_transform, global_step_transform=None)\n        self.closing_event_name = closing_event_name\n\n    @staticmethod\n    def get_max_number_events(event_name, engine):\n        if event_name in (Events.ITERATION_STARTED, Events.ITERATION_COMPLETED):\n            return engine.state.epoch_length\n        if event_name in (Events.EPOCH_STARTED, Events.EPOCH_COMPLETED):\n            return engine.state.max_epochs\n        return 1\n\n    def __call__(self, engine, logger, event_name):\n\n        pbar_total = self.get_max_number_events(event_name, engine)\n        if logger.pbar is None:\n            logger._reset(pbar_total=pbar_total)\n\n        desc = self.tag\n        max_num_of_closing_events = self.get_max_number_events(self.closing_event_name, engine)\n        if max_num_of_closing_events > 1:\n            global_step = engine.state.get_event_attrib_value(self.closing_event_name)\n            desc += "" [{}/{}]"".format(global_step, max_num_of_closing_events)\n        logger.pbar.set_description(desc)\n\n        metrics = self._setup_output_metrics(engine)\n\n        rendered_metrics = {}\n        for key, value in metrics.items():\n            if isinstance(value, torch.Tensor):\n                if value.ndimension() == 0:\n                    rendered_metrics[key] = value.item()\n                elif value.ndimension() == 1:\n                    for i, v in enumerate(value):\n                        k = ""{}_{}"".format(key, i)\n                        rendered_metrics[k] = v.item()\n                else:\n                    warnings.warn(""ProgressBar can not log "" ""tensor with {} dimensions"".format(value.ndimension()))\n            else:\n                rendered_metrics[key] = value\n\n        if rendered_metrics:\n            logger.pbar.set_postfix(**rendered_metrics)\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        if pbar_total is not None:\n            global_step = (global_step - 1) % pbar_total + 1\n        logger.pbar.update(global_step - logger.pbar.n)\n\n\nclass ProgressBar(BaseLogger):\n    """"""\n    TQDM progress bar handler to log training progress and computed metrics.\n\n    Args:\n        persist (bool, optional): set to ``True`` to persist the progress bar after completion (default = ``False``)\n        bar_format  (str, optional): Specify a custom bar string formatting. May impact performance.\n            [default: \'{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]\'].\n            Set to ``None`` to use ``tqdm`` default bar formatting: \'{l_bar}{bar}{r_bar}\', where\n            l_bar=\'{desc}: {percentage:3.0f}%|\' and\n            r_bar=\'| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]\'. For more details on the\n            formatting, see `tqdm docs <https://tqdm.github.io/docs/tqdm/>`_.\n        **tqdm_kwargs: kwargs passed to tqdm progress bar.\n            By default, progress bar description displays ""Epoch [5/10]"" where 5 is the current epoch and 10 is the\n            number of epochs. If tqdm_kwargs defines `desc`, e.g. ""Predictions"", than the description is\n            ""Predictions [5/10]"" if number of epochs is more than one otherwise it is simply ""Predictions"".\n\n    Examples:\n\n        Simple progress bar\n\n        .. code-block:: python\n\n            trainer = create_supervised_trainer(model, optimizer, loss)\n\n            pbar = ProgressBar()\n            pbar.attach(trainer)\n\n            # Progress bar will looks like\n            # Epoch [2/50]: [64/128]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88      [06:17<12:34]\n\n        Log output to a file instead of stderr (tqdm\'s default output)\n\n        .. code-block:: python\n\n            trainer = create_supervised_trainer(model, optimizer, loss)\n\n            log_file = open(""output.log"", ""w"")\n            pbar = ProgressBar(file=log_file)\n            pbar.attach(trainer)\n\n        Attach metrics that already have been computed at :attr:`~ignite.engine.Events.ITERATION_COMPLETED`\n        (such as :class:`~ignite.metrics.RunningAverage`)\n\n        .. code-block:: python\n\n            trainer = create_supervised_trainer(model, optimizer, loss)\n\n            RunningAverage(output_transform=lambda x: x).attach(trainer, \'loss\')\n\n            pbar = ProgressBar()\n            pbar.attach(trainer, [\'loss\'])\n\n            # Progress bar will looks like\n            # Epoch [2/50]: [64/128]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88      , loss=0.123 [06:17<12:34]\n\n        Directly attach the engine\'s output\n\n        .. code-block:: python\n\n            trainer = create_supervised_trainer(model, optimizer, loss)\n\n            pbar = ProgressBar()\n            pbar.attach(trainer, output_transform=lambda x: {\'loss\': x})\n\n            # Progress bar will looks like\n            # Epoch [2/50]: [64/128]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88      , loss=0.123 [06:17<12:34]\n\n    Note:\n        When adding attaching the progress bar to an engine, it is recommend that you replace\n        every print operation in the engine\'s handlers triggered every iteration with\n        ``pbar.log_message`` to guarantee the correct format of the stdout.\n\n    Note:\n        When using inside jupyter notebook, `ProgressBar` automatically uses `tqdm_notebook`. For correct rendering,\n        please install `ipywidgets <https://ipywidgets.readthedocs.io/en/stable/user_install.html#installation>`_.\n        Due to `tqdm notebook bugs <https://github.com/tqdm/tqdm/issues/594>`_, bar format may be needed to be set\n        to an empty string value.\n\n    """"""\n\n    _events_order = [\n        Events.STARTED,\n        Events.EPOCH_STARTED,\n        Events.ITERATION_STARTED,\n        Events.ITERATION_COMPLETED,\n        Events.EPOCH_COMPLETED,\n        Events.COMPLETED,\n    ]\n\n    def __init__(\n        self,\n        persist=False,\n        bar_format=""{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]"",\n        **tqdm_kwargs\n    ):\n\n        try:\n            from tqdm.autonotebook import tqdm\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires tqdm to be installed. ""\n                ""Please install it with command: \\n pip install tqdm""\n            )\n\n        self.pbar_cls = tqdm\n        self.pbar = None\n        self.persist = persist\n        self.bar_format = bar_format\n        self.tqdm_kwargs = tqdm_kwargs\n\n    def _reset(self, pbar_total):\n        self.pbar = self.pbar_cls(\n            total=pbar_total, leave=self.persist, bar_format=self.bar_format, initial=1, **self.tqdm_kwargs\n        )\n\n    def _close(self, engine):\n        if self.pbar is not None:\n            self.pbar.close()\n        self.pbar = None\n\n    @staticmethod\n    def _compare_lt(event1, event2):\n        i1 = ProgressBar._events_order.index(event1)\n        i2 = ProgressBar._events_order.index(event2)\n        return i1 < i2\n\n    def log_message(self, message):\n        """"""\n        Logs a message, preserving the progress bar correct output format.\n\n        Args:\n            message (str): string you wish to log.\n        """"""\n        from tqdm import tqdm\n\n        tqdm.write(message, file=self.tqdm_kwargs.get(""file"", None))\n\n    def attach(\n        self,\n        engine,\n        metric_names=None,\n        output_transform=None,\n        event_name=Events.ITERATION_COMPLETED,\n        closing_event_name=Events.EPOCH_COMPLETED,\n    ):\n        """"""\n        Attaches the progress bar to an engine object.\n\n        Args:\n            engine (Engine): engine object.\n            metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n                metrics.\n            output_transform (callable, optional): a function to select what you want to print from the engine\'s\n                output. This function may return either a dictionary with entries in the format of ``{name: value}``,\n                or a single scalar, which will be displayed with the default name `output`.\n            event_name: event\'s name on which the progress bar advances. Valid events are from\n                :class:`~ignite.engine.Events`.\n            closing_event_name: event\'s name on which the progress bar is closed. Valid events are from\n                :class:`~ignite.engine.Events`.\n\n        Note: accepted output value types are numbers, 0d and 1d torch tensors and strings\n\n        """"""\n        desc = self.tqdm_kwargs.get(""desc"", ""Epoch"")\n\n        if event_name not in engine._allowed_events:\n            raise ValueError(""Logging event {} is not in allowed events for this engine"".format(event_name.name))\n\n        if isinstance(closing_event_name, CallableEventWithFilter):\n            if closing_event_name.filter != CallableEventWithFilter.default_event_filter:\n                raise ValueError(""Closing Event should not be a filtered event"")\n\n        if not self._compare_lt(event_name, closing_event_name):\n            raise ValueError(\n                ""Logging event {} should be called before closing event {}"".format(event_name, closing_event_name)\n            )\n\n        log_handler = _OutputHandler(desc, metric_names, output_transform, closing_event_name=closing_event_name)\n\n        super(ProgressBar, self).attach(engine, log_handler, event_name)\n        engine.add_event_handler(closing_event_name, self._close)\n\n    def attach_opt_params_handler(self, engine: Engine, event_name: str, *args: Any, **kwargs: Mapping):\n        """"""Intentionally empty""""""\n        pass\n\n    def _create_output_handler(self, *args, **kwargs):\n        return _OutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        """"""Intentionally empty""""""\n        pass\n'"
ignite/contrib/handlers/trains_logger.py,9,"b'import os\nimport tempfile\nimport warnings\nfrom datetime import datetime\nfrom typing import Mapping, Optional\n\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.contrib.handlers.base_logger import (\n    BaseLogger,\n    BaseOptimizerParamsHandler,\n    BaseOutputHandler,\n    BaseWeightsHistHandler,\n    BaseWeightsScalarHandler,\n)\nfrom ignite.handlers import global_step_from_engine\nfrom ignite.handlers.checkpoint import DiskSaver\n\n__all__ = [\n    ""TrainsLogger"",\n    ""TrainsSaver"",\n    ""OptimizerParamsHandler"",\n    ""OutputHandler"",\n    ""WeightsScalarHandler"",\n    ""WeightsHistHandler"",\n    ""GradsScalarHandler"",\n    ""GradsHistHandler"",\n    ""global_step_from_engine"",\n]\n\n\nclass OutputHandler(BaseOutputHandler):\n    """"""Helper handler to log engine\'s output and/or metrics\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n\n            # Create a logger\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer`:\n            trains_logger.attach(\n                evaluator,\n                log_handler=OutputHandler(\n                    tag=""validation"",\n                    metric_names=[""nll"", ""accuracy""],\n                    global_step_transform=global_step_from_engine(trainer)\n                ),\n                event_name=Events.EPOCH_COMPLETED\n            )\n            # or equivalently\n            trains_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)\n            )\n\n        Another example, where model is evaluated every 500 iterations:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n\n            @trainer.on(Events.ITERATION_COMPLETED(every=500))\n            def evaluate(engine):\n                evaluator.run(validation_set, max_epochs=1)\n\n            # Create a logger\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            def global_step_transform(*args, **kwargs):\n                return trainer.state.iteration\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we\n            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time\n            # evaluator metrics are plotted on Trains.\n\n            trains_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metrics=[""nll"", ""accuracy""],\n                global_step_transform=global_step_transform\n            )\n\n    Args:\n        tag (str): common title for all produced plots. For example, ""training""\n        metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n            metrics.\n        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.\n            For example, `output_transform = lambda output: output`\n            This function can also return a dictionary, e.g `{""loss"": loss1, ""another_loss"": loss2}` to label the plot\n            with corresponding keys.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided,\n            uses function output as global_step. To setup global step from another engine, please use\n            :meth:`~ignite.contrib.handlers.trains_logger.global_step_from_engine`.\n\n    Note:\n\n        Example of `global_step_transform`:\n\n        .. code-block:: python\n\n            def global_step_transform(engine, event_name):\n                return engine.state.get_event_attrib_value(event_name)\n\n    """"""\n\n    def __init__(self, tag, metric_names=None, output_transform=None, global_step_transform=None):\n        super(OutputHandler, self).__init__(tag, metric_names, output_transform, global_step_transform)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, TrainsLogger):\n            raise RuntimeError(""Handler OutputHandler works only with TrainsLogger"")\n\n        metrics = self._setup_output_metrics(engine)\n\n        global_step = self.global_step_transform(engine, event_name)\n\n        if not isinstance(global_step, int):\n            raise TypeError(\n                ""global_step must be int, got {}.""\n                "" Please check the output of global_step_transform."".format(type(global_step))\n            )\n\n        for key, value in metrics.items():\n            if isinstance(value, (float, int)):\n                logger.trains_logger.report_scalar(title=self.tag, series=key, iteration=global_step, value=value)\n            else:\n                warnings.warn(""TrainsLogger output_handler can not log "" ""metrics value type {}"".format(type(value)))\n\n\nclass OptimizerParamsHandler(BaseOptimizerParamsHandler):\n    """"""Helper handler to log optimizer parameters\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n\n            # Create a logger\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            trains_logger.attach(\n                trainer,\n                log_handler=OptimizerParamsHandler(optimizer),\n                event_name=Events.ITERATION_STARTED\n            )\n            # or equivalently\n            trains_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer\n            )\n\n    Args:\n        optimizer (torch.optim.Optimizer): torch optimizer which parameters to log\n        param_name (str): parameter name\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n    """"""\n\n    def __init__(self, optimizer, param_name=""lr"", tag=None):\n        super(OptimizerParamsHandler, self).__init__(optimizer, param_name, tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, TrainsLogger):\n            raise RuntimeError(""Handler OptimizerParamsHandler works only with TrainsLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        params = {\n            str(i): float(param_group[self.param_name]) for i, param_group in enumerate(self.optimizer.param_groups)\n        }\n\n        for k, v in params.items():\n            logger.trains_logger.report_scalar(\n                title=""{}{}"".format(tag_prefix, self.param_name), series=k, value=v, iteration=global_step\n            )\n\n\nclass WeightsScalarHandler(BaseWeightsScalarHandler):\n    """"""Helper handler to log model\'s weights as scalars.\n    Handler iterates over named parameters of the model, applies reduction function to each parameter\n    produce a scalar and then logs the scalar.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n\n            # Create a logger\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            trains_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsScalarHandler(model, reduction=torch.norm)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        reduction (callable): function to reduce parameters into scalar\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None):\n        super(WeightsScalarHandler, self).__init__(model, reduction, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, TrainsLogger):\n            raise RuntimeError(""Handler WeightsScalarHandler works only with TrainsLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            title_name, _, series_name = name.partition(""."")\n            logger.trains_logger.report_scalar(\n                title=""{}weights_{}/{}"".format(tag_prefix, self.reduction.__name__, title_name),\n                series=series_name,\n                value=self.reduction(p.data),\n                iteration=global_step,\n            )\n\n\nclass WeightsHistHandler(BaseWeightsHistHandler):\n    """"""Helper handler to log model\'s weights as histograms.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n\n            # Create a logger\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            trains_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsHistHandler(model)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        tag (str, optional): common title for all produced plots. For example, \'generator\'\n\n    """"""\n\n    def __init__(self, model, tag=None):\n        super(WeightsHistHandler, self).__init__(model, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, TrainsLogger):\n            raise RuntimeError(""Handler \'WeightsHistHandler\' works only with TrainsLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            title_name, _, series_name = name.partition(""."")\n\n            logger.grad_helper.add_histogram(\n                title=""{}weights_{}"".format(tag_prefix, title_name),\n                series=series_name,\n                step=global_step,\n                hist_data=p.grad.detach().cpu().numpy(),\n            )\n\n\nclass GradsScalarHandler(BaseWeightsScalarHandler):\n    """"""Helper handler to log model\'s gradients as scalars.\n    Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter\n    produce a scalar and then logs the scalar.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n\n            # Create a logger\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            trains_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=GradsScalarHandler(model, reduction=torch.norm)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        reduction (callable): function to reduce parameters into scalar\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None):\n        super(GradsScalarHandler, self).__init__(model, reduction, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, TrainsLogger):\n            raise RuntimeError(""Handler GradsScalarHandler works only with TrainsLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            title_name, _, series_name = name.partition(""."")\n            logger.trains_logger.report_scalar(\n                title=""{}grads_{}/{}"".format(tag_prefix, self.reduction.__name__, title_name),\n                series=series_name,\n                value=self.reduction(p.data),\n                iteration=global_step,\n            )\n\n\nclass GradsHistHandler(BaseWeightsHistHandler):\n    """"""Helper handler to log model\'s gradients as histograms.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n\n            # Create a logger\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            trains_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=GradsHistHandler(model)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        tag (str, optional): common title for all produced plots. For example, \'generator\'\n\n    """"""\n\n    def __init__(self, model, tag=None):\n        super(GradsHistHandler, self).__init__(model, tag=tag)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, TrainsLogger):\n            raise RuntimeError(""Handler \'GradsHistHandler\' works only with TrainsLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            if p.grad is None:\n                continue\n\n            title_name, _, series_name = name.partition(""."")\n\n            logger.grad_helper.add_histogram(\n                title=""{}grads_{}"".format(tag_prefix, title_name),\n                series=series_name,\n                step=global_step,\n                hist_data=p.grad.detach().cpu().numpy(),\n            )\n\n\nclass TrainsLogger(BaseLogger):\n    """"""\n    `Trains <https://github.com/allegroai/trains>`_ handler to log metrics, text, model/optimizer parameters,\n    plots during training and validation.\n    Also supports model checkpoints logging and upload to the storage solution of your choice (i.e. Trains File server,\n    S3 bucket etc.)\n\n    .. code-block:: bash\n\n        pip install trains\n        trains-init\n\n    Args:\n        project_name (str): The name of the project in which the experiment will be created. If the project\n            does not exist, it is created. If ``project_name`` is ``None``, the repository name is used. (Optional)\n        task_name (str): The name of Task (experiment). If ``task_name`` is ``None``, the Python experiment\n            script\'s file name is used. (Optional)\n        task_type (str): Optional. The task type. Valid values are:\n            - ``TaskTypes.training`` (Default)\n            - ``TaskTypes.train``\n            - ``TaskTypes.testing``\n            - ``TaskTypes.inference``\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n\n            # Create a logger\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            # Attach the logger to the trainer to log training loss at each iteration\n            trains_logger.attach_output_handler(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                tag=""training"",\n                output_transform=lambda loss: {""loss"": loss}\n            )\n\n            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch\n            # We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer` instead of `train_evaluator`.\n            trains_logger.attach_output_handler(\n                train_evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""training"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer),\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the\n            # `trainer` instead of `evaluator`.\n            trains_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)),\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            trains_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer,\n                param_name=\'lr\'  # optional\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            trains_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsScalarHandler(model)\n            )\n\n    """"""\n\n    def __init__(self, *_, **kwargs):\n        try:\n            import trains\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires trains to be installed. ""\n                ""You may install trains using: \\n pip install trains \\n""\n            )\n\n        experiment_kwargs = {k: v for k, v in kwargs.items() if k not in (""project_name"", ""task_name"", ""task_type"",)}\n\n        if self.bypass_mode():\n            warnings.warn(""TrainsSaver: running in bypass mode"")\n\n            class _Stub(object):\n                def __call__(self, *_, **__):\n                    return self\n\n                def __getattr__(self, attr):\n                    if attr in (""name"", ""id""):\n                        return """"\n                    return self\n\n                def __setattr__(self, attr, val):\n                    pass\n\n            self._task = _Stub()\n        else:\n            self._task = trains.Task.init(\n                project_name=kwargs.get(""project_name""),\n                task_name=kwargs.get(""task_name""),\n                task_type=kwargs.get(""task_type"", trains.Task.TaskTypes.training),\n                **experiment_kwargs,\n            )\n\n        self.trains_logger = self._task.get_logger()\n\n        self.grad_helper = trains.binding.frameworks.tensorflow_bind.WeightsGradientHistHelper(\n            logger=self.trains_logger,\n        )\n\n    @classmethod\n    def set_bypass_mode(cls, bypass: bool) -> None:\n        """"""\n        Will bypass all outside communication, and will drop all logs.\n        Should only be used in ""standalone mode"", when there is no access to the *trains-server*.\n        Args:\n            bypass: If ``True``, all outside communication is skipped.\n        """"""\n        setattr(cls, ""_bypass"", bypass)\n\n    @classmethod\n    def bypass_mode(cls) -> bool:\n        """"""\n        Returns the bypass mode state.\n        Note:\n            `GITHUB_ACTIONS` env will automatically set bypass_mode to ``True``\n            unless overridden specifically with ``TrainsLogger.set_bypass_mode(False)``.\n        Return:\n            If True, all outside communication is skipped.\n        """"""\n        return getattr(cls, ""_bypass"", bool(os.environ.get(""CI"")))\n\n    def close(self):\n        self.trains_logger.flush()\n\n    def _create_output_handler(self, *args, **kwargs):\n        return OutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        return OptimizerParamsHandler(*args, **kwargs)\n\n\nclass TrainsSaver(DiskSaver):\n    """"""\n    Handler that saves input checkpoint as Trains artifacts\n\n    Args:\n        logger (TrainsLogger, optional): An instance of :class:`~ignite.contrib.handlers.TrainsLogger`, ensuring a valid\n            Trains ``Task`` has been initialized. If not provided, and a Trains Task has not been manually initialized,\n            a runtime error will be raised.\n        output_uri (str, optional): The default location for output models and other artifacts uploaded by Trains. For\n            more information, see ``trains.Task.init``.\n        dirname (str, optional): Directory path where the checkpoint will be saved. If not provided, a temporary\n            directory will be created.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.trains_logger import *\n            from ignite.handlers import Checkpoint\n\n            trains_logger = TrainsLogger(\n                project_name=""pytorch-ignite-integration"",\n                task_name=""cnn-mnist""\n            )\n\n            to_save = {""model"": model}\n\n            handler = Checkpoint(\n                to_save,\n                TrainsSaver(),\n                n_saved=1,\n                score_function=lambda e: 123,\n                score_name=""acc"",\n                filename_prefix=""best"",\n                global_step_transform=global_step_from_engine(trainer)\n            )\n\n            validation_evaluator.add_event_handler(Events.EVENT_COMPLETED, handler)\n\n    """"""\n\n    def __init__(self, logger: TrainsLogger = None, output_uri: str = None, dirname: str = None, *args, **kwargs):\n\n        self._setup_check_trains(logger, output_uri)\n\n        if not dirname:\n            dirname = """"\n            if idist.get_rank() == 0:\n                dirname = tempfile.mkdtemp(\n                    prefix=""ignite_checkpoints_{}"".format(datetime.now().strftime(""%Y_%m_%d_%H_%M_%S_""))\n                )\n            if idist.get_world_size() > 1:\n                dirname = idist.all_gather(dirname)[0]\n\n            warnings.warn(""TrainsSaver created a temporary checkpoints directory: {}"".format(dirname))\n            idist.barrier()\n\n        # Let\'s set non-atomic tmp dir saving behaviour\n        if ""atomic"" not in kwargs:\n            kwargs[""atomic""] = False\n\n        super(TrainsSaver, self).__init__(dirname=dirname, *args, **kwargs)\n\n    @idist.one_rank_only()\n    def _setup_check_trains(self, logger, output_uri):\n        try:\n            from trains import Task\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires trains to be installed. ""\n                ""You may install trains using: \\n pip install trains \\n""\n            )\n\n        if logger and not isinstance(logger, TrainsLogger):\n            raise TypeError(""logger must be an instance of TrainsLogger"")\n\n        self._task = Task.current_task()\n        if not self._task:\n            raise RuntimeError(\n                ""TrainsSaver requires a Trains Task to be initialized.""\n                ""Please use the `logger` argument or call `trains.Task.init()`.""\n            )\n\n        if output_uri:\n            self._task.output_uri = output_uri\n\n    def __call__(self, checkpoint: Mapping, filename: str, metadata: Optional[Mapping] = None) -> None:\n        super(TrainsSaver, self).__call__(checkpoint, filename, metadata)\n\n        if idist.get_rank() == 0:\n            # Maybe wont work with XLA\n            if self._atomic:\n                try:\n                    import trains\n                except ImportError:\n                    raise RuntimeError(\n                        ""This contrib module requires trains to be installed. ""\n                        ""You may install trains using: \\n pip install trains \\n""\n                    )\n\n                # If atomic, DiskSaver\'s implementation first stores checkpoint into a temporary file\n                # and prohibits trains to automatically detect correct artifact path and name\n                path = os.path.join(self.dirname, filename)\n                if os.path.exists(path):\n                    trains.binding.frameworks.WeightsFileHandler.create_output_model(\n                        model=checkpoint,\n                        saved_path=path,\n                        framework=trains.model.Framework.pytorch,\n                        task=self._task,\n                        singlefile=True,\n                        model_name=os.path.basename(filename),\n                    )\n\n    @idist.one_rank_only()\n    def get_local_copy(self, filename: str) -> Optional[str]:\n        """"""Get artifact local copy.\n\n        .. warning::\n\n            In distributed configuration this method should be called on rank 0 process.\n\n        Args:\n            filename (str): artifact name.\n\n        Returns:\n             a local path to a downloaded copy of the artifact\n        """"""\n        artifact = self._task.artifacts.get(filename)\n        if artifact:\n            return artifact.get_local_copy()\n        self._task.get_logger().report_text(""Can not find artifact {}"".format(filename))\n'"
ignite/contrib/handlers/visdom_logger.py,9,"b'import numbers\nimport os\nimport warnings\n\nimport torch\n\nfrom ignite.contrib.handlers.base_logger import (\n    BaseLogger,\n    BaseOptimizerParamsHandler,\n    BaseOutputHandler,\n    BaseWeightsScalarHandler,\n)\nfrom ignite.handlers import global_step_from_engine\n\n__all__ = [\n    ""VisdomLogger"",\n    ""OptimizerParamsHandler"",\n    ""OutputHandler"",\n    ""WeightsScalarHandler"",\n    ""GradsScalarHandler"",\n    ""global_step_from_engine"",\n]\n\n\nclass _BaseVisDrawer:\n    def __init__(self, show_legend=False):\n        self.windows = {}\n        self.show_legend = show_legend\n\n    def add_scalar(self, logger, k, v, event_name, global_step):\n        """"""\n        Helper method to log a scalar with VisdomLogger.\n\n        Args:\n            logger (VisdomLogger): visdom logger\n            k (str): scalar name which is used to set window title and y-axis label\n            v (int or float): scalar value, y-axis value\n            event_name: Event name which is used to setup x-axis label. Valid events are from\n                :class:`~ignite.engine.Events` or any `event_name` added by\n                :meth:`~ignite.engine.Engine.register_events`.\n            global_step (int): global step, x-axis value\n\n        """"""\n        if k not in self.windows:\n            self.windows[k] = {\n                ""win"": None,\n                ""opts"": {""title"": k, ""xlabel"": str(event_name), ""ylabel"": k, ""showlegend"": self.show_legend},\n            }\n\n        update = None if self.windows[k][""win""] is None else ""append""\n\n        kwargs = {\n            ""X"": [global_step,],\n            ""Y"": [v,],\n            ""env"": logger.vis.env,\n            ""win"": self.windows[k][""win""],\n            ""update"": update,\n            ""opts"": self.windows[k][""opts""],\n            ""name"": k,\n        }\n\n        future = logger.executor.submit(logger.vis.line, **kwargs)\n        if self.windows[k][""win""] is None:\n            self.windows[k][""win""] = future.result()\n\n\nclass OutputHandler(BaseOutputHandler, _BaseVisDrawer):\n    """"""Helper handler to log engine\'s output and/or metrics\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.visdom_logger import *\n\n            # Create a logger\n            vd_logger = VisdomLogger()\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer`:\n            vd_logger.attach(\n                evaluator,\n                log_handler=OutputHandler(\n                    tag=""validation"",\n                    metric_names=[""nll"", ""accuracy""],\n                    global_step_transform=global_step_from_engine(trainer)\n                ),\n                event_name=Events.EPOCH_COMPLETED\n            )\n            # or equivalently\n            vd_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)\n            )\n\n        Another example, where model is evaluated every 500 iterations:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.visdom_logger import *\n\n            @trainer.on(Events.ITERATION_COMPLETED(every=500))\n            def evaluate(engine):\n                evaluator.run(validation_set, max_epochs=1)\n\n            vd_logger = VisdomLogger()\n\n            def global_step_transform(*args, **kwargs):\n                return trainer.state.iteration\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we\n            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time\n            # evaluator metrics are plotted on Visdom.\n\n            vd_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metrics=[""nll"", ""accuracy""],\n                global_step_transform=global_step_transform\n            )\n\n    Args:\n        tag (str): common title for all produced plots. For example, ""training""\n        metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n            metrics.\n        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.\n            For example, `output_transform = lambda output: output`\n            This function can also return a dictionary, e.g `{""loss"": loss1, ""another_loss"": loss2}` to label the plot\n            with corresponding keys.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided,\n            uses function output as global_step. To setup global step from another engine, please use\n            :meth:`~ignite.contrib.handlers.visdom_logger.global_step_from_engine`.\n        show_legend (bool, optional): flag to show legend in the window\n\n    Note:\n\n        Example of `global_step_transform`:\n\n        .. code-block:: python\n\n            def global_step_transform(engine, event_name):\n                return engine.state.get_event_attrib_value(event_name)\n\n    """"""\n\n    def __init__(\n        self, tag, metric_names=None, output_transform=None, global_step_transform=None, show_legend=False,\n    ):\n        super(OutputHandler, self).__init__(tag, metric_names, output_transform, global_step_transform)\n        _BaseVisDrawer.__init__(self, show_legend=show_legend)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, VisdomLogger):\n            raise RuntimeError(""Handler \'OutputHandler\' works only with VisdomLogger"")\n\n        metrics = self._setup_output_metrics(engine)\n\n        global_step = self.global_step_transform(engine, event_name)\n\n        if not isinstance(global_step, int):\n            raise TypeError(\n                ""global_step must be int, got {}.""\n                "" Please check the output of global_step_transform."".format(type(global_step))\n            )\n\n        for key, value in metrics.items():\n\n            values = []\n            keys = []\n            if isinstance(value, numbers.Number) or isinstance(value, torch.Tensor) and value.ndimension() == 0:\n                values.append(value)\n                keys.append(key)\n            elif isinstance(value, torch.Tensor) and value.ndimension() == 1:\n                values = value\n                keys = [""{}/{}"".format(key, i) for i in range(len(value))]\n            else:\n                warnings.warn(""VisdomLogger output_handler can not log "" ""metrics value type {}"".format(type(value)))\n\n            for k, v in zip(keys, values):\n                k = ""{}/{}"".format(self.tag, k)\n                self.add_scalar(logger, k, v, event_name, global_step)\n\n        logger._save()\n\n\nclass OptimizerParamsHandler(BaseOptimizerParamsHandler, _BaseVisDrawer):\n    """"""Helper handler to log optimizer parameters\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.visdom_logger import *\n\n            # Create a logger\n            vb_logger = VisdomLogger()\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            vd_logger.attach(\n                trainer,\n                log_handler=OptimizerParamsHandler(optimizer),\n                event_name=Events.ITERATION_STARTED\n            )\n            # or equivalently\n            vd_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer\n            )\n\n    Args:\n        optimizer (torch.optim.Optimizer): torch optimizer which parameters to log\n        param_name (str): parameter name\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n        show_legend (bool, optional): flag to show legend in the window\n    """"""\n\n    def __init__(self, optimizer, param_name=""lr"", tag=None, show_legend=False):\n        super(OptimizerParamsHandler, self).__init__(optimizer, param_name, tag)\n        _BaseVisDrawer.__init__(self, show_legend=show_legend)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, VisdomLogger):\n            raise RuntimeError(""Handler OptimizerParamsHandler works only with VisdomLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        params = {\n            ""{}{}/group_{}"".format(tag_prefix, self.param_name, i): float(param_group[self.param_name])\n            for i, param_group in enumerate(self.optimizer.param_groups)\n        }\n\n        for k, v in params.items():\n            self.add_scalar(logger, k, v, event_name, global_step)\n\n        logger._save()\n\n\nclass WeightsScalarHandler(BaseWeightsScalarHandler, _BaseVisDrawer):\n    """"""Helper handler to log model\'s weights as scalars.\n    Handler iterates over named parameters of the model, applies reduction function to each parameter\n    produce a scalar and then logs the scalar.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.visdom_logger import *\n\n            # Create a logger\n            vd_logger = VisdomLogger()\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            vd_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsScalarHandler(model, reduction=torch.norm)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        reduction (callable): function to reduce parameters into scalar\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n        show_legend (bool, optional): flag to show legend in the window\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None, show_legend=False):\n        super(WeightsScalarHandler, self).__init__(model, reduction, tag=tag)\n        _BaseVisDrawer.__init__(self, show_legend=show_legend)\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, VisdomLogger):\n            raise RuntimeError(""Handler \'WeightsScalarHandler\' works only with VisdomLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            name = name.replace(""."", ""/"")\n            k = ""{}weights_{}/{}"".format(tag_prefix, self.reduction.__name__, name)\n            v = float(self.reduction(p.data))\n            self.add_scalar(logger, k, v, event_name, global_step)\n\n        logger._save()\n\n\nclass GradsScalarHandler(BaseWeightsScalarHandler, _BaseVisDrawer):\n    """"""Helper handler to log model\'s gradients as scalars.\n    Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter\n    produce a scalar and then logs the scalar.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.visdom_logger import *\n\n            # Create a logger\n            vd_logger = VisdomLogger()\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            vd_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=GradsScalarHandler(model, reduction=torch.norm)\n            )\n\n    Args:\n        model (torch.nn.Module): model to log weights\n        reduction (callable): function to reduce parameters into scalar\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n        show_legend (bool, optional): flag to show legend in the window\n\n    """"""\n\n    def __init__(self, model, reduction=torch.norm, tag=None, show_legend=False):\n        super(GradsScalarHandler, self).__init__(model, reduction, tag)\n        _BaseVisDrawer.__init__(self, show_legend=show_legend)\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, VisdomLogger):\n            raise RuntimeError(""Handler \'GradsScalarHandler\' works only with VisdomLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        for name, p in self.model.named_parameters():\n            name = name.replace(""."", ""/"")\n            k = ""{}grads_{}/{}"".format(tag_prefix, self.reduction.__name__, name)\n            v = float(self.reduction(p.grad))\n            self.add_scalar(logger, k, v, event_name, global_step)\n\n        logger._save()\n\n\nclass VisdomLogger(BaseLogger):\n    """"""\n    VisdomLogger handler to log metrics, model/optimizer parameters, gradients during the training and validation.\n\n    This class requires `visdom <https://github.com/facebookresearch/visdom/>`_ package to be installed:\n\n    .. code-block:: bash\n\n        pip install git+https://github.com/facebookresearch/visdom.git\n\n    Args:\n        server (str, optional): visdom server URL. It can be also specified by environment variable `VISDOM_SERVER_URL`\n        port (int, optional): visdom server\'s port. It can be also specified by environment variable `VISDOM_PORT`\n        num_workers (int, optional): number of workers to use in `concurrent.futures.ThreadPoolExecutor` to post data to\n            visdom server. Default, `num_workers=1`. If `num_workers=0` and logger uses the main thread. If using\n            Python 2.7 and `num_workers>0` the package `futures` should be installed: `pip install futures`\n        **kwargs: kwargs to pass into\n            `visdom.Visdom <https://github.com/facebookresearch/visdom#visdom-arguments-python-only>`_.\n\n    Note:\n        We can also specify username/password using environment variables: VISDOM_USERNAME, VISDOM_PASSWORD\n\n\n    .. warning::\n\n        Frequent logging, e.g. when logger is attached to `Events.ITERATION_COMPLETED`, can slow down the run if the\n        main thread is used to send the data to visdom server (`num_workers=0`). To avoid this situation we can either\n        log less frequently or set `num_workers=1`.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.visdom_logger import *\n\n            # Create a logger\n            vd_logger = VisdomLogger()\n\n            # Attach the logger to the trainer to log training loss at each iteration\n            vd_logger.attach_output_handler(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                tag=""training"",\n                output_transform=lambda loss: {""loss"": loss}\n            )\n\n            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch\n            # We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch\n            # of the `trainer` instead of `train_evaluator`.\n            vd_logger.attach_output_handler(\n                train_evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""training"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer),\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the\n            # `trainer` instead of `evaluator`.\n            vd_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=global_step_from_engine(trainer)),\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            vd_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer,\n                param_name=\'lr\'  # optional\n            )\n\n            # Attach the logger to the trainer to log model\'s weights norm after each iteration\n            vd_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=WeightsScalarHandler(model)\n            )\n\n            # Attach the logger to the trainer to log model\'s gradients norm after each iteration\n            vd_logger.attach(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                log_handler=GradsScalarHandler(model)\n            )\n\n            # We need to close the logger with we are done\n            vd_logger.close()\n\n        It is also possible to use the logger as context manager:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.visdom_logger import *\n\n            with VisdomLogger() as vd_logger:\n\n                trainer = Engine(update_fn)\n                # Attach the logger to the trainer to log training loss at each iteration\n                vd_logger.attach_output_handler(\n                    trainer,\n                    event_name=Events.ITERATION_COMPLETED,\n                    tag=""training"",\n                    output_transform=lambda loss: {""loss"": loss}\n                )\n\n    """"""\n\n    def __init__(self, server=None, port=None, num_workers=1, **kwargs):\n        try:\n            import visdom\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires visdom package. ""\n                ""Please install it with command:\\n""\n                ""pip install git+https://github.com/facebookresearch/visdom.git""\n            )\n\n        if num_workers > 0:\n            # If visdom is installed, one of its dependencies `tornado`\n            # requires also `futures` to be installed.\n            # Let\'s check anyway if we can import it.\n            try:\n                import concurrent.futures\n            except ImportError:\n                raise RuntimeError(\n                    ""This contrib module requires concurrent.futures module""\n                    ""Please install it with command:\\n""\n                    ""pip install futures""\n                )\n\n        if server is None:\n            server = os.environ.get(""VISDOM_SERVER_URL"", ""localhost"")\n\n        if port is None:\n            port = int(os.environ.get(""VISDOM_PORT"", 8097))\n\n        if ""username"" not in kwargs:\n            username = os.environ.get(""VISDOM_USERNAME"", None)\n            kwargs[""username""] = username\n\n        if ""password"" not in kwargs:\n            password = os.environ.get(""VISDOM_PASSWORD"", None)\n            kwargs[""password""] = password\n\n        self.vis = visdom.Visdom(server=server, port=port, **kwargs)\n\n        if not self.vis.check_connection():\n            raise RuntimeError(\n                ""Failed to connect to Visdom server at {}. "" ""Did you run python -m visdom.server ?"".format(server)\n            )\n\n        self.executor = _DummyExecutor()\n        if num_workers > 0:\n            from concurrent.futures import ThreadPoolExecutor\n\n            self.executor = ThreadPoolExecutor(max_workers=num_workers)\n\n    def _save(self):\n        self.vis.save([self.vis.env])\n\n    def close(self):\n        self.vis = None\n        self.executor.shutdown()\n\n    def _create_output_handler(self, *args, **kwargs):\n        return OutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        return OptimizerParamsHandler(*args, **kwargs)\n\n\nclass _DummyExecutor:\n    class _DummyFuture:\n        def __init__(self, result):\n            self._output = result\n\n        def result(self):\n            return self._output\n\n    def __init__(self, *args, **kwargs):\n        pass\n\n    def submit(self, fn, **kwargs):\n        return _DummyExecutor._DummyFuture(fn(**kwargs))\n\n    def shutdown(self, *args, **kwargs):\n        pass\n'"
ignite/contrib/handlers/wandb_logger.py,2,"b'from ignite.contrib.handlers.base_logger import BaseLogger, BaseOptimizerParamsHandler, BaseOutputHandler\nfrom ignite.handlers import global_step_from_engine\n\n__all__ = [""WandBLogger"", ""OutputHandler"", ""OptimizerParamsHandler"", ""global_step_from_engine""]\n\n\nclass OutputHandler(BaseOutputHandler):\n    """"""Helper handler to log engine\'s output and/or metrics\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.wandb_logger import *\n\n            # Create a logger. All parameters are optional. See documentation\n            # on wandb.init for details.\n\n            wandb_logger = WandBLogger(\n                entity=""shared"",\n                project=""pytorch-ignite-integration"",\n                name=""cnn-mnist"",\n                config={""max_epochs"": 10},\n                tags=[""pytorch-ignite"", ""minst""]\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=lambda *_: trainer.state.iteration,` to take iteration value\n            # of the `trainer`:\n            wandb_logger.attach(\n                evaluator,\n                log_handler=OutputHandler(\n                    tag=""validation"",\n                    metric_names=[""nll"", ""accuracy""],\n                    global_step_transform=lambda *_: trainer.state.iteration,\n                ),\n                event_name=Events.EPOCH_COMPLETED\n            )\n            # or equivalently\n            wandb_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=lambda *_: trainer.state.iteration,\n            )\n\n        Another example, where model is evaluated every 500 iterations:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.wandb_logger import *\n\n            @trainer.on(Events.ITERATION_COMPLETED(every=500))\n            def evaluate(engine):\n                evaluator.run(validation_set, max_epochs=1)\n\n            # Create a logger. All parameters are optional. See documentation\n            # on wandb.init for details.\n\n            wandb_logger = WandBLogger(\n                entity=""shared"",\n                project=""pytorch-ignite-integration"",\n                name=""cnn-mnist"",\n                config={""max_epochs"": 10},\n                tags=[""pytorch-ignite"", ""minst""]\n            )\n\n            def global_step_transform(*args, **kwargs):\n                return trainer.state.iteration\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # every 500 iterations. Since evaluator engine does not have access to the training iteration, we\n            # provide a global_step_transform to return the trainer.state.iteration for the global_step, each time\n            # evaluator metrics are plotted on Weights & Biases.\n\n            wandb_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metrics=[""nll"", ""accuracy""],\n                global_step_transform=global_step_transform\n            )\n\n    Args:\n        tag (str): common title for all produced plots. For example, ""training""\n        metric_names (list of str, optional): list of metric names to plot or a string ""all"" to plot all available\n            metrics.\n        output_transform (callable, optional): output transform function to prepare `engine.state.output` as a number.\n            For example, `output_transform = lambda output: output`\n            This function can also return a dictionary, e.g `{""loss"": loss1, ""another_loss"": loss2}` to label the plot\n            with corresponding keys.\n        global_step_transform (callable, optional): global step transform function to output a desired global step.\n            Input of the function is `(engine, event_name)`. Output of function should be an integer.\n            Default is None, global_step based on attached engine. If provided,\n            uses function output as global_step. To setup global step from another engine, please use\n            :meth:`~ignite.contrib.handlers.wandb_logger.global_step_from_engine`.\n        sync (bool, optional): If set to False, process calls to log in a seperate thread. Default (None) uses whatever\n            the default value of wandb.log.\n\n    Note:\n\n        Example of `global_step_transform`:\n\n        .. code-block:: python\n\n            def global_step_transform(engine, event_name):\n                return engine.state.get_event_attrib_value(event_name)\n\n    """"""\n\n    def __init__(self, tag, metric_names=None, output_transform=None, global_step_transform=None, sync=None):\n        super().__init__(tag, metric_names, output_transform, global_step_transform)\n        self.sync = sync\n\n    def __call__(self, engine, logger, event_name):\n\n        if not isinstance(logger, WandBLogger):\n            raise RuntimeError(""Handler \'{}\' works only with WandBLogger."".format(self.__class__.__name__))\n\n        global_step = self.global_step_transform(engine, event_name)\n        if not isinstance(global_step, int):\n            raise TypeError(\n                ""global_step must be int, got {}.""\n                "" Please check the output of global_step_transform."".format(type(global_step))\n            )\n\n        metrics = self._setup_output_metrics(engine)\n        if self.tag is not None:\n            metrics = {""{tag}/{name}"".format(tag=self.tag, name=name): value for name, value in metrics.items()}\n\n        logger.log(metrics, step=global_step, sync=self.sync)\n\n\nclass OptimizerParamsHandler(BaseOptimizerParamsHandler):\n    """"""Helper handler to log optimizer parameters\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.wandb_logger import *\n\n            # Create a logger. All parameters are optional. See documentation\n            # on wandb.init for details.\n\n            wandb_logger = WandBLogger(\n                entity=""shared"",\n                project=""pytorch-ignite-integration"",\n                name=""cnn-mnist"",\n                config={""max_epochs"": 10},\n                tags=[""pytorch-ignite"", ""minst""]\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            wandb_logger.attach(\n                trainer,\n                log_handler=OptimizerParamsHandler(optimizer),\n                event_name=Events.ITERATION_STARTED\n            )\n            # or equivalently\n            wandb_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer\n            )\n\n    Args:\n        optimizer (torch.optim.Optimizer): torch optimizer which parameters to log\n        param_name (str): parameter name\n        tag (str, optional): common title for all produced plots. For example, ""generator""\n        sync (bool, optional): If set to False, process calls to log in a seperate thread. Default (None) uses whatever\n            the default value of wandb.log.\n    """"""\n\n    def __init__(self, optimizer, param_name=""lr"", tag=None, sync=None):\n        super(OptimizerParamsHandler, self).__init__(optimizer, param_name, tag)\n        self.sync = sync\n\n    def __call__(self, engine, logger, event_name):\n        if not isinstance(logger, WandBLogger):\n            raise RuntimeError(""Handler OptimizerParamsHandler works only with WandBLogger"")\n\n        global_step = engine.state.get_event_attrib_value(event_name)\n        tag_prefix = ""{}/"".format(self.tag) if self.tag else """"\n        params = {\n            ""{}{}/group_{}"".format(tag_prefix, self.param_name, i): float(param_group[self.param_name])\n            for i, param_group in enumerate(self.optimizer.param_groups)\n        }\n        logger.log(params, step=global_step, sync=self.sync)\n\n\nclass WandBLogger(BaseLogger):\n    """"""`Weights & Biases <https://app.wandb.ai/>`_ handler to log metrics, model/optimizer parameters, gradients\n    during training and validation. It can also be used to log model checkpoints to the Weights & Biases cloud.\n\n    .. code-block:: bash\n\n        pip install wandb\n\n    This class is also a wrapper for the wandb module. This means that you can call any wandb function using\n    this wrapper. See examples on how to save model parameters and gradients.\n\n    Args:\n        *args: Positional arguments accepted by `wandb.init`.\n        **kwargs: Keyword arguments accepted by `wandb.init`.\n            Please see `wandb.init <https://docs.wandb.com/library/init>`_ for documentation of possible parameters.\n\n    Examples:\n\n        .. code-block:: python\n\n            from ignite.contrib.handlers.wandb_logger import *\n\n            # Create a logger. All parameters are optional. See documentation\n            # on wandb.init for details.\n\n            wandb_logger = WandBLogger(\n                entity=""shared"",\n                project=""pytorch-ignite-integration"",\n                name=""cnn-mnist"",\n                config={""max_epochs"": 10},\n                tags=[""pytorch-ignite"", ""minst""]\n            )\n\n            # Attach the logger to the trainer to log training loss at each iteration\n            wandb_logger.attach_output_handler(\n                trainer,\n                event_name=Events.ITERATION_COMPLETED,\n                tag=""training"",\n                output_transform=lambda loss: {""loss"": loss}\n            )\n\n            # Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch\n            # We setup `global_step_transform=lambda *_: trainer.state.iteration` to take iteration value\n            # of the `trainer`:\n            wandb_logger.attach_output_handler(\n                train_evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""training"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=lambda *_: trainer.state.iteration,\n            )\n\n            # Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after\n            # each epoch. We setup `global_step_transform=lambda *_: trainer.state.iteration` to take iteration value\n            # of the `trainer` instead of `evaluator`.\n            wandb_logger.attach_output_handler(\n                evaluator,\n                event_name=Events.EPOCH_COMPLETED,\n                tag=""validation"",\n                metric_names=[""nll"", ""accuracy""],\n                global_step_transform=lambda *_: trainer.state.iteration,\n            )\n\n            # Attach the logger to the trainer to log optimizer\'s parameters, e.g. learning rate at each iteration\n            wandb_logger.attach_opt_params_handler(\n                trainer,\n                event_name=Events.ITERATION_STARTED,\n                optimizer=optimizer,\n                param_name=\'lr\'  # optional\n            )\n\n        If you want to log model gradients, the model call graph, etc., use the logger as wrapper of wandb. Refer\n        to the documentation of wandb.watch for details:\n\n        .. code-block:: python\n\n            wandb_logger = WandBLogger(\n                entity=""shared"",\n                project=""pytorch-ignite-integration"",\n                name=""cnn-mnist"",\n                config={""max_epochs"": 10},\n                tags=[""pytorch-ignite"", ""minst""]\n            )\n\n            model = torch.nn.Sequential(...)\n            wandb_logger.watch(model)\n\n        For model checkpointing, Weights & Biases creates a local run dir, and automatically synchronizes all\n        files saved there at the end of the run. You can just use the `wandb_logger.run.dir` as path for the\n        `ModelCheckpoint`:\n\n        .. code-block:: python\n\n            from ignite.handlers import ModelCheckpoint\n\n            def score_function(engine):\n                return engine.state.metrics[\'accuracy\']\n\n            model_checkpoint = ModelCheckpoint(\n                wandb_logger.run.dir, n_saved=2, filename_prefix=\'best\',\n                require_empty=False, score_function=score_function,\n                score_name=""validation_accuracy"",\n                global_step_transform=global_step_from_engine(trainer)\n            )\n            evaluator.add_event_handler(Events.COMPLETED, model_checkpoint, {\'model\': model})\n    """"""\n\n    def __init__(self, *args, **kwargs):\n        try:\n            import wandb\n\n            self._wandb = wandb\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires wandb to be installed. ""\n                ""You man install wandb with the command:\\n pip install wandb\\n""\n            )\n        if kwargs.get(""init"", True):\n            wandb.init(*args, **kwargs)\n\n    def __getattr__(self, attr):\n        return getattr(self._wandb, attr)\n\n    def _create_output_handler(self, *args, **kwargs):\n        return OutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        return OptimizerParamsHandler(*args, **kwargs)\n'"
ignite/contrib/metrics/__init__.py,0,"b'import ignite.contrib.metrics.regression\nfrom ignite.contrib.metrics.average_precision import AveragePrecision\nfrom ignite.contrib.metrics.gpu_info import GpuInfo\nfrom ignite.contrib.metrics.precision_recall_curve import PrecisionRecallCurve\nfrom ignite.contrib.metrics.roc_auc import ROC_AUC, RocCurve\n'"
ignite/contrib/metrics/average_precision.py,1,"b'from ignite.metrics import EpochMetric\n\n\ndef average_precision_compute_fn(y_preds, y_targets):\n    try:\n        from sklearn.metrics import average_precision_score\n    except ImportError:\n        raise RuntimeError(""This contrib module requires sklearn to be installed."")\n\n    y_true = y_targets.numpy()\n    y_pred = y_preds.numpy()\n    return average_precision_score(y_true, y_pred)\n\n\nclass AveragePrecision(EpochMetric):\n    """"""Computes Average Precision accumulating predictions and the ground-truth during an epoch\n    and applying `sklearn.metrics.average_precision_score <http://scikit-learn.org/stable/modules/generated/\n    sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score>`_ .\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n\n    AveragePrecision expects y to be comprised of 0\'s and 1\'s. y_pred must either be probability estimates or\n    confidence values. To apply an activation to y_pred, use output_transform as shown below:\n\n    .. code-block:: python\n\n        def activated_output_transform(output):\n            y_pred, y = output\n            y_pred = torch.softmax(y_pred, dim=1)\n            return y_pred, y\n\n        avg_precision = AveragePrecision(activated_output_transform)\n\n    """"""\n\n    def __init__(self, output_transform=lambda x: x):\n        super(AveragePrecision, self).__init__(average_precision_compute_fn, output_transform=output_transform)\n'"
ignite/contrib/metrics/gpu_info.py,1,"b'# -*- coding: utf-8 -*-\nimport warnings\n\nimport torch\n\nfrom ignite.engine import Events\nfrom ignite.metrics import Metric\n\n\nclass GpuInfo(Metric):\n    """"""Provides GPU information: a) used memory percentage, b) gpu utilization percentage values as Metric\n    on each iterations.\n\n    .. Note ::\n\n        In case if gpu utilization reports ""N/A"" on a given GPU, corresponding metric value is not set.\n\n    Examples:\n\n        .. code-block:: python\n\n            # Default GPU measurements\n            GpuInfo().attach(trainer, name=\'gpu\')  # metric names are \'gpu:X mem(%)\', \'gpu:X util(%)\'\n\n            # Logging with TQDM\n            ProgressBar(persist=True).attach(trainer, metric_names=[\'gpu:0 mem(%)\', \'gpu:0 util(%)\'])\n            # Progress bar will looks like\n            # Epoch [2/10]: [12/24]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88      , gpu:0 mem(%)=79, gpu:0 util(%)=59 [00:17<1:23]\n\n            # Logging with Tensorboard\n            tb_logger.attach(trainer,\n                             log_handler=OutputHandler(tag=""training"", metric_names=\'all\'),\n                             event_name=Events.ITERATION_COMPLETED)\n    """"""\n\n    def __init__(self):\n        try:\n            import pynvml\n        except ImportError:\n            raise RuntimeError(\n                ""This contrib module requires pynvml to be installed. ""\n                ""Please install it with command: \\n pip install pynvml""\n            )\n            # Let\'s check available devices\n        if not torch.cuda.is_available():\n            raise RuntimeError(""This contrib module requires available GPU"")\n\n        from pynvml.smi import nvidia_smi\n\n        # Let it fail if no libnvidia drivers or NMVL library found\n        self.nvsmi = nvidia_smi.getInstance()\n        super(GpuInfo, self).__init__()\n\n    def reset(self):\n        pass\n\n    def update(self, output):\n        pass\n\n    def compute(self):\n        data = self.nvsmi.DeviceQuery(""memory.used, memory.total, utilization.gpu"")\n        if len(data) == 0 or (""gpu"" not in data):\n            warnings.warn(""No GPU information available"")\n            return []\n        return data[""gpu""]\n\n    def completed(self, engine, name):\n        data = self.compute()\n        if len(data) < 1:\n            warnings.warn(""No GPU information available"")\n            return\n\n        for i, data_by_rank in enumerate(data):\n            mem_name = ""{}:{} mem(%)"".format(name, i)\n\n            if ""fb_memory_usage"" not in data_by_rank:\n                warnings.warn(""No GPU memory usage information available in {}"".format(data_by_rank))\n                continue\n            mem_report = data_by_rank[""fb_memory_usage""]\n            if not (""used"" in mem_report and ""total"" in mem_report):\n                warnings.warn(\n                    ""GPU memory usage information does not provide used/total ""\n                    ""memory consumption information in {}"".format(mem_report)\n                )\n                continue\n\n            engine.state.metrics[mem_name] = int(mem_report[""used""] * 100.0 / mem_report[""total""])\n\n        for i, data_by_rank in enumerate(data):\n            util_name = ""{}:{} util(%)"".format(name, i)\n            if ""utilization"" not in data_by_rank:\n                warnings.warn(""No GPU utilization information available in {}"".format(data_by_rank))\n                continue\n            util_report = data_by_rank[""utilization""]\n            if not (""gpu_util"" in util_report):\n                warnings.warn(\n                    ""GPU utilization information does not provide \'gpu_util\' information in {}"".format(util_report)\n                )\n                continue\n            try:\n                engine.state.metrics[util_name] = int(util_report[""gpu_util""])\n            except ValueError:\n                # Do not set GPU utilization information\n                pass\n\n    def attach(self, engine, name=""gpu"", event_name=Events.ITERATION_COMPLETED):\n        engine.add_event_handler(event_name, self.completed, name)\n'"
ignite/contrib/metrics/precision_recall_curve.py,1,"b'from ignite.metrics import EpochMetric\n\n\ndef precision_recall_curve_compute_fn(y_preds, y_targets):\n    try:\n        from sklearn.metrics import precision_recall_curve\n    except ImportError:\n        raise RuntimeError(""This contrib module requires sklearn to be installed."")\n\n    y_true = y_targets.numpy()\n    y_pred = y_preds.numpy()\n    return precision_recall_curve(y_true, y_pred)\n\n\nclass PrecisionRecallCurve(EpochMetric):\n    """"""Compute precision-recall pairs for different probability thresholds for binary classification task\n    by accumulating predictions and the ground-truth during an epoch and applying\n    `sklearn.metrics.precision_recall_curve <http://scikit-learn.org/stable/modules/generated/\n    sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve>`_ .\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n\n    PrecisionRecallCurve expects y to be comprised of 0\'s and 1\'s. y_pred must either be probability estimates\n    or confidence values. To apply an activation to y_pred, use output_transform as shown below:\n\n    .. code-block:: python\n\n        def activated_output_transform(output):\n            y_pred, y = output\n            y_pred = torch.sigmoid(y_pred)\n            return y_pred, y\n\n        roc_auc = PrecisionRecallCurve(activated_output_transform)\n\n    """"""\n\n    def __init__(self, output_transform=lambda x: x):\n        super(PrecisionRecallCurve, self).__init__(precision_recall_curve_compute_fn, output_transform=output_transform)\n'"
ignite/contrib/metrics/roc_auc.py,2,"b'from ignite.metrics import EpochMetric\n\n\ndef roc_auc_compute_fn(y_preds, y_targets):\n    try:\n        from sklearn.metrics import roc_auc_score\n    except ImportError:\n        raise RuntimeError(""This contrib module requires sklearn to be installed."")\n\n    y_true = y_targets.numpy()\n    y_pred = y_preds.numpy()\n    return roc_auc_score(y_true, y_pred)\n\n\ndef roc_auc_curve_compute_fn(y_preds, y_targets):\n    try:\n        from sklearn.metrics import roc_curve\n    except ImportError:\n        raise RuntimeError(""This contrib module requires sklearn to be installed."")\n\n    y_true = y_targets.numpy()\n    y_pred = y_preds.numpy()\n    return roc_curve(y_true, y_pred)\n\n\nclass ROC_AUC(EpochMetric):\n    """"""Computes Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n    accumulating predictions and the ground-truth during an epoch and applying\n    `sklearn.metrics.roc_auc_score <http://scikit-learn.org/stable/modules/generated/\n    sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score>`_ .\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n\n    ROC_AUC expects y to be comprised of 0\'s and 1\'s. y_pred must either be probability estimates or confidence\n    values. To apply an activation to y_pred, use output_transform as shown below:\n\n    .. code-block:: python\n\n        def activated_output_transform(output):\n            y_pred, y = output\n            y_pred = torch.sigmoid(y_pred)\n            return y_pred, y\n\n        roc_auc = ROC_AUC(activated_output_transform)\n\n    """"""\n\n    def __init__(self, output_transform=lambda x: x):\n        super(ROC_AUC, self).__init__(roc_auc_compute_fn, output_transform=output_transform)\n\n\nclass RocCurve(EpochMetric):\n    """"""Compute Receiver operating characteristic (ROC) for binary classification task\n    by accumulating predictions and the ground-truth during an epoch and applying\n    `sklearn.metrics.roc_curve <http://scikit-learn.org/stable/modules/generated/\n    sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve>`_ .\n\n    Args:\n        output_transform (callable, optional): a callable that is used to transform the\n            :class:`~ignite.engine.Engine`\'s `process_function`\'s output into the\n            form expected by the metric. This can be useful if, for example, you have a multi-output model and\n            you want to compute the metric with respect to one of the outputs.\n\n    RocCurve expects y to be comprised of 0\'s and 1\'s. y_pred must either be probability estimates or confidence\n    values. To apply an activation to y_pred, use output_transform as shown below:\n\n    .. code-block:: python\n\n        def activated_output_transform(output):\n            y_pred, y = output\n            y_pred = torch.sigmoid(y_pred)\n            return y_pred, y\n\n        roc_auc = RocCurve(activated_output_transform)\n\n    """"""\n\n    def __init__(self, output_transform=lambda x: x):\n        super(RocCurve, self).__init__(roc_auc_curve_compute_fn, output_transform=output_transform)\n'"
ignite/distributed/comp_models/__init__.py,0,"b'from ignite.distributed.comp_models.base import _SerialModel\nfrom ignite.distributed.comp_models.native import has_native_dist_support\nfrom ignite.distributed.comp_models.xla import has_xla_support\n\n\ndef setup_available_computation_models():\n    models = [\n        _SerialModel,\n    ]\n    if has_native_dist_support:\n        from ignite.distributed.comp_models.native import _NativeDistModel\n\n        models.append(_NativeDistModel)\n    if has_xla_support:\n        from ignite.distributed.comp_models.xla import _XlaDistModel\n\n        models.append(_XlaDistModel)\n\n    return tuple(models)\n\n\nregistered_computation_models = setup_available_computation_models()\n'"
ignite/distributed/comp_models/base.py,23,"b'import warnings\nfrom abc import ABCMeta, abstractmethod\nfrom numbers import Number\nfrom typing import Callable, List, Optional, Union\n\nimport torch\n\n\nclass ComputationModel(metaclass=ABCMeta):\n    """"""Base class for distributed computation models and defines interface methods.\n\n    This class is public and should be used for other custom derived distributed models.\n    """"""\n\n    # this is an additional local rank storage used when idist is setup from existing native torch dist context\n    _ext_local_rank = None\n\n    def __init__(self):\n        self._backend = None\n        self._ntasks_per_node = None\n        self._nnodes = None\n        self._node = None\n\n    def _setup_attrs(self):\n        if self._ntasks_per_node is None:\n            self._ntasks_per_node = self._compute_ntasks_per_node() if self.get_world_size() > 1 else 1\n        if self._nnodes is None:\n            self._nnodes = self.get_world_size() // self._ntasks_per_node\n        if self._node is None:\n            self._node = self.get_rank() // self._ntasks_per_node\n\n    @abstractmethod\n    def _compute_ntasks_per_node(self) -> int:\n        pass\n\n    @abstractmethod\n    def get_local_rank(self) -> int:\n        pass\n\n    @abstractmethod\n    def get_rank(self) -> int:\n        pass\n\n    @abstractmethod\n    def get_world_size(self) -> int:\n        pass\n\n    @abstractmethod\n    def get_ntasks_per_node(self) -> int:\n        pass\n\n    @abstractmethod\n    def get_num_nodes(self) -> int:\n        pass\n\n    @abstractmethod\n    def get_node_rank(self) -> int:\n        pass\n\n    @abstractmethod\n    def device(self) -> torch.device:\n        pass\n\n    @abstractmethod\n    def backend(self) -> Optional[str]:\n        pass\n\n    @abstractmethod\n    def finalize(self):\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def create_from_context() -> Optional[""ComputationModel""]:\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def create_from_backend(backend: str, **kwargs) -> ""ComputationModel"":\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def spawn(*args, **kwargs):\n        pass\n\n    _collective_op_dtype = None\n\n    @staticmethod\n    def _encode_str(x: str, device: torch.device) -> torch.Tensor:\n        # use fix padded size\n        size = 1024\n        if len(x) > size:\n            warnings.warn(""Input string size {} is larger than {} and thus will be truncated"".format(len(x), size))\n            x = x[:size]\n\n        name = torch.tensor(bytearray(x, ""utf-8"")).to(device)\n        padded_x = torch.zeros(size + 1, device=device, dtype=torch.long)\n        padded_x[: len(name)] = name\n        padded_x[-1] = len(name)\n        return padded_x.unsqueeze(0)\n\n    @staticmethod\n    def _decode_str(xs: torch.Tensor) -> List[str]:\n        # xs.shape = (world_size, 1025)\n        out = [bytearray(x[: x[-1]].tolist()).decode(""utf-8"") for x in xs]\n        return out\n\n    def _all_collective_op(\n        self, tensor: Union[torch.Tensor, Number, str], fn: Callable, *args, **kwargs\n    ) -> Union[torch.Tensor, Number, List[str]]:\n        tensor_to_number = tensor_to_str = False\n        device = self.device()\n        if isinstance(tensor, Number):\n            tensor_to_number = True\n            tensor = torch.tensor(tensor, device=device, dtype=self._collective_op_dtype)\n        elif isinstance(tensor, str):\n            tensor_to_str = True\n            tensor = self._encode_str(tensor, device)\n\n        out_dtype = None\n\n        # check if the tensor is at specified device\n        if tensor.device != device:\n            tensor = tensor.to(device)\n        if self._collective_op_dtype is not None:\n            # cast to _collective_op_dtype if current type is not floatX\n            if tensor.dtype not in (torch.float32, torch.float64):\n                out_dtype = tensor.dtype\n                tensor = tensor.to(self._collective_op_dtype)\n\n        tensor = fn(tensor, *args, **kwargs)\n\n        if out_dtype is not None:\n            tensor = tensor.to(dtype=out_dtype)\n\n        if tensor_to_number and tensor.numel() == 1:\n            return tensor.item()\n        elif tensor_to_str:\n            return self._decode_str(tensor)\n        return tensor\n\n    def all_reduce(self, tensor: Union[torch.Tensor, Number], op: str = ""sum"") -> Union[torch.Tensor, Number]:\n        if not isinstance(tensor, (torch.Tensor, Number)):\n            raise TypeError(""Unhandled input type {}"".format(type(tensor)))\n\n        return self._all_collective_op(tensor, self._do_all_reduce, op)\n\n    def all_gather(self, tensor: Union[torch.Tensor, Number, str]) -> Union[torch.Tensor, Number, List[str]]:\n        if not isinstance(tensor, (torch.Tensor, Number, str)):\n            raise TypeError(""Unhandled input type {}"".format(type(tensor)))\n\n        return self._all_collective_op(tensor, self._do_all_gather)\n\n    @abstractmethod\n    def _do_all_reduce(self, tensor: torch.Tensor, op: str = ""sum"") -> torch.Tensor:\n        pass\n\n    @abstractmethod\n    def _do_all_gather(self, tensor: torch.Tensor) -> torch.Tensor:\n        pass\n\n    @abstractmethod\n    def barrier(self):\n        pass\n\n\nclass _SerialModel(ComputationModel):\n    """"""Private class defines non-distributed computation model for code compatibility with other distributed models.\n    """"""\n\n    name = ""serial""\n    available_backends = tuple()\n\n    def get_local_rank(self) -> int:\n        return 0\n\n    def get_rank(self) -> int:\n        return 0\n\n    def get_world_size(self) -> int:\n        return 1\n\n    def get_ntasks_per_node(self) -> int:\n        return 1\n\n    def get_num_nodes(self) -> int:\n        return 1\n\n    def get_node_rank(self) -> int:\n        return 0\n\n    def device(self) -> torch.device:\n        if torch.cuda.is_available():\n            return torch.device(""cuda"")\n        return torch.device(""cpu"")\n\n    def backend(self) -> None:\n        return None\n\n    def finalize(self):\n        pass\n\n    def _compute_ntasks_per_node(self) -> int:\n        return 1\n\n    @staticmethod\n    def create_from_context() -> ""_SerialModel"":\n        return _SerialModel()\n\n    @staticmethod\n    def create_from_backend(backend: Optional[str] = None, **kwargs) -> ""_SerialModel"":\n        return _SerialModel()\n\n    @staticmethod\n    def spawn(*args, **kwargs):\n        raise NotImplementedError(""Serial computation model does not implement spawn method"")\n\n    def all_reduce(self, tensor: Union[torch.Tensor, Number], op: str = ""sum"") -> Union[torch.Tensor, Number]:\n        return tensor\n\n    def all_gather(self, tensor: Union[torch.Tensor, Number]) -> Union[torch.Tensor, Number]:\n        return tensor\n\n    def _do_all_reduce(self, tensor: torch.Tensor, op: str = ""sum"") -> torch.Tensor:\n        pass\n\n    def _do_all_gather(self, tensor: torch.Tensor) -> torch.Tensor:\n        pass\n\n    def barrier(self):\n        pass\n'"
ignite/distributed/comp_models/native.py,21,"b'import os\nimport subprocess\nimport warnings\nfrom distutils.version import LooseVersion\nfrom typing import Callable, Mapping, Optional, Tuple\n\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\nfrom ignite.distributed.comp_models.base import ComputationModel\n\nhas_native_dist_support = dist.is_available()\n\n\nif has_native_dist_support:\n\n    class _NativeDistModel(ComputationModel):\n        """"""Private class for PyTorch native distributed computation model.\n\n        Supported `backends <https://pytorch.org/docs/stable/distributed.html#backends>`_:\n\n        - NCCL\n        - GLOO\n        - MPI\n\n        In this implementation we assume the following mapping between backend and devices:\n\n        - NCCL <-> GPU\n        - GLOO <-> CPU\n        - MPI  <-> CPU\n\n        """"""\n\n        name = ""native-dist""\n        available_backends = tuple(\n            name\n            for name in [dist.Backend.NCCL, dist.Backend.GLOO, dist.Backend.MPI]\n            if getattr(dist, ""is_{}_available"".format(name))()\n        )\n\n        @staticmethod\n        def create_from_context() -> Optional[""_NativeDistModel""]:\n            if not (dist.is_available() and dist.is_initialized()):\n                return None\n            return _NativeDistModel()\n\n        @staticmethod\n        def create_from_backend(backend: str, **kwargs) -> ""_NativeDistModel"":\n            if dist.is_available() and dist.is_initialized():\n                raise RuntimeError(""Can not create new distributed process group if default one is already initialized"")\n            return _NativeDistModel(backend=backend, **kwargs)\n\n        def __init__(self, backend=None, timeout=None, **kwargs):\n            """"""This is a private method. Please, use `create_from_backend` or `create_from_context`\n            """"""\n            super(_NativeDistModel, self).__init__()\n            if backend is not None:\n                self._create_from_backend(backend, timeout=timeout, **kwargs)\n            else:\n                self._init_from_context()\n\n        def _create_from_backend(self, backend, timeout=None, **kwargs):\n            self.setup_env_vars()\n\n            self._local_rank = int(os.environ[""LOCAL_RANK""])\n            # for debug purposes\n            self._master_port = int(os.environ[""MASTER_PORT""])\n            self._master_addr = os.environ[""MASTER_ADDR""]\n\n            init_pg_kwargs = {}\n            if timeout is not None:\n                init_pg_kwargs[""timeout""] = timeout\n\n            dist.init_process_group(backend, init_method=""env://"", **init_pg_kwargs)\n            # https://github.com/facebookresearch/maskrcnn-benchmark/issues/172\n            dist.barrier()\n\n            if backend == dist.Backend.NCCL:\n                torch.cuda.set_device(self._local_rank)\n\n            self._setup_attrs()\n\n        def _init_from_context(self):\n\n            self._identify_local_rank()\n\n            # for debug purposes\n            self._master_port = None\n            self._master_addr = None\n            self._setup_attrs()\n\n        def _compute_ntasks_per_node(self):\n            tensor = torch.tensor([self.get_local_rank() + 1]).to(self.device())\n            dist.all_reduce(tensor, op=dist.ReduceOp.MAX)\n            return tensor.item()\n\n        def _get_all_hostnames(self):\n            import socket\n\n            device = ""cpu""\n            if self.backend() == dist.Backend.NCCL:\n                index = torch.cuda.current_device()\n                device = ""cuda:{}"".format(index)\n            name = socket.gethostname()\n            name = torch.tensor(bytearray(name, ""utf-8"")).to(device)\n            padded_t_name = torch.zeros(256, device=device, dtype=torch.long)\n            padded_t_name[: len(name)] = name\n            out_t_names = [torch.zeros_like(padded_t_name) for _ in range(self.get_world_size())]\n            dist.all_gather(out_t_names, padded_t_name)\n            out_t_names = [tuple(t.cpu().tolist()) for t in out_t_names]\n            return out_t_names\n\n        @staticmethod\n        def _compute_node_and_local_ranks(rank, hostnames):\n            from collections import Counter\n\n            c = Counter(hostnames)\n            sizes = torch.tensor([0,] + list(c.values()))\n            cumsum_sizes = torch.cumsum(sizes, dim=0)\n            node_rank = (rank // cumsum_sizes[1:]).clamp(0, 1).sum().item()\n            local_rank = rank - cumsum_sizes[node_rank].item()\n            return local_rank, node_rank\n\n        def _compute_local_rank_via_hostname(self):\n            # get all hostnames\n            hostnames = self._get_all_hostnames()\n            local_rank, self._node = self._compute_node_and_local_ranks(self.get_rank(), hostnames)\n\n            if local_rank < 0 or self._node < 0:\n                raise ValueError(\n                    ""Failed to correctly estimate local rank. ""\n                    ""Debugging info: local rank: {}, node rank: {}, hostnames: {}"".format(\n                        local_rank, self._node, hostnames\n                    )\n                )\n            return local_rank\n\n        def _identify_local_rank(self):\n\n            if ""SLURM_JOBID"" in os.environ:\n                os.environ[""LOCAL_RANK""] = os.environ[""SLURM_LOCALID""]\n\n            if ""LOCAL_RANK"" in os.environ:\n                self._local_rank = int(os.environ[""LOCAL_RANK""])\n            elif self._ext_local_rank is not None:\n                self._local_rank = self._ext_local_rank\n            else:\n                warnings.warn(\n                    ""Local rank information for native distributed setting will be initialized using ""\n                    ""heuristic approach based on hostname which can be different of real setup. Please, ""\n                    ""either set `os.environ[\'LOCAL_RANK\']` ""\n                    ""or use `idist.set_local_rank(local_rank)` with correct local rank index.""\n                )\n                # use socket gethostname heuristic to determine number of nodes => local rank\n                self._local_rank = self._compute_local_rank_via_hostname()\n\n        def setup_env_vars(self):\n            if ""SLURM_JOBID"" in os.environ:\n                self._setup_env_in_slurm()\n                return\n\n            # check if all necessary env vars are set\n            # if partially defined raise an error\n            necessary_env_vars = [""RANK"", ""LOCAL_RANK"", ""WORLD_SIZE""]\n            all_env_vars_defined = [k in os.environ for k in necessary_env_vars]\n            if any(all_env_vars_defined) and not all(all_env_vars_defined):\n                raise RuntimeError(\n                    ""PyTorch distributed configuration should define env variables \'{}\'"".format(necessary_env_vars)\n                )\n\n            os.environ[""RANK""] = os.environ.get(""RANK"", ""0"")\n            os.environ[""LOCAL_RANK""] = os.environ.get(""LOCAL_RANK"", ""0"")\n            os.environ[""WORLD_SIZE""] = os.environ.get(""WORLD_SIZE"", ""1"")\n            os.environ[""MASTER_ADDR""] = os.environ.get(""MASTER_ADDR"", ""127.0.0.1"")\n            os.environ[""MASTER_PORT""] = os.environ.get(""MASTER_PORT"", ""15000"")\n\n        def _setup_env_in_slurm(self):\n            for k in [""SLURM_PROCID"", ""SLURM_LOCALID"", ""SLURM_NTASKS"", ""SLURM_JOB_NODELIST""]:\n                if k not in os.environ:\n                    raise RuntimeError(""SLURM distributed configuration is missing \'{}\' in env variables"".format(k))\n\n            os.environ[""RANK""] = os.environ[""SLURM_PROCID""]\n            os.environ[""LOCAL_RANK""] = os.environ[""SLURM_LOCALID""]\n            os.environ[""WORLD_SIZE""] = os.environ[""SLURM_NTASKS""]\n            # port should be the same over all process\n            slurm_port = os.environ[""SLURM_JOB_ID""]\n            slurm_port = slurm_port[-4:]\n            os.environ[""MASTER_PORT""] = str(int(slurm_port) + 15000)\n            # master address is the first hostname of nodes list\n            hostnames = subprocess.check_output([""scontrol"", ""show"", ""hostnames"", os.environ[""SLURM_JOB_NODELIST""]])\n            os.environ[""MASTER_ADDR""] = hostnames.split()[0].decode(""utf-8"")\n\n        def get_local_rank(self) -> int:\n            return self._local_rank\n\n        def get_rank(self) -> int:\n            return dist.get_rank()\n\n        def get_world_size(self) -> int:\n            return dist.get_world_size()\n\n        def get_ntasks_per_node(self) -> int:\n            return self._ntasks_per_node\n\n        def get_num_nodes(self) -> int:\n            return self._nnodes\n\n        def get_node_rank(self) -> int:\n            return self._node\n\n        def device(self) -> torch.device:\n            if self.backend() == dist.Backend.NCCL:\n                index = torch.cuda.current_device()\n                return torch.device(""cuda:{}"".format(index))\n            return torch.device(""cpu"")\n\n        def backend(self) -> str:\n            return dist.get_backend()\n\n        def finalize(self):\n            dist.destroy_process_group()\n\n        @staticmethod\n        def _dist_worker_task_fn(\n            local_rank, backend, fn, args, kw_dict, world_size, nprocs_per_node, node_rank, master_addr, master_port, kw\n        ):\n            from ignite.distributed.utils import _set_model, finalize\n\n            copy_env_vars = dict(os.environ)\n\n            os.environ[""LOCAL_RANK""] = str(local_rank)\n            os.environ[""RANK""] = str(node_rank * nprocs_per_node + local_rank)\n            os.environ[""WORLD_SIZE""] = str(world_size)\n            os.environ[""MASTER_ADDR""] = str(master_addr)\n            os.environ[""MASTER_PORT""] = str(master_port)\n\n            model = _NativeDistModel.create_from_backend(backend, **kw)\n            _set_model(model)\n            fn(local_rank, *args, **kw_dict)\n            finalize()\n\n            os.environ = copy_env_vars\n\n        @staticmethod\n        def spawn(\n            fn: Callable,\n            args: Tuple,\n            kwargs_dict: Optional[Mapping] = None,\n            num_procs_per_node: int = 1,\n            num_nodes: int = 1,\n            node_rank: int = 0,\n            master_addr: str = ""127.0.0.1"",\n            master_port: int = 2222,\n            backend: str = ""nccl"",\n            **kwargs\n        ):\n            world_size = num_nodes * num_procs_per_node\n\n            spawn_kwargs = {\n                ""join"": kwargs.get(""join"", True),\n                ""daemon"": kwargs.get(""daemon"", False),\n            }\n            # start_method in pytorch >= 1.5\n            if LooseVersion(torch.__version__) >= LooseVersion(""1.5.0""):\n                spawn_kwargs[""start_method""] = kwargs.get(""start_method"", ""spawn"")\n\n            mp.spawn(\n                _NativeDistModel._dist_worker_task_fn,\n                nprocs=num_procs_per_node,\n                args=(\n                    backend,\n                    fn,\n                    args,\n                    kwargs_dict,\n                    world_size,\n                    num_procs_per_node,\n                    node_rank,\n                    master_addr,\n                    master_port,\n                    kwargs,\n                ),\n                **spawn_kwargs,\n            )\n\n        _reduce_op_map = {\n            ""SUM"": dist.ReduceOp.SUM,\n            ""PRODUCT"": dist.ReduceOp.PRODUCT,\n            ""MIN"": dist.ReduceOp.MIN,\n            ""MAX"": dist.ReduceOp.MAX,\n        }\n        if LooseVersion(torch.__version__) > LooseVersion(""1.2.0""):\n            _reduce_op_map.update(\n                {""AND"": dist.ReduceOp.BAND, ""OR"": dist.ReduceOp.BOR,}\n            )\n\n        def _do_all_reduce(self, tensor: torch.Tensor, op: str = ""SUM"") -> torch.Tensor:\n            if op not in self._reduce_op_map:\n                raise ValueError(""Unsupported reduction operation: \'{}\'"".format(op))\n            op = self._reduce_op_map[op]\n            dist.all_reduce(tensor, op)\n            return tensor\n\n        def _do_all_gather(self, tensor: torch.Tensor) -> torch.Tensor:\n            if tensor.ndimension() == 0:\n                tensor = tensor.unsqueeze(0)\n            output = [torch.zeros_like(tensor) for _ in range(self.get_world_size())]\n            dist.all_gather(output, tensor)\n            return torch.cat(output, dim=0)\n\n        def barrier(self):\n            dist.barrier()\n'"
ignite/distributed/comp_models/xla.py,7,"b'from typing import Callable, Mapping, Optional, Tuple\n\nimport torch\n\nfrom ignite.distributed.comp_models.base import ComputationModel\n\ntry:\n    import torch_xla\n    import torch_xla.core.xla_model as xm\n    import torch_xla.distributed.xla_multiprocessing as xmp\n\n    has_xla_support = True\nexcept ImportError:\n    has_xla_support = False\n\n\nif has_xla_support:\n\n    class _XlaDistModel(ComputationModel):\n        """"""Private class for PyTorch XLA basic distributed computation model.\n        It handles single/multi-device computation model.\n\n        Supported XLA devices:\n\n        - CPU\n        - TPU\n\n        """"""\n\n        name = ""xla-dist""\n\n        available_backends = tuple([""xla-tpu"",])\n\n        @staticmethod\n        def create_from_context() -> Optional[""_XlaDistModel""]:\n            return _XlaDistModel()\n\n        @staticmethod\n        def create_from_backend(backend: str = ""xla-tpu"", **kwargs) -> ""_XlaDistModel"":\n            return _XlaDistModel(backend=backend, **kwargs)\n\n        def __init__(self, backend=None, **kwargs):\n            """"""This is a private method. Please, use `create_from_backend` or `create_from_context`\n            """"""\n            super(_XlaDistModel, self).__init__()\n            if backend is not None:\n                self._create_from_backend(backend, **kwargs)\n            else:\n                self._init_from_context()\n\n        def _create_from_backend(self, backend, **kwargs):\n            xm.rendezvous(""init"")\n\n            self._backend = backend\n            self._setup_attrs()\n\n        def _init_from_context(self):\n            self._backend = ""xla-tpu""\n            self._setup_attrs()\n\n        def _compute_ntasks_per_node(self):\n            tensor = torch.tensor([self.get_local_rank() + 1.0], dtype=torch.float).to(self.device())\n            xm.all_reduce(""max"", [tensor,])\n            return int(tensor.item())\n\n        def get_local_rank(self) -> int:\n            return xm.get_local_ordinal()\n\n        def get_rank(self) -> int:\n            return xm.get_ordinal()\n\n        def get_world_size(self) -> int:\n            return xm.xrt_world_size()\n\n        def get_ntasks_per_node(self) -> int:\n            return self._ntasks_per_node\n\n        def get_num_nodes(self) -> int:\n            return self._nnodes\n\n        def get_node_rank(self) -> int:\n            return self._node\n\n        def device(self) -> torch.device:\n            dev = torch_xla._XLAC._xla_get_default_device()\n            return torch.device(dev)\n\n        def backend(self) -> str:\n            return self._backend\n\n        def finalize(self):\n            pass\n\n        @staticmethod\n        def _dist_worker_task_fn(local_rank, backend, fn, args, kwargs_dict):\n            from ignite.distributed.utils import _set_model, finalize\n\n            model = _XlaDistModel.create_from_backend(backend)\n            _set_model(model)\n            fn(local_rank, *args, **kwargs_dict)\n            finalize()\n\n        @staticmethod\n        def spawn(\n            fn: Callable,\n            args: Tuple,\n            kwargs_dict: Optional[Mapping] = None,\n            num_procs_per_node: int = 1,\n            num_nodes: int = 1,\n            node_rank: int = 0,\n            backend: str = ""xla-tpu"",\n            **kwargs\n        ):\n            import os\n\n            if ""COLAB_TPU_ADDR"" in os.environ:\n                kwargs[""start_method""] = ""fork""\n\n            xmp.spawn(\n                _XlaDistModel._dist_worker_task_fn,\n                args=(backend, fn, args, kwargs_dict),\n                nprocs=num_procs_per_node,\n                **kwargs,\n            )\n\n        _collective_op_dtype = torch.float32\n        _reduce_op_map = {\n            ""SUM"": ""sum"",\n            ""PRODUCT"": ""mul"",\n            ""MIN"": ""min"",\n            ""MAX"": ""max"",\n            ""AND"": ""and"",\n            ""OR"": ""or"",\n        }\n\n        def _do_all_reduce(self, tensor: torch.Tensor, op: str = ""SUM"") -> torch.Tensor:\n            if op not in self._reduce_op_map:\n                raise ValueError(""Unsupported reduction operation: \'{}\'"".format(op))\n            op = self._reduce_op_map[op]\n            xm.all_reduce(op, [tensor,])\n            return tensor\n\n        def _do_all_gather(self, tensor: torch.Tensor) -> torch.Tensor:\n            # from https://github.com/jysohn23/xla/blob/model-parallel-colab/Gather_Scatter_Broadcast_PyTorch_XLA.ipynb\n            group_size = self.get_world_size()\n            output = torch.zeros((group_size,) + tensor.shape, dtype=tensor.dtype, device=tensor.device)\n            output[self.get_rank() % group_size] = tensor\n            xm.all_reduce(""sum"", [output,])\n            return output.reshape(-1, *output.shape[2:])\n\n        def barrier(self):\n            xm.rendezvous(""barrier"")\n'"
tests/ignite/base/__init__.py,0,b''
tests/ignite/base/test_mixins.py,0,b'from ignite.base import Serializable\n\n\ndef test_load_state_dict():\n\n    s = Serializable()\n    s.load_state_dict({})\n'
tests/ignite/contrib/__init__.py,0,b'# coding: utf-8\n'
tests/ignite/contrib/conftest.py,0,"b'import pytest\n\n\n@pytest.fixture()\ndef visdom_server():\n\n    import os\n    import signal\n    import subprocess\n    import time\n\n    from visdom.server import download_scripts\n\n    download_scripts()\n\n    hostname = ""localhost""\n    port = 8098\n    p = subprocess.Popen(""visdom --hostname {} -port {}"".format(hostname, port), shell=True, preexec_fn=os.setsid)\n    time.sleep(5)\n    yield (hostname, port)\n    os.killpg(os.getpgid(p.pid), signal.SIGTERM)\n'"
tests/ignite/distributed/__init__.py,0,b''
tests/ignite/distributed/test_utils.py,30,"b'import os\n\nimport pytest\nimport torch\nimport torch.distributed as dist\n\nimport ignite.distributed as idist\nfrom ignite.distributed.utils import has_native_dist_support, has_xla_support, sync\nfrom ignite.engine import Engine, Events\n\n\ndef _sanity_check():\n    from ignite.distributed.utils import _model\n\n    assert _model.get_world_size() == _model.get_num_nodes() * _model.get_ntasks_per_node()\n    assert _model.get_local_rank() < _model.get_ntasks_per_node()\n    assert _model.get_rank() < _model.get_world_size()\n    assert _model.get_node_rank() < _model.get_num_nodes()\n\n\ndef test_no_distrib(capsys):\n\n    from ignite.distributed.utils import _model\n\n    print(""test_no_distrib : dist: "", dist.is_available())\n    print(""test_no_distrib : _model"", type(_model))\n\n    assert idist.backend() is None\n    if torch.cuda.is_available():\n        assert idist.device().type == ""cuda""\n    else:\n        assert idist.device().type == ""cpu""\n    assert idist.get_rank() == 0\n    assert idist.get_world_size() == 1\n    assert idist.get_local_rank() == 0\n    assert idist.model_name() == ""serial""\n\n    from ignite.distributed.utils import _model, _SerialModel\n\n    _sanity_check()\n    assert isinstance(_model, _SerialModel)\n\n    idist.show_config()\n    captured = capsys.readouterr()\n    out = captured.err.split(""\\r"")\n    out = list(map(lambda x: x.strip(), out))\n    out = list(filter(None, out))\n    assert ""ignite.distributed.utils INFO: distributed configuration: serial"" in out[-1]\n    assert ""ignite.distributed.utils INFO: backend: None"" in out[-1]\n    if torch.cuda.is_available():\n        assert ""ignite.distributed.utils INFO: device: cuda"" in out[-1]\n    else:\n        assert ""ignite.distributed.utils INFO: device: cpu"" in out[-1]\n    assert ""ignite.distributed.utils INFO: rank: 0"" in out[-1]\n    assert ""ignite.distributed.utils INFO: local rank: 0"" in out[-1]\n    assert ""ignite.distributed.utils INFO: world size: 1"" in out[-1]\n\n\ndef _test_distrib_config(local_rank, backend, ws, true_device, rank=None):\n    assert idist.backend() == backend, ""{} vs {}"".format(idist.backend(), backend)\n\n    this_device = idist.device()\n    assert isinstance(this_device, torch.device)\n    if backend == ""nccl"":\n        true_device = torch.device(""{}:{}"".format(true_device, local_rank))\n        assert this_device == true_device, ""{} vs {}"".format(this_device, true_device)\n    elif backend == ""gloo"":\n        assert this_device == torch.device(true_device)\n    elif backend == ""xla-tpu"":\n        assert true_device in this_device.type\n\n    if rank is None:\n        if idist.model_name() == ""native-dist"":\n            rank = dist.get_rank()\n            assert idist.get_rank() == rank\n\n    assert idist.get_world_size() == ws\n    assert idist.get_local_rank() == local_rank\n\n    assert idist.model_name() in (""native-dist"", ""xla-dist"")\n\n    _sanity_check()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_native_distrib_single_node_launch_tool_gloo(local_rank, world_size):\n    import os\n    from datetime import timedelta\n\n    timeout = timedelta(seconds=20)\n    rank = local_rank\n    os.environ[""RANK""] = ""{}"".format(rank)\n\n    idist.initialize(""gloo"", timeout=timeout)\n    _test_distrib_config(local_rank, ""gloo"", world_size, ""cpu"", rank)\n    idist.finalize()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_native_distrib_single_node_launch_tool_nccl(local_rank, world_size):\n    import os\n\n    rank = local_rank\n    os.environ[""RANK""] = ""{}"".format(rank)\n\n    idist.initialize(""nccl"")\n    _test_distrib_config(local_rank, ""nccl"", world_size, ""cuda"", rank)\n    idist.finalize()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""WORLD_SIZE"" in os.environ, reason=""Skip if launched as multiproc"")\ndef test_native_distrib_single_node_spawn_gloo():\n\n    from datetime import timedelta\n\n    timeout = timedelta(seconds=20)\n\n    world_size = 4\n\n    idist.spawn(\n        ""gloo"", _test_distrib_config, args=(""gloo"", world_size, ""cpu""), num_procs_per_node=world_size, timeout=timeout\n    )\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""WORLD_SIZE"" in os.environ, reason=""Skip if launched as multiproc"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_native_distrib_single_node_spawn_nccl():\n    world_size = torch.cuda.device_count()\n\n    idist.spawn(""nccl"", _test_distrib_config, args=(""nccl"", world_size, ""cuda""), num_procs_per_node=world_size)\n\n\n@pytest.mark.skipif(has_xla_support, reason=""Skip if has PyTorch XLA package"")\ndef test_xla_distrib_spawn_no_xla_support():\n    with pytest.raises(ValueError, match=r""Backend should be one of""):\n        idist.spawn(""xla-tpu"", _test_distrib_config, args=(""xla-tpu"", 1, ""xla""), num_procs_per_node=1)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_xla_distrib_single_node_no_spawn():\n    idist.initialize(""xla-tpu"")\n    _test_distrib_config(local_rank=0, backend=""xla-tpu"", ws=1, true_device=""xla"")\n    idist.finalize()\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_xla_distrib_single_node_spawn_one_proc():\n    try:\n        idist.spawn(""xla-tpu"", _test_distrib_config, args=(""xla-tpu"", 1, ""xla""), num_procs_per_node=1)\n    except SystemExit:\n        pass\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_xla_distrib_single_node_spawn_n_procs():\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    try:\n        idist.spawn(""xla-tpu"", _test_distrib_config, args=(""xla-tpu"", n, ""xla""), num_procs_per_node=n)\n    except SystemExit:\n        pass\n\n\ndef _test_sync(cls):\n    from ignite.distributed.utils import _set_model, _SerialModel\n\n    _set_model(_SerialModel())\n\n    sync()\n\n    from ignite.distributed.utils import _model\n\n    assert isinstance(_model, cls), ""{} vs {}"".format(type(_model), cls)\n\n\ndef test_sync_no_dist():\n    from ignite.distributed.comp_models import _SerialModel\n\n    _test_sync(_SerialModel)\n\n\ndef test_idist_methods_no_dist():\n    assert idist.get_world_size() < 2\n    assert idist.backend() is None, ""{}"".format(idist.backend())\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_sync_as_xla():\n    from ignite.distributed.comp_models.xla import _XlaDistModel\n\n    _test_sync(_XlaDistModel)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_sync_as_native_gloo(distributed_context_single_node_gloo):\n    from ignite.distributed.comp_models.native import _NativeDistModel\n\n    _test_sync(_NativeDistModel)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_sync_as_native_nccl(distributed_context_single_node_nccl):\n    from ignite.distributed.comp_models.native import _NativeDistModel\n\n    _test_sync(_NativeDistModel)\n\n\ndef _test_sync_as_xla_in_child_proc(index):\n    from ignite.distributed.comp_models.xla import _XlaDistModel\n\n    _test_sync(_XlaDistModel)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_sync_as_xla_in_child_proc(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_sync_as_xla_in_child_proc, args=(), nprocs=n)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_methods_in_xla_context():\n    # We explicitly set _model as _SerialModel\n    # then call idist.* methods and check that they give correct values\n    from ignite.distributed.utils import _set_model, _SerialModel\n\n    _set_model(_SerialModel())\n\n    _test_distrib_config(local_rank=0, backend=""xla-tpu"", ws=1, true_device=""xla"", rank=0)\n\n\ndef _test_idist_methods_in_xla_context_in_child_proc(index):\n    # We explicitly set _model as _SerialModel\n    # then call idist.* methods and check that they give correct values\n    from ignite.distributed.utils import _set_model, _SerialModel\n\n    _set_model(_SerialModel())\n\n    import torch_xla.core.xla_model as xm\n\n    _test_distrib_config(\n        local_rank=index, backend=""xla-tpu"", ws=xm.xrt_world_size(), true_device=""xla"", rank=xm.get_ordinal()\n    )\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_methods_in_xla_context_in_child_proc(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_idist_methods_in_xla_context_in_child_proc, args=(), nprocs=n)\n\n\ndef _test_idist_methods_in_native_context(backend, device, local_rank):\n    # We explicitly set _model as _SerialModel\n    # then call idist.* methods and check that they give correct values\n    from ignite.distributed.utils import _set_model, _SerialModel\n\n    _set_model(_SerialModel())\n\n    ws = dist.get_world_size()\n    rank = dist.get_rank()\n    _test_distrib_config(local_rank, backend=backend, ws=ws, true_device=device, rank=rank)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_idist_methods_in_native_gloo_context(distributed_context_single_node_gloo):\n    local_rank = distributed_context_single_node_gloo[""local_rank""]\n    _test_idist_methods_in_native_context(""gloo"", ""cpu"", local_rank)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_idist_methods_in_native_nccl_context(distributed_context_single_node_nccl):\n    local_rank = distributed_context_single_node_nccl[""local_rank""]\n    _test_idist_methods_in_native_context(""nccl"", ""cuda"", local_rank)\n\n\ndef _test_idist_methods_in_native_context_set_local_rank(backend, device, local_rank):\n    # We explicitly set _model as _SerialModel\n    # then call idist.* methods and check that they give correct values\n    from ignite.distributed.utils import _set_model, _SerialModel\n\n    _set_model(_SerialModel())\n\n    lrank = int(os.environ[""LOCAL_RANK""])\n    del os.environ[""LOCAL_RANK""]\n\n    ws = dist.get_world_size()\n    rank = dist.get_rank()\n\n    idist.set_local_rank(local_rank)\n\n    _test_distrib_config(local_rank=local_rank, backend=backend, ws=ws, true_device=device, rank=rank)\n\n    os.environ[""LOCAL_RANK""] = str(lrank)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_idist_methods_in_native_gloo_context_set_local_rank(distributed_context_single_node_gloo):\n    local_rank = distributed_context_single_node_gloo[""local_rank""]\n    _test_idist_methods_in_native_context_set_local_rank(""gloo"", ""cpu"", local_rank)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_idist_methods_in_native_nccl_context_set_local_rank(distributed_context_single_node_nccl):\n    local_rank = distributed_context_single_node_nccl[""local_rank""]\n    _test_idist_methods_in_native_context_set_local_rank(""nccl"", ""cuda"", local_rank)\n\n\ndef test_idist_all_reduce_no_dist():\n    assert idist.all_reduce(10) == 10\n\n\ndef test_idist_all_gather_no_dist():\n    assert idist.all_gather(10) == 10\n\n\ndef _test_distrib_all_reduce(device):\n\n    res = idist.all_reduce(10)\n    assert res == 10 * idist.get_world_size()\n\n    t = torch.tensor(10, device=device)\n    res = idist.all_reduce(t)\n    assert res.item() == 10 * idist.get_world_size()\n\n    t = torch.tensor(idist.get_rank(), device=device)\n    res = idist.all_reduce(t)\n    assert res.item() == sum([i for i in range(idist.get_world_size())])\n\n    if idist.get_world_size() > 1:\n        with pytest.raises(TypeError, match=r""Unhandled input type""):\n            idist.all_reduce(""abc"")\n\n        with pytest.raises(ValueError, match=r""Unsupported reduction operation""):\n            idist.all_reduce(10, op=""ABC"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_idist_all_reduce_nccl(distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(distributed_context_single_node_nccl[""local_rank""])\n    _test_distrib_all_reduce(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_idist_all_reduce_gloo(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_all_reduce(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_all_reduce_xla():\n    device = idist.device()\n    _test_distrib_all_reduce(device)\n\n\ndef _test_idist_all_reduce_xla_in_child_proc(index):\n    device = idist.device()\n    _test_distrib_all_reduce(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_all_reduce_xla_in_child_proc(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_idist_all_reduce_xla_in_child_proc, args=(), nprocs=n)\n\n\ndef _test_distrib_all_gather(device):\n\n    res = idist.all_gather(10)\n    true_res = torch.tensor([10,] * idist.get_world_size(), device=device)\n    assert (res == true_res).all()\n\n    t = torch.tensor(idist.get_rank(), device=device)\n    res = idist.all_gather(t)\n    true_res = torch.tensor([i for i in range(idist.get_world_size())], device=device)\n    assert (res == true_res).all()\n\n    x = ""test-test""\n    if idist.get_rank() == 0:\n        x = ""abc""\n    res = idist.all_gather(x)\n    true_res = [""abc"",] + [""test-test""] * (idist.get_world_size() - 1)\n    assert res == true_res\n\n    base_x = ""x"" * 1026\n    x = base_x\n    if idist.get_rank() == 0:\n        x = ""abc""\n\n    if idist.get_rank() > 0:\n        with pytest.warns(UserWarning, match=r""is larger than 1024 and thus will be truncated""):\n            res = idist.all_gather(x)\n    else:\n        res = idist.all_gather(x)\n    true_res = [""abc"",] + [base_x[:1024]] * (idist.get_world_size() - 1)\n    assert res == true_res\n\n    t = torch.arange(100, device=device).reshape(4, 25) * (idist.get_rank() + 1)\n    in_dtype = t.dtype\n    res = idist.all_gather(t)\n    assert res.shape == (idist.get_world_size() * 4, 25)\n    assert res.dtype == in_dtype\n    true_res = torch.zeros(idist.get_world_size() * 4, 25, device=device)\n    for i in range(idist.get_world_size()):\n        true_res[i * 4 : (i + 1) * 4, ...] = torch.arange(100, device=device).reshape(4, 25) * (i + 1)\n    assert (res == true_res).all()\n\n    if idist.get_world_size() > 1:\n        with pytest.raises(TypeError, match=r""Unhandled input type""):\n            idist.all_reduce([0, 1, 2])\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_idist_all_gather_nccl(distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(distributed_context_single_node_nccl[""local_rank""])\n    _test_distrib_all_gather(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_idist_all_gather_gloo(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_all_gather(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_all_gather_xla():\n\n    device = idist.device()\n    _test_distrib_all_gather(device)\n\n\ndef _test_idist_all_gather_xla_in_child_proc(index):\n    device = idist.device()\n    _test_distrib_all_gather(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_all_gather_xla_in_child_proc(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_idist_all_gather_xla_in_child_proc, args=(), nprocs=n)\n\n\ndef _test_distrib_barrier(device):\n\n    t = torch.tensor([idist.get_rank()], device=device, dtype=torch.float)\n    true_res = sum([i for i in range(idist.get_world_size())])\n\n    if idist.get_rank() == 0:\n        t += 10.0\n    idist.barrier()\n\n    tt = idist.all_reduce(t)\n    assert tt.item() == true_res + 10.0\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_idist_barrier_nccl(distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(distributed_context_single_node_nccl[""local_rank""])\n    _test_distrib_barrier(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_idist_barrier_gloo(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_barrier(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_barrier_xla():\n\n    device = idist.device()\n    _test_distrib_barrier(device)\n\n\ndef _test_idist_barrier_xla_in_child_proc(index):\n    device = idist.device()\n    _test_distrib_barrier(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_barrier_xla_in_child_proc(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_idist_barrier_xla_in_child_proc, args=(), nprocs=n)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_idist_methods_overhead_gloo(distributed_context_single_node_gloo):\n    import time\n\n    n = 100000\n    start = time.time()\n    for _ in range(n):\n        _ = idist.get_world_size()\n        _ = idist.get_rank()\n    elapsed = time.time() - start\n    t1 = elapsed / n\n\n    start = time.time()\n    for _ in range(n):\n        _ = dist.get_world_size()\n        _ = idist.get_rank()\n    elapsed = time.time() - start\n    t2 = elapsed / n\n\n    assert t2 * 6 > t1, ""{} * 6 vs {}"".format(t2, t1)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_idist_methods_overhead_nccl(distributed_context_single_node_nccl):\n    import time\n\n    n = 100000\n    start = time.time()\n    for _ in range(n):\n        _ = idist.get_world_size()\n        _ = idist.get_rank()\n    elapsed = time.time() - start\n    t1 = elapsed / n\n\n    start = time.time()\n    for _ in range(n):\n        _ = dist.get_world_size()\n        _ = idist.get_rank()\n    elapsed = time.time() - start\n    t2 = elapsed / n\n\n    assert t2 * 3 > t1, ""{} * 3 vs {}"".format(t2, t1)\n\n\ndef _test_distrib_one_rank_only(device):\n    def _test(barrier):\n        # last rank\n        rank = idist.get_world_size() - 1\n\n        value = torch.tensor(0).to(device)\n\n        @idist.one_rank_only(rank=rank, with_barrier=barrier)\n        def initialize():\n            value.data = torch.tensor(100).to(device)\n\n        initialize()\n\n        value_list = idist.all_gather(tensor=value)\n\n        for r in range(idist.get_world_size()):\n            if r == rank:\n                assert value_list[r].item() == 100\n            else:\n                assert value_list[r].item() == 0\n\n    _test(barrier=True)\n    _test(barrier=False)\n\n\ndef _test_distrib_one_rank_only_with_engine(device):\n    def _test(barrier):\n        engine = Engine(lambda e, b: b)\n\n        batch_sum = torch.tensor(0).to(device)\n\n        @engine.on(Events.ITERATION_COMPLETED)\n        @idist.one_rank_only(with_barrier=barrier)  # ie rank == 0\n        def _(_):\n            batch_sum.data += torch.tensor(engine.state.batch).to(device)\n\n        engine.run([1, 2, 3], max_epochs=2)\n\n        value_list = idist.all_gather(tensor=batch_sum)\n\n        for r in range(idist.get_world_size()):\n            if r == 0:\n                assert value_list[r].item() == 12\n            else:\n                assert value_list[r].item() == 0\n\n    _test(barrier=True)\n    _test(barrier=False)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_idist_one_rank_only_gloo(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_one_rank_only(device=device)\n    _test_distrib_one_rank_only_with_engine(device=device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_idist_one_rank_only_nccl(local_rank, distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_one_rank_only(device=device)\n    _test_distrib_one_rank_only_with_engine(device=device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_one_rank_only_xla():\n\n    device = idist.device()\n    _test_distrib_one_rank_only(device=device)\n    _test_distrib_one_rank_only_with_engine(device=device)\n\n\ndef _test_idist_one_rank_only_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_one_rank_only(device=device)\n    _test_distrib_one_rank_only_with_engine(device=device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_idist_one_rank_only_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_idist_one_rank_only_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/engine/__init__.py,6,"b'import torch\n\ntry:\n    from torch.utils.data import IterableDataset\nexcept ImportError:\n\n    class IterableDataset:\n\n        pass\n\n\nclass BatchChecker:\n    def __init__(self, data, init_counter=0):\n        self.counter = init_counter\n        self.data = data\n        self.true_batch = None\n\n    def check(self, batch):\n        self.true_batch = self.data[self.counter % len(self.data)]\n        self.counter += 1\n        res = self.true_batch == batch\n        return res.all() if not isinstance(res, bool) else res\n\n\nclass IterationCounter:\n    def __init__(self, start_value=1):\n        self.current_iteration_count = start_value\n\n    def __call__(self, engine):\n        assert engine.state.iteration == self.current_iteration_count\n        self.current_iteration_count += 1\n\n\nclass EpochCounter:\n    def __init__(self, start_value=1):\n        self.current_epoch_count = start_value\n\n    def __call__(self, engine):\n        assert engine.state.epoch == self.current_epoch_count\n        self.current_epoch_count += 1\n\n\ndef setup_sampler(sampler_type, num_iters, batch_size):\n    if sampler_type is None:\n        return None, batch_size\n\n    if sampler_type == ""weighted"":\n        from torch.utils.data.sampler import WeightedRandomSampler\n\n        w = torch.ones(num_iters * batch_size, dtype=torch.float)\n        for i in range(num_iters):\n            w[batch_size * i : batch_size * (i + 1)] += i * 1.0\n        return WeightedRandomSampler(w, num_samples=num_iters * batch_size, replacement=True), batch_size\n\n    if sampler_type == ""distributed"":\n        from torch.utils.data.distributed import DistributedSampler\n        import torch.distributed as dist\n\n        num_replicas = 1\n        rank = 0\n        if dist.is_available() and dist.is_initialized():\n            num_replicas = dist.get_world_size()\n            rank = dist.get_rank()\n\n        dataset = torch.zeros(num_iters * batch_size)\n        return DistributedSampler(dataset, num_replicas=num_replicas, rank=rank), batch_size // num_replicas\n\n\nclass MyIterableDataset(IterableDataset):\n    def __init__(self, start, end):\n        super(MyIterableDataset).__init__()\n        assert end > start, ""this example code only works with end >= start""\n        self.start = start\n        self.end = end\n\n    def __iter__(self):\n        return iter(range(self.start, self.end))\n\n\ndef get_iterable_dataset(*args, **kwargs):\n    return MyIterableDataset(*args, **kwargs)\n'"
tests/ignite/engine/test_create_supervised.py,17,"b'import os\nfrom typing import Optional\n\nimport pytest\nimport torch\nfrom pytest import approx\nfrom torch.nn import Linear\nfrom torch.nn.functional import mse_loss\nfrom torch.optim import SGD\n\nimport ignite.distributed as idist\nfrom ignite.engine import create_supervised_evaluator, create_supervised_trainer\nfrom ignite.metrics import MeanSquaredError\n\n\ndef _test_create_supervised_trainer(\n    model_device: Optional[str] = None, trainer_device: Optional[str] = None, trace: bool = False\n):\n    model = Linear(1, 1)\n\n    if model_device:\n        model.to(model_device)\n\n    model.weight.data.zero_()\n    model.bias.data.zero_()\n    optimizer = SGD(model.parameters(), 0.1)\n\n    if trace:\n        example_input = torch.randn(1, 1)\n        model = torch.jit.trace(model, example_input)\n\n    trainer = create_supervised_trainer(model, optimizer, mse_loss, device=trainer_device)\n\n    x = torch.tensor([[1.0], [2.0]])\n    y = torch.tensor([[3.0], [5.0]])\n    data = [(x, y)]\n\n    assert model.weight.data[0, 0].item() == approx(0.0)\n    assert model.bias.item() == approx(0.0)\n\n    if model_device == trainer_device or ((model_device == ""cpu"") ^ (trainer_device == ""cpu"")):\n        state = trainer.run(data)\n\n        assert state.output == approx(17.0)\n        assert model.weight.data[0, 0].item() == approx(1.3)\n        assert model.bias.item() == approx(0.8)\n    else:\n        with pytest.raises(RuntimeError, match=r""device type""):\n            trainer.run(data)\n\n\ndef _test_create_supervised_evaluator(\n    model_device: Optional[str] = None, evaluator_device: Optional[str] = None, trace: bool = False\n):\n    model = Linear(1, 1)\n\n    if model_device:\n        model.to(model_device)\n\n    model.weight.data.zero_()\n    model.bias.data.zero_()\n\n    if trace:\n        example_input = torch.randn(1, 1)\n        model = torch.jit.trace(model, example_input)\n\n    evaluator = create_supervised_evaluator(model, device=evaluator_device)\n\n    x = torch.tensor([[1.0], [2.0]])\n    y = torch.tensor([[3.0], [5.0]])\n    data = [(x, y)]\n\n    if model_device == evaluator_device or ((model_device == ""cpu"") ^ (evaluator_device == ""cpu"")):\n        state = evaluator.run(data)\n\n        y_pred, y = state.output\n\n        assert y_pred[0, 0].item() == approx(0.0)\n        assert y_pred[1, 0].item() == approx(0.0)\n        assert y[0, 0].item() == approx(3.0)\n        assert y[1, 0].item() == approx(5.0)\n\n        assert model.weight.data[0, 0].item() == approx(0.0)\n        assert model.bias.item() == approx(0.0)\n\n    else:\n        with pytest.raises(RuntimeError, match=r""device type""):\n            evaluator.run(data)\n\n\ndef test_create_supervised_trainer():\n    _test_create_supervised_trainer()\n\n\ndef test_create_supervised_trainer_with_cpu():\n    _test_create_supervised_trainer(trainer_device=""cpu"")\n\n\ndef test_create_supervised_trainer_traced_with_cpu():\n    _test_create_supervised_trainer(trainer_device=""cpu"", trace=True)\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=""Skip if no GPU"")\ndef test_create_supervised_trainer_on_cuda():\n    model_device = trainer_device = ""cuda""\n    _test_create_supervised_trainer(model_device=model_device, trainer_device=trainer_device)\n\n\n@pytest.mark.skipif(idist.has_xla_support, reason=""Skip if has PyTorch XLA package"")\ndef test_create_supervised_trainer_on_tpu_no_xla():\n    model_device = ""cpu""\n    trainer_device = ""xla""\n    with pytest.raises(RuntimeError, match=r""In order to run on TPU, please install PyTorch XLA""):\n        _test_create_supervised_trainer(model_device=model_device, trainer_device=trainer_device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_create_supervised_trainer_on_tpu():\n    model_device = trainer_device = ""xla""\n    _test_create_supervised_trainer(model_device=model_device, trainer_device=trainer_device)\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=""Skip if no GPU"")\ndef test_create_supervised_trainer_on_cuda_with_model_on_cpu():\n    _test_create_supervised_trainer(trainer_device=""cuda"")\n\n\ndef test_create_supervised_evaluator():\n    _test_create_supervised_evaluator()\n\n\ndef test_create_supervised_evaluator_on_cpu():\n    _test_create_supervised_evaluator(evaluator_device=""cpu"")\n\n\ndef test_create_supervised_evaluator_traced_on_cpu():\n    _test_create_supervised_evaluator(evaluator_device=""cpu"", trace=True)\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=""Skip if no GPU"")\ndef test_create_supervised_evaluator_on_cuda():\n    model_device = evaluator_device = ""cuda""\n    _test_create_supervised_evaluator(model_device=model_device, evaluator_device=evaluator_device)\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=""Skip if no GPU"")\ndef test_create_supervised_evaluator_on_cuda_with_model_on_cpu():\n    _test_create_supervised_evaluator(evaluator_device=""cuda"")\n\n\ndef test_create_supervised_evaluator_with_metrics():\n    model = Linear(1, 1)\n    model.weight.data.zero_()\n    model.bias.data.zero_()\n\n    evaluator = create_supervised_evaluator(model, metrics={""mse"": MeanSquaredError()})\n\n    x = torch.tensor([[1.0], [2.0]])\n    y = torch.tensor([[3.0], [4.0]])\n    data = [(x, y)]\n\n    state = evaluator.run(data)\n    assert state.metrics[""mse""] == 12.5\n'"
tests/ignite/engine/test_custom_events.py,4,"b'from enum import Enum\nfrom unittest.mock import MagicMock\n\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events\nfrom ignite.engine.events import CallableEvents, CallableEventWithFilter, EventEnum, EventsList\n\n\ndef test_deprecated_callable_events_class():\n    engine = Engine(lambda engine, batch: 0)\n\n    with pytest.warns(DeprecationWarning, match=r""Class ignite\\.engine\\.events\\.CallableEvents is deprecated""):\n\n        class CustomEvents(CallableEvents, Enum):\n            TEST_EVENT = ""test_event""\n\n        engine.register_events(*CustomEvents)\n\n\ndef test_custom_events():\n    class CustomEvents(EventEnum):\n        TEST_EVENT = ""test_event""\n\n    # Dummy engine\n    engine = Engine(lambda engine, batch: 0)\n    engine.register_events(*CustomEvents)\n\n    # Handle is never called\n    handle = MagicMock()\n    engine.add_event_handler(CustomEvents.TEST_EVENT, handle)\n    engine.run(range(1))\n    assert not handle.called\n\n    # Advanced engine\n    def process_func(engine, batch):\n        engine.fire_event(CustomEvents.TEST_EVENT)\n\n    engine = Engine(process_func)\n    engine.register_events(*CustomEvents)\n\n    # Handle should be called\n    handle = MagicMock()\n    engine.add_event_handler(CustomEvents.TEST_EVENT, handle)\n    engine.run(range(1))\n    assert handle.called\n\n\ndef test_custom_events_with_event_to_attr():\n    class CustomEvents(EventEnum):\n        TEST_EVENT = ""test_event""\n\n    custom_event_to_attr = {CustomEvents.TEST_EVENT: ""test_event""}\n\n    # Dummy engine\n    engine = Engine(lambda engine, batch: 0)\n    engine.register_events(*CustomEvents, event_to_attr=custom_event_to_attr)\n\n    # Handle is never called\n    handle = MagicMock()\n    engine.add_event_handler(CustomEvents.TEST_EVENT, handle)\n    engine.run(range(1))\n    assert hasattr(engine.state, ""test_event"")\n    assert engine.state.test_event == 0\n\n    # Advanced engine\n    def process_func(engine, batch):\n        engine.fire_event(CustomEvents.TEST_EVENT)\n\n    engine = Engine(process_func)\n    engine.register_events(*CustomEvents, event_to_attr=custom_event_to_attr)\n\n    def handle(engine):\n        engine.state.test_event += 1\n\n    engine.add_event_handler(CustomEvents.TEST_EVENT, handle)\n    engine.run(range(25))\n    assert engine.state.test_event == 25\n\n    custom_event_to_attr = ""a""\n    engine = Engine(lambda engine, batch: 0)\n    with pytest.raises(ValueError):\n        engine.register_events(*CustomEvents, event_to_attr=custom_event_to_attr)\n\n\ndef test_custom_events_with_events_list():\n    class CustomEvents(EventEnum):\n        TEST_EVENT = ""test_event""\n\n    def process_func(engine, batch):\n        engine.fire_event(CustomEvents.TEST_EVENT)\n\n    engine = Engine(process_func)\n    engine.register_events(*CustomEvents)\n\n    # Handle should be called\n    handle = MagicMock()\n    engine.add_event_handler(CustomEvents.TEST_EVENT | Events.STARTED, handle)\n    engine.run(range(1))\n    assert handle.called\n\n\ndef test_callable_events_with_wrong_inputs():\n\n    with pytest.raises(ValueError, match=r""Only one of the input arguments should be specified""):\n        Events.ITERATION_STARTED()\n\n    with pytest.raises(ValueError, match=r""Only one of the input arguments should be specified""):\n        Events.ITERATION_STARTED(event_filter=""123"", every=12)\n\n    with pytest.raises(TypeError, match=r""Argument event_filter should be a callable""):\n        Events.ITERATION_STARTED(event_filter=""123"")\n\n    with pytest.raises(ValueError, match=r""Argument every should be integer and greater than zero""):\n        Events.ITERATION_STARTED(every=-1)\n\n    with pytest.raises(ValueError, match=r""but will be called with""):\n        Events.ITERATION_STARTED(event_filter=lambda x: x)\n\n\ndef test_callable_events():\n\n    assert isinstance(Events.ITERATION_STARTED.value, str)\n\n    def foo(engine, event):\n        return True\n\n    ret = Events.ITERATION_STARTED(event_filter=foo)\n    assert isinstance(ret, CallableEventWithFilter)\n    assert ret == Events.ITERATION_STARTED\n    assert ret.filter == foo\n    assert isinstance(Events.ITERATION_STARTED.value, str)\n\n    # assert ret in Events\n    assert Events.ITERATION_STARTED.name in ""{}"".format(ret)\n    # assert ret in State.event_to_attr\n\n    ret = Events.ITERATION_STARTED(every=10)\n    assert isinstance(ret, CallableEventWithFilter)\n    assert ret == Events.ITERATION_STARTED\n    assert ret.filter is not None\n\n    # assert ret in Events\n    assert Events.ITERATION_STARTED.name in ""{}"".format(ret)\n    # assert ret in State.event_to_attr\n\n    ret = Events.ITERATION_STARTED(once=10)\n    assert isinstance(ret, CallableEventWithFilter)\n    assert ret == Events.ITERATION_STARTED\n    assert ret.filter is not None\n\n    # assert ret in Events\n    assert Events.ITERATION_STARTED.name in ""{}"".format(ret)\n    # assert ret in State.event_to_attr\n\n    def _attach(e1, e2):\n        assert id(e1) != id(e2)\n\n    _attach(Events.ITERATION_STARTED(every=10), Events.ITERATION_COMPLETED(every=10))\n\n\ndef test_callable_events_every_eq_one():\n    e = Events.ITERATION_STARTED(every=1)\n    assert isinstance(e, CallableEventWithFilter)\n\n\ndef test_has_handler_on_callable_events():\n    engine = Engine(lambda e, b: 1)\n\n    def foo(e):\n        pass\n\n    assert not engine.has_event_handler(foo)\n\n    engine.add_event_handler(Events.EPOCH_STARTED, foo)\n    assert engine.has_event_handler(foo)\n\n    def bar(e):\n        pass\n\n    engine.add_event_handler(Events.EPOCH_COMPLETED(every=3), bar)\n    assert engine.has_event_handler(bar)\n    assert engine.has_event_handler(bar, Events.EPOCH_COMPLETED)\n\n    engine.has_event_handler(bar, Events.EPOCH_COMPLETED(every=3))\n\n\ndef test_remove_event_handler_on_callable_events():\n\n    engine = Engine(lambda e, b: 1)\n\n    def foo(e):\n        pass\n\n    assert not engine.has_event_handler(foo)\n\n    engine.add_event_handler(Events.EPOCH_STARTED, foo)\n    assert engine.has_event_handler(foo)\n    engine.remove_event_handler(foo, Events.EPOCH_STARTED)\n    assert not engine.has_event_handler(foo)\n\n    def bar(e):\n        pass\n\n    engine.add_event_handler(Events.EPOCH_COMPLETED(every=3), bar)\n    assert engine.has_event_handler(bar)\n    engine.remove_event_handler(bar, Events.EPOCH_COMPLETED)\n    assert not engine.has_event_handler(bar)\n\n    engine.add_event_handler(Events.EPOCH_COMPLETED(every=3), bar)\n    assert engine.has_event_handler(bar)\n    engine.remove_event_handler(bar, Events.EPOCH_COMPLETED(every=3))\n    assert not engine.has_event_handler(bar)\n\n\ndef _test_every_event_filter_with_engine(device=""cpu""):\n\n    data = torch.rand(100, 4, device=device)\n\n    def _test(event_name, event_attr, every, true_num_calls):\n\n        engine = Engine(lambda e, b: b)\n\n        counter = [\n            0,\n        ]\n        counter_every = [\n            0,\n        ]\n        num_calls = [\n            0,\n        ]\n\n        @engine.on(event_name(every=every))\n        def assert_every(engine):\n            counter_every[0] += every\n            assert getattr(engine.state, event_attr) % every == 0\n            assert counter_every[0] == getattr(engine.state, event_attr)\n            num_calls[0] += 1\n\n        @engine.on(event_name(every=every))\n        def assert_every_no_engine():\n            assert getattr(engine.state, event_attr) % every == 0\n            assert counter_every[0] == getattr(engine.state, event_attr)\n\n        @engine.on(event_name)\n        def assert_(engine):\n            counter[0] += 1\n            assert getattr(engine.state, event_attr) == counter[0]\n\n        @engine.on(event_name)\n        def assert_no_engine():\n            assert getattr(engine.state, event_attr) == counter[0]\n\n        engine.run(data, max_epochs=5)\n\n        assert num_calls[0] == true_num_calls\n\n    _test(Events.ITERATION_STARTED, ""iteration"", 10, 100 * 5 // 10)\n    _test(Events.ITERATION_COMPLETED, ""iteration"", 10, 100 * 5 // 10)\n    _test(Events.EPOCH_STARTED, ""epoch"", 2, 5 // 2)\n    _test(Events.EPOCH_COMPLETED, ""epoch"", 2, 5 // 2)\n\n\ndef test_every_event_filter_with_engine():\n    _test_every_event_filter_with_engine()\n\n\ndef test_once_event_filter_with_engine():\n    def _test(event_name, event_attr):\n\n        engine = Engine(lambda e, b: b)\n\n        once = 2\n        counter = [\n            0,\n        ]\n        num_calls = [\n            0,\n        ]\n\n        @engine.on(event_name(once=once))\n        def assert_once(engine):\n            assert getattr(engine.state, event_attr) == once\n            num_calls[0] += 1\n\n        @engine.on(event_name)\n        def assert_(engine):\n            counter[0] += 1\n            assert getattr(engine.state, event_attr) == counter[0]\n\n        d = list(range(100))\n        engine.run(d, max_epochs=5)\n\n        assert num_calls[0] == 1\n\n    _test(Events.ITERATION_STARTED, ""iteration"")\n    _test(Events.ITERATION_COMPLETED, ""iteration"")\n    _test(Events.EPOCH_STARTED, ""epoch"")\n    _test(Events.EPOCH_COMPLETED, ""epoch"")\n\n\ndef test_custom_event_filter_with_engine():\n\n    special_events = [1, 2, 5, 7, 17, 20]\n\n    def custom_event_filter(engine, event):\n        if event in special_events:\n            return True\n        return False\n\n    def _test(event_name, event_attr, true_num_calls):\n\n        engine = Engine(lambda e, b: b)\n\n        num_calls = [\n            0,\n        ]\n\n        @engine.on(event_name(event_filter=custom_event_filter))\n        def assert_on_special_event(engine):\n            assert getattr(engine.state, event_attr) == special_events.pop(0)\n            num_calls[0] += 1\n\n        d = list(range(50))\n        engine.run(d, max_epochs=25)\n\n        assert num_calls[0] == true_num_calls\n\n    _test(Events.ITERATION_STARTED, ""iteration"", len(special_events))\n    _test(Events.ITERATION_COMPLETED, ""iteration"", len(special_events))\n    _test(Events.EPOCH_STARTED, ""epoch"", len(special_events))\n    _test(Events.EPOCH_COMPLETED, ""epoch"", len(special_events))\n\n\ndef test_callable_event_bad_behaviour():\n\n    special_events = [1, 2, 5, 7, 17, 20]\n\n    def custom_event_filter(engine, event):\n        if event in special_events:\n            return True\n        return False\n\n    # Check bad behaviour\n    engine = Engine(lambda e, b: b)\n    counter = [\n        0,\n    ]\n\n    # Modify events\n    Events.ITERATION_STARTED(event_filter=custom_event_filter)\n\n    @engine.on(Events.ITERATION_STARTED)\n    def assert_all_iters(engine):\n        counter[0] += 1\n        assert engine.state.iteration == counter[0]\n\n    d = list(range(50))\n    engine.run(d, max_epochs=25)\n\n    assert counter[0] == engine.state.iteration\n\n\ndef test_custom_callable_events():\n    class CustomEvents(Enum):\n        TEST_EVENT = ""test_event""\n\n    with pytest.raises(TypeError, match=r""object is not callable""):\n        CustomEvents.TEST_EVENT(every=10)\n\n    class CustomEvents2(EventEnum):\n        TEST_EVENT = ""test_event""\n\n    CustomEvents2.TEST_EVENT(every=10)\n\n\ndef test_custom_callable_events_with_engine():\n    class CustomEvents(EventEnum):\n        TEST_EVENT = ""test_event""\n\n    event_to_attr = {CustomEvents.TEST_EVENT: ""test_event""}\n\n    special_events = [1, 2, 5, 7, 17, 20]\n\n    def custom_event_filter(engine, event):\n        if event in special_events:\n            return True\n        return False\n\n    def _test(event_name, event_attr, true_num_calls):\n        def update_fn(engine, batch):\n            engine.state.test_event = engine.state.iteration\n            engine.fire_event(CustomEvents.TEST_EVENT)\n\n        engine = Engine(update_fn)\n        engine.register_events(*CustomEvents, event_to_attr=event_to_attr)\n\n        num_calls = [\n            0,\n        ]\n\n        @engine.on(event_name(event_filter=custom_event_filter))\n        def assert_on_special_event(engine):\n            assert getattr(engine.state, event_attr) == special_events.pop(0)\n            num_calls[0] += 1\n\n        d = list(range(50))\n        engine.run(d, max_epochs=25)\n\n        assert num_calls[0] == true_num_calls\n\n    _test(CustomEvents.TEST_EVENT, ""test_event"", len(special_events))\n\n\ndef _test_every_event_filter_with_engine_with_dataloader(device):\n    def _test(num_workers):\n        max_epochs = 3\n        batch_size = 4\n        num_iters = 21\n        data = torch.randint(0, 1000, size=(num_iters * batch_size,))\n\n        dataloader = torch.utils.data.DataLoader(\n            data,\n            batch_size=batch_size,\n            num_workers=num_workers,\n            pin_memory=""cuda"" in device,\n            drop_last=True,\n            shuffle=True,\n        )\n        seen_batchs = []\n\n        def update_fn(_, batch):\n            batch_to_device = batch.to(device)\n            seen_batchs.append(batch)\n\n        engine = Engine(update_fn)\n\n        def foo(_):\n            pass\n\n        engine.add_event_handler(Events.EPOCH_STARTED(every=2), foo)\n        engine.run(dataloader, max_epochs=max_epochs)\n        engine = None\n\n        import gc\n\n        gc.collect()\n        assert len(gc.garbage) == 0\n\n    _test(num_workers=0)\n    _test(num_workers=1)\n\n\ndef test_every_event_filter_with_engine_with_dataloader():\n    _test_every_event_filter_with_engine_with_dataloader(""cpu"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    _test_every_event_filter_with_engine()\n    _test_every_event_filter_with_engine_with_dataloader(""cpu"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_single_node_nccl[""local_rank""])\n    _test_every_event_filter_with_engine(device)\n    _test_every_event_filter_with_engine_with_dataloader(device)\n\n\ndef test_event_list():\n\n    e1 = Events.ITERATION_STARTED(once=1)\n    e2 = Events.ITERATION_STARTED(every=3)\n    e3 = Events.COMPLETED\n\n    event_list = e1 | e2 | e3\n\n    assert type(event_list) == EventsList\n    assert len(event_list) == 3\n    assert event_list[0] == e1\n    assert event_list[1] == e2\n    assert event_list[2] == e3\n\n\ndef test_list_of_events():\n    def _test(event_list, true_iterations):\n\n        engine = Engine(lambda e, b: b)\n\n        iterations = []\n\n        num_calls = [0]\n\n        @engine.on(event_list)\n        def execute_some_handler(e):\n            iterations.append(e.state.iteration)\n            num_calls[0] += 1\n\n        engine.run(range(3), max_epochs=5)\n\n        assert iterations == true_iterations\n        assert num_calls[0] == len(true_iterations)\n\n    _test(Events.ITERATION_STARTED(once=1) | Events.ITERATION_STARTED(once=1), [1, 1])\n    _test(Events.ITERATION_STARTED(once=1) | Events.ITERATION_STARTED(once=10), [1, 10])\n    _test(Events.ITERATION_STARTED(once=1) | Events.ITERATION_STARTED(every=3), [1, 3, 6, 9, 12, 15])\n'"
tests/ignite/engine/test_deterministic.py,55,"b'import os\nimport random\nimport sys\nfrom unittest.mock import patch\n\nimport numpy as np\nimport pytest\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nimport ignite.distributed as idist\nfrom ignite.engine import Events\nfrom ignite.engine.deterministic import (\n    DeterministicEngine,\n    ReproducibleBatchSampler,\n    keep_random_state,\n    update_dataloader,\n)\nfrom ignite.utils import manual_seed\nfrom tests.ignite.engine import BatchChecker, setup_sampler\n\n\ndef test_update_dataloader():\n    def _test(sampler_type=None):\n        num_epochs = 3\n        total_batch_size = 4\n        num_iters = 17\n        data = torch.randint(0, 1000, size=(num_iters * total_batch_size,))\n        num_workers = 4\n\n        sampler, batch_size = setup_sampler(sampler_type, num_iters, total_batch_size)\n        dataloader = DataLoader(\n            data,\n            batch_size=batch_size,\n            num_workers=num_workers,\n            pin_memory=False,\n            sampler=sampler,\n            drop_last=True,\n            shuffle=sampler is None,\n        )\n\n        torch.manual_seed(12)\n        seen_batches = []\n        for i in range(num_epochs):\n            t = []\n            if sampler_type == ""distributed"":\n                sampler.set_epoch(i)\n            for b in dataloader:\n                t.append(b)\n            seen_batches.append(t)\n\n        sampler, batch_size = setup_sampler(sampler_type, num_iters, total_batch_size)\n        dataloader = DataLoader(\n            data,\n            batch_size=batch_size,\n            num_workers=num_workers,\n            pin_memory=False,\n            sampler=sampler,\n            drop_last=True,\n            shuffle=sampler is None,\n        )\n        batch_sampler = dataloader.batch_sampler\n        new_dataloader = update_dataloader(dataloader, ReproducibleBatchSampler(batch_sampler))\n\n        torch.manual_seed(12)\n        new_batches = []\n        for i in range(num_epochs):\n            t = []\n            if sampler_type == ""distributed"":\n                sampler.set_epoch(i)\n            for b in new_dataloader:\n                t.append(b)\n            new_batches.append(t)\n\n        for i in range(num_epochs):\n            assert all([(b1 == b2).all() for b1, b2 in zip(seen_batches[i], new_batches[i])])\n\n    _test()\n    _test(""weighted"")\n    _test(""distributed"")\n\n\ndef test_reproducible_batch_sampler_wrong_input():\n    with pytest.raises(TypeError, match=r""Argument batch_sampler should be torch.utils.data.sampler.BatchSampler""):\n        ReproducibleBatchSampler(""abc"")\n\n\ndef test_reproducible_batch_sampler():\n    import torch\n    from torch.utils.data import DataLoader\n\n    data = list(range(100))\n    dataloader = DataLoader(data, batch_size=12, num_workers=0, shuffle=True, drop_last=True)\n\n    torch.manual_seed(12 + 0)\n    dataloader_ = update_dataloader(dataloader, ReproducibleBatchSampler(dataloader.batch_sampler))\n\n    seen_batches = []\n    num_epochs = 3\n    for i in range(num_epochs):\n        t = []\n        for b in dataloader_:\n            t.append(b)\n        seen_batches.append(t)\n        torch.manual_seed(12 + i + 1)\n\n    for i in range(num_epochs - 1):\n        for j in range(i + 1, num_epochs):\n            assert not all([(b1 == b2).all() for b1, b2 in zip(seen_batches[i], seen_batches[j])])\n\n    for resume_epoch in range(num_epochs):\n        torch.manual_seed(12 + resume_epoch)\n        dataloader_ = update_dataloader(dataloader, ReproducibleBatchSampler(dataloader.batch_sampler))\n        resumed_seen_batches = []\n        for b in dataloader_:\n            resumed_seen_batches.append(b)\n\n        assert all([(b1 == b2).all() for b1, b2 in zip(seen_batches[resume_epoch], resumed_seen_batches)])\n\n\ndef _test_keep_random_state(with_numpy):\n\n    manual_seed(54)\n    true_values = []\n    for _ in range(5):\n        t = [\n            torch.tensor([random.random()]),\n            torch.rand(2),\n        ]\n        if with_numpy:\n            t.append(torch.from_numpy(np.random.rand(2)))\n        true_values.append(t)\n\n    @keep_random_state\n    def user_handler():\n        manual_seed(22)\n        _ = [\n            random.random(),\n            torch.rand(2),\n        ]\n        if with_numpy:\n            _ = np.random.rand(2)\n\n    manual_seed(54)\n    res_values = []\n    for _ in range(5):\n        r = [\n            torch.tensor([random.random()]),\n            torch.rand(2),\n        ]\n        if with_numpy:\n            r.append(torch.from_numpy(np.random.rand(2)))\n        res_values.append(r)\n        user_handler()\n\n    for a, b in zip(true_values, res_values):\n        for i, j in zip(a, b):\n            assert (i == j).all()\n\n\ndef test_keep_random_state():\n    _test_keep_random_state(with_numpy=True)\n\n\ndef test_keep_random_state_without_numpy():\n    with patch.dict(""sys.modules"", {""numpy"": None}):\n        _test_keep_random_state(with_numpy=False)\n\n\ndef test_strict_resume_from_iter():\n    def _test(epoch_length=None):\n\n        max_epochs = 5\n        num_iters = 21\n        torch.manual_seed(0)\n        data = torch.randint(0, 1000, size=(num_iters,))\n        if epoch_length is None:\n            epoch_length = num_iters\n\n        for resume_iteration in range(2, min(num_iters * max_epochs, epoch_length * max_epochs), 4):\n            print(""\\n----"", resume_iteration, epoch_length)\n            batch_checker = BatchChecker(data, init_counter=resume_iteration)\n\n            def update_fn(_, batch):\n                assert batch_checker.check(batch), ""{} | {}: {} vs {}"".format(\n                    resume_iteration, batch_checker.counter, batch_checker.true_batch, batch\n                )\n\n            engine = DeterministicEngine(update_fn)\n\n            @engine.on(Events.EPOCH_COMPLETED)\n            def check_iteration(_):\n                assert engine.state.iteration == batch_checker.counter\n\n            resume_state_dict = dict(\n                iteration=resume_iteration, max_epochs=max_epochs, epoch_length=epoch_length, rng_states=None\n            )\n            engine.load_state_dict(resume_state_dict)\n            engine.run(data)\n            assert engine.state.epoch == max_epochs\n            assert engine.state.iteration == epoch_length * max_epochs\n\n    _test()\n    _test(60)\n    _test(15)\n\n\ndef test_strict_resume_from_epoch():\n    def _test(epoch_length=None):\n        max_epochs = 10\n        num_iters = 21\n        torch.manual_seed(0)\n        data = torch.randint(0, 1000, size=(num_iters,))\n        if epoch_length is None:\n            epoch_length = num_iters\n\n        for resume_epoch in range(1, max_epochs):\n            batch_checker = BatchChecker(data, init_counter=resume_epoch * epoch_length)\n\n            def update_fn(_, batch):\n                assert batch_checker.check(batch), ""{} | {}: {} vs {}"".format(\n                    resume_epoch, batch_checker.counter, batch_checker.true_batch, batch\n                )\n\n            engine = DeterministicEngine(update_fn)\n\n            resume_state_dict = dict(\n                epoch=resume_epoch, max_epochs=max_epochs, epoch_length=epoch_length, rng_states=None\n            )\n            engine.load_state_dict(resume_state_dict)\n            engine.run(data)\n            assert engine.state.epoch == max_epochs\n            assert engine.state.iteration == epoch_length * max_epochs\n\n    _test()\n    _test(60)\n    _test(15)\n\n\ndef _test_resume_random_dataloader_from_epoch(device, _setup_sampler, sampler_type=None):\n    def _test(epoch_length=None):\n\n        max_epochs = 5\n        total_batch_size = 4\n        num_iters = 21\n        torch.manual_seed(0)\n        data = torch.randint(0, 1000, size=(num_iters * total_batch_size,))\n\n        if epoch_length is None:\n            epoch_length = num_iters\n\n        for resume_epoch in range(1, max_epochs, 2):\n\n            for num_workers in [0, 4]:\n                sampler, batch_size = _setup_sampler(sampler_type, num_iters, total_batch_size)\n\n                orig_dataloader = DataLoader(\n                    data,\n                    batch_size=batch_size,\n                    num_workers=num_workers,\n                    pin_memory=""cuda"" in device,\n                    sampler=sampler,\n                    drop_last=True,\n                    shuffle=sampler is None,\n                )\n\n                seen_batchs = []\n\n                def update_fn(_, batch):\n                    batch_to_device = batch.to(device)\n                    seen_batchs.append(batch)\n\n                engine = DeterministicEngine(update_fn)\n\n                if sampler_type == ""distributed"":\n\n                    @engine.on(Events.EPOCH_STARTED)\n                    def _(engine):\n                        sampler.set_epoch(engine.state.epoch - 1)\n\n                torch.manual_seed(87)\n                engine.run(\n                    orig_dataloader, max_epochs=max_epochs, epoch_length=epoch_length,\n                )\n\n                batch_checker = BatchChecker(seen_batchs, init_counter=resume_epoch * epoch_length)\n\n                sampler, batch_size = _setup_sampler(sampler_type, num_iters, total_batch_size)\n                resume_dataloader = DataLoader(\n                    data,\n                    batch_size=batch_size,\n                    num_workers=num_workers,\n                    pin_memory=""cuda"" in device,\n                    sampler=sampler,\n                    drop_last=True,\n                    shuffle=sampler is None,\n                )\n\n                def update_fn(_, batch):\n                    batch_to_device = batch.to(device)\n                    assert batch_checker.check(batch), ""{} {} | {}: {} vs {}"".format(\n                        num_workers, resume_epoch, batch_checker.counter, batch_checker.true_batch, batch\n                    )\n\n                engine = DeterministicEngine(update_fn)\n\n                if sampler_type == ""distributed"":\n\n                    @engine.on(Events.EPOCH_STARTED)\n                    def _(engine):\n                        sampler.set_epoch(engine.state.epoch - 1)\n\n                resume_state_dict = dict(\n                    epoch=resume_epoch, max_epochs=max_epochs, epoch_length=epoch_length, rng_states=None\n                )\n                engine.load_state_dict(resume_state_dict)\n                torch.manual_seed(87)\n                engine.run(resume_dataloader)\n                assert engine.state.epoch == max_epochs\n                assert engine.state.iteration == epoch_length * max_epochs\n\n    _test()\n    if sampler_type != ""distributed"":\n        _test(60)\n        _test(15)\n\n\n@pytest.mark.skipif(""win"" in sys.platform, reason=""Skip extremely slow test on Windows/MacOSX"")\ndef test_resume_random_dataloader_from_epoch():\n    _test_resume_random_dataloader_from_epoch(""cpu"", setup_sampler)\n    _test_resume_random_dataloader_from_epoch(""cpu"", setup_sampler, sampler_type=""weighted"")\n    _test_resume_random_dataloader_from_epoch(""cpu"", setup_sampler, sampler_type=""distributed"")\n\n\nclass AugmentedData:\n    def __init__(self, data, enabled=True):\n        self.data = data\n        self.enabled = enabled\n\n    def __getitem__(self, i):\n        dp = self.data[i]\n        r = torch.randint_like(dp, -100, 100) if self.enabled else 0.0\n        return dp + r * 0.01\n\n    def __len__(self):\n        return len(self.data)\n\n\ndef _test_resume_random_dataloader_from_iter(device, _setup_sampler, sampler_type=None):\n    def _test(epoch_length=None):\n        max_epochs = 3\n        total_batch_size = 4\n        num_iters = 17\n        torch.manual_seed(0)\n        data = torch.randint(0, 1000, size=(num_iters * total_batch_size,))\n\n        if epoch_length is None:\n            epoch_length = num_iters\n\n        for resume_iteration in range(2, min(num_iters * max_epochs, epoch_length * max_epochs), 13):\n\n            for num_workers in [0, 4]:\n\n                sampler, batch_size = _setup_sampler(sampler_type, num_iters, total_batch_size)\n                orig_dataloader = DataLoader(\n                    data,\n                    batch_size=batch_size,\n                    num_workers=num_workers,\n                    pin_memory=""cuda"" in device,\n                    sampler=sampler,\n                    drop_last=True,\n                    shuffle=sampler is None,\n                )\n                seen_batchs = []\n\n                def update_fn(_, batch):\n                    batch_to_device = batch.to(device)\n                    seen_batchs.append(batch)\n\n                engine = DeterministicEngine(update_fn)\n\n                if sampler_type == ""distributed"":\n\n                    @engine.on(Events.EPOCH_STARTED)\n                    def _(engine):\n                        sampler.set_epoch(engine.state.epoch)\n\n                torch.manual_seed(12)\n                engine.run(\n                    orig_dataloader, max_epochs=max_epochs, epoch_length=epoch_length,\n                )\n\n                batch_checker = BatchChecker(seen_batchs, init_counter=resume_iteration)\n\n                sampler, batch_size = _setup_sampler(sampler_type, num_iters, total_batch_size)\n                resume_dataloader = DataLoader(\n                    data,\n                    batch_size=batch_size,\n                    num_workers=num_workers,\n                    pin_memory=""cuda"" in device,\n                    sampler=sampler,\n                    drop_last=True,\n                    shuffle=sampler is None,\n                )\n\n                def update_fn(_, batch):\n                    batch_to_device = batch.to(device)\n                    assert batch_checker.check(batch), ""{} {} | {}: {} vs {}"".format(\n                        num_workers, resume_iteration, batch_checker.counter, batch_checker.true_batch, batch\n                    )\n\n                engine = DeterministicEngine(update_fn)\n\n                if sampler_type == ""distributed"":\n\n                    @engine.on(Events.EPOCH_STARTED)\n                    def _(engine):\n                        sampler.set_epoch(engine.state.epoch)\n\n                resume_state_dict = dict(\n                    iteration=resume_iteration, max_epochs=max_epochs, epoch_length=epoch_length, rng_states=None\n                )\n                engine.load_state_dict(resume_state_dict)\n                torch.manual_seed(12)\n                engine.run(resume_dataloader)\n                assert engine.state.epoch == max_epochs\n                assert engine.state.iteration == epoch_length * max_epochs, ""{}, {} | {} vs {}"".format(\n                    num_workers, resume_iteration, engine.state.iteration, epoch_length * max_epochs\n                )\n\n    _test()\n    if sampler_type != ""distributed"":\n        _test(40)\n        _test(11)\n\n\n@pytest.mark.skipif(""win"" in sys.platform, reason=""Skip extremely slow test on Windows/MacOSX"")\ndef test_resume_random_dataloader_from_iter():\n    _test_resume_random_dataloader_from_iter(""cpu"", setup_sampler)\n    _test_resume_random_dataloader_from_iter(""cpu"", setup_sampler, sampler_type=""weighted"")\n    _test_resume_random_dataloader_from_iter(""cpu"", setup_sampler, sampler_type=""distributed"")\n\n\ndef _test_resume_random_data_iterator_from_epoch(device):\n    def _test(epoch_length=None):\n        max_epochs = 5\n        batch_size = 4\n        num_iters = 21\n\n        def infinite_data_iterator():\n            while True:\n                for _ in range(num_iters):\n                    data = torch.randint(0, 1000, size=(batch_size,), device=device)\n                    yield data\n\n        if epoch_length is None:\n            epoch_length = num_iters\n\n        for resume_epoch in range(1, max_epochs):\n            seen_batchs = []\n\n            def update_fn(_, batch):\n                # if there is a random op when using data batch etc, we can not resume correctly\n                # torch.rand(1)\n                seen_batchs.append(batch)\n\n            engine = DeterministicEngine(update_fn)\n            torch.manual_seed(121)\n            engine.run(\n                infinite_data_iterator(), max_epochs=max_epochs, epoch_length=epoch_length,\n            )\n\n            batch_checker = BatchChecker(seen_batchs, init_counter=resume_epoch * epoch_length)\n\n            def update_fn(_, batch):\n                assert batch_checker.check(batch), ""{} | {}: {} vs {}"".format(\n                    resume_epoch, batch_checker.counter, batch_checker.true_batch, batch\n                )\n\n            engine = DeterministicEngine(update_fn)\n\n            resume_state_dict = dict(\n                epoch=resume_epoch, max_epochs=max_epochs, epoch_length=epoch_length, rng_states=None\n            )\n            engine.load_state_dict(resume_state_dict)\n            torch.manual_seed(121)\n            engine.run(infinite_data_iterator())\n            assert engine.state.epoch == max_epochs\n            assert engine.state.iteration == epoch_length * max_epochs\n\n    _test()\n    _test(60)\n    _test(15)\n\n\ndef test_resume_random_data_iterator_from_epoch():\n    _test_resume_random_data_iterator_from_epoch(""cpu"")\n\n\ndef _test_resume_random_data_iterator_from_iter(device):\n    def _test(epoch_length=None):\n        max_epochs = 3\n        batch_size = 4\n        num_iters = 17\n\n        def infinite_data_iterator():\n            while True:\n                for _ in range(num_iters):\n                    data = torch.randint(0, 1000, size=(batch_size,), device=device)\n                    yield data\n\n        if epoch_length is None:\n            epoch_length = num_iters\n\n        for resume_iteration in range(1, min(num_iters * max_epochs, epoch_length * max_epochs), 7):\n\n            seen_batchs = []\n\n            def update_fn(_, batch):\n                seen_batchs.append(batch)\n\n            engine = DeterministicEngine(update_fn)\n\n            torch.manual_seed(24)\n            engine.run(\n                infinite_data_iterator(), max_epochs=max_epochs, epoch_length=epoch_length,\n            )\n\n            batch_checker = BatchChecker(seen_batchs, init_counter=resume_iteration)\n\n            def update_fn(_, batch):\n                assert batch_checker.check(batch), ""{} | {}: {} vs {}"".format(\n                    resume_iteration, batch_checker.counter, batch_checker.true_batch, batch\n                )\n\n            engine = DeterministicEngine(update_fn)\n\n            resume_state_dict = dict(\n                iteration=resume_iteration, max_epochs=max_epochs, epoch_length=epoch_length, rng_states=None\n            )\n            engine.load_state_dict(resume_state_dict)\n            torch.manual_seed(24)\n            engine.run(infinite_data_iterator())\n            assert engine.state.epoch == max_epochs\n            assert engine.state.iteration == epoch_length * max_epochs, ""{} | {} vs {}"".format(\n                resume_iteration, engine.state.iteration, epoch_length * max_epochs\n            )\n\n    _test()\n    _test(50)\n    _test(11)\n\n\ndef test_resume_random_data_iterator_from_iter():\n    _test_resume_random_data_iterator_from_iter(""cpu"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_single_node_nccl[""local_rank""])\n    _test_resume_random_dataloader_from_iter(device, setup_sampler, sampler_type=""distributed"")\n    _test_resume_random_dataloader_from_epoch(device, setup_sampler, sampler_type=""distributed"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_resume_random_dataloader_from_iter(device, setup_sampler, sampler_type=""distributed"")\n    _test_resume_random_dataloader_from_epoch(device, setup_sampler, sampler_type=""distributed"")\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_resume_random_dataloader_from_iter(device, setup_sampler, sampler_type=""distributed"")\n    _test_resume_random_dataloader_from_epoch(device, setup_sampler, sampler_type=""distributed"")\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_resume_random_dataloader_from_iter(device, setup_sampler, sampler_type=""distributed"")\n    _test_resume_random_dataloader_from_epoch(device, setup_sampler, sampler_type=""distributed"")\n\n\ndef test_concepts_snippet_resume():\n\n    import torch\n    from torch.utils.data import DataLoader\n    from ignite.engine import DeterministicEngine, Events\n    from ignite.utils import manual_seed\n\n    seen_batches = []\n    manual_seed(seed=15)\n\n    def random_train_data_loader(size):\n        data = torch.arange(0, size)\n        return DataLoader(data, batch_size=4, shuffle=True)\n\n    def print_train_data(engine, batch):\n        i = engine.state.iteration\n        e = engine.state.epoch\n        print(""train"", e, i, batch.tolist())\n        seen_batches.append(batch)\n\n    trainer = DeterministicEngine(print_train_data)\n\n    print(""Original Run"")\n    manual_seed(56)\n    trainer.run(random_train_data_loader(40), max_epochs=2, epoch_length=5)\n\n    original_batches = list(seen_batches)\n    seen_batches = []\n\n    print(""Resumed Run"")\n    trainer.load_state_dict({""epoch"": 1, ""epoch_length"": 5, ""max_epochs"": 2, ""rng_states"": None})\n    manual_seed(56)\n    trainer.run(random_train_data_loader(40))\n\n    resumed_batches = list(seen_batches)\n    seen_batches = []\n    for b1, b2 in zip(original_batches[5:], resumed_batches):\n        assert (b1 == b2).all()\n\n\ndef test_concepts_snippet_warning():\n    def random_train_data_generator():\n        while True:\n            yield torch.randint(0, 100, size=(1,))\n\n    def print_train_data(engine, batch):\n        i = engine.state.iteration\n        e = engine.state.epoch\n        print(""train"", e, i, batch.tolist())\n\n    trainer = DeterministicEngine(print_train_data)\n\n    @trainer.on(Events.ITERATION_COMPLETED(every=3))\n    def user_handler(_):\n        # handler synchronizes the random state\n        torch.manual_seed(12)\n        a = torch.rand(1)\n\n    trainer.run(random_train_data_generator(), max_epochs=3, epoch_length=5)\n\n\ndef _test_gradients_on_resume(\n    dirname, device, with_dropout=True, with_dataaugs=True, data_size=24, batch_size=4, save_iter=None, save_epoch=None\n):\n\n    debug = True\n\n    from torch.utils.data import DataLoader\n    from torch.optim import SGD\n\n    def random_train_data_loader(size):\n        d = AugmentedData(torch.rand(size, 3, 32, 32), enabled=with_dataaugs)\n        return DataLoader(d, batch_size=batch_size, shuffle=True, num_workers=4)\n\n    def _train(save_iter=None, save_epoch=None, sd=None):\n        w_norms = []\n        grad_norms = []\n        data = []\n        chkpt = []\n\n        manual_seed(12)\n        arch = [\n            nn.Conv2d(3, 10, 3),\n            nn.ReLU(),\n            nn.Conv2d(10, 10, 3),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(10, 5),\n            nn.ReLU(),\n            nn.Linear(5, 2),\n        ]\n        if with_dropout:\n            arch.insert(2, nn.Dropout2d())\n            arch.insert(-2, nn.Dropout())\n\n        model = nn.Sequential(*arch).to(device)\n        opt = SGD(model.parameters(), lr=0.001)\n\n        def proc_fn(e, b):\n            from ignite.engine.deterministic import _repr_rng_state, _get_rng_states\n\n            s = _repr_rng_state(_get_rng_states())\n            model.train()\n            opt.zero_grad()\n            y = model(b.to(device))\n            y.sum().backward()\n            opt.step()\n            if debug:\n                print(\n                    trainer.state.iteration, trainer.state.epoch, ""proc_fn - b.shape"", b.shape, torch.norm(y).item(), s\n                )\n\n        trainer = DeterministicEngine(proc_fn)\n\n        if save_iter is not None:\n            ev = Events.ITERATION_COMPLETED(once=save_iter)\n        elif save_epoch is not None:\n            ev = Events.EPOCH_COMPLETED(once=save_epoch)\n            save_iter = save_epoch * (data_size // batch_size)\n\n        @trainer.on(ev)\n        def save_chkpt(_):\n            if debug:\n                print(trainer.state.iteration, ""save_chkpt"")\n            fp = os.path.join(dirname, ""test.pt"")\n            from ignite.engine.deterministic import _repr_rng_state\n\n            tsd = trainer.state_dict()\n            if debug:\n                print(""->"", _repr_rng_state(tsd[""rng_states""]))\n            torch.save([model.state_dict(), opt.state_dict(), tsd], fp)\n            chkpt.append(fp)\n\n        def log_event_filter(_, event):\n            if (event // save_iter == 1) and 1 <= (event % save_iter) <= 5:\n                return True\n            return False\n\n        @trainer.on(Events.ITERATION_COMPLETED(event_filter=log_event_filter))\n        def write_data_grads_weights(e):\n            x = e.state.batch\n            i = e.state.iteration\n            data.append([i, x.mean().item(), x.std().item()])\n\n            total = [0.0, 0.0]\n            out1 = []\n            out2 = []\n            for p in model.parameters():\n                n1 = torch.norm(p).item()\n                n2 = torch.norm(p.grad).item()\n                out1.append(n1)\n                out2.append(n2)\n                total[0] += n1\n                total[1] += n2\n            w_norms.append([i, total[0]] + out1)\n            grad_norms.append([i, total[1]] + out2)\n\n        if sd is not None:\n            sd = torch.load(sd)\n            model.load_state_dict(sd[0])\n            opt.load_state_dict(sd[1])\n            from ignite.engine.deterministic import _repr_rng_state\n\n            if debug:\n                print(""-->"", _repr_rng_state(sd[2][""rng_states""]))\n            trainer.load_state_dict(sd[2])\n\n        manual_seed(32)\n        trainer.run(random_train_data_loader(size=data_size), max_epochs=5)\n        return {""sd"": chkpt, ""data"": data, ""grads"": grad_norms, ""weights"": w_norms}\n\n    out_original = _train(save_iter=save_iter, save_epoch=save_epoch)\n    assert len(out_original[""sd""]) > 0\n\n    out_resumed = _train(save_iter=save_iter, save_epoch=save_epoch, sd=out_original[""sd""][0])\n\n    if debug:\n        print(""Original:"")\n        print("" data:"", out_original[""data""])\n        print(""grads:"", out_original[""grads""])\n        print(""    W:"", out_original[""weights""])\n        print(""Resume:"")\n        print("" data:"", out_resumed[""data""])\n        print(""grads:"", out_resumed[""grads""])\n        print(""    W:"", out_resumed[""weights""])\n\n    # check data:\n    for d1, d2 in zip(out_original[""data""], out_resumed[""data""]):\n        assert d1 == d2\n\n    # check grads:\n    for d1, d2 in zip(out_original[""grads""], out_resumed[""grads""]):\n        assert d1 == d2\n\n    # check weights:\n    for d1, d2 in zip(out_original[""weights""], out_resumed[""weights""]):\n        assert d1 == d2\n\n\ndef test_gradients_on_resume_cpu(dirname):\n    with pytest.raises(AssertionError):\n        _test_gradients_on_resume(dirname, ""cpu"", with_dataaugs=True, save_iter=25)\n    _test_gradients_on_resume(dirname, ""cpu"", with_dataaugs=False, save_iter=25)\n    # resume from epoch\n    _test_gradients_on_resume(dirname, ""cpu"", with_dataaugs=True, save_epoch=3)\n    _test_gradients_on_resume(dirname, ""cpu"", with_dataaugs=False, save_epoch=3)\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=""Skip if no GPU"")\ndef test_gradients_on_resume_on_cuda(dirname):\n    with pytest.raises(AssertionError):\n        _test_gradients_on_resume(dirname, ""cuda"", with_dataaugs=True, save_iter=25)\n    with pytest.raises(AssertionError):\n        _test_gradients_on_resume(dirname, ""cuda"", with_dataaugs=False, save_iter=25)\n    # resume from epoch\n    _test_gradients_on_resume(dirname, ""cuda"", with_dataaugs=True, save_epoch=3)\n    _test_gradients_on_resume(dirname, ""cuda"", with_dataaugs=False, save_epoch=3)\n\n\ndef test_engine_with_dataloader_no_auto_batching():\n    # tests https://github.com/pytorch/ignite/issues/941\n    from torch.utils.data import DataLoader, BatchSampler, RandomSampler\n\n    data = torch.rand(64, 4, 10)\n    data_loader = DataLoader(\n        data, batch_size=None, sampler=BatchSampler(RandomSampler(data), batch_size=8, drop_last=True)\n    )\n\n    counter = [0]\n\n    def foo(e, b):\n        print(""{}-{}: {}"".format(e.state.epoch, e.state.iteration, b))\n        counter[0] += 1\n\n    engine = DeterministicEngine(foo)\n    engine.run(data_loader, epoch_length=10, max_epochs=5)\n\n    assert counter[0] == 50\n\n\ndef test_run_finite_iterator_no_epoch_length():\n    # FR: https://github.com/pytorch/ignite/issues/871\n    unknown_size = 11\n\n    def finite_unk_size_data_iter():\n        for i in range(unknown_size):\n            yield i\n\n    bc = BatchChecker(data=list(range(unknown_size)))\n\n    engine = DeterministicEngine(lambda e, b: bc.check(b))\n\n    @engine.on(Events.DATALOADER_STOP_ITERATION)\n    def restart_iter():\n        engine.state.dataloader = finite_unk_size_data_iter()\n\n    data_iter = finite_unk_size_data_iter()\n    engine.run(data_iter, max_epochs=5)\n\n    assert engine.state.epoch == 5\n    assert engine.state.iteration == unknown_size * 5\n\n\nclass OldDataLoader(DataLoader):\n    def __init__(self, dl, *args, **kwargs):\n        self.dl = dl\n        self.sampler = self.dl.sampler\n        self.batch_sampler = self.dl.batch_sampler\n\n    def __len__(self):\n        return len(self.dl)\n\n    def __iter__(self):\n        return iter(self.dl)\n\n\ndef test_dataloader_no_dataset_kind():\n    # tests issue : https://github.com/pytorch/ignite/issues/1022\n\n    engine = DeterministicEngine(lambda e, b: None)\n\n    data = torch.randint(0, 1000, size=(100 * 4,))\n    dataloader = DataLoader(data, batch_size=4)\n    dataloader = OldDataLoader(dataloader)\n\n    engine.run(dataloader)\n'"
tests/ignite/engine/test_engine.py,29,"b'import os\nimport time\nfrom distutils.version import LooseVersion\nfrom unittest.mock import MagicMock, Mock, call\n\nimport numpy as np\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events, State\nfrom ignite.engine.deterministic import keep_random_state\nfrom ignite.metrics import Average\nfrom tests.ignite.engine import BatchChecker, EpochCounter, IterationCounter, get_iterable_dataset\n\n\ndef test_terminate():\n    engine = Engine(lambda e, b: 1)\n    assert not engine.should_terminate\n    engine.terminate()\n    assert engine.should_terminate\n\n\ndef test_invalid_process_raises_with_invalid_signature():\n    with pytest.raises(ValueError):\n        Engine(None)\n\n    with pytest.raises(ValueError):\n        Engine(lambda: None)\n\n    with pytest.raises(ValueError):\n        Engine(lambda batch: None)\n\n    with pytest.raises(ValueError):\n        Engine(lambda engine, batch, extra_arg: None)\n\n\ndef test_current_epoch_counter_increases_every_epoch():\n    engine = Engine(MagicMock(return_value=1))\n    max_epochs = 5\n\n    counter = EpochCounter()\n    engine.add_event_handler(Events.EPOCH_STARTED, counter)\n\n    state = engine.run([1, 2], max_epochs=max_epochs)\n    assert state.epoch == max_epochs\n    counter.current_epoch_count = 1\n    state = engine.run([1, 2], max_epochs=max_epochs)\n    assert state.epoch == max_epochs\n\n\ndef test_current_iteration_counter_increases_every_iteration():\n    batches = [1, 2, 3]\n    engine = Engine(MagicMock(return_value=1))\n    max_epochs = 5\n\n    counter = IterationCounter()\n    engine.add_event_handler(Events.ITERATION_STARTED, counter)\n\n    state = engine.run(batches, max_epochs=max_epochs)\n    assert state.iteration == max_epochs * len(batches)\n    counter.current_iteration_count = 1\n    state = engine.run(batches, max_epochs=max_epochs)\n    assert state.iteration == max_epochs * len(batches)\n\n\ndef test_stopping_criterion_is_max_epochs():\n    engine = Engine(MagicMock(return_value=1))\n    max_epochs = 5\n    state = engine.run([1], max_epochs=max_epochs)\n    assert state.epoch == max_epochs\n\n\ndef test_terminate_at_end_of_epoch_stops_run():\n    max_epochs = 5\n    last_epoch_to_run = 3\n\n    engine = Engine(MagicMock(return_value=1))\n\n    def end_of_epoch_handler(engine):\n        if engine.state.epoch == last_epoch_to_run:\n            engine.terminate()\n\n    engine.add_event_handler(Events.EPOCH_COMPLETED, end_of_epoch_handler)\n\n    assert not engine.should_terminate\n\n    state = engine.run([1], max_epochs=max_epochs)\n\n    assert state.epoch == last_epoch_to_run\n    assert engine.should_terminate\n\n\ndef test_terminate_at_start_of_epoch_stops_run_after_completing_iteration():\n    max_epochs = 5\n    epoch_to_terminate_on = 3\n    batches_per_epoch = [1, 2, 3]\n\n    engine = Engine(MagicMock(return_value=1))\n\n    def start_of_epoch_handler(engine):\n        if engine.state.epoch == epoch_to_terminate_on:\n            engine.terminate()\n\n    engine.add_event_handler(Events.EPOCH_STARTED, start_of_epoch_handler)\n\n    assert not engine.should_terminate\n\n    state = engine.run(batches_per_epoch, max_epochs=max_epochs)\n\n    # epoch is not completed so counter is not incremented\n    assert state.epoch == epoch_to_terminate_on\n    assert engine.should_terminate\n    # completes first iteration\n    assert state.iteration == ((epoch_to_terminate_on - 1) * len(batches_per_epoch)) + 1\n\n\ndef test_terminate_stops_run_mid_epoch():\n    num_iterations_per_epoch = 10\n    iteration_to_stop = num_iterations_per_epoch + 3\n\n    engine = Engine(MagicMock(return_value=1))\n\n    def start_of_iteration_handler(engine):\n        if engine.state.iteration == iteration_to_stop:\n            engine.terminate()\n\n    engine.add_event_handler(Events.ITERATION_STARTED, start_of_iteration_handler)\n    state = engine.run(data=[None] * num_iterations_per_epoch, max_epochs=3)\n    # completes the iteration but doesn\'t increment counter (this happens just before a new iteration starts)\n    assert state.iteration == iteration_to_stop\n    assert state.epoch == np.ceil(iteration_to_stop / num_iterations_per_epoch)  # it starts from 0\n\n\ndef test_terminate_epoch_stops_mid_epoch():\n    num_iterations_per_epoch = 10\n    iteration_to_stop = num_iterations_per_epoch + 4\n\n    engine = Engine(MagicMock(return_value=1))\n\n    def start_of_iteration_handler(engine):\n        if engine.state.iteration == iteration_to_stop:\n            engine.terminate_epoch()\n\n    max_epochs = 3\n    engine.add_event_handler(Events.ITERATION_STARTED, start_of_iteration_handler)\n    state = engine.run(data=[None] * num_iterations_per_epoch, max_epochs=max_epochs)\n    # completes the iteration but doesn\'t increment counter (this happens just before a new iteration starts)\n    true_value = num_iterations_per_epoch * (max_epochs - 1) + iteration_to_stop % num_iterations_per_epoch\n    assert state.iteration == true_value\n\n\ndef _create_mock_data_loader(epochs, batches_per_epoch):\n    batches = [MagicMock()] * batches_per_epoch\n    data_loader_manager = MagicMock()\n    batch_iterators = [iter(batches) for _ in range(epochs)]\n\n    data_loader_manager.__iter__.side_effect = batch_iterators\n    data_loader_manager.__len__.return_value = batches_per_epoch\n\n    return data_loader_manager\n\n\ndef test_iteration_events_are_fired():\n    max_epochs = 5\n    num_batches = 3\n    data = _create_mock_data_loader(max_epochs, num_batches)\n\n    engine = Engine(MagicMock(return_value=1))\n\n    mock_manager = Mock()\n    iteration_started = Mock()\n    engine.add_event_handler(Events.ITERATION_STARTED, iteration_started)\n\n    iteration_complete = Mock()\n    engine.add_event_handler(Events.ITERATION_COMPLETED, iteration_complete)\n\n    mock_manager.attach_mock(iteration_started, ""iteration_started"")\n    mock_manager.attach_mock(iteration_complete, ""iteration_complete"")\n\n    engine.run(data, max_epochs=max_epochs)\n\n    assert iteration_started.call_count == num_batches * max_epochs\n    assert iteration_complete.call_count == num_batches * max_epochs\n\n    expected_calls = []\n    for i in range(max_epochs * num_batches):\n        expected_calls.append(call.iteration_started(engine))\n        expected_calls.append(call.iteration_complete(engine))\n\n    assert mock_manager.mock_calls == expected_calls\n\n\ndef test_last_event_name():\n    engine = Engine(MagicMock(return_value=1))\n    assert engine.last_event_name is None\n\n    @engine.on(Events.STARTED)\n    def _(_engine):\n        assert _engine.last_event_name == Events.STARTED\n\n    @engine.on(Events.EPOCH_STARTED)\n    def _(_engine):\n        assert _engine.last_event_name == Events.EPOCH_STARTED\n\n    @engine.on(Events.ITERATION_STARTED)\n    def _(_engine):\n        assert _engine.last_event_name == Events.ITERATION_STARTED\n\n    @engine.on(Events.ITERATION_COMPLETED)\n    def _(_engine):\n        assert _engine.last_event_name == Events.ITERATION_COMPLETED\n\n    @engine.on(Events.EPOCH_COMPLETED)\n    def _(_engine):\n        assert _engine.last_event_name == Events.EPOCH_COMPLETED\n\n    engine.run([0, 1])\n    assert engine.last_event_name == Events.COMPLETED\n\n\ndef test_reset_should_terminate():\n    def update_fn(engine, batch):\n        pass\n\n    engine = Engine(update_fn)\n\n    @engine.on(Events.ITERATION_COMPLETED)\n    def terminate_on_iteration_10(engine):\n        if engine.state.iteration == 10:\n            engine.terminate()\n\n    engine.run([0] * 20)\n    assert engine.state.iteration == 10\n\n    engine.run([0] * 20)\n    assert engine.state.iteration == 10\n\n\ndef test_batch_values():\n    def _test(data):\n        # This test check the content passed to update function\n        counter = [0]\n        num_iters = len(data)\n\n        def update_fn(_, batch):\n            assert batch == data[counter[0] % num_iters]\n            counter[0] += 1\n\n        engine = Engine(update_fn)\n        engine.run(data, max_epochs=10)\n\n    data = torch.randint(0, 1000, size=(256,))\n    _test(data)\n\n\ndef test_state_repr():\n\n    data = [0, 1, 2, 3, 4, 5]\n    max_epochs = 1\n    metrics = {""accuracy"": Mock()}\n    state = State(dataloader=data, max_epochs=max_epochs, metrics=metrics)\n    s = repr(state)\n    assert ""iteration"" in s\n    assert ""epoch"" in s\n    assert ""max_epochs: 1"" in s\n    assert ""dataloader"" in s\n    assert ""metrics"" in s\n    assert ""output"" in s\n    assert ""batch"" in s\n\n\ndef test_alter_batch():\n\n    small_shape = (1, 2, 2)\n    large_shape = (1, 3, 3)\n\n    small_loader = torch.randint(0, 256, size=(30,) + small_shape)\n    large_loader = torch.randint(0, 256, size=(20,) + large_shape)\n\n    switch_iteration = 50\n\n    def should_take_large_img(i):\n        return i >= switch_iteration\n\n    def update_fn(engine, batch):\n        i = engine.state.iteration\n        if i < switch_iteration:\n            assert batch.shape == small_shape\n            assert (small_loader[(i - 1) % len(small_loader), ...] == batch).all()\n        else:\n            assert batch.shape == large_shape\n            assert (large_loader[(i - switch_iteration) % len(large_loader), ...] == batch).all()\n\n    trainer = Engine(update_fn)\n\n    def cycle(seq):\n        while True:\n            for i in seq:\n                yield i\n\n    small_loader_iter = cycle(small_loader)\n    large_loader_iter = cycle(large_loader)\n\n    @trainer.on(Events.ITERATION_STARTED)\n    def choose_batch(engine):\n        i = engine.state.iteration\n        if should_take_large_img(i):\n            batch = next(large_loader_iter)\n        else:\n            batch = next(small_loader_iter)\n\n        engine.state.batch = batch\n\n    num_epochs = 5\n    num_iters = 25\n    data = range(num_iters)\n    trainer.run(data, num_epochs)\n\n\ndef test__is_done():\n    state = State(iteration=10, epoch=1, max_epochs=100, epoch_length=100)\n    assert not Engine._is_done(state)\n\n    state = State(iteration=1000, max_epochs=10, epoch_length=100)\n    assert Engine._is_done(state)\n\n\ndef test__setup_engine():\n    engine = Engine(lambda e, b: 1)\n    engine.state = State(iteration=10, epoch=1, max_epochs=100, epoch_length=100)\n\n    data = list(range(100))\n    engine.state.dataloader = data\n    engine._setup_engine()\n    assert len(engine._init_iter) == 1 and engine._init_iter[0] == 10\n    # assert engine._dataloader_len == len(data)\n\n\ndef test_run_asserts():\n    engine = Engine(lambda e, b: 1)\n\n    with pytest.raises(ValueError, match=r""Input data has zero size. Please provide non-empty data""):\n        engine.run([])\n\n    with pytest.warns(UserWarning, match=""Argument seed is deprecated""):\n        engine.run([0, 1, 2, 3, 4], seed=1234)\n\n\ndef test_state_get_event_attrib_value():\n    state = State()\n    state.iteration = 10\n    state.epoch = 9\n\n    e = Events.ITERATION_STARTED\n    assert state.get_event_attrib_value(e) == state.iteration\n    e = Events.ITERATION_COMPLETED\n    assert state.get_event_attrib_value(e) == state.iteration\n    e = Events.EPOCH_STARTED\n    assert state.get_event_attrib_value(e) == state.epoch\n    e = Events.EPOCH_COMPLETED\n    assert state.get_event_attrib_value(e) == state.epoch\n    e = Events.STARTED\n    assert state.get_event_attrib_value(e) == state.epoch\n    e = Events.COMPLETED\n    assert state.get_event_attrib_value(e) == state.epoch\n\n    e = Events.ITERATION_STARTED(every=10)\n    assert state.get_event_attrib_value(e) == state.iteration\n    e = Events.ITERATION_COMPLETED(every=10)\n    assert state.get_event_attrib_value(e) == state.iteration\n    e = Events.EPOCH_STARTED(once=5)\n    assert state.get_event_attrib_value(e) == state.epoch\n    e = Events.EPOCH_COMPLETED(once=5)\n    assert state.get_event_attrib_value(e) == state.epoch\n\n\ndef test_time_stored_in_state():\n    def _test(data, max_epochs, epoch_length):\n        sleep_time = 0.01\n        engine = Engine(lambda e, b: time.sleep(sleep_time))\n\n        def check_epoch_time(engine):\n            assert engine.state.times[Events.EPOCH_COMPLETED.name] >= sleep_time * epoch_length\n\n        def check_completed_time(engine):\n            assert engine.state.times[Events.COMPLETED.name] >= sleep_time * epoch_length * max_epochs\n\n        engine.add_event_handler(Events.EPOCH_COMPLETED, lambda e: check_epoch_time(e))\n        engine.add_event_handler(Events.COMPLETED, lambda e: check_completed_time(e))\n\n        engine.run(data, max_epochs=max_epochs, epoch_length=epoch_length)\n\n    _test(list(range(100)), max_epochs=2, epoch_length=100)\n    _test(list(range(200)), max_epochs=2, epoch_length=100)\n    _test(list(range(200)), max_epochs=5, epoch_length=100)\n\n\ndef _test_check_triggered_events(data, max_epochs, epoch_length, exp_iter_stops=None):\n    engine = Engine(lambda e, b: 1)\n    events = [\n        Events.STARTED,\n        Events.EPOCH_STARTED,\n        Events.ITERATION_STARTED,\n        Events.ITERATION_COMPLETED,\n        Events.EPOCH_COMPLETED,\n        Events.COMPLETED,\n        Events.GET_BATCH_STARTED,\n        Events.GET_BATCH_COMPLETED,\n        Events.DATALOADER_STOP_ITERATION,\n    ]\n\n    handlers = {e: MagicMock() for e in events}\n\n    for e, handler in handlers.items():\n        engine.add_event_handler(e, handler)\n\n    engine.run(data, max_epochs=max_epochs, epoch_length=epoch_length)\n\n    expected_num_calls = {\n        Events.STARTED: 1,\n        Events.COMPLETED: 1,\n        Events.EPOCH_STARTED: max_epochs,\n        Events.EPOCH_COMPLETED: max_epochs,\n        Events.ITERATION_STARTED: max_epochs * epoch_length,\n        Events.ITERATION_COMPLETED: max_epochs * epoch_length,\n        Events.GET_BATCH_STARTED: max_epochs * epoch_length,\n        Events.GET_BATCH_COMPLETED: max_epochs * epoch_length,\n        Events.DATALOADER_STOP_ITERATION: (max_epochs - 1) if exp_iter_stops is None else exp_iter_stops,\n    }\n\n    for n, handler in handlers.items():\n        assert handler.call_count == expected_num_calls[n], ""{}: {} vs {}"".format(\n            n, handler.call_count, expected_num_calls[n]\n        )\n\n\ndef _test_run_check_triggered_events():\n    # tests issue https://github.com/pytorch/ignite/issues/818\n    _test_check_triggered_events(list(range(10)), max_epochs=4, epoch_length=10)\n    _test_check_triggered_events(list(range(100)), max_epochs=5, epoch_length=100)\n    _test_check_triggered_events(list(range(100)), max_epochs=5, epoch_length=50, exp_iter_stops=50 * 5 // 100)\n    _test_check_triggered_events(list(range(100)), max_epochs=5, epoch_length=150, exp_iter_stops=150 * 5 // 100)\n\n\ndef test_run_check_triggered_events_list():\n    _test_run_check_triggered_events()\n\n\ndef _test_run_check_triggered_events_on_iterator():\n    def infinite_data_iterator():\n        while True:\n            for i in range(100):\n                yield i\n\n    _test_check_triggered_events(infinite_data_iterator(), max_epochs=5, epoch_length=100, exp_iter_stops=0)\n    _test_check_triggered_events(infinite_data_iterator(), max_epochs=5, epoch_length=50, exp_iter_stops=0)\n    _test_check_triggered_events(infinite_data_iterator(), max_epochs=5, epoch_length=150, exp_iter_stops=0)\n\n    def limited_data_iterator():\n        for i in range(100):\n            yield i\n\n    _test_check_triggered_events(limited_data_iterator(), max_epochs=1, epoch_length=100, exp_iter_stops=0)\n    _test_check_triggered_events(limited_data_iterator(), max_epochs=10, epoch_length=10, exp_iter_stops=0)\n\n    # These tests will fail\n    with pytest.raises(AssertionError):\n        with pytest.warns(UserWarning, match=r""Data iterator can not provide data anymore""):\n            _test_check_triggered_events(limited_data_iterator(), max_epochs=3, epoch_length=100)\n\n    with pytest.raises(AssertionError):\n        with pytest.warns(UserWarning, match=r""Data iterator can not provide data anymore""):\n            _test_check_triggered_events(limited_data_iterator(), max_epochs=3, epoch_length=75)\n\n    with pytest.raises(AssertionError):\n        with pytest.warns(UserWarning, match=r""Data iterator can not provide data anymore""):\n            _test_check_triggered_events(limited_data_iterator(), max_epochs=1, epoch_length=101)\n\n\ndef test_run_check_triggered_events_on_iterator():\n\n    _test_run_check_triggered_events_on_iterator()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl):\n    _test_run_check_triggered_events_on_iterator()\n    _test_run_check_triggered_events()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    _test_run_check_triggered_events_on_iterator()\n    _test_run_check_triggered_events()\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    _test_run_check_triggered_events_on_iterator()\n    _test_run_check_triggered_events()\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    _test_run_check_triggered_events_on_iterator()\n    _test_run_check_triggered_events()\n\n\n@pytest.mark.skipif(LooseVersion(torch.__version__) < LooseVersion(""1.2.0""), reason=""No IterableDataset in torch<1.2.0"")\ndef test_engine_with_iterable_dataloader():\n\n    from torch.utils.data import DataLoader\n\n    def _test(epoch_length=None):\n\n        le = 50\n        num_workers = 4\n        ds = get_iterable_dataset(0, le)\n        data_loader = DataLoader(ds, num_workers=num_workers)\n\n        counter = [0]\n\n        def foo(e, b):\n            print(""{}-{}: {}"".format(e.state.epoch, e.state.iteration, b))\n            counter[0] += 1\n\n        engine = Engine(foo)\n        engine.run(data_loader, epoch_length=epoch_length, max_epochs=5)\n\n        epoch_length = le * num_workers if epoch_length is None else epoch_length\n        assert counter[0] == 5 * epoch_length\n\n    _test(epoch_length=20)\n\n    # tests issue : https://github.com/pytorch/ignite/issues/1076\n    _test(epoch_length=None)\n\n\ndef test_engine_random_state():\n    def random_data_generator():\n        while True:\n            yield torch.randint(0, 100, size=(5,))\n\n    def sum_data(_, batch):\n        result = torch.sum(batch)\n        return result\n\n    def get_engine():\n        engine = Engine(sum_data)\n        average = Average()\n        average.attach(engine, ""average"")\n        return engine\n\n    torch.manual_seed(34)\n    engine = get_engine()\n    state1 = engine.run(random_data_generator(), max_epochs=2, epoch_length=2)\n\n    torch.manual_seed(34)\n    engine = get_engine()\n    state2 = engine.run(random_data_generator(), max_epochs=2, epoch_length=2)\n\n    torch.manual_seed(42)\n    engine = get_engine()\n    state3 = engine.run(random_data_generator(), max_epochs=2, epoch_length=2)\n\n    assert state1.metrics[""average""] == pytest.approx(state2.metrics[""average""])\n    assert state1.metrics[""average""] != pytest.approx(state3.metrics[""average""])\n    assert state2.metrics[""average""] != pytest.approx(state3.metrics[""average""])\n\n\ndef test_altered_random_state():\n    # tests issue https://github.com/pytorch/ignite/issues/795\n    size = 1\n\n    def random_train_data_generator(size):\n        while True:\n            yield torch.randint(0, 100, size=(size,))\n\n    def random_val_data_generator(size):\n        while True:\n            yield torch.randint(0, 100, size=(size,)) + 100\n\n    train_only_batches = []\n\n    def train_fn(_, batch):\n        train_only_batches.append(batch[0].item())\n\n    torch.manual_seed(1)\n    epoch_length = 6\n    trainer = Engine(train_fn)\n    trainer.run(\n        random_train_data_generator(size), max_epochs=4, epoch_length=epoch_length,\n    )\n\n    def val_fn(_1, _2):\n        pass\n\n    evaluator = Engine(val_fn)\n    train_batches = []\n\n    def train_fn2(_, batch):\n        train_batches.append(batch[0].item())\n\n    trainer = Engine(train_fn2)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    @keep_random_state\n    def run_evaluation(_):\n        evaluator.run(random_val_data_generator(size), epoch_length=4)\n\n    torch.manual_seed(1)\n    trainer.run(\n        random_train_data_generator(size), max_epochs=4, epoch_length=epoch_length,\n    )\n\n    for i in range(epoch_length):\n        assert train_batches[epoch_length + i] != train_batches[2 * epoch_length + i]\n        assert train_batches[i] == train_only_batches[i]\n\n\ndef test_engine_with_dataloader_no_auto_batching():\n    # tests https://github.com/pytorch/ignite/issues/941\n    from torch.utils.data import DataLoader, BatchSampler, RandomSampler\n\n    data = torch.rand(64, 4, 10)\n    data_loader = DataLoader(\n        data, batch_size=None, sampler=BatchSampler(RandomSampler(data), batch_size=8, drop_last=True)\n    )\n\n    counter = [0]\n\n    def foo(e, b):\n        print(""{}-{}: {}"".format(e.state.epoch, e.state.iteration, b))\n        counter[0] += 1\n\n    engine = Engine(foo)\n    engine.run(data_loader, epoch_length=10, max_epochs=5)\n\n    assert counter[0] == 50\n\n\ndef test_run_once_finite_iterator_no_epoch_length():\n    # FR: https://github.com/pytorch/ignite/issues/871\n\n    unknown_size = 11\n\n    def finite_unk_size_data_iter():\n        for i in range(unknown_size):\n            yield i\n\n    bc = BatchChecker(data=list(range(unknown_size)))\n\n    engine = Engine(lambda e, b: bc.check(b))\n\n    completed_handler = MagicMock()\n    engine.add_event_handler(Events.COMPLETED, completed_handler)\n\n    data_iter = finite_unk_size_data_iter()\n    engine.run(data_iter)\n\n    assert engine.state.epoch == 1\n    assert engine.state.iteration == unknown_size\n    assert completed_handler.call_count == 1\n\n\ndef test_run_finite_iterator_no_epoch_length():\n    # FR: https://github.com/pytorch/ignite/issues/871\n    unknown_size = 11\n\n    def finite_unk_size_data_iter():\n        for i in range(unknown_size):\n            yield i\n\n    bc = BatchChecker(data=list(range(unknown_size)))\n\n    engine = Engine(lambda e, b: bc.check(b))\n\n    @engine.on(Events.DATALOADER_STOP_ITERATION)\n    def restart_iter():\n        engine.state.dataloader = finite_unk_size_data_iter()\n\n    data_iter = finite_unk_size_data_iter()\n    engine.run(data_iter, max_epochs=5)\n\n    assert engine.state.epoch == 5\n    assert engine.state.iteration == unknown_size * 5\n\n\ndef test_run_finite_iterator_no_epoch_length_2():\n    # FR: https://github.com/pytorch/ignite/issues/871\n    known_size = 11\n\n    def finite_size_data_iter(size):\n        for i in range(size):\n            yield i\n\n    bc = BatchChecker(data=list(range(known_size)))\n\n    engine = Engine(lambda e, b: bc.check(b))\n\n    @engine.on(Events.ITERATION_COMPLETED(every=known_size))\n    def restart_iter():\n        engine.state.dataloader = finite_size_data_iter(known_size)\n\n    data_iter = finite_size_data_iter(known_size)\n    engine.run(data_iter, max_epochs=5)\n\n    assert engine.state.epoch == 5\n    assert engine.state.iteration == known_size * 5\n\n\ndef test_faq_inf_iterator_with_epoch_length():\n    # Code snippet from FAQ\n\n    import torch\n\n    torch.manual_seed(12)\n\n    def infinite_iterator(batch_size):\n        while True:\n            batch = torch.rand(batch_size, 3, 32, 32)\n            yield batch\n\n    def train_step(trainer, batch):\n        # ...\n        s = trainer.state\n        print(""{}/{} : {} - {:.3f}"".format(s.epoch, s.max_epochs, s.iteration, batch.norm()))\n\n    trainer = Engine(train_step)\n    # We need to specify epoch_length to define the epoch\n    trainer.run(infinite_iterator(4), epoch_length=5, max_epochs=3)\n\n    assert trainer.state.epoch == 3\n    assert trainer.state.iteration == 3 * 5\n\n\ndef test_faq_inf_iterator_no_epoch_length():\n    # Code snippet from FAQ\n\n    import torch\n\n    torch.manual_seed(12)\n\n    def infinite_iterator(batch_size):\n        while True:\n            batch = torch.rand(batch_size, 3, 32, 32)\n            yield batch\n\n    def train_step(trainer, batch):\n        # ...\n        s = trainer.state\n        print(""{}/{} : {} - {:.3f}"".format(s.epoch, s.max_epochs, s.iteration, batch.norm()))\n\n    trainer = Engine(train_step)\n\n    @trainer.on(Events.ITERATION_COMPLETED(once=15))\n    def stop_training():\n        trainer.terminate()\n\n    trainer.run(infinite_iterator(4))\n\n    assert trainer.state.epoch == 1\n    assert trainer.state.iteration == 15\n\n\ndef test_faq_fin_iterator_unknw_size():\n    # Code snippet from FAQ\n\n    import torch\n\n    torch.manual_seed(12)\n\n    def finite_unk_size_data_iter():\n        for i in range(11):\n            yield i\n\n    def train_step(trainer, batch):\n        # ...\n        s = trainer.state\n        print(""{}/{} : {} - {:.3f}"".format(s.epoch, s.max_epochs, s.iteration, batch))\n\n    trainer = Engine(train_step)\n\n    @trainer.on(Events.DATALOADER_STOP_ITERATION)\n    def restart_iter():\n        trainer.state.dataloader = finite_unk_size_data_iter()\n\n    data_iter = finite_unk_size_data_iter()\n    trainer.run(data_iter, max_epochs=5)\n\n    assert trainer.state.epoch == 5\n    assert trainer.state.iteration == 5 * 11\n\n    # # # # #\n\n    import torch\n\n    torch.manual_seed(12)\n\n    def finite_unk_size_data_iter():\n        for i in range(11):\n            yield i\n\n    def val_step(evaluator, batch):\n        # ...\n        s = evaluator.state\n        print(""{}/{} : {} - {:.3f}"".format(s.epoch, s.max_epochs, s.iteration, batch))\n\n    evaluator = Engine(val_step)\n\n    data_iter = finite_unk_size_data_iter()\n    evaluator.run(data_iter)\n\n    assert evaluator.state.epoch == 1\n    assert evaluator.state.iteration == 1 * 11\n\n\ndef test_faq_fin_iterator():\n    # Code snippet from FAQ\n\n    import torch\n\n    torch.manual_seed(12)\n\n    size = 11\n\n    def finite_size_data_iter(size):\n        for i in range(size):\n            yield i\n\n    def train_step(trainer, batch):\n        # ...\n        s = trainer.state\n        print(""{}/{} : {} - {:.3f}"".format(s.epoch, s.max_epochs, s.iteration, batch))\n\n    trainer = Engine(train_step)\n\n    @trainer.on(Events.ITERATION_COMPLETED(every=size))\n    def restart_iter():\n        trainer.state.dataloader = finite_size_data_iter(size)\n\n    data_iter = finite_size_data_iter(size)\n    trainer.run(data_iter, max_epochs=5)\n\n    assert trainer.state.epoch == 5\n    assert trainer.state.iteration == 5 * size\n\n    # # # # #\n\n    import torch\n\n    torch.manual_seed(12)\n\n    size = 11\n\n    def finite_size_data_iter(size):\n        for i in range(size):\n            yield i\n\n    def val_step(evaluator, batch):\n        # ...\n        s = evaluator.state\n        print(""{}/{} : {} - {:.3f}"".format(s.epoch, s.max_epochs, s.iteration, batch))\n\n    evaluator = Engine(val_step)\n\n    data_iter = finite_size_data_iter(size)\n    evaluator.run(data_iter)\n\n    assert evaluator.state.epoch == 1\n    assert evaluator.state.iteration == size\n\n\ndef test_set_data():\n    # tests FR https://github.com/pytorch/ignite/issues/833\n    from torch.utils.data import DataLoader\n\n    num_iters1 = 10\n    num_iters2 = 20\n    batch_size = 4\n\n    torch.manual_seed(1)\n    data1 = DataLoader(torch.rand(num_iters1 * batch_size, 11), batch_size=batch_size)\n    data2 = DataLoader(torch.rand(num_iters2 * batch_size, 22), batch_size=batch_size)\n\n    switch_iteration = 35\n\n    def train_fn(e, batch):\n        if e.state.iteration <= switch_iteration:\n            assert batch.shape[1] == 11, ""{}: {}"".format(e.state.iteration, batch.shape)\n        else:\n            assert batch.shape[1] == 22, ""{}: {}"".format(e.state.iteration, batch.shape)\n\n    trainer = Engine(train_fn)\n\n    @trainer.on(Events.ITERATION_COMPLETED(once=switch_iteration))\n    def switch_dataloader():\n        trainer.set_data(data2)\n\n    trainer.run(data1, max_epochs=10)\n'"
tests/ignite/engine/test_engine_state_dict.py,3,"b'import os\nfrom collections.abc import Mapping\n\nimport pytest\nimport torch\n\nfrom ignite.engine import Engine, Events, State\nfrom tests.ignite.engine import BatchChecker, EpochCounter, IterationCounter\n\n\ndef test_state_dict():\n    engine = Engine(lambda e, b: 1)\n    sd = engine.state_dict()\n    assert isinstance(sd, Mapping) and len(sd) == 3\n    assert ""iteration"" in sd and sd[""iteration""] == 0\n    assert ""max_epochs"" in sd and sd[""max_epochs""] is None\n    assert ""epoch_length"" in sd and sd[""epoch_length""] is None\n\n    def _test(state):\n        engine.state = state\n        sd = engine.state_dict()\n        assert isinstance(sd, Mapping) and len(sd) == len(engine._state_dict_all_req_keys) + 1\n        assert sd[""iteration""] == engine.state.iteration\n        assert sd[""epoch_length""] == engine.state.epoch_length\n        assert sd[""max_epochs""] == engine.state.max_epochs\n\n    _test(State(iteration=500, epoch_length=1000, max_epochs=100))\n    _test(State(epoch=5, epoch_length=1000, max_epochs=100))\n\n\ndef test_state_dict_with_user_keys():\n    engine = Engine(lambda e, b: 1)\n    engine.state_dict_user_keys.append(""alpha"")\n    engine.state_dict_user_keys.append(""beta"")\n\n    def _test(state):\n        engine.state = state\n        sd = engine.state_dict()\n        assert isinstance(sd, Mapping) and len(sd) == len(engine._state_dict_all_req_keys) + 1 + len(\n            engine.state_dict_user_keys\n        )\n        assert sd[""iteration""] == engine.state.iteration\n        assert sd[""epoch_length""] == engine.state.epoch_length\n        assert sd[""max_epochs""] == engine.state.max_epochs\n        assert sd[""alpha""] == engine.state.alpha\n        assert sd[""beta""] == engine.state.beta\n\n    _test(State(iteration=500, epoch_length=1000, max_epochs=100, alpha=0.01, beta=""Good""))\n\n\ndef test_state_dict_integration():\n    engine = Engine(lambda e, b: 1)\n    data = range(100)\n    engine.run(data, max_epochs=10)\n    sd = engine.state_dict()\n    assert isinstance(sd, Mapping) and len(sd) == len(engine._state_dict_all_req_keys) + 1\n    assert sd[""iteration""] == engine.state.iteration == 10 * 100\n    assert sd[""epoch_length""] == engine.state.epoch_length == 100\n    assert sd[""max_epochs""] == engine.state.max_epochs == 10\n\n\ndef test_load_state_dict_asserts():\n    engine = Engine(lambda e, b: 1)\n\n    with pytest.raises(TypeError, match=r""Argument state_dict should be a dictionary""):\n        engine.load_state_dict(""123"")\n\n    with pytest.raises(ValueError, match=r""is absent in provided state_dict""):\n        engine.load_state_dict({})\n\n    with pytest.raises(ValueError, match=r""state_dict should contain only one of""):\n        engine.load_state_dict({""max_epochs"": 100, ""epoch_length"": 120})\n\n    with pytest.raises(ValueError, match=r""state_dict should contain only one of""):\n        engine.load_state_dict({""max_epochs"": 100, ""epoch_length"": 120, ""iteration"": 12, ""epoch"": 123})\n\n    engine = Engine(lambda e, b: 1)\n    engine.state_dict_user_keys.append(""alpha"")\n    with pytest.raises(ValueError, match=r""Required user state attribute""):\n        engine.load_state_dict({""max_epochs"": 100, ""epoch_length"": 120, ""iteration"": 12})\n\n    engine = Engine(lambda e, b: 1)\n    with pytest.raises(ValueError, match=r""If epoch is provided in the state dict, epoch_length should not be None""):\n        engine.load_state_dict({""max_epochs"": 100, ""epoch"": 2, ""epoch_length"": None})\n\n\ndef test_load_state_dict():\n    engine = Engine(lambda e, b: 1)\n\n    def _test(sd):\n        engine.load_state_dict(sd)\n        if ""iteration"" in sd:\n            assert sd[""iteration""] == engine.state.iteration\n        elif ""epoch"" in sd:\n            assert sd[""epoch""] == engine.state.epoch\n        assert sd[""epoch_length""] == engine.state.epoch_length\n        assert sd[""max_epochs""] == engine.state.max_epochs\n\n    _test({""max_epochs"": 100, ""epoch_length"": 120, ""iteration"": 123})\n    _test({""max_epochs"": 100, ""epoch_length"": 120, ""epoch"": 5})\n\n\ndef test_load_state_dict_with_user_keys():\n    engine = Engine(lambda e, b: 1)\n    engine.state_dict_user_keys.append(""alpha"")\n    engine.state_dict_user_keys.append(""beta"")\n\n    def _test(sd):\n        engine.load_state_dict(sd)\n        if ""iteration"" in sd:\n            assert sd[""iteration""] == engine.state.iteration\n        elif ""epoch"" in sd:\n            assert sd[""epoch""] == engine.state.epoch\n        assert sd[""epoch_length""] == engine.state.epoch_length\n        assert sd[""max_epochs""] == engine.state.max_epochs\n        assert sd[""alpha""] == engine.state.alpha\n        assert sd[""beta""] == engine.state.beta\n\n    _test({""max_epochs"": 100, ""epoch_length"": 120, ""iteration"": 123, ""alpha"": 0.1, ""beta"": ""abc""})\n\n\ndef test_load_state_dict_integration():\n    engine = Engine(lambda e, b: 1)\n\n    state_dict = {""max_epochs"": 100, ""epoch_length"": 120, ""epoch"": 5}\n\n    engine.load_state_dict(state_dict)\n    engine.add_event_handler(Events.ITERATION_COMPLETED, IterationCounter(5 * 120 + 1))\n    engine.add_event_handler(Events.EPOCH_COMPLETED, EpochCounter(6))\n    data = range(120)\n    engine.run(data)\n\n\ndef test_load_state_dict_with_params_overriding_integration():\n\n    state_dict = {""max_epochs"": 100, ""epoch_length"": 120, ""epoch"": 5}\n    data = range(120)\n\n    # Override max_epochs\n    new_max_epochs = 10\n    engine = Engine(lambda e, b: 1)\n    engine.load_state_dict(state_dict)\n    state = engine.run(data, max_epochs=new_max_epochs)\n    assert state.max_epochs == new_max_epochs\n    assert state.iteration == state_dict[""epoch_length""] * new_max_epochs\n    assert state.epoch == new_max_epochs\n\n    with pytest.raises(ValueError, match=r""Argument max_epochs should be larger than the start epoch""):\n        engine.load_state_dict(state_dict)\n        engine.run(data, max_epochs=3)\n\n    # Override epoch_length\n    with pytest.raises(ValueError, match=r""Argument epoch_length should be same as in the state""):\n        engine.load_state_dict(state_dict)\n        engine.run(data, epoch_length=90)\n\n\ndef test_empty_state_dict_load_state_dict():\n    engine = Engine(lambda e, b: 1)\n    sd = engine.state_dict()\n    engine.load_state_dict(sd)\n\n\ndef test_continue_training():\n    # Tests issue : https://github.com/pytorch/ignite/issues/993\n    max_epochs = 2\n    data = range(10)\n    engine = Engine(lambda e, b: 1)\n    state = engine.run(data, max_epochs=max_epochs)\n    assert state.max_epochs == max_epochs\n    assert state.iteration == len(data) * max_epochs\n    assert state.epoch == max_epochs\n\n    @engine.on(Events.STARTED)\n    def assert_continue_training():\n        assert engine.state.epoch == max_epochs\n\n    state = engine.run(data, max_epochs=max_epochs * 2)\n    assert state.max_epochs == max_epochs * 2\n    assert state.iteration == len(data) * max_epochs * 2\n    assert state.epoch == max_epochs * 2\n\n\ndef test_state_dict_with_user_keys_integration(dirname):\n    engine = Engine(lambda e, b: 1)\n    engine.state_dict_user_keys.append(""alpha"")\n\n    @engine.on(Events.STARTED)\n    def init_user_values(_):\n        engine.state.alpha = 0.1\n\n    fp = os.path.join(dirname, ""engine.pt"")\n\n    @engine.on(Events.COMPLETED)\n    def save_engine(_):\n        state_dict = engine.state_dict()\n        assert ""alpha"" in state_dict\n        torch.save(state_dict, fp)\n\n    engine.run([0, 1])\n\n    assert os.path.exists(fp)\n    state_dict = torch.load(fp)\n    assert ""alpha"" in state_dict and state_dict[""alpha""] == 0.1\n\n\ndef test_epoch_length():\n    def _test(data, max_epochs, num_iters):\n\n        batch_checker = BatchChecker(data)\n\n        def update_fn(_, batch):\n            assert batch_checker.check(batch), ""{}: {} vs {}"".format(\n                batch_checker.counter, batch_checker.true_batch, batch\n            )\n\n        engine = Engine(update_fn)\n        engine.run(data, max_epochs=max_epochs, epoch_length=num_iters)\n        if num_iters is None:\n            num_iters = len(data)\n        assert engine.state.iteration == num_iters * max_epochs\n        assert engine.state.epoch == max_epochs\n\n    def _test_as_iter(data, max_epochs, num_iters):\n\n        batch_checker = BatchChecker(data)\n\n        def update_fn(_, batch):\n            assert batch_checker.check(batch), ""{}: {} vs {}"".format(\n                batch_checker.counter, batch_checker.true_batch, batch\n            )\n\n        engine = Engine(update_fn)\n        engine.run(iter(data), max_epochs=max_epochs, epoch_length=num_iters)\n        if num_iters is None:\n            num_iters = len(data)\n        assert engine.state.iteration == num_iters * max_epochs\n        assert engine.state.epoch == max_epochs\n\n    max_epochs = 10\n    num_iters = 21\n    data = torch.randint(0, 1000, size=(num_iters,))\n    _test(data, max_epochs, num_iters=None)\n    _test(data, max_epochs, num_iters)\n    _test(data, max_epochs, num_iters // 2)\n    _test(data, max_epochs, num_iters * 2)\n\n    _test_as_iter(data, 1, num_iters)\n    _test_as_iter(data, 2, num_iters // 2)\n\n\ndef test_state_custom_attrs_init():\n    def _test(with_load_state_dict=False):\n        engine = Engine(lambda e, b: None)\n        engine.state.alpha = 0.0\n        engine.state.beta = 1.0\n\n        if with_load_state_dict:\n            engine.load_state_dict({""iteration"": 3, ""max_epochs"": 5, ""epoch_length"": 5})\n\n        @engine.on(Events.STARTED | Events.EPOCH_STARTED | Events.EPOCH_COMPLETED | Events.COMPLETED)\n        def check_custom_attr():\n            assert hasattr(engine.state, ""alpha"") and engine.state.alpha == 0.0\n            assert hasattr(engine.state, ""beta"") and engine.state.beta == 1.0\n\n        engine.run([0, 1, 2, 3, 4], max_epochs=5)\n\n    _test()\n    _test(with_load_state_dict=True)\n'"
tests/ignite/engine/test_event_handlers.py,0,"b'import functools\nimport gc\nfrom unittest.mock import MagicMock, call, create_autospec\n\nimport pytest\nfrom pytest import raises\n\nfrom ignite.engine import Engine, Events, State\nfrom ignite.engine.events import EventsList\n\n\nclass DummyEngine(Engine):\n    def __init__(self):\n        super(DummyEngine, self).__init__(lambda e, b: 1)\n\n    def run(self, num_times):\n        self.state = State()\n        for _ in range(num_times):\n            self.fire_event(Events.STARTED)\n            self.fire_event(Events.COMPLETED)\n        return self.state\n\n\ndef test_add_event_handler_raises_with_invalid_event():\n    engine = Engine(lambda e, b: 1)\n\n    with pytest.raises(ValueError, match=r""is not a valid event for this Engine""):\n        engine.add_event_handler(""incorrect"", lambda engine: None)\n\n\ndef test_add_event_handler_raises_with_invalid_signature():\n    engine = Engine(MagicMock())\n\n    def handler(engine):\n        pass\n\n    engine.add_event_handler(Events.STARTED, handler)\n    engine.add_event_handler(Events.STARTED, handler, 1)\n\n    def handler_with_args(engine, a):\n        pass\n\n    engine.add_event_handler(Events.STARTED, handler_with_args, 1)\n    with pytest.raises(ValueError):\n        engine.add_event_handler(Events.STARTED, handler_with_args)\n\n    def handler_with_kwargs(engine, b=42):\n        pass\n\n    engine.add_event_handler(Events.STARTED, handler_with_kwargs, b=2)\n    with pytest.raises(ValueError):\n        engine.add_event_handler(Events.STARTED, handler_with_kwargs, c=3)\n    engine.add_event_handler(Events.STARTED, handler_with_kwargs, 1, b=2)\n\n    def handler_with_args_and_kwargs(engine, a, b=42):\n        pass\n\n    engine.add_event_handler(Events.STARTED, handler_with_args_and_kwargs, 1, b=2)\n    engine.add_event_handler(Events.STARTED, handler_with_args_and_kwargs, 1, 2, b=2)\n    with pytest.raises(ValueError):\n        engine.add_event_handler(Events.STARTED, handler_with_args_and_kwargs, 1, b=2, c=3)\n\n\ndef test_add_event_handler():\n    engine = DummyEngine()\n\n    class Counter(object):\n        def __init__(self, count=0):\n            self.count = count\n\n    started_counter = Counter()\n\n    def handle_iteration_started(engine, counter):\n        counter.count += 1\n\n    engine.add_event_handler(Events.STARTED, handle_iteration_started, started_counter)\n\n    completed_counter = Counter()\n\n    def handle_iteration_completed(engine, counter):\n        counter.count += 1\n\n    engine.add_event_handler(Events.COMPLETED, handle_iteration_completed, completed_counter)\n\n    engine.run(15)\n\n    assert started_counter.count == 15\n    assert completed_counter.count == 15\n\n\ndef test_add_event_handler_without_engine():\n    engine = DummyEngine()\n\n    class Counter(object):\n        def __init__(self, count=0):\n            self.count = count\n\n    started_counter = Counter()\n\n    def handle_iteration_started():\n        started_counter.count += 1\n\n    engine.add_event_handler(Events.STARTED, handle_iteration_started)\n\n    completed_counter = Counter()\n\n    def handle_iteration_completed(counter):\n        counter.count += 1\n\n    engine.add_event_handler(Events.COMPLETED, handle_iteration_completed, completed_counter)\n\n    engine.run(15)\n\n    assert started_counter.count == 15\n    assert completed_counter.count == 15\n\n\ndef test_adding_multiple_event_handlers():\n    mock_fn_1 = create_autospec(spec=lambda x: None)\n    mock_fn_2 = create_autospec(spec=lambda x: None)\n\n    engine = DummyEngine()\n    handlers = [mock_fn_1, mock_fn_2]\n    for handler in handlers:\n        engine.add_event_handler(Events.STARTED, handler)\n\n    engine.run(1)\n    for handler in handlers:\n        handler.assert_called_once_with(engine)\n\n\ndef test_event_removable_handle():\n\n    # Removable handle removes event from engine.\n    engine = DummyEngine()\n    handler = create_autospec(spec=lambda x: None)\n    assert not hasattr(handler, ""_parent"")\n\n    removable_handle = engine.add_event_handler(Events.STARTED, handler)\n    assert engine.has_event_handler(handler, Events.STARTED)\n\n    engine.run(1)\n    handler.assert_called_once_with(engine)\n\n    removable_handle.remove()\n    assert not engine.has_event_handler(handler, Events.STARTED)\n\n    # Second engine pass does not fire handle again.\n    engine.run(1)\n    handler.assert_called_once_with(engine)\n\n    # Removable handle can be used as a context manager\n    handler = create_autospec(spec=lambda x: None)\n\n    with engine.add_event_handler(Events.STARTED, handler):\n        assert engine.has_event_handler(handler, Events.STARTED)\n        engine.run(1)\n\n    assert not engine.has_event_handler(handler, Events.STARTED)\n    handler.assert_called_once_with(engine)\n\n    engine.run(1)\n    handler.assert_called_once_with(engine)\n\n    # Removeable handle only effects a single event registration\n    handler = MagicMock(spec_set=True)\n\n    with engine.add_event_handler(Events.STARTED, handler):\n        with engine.add_event_handler(Events.COMPLETED, handler):\n            assert engine.has_event_handler(handler, Events.STARTED)\n            assert engine.has_event_handler(handler, Events.COMPLETED)\n        assert engine.has_event_handler(handler, Events.STARTED)\n        assert not engine.has_event_handler(handler, Events.COMPLETED)\n    assert not engine.has_event_handler(handler, Events.STARTED)\n    assert not engine.has_event_handler(handler, Events.COMPLETED)\n\n    # Removeable handle is re-enter and re-exitable\n\n    handler = MagicMock(spec_set=True)\n\n    remove = engine.add_event_handler(Events.STARTED, handler)\n\n    with remove:\n        with remove:\n            assert engine.has_event_handler(handler, Events.STARTED)\n        assert not engine.has_event_handler(handler, Events.STARTED)\n    assert not engine.has_event_handler(handler, Events.STARTED)\n\n    # Removeable handle is a weakref, does not keep engine or event alive\n    def _add_in_closure():\n        _engine = DummyEngine()\n\n        def _handler(_):\n            pass\n\n        _handle = _engine.add_event_handler(Events.STARTED, _handler)\n        assert _handle.engine() is _engine\n        assert _handle.handler() is _handler\n\n        return _handle\n\n    removable_handle = _add_in_closure()\n\n    # gc.collect, resolving reference cycles in engine/state\n    # required to ensure object deletion in python2\n    gc.collect()\n\n    assert removable_handle.engine() is None\n    assert removable_handle.handler() is None\n\n\ndef test_events_list_removable_handle():\n\n    # Removable handle removes event from engine.\n    engine = DummyEngine()\n    handler = create_autospec(spec=lambda x: None)\n    assert not hasattr(handler, ""_parent"")\n\n    events_list = Events.STARTED | Events.COMPLETED\n\n    removable_handle = engine.add_event_handler(events_list, handler)\n    for e in events_list:\n        assert engine.has_event_handler(handler, e)\n\n    engine.run(1)\n    calls = [call(engine), call(engine)]\n    handler.assert_has_calls(calls)\n    assert handler.call_count == 2\n\n    removable_handle.remove()\n    for e in events_list:\n        assert not engine.has_event_handler(handler, e)\n\n    # Second engine pass does not fire handle again.\n    engine.run(1)\n    handler.assert_has_calls(calls)\n    assert handler.call_count == 2\n\n    # Removable handle can be used as a context manager\n    handler = create_autospec(spec=lambda x: None)\n\n    with engine.add_event_handler(events_list, handler):\n        for e in events_list:\n            assert engine.has_event_handler(handler, e)\n        engine.run(1)\n\n    for e in events_list:\n        assert not engine.has_event_handler(handler, e)\n    handler.assert_has_calls(calls)\n    assert handler.call_count == 2\n\n    engine.run(1)\n    handler.assert_has_calls(calls)\n    assert handler.call_count == 2\n\n    # Removeable handle only effects a single event registration\n    handler = create_autospec(spec=lambda x: None)\n\n    other_events_list = Events.EPOCH_STARTED | Events.EPOCH_COMPLETED\n\n    with engine.add_event_handler(events_list, handler):\n        with engine.add_event_handler(other_events_list, handler):\n            for e in events_list:\n                assert engine.has_event_handler(handler, e)\n            for e in other_events_list:\n                assert engine.has_event_handler(handler, e)\n        for e in events_list:\n            assert engine.has_event_handler(handler, e)\n        for e in other_events_list:\n            assert not engine.has_event_handler(handler, e)\n    for e in events_list:\n        assert not engine.has_event_handler(handler, e)\n    for e in other_events_list:\n        assert not engine.has_event_handler(handler, e)\n\n    # Removeable handle is re-enter and re-exitable\n\n    handler = create_autospec(spec=lambda x: None)\n\n    remove = engine.add_event_handler(events_list, handler)\n\n    with remove:\n        with remove:\n            for e in events_list:\n                assert engine.has_event_handler(handler, e)\n        for e in events_list:\n            assert not engine.has_event_handler(handler, e)\n    for e in events_list:\n        assert not engine.has_event_handler(handler, e)\n\n    # Removeable handle is a weakref, does not keep engine or event alive\n    def _add_in_closure():\n        _engine = DummyEngine()\n\n        def _handler(_):\n            pass\n\n        _handle = _engine.add_event_handler(events_list, _handler)\n        assert _handle.engine() is _engine\n        assert _handle.handler() is _handler\n\n        return _handle\n\n    removable_handle = _add_in_closure()\n\n    # gc.collect, resolving reference cycles in engine/state\n    # required to ensure object deletion in python2\n    gc.collect()\n\n    assert removable_handle.engine() is None\n    assert removable_handle.handler() is None\n\n\ndef test_eventslist__append_raises():\n    ev_list = EventsList()\n    with pytest.raises(ValueError, match=r""Argument event should be Events or CallableEventWithFilter""):\n        ev_list._append(""abc"")\n\n\ndef test_has_event_handler():\n    engine = DummyEngine()\n    handlers = [MagicMock(spec_set=True), MagicMock(spec_set=True)]\n    m = MagicMock(spec_set=True)\n    for handler in handlers:\n        engine.add_event_handler(Events.STARTED, handler)\n    engine.add_event_handler(Events.COMPLETED, m)\n\n    for handler in handlers:\n        assert engine.has_event_handler(handler, Events.STARTED)\n        assert engine.has_event_handler(handler)\n        assert not engine.has_event_handler(handler, Events.COMPLETED)\n        assert not engine.has_event_handler(handler, Events.EPOCH_STARTED)\n\n    assert not engine.has_event_handler(m, Events.STARTED)\n    assert engine.has_event_handler(m, Events.COMPLETED)\n    assert engine.has_event_handler(m)\n    assert not engine.has_event_handler(m, Events.EPOCH_STARTED)\n\n\ndef test_remove_event_handler():\n    engine = DummyEngine()\n\n    with pytest.raises(ValueError, match=r""Input event name""):\n        engine.remove_event_handler(lambda x: x, ""an event"")\n\n    def on_started(engine):\n        return 0\n\n    engine.add_event_handler(Events.STARTED, on_started)\n\n    with pytest.raises(ValueError, match=r""Input handler""):\n        engine.remove_event_handler(lambda x: x, Events.STARTED)\n\n    h1 = MagicMock(spec_set=True)\n    h2 = MagicMock(spec_set=True)\n    handlers = [h1, h2]\n    m = MagicMock(spec_set=True)\n    for handler in handlers:\n        engine.add_event_handler(Events.EPOCH_STARTED, handler)\n    engine.add_event_handler(Events.EPOCH_COMPLETED, m)\n\n    assert len(engine._event_handlers[Events.EPOCH_STARTED]) == 2\n    engine.remove_event_handler(h1, Events.EPOCH_STARTED)\n    assert len(engine._event_handlers[Events.EPOCH_STARTED]) == 1\n    assert engine._event_handlers[Events.EPOCH_STARTED][0][0] == h2\n\n    assert len(engine._event_handlers[Events.EPOCH_COMPLETED]) == 1\n    engine.remove_event_handler(m, Events.EPOCH_COMPLETED)\n    assert len(engine._event_handlers[Events.EPOCH_COMPLETED]) == 0\n\n\ndef test_args_and_kwargs_are_passed_to_event():\n    engine = DummyEngine()\n    kwargs = {""a"": ""a"", ""b"": ""b""}\n    args = (1, 2, 3)\n    handlers = []\n    for event in [Events.STARTED, Events.COMPLETED]:\n        handler = create_autospec(spec=lambda e, x1, x2, x3, a, b: None)\n        engine.add_event_handler(event, handler, *args, **kwargs)\n        handlers.append(handler)\n\n    engine.run(1)\n    called_handlers = [handle for handle in handlers if handle.called]\n    assert len(called_handlers) == 2\n\n    for handler in called_handlers:\n        handler_args, handler_kwargs = handler.call_args\n        assert handler_args[0] == engine\n        assert handler_args[1::] == args\n        assert handler_kwargs == kwargs\n\n\ndef test_on_decorator_raises_with_invalid_event():\n    engine = DummyEngine()\n    with pytest.raises(ValueError):\n\n        @engine.on(""incorrect"")\n        def f(engine):\n            pass\n\n\ndef test_on_decorator():\n    engine = DummyEngine()\n\n    class Counter(object):\n        def __init__(self, count=0):\n            self.count = count\n\n    started_counter = Counter()\n\n    @engine.on(Events.STARTED, started_counter)\n    def handle_iteration_started(engine, started_counter):\n        started_counter.count += 1\n\n    completed_counter = Counter()\n\n    @engine.on(Events.COMPLETED, completed_counter)\n    def handle_iteration_completed(engine, completed_counter):\n        completed_counter.count += 1\n\n    engine.run(15)\n\n    assert started_counter.count == 15\n    assert completed_counter.count == 15\n\n\ndef test_returns_state():\n    engine = Engine(MagicMock(return_value=1))\n    state = engine.run([0,])\n\n    assert isinstance(state, State)\n\n\ndef test_state_attributes():\n    dataloader = [1, 2, 3]\n    engine = Engine(MagicMock(return_value=1))\n    state = engine.run(dataloader, max_epochs=3)\n\n    assert state.iteration == 9\n    assert state.output == 1\n    assert state.batch == 3\n    assert state.dataloader == dataloader\n    assert state.epoch == 3\n    assert state.max_epochs == 3\n    assert state.metrics == {}\n\n\ndef test_default_exception_handler():\n    update_function = MagicMock(side_effect=ValueError())\n    engine = Engine(update_function)\n\n    with raises(ValueError):\n        engine.run([1])\n\n\ndef test_custom_exception_handler():\n    value_error = ValueError()\n    update_function = MagicMock(side_effect=value_error)\n\n    engine = Engine(update_function)\n\n    class ExceptionCounter(object):\n        def __init__(self):\n            self.exceptions = []\n\n        def __call__(self, engine, e):\n            self.exceptions.append(e)\n\n    counter = ExceptionCounter()\n    engine.add_event_handler(Events.EXCEPTION_RAISED, counter)\n    engine.run([1])\n\n    # only one call from _run_once_over_data, since the exception is swallowed\n    assert len(counter.exceptions) == 1 and counter.exceptions[0] == value_error\n\n\ndef test_event_handlers_with_decoration():\n\n    engine = Engine(lambda e, b: b)\n\n    def decorated(fun):\n        @functools.wraps(fun)\n        def wrapper(*args, **kwargs):\n            return fun(*args, **kwargs)\n\n        return wrapper\n\n    values = []\n\n    def foo():\n        values.append(""foo"")\n\n    @decorated\n    def decorated_foo():\n        values.append(""decorated_foo"")\n\n    engine.add_event_handler(Events.EPOCH_STARTED, foo)\n    engine.add_event_handler(Events.EPOCH_STARTED(every=2), foo)\n    engine.add_event_handler(Events.EPOCH_STARTED, decorated_foo)\n    engine.add_event_handler(Events.EPOCH_STARTED(every=2), decorated_foo)\n\n    def foo_args(e):\n        values.append(""foo_args"")\n        values.append(e.state.iteration)\n\n    @decorated\n    def decorated_foo_args(e):\n        values.append(""decorated_foo_args"")\n        values.append(e.state.iteration)\n\n    engine.add_event_handler(Events.EPOCH_STARTED, foo_args)\n    engine.add_event_handler(Events.EPOCH_STARTED(every=2), foo_args)\n    engine.add_event_handler(Events.EPOCH_STARTED, decorated_foo_args)\n    engine.add_event_handler(Events.EPOCH_STARTED(every=2), decorated_foo_args)\n\n    class Foo:\n        def __init__(self):\n            self.values = []\n\n        def foo(self):\n            self.values.append(""foo"")\n\n        @decorated\n        def decorated_foo(self):\n            self.values.append(""decorated_foo"")\n\n        def foo_args(self, e):\n            self.values.append(""foo_args"")\n            self.values.append(e.state.iteration)\n\n        @decorated\n        def decorated_foo_args(self, e):\n            self.values.append(""decorated_foo_args"")\n            self.values.append(e.state.iteration)\n\n    foo = Foo()\n\n    engine.add_event_handler(Events.EPOCH_STARTED, foo.foo)\n    engine.add_event_handler(Events.EPOCH_STARTED(every=2), foo.foo)\n    engine.add_event_handler(Events.EPOCH_STARTED, foo.decorated_foo)\n    engine.add_event_handler(Events.EPOCH_STARTED(every=2), foo.decorated_foo)\n    engine.add_event_handler(Events.EPOCH_STARTED, foo.foo_args)\n    engine.add_event_handler(Events.EPOCH_STARTED(every=2), foo.foo_args)\n    engine.add_event_handler(Events.EPOCH_STARTED, foo.decorated_foo_args)\n    engine.add_event_handler(Events.EPOCH_STARTED(every=2), foo.decorated_foo_args)\n\n    engine.run([0], max_epochs=2)\n\n    assert values == foo.values\n'"
tests/ignite/handlers/__init__.py,0,b'# Needed to collect coverage data\n'
tests/ignite/handlers/test_checkpoint.py,26,"b'import os\nimport warnings\nfrom unittest.mock import MagicMock\n\nimport pytest\nimport torch\nimport torch.nn as nn\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events, State\nfrom ignite.handlers import Checkpoint, DiskSaver, ModelCheckpoint\nfrom ignite.handlers.checkpoint import BaseSaveHandler\n\n_PREFIX = ""PREFIX""\n\n\nclass DummyModel(nn.Module):\n    def __init__(self):\n        super(DummyModel, self).__init__()\n        self.net = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.net(x)\n\n\nclass DummyPretrainedModel(nn.Module):\n    def __init__(self):\n        super(DummyPretrainedModel, self).__init__()\n        self.features = nn.Linear(4, 2, bias=False)\n        self.fc = nn.Linear(2, 1)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.fc(x)\n        return x\n\n\ndef test_checkpoint_wrong_input():\n\n    with pytest.raises(TypeError, match=r""Argument `to_save` should be a dictionary""):\n        Checkpoint(12, lambda x: x, ""prefix"")\n\n    with pytest.raises(TypeError, match=r""Argument `to_save` should be a dictionary""):\n        Checkpoint([12], lambda x: x, ""prefix"")\n\n    with pytest.raises(ValueError, match=r""No objects to checkpoint.""):\n        Checkpoint({}, lambda x: x, ""prefix"")\n\n    model = DummyModel()\n    to_save = {""model"": model}\n\n    with pytest.raises(TypeError, match=r""Argument `save_handler` should be callable""):\n        Checkpoint(to_save, 12, ""prefix"")\n\n    with pytest.raises(\n        ValueError, match=r""If `score_name` is provided, then `score_function` should be also provided.""\n    ):\n        Checkpoint(to_save, lambda x: x, score_name=""acc"")\n\n    with pytest.raises(TypeError, match=r""global_step_transform should be a function.""):\n        Checkpoint(to_save, lambda x: x, score_function=lambda e: 123, score_name=""acc"", global_step_transform=123)\n\n    with pytest.warns(UserWarning, match=r""Argument archived is deprecated""):\n        Checkpoint(to_save, lambda x: x, score_function=lambda e: 123, score_name=""acc"", archived=True)\n\n\ndef test_checkpoint_score_function_wrong_output():\n    model = DummyModel()\n    to_save = {""model"": model}\n\n    checkpointer = Checkpoint(to_save, lambda x: x, score_function=lambda e: {""1"": 1}, score_name=""acc"")\n    trainer = Engine(lambda e, b: None)\n    trainer.state = State(epoch=0, iteration=0)\n    with pytest.raises(ValueError, match=r""Output of score_function should be a number""):\n        checkpointer(trainer)\n\n\ndef test_checkpoint_default():\n    def _test(to_save, obj, name):\n        save_handler = MagicMock(spec=BaseSaveHandler)\n\n        checkpointer = Checkpoint(to_save, save_handler=save_handler)\n        assert checkpointer.last_checkpoint is None\n\n        trainer = Engine(lambda e, b: None)\n        trainer.state = State(epoch=0, iteration=0)\n\n        checkpointer(trainer)\n        assert save_handler.call_count == 1\n\n        metadata = {""basename"": name, ""score_name"": None, ""priority"": 0}\n        save_handler.assert_called_with(obj, ""{}_0.pt"".format(name), metadata)\n\n        trainer.state.epoch = 12\n        trainer.state.iteration = 1234\n        checkpointer(trainer)\n        assert save_handler.call_count == 2\n        metadata[""priority""] = 1234\n        save_handler.assert_called_with(obj, ""{}_1234.pt"".format(name), metadata)\n        assert save_handler.remove.call_count == 1\n        save_handler.remove.assert_called_with(""{}_0.pt"".format(name))\n        assert checkpointer.last_checkpoint == ""{}_1234.pt"".format(name)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    _test(to_save, model.state_dict(), ""model"")\n\n    model = DummyModel()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n    to_save = {""model"": model, ""optimizer"": optimizer}\n    _test(to_save, {""model"": model.state_dict(), ""optimizer"": optimizer.state_dict()}, ""checkpoint"")\n\n\ndef test_checkpoint_with_dp():\n\n    model = DummyModel()\n    dp_model = nn.DataParallel(model)\n    to_save = {""model"": dp_model}\n\n    save_handler = MagicMock(spec=BaseSaveHandler)\n    checkpointer = Checkpoint(to_save, save_handler=save_handler)\n\n    trainer = Engine(lambda e, b: None)\n    trainer.state = State(epoch=0, iteration=0)\n\n    checkpointer(trainer)\n    assert save_handler.call_count == 1\n    metadata = {""basename"": ""model"", ""score_name"": None, ""priority"": 0}\n    save_handler.assert_called_with(model.state_dict(), ""model_0.pt"", metadata)\n\n\ndef test_checkpoint_with_global_step_transform():\n    def _test(filename_prefix, to_save, obj, name):\n        save_handler = MagicMock(spec=BaseSaveHandler)\n\n        checkpointer = Checkpoint(\n            to_save,\n            save_handler=save_handler,\n            filename_prefix=filename_prefix,\n            global_step_transform=lambda e, _: e.state.epoch,\n        )\n\n        trainer = Engine(lambda e, b: None)\n        trainer.state = State(epoch=1, iteration=1)\n\n        checkpointer(trainer)\n        assert save_handler.call_count == 1\n\n        if len(filename_prefix) > 0:\n            filename_prefix += ""_""\n\n        metadata = {""basename"": ""{}{}"".format(filename_prefix, name), ""score_name"": None, ""priority"": 1}\n        save_handler.assert_called_with(obj, ""{}{}_1.pt"".format(filename_prefix, name), metadata)\n\n        trainer.state.epoch = 12\n        trainer.state.iteration = 1234\n        checkpointer(trainer)\n        assert save_handler.call_count == 2\n        metadata[""priority""] = 1234\n        save_handler.assert_called_with(obj, ""{}{}_12.pt"".format(filename_prefix, name), metadata)\n        assert save_handler.remove.call_count == 1\n        save_handler.remove.assert_called_with(""{}{}_1.pt"".format(filename_prefix, name))\n        assert checkpointer.last_checkpoint == ""{}{}_12.pt"".format(filename_prefix, name)\n\n    for prefix in ["""", ""dummytask""]:\n        model = DummyModel()\n        to_save = {""model"": model}\n        _test(prefix, to_save, model.state_dict(), ""model"")\n\n        model = DummyModel()\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n        to_save = {""model"": model, ""optimizer"": optimizer}\n        _test(prefix, to_save, {""model"": model.state_dict(), ""optimizer"": optimizer.state_dict()}, ""checkpoint"")\n\n\ndef test_checkpoint_with_score_function():\n    def _test(to_save, obj, name):\n        save_handler = MagicMock(spec=BaseSaveHandler)\n\n        checkpointer = Checkpoint(to_save, save_handler=save_handler, score_function=lambda e: e.state.score)\n\n        trainer = Engine(lambda e, b: None)\n        trainer.state = State(epoch=1, iteration=1, score=0.77)\n\n        checkpointer(trainer)\n        assert save_handler.call_count == 1\n\n        metadata = {""basename"": name, ""score_name"": None, ""priority"": 0.77}\n        save_handler.assert_called_with(obj, ""{}_0.7700.pt"".format(name), metadata)\n\n        trainer.state.epoch = 12\n        trainer.state.iteration = 1234\n        trainer.state.score = 0.78\n\n        checkpointer(trainer)\n        assert save_handler.call_count == 2\n        metadata[""priority""] = 0.78\n        save_handler.assert_called_with(obj, ""{}_0.7800.pt"".format(name), metadata)\n        assert save_handler.remove.call_count == 1\n        save_handler.remove.assert_called_with(""{}_0.7700.pt"".format(name))\n        assert checkpointer.last_checkpoint == ""{}_0.7800.pt"".format(name)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    _test(to_save, model.state_dict(), ""model"")\n\n    model = DummyModel()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n    to_save = {""model"": model, ""optimizer"": optimizer}\n    _test(to_save, {""model"": model.state_dict(), ""optimizer"": optimizer.state_dict()}, ""checkpoint"")\n\n\ndef test_checkpoint_with_score_name_and_function():\n    def _test(to_save, obj, name):\n        save_handler = MagicMock(spec=BaseSaveHandler)\n\n        checkpointer = Checkpoint(\n            to_save, save_handler=save_handler, score_name=""loss"", score_function=lambda e: e.state.score\n        )\n\n        trainer = Engine(lambda e, b: None)\n        trainer.state = State(epoch=1, iteration=1, score=-0.77)\n\n        checkpointer(trainer)\n        assert save_handler.call_count == 1\n\n        metadata = {""basename"": name, ""score_name"": ""loss"", ""priority"": -0.77}\n        save_handler.assert_called_with(obj, ""{}_loss=-0.7700.pt"".format(name), metadata)\n\n        trainer.state.epoch = 12\n        trainer.state.iteration = 1234\n        trainer.state.score = -0.76\n\n        checkpointer(trainer)\n        assert save_handler.call_count == 2\n        metadata[""priority""] = -0.76\n        save_handler.assert_called_with(obj, ""{}_loss=-0.7600.pt"".format(name), metadata)\n        assert save_handler.remove.call_count == 1\n        save_handler.remove.assert_called_with(""{}_loss=-0.7700.pt"".format(name))\n        assert checkpointer.last_checkpoint == ""{}_loss=-0.7600.pt"".format(name)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    _test(to_save, model.state_dict(), ""model"")\n\n    model = DummyModel()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n    to_save = {""model"": model, ""optimizer"": optimizer}\n    _test(to_save, {""model"": model.state_dict(), ""optimizer"": optimizer.state_dict()}, ""checkpoint"")\n\n\ndef test_checkpoint_with_int_score():\n    def _test(to_save, obj, name, score_name=None):\n        save_handler = MagicMock(spec=BaseSaveHandler)\n\n        checkpointer = Checkpoint(\n            to_save, save_handler=save_handler, score_name=score_name, score_function=lambda e: e.state.epoch\n        )\n\n        if score_name is None:\n            score_name = """"\n        else:\n            score_name += ""=""\n\n        trainer = Engine(lambda e, b: None)\n        trainer.state = State(epoch=1, iteration=1)\n\n        checkpointer(trainer)\n        assert save_handler.call_count == 1\n\n        metadata = {""basename"": name, ""score_name"": score_name[:-1] if len(score_name) > 0 else None, ""priority"": 1}\n        save_handler.assert_called_with(obj, ""{}_{}1.pt"".format(name, score_name), metadata)\n\n        trainer.state.epoch = 12\n        trainer.state.iteration = 1234\n\n        checkpointer(trainer)\n        assert save_handler.call_count == 2\n        metadata[""priority""] = 12\n        save_handler.assert_called_with(obj, ""{}_{}12.pt"".format(name, score_name), metadata)\n        assert save_handler.remove.call_count == 1\n        save_handler.remove.assert_called_with(""{}_{}1.pt"".format(name, score_name))\n        assert checkpointer.last_checkpoint == ""{}_{}12.pt"".format(name, score_name)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    _test(to_save, model.state_dict(), ""model"")\n    _test(to_save, model.state_dict(), ""model"", ""epoch"")\n\n    model = DummyModel()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n    to_save = {""model"": model, ""optimizer"": optimizer}\n    _test(to_save, {""model"": model.state_dict(), ""optimizer"": optimizer.state_dict()}, ""checkpoint"")\n    _test(to_save, {""model"": model.state_dict(), ""optimizer"": optimizer.state_dict()}, ""checkpoint"", ""epoch"")\n\n\ndef test_checkpoint_with_score_function_and_trainer_epoch():\n    def _test(to_save, obj, name):\n        save_handler = MagicMock(spec=BaseSaveHandler)\n\n        trainer = Engine(lambda e, b: None)\n        evaluator = Engine(lambda e, b: None)\n        trainer.state = State(epoch=11, iteration=1)\n\n        checkpointer = Checkpoint(\n            to_save,\n            save_handler=save_handler,\n            global_step_transform=lambda _1, _2: trainer.state.epoch,\n            score_function=lambda e: e.state.metrics[""val_acc""],\n        )\n\n        evaluator.state = State(epoch=1, iteration=1000, metrics={""val_acc"": 0.77})\n        checkpointer(evaluator)\n        assert save_handler.call_count == 1\n\n        metadata = {""basename"": name, ""score_name"": None, ""priority"": 0.77}\n        save_handler.assert_called_with(obj, ""{}_11_0.7700.pt"".format(name), metadata)\n\n        trainer.state.epoch = 12\n        evaluator.state.metrics[""val_acc""] = 0.78\n\n        checkpointer(evaluator)\n        assert save_handler.call_count == 2\n        metadata[""priority""] = 0.78\n        save_handler.assert_called_with(obj, ""{}_12_0.7800.pt"".format(name), metadata)\n        assert save_handler.remove.call_count == 1\n        save_handler.remove.assert_called_with(""{}_11_0.7700.pt"".format(name))\n        assert checkpointer.last_checkpoint == ""{}_12_0.7800.pt"".format(name)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    _test(to_save, model.state_dict(), ""model"")\n\n\ndef test_checkpoint_with_score_name_and_function_and_trainer_epoch():\n    def _test(to_save, obj, name):\n        save_handler = MagicMock(spec=BaseSaveHandler)\n\n        trainer = Engine(lambda e, b: None)\n        evaluator = Engine(lambda e, b: None)\n        trainer.state = State(epoch=11, iteration=1)\n\n        checkpointer = Checkpoint(\n            to_save,\n            save_handler=save_handler,\n            global_step_transform=lambda _1, _2: trainer.state.epoch,\n            score_name=""val_acc"",\n            score_function=lambda e: e.state.metrics[""val_acc""],\n        )\n\n        evaluator.state = State(epoch=1, iteration=1000, metrics={""val_acc"": 0.77})\n\n        checkpointer(evaluator)\n        assert save_handler.call_count == 1\n\n        metadata = {""basename"": name, ""score_name"": ""val_acc"", ""priority"": 0.77}\n        save_handler.assert_called_with(obj, ""{}_11_val_acc=0.7700.pt"".format(name), metadata)\n\n        trainer.state.epoch = 12\n        evaluator.state.metrics[""val_acc""] = 0.78\n\n        checkpointer(evaluator)\n        assert save_handler.call_count == 2\n        metadata[""priority""] = 0.78\n        save_handler.assert_called_with(obj, ""{}_12_val_acc=0.7800.pt"".format(name), metadata)\n        assert save_handler.remove.call_count == 1\n        save_handler.remove.assert_called_with(""{}_11_val_acc=0.7700.pt"".format(name))\n        assert checkpointer.last_checkpoint == ""{}_12_val_acc=0.7800.pt"".format(name)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    _test(to_save, model.state_dict(), ""model"")\n\n\ndef test_checkpoint_last_checkpoint():\n    save_handler = MagicMock(spec=BaseSaveHandler)\n    to_save = {""model"": DummyModel()}\n\n    checkpointer = Checkpoint(to_save, save_handler=save_handler, n_saved=None)\n\n    trainer = Engine(lambda e, b: None)\n\n    for i in range(10):\n        trainer.state = State(epoch=1, iteration=i)\n        checkpointer(trainer)\n\n    assert save_handler.call_count == 10\n    assert checkpointer.last_checkpoint == ""{}_9.pt"".format(""model"")\n\n\ndef test_checkpoint_last_checkpoint_on_score():\n    save_handler = MagicMock(spec=BaseSaveHandler)\n    to_save = {""model"": DummyModel()}\n\n    checkpointer = Checkpoint(\n        to_save,\n        save_handler=save_handler,\n        n_saved=None,\n        score_name=""val_acc"",\n        score_function=lambda e: e.state.metrics[""val_acc""],\n    )\n\n    trainer = Engine(lambda e, b: None)\n\n    val_acc = 0.0\n    for i in range(10):\n        val_acc = i * 0.1\n        trainer.state = State(epoch=1, iteration=i, metrics={""val_acc"": val_acc})\n        checkpointer(trainer)\n\n    assert save_handler.call_count == 10\n    assert checkpointer.last_checkpoint == ""{}_val_acc=0.9000.pt"".format(""model"")\n\n\ndef test_checkpoint_save_handler_callable():\n    def save_handler(c, f):\n        assert f == ""model_12.pt""\n\n    to_save = {""model"": DummyModel()}\n\n    checkpointer = Checkpoint(to_save, save_handler=save_handler,)\n\n    trainer = Engine(lambda e, b: None)\n\n    trainer.state = State(epoch=1, iteration=12)\n    checkpointer(trainer)\n\n\ndef test_model_checkpoint_args_validation(dirname):\n    existing = os.path.join(dirname, ""existing_dir"")\n    nonempty = os.path.join(dirname, ""nonempty"")\n\n    os.makedirs(existing)\n    os.makedirs(nonempty)\n\n    with open(os.path.join(nonempty, ""{}_name_0.pt"".format(_PREFIX)), ""w""):\n        pass\n\n    with pytest.raises(ValueError, match=r""with extension \'.pt\' are already present ""):\n        ModelCheckpoint(nonempty, _PREFIX)\n\n    with pytest.raises(ValueError, match=r""Argument save_interval is deprecated and should be None""):\n        ModelCheckpoint(existing, _PREFIX, save_interval=42)\n\n    with pytest.raises(ValueError, match=r""Directory path \'\\S+\' is not found""):\n        ModelCheckpoint(os.path.join(dirname, ""non_existing_dir""), _PREFIX, create_dir=False)\n\n    with pytest.raises(ValueError, match=r""Argument save_as_state_dict is deprecated and should be True""):\n        ModelCheckpoint(existing, _PREFIX, create_dir=False, save_as_state_dict=False)\n\n    with pytest.raises(ValueError, match=r""If `score_name` is provided, then `score_function` ""):\n        ModelCheckpoint(existing, _PREFIX, create_dir=False, score_name=""test"")\n\n    with pytest.raises(TypeError, match=r""global_step_transform should be a function""):\n        ModelCheckpoint(existing, _PREFIX, create_dir=False, global_step_transform=1234)\n\n    with pytest.warns(UserWarning, match=r""Argument archived is deprecated""):\n        ModelCheckpoint(existing, _PREFIX, create_dir=False, archived=True)\n\n    h = ModelCheckpoint(dirname, _PREFIX, create_dir=False)\n    assert h.last_checkpoint is None\n    with pytest.raises(RuntimeError, match=r""No objects to checkpoint found.""):\n        h(None, [])\n\n\ndef test_model_checkpoint_simple_recovery(dirname):\n    h = ModelCheckpoint(dirname, _PREFIX, create_dir=False)\n    engine = Engine(lambda e, b: None)\n    engine.state = State(epoch=0, iteration=1)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    h(engine, to_save)\n\n    fname = h.last_checkpoint\n    assert isinstance(fname, str)\n    assert os.path.join(dirname, _PREFIX) in fname\n    assert os.path.exists(fname)\n    loaded_objects = torch.load(fname)\n    assert loaded_objects == model.state_dict()\n\n\ndef test_model_checkpoint_simple_recovery_from_existing_non_empty(dirname):\n    def _test(ext, require_empty):\n        previous_fname = os.path.join(dirname, ""{}_{}_{}{}"".format(_PREFIX, ""obj"", 1, ext))\n        with open(previous_fname, ""w"") as f:\n            f.write(""test"")\n\n        h = ModelCheckpoint(dirname, _PREFIX, create_dir=True, require_empty=require_empty)\n        engine = Engine(lambda e, b: None)\n        engine.state = State(epoch=0, iteration=1)\n\n        model = DummyModel()\n        to_save = {""model"": model}\n        h(engine, to_save)\n\n        fname = h.last_checkpoint\n        ext = "".pt""\n        assert isinstance(fname, str)\n        assert os.path.join(dirname, ""{}_{}_{}{}"".format(_PREFIX, ""model"", 1, ext)) == fname\n        assert os.path.exists(fname)\n        assert os.path.exists(previous_fname)\n        loaded_objects = torch.load(fname)\n        assert loaded_objects == model.state_dict()\n        os.remove(fname)\n\n    _test("".txt"", require_empty=True)\n    _test("".pt"", require_empty=False)\n\n\ndef test_disk_saver_atomic(dirname):\n\n    model = DummyModel()\n    to_save_serializable = {""model"": model}\n    to_save_non_serializable = {""model"": lambda x: x}\n\n    def _test_existance(atomic, _to_save, expected):\n\n        saver = DiskSaver(dirname, atomic=atomic, create_dir=False, require_empty=False)\n        fname = ""test.pt""\n        try:\n            with warnings.catch_warnings():\n                # Ignore torch/serialization.py:292: UserWarning: Couldn\'t retrieve source code for container of type\n                # DummyModel. It won\'t be checked for correctness upon loading.\n                warnings.simplefilter(""ignore"", category=UserWarning)\n                saver(_to_save, fname)\n        except Exception:\n            pass\n        fp = os.path.join(saver.dirname, fname)\n        assert os.path.exists(fp) == expected\n        if expected:\n            saver.remove(fname)\n\n    _test_existance(atomic=False, _to_save=to_save_serializable, expected=True)\n    _test_existance(atomic=False, _to_save=to_save_non_serializable, expected=True)\n\n    _test_existance(atomic=True, _to_save=to_save_serializable, expected=True)\n    _test_existance(atomic=True, _to_save=to_save_non_serializable, expected=False)\n\n\ndef test_last_k(dirname):\n\n    h = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=2)\n    engine = Engine(lambda e, b: None)\n    engine.state = State(epoch=0, iteration=0)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    h(engine, to_save)\n\n    for i in range(1, 9):\n        engine.state.iteration = i\n        h(engine, to_save)\n\n    expected = [""{}_{}_{}.pt"".format(_PREFIX, ""model"", i) for i in [7, 8]]\n\n    assert sorted(os.listdir(dirname)) == expected, ""{} vs {}"".format(sorted(os.listdir(dirname)), expected)\n\n\ndef test_disabled_n_saved(dirname):\n\n    h = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=None)\n    engine = Engine(lambda e, b: None)\n    engine.state = State(epoch=0, iteration=0)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n\n    num_iters = 100\n    for i in range(num_iters):\n        engine.state.iteration = i\n        h(engine, to_save)\n\n    saved_files = sorted(os.listdir(dirname))\n    assert len(saved_files) == num_iters, ""{}"".format(saved_files)\n\n    expected = sorted([""{}_{}_{}.pt"".format(_PREFIX, ""model"", i) for i in range(num_iters)])\n    assert saved_files == expected, ""{} vs {}"".format(saved_files, expected)\n\n\ndef test_best_k(dirname):\n    scores = iter([1.2, -2.0, 3.1, -4.0])\n\n    def score_function(_):\n        return next(scores)\n\n    h = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=2, score_function=score_function)\n\n    engine = Engine(lambda e, b: None)\n    engine.state = State(epoch=0, iteration=0)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    for _ in range(4):\n        h(engine, to_save)\n\n    expected = [""{}_{}_{:.4f}.pt"".format(_PREFIX, ""model"", i) for i in [1.2, 3.1]]\n\n    assert sorted(os.listdir(dirname)) == expected\n\n\ndef test_best_k_with_suffix(dirname):\n    scores = [0.3456789, 0.1234, 0.4567, 0.134567]\n    scores_iter = iter(scores)\n\n    def score_function(engine):\n        return next(scores_iter)\n\n    h = ModelCheckpoint(\n        dirname, _PREFIX, create_dir=False, n_saved=2, score_function=score_function, score_name=""val_loss""\n    )\n\n    engine = Engine(lambda e, b: None)\n    engine.state = State(epoch=0, iteration=0)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    for _ in range(4):\n        engine.state.epoch += 1\n        h(engine, to_save)\n\n    expected = [""{}_{}_val_loss={:.4}.pt"".format(_PREFIX, ""model"", scores[e - 1]) for e in [1, 3]]\n\n    assert sorted(os.listdir(dirname)) == expected\n\n\ndef test_removes_each_score_at_most_once(dirname):\n    scores = [0, 1, 1, 2, 3]\n    scores_iter = iter(scores)\n\n    def score_function(_):\n        return next(scores_iter)\n\n    h = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=2, score_function=score_function)\n\n    engine = Engine(lambda e, b: None)\n    engine.state = State(epoch=0, iteration=0)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    for _ in range(len(scores)):\n        h(engine, to_save)\n\n    # If a score was removed multiple times, the code above would have raise a\n    # FileNotFoundError. So this just tests the absence of such a failure\n    # without futher assertions.\n\n\ndef test_with_engine(dirname):\n    def update_fn(_1, _2):\n        pass\n\n    name = ""model""\n    engine = Engine(update_fn)\n    handler = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=2)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    engine.add_event_handler(Events.EPOCH_COMPLETED, handler, to_save)\n    engine.run([0], max_epochs=4)\n\n    expected = [""{}_{}_{}.pt"".format(_PREFIX, name, i) for i in [3, 4]]\n\n    assert sorted(os.listdir(dirname)) == expected\n\n\ndef test_with_state_dict(dirname):\n    def update_fn(_1, _2):\n        pass\n\n    engine = Engine(update_fn)\n    handler = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=1)\n\n    model = DummyModel()\n    to_save = {""model"": model}\n    engine.add_event_handler(Events.EPOCH_COMPLETED, handler, to_save)\n    engine.run([0], max_epochs=4)\n\n    saved_model = os.path.join(dirname, os.listdir(dirname)[0])\n    load_model = torch.load(saved_model)\n\n    assert not isinstance(load_model, DummyModel)\n    assert isinstance(load_model, dict)\n\n    model_state_dict = model.state_dict()\n    loaded_model_state_dict = load_model\n    for key in model_state_dict.keys():\n        assert key in loaded_model_state_dict\n\n        model_value = model_state_dict[key]\n        loaded_model_value = loaded_model_state_dict[key]\n\n        assert model_value.numpy() == loaded_model_value.numpy()\n\n\ndef test_valid_state_dict_save(dirname):\n    model = DummyModel()\n    h = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=1)\n\n    engine = Engine(lambda e, b: None)\n    engine.state = State(epoch=0, iteration=0)\n\n    to_save = {""name"": 42}\n    with pytest.raises(TypeError, match=r""should have `state_dict` method""):\n        h(engine, to_save)\n    to_save = {""name"": model}\n    try:\n        h(engine, to_save)\n    except ValueError:\n        pytest.fail(""Unexpected ValueError"")\n\n\ndef _test_save_model_optimizer_lr_scheduler_with_state_dict(device, dirname, on_zero_rank=False):\n\n    torch.manual_seed(23)\n\n    model = DummyModel().to(device)\n\n    optim = torch.optim.SGD(model.parameters(), lr=0.1)\n    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.5)\n\n    def update_fn(engine, batch):\n        x = torch.rand((4, 1)).to(device)\n        optim.zero_grad()\n        y = model(x)\n        loss = y.pow(2.0).sum()\n        loss.backward()\n        if idist.has_xla_support:\n            import torch_xla.core.xla_model as xm\n\n            xm.optimizer_step(optim, barrier=True)\n        else:\n            optim.step()\n        lr_scheduler.step()\n\n    engine = Engine(update_fn)\n\n    if (not on_zero_rank) or (on_zero_rank and idist.get_rank() == 0):\n        handler = ModelCheckpoint(dirname, _PREFIX, create_dir=True, n_saved=1)\n\n        engine.add_event_handler(\n            Events.EPOCH_COMPLETED, handler, {""model"": model, ""optimizer"": optim, ""lr_scheduler"": lr_scheduler}\n        )\n\n    engine.run([0], max_epochs=4)\n\n    idist.barrier()\n\n    saved_objects = sorted(os.listdir(dirname))\n    # saved object is [\'PREFIX_checkpoint_3.pt\', ]\n    saved_checkpoint = os.path.join(dirname, saved_objects[0])\n\n    if idist.has_xla_support:\n        device = ""cpu""\n\n    loaded_obj = torch.load(saved_checkpoint, map_location=device)\n    for f in [""model"", ""optimizer"", ""lr_scheduler""]:\n        assert f in loaded_obj\n    loaded_model_state_dict = loaded_obj[""model""]\n    loaded_optimizer_state_dict = loaded_obj[""optimizer""]\n    loaded_lr_scheduler_state_dict = loaded_obj[""lr_scheduler""]\n\n    assert isinstance(loaded_model_state_dict, dict)\n    assert isinstance(loaded_optimizer_state_dict, dict)\n    assert isinstance(loaded_lr_scheduler_state_dict, dict)\n\n    # Specifically move device to CPU first\n    model_state_dict = model.cpu().state_dict()\n    for key in model_state_dict.keys():\n        assert key in loaded_model_state_dict\n        model_value = model_state_dict[key]\n        loaded_model_value = loaded_model_state_dict[key]\n        assert model_value.cpu().numpy() == loaded_model_value.cpu().numpy()\n\n    optim_state_dict = optim.state_dict()\n    for key in optim_state_dict.keys():\n        assert key in loaded_optimizer_state_dict\n        optim_value = optim_state_dict[key]\n        loaded_optim_value = loaded_optimizer_state_dict[key]\n        if idist.get_rank() == 0:\n            assert optim_value == loaded_optim_value\n\n    lr_scheduler_state_dict = lr_scheduler.state_dict()\n    for key in lr_scheduler_state_dict.keys():\n        assert key in loaded_lr_scheduler_state_dict\n        lr_scheduler_value = lr_scheduler_state_dict[key]\n        loaded_lr_scheduler_value = loaded_lr_scheduler_state_dict[key]\n        assert lr_scheduler_value == loaded_lr_scheduler_value\n\n\ndef test_save_model_optimizer_lr_scheduler_with_state_dict(dirname):\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(""cpu"", dirname)\n\n\ndef test_checkpoint_load_objects():\n\n    with pytest.raises(TypeError, match=r""Argument checkpoint should be a dictionary""):\n        Checkpoint.load_objects({}, [])\n\n    with pytest.raises(TypeError, match=r""should have `load_state_dict` method""):\n        Checkpoint.load_objects({""a"": None}, {""a"": None})\n\n    model = DummyModel()\n    to_load = {""model"": model, ""another_model"": model}\n\n    with pytest.raises(ValueError, match=r""from `to_load` is not found in the checkpoint""):\n        Checkpoint.load_objects(to_load, {})\n\n    model = DummyModel()\n    to_load = {""model"": model}\n    model2 = DummyModel()\n\n    chkpt = {""model"": model2.state_dict()}\n    Checkpoint.load_objects(to_load, chkpt)\n    assert model.state_dict() == model2.state_dict()\n\n\ndef test_checkpoint_load_objects_from_saved_file(dirname):\n    def _get_single_obj_to_save():\n        model = DummyModel()\n        to_save = {""model"": model}\n        return to_save\n\n    def _get_multiple_objs_to_save():\n        model = DummyModel()\n        optim = torch.optim.SGD(model.parameters(), lr=0.001)\n        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.5)\n        to_save = {""model"": model, ""optimizer"": optim, ""lr_scheduler"": lr_scheduler}\n        return to_save\n\n    trainer = Engine(lambda e, b: None)\n    trainer.state = State(epoch=0, iteration=0)\n\n    # case: multiple objects\n    handler = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=1)\n    to_save = _get_multiple_objs_to_save()\n    handler(trainer, to_save)\n    fname = handler.last_checkpoint\n    assert isinstance(fname, str)\n    assert os.path.join(dirname, _PREFIX) in fname\n    assert os.path.exists(fname)\n    loaded_objects = torch.load(fname)\n    Checkpoint.load_objects(to_save, loaded_objects)\n    os.remove(fname)\n\n    # case: saved multiple objects, loaded single object\n    handler = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=1)\n    to_save = _get_multiple_objs_to_save()\n    handler(trainer, to_save)\n    fname = handler.last_checkpoint\n    assert isinstance(fname, str)\n    assert os.path.join(dirname, _PREFIX) in fname\n    assert os.path.exists(fname)\n    loaded_objects = torch.load(fname)\n    to_load = {""model"": to_save[""model""]}\n    Checkpoint.load_objects(to_load, loaded_objects)\n    os.remove(fname)\n\n    # case: single object\n    handler = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=1)\n    to_save = _get_single_obj_to_save()\n    handler(trainer, to_save)\n    fname = handler.last_checkpoint\n    assert isinstance(fname, str)\n    assert os.path.join(dirname, _PREFIX) in fname\n    assert os.path.exists(fname)\n    loaded_objects = torch.load(fname)\n    Checkpoint.load_objects(to_save, loaded_objects)\n\n\ndef test_load_checkpoint_with_different_num_classes(dirname):\n    model = DummyPretrainedModel()\n    to_save_single_object = {""model"": model}\n\n    trainer = Engine(lambda e, b: None)\n    trainer.state = State(epoch=0, iteration=0)\n\n    handler = ModelCheckpoint(dirname, _PREFIX, create_dir=False, n_saved=1)\n    handler(trainer, to_save_single_object)\n\n    fname = handler.last_checkpoint\n    loaded_checkpoint = torch.load(fname)\n\n    to_load_single_object = {""pretrained_features"": model.features}\n\n    with pytest.raises(RuntimeError):\n        Checkpoint.load_objects(to_load_single_object, loaded_checkpoint)\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(""ignore"", category=UserWarning)\n        Checkpoint.load_objects(to_load_single_object, loaded_checkpoint, strict=False, blah=""blah"")\n\n    loaded_weights = to_load_single_object[""pretrained_features""].state_dict()[""weight""]\n\n    assert torch.all(model.state_dict()[""features.weight""].eq(loaded_weights))\n\n\ndef test_disksaver_wrong_input(dirname):\n\n    with pytest.raises(ValueError, match=r""Directory path \'\\S+\' is not found""):\n        DiskSaver(""/tmp/non-existing-folder"", create_dir=False)\n\n    def _test(ext):\n        previous_fname = os.path.join(dirname, ""{}_{}_{}{}"".format(_PREFIX, ""obj"", 1, ext))\n        with open(previous_fname, ""w"") as f:\n            f.write(""test"")\n\n        with pytest.raises(ValueError, match=r""with extension \'.pt\' are already present""):\n            DiskSaver(dirname, require_empty=True)\n\n    _test("".pt"")\n\n\ndef _test_checkpoint_with_ddp(device):\n    torch.manual_seed(0)\n\n    model = DummyModel().to(device)\n    device_ids = (\n        None if ""cpu"" in device.type else [device,]\n    )\n    ddp_model = nn.parallel.DistributedDataParallel(model, device_ids=device_ids)\n    to_save = {""model"": ddp_model}\n\n    save_handler = MagicMock(spec=BaseSaveHandler)\n    checkpointer = Checkpoint(to_save, save_handler=save_handler)\n\n    trainer = Engine(lambda e, b: None)\n    trainer.state = State(epoch=0, iteration=0)\n\n    checkpointer(trainer)\n    assert save_handler.call_count == 1\n    metadata = {""basename"": ""model"", ""score_name"": None, ""priority"": 0}\n    save_handler.assert_called_with(model.state_dict(), ""model_0.pt"", metadata)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo, get_rank_zero_dirname):\n    device = torch.device(""cpu"")\n    dirname = get_rank_zero_dirname()\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(device, os.path.join(dirname, ""1""))\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(device, os.path.join(dirname, ""2""), on_zero_rank=True)\n    _test_checkpoint_with_ddp(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl, get_rank_zero_dirname):\n    device = idist.device()\n    dirname = get_rank_zero_dirname()\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(device, os.path.join(dirname, ""1""))\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(""cpu"", os.path.join(dirname, ""2""), on_zero_rank=True)\n    _test_checkpoint_with_ddp(device=device)\n\n\ndef _test_tpu_saves_to_cpu(device, dirname):\n    torch.manual_seed(0)\n\n    h = ModelCheckpoint(dirname, _PREFIX)\n    engine = Engine(lambda e, b: None)\n    engine.state = State(epoch=0, iteration=1)\n\n    model = DummyModel().to(device)\n    to_save = {""model"": model}\n\n    h(engine, to_save)\n\n    idist.barrier()\n\n    fname = h.last_checkpoint\n    assert isinstance(fname, str)\n    assert os.path.join(dirname, _PREFIX) in fname\n    assert os.path.exists(fname)\n    loaded_objects = torch.load(fname)\n    assert loaded_objects == model.cpu().state_dict()\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Not on TPU device"")\ndef test_distrib_single_device_xla(dirname):\n    assert ""xla"" in idist.device().type\n    _test_tpu_saves_to_cpu(idist.device(), os.path.join(dirname, ""1""))\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(idist.device(), os.path.join(dirname, ""2""))\n\n\ndef _test_tpu_saves_to_cpu_nprocs(index, dirname):\n    device = idist.device()\n    _test_tpu_saves_to_cpu(device, os.path.join(dirname, ""1""))\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(device, os.path.join(dirname, ""2""))\n\n    import time\n\n    # hack to have all proc properly sync:\n    time.sleep(1)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Not on TPU device"")\ndef test_distrib_single_device_xla_nprocs(xmp_executor, dirname):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_tpu_saves_to_cpu_nprocs, args=(dirname,), nprocs=n)\n'"
tests/ignite/handlers/test_early_stopping.py,12,"b'import os\n\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import EarlyStopping\n\n\ndef do_nothing_update_fn(engine, batch):\n    pass\n\n\ndef test_args_validation():\n\n    trainer = Engine(do_nothing_update_fn)\n\n    with pytest.raises(ValueError, match=r""Argument patience should be positive integer.""):\n        EarlyStopping(patience=-1, score_function=lambda engine: 0, trainer=trainer)\n\n    with pytest.raises(ValueError, match=r""Argument min_delta should not be a negative number.""):\n        EarlyStopping(patience=2, min_delta=-0.1, score_function=lambda engine: 0, trainer=trainer)\n\n    with pytest.raises(TypeError, match=r""Argument score_function should be a function.""):\n        EarlyStopping(patience=2, score_function=12345, trainer=trainer)\n\n    with pytest.raises(TypeError, match=r""Argument trainer should be an instance of Engine.""):\n        EarlyStopping(patience=2, score_function=lambda engine: 0, trainer=None)\n\n\ndef test_simple_early_stopping():\n\n    scores = iter([1.0, 0.8, 0.88])\n\n    def score_function(engine):\n        return next(scores)\n\n    trainer = Engine(do_nothing_update_fn)\n\n    h = EarlyStopping(patience=2, score_function=score_function, trainer=trainer)\n    # Call 3 times and check if stopped\n    assert not trainer.should_terminate\n    h(None)\n    assert not trainer.should_terminate\n    h(None)\n    assert not trainer.should_terminate\n    h(None)\n    assert trainer.should_terminate\n\n\ndef test_early_stopping_on_delta():\n\n    scores = iter([1.0, 2.0, 2.01, 3.0, 3.01, 3.02])\n\n    trainer = Engine(do_nothing_update_fn)\n\n    h = EarlyStopping(patience=2, min_delta=0.1, score_function=lambda _: next(scores), trainer=trainer)\n\n    assert not trainer.should_terminate\n    h(None)  # counter == 0\n    assert not trainer.should_terminate\n    h(None)  # delta == 1.0; counter == 0\n    assert not trainer.should_terminate\n    h(None)  # delta == 0.01; counter == 1\n    assert not trainer.should_terminate\n    h(None)  # delta == 0.99; counter == 0\n    assert not trainer.should_terminate\n    h(None)  # delta == 0.01; counter == 1\n    assert not trainer.should_terminate\n    h(None)  # delta == 0.01; counter == 2\n    assert trainer.should_terminate\n\n\ndef test_early_stopping_on_last_event_delta():\n\n    scores = iter([0.0, 0.3, 0.6])\n\n    trainer = Engine(do_nothing_update_fn)\n\n    h = EarlyStopping(\n        patience=2, min_delta=0.4, cumulative_delta=False, score_function=lambda _: next(scores), trainer=trainer\n    )\n\n    assert not trainer.should_terminate\n    h(None)  # counter == 0\n    assert not trainer.should_terminate\n    h(None)  # delta == 0.3; counter == 1\n    assert not trainer.should_terminate\n    h(None)  # delta == 0.3; counter == 2\n    assert trainer.should_terminate\n\n\ndef test_early_stopping_on_cumulative_delta():\n\n    scores = iter([0.0, 0.3, 0.6])\n\n    trainer = Engine(do_nothing_update_fn)\n\n    h = EarlyStopping(\n        patience=2, min_delta=0.4, cumulative_delta=True, score_function=lambda _: next(scores), trainer=trainer\n    )\n\n    assert not trainer.should_terminate\n    h(None)  # counter == 0\n    assert not trainer.should_terminate\n    h(None)  # delta == 0.3; counter == 1\n    assert not trainer.should_terminate\n    h(None)  # delta == 0.6; counter == 0\n    assert not trainer.should_terminate\n\n\ndef test_simple_early_stopping_on_plateau():\n    def score_function(engine):\n        return 42\n\n    trainer = Engine(do_nothing_update_fn)\n\n    h = EarlyStopping(patience=1, score_function=score_function, trainer=trainer)\n    # Call 2 times and check if stopped\n    assert not trainer.should_terminate\n    h(None)\n    assert not trainer.should_terminate\n    h(None)\n    assert trainer.should_terminate\n\n\ndef test_simple_no_early_stopping():\n\n    scores = iter([1.0, 0.8, 1.2])\n\n    def score_function(engine):\n        return next(scores)\n\n    trainer = Engine(do_nothing_update_fn)\n\n    h = EarlyStopping(patience=2, score_function=score_function, trainer=trainer)\n    # Call 3 times and check if not stopped\n    assert not trainer.should_terminate\n    h(None)\n    h(None)\n    h(None)\n    assert not trainer.should_terminate\n\n\ndef test_with_engine_early_stopping():\n    class Counter(object):\n        def __init__(self, count=0):\n            self.count = count\n\n    n_epochs_counter = Counter()\n\n    scores = iter([1.0, 0.8, 1.2, 1.5, 0.9, 1.0, 0.99, 1.1, 0.9])\n\n    def score_function(engine):\n        return next(scores)\n\n    trainer = Engine(do_nothing_update_fn)\n    evaluator = Engine(do_nothing_update_fn)\n    early_stopping = EarlyStopping(patience=3, score_function=score_function, trainer=trainer)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def evaluation(engine):\n        evaluator.run([0])\n        n_epochs_counter.count += 1\n\n    evaluator.add_event_handler(Events.COMPLETED, early_stopping)\n    trainer.run([0], max_epochs=10)\n    assert n_epochs_counter.count == 7\n    assert trainer.state.epoch == 7\n\n\ndef test_with_engine_early_stopping_on_plateau():\n    class Counter(object):\n        def __init__(self, count=0):\n            self.count = count\n\n    n_epochs_counter = Counter()\n\n    def score_function(engine):\n        return 0.047\n\n    trainer = Engine(do_nothing_update_fn)\n    evaluator = Engine(do_nothing_update_fn)\n    early_stopping = EarlyStopping(patience=4, score_function=score_function, trainer=trainer)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def evaluation(engine):\n        evaluator.run([0])\n        n_epochs_counter.count += 1\n\n    evaluator.add_event_handler(Events.COMPLETED, early_stopping)\n    trainer.run([0], max_epochs=10)\n    assert n_epochs_counter.count == 5\n    assert trainer.state.epoch == 5\n\n\ndef test_with_engine_no_early_stopping():\n    class Counter(object):\n        def __init__(self, count=0):\n            self.count = count\n\n    n_epochs_counter = Counter()\n\n    scores = iter([1.0, 0.8, 1.2, 1.23, 0.9, 1.0, 1.1, 1.253, 1.26, 1.2])\n\n    def score_function(engine):\n        return next(scores)\n\n    trainer = Engine(do_nothing_update_fn)\n    evaluator = Engine(do_nothing_update_fn)\n    early_stopping = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def evaluation(engine):\n        evaluator.run([0])\n        n_epochs_counter.count += 1\n\n    evaluator.add_event_handler(Events.COMPLETED, early_stopping)\n    trainer.run([0], max_epochs=10)\n    assert n_epochs_counter.count == 10\n    assert trainer.state.epoch == 10\n\n\ndef _test_distrib_with_engine_early_stopping(device):\n\n    import torch.distributed as dist\n\n    torch.manual_seed(12)\n\n    class Counter(object):\n        def __init__(self, count=0):\n            self.count = count\n\n    n_epochs_counter = Counter()\n\n    scores = torch.tensor([1.0, 0.8, 1.2, 1.5, 0.9, 1.0, 0.99, 1.1, 0.9], requires_grad=False).to(device)\n\n    def score_function(engine):\n        i = trainer.state.epoch - 1\n        v = scores[i]\n        dist.all_reduce(v)\n        v /= dist.get_world_size()\n        return v.item()\n\n    trainer = Engine(do_nothing_update_fn)\n    evaluator = Engine(do_nothing_update_fn)\n    early_stopping = EarlyStopping(patience=3, score_function=score_function, trainer=trainer)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def evaluation(engine):\n        evaluator.run([0])\n        n_epochs_counter.count += 1\n\n    evaluator.add_event_handler(Events.COMPLETED, early_stopping)\n    trainer.run([0], max_epochs=10)\n    assert trainer.state.epoch == 7\n    assert n_epochs_counter.count == 7\n\n\ndef _test_distrib_integration_engine_early_stopping(device):\n\n    import torch.distributed as dist\n    from ignite.metrics import Accuracy\n\n    rank = dist.get_rank()\n    ws = dist.get_world_size()\n    torch.manual_seed(12)\n\n    n_epochs = 10\n    n_iters = 20\n\n    y_preds = (\n        [torch.randint(0, 2, size=(n_iters, ws)).to(device)]\n        + [torch.ones(n_iters, ws).to(device)]\n        + [torch.randint(0, 2, size=(n_iters, ws)).to(device) for _ in range(n_epochs - 2)]\n    )\n\n    y_true = (\n        [torch.randint(0, 2, size=(n_iters, ws)).to(device)]\n        + [torch.ones(n_iters, ws).to(device)]\n        + [torch.randint(0, 2, size=(n_iters, ws)).to(device) for _ in range(n_epochs - 2)]\n    )\n\n    def update(engine, _):\n        e = trainer.state.epoch - 1\n        i = engine.state.iteration - 1\n        return y_preds[e][i, rank], y_true[e][i, rank]\n\n    evaluator = Engine(update)\n    acc = Accuracy(device=device)\n    acc.attach(evaluator, ""acc"")\n\n    def score_function(engine):\n        return engine.state.metrics[""acc""]\n\n    trainer = Engine(lambda e, b: None)\n    early_stopping = EarlyStopping(patience=3, score_function=score_function, trainer=trainer)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def evaluation(engine):\n        data = list(range(n_iters))\n        evaluator.run(data=data)\n\n    evaluator.add_event_handler(Events.COMPLETED, early_stopping)\n    trainer.run([0], max_epochs=10)\n    assert trainer.state.epoch == 5\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_with_engine_early_stopping(device)\n    _test_distrib_integration_engine_early_stopping(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(local_rank, distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_with_engine_early_stopping(device)\n    _test_distrib_integration_engine_early_stopping(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_with_engine_early_stopping(device)\n    _test_distrib_integration_engine_early_stopping(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_with_engine_early_stopping(device)\n    _test_distrib_integration_engine_early_stopping(device)\n'"
tests/ignite/handlers/test_handlers.py,0,"b'from unittest.mock import MagicMock\n\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import global_step_from_engine\n\n\ndef test_global_step_from_engine():\n\n    iteration = 12\n    epoch = 23\n\n    trainer = Engine(lambda e, b: None)\n    trainer.state.iteration = iteration\n    trainer.state.epoch = epoch\n\n    gst = global_step_from_engine(trainer)\n    assert gst(MagicMock(), Events.EPOCH_COMPLETED) == epoch\n\n    gst = global_step_from_engine(trainer, custom_event_name=Events.ITERATION_COMPLETED)\n    assert gst(MagicMock(), Events.EPOCH_COMPLETED) == iteration\n'"
tests/ignite/handlers/test_terminate_on_nan.py,15,"b'import numpy as np\nimport torch\n\nfrom ignite.engine import Engine, Events, State\nfrom ignite.handlers import TerminateOnNan\n\n\ndef test_terminate_on_nan_and_inf():\n\n    torch.manual_seed(12)\n\n    def update_fn(engine, batch):\n        pass\n\n    trainer = Engine(update_fn)\n    trainer.state = State()\n    h = TerminateOnNan()\n\n    trainer.state.output = 1.0\n    h(trainer)\n    assert not trainer.should_terminate\n\n    trainer.state.output = torch.tensor(123.45)\n    h(trainer)\n    assert not trainer.should_terminate\n\n    trainer.state.output = torch.asin(torch.randn(10,))\n    h(trainer)\n    assert trainer.should_terminate\n    trainer.should_terminate = False\n\n    trainer.state.output = np.array([1.0, 2.0])\n    h._output_transform = lambda x: x.tolist()\n    h(trainer)\n    assert not trainer.should_terminate\n    h._output_transform = lambda x: x\n\n    trainer.state.output = torch.asin(torch.randn(4, 4))\n    h(trainer)\n    assert trainer.should_terminate\n    trainer.should_terminate = False\n\n    trainer.state.output = (10.0, 1.0 / torch.randint(0, 2, size=(4,)).type(torch.float), 1.0)\n    h(trainer)\n    assert trainer.should_terminate\n    trainer.should_terminate = False\n\n    trainer.state.output = (1.0, torch.tensor(1.0), ""abc"")\n    h(trainer)\n    assert not trainer.should_terminate\n\n    trainer.state.output = 1.0 / torch.randint(0, 2, size=(4, 4)).type(torch.float)\n    h(trainer)\n    assert trainer.should_terminate\n    trainer.should_terminate = False\n\n    trainer.state.output = (float(""nan""), 10.0)\n    h(trainer)\n    assert trainer.should_terminate\n    trainer.should_terminate = False\n\n    trainer.state.output = float(""inf"")\n    h(trainer)\n    assert trainer.should_terminate\n    trainer.should_terminate = False\n\n    trainer.state.output = [float(""nan""), 10.0]\n    h(trainer)\n    assert trainer.should_terminate\n    trainer.should_terminate = False\n\n\ndef test_with_terminate_on_nan():\n\n    torch.manual_seed(12)\n\n    data = [1.0, 0.8, (torch.rand(4, 4), torch.rand(4, 4)), torch.rand(5), torch.asin(torch.randn(4, 4)), 0.0, 1.0]\n\n    def update_fn(engine, batch):\n        return batch\n\n    trainer = Engine(update_fn)\n    h = TerminateOnNan()\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, h)\n\n    trainer.run(data, max_epochs=2)\n    assert trainer.state.iteration == 5\n\n\ndef test_with_terminate_on_inf():\n\n    torch.manual_seed(12)\n\n    data = [\n        1.0,\n        0.8,\n        torch.rand(4, 4),\n        (1.0 / torch.randint(0, 2, size=(4,)).type(torch.float), torch.tensor(1.234)),\n        torch.rand(5),\n        torch.asin(torch.randn(4, 4)),\n        0.0,\n        1.0,\n    ]\n\n    def update_fn(engine, batch):\n        return batch\n\n    trainer = Engine(update_fn)\n    h = TerminateOnNan()\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, h)\n\n    trainer.run(data, max_epochs=2)\n    assert trainer.state.iteration == 4\n\n\ndef test_without_terminate_on_nan_inf():\n\n    data = [1.0, 0.8, torch.rand(4, 4), (torch.rand(5), torch.rand(5, 4)), 0.0, 1.0]\n\n    def update_fn(engine, batch):\n        return batch\n\n    trainer = Engine(update_fn)\n    h = TerminateOnNan()\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, h)\n\n    trainer.run(data, max_epochs=2)\n    assert trainer.state.iteration == len(data) * 2\n'"
tests/ignite/handlers/test_timing.py,0,"b'import sys\nimport time\n\nimport pytest\n\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import Timer\n\nif sys.platform.startswith(""darwin""):\n    pytest.skip(""Skip if on MacOS"", allow_module_level=True)\n\n\ndef test_timer():\n    sleep_t = 0.2\n    n_iter = 3\n\n    def _train_func(engine, batch):\n        time.sleep(sleep_t)\n\n    def _test_func(engine, batch):\n        time.sleep(sleep_t)\n\n    trainer = Engine(_train_func)\n    tester = Engine(_test_func)\n\n    t_total = Timer()\n    t_batch = Timer(average=True)\n    t_train = Timer()\n\n    t_total.attach(trainer)\n    t_batch.attach(\n        trainer, pause=Events.ITERATION_COMPLETED, resume=Events.ITERATION_STARTED, step=Events.ITERATION_COMPLETED\n    )\n    t_train.attach(trainer, pause=Events.EPOCH_COMPLETED, resume=Events.EPOCH_STARTED)\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def run_validation(trainer):\n        tester.run(range(n_iter))\n\n    # Run ""training""\n    trainer.run(range(n_iter))\n\n    def _equal(lhs, rhs):\n        return round(lhs, 1) == round(rhs, 1)\n\n    assert _equal(t_total.value(), (2 * n_iter * sleep_t))\n    assert _equal(t_batch.value(), (sleep_t))\n    assert _equal(t_train.value(), (n_iter * sleep_t))\n\n    t_total.reset()\n    assert _equal(t_total.value(), 0.0)\n'"
tests/ignite/metrics/__init__.py,0,b'# Needed to collect coverage data\n'
tests/ignite/metrics/test_accumulation.py,33,"b'import os\n\nimport numpy as np\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics.accumulation import Average, GeometricAverage, VariableAccumulation\n\ntorch.manual_seed(15)\n\n\ndef test_variable_accumulation_wrong_inputs():\n\n    with pytest.raises(TypeError, match=r""Argument op should be a callable""):\n        VariableAccumulation(1)\n\n    with pytest.raises(TypeError, match=r""Output should be a number or torch.Tensor,""):\n        mean_acc = VariableAccumulation(lambda a, x: a + x)\n        mean_acc.update((1, 2))\n\n    with pytest.raises(TypeError, match=r""Output should be a number or torch.Tensor,""):\n        mean_acc = VariableAccumulation(lambda a, x: a + x)\n        mean_acc.update(""a"")\n\n\ndef test_variable_accumulation_mean_variable():\n\n    mean_var = VariableAccumulation(lambda a, x: a + x)\n    y_true = torch.rand(100)\n\n    for y in y_true:\n        mean_var.update(y)\n\n    a, n = mean_var.compute()\n    assert a.item() == pytest.approx(y_true.sum().item())\n    assert n == len(y_true)\n\n    mean_var = VariableAccumulation(lambda a, x: a + x)\n    y_true = torch.rand(100, 10)\n    for y in y_true:\n        mean_var.update(y)\n\n    a, n = mean_var.compute()\n    assert a.numpy() == pytest.approx(y_true.sum(dim=0).numpy())\n    assert n == len(y_true)\n\n    mean_var = VariableAccumulation(lambda a, x: a + x.sum(dim=0))\n    # iterate by batch of 16 samples\n    y_true = torch.rand(8, 16, 10)\n    for y in y_true:\n        mean_var.update(y)\n\n    a, n = mean_var.compute()\n    assert a.numpy() == pytest.approx(y_true.reshape(-1, 10).sum(dim=0).numpy())\n    assert n == y_true.shape[0] * y_true.shape[1]\n\n\ndef test_average():\n\n    with pytest.raises(NotComputableError):\n        v = Average()\n        v.compute()\n\n    mean_var = Average()\n    y_true = torch.rand(100) + torch.randint(0, 10, size=(100,)).float()\n\n    for y in y_true:\n        mean_var.update(y.item())\n\n    m = mean_var.compute()\n    assert m.item() == pytest.approx(y_true.mean().item())\n\n    mean_var = Average()\n    y_true = torch.rand(100, 10) + torch.randint(0, 10, size=(100, 10)).float()\n    for y in y_true:\n        mean_var.update(y)\n\n    m = mean_var.compute()\n    assert m.numpy() == pytest.approx(y_true.mean(dim=0).numpy())\n\n    mean_var = Average()\n    y_true = torch.rand(8, 16, 10) + torch.randint(0, 10, size=(8, 16, 10)).float()\n    for y in y_true:\n        mean_var.update(y)\n\n    m = mean_var.compute()\n    assert m.numpy() == pytest.approx(y_true.reshape(-1, 10).mean(dim=0).numpy())\n\n\ndef _geom_mean(t):\n    np_t = t.numpy()\n    return np.exp(np.mean(np.log(np_t), axis=0))\n\n\ndef test_geom_average():\n\n    with pytest.raises(NotComputableError):\n        v = GeometricAverage()\n        v.compute()\n\n    mean_var = GeometricAverage()\n    y_true = torch.rand(100) + torch.randint(0, 10, size=(100,)).float()\n\n    for y in y_true:\n        mean_var.update(y.item())\n\n    m = mean_var.compute()\n    assert m.item() == pytest.approx(_geom_mean(y_true))\n\n    mean_var = GeometricAverage()\n    y_true = torch.rand(100, 10) + torch.randint(0, 10, size=(100, 10)).float()\n    for y in y_true:\n        mean_var.update(y)\n\n    m = mean_var.compute()\n    np.testing.assert_almost_equal(m.numpy(), _geom_mean(y_true), decimal=5)\n\n    mean_var = GeometricAverage()\n    y_true = torch.rand(8, 16, 10) + torch.randint(0, 10, size=(8, 16, 10)).float()\n    for y in y_true:\n        mean_var.update(y)\n\n    m = mean_var.compute()\n    np.testing.assert_almost_equal(m.numpy(), _geom_mean(y_true.reshape(-1, 10)), decimal=5)\n\n\ndef test_integration():\n    def _test(metric_cls, true_result_fn):\n\n        size = 100\n        custom_variable = 10.0 + 5.0 * torch.rand(size, 12)\n\n        def update_fn(engine, batch):\n            return 0, custom_variable[engine.state.iteration - 1]\n\n        engine = Engine(update_fn)\n\n        custom_var_mean = metric_cls(output_transform=lambda output: output[1])\n        custom_var_mean.attach(engine, ""agg_custom_var"")\n\n        state = engine.run([0] * size)\n        np.testing.assert_almost_equal(\n            state.metrics[""agg_custom_var""].numpy(), true_result_fn(custom_variable), decimal=5\n        )\n\n        size = 100\n        custom_variable = 10.0 + 5.0 * torch.rand(size)\n\n        def update_fn(engine, batch):\n            return 0, custom_variable[engine.state.iteration - 1].item()\n\n        engine = Engine(update_fn)\n\n        custom_var_mean = metric_cls(output_transform=lambda output: output[1])\n        custom_var_mean.attach(engine, ""agg_custom_var"")\n\n        state = engine.run([0] * size)\n        assert state.metrics[""agg_custom_var""] == pytest.approx(true_result_fn(custom_variable))\n\n    def _mean(y_true):\n        return y_true.mean(dim=0).numpy()\n\n    _test(Average, _mean)\n    _test(GeometricAverage, _geom_mean)\n\n\ndef test_compute_mean_std():\n    n = 8\n    b = 12\n    c = 3\n    w = h = 64\n    true_data = np.arange(0, n * b * h * w * c, dtype=""float64"").reshape(n * b, c, h, w) - (n * b * c * w * h * 0.75)\n    mean = true_data.transpose((0, 2, 3, 1)).reshape(-1, c).mean(axis=0)\n    std = true_data.transpose((0, 2, 3, 1)).reshape(-1, c).std(axis=0)\n\n    train_loader = torch.from_numpy(true_data).reshape(n, b, c, h, w)\n\n    def compute_mean_std(engine, batch):\n        _b, _c = batch.shape[:2]\n        data = batch.reshape(_b, _c, -1).to(dtype=torch.float64)\n        _mean = torch.mean(data, dim=-1)\n        _mean2 = torch.mean(data ** 2, dim=-1)\n        return {""mean"": _mean, ""mean^2"": _mean2}\n\n    compute_engine = Engine(compute_mean_std)\n    img_mean = Average(output_transform=lambda output: output[""mean""])\n    img_mean2 = Average(output_transform=lambda output: output[""mean^2""])\n    img_mean.attach(compute_engine, ""mean"")\n    img_mean2.attach(compute_engine, ""mean2"")\n    state = compute_engine.run(train_loader)\n    state.metrics[""std""] = torch.sqrt(state.metrics[""mean2""] - state.metrics[""mean""] ** 2)\n\n    np.testing.assert_almost_equal(state.metrics[""mean""].numpy(), mean, decimal=7)\n    np.testing.assert_almost_equal(state.metrics[""std""].numpy(), std, decimal=5)\n\n\ndef _test_distrib_variable_accumulation(device):\n\n    mean_var = VariableAccumulation(lambda a, x: a + x, device=device)\n    y_true = torch.rand(100, device=device, dtype=torch.float64)\n\n    for y in y_true:\n        mean_var.update(y)\n\n    y_true = idist.all_reduce(y_true)\n    a, n = mean_var.compute()\n    assert a.item() == pytest.approx(y_true.sum().item())\n    assert n == len(y_true) * idist.get_world_size()\n    # check if call compute twice\n    a, n = mean_var.compute()\n    assert a.item() == pytest.approx(y_true.sum().item())\n    assert n == len(y_true) * idist.get_world_size()\n\n    mean_var = VariableAccumulation(lambda a, x: a + x, device=device)\n    y_true = torch.rand(50, 10, device=device, dtype=torch.float64)\n\n    for y in y_true:\n        mean_var.update(y)\n\n    y_true = idist.all_reduce(y_true)\n    a, n = mean_var.compute()\n    assert n == len(y_true) * idist.get_world_size()\n    np.testing.assert_almost_equal(a.cpu().numpy(), y_true.sum(dim=0).cpu().numpy(), decimal=4)\n    a, n = mean_var.compute()\n    assert n == len(y_true) * idist.get_world_size()\n    np.testing.assert_almost_equal(a.cpu().numpy(), y_true.sum(dim=0).cpu().numpy(), decimal=4)\n\n\ndef _test_distrib_average(device):\n\n    with pytest.raises(NotComputableError):\n        v = Average(device=device)\n        v.compute()\n\n    mean_var = Average(device=device)\n    y_true = torch.rand(100, dtype=torch.float64) + torch.randint(0, 10, size=(100,)).double()\n    y_true = y_true.to(device)\n\n    for y in y_true:\n        mean_var.update(y)\n\n    m = mean_var.compute()\n\n    y_true = idist.all_reduce(y_true)\n    assert m.item() == pytest.approx(y_true.mean().item() / idist.get_world_size())\n\n    mean_var = Average(device=device)\n    y_true = torch.rand(100, 10, dtype=torch.float64) + torch.randint(0, 10, size=(100, 10)).double()\n    y_true = y_true.to(device)\n\n    for y in y_true:\n        mean_var.update(y)\n\n    m = mean_var.compute()\n\n    y_true = idist.all_reduce(y_true)\n    np.testing.assert_almost_equal(\n        m.cpu().numpy(), y_true.mean(dim=0).cpu().numpy() / idist.get_world_size(), decimal=5\n    )\n\n\ndef _test_distrib_geom_average(device):\n\n    with pytest.raises(NotComputableError):\n        v = GeometricAverage(device=device)\n        v.compute()\n\n    mean_var = GeometricAverage(device=device)\n    y_true = torch.rand(100, dtype=torch.float64) + torch.randint(0, 10, size=(100,)).double()\n    y_true = y_true.to(device)\n\n    for y in y_true:\n        mean_var.update(y)\n\n    m = mean_var.compute()\n    log_y_true = torch.log(y_true)\n    log_y_true = idist.all_reduce(log_y_true)\n    assert m.item() == pytest.approx(torch.exp(log_y_true.mean(dim=0) / idist.get_world_size()).item())\n\n    mean_var = GeometricAverage(device=device)\n    y_true = torch.rand(100, 10, dtype=torch.float64) + torch.randint(0, 10, size=(100, 10)).double()\n    y_true = y_true.to(device)\n\n    for y in y_true:\n        mean_var.update(y)\n\n    m = mean_var.compute()\n    log_y_true = torch.log(y_true)\n    log_y_true = idist.all_reduce(log_y_true)\n    np.testing.assert_almost_equal(\n        m.cpu().numpy(), torch.exp(log_y_true.mean(dim=0) / idist.get_world_size()).cpu().numpy(), decimal=5\n    )\n\n\ndef _test_distrib_integration(device):\n    def _test(metric_cls, true_result_fn, tol=1e-5):\n\n        size = 100\n        custom_variable = 10.0 + 5.0 * torch.rand(size, 12, dtype=torch.float64)\n        custom_variable = custom_variable.to(device)\n\n        def update_fn(engine, batch):\n            return 0, custom_variable[engine.state.iteration - 1]\n\n        engine = Engine(update_fn)\n\n        custom_var_mean = metric_cls(output_transform=lambda output: output[1], device=device)\n        custom_var_mean.attach(engine, ""agg_custom_var"")\n\n        state = engine.run([0] * size)\n        np.testing.assert_almost_equal(\n            state.metrics[""agg_custom_var""].cpu().numpy(),\n            true_result_fn(custom_variable),\n            decimal=int(np.log10(1.0 / tol)),\n        )\n\n        size = 100\n        custom_variable = 10.0 + 5.0 * torch.rand(size, dtype=torch.float64)\n        custom_variable = custom_variable.to(device)\n\n        def update_fn(engine, batch):\n            return 0, custom_variable[engine.state.iteration - 1].item()\n\n        engine = Engine(update_fn)\n\n        custom_var_mean = metric_cls(output_transform=lambda output: output[1], device=device)\n        custom_var_mean.attach(engine, ""agg_custom_var"")\n\n        state = engine.run([0] * size)\n        assert state.metrics[""agg_custom_var""] == pytest.approx(true_result_fn(custom_variable), abs=tol)\n\n    def _mean(y_true):\n        y_true = idist.all_reduce(y_true)\n        return y_true.mean(dim=0).cpu().numpy() / idist.get_world_size()\n\n    def _geom_mean(y_true):\n        log_y_true = torch.log(y_true)\n        log_y_true = idist.all_reduce(log_y_true)\n        np_t = log_y_true.cpu().numpy()\n        return np.exp(np.mean(np_t, axis=0) / idist.get_world_size())\n\n    _test(Average, _mean)\n    _test(GeometricAverage, _geom_mean, tol=1e-4)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(distributed_context_single_node_nccl[""local_rank""])\n    _test_distrib_variable_accumulation(device)\n    _test_distrib_average(device)\n    _test_distrib_geom_average(device)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_variable_accumulation(device)\n    _test_distrib_average(device)\n    _test_distrib_geom_average(device)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_variable_accumulation(device)\n    _test_distrib_average(device)\n    _test_distrib_geom_average(device)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_variable_accumulation(device)\n    _test_distrib_average(device)\n    _test_distrib_geom_average(device)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_variable_accumulation(device)\n    _test_distrib_average(device)\n    _test_distrib_geom_average(device)\n    _test_distrib_integration(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_variable_accumulation(device)\n    _test_distrib_average(device)\n    _test_distrib_geom_average(device)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_accuracy.py,102,"b'import os\n\nimport pytest\nimport torch\nfrom sklearn.metrics import accuracy_score\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import Accuracy\n\ntorch.manual_seed(12)\n\n\ndef test_no_update():\n    acc = Accuracy()\n    with pytest.raises(NotComputableError):\n        acc.compute()\n\n\ndef test__check_shape():\n    acc = Accuracy()\n\n    with pytest.raises(ValueError):\n        acc._check_shape((torch.randint(0, 2, size=(10, 1, 5, 12)).long(), torch.randint(0, 2, size=(10, 5, 6)).long()))\n\n    with pytest.raises(ValueError):\n        acc._check_shape((torch.randint(0, 2, size=(10, 1, 6)).long(), torch.randint(0, 2, size=(10, 5, 6)).long()))\n\n    with pytest.raises(ValueError):\n        acc._check_shape((torch.randint(0, 2, size=(10, 1)).long(), torch.randint(0, 2, size=(10, 5)).long()))\n\n\ndef test_binary_wrong_inputs():\n    acc = Accuracy()\n\n    with pytest.raises(ValueError):\n        # y has not only 0 or 1 values\n        acc.update((torch.randint(0, 2, size=(10,)).long(), torch.arange(0, 10).long()))\n\n    with pytest.raises(ValueError):\n        # y_pred values are not thresholded to 0, 1 values\n        acc.update((torch.rand(10,), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        acc.update((torch.randint(0, 2, size=(10,)).long(), torch.randint(0, 2, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        acc.update((torch.randint(0, 2, size=(10, 5, 6)).long(), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        acc.update((torch.randint(0, 2, size=(10,)).long(), torch.randint(0, 2, size=(10, 5, 6)).long()))\n\n\ndef test_binary_input_N():\n    # Binary accuracy on input of shape (N, 1) or (N, )\n    def _test():\n        acc = Accuracy()\n\n        y_pred = torch.randint(0, 2, size=(10,)).long()\n        y = torch.randint(0, 2, size=(10,)).long()\n        acc.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(100,)).long()\n        y = torch.randint(0, 2, size=(100,)).long()\n\n        n_iters = 16\n        batch_size = y.shape[0] // n_iters + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_binary_input_NL():\n    # Binary accuracy on input of shape (N, L)\n    def _test():\n        acc = Accuracy()\n\n        y_pred = torch.randint(0, 2, size=(10, 5)).long()\n        y = torch.randint(0, 2, size=(10, 5)).long()\n        acc.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(10, 1, 5)).long()\n        y = torch.randint(0, 2, size=(10, 1, 5)).long()\n        acc.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(100, 8)).long()\n        y = torch.randint(0, 2, size=(100, 8)).long()\n\n        n_iters = 16\n        batch_size = y.shape[0] // n_iters + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_binary_input_NHW():\n    # Binary accuracy on input of shape (N, H, W, ...)\n    def _test():\n        acc = Accuracy()\n\n        y_pred = torch.randint(0, 2, size=(4, 12, 10)).long()\n        y = torch.randint(0, 2, size=(4, 12, 10)).long()\n        acc.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(4, 1, 12, 10)).long()\n        y = torch.randint(0, 2, size=(4, 1, 12, 10)).long()\n        acc.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(100, 8, 8)).long()\n        y = torch.randint(0, 2, size=(100, 8, 8)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_binary_as_multiclass_input():\n    # Binary accuracy on input of shape (N, 1, ...)\n    def _test():\n        acc = Accuracy()\n\n        y_pred = torch.randint(0, 2, size=(4, 1)).long()\n        y = torch.randint(0, 2, size=(4,)).long()\n        acc.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(4, 1, 12)).long()\n        y = torch.randint(0, 2, size=(4, 12)).long()\n        acc.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(100, 1, 8, 8)).long()\n        y = torch.randint(0, 2, size=(100, 8, 8)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert acc._type == ""binary""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_multiclass_wrong_inputs():\n    acc = Accuracy()\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        acc.update((torch.rand(10, 5, 4), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        acc.update((torch.rand(10, 5, 6), torch.randint(0, 5, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        acc.update((torch.rand(10), torch.randint(0, 5, size=(10, 5, 6)).long()))\n\n\ndef test_multiclass_input_N():\n    # Multiclass input data of shape (N, ) and (N, C)\n    def _test():\n        acc = Accuracy()\n\n        y_pred = torch.rand(10, 4)\n        y = torch.randint(0, 4, size=(10,)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.rand(10, 10, 1)\n        y = torch.randint(0, 18, size=(10, 1)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.rand(10, 18)\n        y = torch.randint(0, 18, size=(10,)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.rand(4, 10)\n        y = torch.randint(0, 10, size=(4,)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # 2-classes\n        acc.reset()\n        y_pred = torch.rand(4, 2)\n        y = torch.randint(0, 2, size=(4,)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.rand(100, 5)\n        y = torch.randint(0, 5, size=(100,)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_multiclass_input_NL():\n    # Multiclass input data of shape (N, L) and (N, C, L)\n    def _test():\n        acc = Accuracy()\n\n        y_pred = torch.rand(10, 4, 5)\n        y = torch.randint(0, 4, size=(10, 5)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.rand(4, 10, 5)\n        y = torch.randint(0, 10, size=(4, 5)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.rand(100, 9, 7)\n        y = torch.randint(0, 9, size=(100, 7)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_multiclass_input_NHW():\n    # Multiclass input data of shape (N, H, W, ...) and (N, C, H, W, ...)\n    def _test():\n        acc = Accuracy()\n\n        y_pred = torch.rand(4, 5, 12, 10)\n        y = torch.randint(0, 5, size=(4, 12, 10)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.rand(4, 5, 10, 12, 8)\n        y = torch.randint(0, 5, size=(4, 10, 12, 8)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.rand(100, 3, 8, 8)\n        y = torch.randint(0, 3, size=(100, 8, 8)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        assert acc._type == ""multiclass""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef to_numpy_multilabel(y):\n    # reshapes input array to (N x ..., C)\n    y = y.transpose(1, 0).cpu().numpy()\n    num_classes = y.shape[0]\n    y = y.reshape((num_classes, -1)).transpose(1, 0)\n    return y\n\n\ndef test_multilabel_wrong_inputs():\n    acc = Accuracy(is_multilabel=True)\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        acc.update((torch.randint(0, 2, size=(10,)), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible y_pred\n        acc.update((torch.rand(10, 5), torch.randint(0, 2, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible y\n        acc.update((torch.randint(0, 5, size=(10, 5, 6)), torch.rand(10)))\n\n\ndef test_multilabel_input_N():\n    # Multilabel input data of shape (N, C, ...) and (N, C, ...)\n\n    def _test():\n        acc = Accuracy(is_multilabel=True)\n        y_pred = torch.randint(0, 2, size=(10, 4))\n        y = torch.randint(0, 2, size=(10, 4)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy()\n        np_y = y.numpy()\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(50, 7)).long()\n        y = torch.randint(0, 2, size=(50, 7)).long()\n        acc.update((y_pred, y))\n        np_y_pred = y_pred.numpy()\n        np_y = y.numpy()\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(100, 4))\n        y = torch.randint(0, 2, size=(100, 4)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy()\n        np_y_pred = y_pred.numpy()\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_multilabel_input_NL():\n    # Multilabel input data of shape (N, C, L, ...) and (N, C, L, ...)\n\n    def _test():\n        acc = Accuracy(is_multilabel=True)\n\n        y_pred = torch.randint(0, 2, size=(10, 4, 5))\n        y = torch.randint(0, 2, size=(10, 4, 5)).long()\n        acc.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)  # (N, C, L, ...) -> (N * L * ..., C)\n        np_y = to_numpy_multilabel(y)  # (N, C, L, ...) -> (N * L ..., C)\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(4, 10, 8)).long()\n        y = torch.randint(0, 2, size=(4, 10, 8)).long()\n        acc.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)  # (N, C, L, ...) -> (N * L * ..., C)\n        np_y = to_numpy_multilabel(y)  # (N, C, L, ...) -> (N * L ..., C)\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(100, 4, 5))\n        y = torch.randint(0, 2, size=(100, 4, 5)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y_pred = to_numpy_multilabel(y_pred)  # (N, C, L, ...) -> (N * L * ..., C)\n        np_y = to_numpy_multilabel(y)  # (N, C, L, ...) -> (N * L ..., C)\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_multilabel_input_NHW():\n    # Multilabel input data of shape (N, C, H, W, ...) and (N, C, H, W, ...)\n\n    def _test():\n        acc = Accuracy(is_multilabel=True)\n\n        y_pred = torch.randint(0, 2, size=(4, 5, 12, 10))\n        y = torch.randint(0, 2, size=(4, 5, 12, 10)).long()\n        acc.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)  # (N, C, H, W, ...) -> (N * H * W ..., C)\n        np_y = to_numpy_multilabel(y)  # (N, C, H, W, ...) -> (N * H * W ..., C)\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(4, 10, 12, 8)).long()\n        y = torch.randint(0, 2, size=(4, 10, 12, 8)).long()\n        acc.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)  # (N, C, H, W, ...) -> (N * H * W ..., C)\n        np_y = to_numpy_multilabel(y)  # (N, C, H, W, ...) -> (N * H * W ..., C)\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n        # Batched Updates\n        acc.reset()\n        y_pred = torch.randint(0, 2, size=(100, 5, 12, 10))\n        y = torch.randint(0, 2, size=(100, 5, 12, 10)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y_pred = to_numpy_multilabel(y_pred)  # (N, C, L, ...) -> (N * L * ..., C)\n        np_y = to_numpy_multilabel(y)  # (N, C, L, ...) -> (N * L ..., C)\n        assert acc._type == ""multilabel""\n        assert isinstance(acc.compute(), float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(acc.compute())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test()\n\n\ndef test_incorrect_type():\n    acc = Accuracy()\n\n    # Start as binary data\n    y_pred = torch.randint(0, 2, size=(4,))\n    y = torch.ones(4).long()\n    acc.update((y_pred, y))\n\n    # And add a multiclass data\n    y_pred = torch.rand(4, 4)\n    y = torch.ones(4).long()\n\n    with pytest.raises(RuntimeError):\n        acc.update((y_pred, y))\n\n\ndef _test_distrib_multilabel_input_NHW(device):\n    # Multilabel input data of shape (N, C, H, W, ...) and (N, C, H, W, ...)\n\n    rank = idist.get_rank()\n\n    def _test():\n        acc = Accuracy(is_multilabel=True)\n\n        torch.manual_seed(10 + rank)\n        y_pred = torch.randint(0, 2, size=(4, 5, 8, 10), device=device).long()\n        y = torch.randint(0, 2, size=(4, 5, 8, 10), device=device).long()\n        acc.update((y_pred, y))\n\n        # gather y_pred, y\n        y_pred = idist.all_gather(y_pred)\n        y = idist.all_gather(y)\n\n        np_y_pred = to_numpy_multilabel(y_pred.cpu())  # (N, C, H, W, ...) -> (N * H * W ..., C)\n        np_y = to_numpy_multilabel(y.cpu())  # (N, C, H, W, ...) -> (N * H * W ..., C)\n        assert acc._type == ""multilabel""\n        n = acc._num_examples\n        res = acc.compute()\n        assert n * idist.get_world_size() == acc._num_examples\n        assert isinstance(res, float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(res)\n\n        acc.reset()\n        torch.manual_seed(10 + rank)\n        y_pred = torch.randint(0, 2, size=(4, 7, 10, 8), device=device).long()\n        y = torch.randint(0, 2, size=(4, 7, 10, 8), device=device).long()\n        acc.update((y_pred, y))\n\n        # gather y_pred, y\n        y_pred = idist.all_gather(y_pred)\n        y = idist.all_gather(y)\n\n        np_y_pred = to_numpy_multilabel(y_pred.cpu())  # (N, C, H, W, ...) -> (N * H * W ..., C)\n        np_y = to_numpy_multilabel(y.cpu())  # (N, C, H, W, ...) -> (N * H * W ..., C)\n\n        assert acc._type == ""multilabel""\n        n = acc._num_examples\n        res = acc.compute()\n        assert n * idist.get_world_size() == acc._num_examples\n        assert isinstance(res, float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(res)\n        # check that result is not changed\n        res = acc.compute()\n        assert n * idist.get_world_size() == acc._num_examples\n        assert isinstance(res, float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(res)\n\n        # Batched Updates\n        acc.reset()\n        torch.manual_seed(10 + rank)\n        y_pred = torch.randint(0, 2, size=(80, 5, 8, 10), device=device).long()\n        y = torch.randint(0, 2, size=(80, 5, 8, 10), device=device).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            acc.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        # gather y_pred, y\n        y_pred = idist.all_gather(y_pred)\n        y = idist.all_gather(y)\n\n        np_y_pred = to_numpy_multilabel(y_pred.cpu())  # (N, C, L, ...) -> (N * L * ..., C)\n        np_y = to_numpy_multilabel(y.cpu())  # (N, C, L, ...) -> (N * L ..., C)\n\n        assert acc._type == ""multilabel""\n        n = acc._num_examples\n        res = acc.compute()\n        assert n * idist.get_world_size() == acc._num_examples\n        assert isinstance(res, float)\n        assert accuracy_score(np_y, np_y_pred) == pytest.approx(res)\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(5):\n        _test()\n\n\ndef _test_distrib_integration_multiclass(device):\n\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    def _test(n_epochs):\n        n_iters = 80\n        s = 16\n        n_classes = 10\n\n        offset = n_iters * s\n        y_true = torch.randint(0, n_classes, size=(offset * idist.get_world_size(),)).to(device)\n        y_preds = torch.rand(offset * idist.get_world_size(), n_classes).to(device)\n\n        def update(engine, i):\n            return (\n                y_preds[i * s + rank * offset : (i + 1) * s + rank * offset, :],\n                y_true[i * s + rank * offset : (i + 1) * s + rank * offset],\n            )\n\n        engine = Engine(update)\n\n        acc = Accuracy()\n        acc.attach(engine, ""acc"")\n\n        data = list(range(n_iters))\n        engine.run(data=data, max_epochs=n_epochs)\n\n        assert ""acc"" in engine.state.metrics\n        res = engine.state.metrics[""acc""]\n        if isinstance(res, torch.Tensor):\n            res = res.cpu().numpy()\n\n        true_res = accuracy_score(y_true.cpu().numpy(), torch.argmax(y_preds, dim=1).cpu().numpy())\n\n        assert pytest.approx(res) == true_res\n\n    for _ in range(3):\n        _test(n_epochs=1)\n        _test(n_epochs=2)\n\n\ndef _test_distrib_integration_multilabel(device):\n\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    def _test(n_epochs):\n        n_iters = 80\n        s = 16\n        n_classes = 10\n\n        offset = n_iters * s\n        y_true = torch.randint(0, 2, size=(offset * idist.get_world_size(), n_classes, 8, 10)).to(device)\n        y_preds = torch.randint(0, 2, size=(offset * idist.get_world_size(), n_classes, 8, 10)).to(device)\n\n        def update(engine, i):\n            return (\n                y_preds[i * s + rank * offset : (i + 1) * s + rank * offset, ...],\n                y_true[i * s + rank * offset : (i + 1) * s + rank * offset, ...],\n            )\n\n        engine = Engine(update)\n\n        acc = Accuracy(is_multilabel=True)\n        acc.attach(engine, ""acc"")\n\n        data = list(range(n_iters))\n        engine.run(data=data, max_epochs=n_epochs)\n\n        assert ""acc"" in engine.state.metrics\n        res = engine.state.metrics[""acc""]\n        if isinstance(res, torch.Tensor):\n            res = res.cpu().numpy()\n\n        true_res = accuracy_score(to_numpy_multilabel(y_true), to_numpy_multilabel(y_preds))\n\n        assert pytest.approx(res) == true_res\n\n    for _ in range(3):\n        _test(n_epochs=1)\n        _test(n_epochs=2)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_single_node_nccl[""local_rank""])\n    _test_distrib_multilabel_input_NHW(device)\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_multilabel_input_NHW(device)\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_multilabel_input_NHW(device)\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_multilabel_input_NHW(device)\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_multilabel_input_NHW(device)\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_multilabel_input_NHW(device)\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_confusion_matrix.py,46,"b'import os\n\nimport numpy as np\nimport pytest\nimport torch\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import ConfusionMatrix, IoU, mIoU\nfrom ignite.metrics.confusion_matrix import DiceCoefficient, cmAccuracy, cmPrecision, cmRecall\n\ntorch.manual_seed(12)\n\n\ndef test_no_update():\n    cm = ConfusionMatrix(10)\n    with pytest.raises(NotComputableError):\n        cm.compute()\n\n\ndef test_multiclass_wrong_inputs():\n    cm = ConfusionMatrix(10)\n\n    with pytest.raises(ValueError, match=r""y_pred must have shape \\(batch_size, num_categories, ...\\)""):\n        cm.update((torch.rand(10), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError, match=r""y_pred does not have correct number of categories:""):\n        cm.update((torch.rand(10, 5, 4), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(\n        ValueError, match=r""y_pred must have shape \\(batch_size, num_categories, ...\\) "" r""and y must have ""\n    ):\n        cm.update((torch.rand(4, 10, 12, 12), torch.randint(0, 10, size=(10,)).long()))\n\n    with pytest.raises(ValueError, match=r""y and y_pred must have compatible shapes.""):\n        cm.update((torch.rand(4, 10, 12, 14), torch.randint(0, 10, size=(4, 5, 6)).long()))\n\n    with pytest.raises(ValueError, match=r""Argument average can None or one of""):\n        ConfusionMatrix(num_classes=10, average=""abc"")\n\n\ndef test_multiclass_input_N():\n    # Multiclass input data of shape (N, )\n    def _test_N():\n        num_classes = 4\n        cm = ConfusionMatrix(num_classes=num_classes)\n        y_pred = torch.rand(10, num_classes)\n        y = torch.randint(0, num_classes, size=(10,)).long()\n        cm.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n        num_classes = 10\n        cm = ConfusionMatrix(num_classes=num_classes)\n        y_pred = torch.rand(4, num_classes)\n        y = torch.randint(0, num_classes, size=(4,)).long()\n        cm.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n        # 2-classes\n        num_classes = 2\n        cm = ConfusionMatrix(num_classes=num_classes)\n        y_pred = torch.rand(4, num_classes)\n        y = torch.randint(0, num_classes, size=(4,)).long()\n        cm.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n        # Batched Updates\n        num_classes = 5\n        cm = ConfusionMatrix(num_classes=num_classes)\n\n        y_pred = torch.rand(100, num_classes)\n        y = torch.randint(0, num_classes, size=(100,)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            cm.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test_N()\n\n\ndef test_multiclass_input_NL():\n    # Multiclass input data of shape (N, L)\n    def _test_NL():\n        num_classes = 4\n        cm = ConfusionMatrix(num_classes=num_classes)\n\n        y_pred = torch.rand(10, num_classes, 5)\n        y = torch.randint(0, num_classes, size=(10, 5)).long()\n        cm.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n        num_classes = 10\n        cm = ConfusionMatrix(num_classes=num_classes)\n        y_pred = torch.rand(4, num_classes, 5)\n        y = torch.randint(0, num_classes, size=(4, 5)).long()\n        cm.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n        # Batched Updates\n        num_classes = 9\n        cm = ConfusionMatrix(num_classes=num_classes)\n\n        y_pred = torch.rand(100, num_classes, 7)\n        y = torch.randint(0, num_classes, size=(100, 7)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            cm.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test_NL()\n\n\ndef test_multiclass_input_NHW():\n    # Multiclass input data of shape (N, H, W, ...)\n    def _test_NHW():\n        num_classes = 5\n        cm = ConfusionMatrix(num_classes=num_classes)\n\n        y_pred = torch.rand(4, num_classes, 12, 10)\n        y = torch.randint(0, num_classes, size=(4, 12, 10)).long()\n        cm.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n        num_classes = 5\n        cm = ConfusionMatrix(num_classes=num_classes)\n        y_pred = torch.rand(4, num_classes, 10, 12, 8)\n        y = torch.randint(0, num_classes, size=(4, 10, 12, 8)).long()\n        cm.update((y_pred, y))\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        np_y = y.numpy().ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n        # Batched Updates\n        num_classes = 3\n        cm = ConfusionMatrix(num_classes=num_classes)\n        y_pred = torch.rand(100, num_classes, 8, 8)\n        y = torch.randint(0, num_classes, size=(100, 8, 8)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            cm.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n        assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n    # check multiple random inputs as random exact occurencies are rare\n    for _ in range(10):\n        _test_NHW()\n\n\ndef test_ignored_out_of_num_classes_indices():\n    num_classes = 21\n    cm = ConfusionMatrix(num_classes=num_classes)\n\n    y_pred = torch.rand(4, num_classes, 12, 10)\n    y = torch.randint(0, 255, size=(4, 12, 10)).long()\n    cm.update((y_pred, y))\n    np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n    np_y = y.numpy().ravel()\n    assert np.all(confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) == cm.compute().numpy())\n\n\ndef get_y_true_y_pred():\n    # Generate an image with labels 0 (background), 1, 2\n    # 3 classes:\n    y_true = np.zeros((30, 30), dtype=np.int)\n    y_true[1:11, 1:11] = 1\n    y_true[15:25, 15:25] = 2\n\n    y_pred = np.zeros((30, 30), dtype=np.int)\n    y_pred[5:15, 1:11] = 1\n    y_pred[20:30, 20:30] = 2\n    return y_true, y_pred\n\n\ndef compute_th_y_true_y_logits(y_true, y_pred):\n    # Create torch.tensor from numpy\n    th_y_true = torch.from_numpy(y_true).unsqueeze(0)\n    # Create logits torch.tensor:\n    num_classes = max(np.max(y_true), np.max(y_pred)) + 1\n    y_probas = np.ones((num_classes,) + y_true.shape) * -10\n    for i in range(num_classes):\n        y_probas[i, (y_pred == i)] = 720\n    th_y_logits = torch.from_numpy(y_probas).unsqueeze(0)\n    return th_y_true, th_y_logits\n\n\ndef test_multiclass_images():\n    num_classes = 3\n    cm = ConfusionMatrix(num_classes=num_classes)\n\n    y_true, y_pred = get_y_true_y_pred()\n\n    # Compute confusion matrix with sklearn\n    true_res = confusion_matrix(y_true.reshape(-1), y_pred.reshape(-1))\n\n    th_y_true, th_y_logits = compute_th_y_true_y_logits(y_true, y_pred)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = cm.compute().numpy()\n\n    assert np.all(true_res == res)\n\n    # Another test on batch of 2 images\n    num_classes = 3\n    cm = ConfusionMatrix(num_classes=num_classes)\n\n    # Create a batch of two images:\n    th_y_true1 = torch.from_numpy(y_true).reshape(1, 30, 30)\n    th_y_true2 = torch.from_numpy(y_true.transpose()).reshape(1, 30, 30)\n    th_y_true = torch.cat([th_y_true1, th_y_true2], dim=0)\n\n    # Create a batch of 2 logits tensors\n    y_probas = np.ones((3, 30, 30)) * -10\n    y_probas[0, (y_pred == 0)] = 720\n    y_probas[1, (y_pred == 1)] = 720\n    y_probas[2, (y_pred == 2)] = 768\n    th_y_logits1 = torch.from_numpy(y_probas).reshape(1, 3, 30, 30)\n\n    y_probas = np.ones((3, 30, 30)) * -10\n    y_probas[0, (y_pred.transpose() == 0)] = 720\n    y_probas[1, (y_pred.transpose() == 2)] = 720\n    y_probas[2, (y_pred.transpose() == 1)] = 768\n    th_y_logits2 = torch.from_numpy(y_probas).reshape(1, 3, 30, 30)\n\n    th_y_logits = torch.cat([th_y_logits1, th_y_logits2], dim=0)\n\n    # Update metric & compute\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n    res = cm.compute().numpy()\n\n    # Compute confusion matrix with sklearn\n    true_res = confusion_matrix(th_y_true.numpy().reshape(-1), np.argmax(th_y_logits.numpy(), axis=1).reshape(-1))\n\n    assert np.all(true_res == res)\n\n\ndef test_iou_wrong_input():\n\n    with pytest.raises(TypeError, match=""Argument cm should be instance of ConfusionMatrix""):\n        IoU(None)\n\n    cm = ConfusionMatrix(num_classes=10)\n    with pytest.raises(ValueError, match=""ignore_index should be non-negative integer""):\n        IoU(cm, ignore_index=-1)\n\n    with pytest.raises(ValueError, match=""ignore_index should be non-negative integer""):\n        IoU(cm, ignore_index=""a"")\n\n    with pytest.raises(ValueError, match=""ignore_index should be non-negative integer""):\n        IoU(cm, ignore_index=10)\n\n    with pytest.raises(ValueError, match=""ignore_index should be non-negative integer""):\n        IoU(cm, ignore_index=11)\n\n\ndef test_iou():\n\n    y_true, y_pred = get_y_true_y_pred()\n    th_y_true, th_y_logits = compute_th_y_true_y_logits(y_true, y_pred)\n\n    true_res = [0, 0, 0]\n    for index in range(3):\n        bin_y_true = y_true == index\n        bin_y_pred = y_pred == index\n        intersection = bin_y_true & bin_y_pred\n        union = bin_y_true | bin_y_pred\n        true_res[index] = intersection.sum() / union.sum()\n\n    cm = ConfusionMatrix(num_classes=3)\n    iou_metric = IoU(cm)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = iou_metric.compute().numpy()\n\n    assert np.all(res == true_res)\n\n    for ignore_index in range(3):\n        cm = ConfusionMatrix(num_classes=3)\n        iou_metric = IoU(cm, ignore_index=ignore_index)\n        # Update metric\n        output = (th_y_logits, th_y_true)\n        cm.update(output)\n        res = iou_metric.compute().numpy()\n        true_res_ = true_res[:ignore_index] + true_res[ignore_index + 1 :]\n        assert np.all(res == true_res_), ""{}: {} vs {}"".format(ignore_index, res, true_res_)\n\n\ndef test_miou():\n\n    y_true, y_pred = get_y_true_y_pred()\n    th_y_true, th_y_logits = compute_th_y_true_y_logits(y_true, y_pred)\n\n    true_res = [0, 0, 0]\n    for index in range(3):\n        bin_y_true = y_true == index\n        bin_y_pred = y_pred == index\n        intersection = bin_y_true & bin_y_pred\n        union = bin_y_true | bin_y_pred\n        true_res[index] = intersection.sum() / union.sum()\n\n    true_res_ = np.mean(true_res)\n\n    cm = ConfusionMatrix(num_classes=3)\n    iou_metric = mIoU(cm)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = iou_metric.compute().numpy()\n\n    assert res == true_res_\n\n    for ignore_index in range(3):\n        cm = ConfusionMatrix(num_classes=3)\n        iou_metric = mIoU(cm, ignore_index=ignore_index)\n        # Update metric\n        output = (th_y_logits, th_y_true)\n        cm.update(output)\n        res = iou_metric.compute().numpy()\n        true_res_ = np.mean(true_res[:ignore_index] + true_res[ignore_index + 1 :])\n        assert res == true_res_, ""{}: {} vs {}"".format(ignore_index, res, true_res_)\n\n\ndef test_cm_accuracy():\n\n    y_true, y_pred = get_y_true_y_pred()\n    th_y_true, th_y_logits = compute_th_y_true_y_logits(y_true, y_pred)\n\n    true_acc = accuracy_score(y_true.reshape(-1), y_pred.reshape(-1))\n\n    cm = ConfusionMatrix(num_classes=3)\n    acc_metric = cmAccuracy(cm)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = acc_metric.compute().numpy()\n\n    assert pytest.approx(res) == true_acc\n\n\ndef test_cm_precision():\n\n    y_true, y_pred = np.random.randint(0, 10, size=(1000,)), np.random.randint(0, 10, size=(1000,))\n    th_y_true, th_y_logits = compute_th_y_true_y_logits(y_true, y_pred)\n\n    true_pr = precision_score(y_true.reshape(-1), y_pred.reshape(-1), average=""macro"")\n\n    cm = ConfusionMatrix(num_classes=10)\n    pr_metric = cmPrecision(cm, average=True)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = pr_metric.compute().numpy()\n\n    assert pytest.approx(res) == true_pr\n\n    true_pr = precision_score(y_true.reshape(-1), y_pred.reshape(-1), average=None)\n    cm = ConfusionMatrix(num_classes=10)\n    pr_metric = cmPrecision(cm, average=False)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = pr_metric.compute().numpy()\n\n    assert np.all(res == true_pr)\n\n\ndef test_cm_recall():\n\n    y_true, y_pred = np.random.randint(0, 10, size=(1000,)), np.random.randint(0, 10, size=(1000,))\n    th_y_true, th_y_logits = compute_th_y_true_y_logits(y_true, y_pred)\n\n    true_re = recall_score(y_true.reshape(-1), y_pred.reshape(-1), average=""macro"")\n\n    cm = ConfusionMatrix(num_classes=10)\n    re_metric = cmRecall(cm, average=True)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = re_metric.compute().numpy()\n\n    assert pytest.approx(res) == true_re\n\n    true_re = recall_score(y_true.reshape(-1), y_pred.reshape(-1), average=None)\n    cm = ConfusionMatrix(num_classes=10)\n    re_metric = cmRecall(cm, average=False)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = re_metric.compute().numpy()\n\n    assert np.all(res == true_re)\n\n\ndef test_cm_with_average():\n    num_classes = 5\n    y_pred = torch.rand(40, num_classes)\n    y = torch.randint(0, num_classes, size=(40,)).long()\n    np_y_pred = y_pred.numpy().argmax(axis=1).ravel()\n    np_y = y.numpy().ravel()\n\n    cm = ConfusionMatrix(num_classes=num_classes, average=""samples"")\n    cm.update((y_pred, y))\n    true_res = confusion_matrix(np_y, np_y_pred, labels=list(range(num_classes))) * 1.0 / len(np_y)\n    res = cm.compute().numpy()\n    np.testing.assert_almost_equal(true_res, res)\n\n    cm = ConfusionMatrix(num_classes=num_classes, average=""recall"")\n    cm.update((y_pred, y))\n    true_re = recall_score(np_y, np_y_pred, average=None, labels=list(range(num_classes)))\n    res = cm.compute().numpy().diagonal()\n    np.testing.assert_almost_equal(true_re, res)\n\n    res = cm.compute().numpy()\n    true_res = confusion_matrix(np_y, np_y_pred, normalize=""true"")\n    np.testing.assert_almost_equal(true_res, res)\n\n    cm = ConfusionMatrix(num_classes=num_classes, average=""precision"")\n    cm.update((y_pred, y))\n    true_pr = precision_score(np_y, np_y_pred, average=None, labels=list(range(num_classes)))\n    res = cm.compute().numpy().diagonal()\n    np.testing.assert_almost_equal(true_pr, res)\n\n    res = cm.compute().numpy()\n    true_res = confusion_matrix(np_y, np_y_pred, normalize=""pred"")\n    np.testing.assert_almost_equal(true_res, res)\n\n\ndef test_dice_coefficient_wrong_input():\n\n    with pytest.raises(TypeError, match=""Argument cm should be instance of ConfusionMatrix""):\n        DiceCoefficient(None)\n\n    cm = ConfusionMatrix(num_classes=10)\n    with pytest.raises(ValueError, match=""ignore_index should be non-negative integer""):\n        DiceCoefficient(cm, ignore_index=-1)\n\n    with pytest.raises(ValueError, match=""ignore_index should be non-negative integer""):\n        DiceCoefficient(cm, ignore_index=""a"")\n\n    with pytest.raises(ValueError, match=""ignore_index should be non-negative integer""):\n        DiceCoefficient(cm, ignore_index=10)\n\n    with pytest.raises(ValueError, match=""ignore_index should be non-negative integer""):\n        DiceCoefficient(cm, ignore_index=11)\n\n\ndef test_dice_coefficient():\n\n    y_true, y_pred = get_y_true_y_pred()\n    th_y_true, th_y_logits = compute_th_y_true_y_logits(y_true, y_pred)\n\n    true_res = [0, 0, 0]\n    for index in range(3):\n        bin_y_true = y_true == index\n        bin_y_pred = y_pred == index\n        # dice coefficient: 2*intersection(x, y) / (|x| + |y|)\n        # union(x, y) = |x| + |y| - intersection(x, y)\n        intersection = bin_y_true & bin_y_pred\n        union = bin_y_true | bin_y_pred\n        true_res[index] = 2.0 * intersection.sum() / (union.sum() + intersection.sum())\n\n    cm = ConfusionMatrix(num_classes=3)\n    dice_metric = DiceCoefficient(cm)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = dice_metric.compute().numpy()\n    np.testing.assert_allclose(res, true_res)\n\n    for ignore_index in range(3):\n        cm = ConfusionMatrix(num_classes=3)\n        dice_metric = DiceCoefficient(cm, ignore_index=ignore_index)\n        # Update metric\n        output = (th_y_logits, th_y_true)\n        cm.update(output)\n        res = dice_metric.compute().numpy()\n        true_res_ = true_res[:ignore_index] + true_res[ignore_index + 1 :]\n        assert np.all(res == true_res_), ""{}: {} vs {}"".format(ignore_index, res, true_res_)\n\n\ndef _test_distrib_multiclass_images(device):\n\n    num_classes = 3\n    cm = ConfusionMatrix(num_classes=num_classes, device=device)\n\n    y_true, y_pred = get_y_true_y_pred()\n\n    # Compute confusion matrix with sklearn\n    true_res = confusion_matrix(y_true.reshape(-1), y_pred.reshape(-1))\n\n    th_y_true, th_y_logits = compute_th_y_true_y_logits(y_true, y_pred)\n    th_y_true = th_y_true.to(device)\n    th_y_logits = th_y_logits.to(device)\n\n    # Update metric\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n\n    res = cm.compute().cpu().numpy() / idist.get_world_size()\n\n    assert np.all(true_res == res)\n\n    # Another test on batch of 2 images\n    num_classes = 3\n    cm = ConfusionMatrix(num_classes=num_classes, device=device)\n\n    # Create a batch of two images:\n    th_y_true1 = torch.from_numpy(y_true).reshape(1, 30, 30)\n    th_y_true2 = torch.from_numpy(y_true.transpose()).reshape(1, 30, 30)\n    th_y_true = torch.cat([th_y_true1, th_y_true2], dim=0)\n    th_y_true = th_y_true.to(device)\n\n    # Create a batch of 2 logits tensors\n    y_probas = np.ones((3, 30, 30)) * -10\n    y_probas[0, (y_pred == 0)] = 720\n    y_probas[1, (y_pred == 1)] = 720\n    y_probas[2, (y_pred == 2)] = 768\n    th_y_logits1 = torch.from_numpy(y_probas).reshape(1, 3, 30, 30)\n\n    y_probas = np.ones((3, 30, 30)) * -10\n    y_probas[0, (y_pred.transpose() == 0)] = 720\n    y_probas[1, (y_pred.transpose() == 2)] = 720\n    y_probas[2, (y_pred.transpose() == 1)] = 768\n    th_y_logits2 = torch.from_numpy(y_probas).reshape(1, 3, 30, 30)\n\n    th_y_logits = torch.cat([th_y_logits1, th_y_logits2], dim=0)\n    # check update if input is on another device\n    th_y_logits = th_y_logits.to(device)\n\n    # Update metric & compute\n    output = (th_y_logits, th_y_true)\n    cm.update(output)\n    res = cm.compute().cpu().numpy()\n\n    # Compute confusion matrix with sklearn\n    th_y_true = idist.all_gather(th_y_true)\n    th_y_logits = idist.all_gather(th_y_logits)\n\n    np_y_true = th_y_true.cpu().numpy().reshape(-1)\n    np_y_pred = np.argmax(th_y_logits.cpu().numpy(), axis=1).reshape(-1)\n    true_res = confusion_matrix(np_y_true, np_y_pred)\n\n    assert np.all(true_res == res)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_multiclass_images(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_multiclass_images(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_multiclass_images(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_multiclass_images(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_multiclass_images(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_multiclass_images(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_dill.py,0,"b'import dill\n\nfrom ignite.metrics import Metric\n\n\nclass Accumulation(Metric):\n    def __init__(self):\n        self.value = 0\n        super(Accumulation, self).__init__()\n\n    def reset(self):\n        self.value = 0\n\n    def compute(self):\n        return self.value\n\n    def update(self, output):\n        self.value += output\n\n\ndef test_metric():\n    def _test(m, values, e):\n        for v in values:\n            m.update(v)\n        assert m.compute() == e\n\n    metric = Accumulation()\n\n    m1 = dill.loads(dill.dumps(metric))\n\n    values = list(range(10))\n    expected = sum(values)\n\n    _test(m1, values, expected)\n\n    metric.update(5)\n\n    m2 = dill.loads(dill.dumps(metric))\n\n    _test(m2, values, expected + 5)\n'"
tests/ignite/metrics/test_epoch_metric.py,37,"b'import os\n\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.metrics import EpochMetric\nfrom ignite.metrics.epoch_metric import EpochMetricWarning\n\n\ndef test_epoch_metric_wrong_setup_or_input():\n\n    # Wrong compute function\n    with pytest.raises(TypeError, match=r""Argument compute_fn should be callable.""):\n        EpochMetric(12345)\n\n    def compute_fn(y_preds, y_targets):\n        return 0.0\n\n    em = EpochMetric(compute_fn)\n\n    # Wrong input dims\n    with pytest.raises(ValueError, match=r""Predictions should be of shape""):\n        output = (torch.tensor(0), torch.tensor(0))\n        em.update(output)\n\n    # Wrong input dims\n    with pytest.raises(ValueError, match=r""Targets should be of shape""):\n        output = (torch.rand(4, 3), torch.rand(4, 3, 1))\n        em.update(output)\n\n    # Wrong input dims\n    with pytest.raises(ValueError, match=r""Predictions should be of shape""):\n        output = (torch.rand(4, 3, 1), torch.rand(4, 3))\n        em.update(output)\n\n    # Target is not binary\n    with pytest.raises(ValueError, match=r""Targets should be binary""):\n        output = (torch.rand(4, 3), torch.randint(0, 5, size=(4, 3)))\n        em.update(output)\n\n    em.reset()\n    output1 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output1)\n\n    with pytest.raises(ValueError, match=r""Incoherent types between input y_pred and stored predictions""):\n        output2 = (torch.randint(0, 5, size=(4, 3)), torch.randint(0, 2, size=(4, 3)))\n        em.update(output2)\n\n    with pytest.raises(ValueError, match=r""Incoherent types between input y and stored targets""):\n        output2 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3)).to(torch.int32))\n        em.update(output2)\n\n\ndef test_epoch_metric():\n    def compute_fn(y_preds, y_targets):\n        return 0.0\n\n    em = EpochMetric(compute_fn)\n\n    em.reset()\n    output1 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output1)\n    output2 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output2)\n\n    assert all([t.device.type == ""cpu"" for t in em._predictions + em._targets])\n    assert torch.equal(em._predictions[0], output1[0])\n    assert torch.equal(em._predictions[1], output2[0])\n    assert torch.equal(em._targets[0], output1[1])\n    assert torch.equal(em._targets[1], output2[1])\n    assert em.compute() == 0.0\n\n    # test when y and y_pred are (batch_size, 1) that are squeezed to (batch_size, )\n    em.reset()\n    output1 = (torch.rand(4, 1), torch.randint(0, 2, size=(4, 1), dtype=torch.long))\n    em.update(output1)\n    output2 = (torch.rand(4, 1), torch.randint(0, 2, size=(4, 1), dtype=torch.long))\n    em.update(output2)\n\n    assert all([t.device.type == ""cpu"" for t in em._predictions + em._targets])\n    assert torch.equal(em._predictions[0], output1[0][:, 0])\n    assert torch.equal(em._predictions[1], output2[0][:, 0])\n    assert torch.equal(em._targets[0], output1[1][:, 0])\n    assert torch.equal(em._targets[1], output2[1][:, 0])\n    assert em.compute() == 0.0\n\n\ndef test_mse_epoch_metric():\n    def compute_fn(y_preds, y_targets):\n        return torch.mean(((y_preds - y_targets.type_as(y_preds)) ** 2)).item()\n\n    em = EpochMetric(compute_fn)\n\n    em.reset()\n    output1 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output1)\n    output2 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output2)\n    output3 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output3)\n\n    preds = torch.cat([output1[0], output2[0], output3[0]], dim=0)\n    targets = torch.cat([output1[1], output2[1], output3[1]], dim=0)\n\n    result = em.compute()\n    assert result == compute_fn(preds, targets)\n\n    em.reset()\n    output1 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output1)\n    output2 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output2)\n    output3 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 3), dtype=torch.long))\n    em.update(output3)\n\n    preds = torch.cat([output1[0], output2[0], output3[0]], dim=0)\n    targets = torch.cat([output1[1], output2[1], output3[1]], dim=0)\n\n    result = em.compute()\n    assert result == compute_fn(preds, targets)\n\n\ndef test_bad_compute_fn():\n    def compute_fn(y_preds, y_targets):\n        # Following will raise the error:\n        # The size of tensor a (3) must match the size of tensor b (4)\n        # at non-singleton dimension 1\n        return torch.mean(y_preds - y_targets).item()\n\n    em = EpochMetric(compute_fn)\n\n    em.reset()\n    output1 = (torch.rand(4, 3), torch.randint(0, 2, size=(4, 4), dtype=torch.long))\n    with pytest.warns(EpochMetricWarning, match=r""Probably, there can be a problem with `compute_fn`""):\n        em.update(output1)\n\n\ndef _test_warning():\n    def compute_fn(y_preds, y_targets):\n        return 0.0\n\n    with pytest.warns(RuntimeWarning, match=""EpochMetric class does not support distributed setting""):\n        EpochMetric(compute_fn)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n    # Perform some ops otherwise, next tests fail\n\n    if idist.get_world_size() > 1:\n        _test_warning()\n\n    device = ""cuda:{}"".format(local_rank)\n\n    y = torch.rand(10, 12, device=device)\n    y = idist.all_gather(y)\n    assert isinstance(y, torch.Tensor)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(local_rank, distributed_context_single_node_gloo):\n    # Perform some ops otherwise, next tests fail\n\n    if idist.get_world_size() > 1:\n        _test_warning()\n\n    device = ""cpu""\n\n    y = torch.rand(10, 12, device=device)\n    y = idist.all_gather(y)\n    assert isinstance(y, torch.Tensor)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n\n    _test_warning()\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    _test_warning()\n'"
tests/ignite/metrics/test_fbeta.py,10,"b'import os\n\nimport numpy as np\nimport pytest\nimport torch\nfrom sklearn.metrics import fbeta_score\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine\nfrom ignite.metrics import Fbeta, Precision, Recall\n\ntorch.manual_seed(12)\n\n\ndef test_wrong_inputs():\n\n    with pytest.raises(ValueError, match=r""Beta should be a positive integer""):\n        Fbeta(0.0)\n\n    with pytest.raises(ValueError, match=r""Input precision metric should have average=False""):\n        p = Precision(average=True)\n        Fbeta(1.0, precision=p)\n\n    with pytest.raises(ValueError, match=r""Input recall metric should have average=False""):\n        r = Recall(average=True)\n        Fbeta(1.0, recall=r)\n\n    with pytest.raises(ValueError, match=r""If precision argument is provided, output_transform should be None""):\n        p = Precision(average=False)\n        Fbeta(1.0, precision=p, output_transform=lambda x: x)\n\n    with pytest.raises(ValueError, match=r""If recall argument is provided, output_transform should be None""):\n        r = Recall(average=False)\n        Fbeta(1.0, recall=r, output_transform=lambda x: x)\n\n\ndef test_integration():\n    def _test(p, r, average, output_transform):\n        np.random.seed(1)\n\n        n_iters = 10\n        batch_size = 10\n        n_classes = 10\n\n        y_true = np.arange(0, n_iters * batch_size, dtype=""int64"") % n_classes\n        y_pred = 0.2 * np.random.rand(n_iters * batch_size, n_classes)\n        for i in range(n_iters * batch_size):\n            if np.random.rand() > 0.4:\n                y_pred[i, y_true[i]] = 1.0\n            else:\n                j = np.random.randint(0, n_classes)\n                y_pred[i, j] = 0.7\n\n        y_true_batch_values = iter(y_true.reshape(n_iters, batch_size))\n        y_pred_batch_values = iter(y_pred.reshape(n_iters, batch_size, n_classes))\n\n        def update_fn(engine, batch):\n            y_true_batch = next(y_true_batch_values)\n            y_pred_batch = next(y_pred_batch_values)\n            if output_transform is not None:\n                return {""y_pred"": torch.from_numpy(y_pred_batch), ""y"": torch.from_numpy(y_true_batch)}\n            return torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n        evaluator = Engine(update_fn)\n\n        f2 = Fbeta(beta=2.0, average=average, precision=p, recall=r, output_transform=output_transform)\n        f2.attach(evaluator, ""f2"")\n\n        data = list(range(n_iters))\n        state = evaluator.run(data, max_epochs=1)\n\n        f2_true = fbeta_score(y_true, np.argmax(y_pred, axis=-1), average=""macro"" if average else None, beta=2.0)\n        if isinstance(state.metrics[""f2""], torch.Tensor):\n            np.testing.assert_allclose(f2_true, state.metrics[""f2""].numpy())\n        else:\n            assert f2_true == pytest.approx(state.metrics[""f2""]), ""{} vs {}"".format(f2_true, state.metrics[""f2""])\n\n    _test(None, None, False, output_transform=None)\n    _test(None, None, True, output_transform=None)\n\n    def output_transform(output):\n        return output[""y_pred""], output[""y""]\n\n    _test(None, None, False, output_transform=output_transform)\n    _test(None, None, True, output_transform=output_transform)\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n    _test(precision, recall, False, None)\n    _test(precision, recall, True, None)\n\n\ndef _test_distrib_integration(device):\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    def _test(p, r, average, n_epochs):\n        n_iters = 60\n        s = 16\n        n_classes = 7\n\n        offset = n_iters * s\n        y_true = torch.randint(0, n_classes, size=(offset * idist.get_world_size(),)).to(device)\n        y_preds = torch.rand(offset * idist.get_world_size(), n_classes).to(device)\n\n        def update(engine, i):\n            return (\n                y_preds[i * s + rank * offset : (i + 1) * s + rank * offset, :],\n                y_true[i * s + rank * offset : (i + 1) * s + rank * offset],\n            )\n\n        engine = Engine(update)\n\n        fbeta = Fbeta(beta=2.5, average=average, device=device)\n        fbeta.attach(engine, ""f2.5"")\n\n        data = list(range(n_iters))\n        engine.run(data=data, max_epochs=n_epochs)\n\n        assert ""f2.5"" in engine.state.metrics\n        res = engine.state.metrics[""f2.5""]\n        if isinstance(res, torch.Tensor):\n            res = res.cpu().numpy()\n\n        true_res = fbeta_score(\n            y_true.cpu().numpy(),\n            torch.argmax(y_preds, dim=1).cpu().numpy(),\n            beta=2.5,\n            average=""macro"" if average else None,\n        )\n\n        assert pytest.approx(res) == true_res\n\n    _test(None, None, average=True, n_epochs=1)\n    _test(None, None, average=True, n_epochs=2)\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n    _test(precision, recall, average=False, n_epochs=1)\n    _test(precision, recall, average=False, n_epochs=2)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_frequency.py,0,"b'import os\nimport sys\nimport time\n\nimport pytest\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events\nfrom ignite.metrics import Frequency\n\nif sys.platform.startswith(""darwin""):\n    pytest.skip(""Skip if on MacOS"", allow_module_level=True)\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_nondistributed_average():\n    artificial_time = 1  # seconds\n    num_tokens = 100\n    average_upper_bound = num_tokens / artificial_time\n    average_lower_bound = average_upper_bound * 0.9\n    freq_metric = Frequency()\n    freq_metric.reset()\n    time.sleep(artificial_time)\n    freq_metric.update(num_tokens)\n    average = freq_metric.compute()\n    assert average_lower_bound < average < average_upper_bound\n\n\ndef _test_frequency_with_engine(device, workers, lower_bound_factor=0.8, every=1):\n\n    artificial_time = 1.0 / workers  # seconds\n    total_tokens = 400 // workers\n    batch_size = 128 // workers\n\n    estimated_wps = batch_size * workers / artificial_time\n\n    def update_fn(engine, batch):\n        time.sleep(artificial_time)\n        return {""ntokens"": len(batch)}\n\n    engine = Engine(update_fn)\n    wps_metric = Frequency(output_transform=lambda x: x[""ntokens""], device=device)\n    event = Events.ITERATION_COMPLETED(every=every)\n    wps_metric.attach(engine, ""wps"", event_name=event)\n\n    @engine.on(event)\n    def assert_wps(e):\n        wps = e.state.metrics[""wps""]\n        assert estimated_wps * lower_bound_factor < wps <= estimated_wps, ""{}: {} < {} < {}"".format(\n            e.state.iteration, estimated_wps * lower_bound_factor, wps, estimated_wps\n        )\n\n    data = [[i] * batch_size for i in range(0, total_tokens, batch_size)]\n    engine.run(data, max_epochs=1)\n\n\n@pytest.mark.skipif(sys.platform.startswith(""darwin""), reason=""Skip on MacOS"")\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_frequency_with_engine():\n    device = ""cpu""\n    _test_frequency_with_engine(device, workers=1)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_frequency_with_engine_distributed(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_frequency_with_engine(device, workers=idist.get_world_size())\n\n\ndef test_frequency_with_engine_with_every():\n    device = ""cpu""\n    _test_frequency_with_engine(device, workers=1, every=1)\n    _test_frequency_with_engine(device, workers=1, every=10)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_frequency_with_engine_distributed_with_every(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_frequency_with_engine(device, workers=idist.get_world_size(), every=1)\n    _test_frequency_with_engine(device, workers=idist.get_world_size(), every=10)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_frequency_with_engine(device, workers=idist.get_world_size(), every=10)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_frequency_with_engine(device, workers=idist.get_world_size(), every=10)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_loss.py,21,"b'import os\n\nimport pytest\nimport torch\nfrom numpy.testing import assert_almost_equal\nfrom torch import nn\nfrom torch.nn.functional import nll_loss\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import Loss\n\n\ndef test_zero_div():\n    loss = Loss(nll_loss)\n    with pytest.raises(NotComputableError):\n        loss.compute()\n\n\ndef test_compute():\n    loss = Loss(nll_loss)\n\n    y_pred = torch.tensor([[0.1, 0.4, 0.5], [0.1, 0.7, 0.2]]).log()\n    y = torch.tensor([2, 2]).long()\n    loss.update((y_pred, y))\n    assert_almost_equal(loss.compute(), 1.1512925625)\n\n    y_pred = torch.tensor([[0.1, 0.3, 0.6], [0.6, 0.2, 0.2], [0.2, 0.7, 0.1]]).log()\n    y = torch.tensor([2, 0, 2]).long()\n    loss.update((y_pred, y))\n    assert_almost_equal(loss.compute(), 1.1253643036)  # average\n\n\ndef test_compute_on_criterion():\n    loss = Loss(nn.NLLLoss())\n\n    y_pred = torch.tensor([[0.1, 0.4, 0.5], [0.1, 0.7, 0.2]]).log()\n    y = torch.tensor([2, 2]).long()\n    loss.update((y_pred, y))\n    assert_almost_equal(loss.compute(), 1.1512925625)\n\n    y_pred = torch.tensor([[0.1, 0.3, 0.6], [0.6, 0.2, 0.2], [0.2, 0.7, 0.1]]).log()\n    y = torch.tensor([2, 0, 2]).long()\n    loss.update((y_pred, y))\n    assert_almost_equal(loss.compute(), 1.1253643036)  # average\n\n\ndef test_non_averaging_loss():\n    loss = Loss(nn.NLLLoss(reduction=""none""))\n\n    y_pred = torch.tensor([[0.1, 0.4, 0.5], [0.1, 0.7, 0.2]]).log()\n    y = torch.tensor([2, 2]).long()\n    with pytest.raises(ValueError):\n        loss.update((y_pred, y))\n\n\ndef test_kwargs_loss():\n    loss = Loss(nll_loss)\n\n    y_pred = torch.tensor([[0.1, 0.4, 0.5], [0.1, 0.7, 0.2]]).log()\n    y = torch.tensor([2, 2]).long()\n    loss.update((y_pred, y, {""weight"": torch.tensor([0, 0, 0], dtype=torch.float)}))\n    assert_almost_equal(loss.compute(), 0)\n\n\ndef test_reset():\n    loss = Loss(nll_loss)\n\n    y_pred = torch.tensor([[0.1, 0.3, 0.6], [0.6, 0.2, 0.2]]).log()\n    y = torch.tensor([2, 0]).long()\n    loss.update((y_pred, y))\n    loss.compute()\n    loss.reset()\n    with pytest.raises(NotComputableError):\n        loss.compute()\n\n\ndef _test_distrib_compute_on_criterion(device):\n\n    criterion = nn.NLLLoss().to(device)\n    loss = Loss(criterion, device=device)\n\n    y_pred = torch.tensor([[0.1, 0.4, 0.5], [0.1, 0.7, 0.2]], device=device).log()\n    y = torch.tensor([2, 2], device=device).long()\n    loss.update((y_pred, y))\n    n = loss._num_examples\n    assert n == len(y)\n    res = loss.compute()\n    assert n * idist.get_world_size() == loss._num_examples\n\n    y_pred = idist.all_gather(y_pred)\n    y = idist.all_gather(y)\n    true_loss_value = criterion(y_pred, y)\n    assert_almost_equal(res, true_loss_value.item())\n\n    loss.reset()\n    y_pred = torch.tensor([[0.1, 0.3, 0.6], [0.6, 0.2, 0.2], [0.2, 0.7, 0.1]], device=device).log()\n    y = torch.tensor([2, 0, 2], device=device).long()\n    loss.update((y_pred, y))\n    n = loss._num_examples\n    res = loss.compute()\n    assert n * idist.get_world_size() == loss._num_examples\n\n    y_pred = idist.all_gather(y_pred)\n    y = idist.all_gather(y)\n    true_loss_value = criterion(y_pred, y)\n    assert_almost_equal(res, true_loss_value.item())\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_compute_on_criterion(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_compute_on_criterion(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_compute_on_criterion(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_compute_on_criterion(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_compute_on_criterion(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_compute_on_criterion(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_mean_absolute_error.py,7,"b'import os\n\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import MeanAbsoluteError\n\n\ndef test_zero_div():\n    mae = MeanAbsoluteError()\n    with pytest.raises(NotComputableError):\n        mae.compute()\n\n\ndef test_compute():\n    mae = MeanAbsoluteError()\n\n    y_pred = torch.Tensor([[2.0], [-2.0]])\n    y = torch.zeros(2)\n    mae.update((y_pred, y))\n    assert isinstance(mae.compute(), float)\n    assert mae.compute() == 2.0\n\n    mae.reset()\n    y_pred = torch.Tensor([[3.0], [-3.0]])\n    y = torch.zeros(2)\n    mae.update((y_pred, y))\n    assert isinstance(mae.compute(), float)\n    assert mae.compute() == 3.0\n\n\ndef _test_distrib_integration(device):\n    import numpy as np\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    n_iters = 80\n    s = 50\n    offset = n_iters * s\n\n    y_true = torch.arange(0, offset * idist.get_world_size(), dtype=torch.float).to(device)\n    y_preds = torch.ones(offset * idist.get_world_size(), dtype=torch.float).to(device)\n\n    def update(engine, i):\n        return (\n            y_preds[i * s + offset * rank : (i + 1) * s + offset * rank],\n            y_true[i * s + offset * rank : (i + 1) * s + offset * rank],\n        )\n\n    engine = Engine(update)\n\n    m = MeanAbsoluteError()\n    m.attach(engine, ""mae"")\n\n    data = list(range(n_iters))\n    engine.run(data=data, max_epochs=1)\n\n    assert ""mae"" in engine.state.metrics\n    res = engine.state.metrics[""mae""]\n\n    true_res = np.mean(np.abs((y_true - y_preds).cpu().numpy()))\n\n    assert pytest.approx(res) == true_res\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_mean_pairwise_distance.py,9,"b'import os\n\nimport pytest\nimport torch\nfrom pytest import approx\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import MeanPairwiseDistance\n\n\ndef test_zero_div():\n    mpd = MeanPairwiseDistance()\n    with pytest.raises(NotComputableError):\n        mpd.compute()\n\n\ndef test_compute():\n    mpd = MeanPairwiseDistance()\n\n    y_pred = torch.Tensor([[3.0, 4.0], [-3.0, -4.0]])\n    y = torch.zeros(2, 2)\n    mpd.update((y_pred, y))\n    assert isinstance(mpd.compute(), float)\n    assert mpd.compute() == approx(5.0)\n\n    mpd.reset()\n    y_pred = torch.Tensor([[4.0, 4.0, 4.0, 4.0], [-4.0, -4.0, -4.0, -4.0]])\n    y = torch.zeros(2, 4)\n    mpd.update((y_pred, y))\n    assert isinstance(mpd.compute(), float)\n    assert mpd.compute() == approx(8.0)\n\n\ndef _test_distrib_integration(device):\n    import numpy as np\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    n_iters = 100\n    s = 50\n    offset = n_iters * s\n\n    y_true = torch.rand(offset * idist.get_world_size(), 10).to(device)\n    y_preds = torch.rand(offset * idist.get_world_size(), 10).to(device)\n\n    def update(engine, i):\n        return (\n            y_preds[i * s + offset * rank : (i + 1) * s + offset * rank, ...],\n            y_true[i * s + offset * rank : (i + 1) * s + offset * rank, ...],\n        )\n\n    engine = Engine(update)\n\n    m = MeanPairwiseDistance()\n    m.attach(engine, ""mpwd"")\n\n    data = list(range(n_iters))\n    engine.run(data=data, max_epochs=1)\n\n    assert ""mpwd"" in engine.state.metrics\n    res = engine.state.metrics[""mpwd""]\n\n    true_res = []\n    for i in range(n_iters * idist.get_world_size()):\n        true_res.append(\n            torch.pairwise_distance(\n                y_true[i * s : (i + 1) * s, ...], y_preds[i * s : (i + 1) * s, ...], p=m._p, eps=m._eps\n            )\n            .cpu()\n            .numpy()\n        )\n    true_res = np.array(true_res).ravel()\n    true_res = true_res.mean()\n\n    assert pytest.approx(res) == true_res\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_mean_squared_error.py,7,"b'import os\n\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import MeanSquaredError\n\n\ndef test_zero_div():\n    mse = MeanSquaredError()\n    with pytest.raises(NotComputableError):\n        mse.compute()\n\n\ndef test_compute():\n    mse = MeanSquaredError()\n\n    y_pred = torch.Tensor([[2.0], [-2.0]])\n    y = torch.zeros(2)\n    mse.update((y_pred, y))\n    assert isinstance(mse.compute(), float)\n    assert mse.compute() == 4.0\n\n    mse.reset()\n    y_pred = torch.Tensor([[3.0], [-3.0]])\n    y = torch.zeros(2)\n    mse.update((y_pred, y))\n    assert isinstance(mse.compute(), float)\n    assert mse.compute() == 9.0\n\n\ndef _test_distrib_integration(device, tol=1e-6):\n    import numpy as np\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    n_iters = 100\n    s = 10\n    offset = n_iters * s\n\n    y_true = torch.arange(0, offset * idist.get_world_size(), dtype=torch.float).to(device)\n    y_preds = torch.ones(offset * idist.get_world_size(), dtype=torch.float).to(device)\n\n    def update(engine, i):\n        return (\n            y_preds[i * s + offset * rank : (i + 1) * s + offset * rank],\n            y_true[i * s + offset * rank : (i + 1) * s + offset * rank],\n        )\n\n    engine = Engine(update)\n\n    m = MeanSquaredError()\n    m.attach(engine, ""mse"")\n\n    data = list(range(n_iters))\n    engine.run(data=data, max_epochs=1)\n\n    assert ""mse"" in engine.state.metrics\n    res = engine.state.metrics[""mse""]\n\n    true_res = np.mean(np.power((y_true - y_preds).cpu().numpy(), 2.0))\n\n    assert pytest.approx(res, rel=tol) == true_res\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration(device, tol=1e-4)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration(device, tol=1e-4)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_metric.py,19,"b'import numbers\nimport os\nimport sys\nfrom unittest.mock import MagicMock\n\nimport numpy as np\nimport pytest\nimport torch\nfrom pytest import approx, raises\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events, State\nfrom ignite.metrics import ConfusionMatrix, Precision, Recall\nfrom ignite.metrics.metric import BatchFiltered, BatchWise, EpochWise, Metric, reinit__is_reduced\n\n\nclass DummyMetric1(Metric):\n    def __init__(self, true_output, output_transform=lambda x: x):\n        super(DummyMetric1, self).__init__(output_transform=output_transform)\n        self.true_output = true_output\n\n    def reset(self):\n        pass\n\n    def compute(self):\n        pass\n\n    def update(self, output):\n        assert output == self.true_output\n\n\ndef test_no_transform():\n    y_pred = torch.Tensor([[2.0], [-2.0]])\n    y = torch.zeros(2)\n\n    metric = DummyMetric1(true_output=(y_pred, y))\n    state = State(output=(y_pred, y))\n    engine = MagicMock(state=state)\n    metric.iteration_completed(engine)\n\n\ndef test_transform():\n    y_pred = torch.Tensor([[2.0], [-2.0]])\n    y = torch.zeros(2)\n\n    def transform(output):\n        pred_dict, target_dict = output\n        return pred_dict[""y""], target_dict[""y""]\n\n    metric = DummyMetric1(true_output=(y_pred, y), output_transform=transform)\n    state = State(output=({""y"": y_pred}, {""y"": y}))\n    engine = MagicMock(state=state)\n    metric.iteration_completed(engine)\n\n\ndef test_output_as_mapping_wrong_keys():\n    metric = DummyMetric1(true_output=(0, 1))\n    state = State(output=({""y1"": 0, ""y2"": 1}))\n    engine = MagicMock(state=state)\n\n    with pytest.raises(\n        ValueError, match=r""When transformed engine\'s output is a mapping, "" r""it should contain \\(\'y_pred\', \'y\'\\) keys""\n    ):\n        metric.iteration_completed(engine)\n\n\ndef test_output_as_mapping_keys_is_none():\n    class DummyMetric(Metric):\n        _required_output_keys = None\n\n        def reset(self):\n            pass\n\n        def compute(self):\n            pass\n\n        def update(self, output):\n            pass\n\n    metric = DummyMetric()\n    assert metric._required_output_keys is None\n    state = State(output=({""y1"": 0, ""y2"": 1}))\n    engine = MagicMock(state=state)\n\n    with pytest.raises(TypeError, match=r""Transformed engine output for DummyMetric metric should be a tuple/list""):\n        metric.iteration_completed(engine)\n\n\ndef test_output_as_mapping():\n    y_pred = torch.Tensor([[2.0], [-2.0]])\n    y = torch.zeros(2)\n\n    metric = DummyMetric1(true_output=(y_pred, y))\n    state = State(output=({""y_pred"": y_pred, ""y"": y}))\n    engine = MagicMock(state=state)\n    metric.iteration_completed(engine)\n\n\ndef test_no_grad():\n    y_pred = torch.zeros(4, requires_grad=True)\n    y = torch.zeros(4, requires_grad=False)\n\n    class DummyMetric(Metric):\n        def reset(self):\n            pass\n\n        def compute(self):\n            pass\n\n        def update(self, output):\n            y_pred, y = output\n            mse = torch.pow(y_pred - y.view_as(y_pred), 2)\n            assert y_pred.requires_grad\n            assert not mse.requires_grad\n\n    metric = DummyMetric()\n    state = State(output=(y_pred, y))\n    engine = MagicMock(state=state)\n    metric.iteration_completed(engine)\n\n\ndef test_arithmetics():\n    class ListGatherMetric(Metric):\n        def __init__(self, index):\n            self.index = index\n            super(ListGatherMetric, self).__init__()\n\n        def reset(self):\n            self.list_ = []\n\n        def update(self, output):\n            self.list_ = output\n\n        def compute(self):\n            return self.list_[self.index]\n\n    m0 = ListGatherMetric(0)\n    m1 = ListGatherMetric(1)\n    m2 = ListGatherMetric(2)\n\n    # __add__\n    m0_plus_m1 = m0 + m1\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    assert m0_plus_m1.compute() == 11\n    m0.update([2, 20, 200])\n    m1.update([2, 20, 200])\n    assert m0_plus_m1.compute() == 22\n\n    m2_plus_2 = m2 + 2\n    m2.update([1, 10, 100])\n    assert m2_plus_2.compute() == 102\n\n    m2_plus_2 = 2 + m2\n    m2.update([1, 10, 100])\n    assert m2_plus_2.compute() == 102\n\n    # __sub__\n    m0_minus_m1 = m0 - m1\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    assert m0_minus_m1.compute() == -9\n    m0.update([2, 20, 200])\n    m1.update([2, 20, 200])\n    assert m0_minus_m1.compute() == -18\n\n    m2_minus_2 = m2 - 2\n    m2.update([1, 10, 100])\n    assert m2_minus_2.compute() == 98\n\n    m2_minus_2 = 2 - m2\n    m2.update([1, 10, 100])\n    assert m2_minus_2.compute() == -98\n\n    # __mul__\n    m0_times_m1 = m0 * m1\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    assert m0_times_m1.compute() == 10\n    m0.update([2, 20, 200])\n    m1.update([2, 20, 200])\n    assert m0_times_m1.compute() == 40\n\n    m2_times_2 = m2 * 2\n    m2.update([1, 10, 100])\n    assert m2_times_2.compute() == 200\n\n    m2_times_2 = 2 * m2\n    m2.update([1, 10, 100])\n    assert m2_times_2.compute() == 200\n\n    # __pow__\n    m0_pow_m1 = m0 ** m1\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    assert m0_pow_m1.compute() == 1\n    m0.update([2, 20, 200])\n    m1.update([2, 20, 200])\n    assert m0_pow_m1.compute() == 2 ** 20\n\n    m2_pow_2 = m2 ** 2\n    m2.update([1, 10, 100])\n    assert m2_pow_2.compute() == 10000\n\n    m2_pow_2 = 0.99 ** m2\n    m2.update([1, 10, 100])\n    assert m2_pow_2.compute() == 0.3660323412732292\n\n    # __mod__\n    m0_mod_m1 = m0 % m1\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    assert m0_mod_m1.compute() == 1\n    m0.update([2, 20, 200])\n    m1.update([2, 20, 200])\n    assert m0_mod_m1.compute() == 2\n\n    m2_mod_2 = m2 % 2\n    m2.update([1, 10, 100])\n    assert m2_mod_2.compute() == 0\n\n    # __div__, only applicable to python2\n    if sys.version_info[0] < 3:\n        m0_div_m1 = m0.__div__(m1)\n        m0.update([1, 10, 100])\n        m1.update([1, 10, 100])\n        assert m0_div_m1.compute() == 0\n        m0.update([2, 20, 200])\n        m1.update([2, 20, 200])\n        assert m0_div_m1.compute() == 0\n\n        m2_div_2 = m2.__div__(2)\n        m2.update([1, 10, 100])\n        assert m2_div_2.compute() == 50\n\n        m2_div_2 = 200 / m2\n        m2.update([1, 10, 100])\n        assert m2_div_2.compute() == 2\n\n    # __truediv__\n    m0_truediv_m1 = m0.__truediv__(m1)\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    assert m0_truediv_m1.compute() == approx(0.1)\n    m0.update([2, 20, 200])\n    m1.update([2, 20, 200])\n    assert m0_truediv_m1.compute() == approx(0.1)\n\n    m2_truediv_2 = m2.__truediv__(2)\n    m2.update([1, 10, 100])\n    assert m2_truediv_2.compute() == approx(50.0)\n\n    m2_truediv_2 = m2.__rtruediv__(200)\n    m2.update([1, 10, 100])\n    assert m2_truediv_2.compute() == approx(2.0)\n\n    # __floordiv__\n    m0_floordiv_m1 = m0 // m1\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    assert m0_floordiv_m1.compute() == 0\n    m0.update([2, 20, 200])\n    m1.update([2, 20, 200])\n    assert m0_floordiv_m1.compute() == 0\n\n    m2_floordiv_2 = m2 // 2\n    m2.update([1, 10, 100])\n    assert m2_floordiv_2.compute() == 50\n\n\ndef test_attach():\n    class CountMetric(Metric):\n        def __init__(self, value):\n            self.reset_count = 0\n            super(CountMetric, self).__init__()\n            self.reset_count = 0\n            self.compute_count = 0\n            self.update_count = 0\n            self.value = value\n\n        def reset(self):\n            self.reset_count += 1\n\n        def compute(self):\n            self.compute_count += 1\n            return self.value\n\n        def update(self, output):\n            self.update_count += 1\n\n    def process_function(*args, **kwargs):\n        return 1\n\n    engine = Engine(process_function)\n    m1 = CountMetric(123)\n    m2 = CountMetric(456)\n    m1.attach(engine, ""m1"")\n    m2.attach(engine, ""m2_1"")\n    m2.attach(engine, ""m2_2"")\n    engine.run(range(10), 5)\n\n    assert engine.state.metrics[""m1""] == 123\n    assert engine.state.metrics[""m2_1""] == 456\n    assert engine.state.metrics[""m2_2""] == 456\n\n    assert m1.reset_count == 5\n    assert m1.compute_count == 5\n    assert m1.update_count == 50\n\n    assert m2.reset_count == 5\n    assert m2.compute_count == 10\n    assert m2.update_count == 50\n\n    assert m1.is_attached(engine)\n    assert m2.is_attached(engine)\n\n\ndef test_detach():\n    class DummyMetric(Metric):\n        _required_output_keys = None\n\n        def reset(self):\n            pass\n\n        def compute(self):\n            pass\n\n        def update(self, output):\n            pass\n\n    def process_function(*args, **kwargs):\n        return 1\n\n    engine = Engine(process_function)\n    m1 = DummyMetric()\n    m2 = DummyMetric()\n    m1.attach(engine, ""m1"")\n    m2.attach(engine, ""m2_1"")\n    m2.attach(engine, ""m2_2"")\n    m1.detach(engine)\n    m2.detach(engine)\n    engine.run(range(10), 5)\n\n    assert ""m1"" not in engine.state.metrics\n    assert ""m2_1"" not in engine.state.metrics\n    assert ""m2_2"" not in engine.state.metrics\n\n    assert not m1.is_attached(engine)\n    assert not m2.is_attached(engine)\n\n\ndef test_integration():\n    np.random.seed(1)\n\n    n_iters = 10\n    batch_size = 10\n    n_classes = 10\n\n    y_true = np.arange(0, n_iters * batch_size, dtype=""int64"") % n_classes\n    y_pred = 0.2 * np.random.rand(n_iters * batch_size, n_classes)\n    for i in range(n_iters * batch_size):\n        if np.random.rand() > 0.4:\n            y_pred[i, y_true[i]] = 1.0\n        else:\n            j = np.random.randint(0, n_classes)\n            y_pred[i, j] = 0.7\n\n    y_true_batch_values = iter(y_true.reshape(n_iters, batch_size))\n    y_pred_batch_values = iter(y_pred.reshape(n_iters, batch_size, n_classes))\n\n    def update_fn(engine, batch):\n        y_true_batch = next(y_true_batch_values)\n        y_pred_batch = next(y_pred_batch_values)\n        return torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    evaluator = Engine(update_fn)\n\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n    F1 = precision * recall * 2 / (precision + recall)\n\n    precision.attach(evaluator, ""precision"")\n    recall.attach(evaluator, ""recall"")\n    F1.attach(evaluator, ""f1"")\n\n    data = list(range(n_iters))\n    state = evaluator.run(data, max_epochs=1)\n\n    precision_true = precision_score(y_true, np.argmax(y_pred, axis=-1), average=None)\n    recall_true = recall_score(y_true, np.argmax(y_pred, axis=-1), average=None)\n    f1_true = f1_score(y_true, np.argmax(y_pred, axis=-1), average=None)\n\n    precision = state.metrics[""precision""].numpy()\n    recall = state.metrics[""recall""].numpy()\n    f1 = state.metrics[""f1""].numpy()\n\n    assert precision_true == approx(precision), ""{} vs {}"".format(precision_true, precision)\n    assert recall_true == approx(recall), ""{} vs {}"".format(recall_true, recall)\n    assert f1_true == approx(f1), ""{} vs {}"".format(f1_true, f1)\n\n\ndef test_abstract_class():\n    with raises(TypeError):\n        Metric()\n\n\ndef test_pytorch_operators():\n    def _test(composed_metric, metric_name, compute_true_value_fn):\n\n        metrics = {\n            metric_name: composed_metric,\n        }\n\n        y_pred = torch.rand(15, 10, 5).float()\n        y = torch.randint(0, 5, size=(15, 10)).long()\n\n        def update_fn(engine, batch):\n            y_pred, y = batch\n            return y_pred, y\n\n        validator = Engine(update_fn)\n\n        for name, metric in metrics.items():\n            metric.attach(validator, name)\n\n        def data(y_pred, y):\n            for i in range(y_pred.shape[0]):\n                yield (y_pred[i], y[i])\n\n        d = data(y_pred, y)\n        state = validator.run(d, max_epochs=1, epoch_length=y_pred.shape[0])\n\n        assert set(state.metrics.keys()) == set([metric_name,])\n        np_y_pred = np.argmax(y_pred.numpy(), axis=-1).ravel()\n        np_y = y.numpy().ravel()\n        assert state.metrics[metric_name] == approx(compute_true_value_fn(np_y_pred, np_y))\n\n    precision_1 = Precision(average=False)\n    precision_2 = Precision(average=False)\n    norm_summed_precision = (precision_1 + precision_2).norm(p=10)\n\n    def compute_true_norm_summed_precision(y_pred, y):\n        p1 = precision_score(y, y_pred, average=None)\n        p2 = precision_score(y, y_pred, average=None)\n        return np.linalg.norm(p1 + p2, ord=10)\n\n    _test(norm_summed_precision, ""mean summed precision"", compute_true_value_fn=compute_true_norm_summed_precision)\n\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n    sum_precision_recall = (precision + recall).sum()\n\n    def compute_sum_precision_recall(y_pred, y):\n        p = precision_score(y, y_pred, average=None)\n        r = recall_score(y, y_pred, average=None)\n        return np.sum(p + r)\n\n    _test(sum_precision_recall, ""sum precision recall"", compute_true_value_fn=compute_sum_precision_recall)\n\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n    f1 = (precision * recall * 2 / (precision + recall + 1e-20)).mean()\n\n    def compute_f1(y_pred, y):\n        f1 = f1_score(y, y_pred, average=""macro"")\n        return f1\n\n    _test(f1, ""f1"", compute_true_value_fn=compute_f1)\n\n\ndef test_indexing_metric():\n    def _test(ignite_metric, sklearn_metic, sklearn_args, index, num_classes=5):\n        y_pred = torch.rand(15, 10, num_classes).float()\n        y = torch.randint(0, num_classes, size=(15, 10)).long()\n\n        def update_fn(engine, batch):\n            y_pred, y = batch\n            return y_pred, y\n\n        metrics = {""metric"": ignite_metric[index], ""metric_wo_index"": ignite_metric}\n\n        validator = Engine(update_fn)\n\n        for name, metric in metrics.items():\n            metric.attach(validator, name)\n\n        def data(y_pred, y):\n            for i in range(y_pred.shape[0]):\n                yield (y_pred[i], y[i])\n\n        d = data(y_pred, y)\n        state = validator.run(d, max_epochs=1, epoch_length=y_pred.shape[0])\n\n        sklearn_output = sklearn_metic(\n            y.view(-1).numpy(), y_pred.view(-1, num_classes).argmax(dim=1).numpy(), **sklearn_args\n        )\n\n        assert (state.metrics[""metric_wo_index""][index] == state.metrics[""metric""]).all()\n        assert np.allclose(state.metrics[""metric""].numpy(), sklearn_output)\n\n    num_classes = 5\n\n    labels = list(range(0, num_classes, 2))\n    _test(Precision(), precision_score, {""labels"": labels, ""average"": None}, index=labels)\n    labels = list(range(num_classes - 1, 0, -2))\n    _test(Precision(), precision_score, {""labels"": labels, ""average"": None}, index=labels)\n    labels = [1]\n    _test(Precision(), precision_score, {""labels"": labels, ""average"": None}, index=labels)\n\n    labels = list(range(0, num_classes, 2))\n    _test(Recall(), recall_score, {""labels"": labels, ""average"": None}, index=labels)\n    labels = list(range(num_classes - 1, 0, -2))\n    _test(Recall(), recall_score, {""labels"": labels, ""average"": None}, index=labels)\n    labels = [1]\n    _test(Recall(), recall_score, {""labels"": labels, ""average"": None}, index=labels)\n\n    # np.ix_ is used to allow for a 2D slice of a matrix. This is required to get accurate result from\n    # ConfusionMatrix. ConfusionMatrix must be sliced the same row-wise and column-wise.\n    labels = list(range(0, num_classes, 2))\n    _test(ConfusionMatrix(num_classes), confusion_matrix, {""labels"": labels}, index=np.ix_(labels, labels))\n    labels = list(range(num_classes - 1, 0, -2))\n    _test(ConfusionMatrix(num_classes), confusion_matrix, {""labels"": labels}, index=np.ix_(labels, labels))\n    labels = [1]\n    _test(ConfusionMatrix(num_classes), confusion_matrix, {""labels"": labels}, index=np.ix_(labels, labels))\n\n\nclass DummyMetric2(Metric):\n    @reinit__is_reduced\n    def reset(self):\n        pass\n\n    def compute(self):\n        pass\n\n    @reinit__is_reduced\n    def update(self, output):\n        pass\n\n\ndef _test_distrib_sync_all_reduce_decorator(device):\n\n    from ignite.metrics.metric import sync_all_reduce, reinit__is_reduced\n\n    class DummyMetric(Metric):\n        @reinit__is_reduced\n        def reset(self):\n            self.a = torch.tensor([0.0, 1.0, 2.0, 3.0], device=self._device, requires_grad=False)\n            self.a_nocomp = self.a.clone().to(""cpu"")\n            self.b = torch.tensor(1.0, dtype=torch.float64, device=self._device, requires_grad=False)\n            self.b_nocomp = self.b.clone().to(""cpu"")\n            self.c = 0.0\n            self.c_nocomp = self.c\n            self.n = 0\n            self.n_nocomp = self.n\n\n        @sync_all_reduce(""a"", ""b"", ""c"", ""n"")\n        def compute(self):\n            assert (self.a.cpu() == (self.a_nocomp + 10) * idist.get_world_size()).all()\n            assert (self.b.cpu() == (self.b_nocomp - 5) * idist.get_world_size()).all()\n            assert self.c == pytest.approx((self.c_nocomp + 1.23456) * idist.get_world_size())\n            assert self.n == (self.n_nocomp + 1) * idist.get_world_size()\n\n        @reinit__is_reduced\n        def update(self, output):\n            self.n += 1\n            self.c += 1.23456\n            self.a += 10.0\n            self.b -= 5.0\n\n    m = DummyMetric(device=device)\n    m.update(None)\n    m.compute()\n    # check if can call compute multiple times without all reduce invocation\n    m.compute()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(distributed_context_single_node_nccl[""local_rank""])\n    _test_distrib_sync_all_reduce_decorator(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_sync_all_reduce_decorator(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_sync_all_reduce_decorator(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_sync_all_reduce_decorator(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_sync_all_reduce_decorator(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_sync_all_reduce_decorator(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n\n\ndef test_completed():\n    class DummyMetric(Metric):\n        def reset(self):\n            pass\n\n        def compute(self):\n            pass\n\n        def update(self, output):\n            pass\n\n    m = DummyMetric()\n\n    # tensor\n    engine = MagicMock(state=State(metrics={}))\n    m.compute = MagicMock(return_value=torch.tensor(1.0))\n    m.completed(engine, ""metric"")\n    assert engine.state.metrics == {""metric"": 1.0}\n    assert isinstance(engine.state.metrics[""metric""], numbers.Number)\n\n    # mapping\n    engine = MagicMock(state=State(metrics={}))\n    metrics = {""foo"": 1, ""bar"": torch.tensor(2.0), ""baz"": {""qux"": ""quux""}}\n    m.compute = MagicMock(return_value=metrics)\n    m.completed(engine, ""metric"")\n    assert engine.state.metrics == metrics\n\n    # other\n    engine = MagicMock(state=State(metrics={}))\n    m.compute = MagicMock(return_value=""foo"")\n    m.completed(engine, ""metric"")\n    assert engine.state.metrics == {""metric"": ""foo""}\n\n\ndef test_usage_exception():\n    engine = Engine(lambda e, b: b)\n    m = DummyMetric2()\n    with pytest.raises(TypeError, match=r""Unhandled usage type""):\n        m.attach(engine, ""dummy"", usage=1)\n    with pytest.raises(ValueError, match=r""usage should be \'EpochWise.usage_name\' or \'BatchWise.usage_name\'""):\n        m.attach(engine, ""dummy"", usage=""fake"")\n\n\ndef test_epochwise_usage():\n    class MyMetric(Metric):\n        def __init__(self):\n            super(MyMetric, self).__init__()\n            self.value = []\n\n        def reset(self):\n            self.value = []\n\n        def compute(self):\n            return self.value\n\n        def update(self, output):\n            self.value.append(output)\n\n    def test(usage):\n        engine = Engine(lambda e, b: b)\n\n        m = MyMetric()\n\n        m.attach(engine, ""ewm"", usage=usage)\n\n        @engine.on(Events.EPOCH_COMPLETED)\n        def _():\n            ewm = engine.state.metrics[""ewm""]\n            assert len(ewm) == 3\n            assert ewm == [0, 1, 2]\n\n        engine.run([0, 1, 2], max_epochs=10)\n        m.detach(engine, usage=usage)\n\n    test(""epoch_wise"")\n    test(EpochWise.usage_name)\n    test(EpochWise())\n\n\ndef test_batchwise_usage():\n    class MyMetric(Metric):\n        def __init__(self):\n            super(MyMetric, self).__init__()\n            self.value = []\n\n        def reset(self):\n            self.value = []\n\n        def compute(self):\n            return self.value\n\n        def update(self, output):\n            self.value.append(output)\n\n    def test(usage):\n        engine = Engine(lambda e, b: b)\n\n        m = MyMetric()\n\n        m.attach(engine, ""bwm"", usage=usage)\n\n        @engine.on(Events.ITERATION_COMPLETED)\n        def _():\n            bwm = engine.state.metrics[""bwm""]\n            assert len(bwm) == 1\n            assert bwm[0] == (engine.state.iteration - 1) % 3\n\n        engine.run([0, 1, 2], max_epochs=10)\n        m.detach(engine, usage=usage)\n\n    test(""batch_wise"")\n    test(BatchWise.usage_name)\n    test(BatchWise())\n\n\ndef test_batchfiltered_usage():\n    class MyMetric(Metric):\n        def __init__(self):\n            super(MyMetric, self).__init__()\n            self.value = []\n\n        def reset(self):\n            self.value = []\n\n        def compute(self):\n            return self.value\n\n        def update(self, output):\n            self.value.append(output)\n\n    engine = Engine(lambda e, b: b)\n\n    m = MyMetric()\n\n    usage = BatchFiltered(every=2)\n\n    m.attach(engine, ""bfm"", usage=usage)\n\n    @engine.on(Events.EPOCH_COMPLETED)\n    def _():\n        bfm = engine.state.metrics[""bfm""]\n        print(len(bfm), bfm[0])\n        assert len(bfm) == 2\n        assert bfm[0] == 1\n\n    engine.run([0, 1, 2, 3], max_epochs=10)\n'"
tests/ignite/metrics/test_metrics_lambda.py,15,"b'import os\n\nimport numpy as np\nimport pytest\nimport torch\nfrom pytest import approx\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine\nfrom ignite.metrics import Metric, MetricsLambda, Precision, Recall\n\n\nclass ListGatherMetric(Metric):\n    def __init__(self, index):\n        super(ListGatherMetric, self).__init__()\n        self.index = index\n\n    def reset(self):\n        self.list_ = None\n\n    def update(self, output):\n        self.list_ = output\n\n    def compute(self):\n        return self.list_[self.index]\n\n\ndef test_metrics_lambda():\n    m0 = ListGatherMetric(0)\n    m1 = ListGatherMetric(1)\n    m2 = ListGatherMetric(2)\n\n    def process_function(engine, data):\n        return data\n\n    engine = Engine(process_function)\n\n    def plus(this, other):\n        return this + other\n\n    m0_plus_m1 = MetricsLambda(plus, m0, other=m1)\n    m2_plus_2 = MetricsLambda(plus, m2, 2)\n    m0_plus_m1.attach(engine, ""m0_plus_m1"")\n    m2_plus_2.attach(engine, ""m2_plus_2"")\n\n    engine.run([[1, 10, 100]])\n    assert engine.state.metrics[""m0_plus_m1""] == 11\n    assert engine.state.metrics[""m2_plus_2""] == 102\n    engine.run([[2, 20, 200]])\n    assert engine.state.metrics[""m0_plus_m1""] == 22\n    assert engine.state.metrics[""m2_plus_2""] == 202\n\n    # metrics are partially attached\n    assert not m0.is_attached(engine)\n    assert not m1.is_attached(engine)\n    assert not m2.is_attached(engine)\n\n    # a dependency is detached\n    m0.detach(engine)\n    # so the lambda metric is too\n    assert not m0_plus_m1.is_attached(engine)\n    # the lambda is attached again\n    m0_plus_m1.attach(engine, ""m0_plus_m1"")\n    assert m0_plus_m1.is_attached(engine)\n    # metrics are always partially attached\n    assert not m0.is_attached(engine)\n    m0_plus_m1.detach(engine)\n    assert not m0_plus_m1.is_attached(engine)\n    # detached (and no longer partially attached)\n    assert not m0.is_attached(engine)\n\n\ndef test_metrics_lambda_reset():\n    m0 = ListGatherMetric(0)\n    m1 = ListGatherMetric(1)\n    m2 = ListGatherMetric(2)\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    m2.update([1, 10, 100])\n\n    def fn(x, y, z, t):\n        return 1\n\n    m = MetricsLambda(fn, m0, m1, z=m2, t=0)\n\n    # initiating a new instance of MetricsLambda must reset\n    # its argument metrics\n    assert m0.list_ is None\n    assert m1.list_ is None\n    assert m2.list_ is None\n\n    m0.update([1, 10, 100])\n    m1.update([1, 10, 100])\n    m2.update([1, 10, 100])\n    m.reset()\n    assert m0.list_ is None\n    assert m1.list_ is None\n    assert m2.list_ is None\n\n\ndef test_integration():\n    np.random.seed(1)\n\n    n_iters = 10\n    batch_size = 10\n    n_classes = 10\n\n    y_true = np.arange(0, n_iters * batch_size, dtype=""int64"") % n_classes\n    y_pred = 0.2 * np.random.rand(n_iters * batch_size, n_classes)\n    for i in range(n_iters * batch_size):\n        if np.random.rand() > 0.4:\n            y_pred[i, y_true[i]] = 1.0\n        else:\n            j = np.random.randint(0, n_classes)\n            y_pred[i, j] = 0.7\n\n    y_true_batch_values = iter(y_true.reshape(n_iters, batch_size))\n    y_pred_batch_values = iter(y_pred.reshape(n_iters, batch_size, n_classes))\n\n    def update_fn(engine, batch):\n        y_true_batch = next(y_true_batch_values)\n        y_pred_batch = next(y_pred_batch_values)\n        return torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    evaluator = Engine(update_fn)\n\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n\n    def Fbeta(r, p, beta):\n        return torch.mean((1 + beta ** 2) * p * r / (beta ** 2 * p + r)).item()\n\n    F1 = MetricsLambda(Fbeta, recall, precision, 1)\n\n    precision.attach(evaluator, ""precision"")\n    recall.attach(evaluator, ""recall"")\n    F1.attach(evaluator, ""f1"")\n\n    data = list(range(n_iters))\n    state = evaluator.run(data, max_epochs=1)\n\n    precision_true = precision_score(y_true, np.argmax(y_pred, axis=-1), average=None)\n    recall_true = recall_score(y_true, np.argmax(y_pred, axis=-1), average=None)\n    f1_true = f1_score(y_true, np.argmax(y_pred, axis=-1), average=""macro"")\n\n    precision = state.metrics[""precision""].numpy()\n    recall = state.metrics[""recall""].numpy()\n\n    assert precision_true == approx(precision), ""{} vs {}"".format(precision_true, precision)\n    assert recall_true == approx(recall), ""{} vs {}"".format(recall_true, recall)\n    assert f1_true == approx(state.metrics[""f1""]), ""{} vs {}"".format(f1_true, state.metrics[""f1""])\n\n\ndef test_integration_ingredients_not_attached():\n    np.random.seed(1)\n\n    n_iters = 10\n    batch_size = 10\n    n_classes = 10\n\n    y_true = np.arange(0, n_iters * batch_size, dtype=""int64"") % n_classes\n    y_pred = 0.2 * np.random.rand(n_iters * batch_size, n_classes)\n    for i in range(n_iters * batch_size):\n        if np.random.rand() > 0.4:\n            y_pred[i, y_true[i]] = 1.0\n        else:\n            j = np.random.randint(0, n_classes)\n            y_pred[i, j] = 0.7\n\n    y_true_batch_values = iter(y_true.reshape(n_iters, batch_size))\n    y_pred_batch_values = iter(y_pred.reshape(n_iters, batch_size, n_classes))\n\n    def update_fn(engine, batch):\n        y_true_batch = next(y_true_batch_values)\n        y_pred_batch = next(y_pred_batch_values)\n        return torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    evaluator = Engine(update_fn)\n\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n\n    def Fbeta(r, p, beta):\n        return torch.mean((1 + beta ** 2) * p * r / (beta ** 2 * p + r)).item()\n\n    F1 = MetricsLambda(Fbeta, recall, precision, 1)\n    F1.attach(evaluator, ""f1"")\n\n    data = list(range(n_iters))\n    state = evaluator.run(data, max_epochs=1)\n    f1_true = f1_score(y_true, np.argmax(y_pred, axis=-1), average=""macro"")\n    assert f1_true == approx(state.metrics[""f1""]), ""{} vs {}"".format(f1_true, state.metrics[""f1""])\n\n\ndef test_state_metrics():\n\n    y_pred = torch.randint(0, 2, size=(15, 10, 4)).float()\n    y = torch.randint(0, 2, size=(15, 10, 4)).long()\n\n    def update_fn(engine, batch):\n        y_pred, y = batch\n        return y_pred, y\n\n    evaluator = Engine(update_fn)\n\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n    F1 = precision * recall * 2 / (precision + recall + 1e-20)\n    F1 = MetricsLambda(lambda t: torch.mean(t).item(), F1)\n\n    precision.attach(evaluator, ""precision"")\n    recall.attach(evaluator, ""recall"")\n    F1.attach(evaluator, ""f1"")\n\n    def data(y_pred, y):\n        for i in range(y_pred.shape[0]):\n            yield (y_pred[i], y[i])\n\n    d = data(y_pred, y)\n    state = evaluator.run(d, max_epochs=1, epoch_length=y_pred.shape[0])\n\n    assert set(state.metrics.keys()) == set([""precision"", ""recall"", ""f1""])\n\n\ndef test_state_metrics_ingredients_not_attached():\n\n    y_pred = torch.randint(0, 2, size=(15, 10, 4)).float()\n    y = torch.randint(0, 2, size=(15, 10, 4)).long()\n\n    def update_fn(engine, batch):\n        y_pred, y = batch\n        return y_pred, y\n\n    evaluator = Engine(update_fn)\n\n    precision = Precision(average=False)\n    recall = Recall(average=False)\n    F1 = precision * recall * 2 / (precision + recall + 1e-20)\n    F1 = MetricsLambda(lambda t: torch.mean(t).item(), F1)\n\n    F1.attach(evaluator, ""F1"")\n\n    def data(y_pred, y):\n        for i in range(y_pred.shape[0]):\n            yield (y_pred[i], y[i])\n\n    d = data(y_pred, y)\n    state = evaluator.run(d, max_epochs=1, epoch_length=y_pred.shape[0])\n\n    assert set(state.metrics.keys()) == set([""F1""])\n\n\ndef test_recursive_attachment():\n    def _test(composed_metric, metric_name, compute_true_value_fn):\n\n        metrics = {\n            metric_name: composed_metric,\n        }\n\n        y_pred = torch.randint(0, 2, size=(15, 10, 4)).float()\n        y = torch.randint(0, 2, size=(15, 10, 4)).long()\n\n        def update_fn(engine, batch):\n            y_pred, y = batch\n            return y_pred, y\n\n        validator = Engine(update_fn)\n\n        for name, metric in metrics.items():\n            metric.attach(validator, name)\n\n        def data(y_pred, y):\n            for i in range(y_pred.shape[0]):\n                yield (y_pred[i], y[i])\n\n        d = data(y_pred, y)\n        state = validator.run(d, max_epochs=1, epoch_length=y_pred.shape[0])\n\n        assert set(state.metrics.keys()) == set([metric_name,])\n        np_y_pred = y_pred.numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert state.metrics[metric_name] == approx(compute_true_value_fn(np_y_pred, np_y))\n\n    precision_1 = Precision()\n    precision_2 = Precision()\n    summed_precision = precision_1 + precision_2\n\n    def compute_true_summed_precision(y_pred, y):\n        p1 = precision_score(y, y_pred)\n        p2 = precision_score(y, y_pred)\n        return p1 + p2\n\n    _test(summed_precision, ""summed precision"", compute_true_value_fn=compute_true_summed_precision)\n\n    precision_1 = Precision()\n    precision_2 = Precision()\n    mean_precision = (precision_1 + precision_2) / 2\n\n    def compute_true_mean_precision(y_pred, y):\n        p1 = precision_score(y, y_pred)\n        p2 = precision_score(y, y_pred)\n        return (p1 + p2) * 0.5\n\n    _test(mean_precision, ""mean precision"", compute_true_value_fn=compute_true_mean_precision)\n\n    precision_1 = Precision()\n    precision_2 = Precision()\n    some_metric = 2.0 + 0.2 * (precision_1 * precision_2 + precision_1 - precision_2) ** 0.5\n\n    def compute_true_somemetric(y_pred, y):\n        p1 = precision_score(y, y_pred)\n        p2 = precision_score(y, y_pred)\n        return 2.0 + 0.2 * (p1 * p2 + p1 - p2) ** 0.5\n\n    _test(some_metric, ""some metric"", compute_true_somemetric)\n\n\ndef _test_distrib_integration(device):\n\n    rank = idist.get_rank()\n    np.random.seed(12)\n\n    n_iters = 10\n    batch_size = 10\n    n_classes = 10\n\n    def _test():\n        y_true = np.arange(0, n_iters * batch_size * idist.get_world_size(), dtype=""int64"") % n_classes\n        y_pred = 0.2 * np.random.rand(n_iters * batch_size * idist.get_world_size(), n_classes)\n        for i in range(n_iters * batch_size * idist.get_world_size()):\n            if np.random.rand() > 0.4:\n                y_pred[i, y_true[i]] = 1.0\n            else:\n                j = np.random.randint(0, n_classes)\n                y_pred[i, j] = 0.7\n\n        y_true = y_true.reshape(n_iters * idist.get_world_size(), batch_size)\n        y_pred = y_pred.reshape(n_iters * idist.get_world_size(), batch_size, n_classes)\n\n        def update_fn(engine, i):\n            y_true_batch = y_true[i + rank * n_iters, ...]\n            y_pred_batch = y_pred[i + rank * n_iters, ...]\n            return torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n        evaluator = Engine(update_fn)\n\n        precision = Precision(average=False, device=device)\n        recall = Recall(average=False, device=device)\n\n        def Fbeta(r, p, beta):\n            return torch.mean((1 + beta ** 2) * p * r / (beta ** 2 * p + r)).item()\n\n        F1 = MetricsLambda(Fbeta, recall, precision, 1)\n        F1.attach(evaluator, ""f1"")\n\n        another_f1 = (1.0 + precision * recall * 2 / (precision + recall + 1e-20)).mean().item()\n        another_f1.attach(evaluator, ""ff1"")\n\n        data = list(range(n_iters))\n        state = evaluator.run(data, max_epochs=1)\n\n        assert ""f1"" in state.metrics\n        assert ""ff1"" in state.metrics\n        f1_true = f1_score(y_true.ravel(), np.argmax(y_pred.reshape(-1, n_classes), axis=-1), average=""macro"")\n        assert f1_true == approx(state.metrics[""f1""])\n        assert 1.0 + f1_true == approx(state.metrics[""ff1""])\n\n    for _ in range(5):\n        _test()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(local_rank, distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_precision.py,127,"b'import os\nimport warnings\n\nimport pytest\nimport torch\nfrom sklearn.exceptions import UndefinedMetricWarning\nfrom sklearn.metrics import precision_score\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import Precision\n\ntorch.manual_seed(12)\n\n\ndef test_no_update():\n    precision = Precision()\n    with pytest.raises(NotComputableError):\n        precision.compute()\n\n    precision = Precision(is_multilabel=True, average=True)\n    with pytest.raises(NotComputableError):\n        precision.compute()\n\n\ndef test_binary_wrong_inputs():\n    pr = Precision()\n\n    with pytest.raises(ValueError):\n        # y has not only 0 or 1 values\n        pr.update((torch.randint(0, 2, size=(10,)).long(), torch.arange(0, 10).long()))\n\n    with pytest.raises(ValueError):\n        # y_pred values are not thresholded to 0, 1 values\n        pr.update((torch.rand(10,), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        pr.update((torch.randint(0, 2, size=(10,)).long(), torch.randint(0, 2, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        pr.update((torch.randint(0, 2, size=(10, 5, 6)).long(), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        pr.update((torch.randint(0, 2, size=(10,)).long(), torch.randint(0, 2, size=(10, 5, 6)).long()))\n\n\ndef test_binary_input_N():\n    # Binary accuracy on input of shape (N, 1) or (N, )\n\n    def _test(average):\n        pr = Precision(average=average)\n        y_pred = torch.randint(0, 2, size=(10,))\n        y = torch.randint(0, 2, size=(10,)).long()\n        pr.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(10,))\n        y = torch.randint(0, 2, size=(10,)).long()\n        pr.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.Tensor([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.51])\n        y_pred = torch.round(y_pred)\n        y = torch.randint(0, 2, size=(10,)).long()\n        pr.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(100,))\n        y = torch.randint(0, 2, size=(100,)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_binary_input_NL():\n    # Binary accuracy on input of shape (N, L)\n\n    def _test(average):\n        pr = Precision(average=average)\n\n        y_pred = torch.randint(0, 2, size=(10, 5))\n        y = torch.randint(0, 2, size=(10, 5)).long()\n        pr.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(10, 1, 5))\n        y = torch.randint(0, 2, size=(10, 1, 5)).long()\n        pr.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(100, 1, 5))\n        y = torch.randint(0, 2, size=(100, 1, 5)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_binary_input_NHW():\n    # Binary accuracy on input of shape (N, H, W)\n\n    def _test(average):\n        pr = Precision(average=average)\n\n        y_pred = torch.randint(0, 2, size=(10, 12, 10))\n        y = torch.randint(0, 2, size=(10, 12, 10)).long()\n        pr.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(10, 1, 12, 10))\n        y = torch.randint(0, 2, size=(10, 1, 12, 10)).long()\n        pr.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(100, 12, 10))\n        y = torch.randint(0, 2, size=(100, 12, 10)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert pr._type == ""binary""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        assert precision_score(np_y, np_y_pred, average=""binary"") == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_multiclass_wrong_inputs():\n    pr = Precision()\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        pr.update((torch.rand(10, 5, 4), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        pr.update((torch.rand(10, 5, 6), torch.randint(0, 5, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        pr.update((torch.rand(10), torch.randint(0, 5, size=(10, 5, 6)).long()))\n\n    pr = Precision(average=True)\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        pr.update((torch.rand(10, 5), torch.randint(0, 5, size=(10,)).long()))\n        pr.update((torch.rand(10, 6), torch.randint(0, 5, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        pr.update((torch.rand(10, 5, 12, 14), torch.randint(0, 5, size=(10, 12, 14)).long()))\n        pr.update((torch.rand(10, 6, 12, 14), torch.randint(0, 5, size=(10, 12, 14)).long()))\n\n    pr = Precision(average=False)\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        pr.update((torch.rand(10, 5), torch.randint(0, 5, size=(10,)).long()))\n        pr.update((torch.rand(10, 6), torch.randint(0, 5, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        pr.update((torch.rand(10, 5, 12, 14), torch.randint(0, 5, size=(10, 12, 14)).long()))\n        pr.update((torch.rand(10, 6, 12, 14), torch.randint(0, 5, size=(10, 12, 14)).long()))\n\n\ndef test_multiclass_input_N():\n    # Multiclass input data of shape (N, ) and (N, C)\n\n    def _test(average):\n        pr = Precision(average=average)\n        y_pred = torch.rand(20, 6)\n        y = torch.randint(0, 6, size=(20,)).long()\n        pr.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.rand(10, 4)\n        y = torch.randint(0, 4, size=(10,)).long()\n        pr.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n        # 2-classes\n        pr.reset()\n        y_pred = torch.rand(10, 2)\n        y = torch.randint(0, 2, size=(10,)).long()\n        pr.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.rand(100, 3)\n        y = torch.randint(0, 3, size=(100,)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        num_classes = y_pred.shape[1]\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_multiclass_input_NL():\n    # Multiclass input data of shape (N, L) and (N, C, L)\n\n    def _test(average):\n        pr = Precision(average=average)\n\n        y_pred = torch.rand(10, 5, 8)\n        y = torch.randint(0, 5, size=(10, 8)).long()\n        pr.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.rand(15, 10, 8)\n        y = torch.randint(0, 10, size=(15, 8)).long()\n        pr.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.rand(100, 8, 12)\n        y = torch.randint(0, 8, size=(100, 12)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        num_classes = y_pred.shape[1]\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_multiclass_input_NHW():\n    # Multiclass input data of shape (N, H, W, ...) and (N, C, H, W, ...)\n\n    def _test(average):\n        pr = Precision(average=average)\n\n        y_pred = torch.rand(10, 5, 18, 16)\n        y = torch.randint(0, 5, size=(10, 18, 16)).long()\n        pr.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.rand(10, 7, 20, 12)\n        y = torch.randint(0, 7, size=(10, 20, 12)).long()\n        pr.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.rand(100, 8, 12, 14)\n        y = torch.randint(0, 8, size=(100, 12, 14)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        num_classes = y_pred.shape[1]\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        assert pr._type == ""multiclass""\n        assert isinstance(pr.compute(), float if average else torch.Tensor)\n        pr_compute = pr.compute() if average else pr.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = precision_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_multilabel_wrong_inputs():\n    pr = Precision(average=True, is_multilabel=True)\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        pr.update((torch.randint(0, 2, size=(10,)), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible y_pred\n        pr.update((torch.rand(10, 5), torch.randint(0, 2, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible y\n        pr.update((torch.randint(0, 5, size=(10, 5, 6)), torch.rand(10)))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        pr.update((torch.randint(0, 2, size=(20, 5)), torch.randint(0, 2, size=(20, 5)).long()))\n        pr.update((torch.randint(0, 2, size=(20, 6)), torch.randint(0, 2, size=(20, 6)).long()))\n\n\ndef to_numpy_multilabel(y):\n    # reshapes input array to (N x ..., C)\n    y = y.transpose(1, 0).cpu().numpy()\n    num_classes = y.shape[0]\n    y = y.reshape((num_classes, -1)).transpose(1, 0)\n    return y\n\n\ndef test_multilabel_input_NC():\n    def _test(average):\n        pr = Precision(average=average, is_multilabel=True)\n\n        y_pred = torch.randint(0, 2, size=(20, 5))\n        y = torch.randint(0, 2, size=(20, 5)).long()\n        pr.update((y_pred, y))\n        np_y_pred = y_pred.numpy()\n        np_y = y.numpy()\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(10, 4))\n        y = torch.randint(0, 2, size=(10, 4)).long()\n        pr.update((y_pred, y))\n        np_y_pred = y_pred.numpy()\n        np_y = y.numpy()\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(100, 4))\n        y = torch.randint(0, 2, size=(100, 4)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy()\n        np_y_pred = y_pred.numpy()\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n    pr1 = Precision(is_multilabel=True, average=True)\n    pr2 = Precision(is_multilabel=True, average=False)\n    y_pred = torch.randint(0, 2, size=(10, 4, 20, 23))\n    y = torch.randint(0, 2, size=(10, 4, 20, 23)).long()\n    pr1.update((y_pred, y))\n    pr2.update((y_pred, y))\n    assert pr1.compute() == pytest.approx(pr2.compute().mean().item())\n\n\ndef test_multilabel_input_NCL():\n    def _test(average):\n        pr = Precision(average=average, is_multilabel=True)\n\n        y_pred = torch.randint(0, 2, size=(10, 5, 10))\n        y = torch.randint(0, 2, size=(10, 5, 10)).long()\n        pr.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(15, 4, 10))\n        y = torch.randint(0, 2, size=(15, 4, 10)).long()\n        pr.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(100, 4, 12))\n        y = torch.randint(0, 2, size=(100, 4, 12)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = to_numpy_multilabel(y)\n        np_y_pred = to_numpy_multilabel(y_pred)\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n    pr1 = Precision(is_multilabel=True, average=True)\n    pr2 = Precision(is_multilabel=True, average=False)\n    y_pred = torch.randint(0, 2, size=(10, 4, 20, 23))\n    y = torch.randint(0, 2, size=(10, 4, 20, 23)).long()\n    pr1.update((y_pred, y))\n    pr2.update((y_pred, y))\n    assert pr1.compute() == pytest.approx(pr2.compute().mean().item())\n\n\ndef test_multilabel_input_NCHW():\n    def _test(average):\n        pr = Precision(average=average, is_multilabel=True)\n\n        y_pred = torch.randint(0, 2, size=(10, 5, 18, 16))\n        y = torch.randint(0, 2, size=(10, 5, 18, 16)).long()\n        pr.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(10, 4, 20, 23))\n        y = torch.randint(0, 2, size=(10, 4, 20, 23)).long()\n        pr.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n        # Batched Updates\n        pr.reset()\n        y_pred = torch.randint(0, 2, size=(100, 5, 12, 14))\n        y = torch.randint(0, 2, size=(100, 5, 12, 14)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            pr.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = to_numpy_multilabel(y)\n        np_y_pred = to_numpy_multilabel(y_pred)\n        assert pr._type == ""multilabel""\n        pr_compute = pr.compute() if average else pr.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert precision_score(np_y, np_y_pred, average=""samples"") == pytest.approx(pr_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n    pr1 = Precision(is_multilabel=True, average=True)\n    pr2 = Precision(is_multilabel=True, average=False)\n    y_pred = torch.randint(0, 2, size=(10, 4, 20, 23))\n    y = torch.randint(0, 2, size=(10, 4, 20, 23)).long()\n    pr1.update((y_pred, y))\n    pr2.update((y_pred, y))\n    assert pr1.compute() == pytest.approx(pr2.compute().mean().item())\n\n\ndef test_incorrect_type():\n    # Tests changing of type during training\n\n    def _test(average):\n        pr = Precision(average=average)\n\n        y_pred = torch.softmax(torch.rand(4, 4), dim=1)\n        y = torch.ones(4).long()\n        pr.update((y_pred, y))\n\n        y_pred = torch.randint(0, 2, size=(4,))\n        y = torch.ones(4).long()\n\n        with pytest.raises(RuntimeError):\n            pr.update((y_pred, y))\n\n    _test(average=True)\n    _test(average=False)\n\n    pr1 = Precision(is_multilabel=True, average=True)\n    pr2 = Precision(is_multilabel=True, average=False)\n    y_pred = torch.randint(0, 2, size=(10, 4, 20, 23))\n    y = torch.randint(0, 2, size=(10, 4, 20, 23)).long()\n    pr1.update((y_pred, y))\n    pr2.update((y_pred, y))\n    assert pr1.compute() == pytest.approx(pr2.compute().mean().item())\n\n\ndef test_incorrect_y_classes():\n    def _test(average):\n        pr = Precision(average=average)\n\n        y_pred = torch.randint(0, 2, size=(10, 4)).float()\n        y = torch.randint(4, 5, size=(10,)).long()\n\n        with pytest.raises(ValueError):\n            pr.update((y_pred, y))\n\n    _test(average=True)\n    _test(average=False)\n\n\ndef _test_distrib_integration_multiclass(device):\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    def _test(average, n_epochs):\n        n_iters = 60\n        s = 16\n        n_classes = 7\n\n        offset = n_iters * s\n        y_true = torch.randint(0, n_classes, size=(offset * idist.get_world_size(),)).to(device)\n        y_preds = torch.rand(offset * idist.get_world_size(), n_classes).to(device)\n\n        def update(engine, i):\n            return (\n                y_preds[i * s + rank * offset : (i + 1) * s + rank * offset, :],\n                y_true[i * s + rank * offset : (i + 1) * s + rank * offset],\n            )\n\n        engine = Engine(update)\n\n        pr = Precision(average=average, device=device)\n        pr.attach(engine, ""pr"")\n\n        data = list(range(n_iters))\n        engine.run(data=data, max_epochs=n_epochs)\n\n        assert ""pr"" in engine.state.metrics\n        res = engine.state.metrics[""pr""]\n        if isinstance(res, torch.Tensor):\n            res = res.cpu().numpy()\n\n        true_res = precision_score(\n            y_true.cpu().numpy(), torch.argmax(y_preds, dim=1).cpu().numpy(), average=""macro"" if average else None\n        )\n\n        assert pytest.approx(res) == true_res\n\n    for _ in range(2):\n        _test(average=True, n_epochs=1)\n        _test(average=True, n_epochs=2)\n        _test(average=False, n_epochs=1)\n        _test(average=False, n_epochs=2)\n\n\ndef _test_distrib_integration_multilabel(device):\n\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    def _test(average, n_epochs):\n        n_iters = 60\n        s = 16\n        n_classes = 7\n\n        offset = n_iters * s\n        y_true = torch.randint(0, 2, size=(offset * idist.get_world_size(), n_classes, 6, 8)).to(device)\n        y_preds = torch.randint(0, 2, size=(offset * idist.get_world_size(), n_classes, 6, 8)).to(device)\n\n        def update(engine, i):\n            return (\n                y_preds[i * s + rank * offset : (i + 1) * s + rank * offset, ...],\n                y_true[i * s + rank * offset : (i + 1) * s + rank * offset, ...],\n            )\n\n        engine = Engine(update)\n\n        pr = Precision(average=average, is_multilabel=True, device=device)\n        pr.attach(engine, ""pr"")\n\n        data = list(range(n_iters))\n        engine.run(data=data, max_epochs=n_epochs)\n\n        assert ""pr"" in engine.state.metrics\n        res = engine.state.metrics[""pr""]\n        res2 = pr.compute()\n        if isinstance(res, torch.Tensor):\n            res = res.cpu().numpy()\n            res2 = res2.cpu().numpy()\n            assert (res == res2).all()\n        else:\n            assert res == res2\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            true_res = precision_score(\n                to_numpy_multilabel(y_true), to_numpy_multilabel(y_preds), average=""samples"" if average else None\n            )\n\n        assert pytest.approx(res) == true_res\n\n    for _ in range(2):\n        _test(average=True, n_epochs=1)\n        _test(average=True, n_epochs=2)\n\n    if idist.get_world_size() > 1:\n        with pytest.warns(\n            RuntimeWarning,\n            match=""Precision/Recall metrics do not work in distributed setting when ""\n            ""average=False and is_multilabel=True"",\n        ):\n            pr = Precision(average=False, is_multilabel=True, device=device)\n\n        y_pred = torch.randint(0, 2, size=(4, 3, 6, 8))\n        y = torch.randint(0, 2, size=(4, 3, 6, 8)).long()\n        pr.update((y_pred, y))\n        pr_compute1 = pr.compute()\n        pr_compute2 = pr.compute()\n        assert len(pr_compute1) == 4 * 6 * 8\n        assert (pr_compute1 == pr_compute2).all()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(local_rank, distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_recall.py,127,"b'import os\nimport warnings\n\nimport pytest\nimport torch\nfrom sklearn.exceptions import UndefinedMetricWarning\nfrom sklearn.metrics import recall_score\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import Recall\n\ntorch.manual_seed(12)\n\n\ndef test_no_update():\n    recall = Recall()\n    with pytest.raises(NotComputableError):\n        recall.compute()\n\n    recall = Recall(is_multilabel=True, average=True)\n    with pytest.raises(NotComputableError):\n        recall.compute()\n\n\ndef test_binary_wrong_inputs():\n    re = Recall()\n\n    with pytest.raises(ValueError):\n        # y has not only 0 or 1 values\n        re.update((torch.randint(0, 2, size=(10,)), torch.arange(0, 10).long()))\n\n    with pytest.raises(ValueError):\n        # y_pred values are not thresholded to 0, 1 values\n        re.update((torch.rand(10, 1), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        re.update((torch.randint(0, 2, size=(10,)), torch.randint(0, 2, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        re.update((torch.randint(0, 2, size=(10, 5, 6)), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        re.update((torch.randint(0, 2, size=(10,)), torch.randint(0, 2, size=(10, 5, 6)).long()))\n\n\ndef test_binary_input_N():\n    # Binary accuracy on input of shape (N, 1) or (N, )\n\n    def _test(average):\n        re = Recall(average=average)\n        y_pred = torch.randint(0, 2, size=(10,))\n        y = torch.randint(0, 2, size=(10,)).long()\n        re.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(10,))\n        y = torch.randint(0, 2, size=(10,)).long()\n        re.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.Tensor([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.51])\n        y_pred = torch.round(y_pred)\n        y = torch.randint(0, 2, size=(10,)).long()\n        re.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(100,))\n        y = torch.randint(0, 2, size=(100,)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_binary_input_NL():\n    # Binary accuracy on input of shape (N, L)\n\n    def _test(average):\n        re = Recall(average=average)\n\n        y_pred = torch.randint(0, 2, size=(10, 5))\n        y = torch.randint(0, 2, size=(10, 5)).long()\n        re.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(10, 1, 5))\n        y = torch.randint(0, 2, size=(10, 1, 5)).long()\n        re.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(100, 5))\n        y = torch.randint(0, 2, size=(100, 5)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_binary_input_NHW():\n    # Binary accuracy on input of shape (N, H, W)\n\n    def _test(average):\n        re = Recall(average=average)\n\n        y_pred = torch.randint(0, 2, size=(10, 12, 10))\n        y = torch.randint(0, 2, size=(10, 12, 10)).long()\n        re.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(10, 1, 12, 10))\n        y = torch.randint(0, 2, size=(10, 1, 12, 10)).long()\n        re.update((y_pred, y))\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(100, 12, 10))\n        y = torch.randint(0, 2, size=(100, 12, 10)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.numpy().ravel()\n        assert re._type == ""binary""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        assert recall_score(np_y, np_y_pred, average=""binary"") == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_multiclass_wrong_inputs():\n    re = Recall()\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        re.update((torch.rand(10, 5, 4), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        re.update((torch.rand(10, 5, 6), torch.randint(0, 5, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        re.update((torch.rand(10), torch.randint(0, 5, size=(10, 5, 6)).long()))\n\n    re = Recall(average=True)\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        re.update((torch.rand(10, 5), torch.randint(0, 5, size=(10,)).long()))\n        re.update((torch.rand(10, 6), torch.randint(0, 5, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        re.update((torch.rand(10, 5, 12, 14), torch.randint(0, 5, size=(10, 12, 14)).long()))\n        re.update((torch.rand(10, 6, 12, 14), torch.randint(0, 5, size=(10, 12, 14)).long()))\n\n    re = Recall(average=False)\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        re.update((torch.rand(10, 5), torch.randint(0, 5, size=(10,)).long()))\n        re.update((torch.rand(10, 6), torch.randint(0, 5, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        re.update((torch.rand(10, 5, 12, 14), torch.randint(0, 5, size=(10, 12, 14)).long()))\n        re.update((torch.rand(10, 6, 12, 14), torch.randint(0, 5, size=(10, 12, 14)).long()))\n\n\ndef test_multiclass_input_N():\n    # Multiclass input data of shape (N, ) and (N, C)\n\n    def _test(average):\n        re = Recall(average=average)\n        y_pred = torch.rand(20, 6)\n        y = torch.randint(0, 6, size=(20,)).long()\n        re.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.rand(10, 4)\n        y = torch.randint(0, 4, size=(10,)).long()\n        re.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n        # 2-classes\n        re.reset()\n        y_pred = torch.rand(10, 2)\n        y = torch.randint(0, 2, size=(10,)).long()\n        re.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.rand(100, 3)\n        y = torch.randint(0, 3, size=(100,)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        num_classes = y_pred.shape[1]\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_multiclass_input_NL():\n    # Multiclass input data of shape (N, L) and (N, C, L)\n\n    def _test(average):\n        re = Recall(average=average)\n\n        y_pred = torch.rand(10, 5, 8)\n        y = torch.randint(0, 5, size=(10, 8)).long()\n        re.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=sk_average_parameter) == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.rand(15, 10, 8)\n        y = torch.randint(0, 10, size=(15, 8)).long()\n        re.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.rand(100, 8, 12)\n        y = torch.randint(0, 8, size=(100, 12)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        num_classes = y_pred.shape[1]\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_multiclass_input_NHW():\n    # Multiclass input data of shape (N, H, W, ...) and (N, C, H, W, ...)\n\n    def _test(average):\n        re = Recall(average=average)\n\n        y_pred = torch.rand(10, 5, 18, 16)\n        y = torch.randint(0, 5, size=(10, 18, 16)).long()\n        re.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.rand(10, 7, 20, 12)\n        y = torch.randint(0, 7, size=(10, 20, 12)).long()\n        re.update((y_pred, y))\n        num_classes = y_pred.shape[1]\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        np_y = y.numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.rand(100, 10, 12, 14)\n        y = torch.randint(0, 10, size=(100, 12, 14)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        num_classes = y_pred.shape[1]\n        np_y = y.numpy().ravel()\n        np_y_pred = y_pred.argmax(dim=1).numpy().ravel()\n        assert re._type == ""multiclass""\n        assert isinstance(re.compute(), float if average else torch.Tensor)\n        re_compute = re.compute() if average else re.compute().numpy()\n        sk_average_parameter = ""macro"" if average else None\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            sk_compute = recall_score(np_y, np_y_pred, labels=range(0, num_classes), average=sk_average_parameter)\n            assert sk_compute == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n\ndef test_multilabel_wrong_inputs():\n    re = Recall(average=True, is_multilabel=True)\n\n    with pytest.raises(ValueError):\n        # incompatible shapes\n        re.update((torch.randint(0, 2, size=(10,)), torch.randint(0, 2, size=(10,)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible y_pred\n        re.update((torch.rand(10, 5), torch.randint(0, 2, size=(10, 5)).long()))\n\n    with pytest.raises(ValueError):\n        # incompatible y\n        re.update((torch.randint(0, 5, size=(10, 5, 6)), torch.rand(10)))\n\n    with pytest.raises(ValueError):\n        # incompatible shapes between two updates\n        re.update((torch.randint(0, 2, size=(20, 5)), torch.randint(0, 2, size=(20, 5)).long()))\n        re.update((torch.randint(0, 2, size=(20, 6)), torch.randint(0, 2, size=(20, 6)).long()))\n\n\ndef to_numpy_multilabel(y):\n    # reshapes input array to (N x ..., C)\n    y = y.transpose(1, 0).cpu().numpy()\n    num_classes = y.shape[0]\n    y = y.reshape((num_classes, -1)).transpose(1, 0)\n    return y\n\n\ndef test_multilabel_input_NC():\n    def _test(average):\n        re = Recall(average=average, is_multilabel=True)\n\n        y_pred = torch.randint(0, 2, size=(20, 5))\n        y = torch.randint(0, 2, size=(20, 5)).long()\n        re.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(10, 4))\n        y = torch.randint(0, 2, size=(10, 4)).long()\n        re.update((y_pred, y))\n        np_y_pred = y_pred.numpy()\n        np_y = y.numpy()\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(100, 4))\n        y = torch.randint(0, 2, size=(100, 4)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = y.numpy()\n        np_y_pred = y_pred.numpy()\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n    re1 = Recall(is_multilabel=True, average=True)\n    re2 = Recall(is_multilabel=True, average=False)\n    y_pred = torch.randint(0, 2, size=(10, 4))\n    y = torch.randint(0, 2, size=(10, 4)).long()\n    re1.update((y_pred, y))\n    re2.update((y_pred, y))\n    assert re1.compute() == pytest.approx(re2.compute().mean().item())\n\n\ndef test_multilabel_input_NCL():\n    def _test(average):\n        re = Recall(average=average, is_multilabel=True)\n\n        y_pred = torch.randint(0, 2, size=(10, 5, 10))\n        y = torch.randint(0, 2, size=(10, 5, 10)).long()\n        re.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(15, 4, 10))\n        y = torch.randint(0, 2, size=(15, 4, 10)).long()\n        re.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(100, 4, 12))\n        y = torch.randint(0, 2, size=(100, 4, 12)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = to_numpy_multilabel(y)\n        np_y_pred = to_numpy_multilabel(y_pred)\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n    re1 = Recall(is_multilabel=True, average=True)\n    re2 = Recall(is_multilabel=True, average=False)\n    y_pred = torch.randint(0, 2, size=(10, 4, 20))\n    y = torch.randint(0, 2, size=(10, 4, 20)).long()\n    re1.update((y_pred, y))\n    re2.update((y_pred, y))\n    assert re1.compute() == pytest.approx(re2.compute().mean().item())\n\n\ndef test_multilabel_input_NCHW():\n    def _test(average):\n        re = Recall(average=average, is_multilabel=True)\n\n        y_pred = torch.randint(0, 2, size=(10, 5, 18, 16))\n        y = torch.randint(0, 2, size=(10, 5, 18, 16)).long()\n        re.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(10, 4, 20, 23))\n        y = torch.randint(0, 2, size=(10, 4, 20, 23)).long()\n        re.update((y_pred, y))\n        np_y_pred = to_numpy_multilabel(y_pred)\n        np_y = to_numpy_multilabel(y)\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n        # Batched Updates\n        re.reset()\n        y_pred = torch.randint(0, 2, size=(100, 5, 12, 14))\n        y = torch.randint(0, 2, size=(100, 5, 12, 14)).long()\n\n        batch_size = 16\n        n_iters = y.shape[0] // batch_size + 1\n\n        for i in range(n_iters):\n            idx = i * batch_size\n            re.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n        np_y = to_numpy_multilabel(y)\n        np_y_pred = to_numpy_multilabel(y_pred)\n        assert re._type == ""multilabel""\n        re_compute = re.compute() if average else re.compute().mean().item()\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            assert recall_score(np_y, np_y_pred, average=""samples"") == pytest.approx(re_compute)\n\n    for _ in range(5):\n        _test(average=True)\n        _test(average=False)\n\n    re1 = Recall(is_multilabel=True, average=True)\n    re2 = Recall(is_multilabel=True, average=False)\n    y_pred = torch.randint(0, 2, size=(10, 4, 20, 23))\n    y = torch.randint(0, 2, size=(10, 4, 20, 23)).long()\n    re1.update((y_pred, y))\n    re2.update((y_pred, y))\n    assert re1.compute() == pytest.approx(re2.compute().mean().item())\n\n\ndef test_incorrect_type():\n    # Tests changing of type during training\n\n    def _test(average):\n        re = Recall(average=average)\n\n        y_pred = torch.softmax(torch.rand(4, 4), dim=1)\n        y = torch.ones(4).long()\n        re.update((y_pred, y))\n\n        y_pred = torch.zeros(4,)\n        y = torch.ones(4).long()\n\n        with pytest.raises(RuntimeError):\n            re.update((y_pred, y))\n\n    _test(average=True)\n    _test(average=False)\n\n    re1 = Recall(is_multilabel=True, average=True)\n    re2 = Recall(is_multilabel=True, average=False)\n    y_pred = torch.randint(0, 2, size=(10, 4, 20, 23))\n    y = torch.randint(0, 2, size=(10, 4, 20, 23)).long()\n    re1.update((y_pred, y))\n    re2.update((y_pred, y))\n    assert re1.compute() == pytest.approx(re2.compute().mean().item())\n\n\ndef test_incorrect_y_classes():\n    def _test(average):\n        re = Recall(average=average)\n\n        y_pred = torch.randint(0, 2, size=(10, 4)).float()\n        y = torch.randint(4, 5, size=(10,)).long()\n\n        with pytest.raises(ValueError):\n            re.update((y_pred, y))\n\n    _test(average=True)\n    _test(average=False)\n\n\ndef _test_distrib_integration_multiclass(device):\n\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    def _test(average, n_epochs):\n        n_iters = 60\n        s = 16\n        n_classes = 7\n\n        offset = n_iters * s\n        y_true = torch.randint(0, n_classes, size=(offset * idist.get_world_size(),)).to(device)\n        y_preds = torch.rand(offset * idist.get_world_size(), n_classes).to(device)\n\n        def update(engine, i):\n            return (\n                y_preds[i * s + rank * offset : (i + 1) * s + rank * offset, :],\n                y_true[i * s + rank * offset : (i + 1) * s + rank * offset],\n            )\n\n        engine = Engine(update)\n\n        re = Recall(average=average, device=device)\n        re.attach(engine, ""re"")\n\n        data = list(range(n_iters))\n        engine.run(data=data, max_epochs=n_epochs)\n\n        assert ""re"" in engine.state.metrics\n        res = engine.state.metrics[""re""]\n        if isinstance(res, torch.Tensor):\n            res = res.cpu().numpy()\n\n        true_res = recall_score(\n            y_true.cpu().numpy(), torch.argmax(y_preds, dim=1).cpu().numpy(), average=""macro"" if average else None\n        )\n\n        assert pytest.approx(res) == true_res\n\n    for _ in range(2):\n        _test(average=True, n_epochs=1)\n        _test(average=True, n_epochs=2)\n        _test(average=False, n_epochs=1)\n        _test(average=False, n_epochs=2)\n\n\ndef _test_distrib_integration_multilabel(device):\n\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    def _test(average, n_epochs):\n        n_iters = 60\n        s = 16\n        n_classes = 7\n\n        offset = n_iters * s\n        y_true = torch.randint(0, 2, size=(offset * idist.get_world_size(), n_classes, 6, 8)).to(device)\n        y_preds = torch.randint(0, 2, size=(offset * idist.get_world_size(), n_classes, 6, 8)).to(device)\n\n        def update(engine, i):\n            return (\n                y_preds[i * s + rank * offset : (i + 1) * s + rank * offset, ...],\n                y_true[i * s + rank * offset : (i + 1) * s + rank * offset, ...],\n            )\n\n        engine = Engine(update)\n\n        re = Recall(average=average, is_multilabel=True, device=device)\n        re.attach(engine, ""re"")\n\n        data = list(range(n_iters))\n        engine.run(data=data, max_epochs=n_epochs)\n\n        assert ""re"" in engine.state.metrics\n        res = engine.state.metrics[""re""]\n        res2 = re.compute()\n        if isinstance(res, torch.Tensor):\n            res = res.cpu().numpy()\n            res2 = res2.cpu().numpy()\n            assert (res == res2).all()\n        else:\n            assert res == res2\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(""ignore"", category=UndefinedMetricWarning)\n            true_res = recall_score(\n                to_numpy_multilabel(y_true), to_numpy_multilabel(y_preds), average=""samples"" if average else None\n            )\n\n        assert pytest.approx(res) == true_res\n\n    for _ in range(2):\n        _test(average=True, n_epochs=1)\n        _test(average=True, n_epochs=2)\n\n    if idist.get_world_size() > 1:\n        with pytest.warns(\n            RuntimeWarning,\n            match=""Precision/Recall metrics do not work in distributed setting when ""\n            ""average=False and is_multilabel=True"",\n        ):\n            re = Recall(average=False, is_multilabel=True, device=device)\n\n        y_pred = torch.randint(0, 2, size=(4, 3, 6, 8))\n        y = torch.randint(0, 2, size=(4, 3, 6, 8)).long()\n        re.update((y_pred, y))\n        re_compute1 = re.compute()\n        re_compute2 = re.compute()\n        assert len(re_compute1) == 4 * 6 * 8\n        assert (re_compute1 == re_compute2).all()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration_multiclass(device)\n    _test_distrib_integration_multilabel(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_root_mean_squared_error.py,9,"b'import os\n\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import RootMeanSquaredError\n\n\ndef test_zero_div():\n    rmse = RootMeanSquaredError()\n    with pytest.raises(NotComputableError):\n        rmse.compute()\n\n\ndef test_compute():\n    rmse = RootMeanSquaredError()\n\n    y_pred = torch.Tensor([[2.0], [-2.0]])\n    y = torch.zeros(2)\n    rmse.update((y_pred, y))\n    assert isinstance(rmse.compute(), float)\n    assert rmse.compute() == 2.0\n\n    rmse.reset()\n    y_pred = torch.Tensor([[3.0], [-3.0]])\n    y = torch.zeros(2)\n    rmse.update((y_pred, y))\n    assert isinstance(rmse.compute(), float)\n    assert rmse.compute() == 3.0\n\n\ndef _test_distrib_integration(device, tol=1e-6):\n    import numpy as np\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    n_iters = 100\n    s = 10\n    offset = n_iters * s\n\n    y_true = torch.arange(0, offset * idist.get_world_size(), dtype=torch.float).to(device)\n    y_preds = (rank + 1) * torch.ones(offset, dtype=torch.float).to(device)\n\n    def update(engine, i):\n        return y_preds[i * s : (i + 1) * s], y_true[i * s + offset * rank : (i + 1) * s + offset * rank]\n\n    engine = Engine(update)\n\n    m = RootMeanSquaredError()\n    m.attach(engine, ""rmse"")\n\n    data = list(range(n_iters))\n    engine.run(data=data, max_epochs=1)\n\n    assert ""rmse"" in engine.state.metrics\n    res = engine.state.metrics[""rmse""]\n\n    y_preds_full = []\n    for i in range(idist.get_world_size()):\n        y_preds_full.append((i + 1) * torch.ones(offset))\n    y_preds_full = torch.stack(y_preds_full).to(device).flatten()\n\n    true_res = np.sqrt(np.mean(np.square((y_true - y_preds_full).cpu().numpy())))\n\n    assert pytest.approx(res, rel=tol) == true_res\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(local_rank, distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration(device, tol=1e-4)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration(device, tol=1e-4)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_running_average.py,19,"b'import os\nfrom functools import partial\n\nimport numpy as np\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.engine import Engine, Events\nfrom ignite.metrics import Accuracy, RunningAverage\n\n\ndef test_wrong_input_args():\n    with pytest.raises(TypeError, match=r""Argument src should be a Metric or None.""):\n        RunningAverage(src=[12, 34])\n\n    with pytest.raises(ValueError, match=r""Argument alpha should be a float between""):\n        RunningAverage(alpha=-1.0)\n\n    with pytest.raises(ValueError, match=r""Argument output_transform should be None if src is a Metric""):\n        RunningAverage(Accuracy(), output_transform=lambda x: x[0])\n\n    with pytest.raises(ValueError, match=r""Argument output_transform should not be None if src corresponds""):\n        RunningAverage()\n\n    with pytest.raises(ValueError, match=r""Argument device should be None if src is a Metric""):\n        RunningAverage(Accuracy(), device=""cpu"")\n\n\ndef test_integration():\n\n    n_iters = 100\n    batch_size = 10\n    n_classes = 10\n    y_true_batch_values = iter(np.random.randint(0, n_classes, size=(n_iters, batch_size)))\n    y_pred_batch_values = iter(np.random.rand(n_iters, batch_size, n_classes))\n    loss_values = iter(range(n_iters))\n\n    def update_fn(engine, batch):\n        loss_value = next(loss_values)\n        y_true_batch = next(y_true_batch_values)\n        y_pred_batch = next(y_pred_batch_values)\n        return loss_value, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    trainer = Engine(update_fn)\n    alpha = 0.98\n\n    acc_metric = RunningAverage(Accuracy(output_transform=lambda x: [x[1], x[2]]), alpha=alpha)\n    acc_metric.attach(trainer, ""running_avg_accuracy"")\n\n    avg_output = RunningAverage(output_transform=lambda x: x[0], alpha=alpha)\n    avg_output.attach(trainer, ""running_avg_output"")\n\n    running_avg_acc = [\n        None,\n    ]\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def manual_running_avg_acc(engine):\n        _, y_pred, y = engine.state.output\n        indices = torch.max(y_pred, 1)[1]\n        correct = torch.eq(indices, y).view(-1)\n        num_correct = torch.sum(correct).item()\n        num_examples = correct.shape[0]\n        batch_acc = num_correct * 1.0 / num_examples\n        if running_avg_acc[0] is None:\n            running_avg_acc[0] = batch_acc\n        else:\n            running_avg_acc[0] = running_avg_acc[0] * alpha + (1.0 - alpha) * batch_acc\n        engine.state.running_avg_acc = running_avg_acc[0]\n\n    @trainer.on(Events.EPOCH_STARTED)\n    def running_avg_output_init(engine):\n        engine.state.running_avg_output = None\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def running_avg_output_update(engine):\n        if engine.state.running_avg_output is None:\n            engine.state.running_avg_output = engine.state.output[0]\n        else:\n            engine.state.running_avg_output = (\n                engine.state.running_avg_output * alpha + (1.0 - alpha) * engine.state.output[0]\n            )\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def assert_equal_running_avg_acc_values(engine):\n        assert engine.state.running_avg_acc == engine.state.metrics[""running_avg_accuracy""], ""{} vs {}"".format(\n            engine.state.running_avg_acc, engine.state.metrics[""running_avg_accuracy""]\n        )\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def assert_equal_running_avg_output_values(engine):\n        assert engine.state.running_avg_output == engine.state.metrics[""running_avg_output""], ""{} vs {}"".format(\n            engine.state.running_avg_output, engine.state.metrics[""running_avg_output""]\n        )\n\n    np.random.seed(10)\n    running_avg_acc = [\n        None,\n    ]\n    n_iters = 10\n    batch_size = 10\n    n_classes = 10\n    data = list(range(n_iters))\n    loss_values = iter(range(n_iters))\n    y_true_batch_values = iter(np.random.randint(0, n_classes, size=(n_iters, batch_size)))\n    y_pred_batch_values = iter(np.random.rand(n_iters, batch_size, n_classes))\n    trainer.run(data, max_epochs=1)\n\n    running_avg_acc = [\n        None,\n    ]\n    n_iters = 10\n    batch_size = 10\n    n_classes = 10\n    data = list(range(n_iters))\n    loss_values = iter(range(n_iters))\n    y_true_batch_values = iter(np.random.randint(0, n_classes, size=(n_iters, batch_size)))\n    y_pred_batch_values = iter(np.random.rand(n_iters, batch_size, n_classes))\n    trainer.run(data, max_epochs=1)\n\n\ndef test_epoch_unbound():\n\n    n_iters = 10\n    n_epochs = 3\n    batch_size = 10\n    n_classes = 10\n    data = list(range(n_iters))\n    loss_values = iter(range(n_epochs * n_iters))\n    y_true_batch_values = iter(np.random.randint(0, n_classes, size=(n_epochs * n_iters, batch_size)))\n    y_pred_batch_values = iter(np.random.rand(n_epochs * n_iters, batch_size, n_classes))\n\n    def update_fn(engine, batch):\n        loss_value = next(loss_values)\n        y_true_batch = next(y_true_batch_values)\n        y_pred_batch = next(y_pred_batch_values)\n        return loss_value, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    trainer = Engine(update_fn)\n    alpha = 0.98\n\n    acc_metric = RunningAverage(Accuracy(output_transform=lambda x: [x[1], x[2]]), alpha=alpha, epoch_bound=False)\n    acc_metric.attach(trainer, ""running_avg_accuracy"")\n\n    avg_output = RunningAverage(output_transform=lambda x: x[0], alpha=alpha, epoch_bound=False)\n    avg_output.attach(trainer, ""running_avg_output"")\n\n    running_avg_acc = [None]\n\n    @trainer.on(Events.STARTED)\n    def running_avg_output_init(engine):\n        engine.state.running_avg_output = None\n\n    @trainer.on(Events.ITERATION_COMPLETED, running_avg_acc)\n    def manual_running_avg_acc(engine, running_avg_acc):\n        _, y_pred, y = engine.state.output\n        indices = torch.max(y_pred, 1)[1]\n        correct = torch.eq(indices, y).view(-1)\n        num_correct = torch.sum(correct).item()\n        num_examples = correct.shape[0]\n        batch_acc = num_correct * 1.0 / num_examples\n        if running_avg_acc[0] is None:\n            running_avg_acc[0] = batch_acc\n        else:\n            running_avg_acc[0] = running_avg_acc[0] * alpha + (1.0 - alpha) * batch_acc\n        engine.state.running_avg_acc = running_avg_acc[0]\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def running_avg_output_update(engine):\n        if engine.state.running_avg_output is None:\n            engine.state.running_avg_output = engine.state.output[0]\n        else:\n            engine.state.running_avg_output = (\n                engine.state.running_avg_output * alpha + (1.0 - alpha) * engine.state.output[0]\n            )\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def assert_equal_running_avg_acc_values(engine):\n        assert engine.state.running_avg_acc == engine.state.metrics[""running_avg_accuracy""], ""{} vs {}"".format(\n            engine.state.running_avg_acc, engine.state.metrics[""running_avg_accuracy""]\n        )\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def assert_equal_running_avg_output_values(engine):\n        assert engine.state.running_avg_output == engine.state.metrics[""running_avg_output""], ""{} vs {}"".format(\n            engine.state.running_avg_output, engine.state.metrics[""running_avg_output""]\n        )\n\n    trainer.run(data, max_epochs=3)\n\n\ndef test_multiple_attach():\n    n_iters = 100\n    errD_values = iter(np.random.rand(n_iters,))\n    errG_values = iter(np.random.rand(n_iters,))\n    D_x_values = iter(np.random.rand(n_iters,))\n    D_G_z1 = iter(np.random.rand(n_iters,))\n    D_G_z2 = iter(np.random.rand(n_iters,))\n\n    def update_fn(engine, batch):\n        return {\n            ""errD"": next(errD_values),\n            ""errG"": next(errG_values),\n            ""D_x"": next(D_x_values),\n            ""D_G_z1"": next(D_G_z1),\n            ""D_G_z2"": next(D_G_z2),\n        }\n\n    trainer = Engine(update_fn)\n    alpha = 0.98\n\n    # attach running average\n    monitoring_metrics = [""errD"", ""errG"", ""D_x"", ""D_G_z1"", ""D_G_z2""]\n    for metric in monitoring_metrics:\n        foo = partial(lambda x, metric: x[metric], metric=metric)\n        RunningAverage(alpha=alpha, output_transform=foo).attach(trainer, metric)\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def check_values(engine):\n\n        values = []\n        for metric in monitoring_metrics:\n            values.append(engine.state.metrics[metric])\n\n        values = set(values)\n        assert len(values) == len(monitoring_metrics)\n\n    data = list(range(n_iters))\n    trainer.run(data)\n\n\ndef test_output_is_tensor():\n\n    m = RunningAverage(output_transform=lambda x: x)\n    m.update(torch.rand(10, requires_grad=True).mean())\n    v = m.compute()\n    assert isinstance(v, torch.Tensor)\n    assert not v.requires_grad\n\n    m.update(torch.rand(10, requires_grad=True).mean())\n    v = m.compute()\n    assert isinstance(v, torch.Tensor)\n    assert not v.requires_grad\n\n    m.update(torch.rand(10, requires_grad=True).mean())\n    v = m.compute()\n    assert isinstance(v, torch.Tensor)\n    assert not v.requires_grad\n\n\ndef _test_distrib_on_output(device):\n\n    rank = idist.get_rank()\n    n_iters = 10\n    n_epochs = 3\n    batch_size = 10\n\n    # Data per rank\n    data = list(range(n_iters))\n    k = n_epochs * batch_size * n_iters\n    all_loss_values = torch.arange(0, k * idist.get_world_size(), dtype=torch.float64).to(device)\n    loss_values = iter(all_loss_values[k * rank : k * (rank + 1)])\n\n    def update_fn(engine, batch):\n        loss_value = next(loss_values)\n        return loss_value.item()\n\n    trainer = Engine(update_fn)\n    alpha = 0.98\n\n    avg_output = RunningAverage(output_transform=lambda x: x, alpha=alpha, epoch_bound=False, device=device)\n    avg_output.attach(trainer, ""running_avg_output"")\n\n    @trainer.on(Events.STARTED)\n    def running_avg_output_init(engine):\n        engine.state.running_avg_output = None\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def running_avg_output_update(engine):\n        i = engine.state.iteration - 1\n        o = sum([all_loss_values[i + j * k] for j in range(idist.get_world_size())]).item()\n        o /= idist.get_world_size()\n        if engine.state.running_avg_output is None:\n            engine.state.running_avg_output = o\n        else:\n            engine.state.running_avg_output = engine.state.running_avg_output * alpha + (1.0 - alpha) * o\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def assert_equal_running_avg_output_values(engine):\n        assert engine.state.running_avg_output == pytest.approx(\n            engine.state.metrics[""running_avg_output""]\n        ), ""{}: {} vs {}"".format(\n            engine.state.iteration, engine.state.running_avg_output, engine.state.metrics[""running_avg_output""]\n        )\n\n    trainer.run(data, max_epochs=3)\n\n\ndef _test_distrib_on_metric(device):\n\n    rank = idist.get_rank()\n    n_iters = 10\n    n_epochs = 3\n    batch_size = 10\n    n_classes = 10\n\n    data = list(range(n_iters))\n    np.random.seed(12)\n    all_y_true_batch_values = np.random.randint(\n        0, n_classes, size=(idist.get_world_size(), n_epochs * n_iters, batch_size)\n    )\n    all_y_pred_batch_values = np.random.rand(idist.get_world_size(), n_epochs * n_iters, batch_size, n_classes)\n\n    y_true_batch_values = iter(all_y_true_batch_values[rank, ...])\n    y_pred_batch_values = iter(all_y_pred_batch_values[rank, ...])\n\n    def update_fn(engine, batch):\n        y_true_batch = next(y_true_batch_values)\n        y_pred_batch = next(y_pred_batch_values)\n        return torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    trainer = Engine(update_fn)\n    alpha = 0.98\n\n    acc_metric = RunningAverage(\n        Accuracy(output_transform=lambda x: [x[0], x[1]], device=device), alpha=alpha, epoch_bound=False\n    )\n    acc_metric.attach(trainer, ""running_avg_accuracy"")\n\n    running_avg_acc = [\n        None,\n    ]\n    true_acc_metric = Accuracy(device=device)\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def manual_running_avg_acc(engine):\n        i = engine.state.iteration - 1\n\n        true_acc_metric.reset()\n        for j in range(idist.get_world_size()):\n            output = (\n                torch.from_numpy(all_y_pred_batch_values[j, i, :, :]),\n                torch.from_numpy(all_y_true_batch_values[j, i, :]),\n            )\n            true_acc_metric.update(output)\n\n        batch_acc = true_acc_metric._num_correct * 1.0 / true_acc_metric._num_examples\n\n        if running_avg_acc[0] is None:\n            running_avg_acc[0] = batch_acc\n        else:\n            running_avg_acc[0] = running_avg_acc[0] * alpha + (1.0 - alpha) * batch_acc\n        engine.state.running_avg_acc = running_avg_acc[0]\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def assert_equal_running_avg_acc_values(engine):\n        assert engine.state.running_avg_acc == engine.state.metrics[""running_avg_accuracy""], ""{} vs {}"".format(\n            engine.state.running_avg_acc, engine.state.metrics[""running_avg_accuracy""]\n        )\n\n    trainer.run(data, max_epochs=3)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_on_output(device)\n    _test_distrib_on_metric(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n\n    device = ""cpu""\n    _test_distrib_on_output(device)\n    _test_distrib_on_metric(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_on_output(device)\n    _test_distrib_on_metric(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_on_output(device)\n    _test_distrib_on_metric(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_on_output(device)\n    _test_distrib_on_metric(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_on_output(device)\n    _test_distrib_on_metric(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/metrics/test_top_k_categorical_accuracy.py,9,"b'import os\n\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.exceptions import NotComputableError\nfrom ignite.metrics import TopKCategoricalAccuracy\n\n\ndef test_zero_div():\n    acc = TopKCategoricalAccuracy(2)\n    with pytest.raises(NotComputableError):\n        acc.compute()\n\n\ndef test_compute():\n    acc = TopKCategoricalAccuracy(2)\n\n    y_pred = torch.FloatTensor([[0.2, 0.4, 0.6, 0.8], [0.8, 0.6, 0.4, 0.2]])\n    y = torch.ones(2).long()\n    acc.update((y_pred, y))\n    assert isinstance(acc.compute(), float)\n    assert acc.compute() == 0.5\n\n    acc.reset()\n    y_pred = torch.FloatTensor([[0.4, 0.8, 0.2, 0.6], [0.8, 0.6, 0.4, 0.2]])\n    y = torch.ones(2).long()\n    acc.update((y_pred, y))\n    assert isinstance(acc.compute(), float)\n    assert acc.compute() == 1.0\n\n\ndef top_k_accuracy(y_true, y_pred, k=5, normalize=True):\n    import numpy as np\n\n    # Taken from\n    # https://github.com/scikit-learn/scikit-learn/blob/4685cb5c50629aba4429f6701585f82fc3eee5f7/\n    # sklearn/metrics/classification.py#L187\n    if len(y_true.shape) == 2:\n        y_true = np.argmax(y_true, axis=1)\n\n    num_obs, num_labels = y_pred.shape\n    idx = num_labels - k - 1\n    counter = 0.0\n    argsorted = np.argsort(y_pred, axis=1)\n    for i in range(num_obs):\n        if y_true[i] in argsorted[i, idx + 1 :]:\n            counter += 1.0\n    if normalize:\n        return counter * 1.0 / num_obs\n    else:\n        return counter\n\n\ndef _test_distrib_integration(device):\n    from ignite.engine import Engine\n\n    rank = idist.get_rank()\n    torch.manual_seed(12)\n\n    def _test(n_epochs):\n        n_iters = 100\n        s = 16\n        n_classes = 10\n\n        offset = n_iters * s\n        y_true = torch.randint(0, n_classes, size=(offset * idist.get_world_size(),)).to(device)\n        y_preds = torch.rand(offset * idist.get_world_size(), n_classes).to(device)\n\n        print(""{}: y_true={} | y_preds={}"".format(rank, y_true[:5], y_preds[:5, :2]))\n\n        def update(engine, i):\n            return (\n                y_preds[i * s + rank * offset : (i + 1) * s + rank * offset, :],\n                y_true[i * s + rank * offset : (i + 1) * s + rank * offset],\n            )\n\n        engine = Engine(update)\n\n        k = 5\n        acc = TopKCategoricalAccuracy(k=k, device=device)\n        acc.attach(engine, ""acc"")\n\n        data = list(range(n_iters))\n        engine.run(data=data, max_epochs=n_epochs)\n\n        assert ""acc"" in engine.state.metrics\n        res = engine.state.metrics[""acc""]\n        if isinstance(res, torch.Tensor):\n            res = res.cpu().numpy()\n\n        true_res = top_k_accuracy(y_true.cpu().numpy(), y_preds.cpu().numpy(), k=k)\n\n        assert pytest.approx(res) == true_res\n\n    for _ in range(5):\n        _test(n_epochs=1)\n        _test(n_epochs=2)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(local_rank, distributed_context_single_node_nccl):\n    device = ""cuda:{}"".format(local_rank)\n    _test_distrib_integration(device)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(local_rank, distributed_context_single_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(distributed_context_multi_node_gloo):\n    device = ""cpu""\n    _test_distrib_integration(device)\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(distributed_context_multi_node_nccl):\n    device = ""cuda:{}"".format(distributed_context_multi_node_nccl[""local_rank""])\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\ndef _test_distrib_xla_nprocs(index):\n    device = idist.device()\n    _test_distrib_integration(device)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test_distrib_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_distrib_xla_nprocs, args=(), nprocs=n)\n'"
examples/contrib/cifar10/gcp_ai_platform/parse_cluster_spec.py,0,"b'import os\nimport json\n\nassert ""CLUSTER_SPEC"" in os.environ\n\ncluster_spec = json.loads(os.environ[""CLUSTER_SPEC""])\n\nmaster_addr_port = cluster_spec[""cluster""][""master""][0].split("":"")\nmaster_addr = master_addr_port[0]\nmaster_port = master_addr_port[1]\n\nrank = cluster_spec[""task""][""index""]\nif cluster_spec[""task""][""type""] == ""worker"":\n    rank += 1\n\nprint(""{},{},{}"".format(master_addr, master_port, rank))\n'"
ignite/contrib/metrics/regression/__init__.py,0,b'from ignite.contrib.metrics.regression.canberra_metric import CanberraMetric\nfrom ignite.contrib.metrics.regression.fractional_absolute_error import FractionalAbsoluteError\nfrom ignite.contrib.metrics.regression.fractional_bias import FractionalBias\nfrom ignite.contrib.metrics.regression.geometric_mean_absolute_error import GeometricMeanAbsoluteError\nfrom ignite.contrib.metrics.regression.geometric_mean_relative_absolute_error import GeometricMeanRelativeAbsoluteError\nfrom ignite.contrib.metrics.regression.manhattan_distance import ManhattanDistance\nfrom ignite.contrib.metrics.regression.maximum_absolute_error import MaximumAbsoluteError\nfrom ignite.contrib.metrics.regression.mean_absolute_relative_error import MeanAbsoluteRelativeError\nfrom ignite.contrib.metrics.regression.mean_error import MeanError\nfrom ignite.contrib.metrics.regression.mean_normalized_bias import MeanNormalizedBias\nfrom ignite.contrib.metrics.regression.median_absolute_error import MedianAbsoluteError\nfrom ignite.contrib.metrics.regression.median_absolute_percentage_error import MedianAbsolutePercentageError\nfrom ignite.contrib.metrics.regression.median_relative_absolute_error import MedianRelativeAbsoluteError\nfrom ignite.contrib.metrics.regression.r2_score import R2Score\nfrom ignite.contrib.metrics.regression.wave_hedges_distance import WaveHedgesDistance\n'
ignite/contrib/metrics/regression/_base.py,2,"b'from abc import abstractmethod\n\nimport torch\n\nfrom ignite.metrics import EpochMetric, Metric\n\n\ndef _check_output_shapes(output):\n    y_pred, y = output\n    if y_pred.shape != y.shape:\n        raise ValueError(""Input data shapes should be the same, but given {} and {}"".format(y_pred.shape, y.shape))\n\n    c1 = y_pred.ndimension() == 2 and y_pred.shape[1] == 1\n    if not (y_pred.ndimension() == 1 or c1):\n        raise ValueError(""Input y_pred should have shape (N,) or (N, 1), but given {}"".format(y_pred.shape))\n\n    c2 = y.ndimension() == 2 and y.shape[1] == 1\n    if not (y.ndimension() == 1 or c2):\n        raise ValueError(""Input y should have shape (N,) or (N, 1), but given {}"".format(y.shape))\n\n\ndef _check_output_types(output):\n    y_pred, y = output\n    if y_pred.dtype not in (torch.float16, torch.float32, torch.float64):\n        raise TypeError(""Input y_pred dtype should be float 16, 32 or 64, but given {}"".format(y_pred.dtype))\n\n    if y.dtype not in (torch.float16, torch.float32, torch.float64):\n        raise TypeError(""Input y dtype should be float 16, 32 or 64, but given {}"".format(y.dtype))\n\n\nclass _BaseRegression(Metric):\n    # Base class for all regression metrics\n    # `update` method check the shapes and call internal overloaded\n    # method `_update`.\n\n    def update(self, output):\n        _check_output_shapes(output)\n        _check_output_types(output)\n        y_pred, y = output\n\n        if y_pred.ndimension() == 2 and y_pred.shape[1] == 1:\n            y_pred = y_pred.squeeze(dim=-1)\n\n        if y.ndimension() == 2 and y.shape[1] == 1:\n            y = y.squeeze(dim=-1)\n\n        self._update((y_pred, y))\n\n    @abstractmethod\n    def _update(self, output):\n        pass\n\n\nclass _BaseRegressionEpoch(EpochMetric):\n    # Base class for all median-based regression metrics\n    # `update` method check the shapes and call internal overloaded method `_update`.\n    # Class internally stores complete history of predictions and targets of type float32.\n\n    def __init__(self, compute_fn, output_transform=lambda x: x):\n        super(_BaseRegressionEpoch, self).__init__(compute_fn=compute_fn, output_transform=output_transform)\n\n    def _check_type(self, output):\n        _check_output_types(output)\n        super(_BaseRegressionEpoch, self)._check_type(output)\n\n    def _check_shape(self, output):\n        _check_output_shapes(output)\n'"
ignite/contrib/metrics/regression/canberra_metric.py,2,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\n\n\nclass CanberraMetric(_BaseRegression):\n    r""""""\n    Calculates the Canberra Metric.\n\n    :math:`\\text{CM} = \\sum_{j=1}^n\\frac{|A_j - P_j|}{A_j + P_j}`\n\n    where, :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n    """"""\n\n    def reset(self):\n        self._sum_of_errors = 0.0\n\n    def _update(self, output):\n        y_pred, y = output\n        errors = torch.abs(y.view_as(y_pred) - y_pred) / (y_pred + y.view_as(y_pred))\n        self._sum_of_errors += torch.sum(errors).item()\n\n    def compute(self):\n        return self._sum_of_errors\n'"
ignite/contrib/metrics/regression/fractional_absolute_error.py,2,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\nfrom ignite.exceptions import NotComputableError\n\n\nclass FractionalAbsoluteError(_BaseRegression):\n    r""""""\n    Calculates the Fractional Absolute Error.\n\n    :math:`\\text{FAE} = \\frac{1}{n}\\sum_{j=1}^n\\frac{2 |A_j - P_j|}{|A_j| + |P_j|}`\n\n    where, :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n    """"""\n\n    def reset(self):\n        self._sum_of_errors = 0.0\n        self._num_examples = 0\n\n    def _update(self, output):\n        y_pred, y = output\n        errors = 2 * torch.abs(y.view_as(y_pred) - y_pred) / (torch.abs(y_pred) + torch.abs(y.view_as(y_pred)))\n        self._sum_of_errors += torch.sum(errors).item()\n        self._num_examples += y.shape[0]\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError(\n                ""FractionalAbsoluteError must have at least "" ""one example before it can be computed.""\n            )\n        return self._sum_of_errors / self._num_examples\n'"
ignite/contrib/metrics/regression/fractional_bias.py,1,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\nfrom ignite.exceptions import NotComputableError\n\n\nclass FractionalBias(_BaseRegression):\n    r""""""\n    Calculates the Fractional Bias:\n\n    :math:`\\text{FB} = \\frac{1}{n}\\sum_{j=1}^n\\frac{2 (A_j - P_j)}{A_j + P_j}`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def reset(self):\n        self._sum_of_errors = 0.0\n        self._num_examples = 0\n\n    def _update(self, output):\n        y_pred, y = output\n        errors = 2 * (y.view_as(y_pred) - y_pred) / (y_pred + y.view_as(y_pred))\n        self._sum_of_errors += torch.sum(errors).item()\n        self._num_examples += y.shape[0]\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError(""FractionalBias must have at least one example before it can be computed."")\n        return self._sum_of_errors / self._num_examples\n'"
ignite/contrib/metrics/regression/geometric_mean_absolute_error.py,3,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\nfrom ignite.exceptions import NotComputableError\n\n\nclass GeometricMeanAbsoluteError(_BaseRegression):\n    r""""""\n    Calculates the Geometric Mean Absolute Error.\n\n    :math:`\\text{GMAE} = \\exp(\\frac{1}{n}\\sum_{j=1}^n\\ln(|A_j - P_j|))`\n\n    where, :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n    """"""\n\n    def reset(self):\n        self._sum_of_errors = 0.0\n        self._num_examples = 0\n\n    def _update(self, output):\n        y_pred, y = output\n        errors = torch.log(torch.abs(y.view_as(y_pred) - y_pred))\n        self._sum_of_errors += torch.sum(errors)\n        self._num_examples += y.shape[0]\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError(\n                ""GeometricMeanAbsoluteError must have at "" ""least one example before it can be computed.""\n            )\n        return torch.exp(self._sum_of_errors / self._num_examples).item()\n'"
ignite/contrib/metrics/regression/geometric_mean_relative_absolute_error.py,4,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\n\n\nclass GeometricMeanRelativeAbsoluteError(_BaseRegression):\n    r""""""\n    Calculates the Geometric Mean Relative Absolute Error:\n\n    :math:`\\text{GMRAE} = \\exp(\\frac{1}{n}\\sum_{j=1}^n \\ln\\frac{|A_j - P_j|}{|A_j - \\bar{A}|})`\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def reset(self):\n        self._sum_y = 0.0\n        self._num_examples = 0\n        self._sum_of_errors = 0.0\n\n    def _update(self, output):\n        y_pred, y = output\n        self._sum_y += y.sum()\n        self._num_examples += y.shape[0]\n        y_mean = self._sum_y / self._num_examples\n        numerator = torch.abs(y.view_as(y_pred) - y_pred)\n        denominator = torch.abs(y.view_as(y_pred) - y_mean)\n        self._sum_of_errors += torch.log(numerator / denominator).sum()\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError(\n                ""GeometricMeanRelativeAbsoluteError must have at least "" ""one example before it can be computed.""\n            )\n        return torch.exp(torch.mean(self._sum_of_errors / self._num_examples)).item()\n'"
ignite/contrib/metrics/regression/manhattan_distance.py,1,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\n\n\nclass ManhattanDistance(_BaseRegression):\n    r""""""\n    Calculates the Manhattan Distance:\n\n    :math:`\\text{MD} = \\sum_{j=1}^n (A_j - P_j)`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def reset(self):\n        self._sum_of_errors = 0.0\n\n    def _update(self, output):\n        y_pred, y = output\n        errors = y.view_as(y_pred) - y_pred\n        self._sum_of_errors += torch.sum(errors).item()\n\n    def compute(self):\n        return self._sum_of_errors\n'"
ignite/contrib/metrics/regression/maximum_absolute_error.py,1,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\nfrom ignite.exceptions import NotComputableError\n\n\nclass MaximumAbsoluteError(_BaseRegression):\n    r""""""\n    Calculates the Maximum Absolute Error:\n\n    :math:`\\text{MaxAE} = \\max_{j=1,n} \\left( \\lvert A_j-P_j \\rvert \\right)`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def reset(self):\n        self._max_of_absolute_errors = -1\n\n    def _update(self, output):\n        y_pred, y = output\n        mae = torch.abs(y_pred - y.view_as(y_pred)).max().item()\n        if self._max_of_absolute_errors < mae:\n            self._max_of_absolute_errors = mae\n\n    def compute(self):\n        if self._max_of_absolute_errors < 0:\n            raise NotComputableError(""MaximumAbsoluteError must have at least one example before it can be computed."")\n        return self._max_of_absolute_errors\n'"
ignite/contrib/metrics/regression/mean_absolute_relative_error.py,2,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\nfrom ignite.exceptions import NotComputableError\n\n\nclass MeanAbsoluteRelativeError(_BaseRegression):\n    r""""""\n    Calculate Mean Absolute Relative Error:\n\n    :math:`\\text{MARE} = \\frac{1}{n}\\sum_{j=1}^n\\frac{\\left|A_j-P_j\\right|}{\\left|A_j\\right|}`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in the reference `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/ftp/arxiv/papers/1809/1809.03006.pdf\n\n    """"""\n\n    def reset(self):\n        self._sum_of_absolute_relative_errors = 0.0\n        self._num_samples = 0\n\n    def _update(self, output):\n        y_pred, y = output\n        if (y == 0).any():\n            raise NotComputableError(""The ground truth has 0."")\n        absolute_error = torch.abs(y_pred - y.view_as(y_pred)) / torch.abs(y.view_as(y_pred))\n        self._sum_of_absolute_relative_errors += torch.sum(absolute_error).item()\n        self._num_samples += y.size()[0]\n\n    def compute(self):\n        if self._num_samples == 0:\n            raise NotComputableError(\n                ""MeanAbsoluteRelativeError must have at least"" ""one sample before it can be computed.""\n            )\n        return self._sum_of_absolute_relative_errors / self._num_samples\n'"
ignite/contrib/metrics/regression/mean_error.py,1,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\nfrom ignite.exceptions import NotComputableError\n\n\nclass MeanError(_BaseRegression):\n    r""""""\n    Calculates the Mean Error:\n\n    :math:`\\text{ME} = \\frac{1}{n}\\sum_{j=1}^n (A_j - P_j)`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in the reference `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def reset(self):\n        self._sum_of_errors = 0.0\n        self._num_examples = 0\n\n    def _update(self, output):\n        y_pred, y = output\n        errors = y.view_as(y_pred) - y_pred\n        self._sum_of_errors += torch.sum(errors).item()\n        self._num_examples += y.shape[0]\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError(""MeanError must have at least one example before it can be computed."")\n        return self._sum_of_errors / self._num_examples\n'"
ignite/contrib/metrics/regression/mean_normalized_bias.py,1,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\nfrom ignite.exceptions import NotComputableError\n\n\nclass MeanNormalizedBias(_BaseRegression):\n    r""""""\n    Calculates the Mean Normalized Bias:\n\n    :math:`\\text{MNB} = \\frac{1}{n}\\sum_{j=1}^n\\frac{A_j - P_j}{A_j}`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in the reference `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def reset(self):\n        self._sum_of_errors = 0.0\n        self._num_examples = 0\n\n    def _update(self, output):\n        y_pred, y = output\n\n        if (y == 0).any():\n            raise NotComputableError(""The ground truth has 0."")\n\n        errors = (y.view_as(y_pred) - y_pred) / y\n        self._sum_of_errors += torch.sum(errors).item()\n        self._num_examples += y.shape[0]\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError(""MeanNormalizedBias must have at least one example before it can be computed."")\n        return self._sum_of_errors / self._num_examples\n'"
ignite/contrib/metrics/regression/median_absolute_error.py,2,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegressionEpoch\n\n\ndef median_absolute_error_compute_fn(y_pred, y):\n    e = torch.abs(y.view_as(y_pred) - y_pred)\n    return torch.median(e).item()\n\n\nclass MedianAbsoluteError(_BaseRegressionEpoch):\n    r""""""\n    Calculates the Median Absolute Error:\n\n    :math:`\\text{MdAE} = \\text{MD}_{j=1,n} \\left( |A_j - P_j| \\right)`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)` and of type `float32`.\n\n    .. warning::\n\n        Current implementation stores all input data (output and target) in as tensors before computing a metric.\n        This can potentially lead to a memory error if the input data is larger than available RAM.\n\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def __init__(self, output_transform=lambda x: x):\n        super(MedianAbsoluteError, self).__init__(median_absolute_error_compute_fn, output_transform)\n'"
ignite/contrib/metrics/regression/median_absolute_percentage_error.py,2,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegressionEpoch\n\n\ndef median_absolute_percentage_error_compute_fn(y_pred, y):\n    e = torch.abs(y.view_as(y_pred) - y_pred) / torch.abs(y.view_as(y_pred))\n    return 100.0 * torch.median(e).item()\n\n\nclass MedianAbsolutePercentageError(_BaseRegressionEpoch):\n    r""""""\n    Calculates the Median Absolute Percentage Error:\n\n    :math:`\\text{MdAPE} = 100 \\cdot \\text{MD}_{j=1,n} \\left( \\frac{|A_j - P_j|}{|A_j|} \\right)`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)` and of type `float32`.\n\n    .. warning::\n\n        Current implementation stores all input data (output and target) in as tensors before computing a metric.\n        This can potentially lead to a memory error if the input data is larger than available RAM.\n\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def __init__(self, output_transform=lambda x: x):\n        super(MedianAbsolutePercentageError, self).__init__(\n            median_absolute_percentage_error_compute_fn, output_transform\n        )\n'"
ignite/contrib/metrics/regression/median_relative_absolute_error.py,2,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegressionEpoch\n\n\ndef median_relative_absolute_error_compute_fn(y_pred, y):\n    e = torch.abs(y.view_as(y_pred) - y_pred) / torch.abs(y.view_as(y_pred) - torch.mean(y))\n    return torch.median(e).item()\n\n\nclass MedianRelativeAbsoluteError(_BaseRegressionEpoch):\n    r""""""\n    Calculates the Median Relative Absolute Error:\n\n    :math:`\\text{MdRAE} = \\text{MD}_{j=1,n} \\left( \\frac{|A_j - P_j|}{|A_j - \\bar{A}|} \\right)`,\n\n    where :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)` and of type `float32`.\n\n    .. warning::\n\n        Current implementation stores all input data (output and target) in as tensors before computing a metric.\n        This can potentially lead to a memory error if the input data is larger than available RAM.\n\n\n    __ https://arxiv.org/abs/1809.03006\n\n    """"""\n\n    def __init__(self, output_transform=lambda x: x):\n        super(MedianRelativeAbsoluteError, self).__init__(median_relative_absolute_error_compute_fn, output_transform)\n'"
ignite/contrib/metrics/regression/r2_score.py,3,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\nfrom ignite.exceptions import NotComputableError\n\n\nclass R2Score(_BaseRegression):\n    r""""""\n        Calculates the R-Squared, the\n        `coefficient of determination <https://en.wikipedia.org/wiki/Coefficient_of_determination>`_:\n\n        :math:`R^2 = 1 - \\frac{\\sum_{j=1}^n(A_j - P_j)^2}{\\sum_{j=1}^n(A_j - \\bar{A})^2}`,\n\n        where :math:`A_j` is the ground truth, :math:`P_j` is the predicted value and\n        :math:`\\bar{A}` is the mean of the ground truth.\n\n        - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n        - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)` and of type `float32`.\n    """"""\n\n    def reset(self):\n        self._num_examples = 0\n        self._sum_of_errors = 0\n        self._y_sq_sum = 0\n        self._y_sum = 0\n\n    def _update(self, output):\n        y_pred, y = output\n        self._num_examples += y.shape[0]\n        self._sum_of_errors += torch.sum(torch.pow(y_pred - y, 2)).item()\n\n        self._y_sum += torch.sum(y).item()\n        self._y_sq_sum += torch.sum(torch.pow(y, 2)).item()\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise NotComputableError(""R2Score must have at least one example before it can be computed."")\n        return 1 - self._sum_of_errors / (self._y_sq_sum - (self._y_sum ** 2) / self._num_examples)\n'"
ignite/contrib/metrics/regression/wave_hedges_distance.py,2,"b'import torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression\n\n\nclass WaveHedgesDistance(_BaseRegression):\n    r""""""\n    Calculates the Wave Hedges Distance.\n\n    :math:`\\text{WHD} = \\sum_{j=1}^n\\frac{|A_j - P_j|}{max(A_j, P_j)}`,\n    where, :math:`A_j` is the ground truth and :math:`P_j` is the predicted value.\n\n    More details can be found in `Botchkarev 2018`__.\n\n    - `update` must receive output of the form `(y_pred, y)` or `{\'y_pred\': y_pred, \'y\': y}`.\n    - `y` and `y_pred` must be of same shape `(N, )` or `(N, 1)`.\n\n    __ https://arxiv.org/abs/1809.03006\n    """"""\n\n    def reset(self):\n        self._sum_of_errors = 0.0\n\n    def _update(self, output):\n        y_pred, y = output\n        errors = torch.abs(y.view_as(y_pred) - y_pred) / torch.max(y_pred, y.view_as(y_pred))\n        self._sum_of_errors += torch.sum(errors).item()\n\n    def compute(self):\n        return self._sum_of_errors\n'"
tests/ignite/contrib/engines/__init__.py,0,b''
tests/ignite/contrib/engines/test_common.py,13,"b'import os\nimport sys\nfrom unittest.mock import MagicMock\n\nimport pytest\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data.distributed import DistributedSampler\n\nimport ignite.contrib.handlers as handlers\nimport ignite.distributed as idist\nfrom ignite.contrib.engines.common import (\n    _setup_logging,\n    add_early_stopping_by_val_score,\n    save_best_model_by_val_score,\n    setup_any_logging,\n    setup_common_training_handlers,\n    setup_mlflow_logging,\n    setup_neptune_logging,\n    setup_plx_logging,\n    setup_tb_logging,\n    setup_trains_logging,\n    setup_visdom_logging,\n    setup_wandb_logging,\n)\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import TerminateOnNan\n\n\nclass DummyModel(nn.Module):\n    def __init__(self):\n        super(DummyModel, self).__init__()\n        self.net = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef _test_setup_common_training_handlers(dirname, device, rank=0, local_rank=0, distributed=False, lr_scheduler=None):\n\n    lr = 0.01\n    step_size = 100\n    gamma = 0.5\n    num_iters = 100\n    num_epochs = 10\n\n    model = DummyModel().to(device)\n    if distributed and ""cuda"" in device:\n        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank,], output_device=local_rank)\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n\n    if lr_scheduler is None:\n        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n    elif isinstance(lr_scheduler, str) and lr_scheduler == ""ignite|LRScheduler"":\n        from ignite.contrib.handlers import LRScheduler\n\n        lr_scheduler = LRScheduler(torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma))\n    elif isinstance(lr_scheduler, str) and lr_scheduler == ""ignite"":\n        from ignite.contrib.handlers import PiecewiseLinear\n\n        milestones_values = [(0, 0.0), (step_size, lr), (num_iters * (num_epochs - 1), 0.0)]\n        lr_scheduler = PiecewiseLinear(optimizer, param_name=""lr"", milestones_values=milestones_values)\n    else:\n        raise ValueError(""Unknown lr_scheduler: {}"".format(lr_scheduler))\n\n    def update_fn(engine, batch):\n        if (engine.state.iteration - 1) % 50 == 0:\n            print(""- lr:"", optimizer.param_groups[0][""lr""])\n        optimizer.zero_grad()\n        x = torch.tensor([batch], requires_grad=True, device=device)\n        y_pred = model(x)\n        loss = y_pred.mean()\n        loss.backward()\n        optimizer.step()\n        return loss\n\n    train_sampler = None\n    if distributed and idist.get_world_size() > 1:\n        train_sampler = MagicMock(spec=DistributedSampler)\n        train_sampler.set_epoch = MagicMock()\n\n    trainer = Engine(update_fn)\n    setup_common_training_handlers(\n        trainer,\n        train_sampler=train_sampler,\n        to_save={""model"": model, ""optimizer"": optimizer},\n        save_every_iters=75,\n        output_path=dirname,\n        lr_scheduler=lr_scheduler,\n        with_gpu_stats=False,\n        output_names=[""batch_loss"",],\n        with_pbars=True,\n        with_pbar_on_iters=True,\n        log_every_iters=50,\n    )\n\n    data = [i * 0.1 for i in range(num_iters)]\n    trainer.run(data, max_epochs=num_epochs)\n\n    # check handlers\n    handlers = trainer._event_handlers[Events.ITERATION_COMPLETED]\n    for cls in [\n        TerminateOnNan,\n    ]:\n        assert any([isinstance(h[0], cls) for h in handlers]), ""{}"".format(handlers)\n    assert ""batch_loss"" in trainer.state.metrics\n\n    # Check saved checkpoint\n    if rank == 0:\n        checkpoints = list(os.listdir(dirname))\n        assert len(checkpoints) == 1\n        for v in [\n            ""training_checkpoint"",\n        ]:\n            assert any([v in c for c in checkpoints])\n\n    # Check LR scheduling\n    assert optimizer.param_groups[0][""lr""] <= lr * gamma ** (num_iters * num_epochs / step_size), ""{} vs {}"".format(\n        optimizer.param_groups[0][""lr""], lr * gamma ** (num_iters * num_epochs / step_size)\n    )\n\n\ndef test_asserts_setup_common_training_handlers():\n    trainer = Engine(lambda e, b: None)\n\n    with pytest.raises(\n        ValueError, match=r""If to_save argument is provided then output_path argument should be also defined""\n    ):\n        setup_common_training_handlers(trainer, to_save={})\n\n    with pytest.warns(UserWarning, match=r""Argument train_sampler is a distributed sampler""):\n        train_sampler = MagicMock(spec=DistributedSampler)\n        setup_common_training_handlers(trainer, train_sampler=train_sampler)\n\n    with pytest.warns(UserWarning, match=r""Argument device is unused and deprecated""):\n        setup_common_training_handlers(trainer, device=""cpu"")\n\n\ndef test_no_warning_with_train_sampler(recwarn):\n    from torch.utils.data import RandomSampler\n\n    trainer = Engine(lambda e, b: None)\n    train_sampler = RandomSampler([0, 1, 2])\n    setup_common_training_handlers(trainer, train_sampler=train_sampler)\n    assert len(recwarn) == 0, recwarn.pop()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""WORLD_SIZE"" not in os.environ, reason=""Should have more than 1 worker"")\ndef test_assert_setup_common_training_handlers_wrong_train_sampler(distributed_context_single_node_gloo):\n    trainer = Engine(lambda e, b: None)\n\n    from torch.utils.data.sampler import RandomSampler\n\n    with pytest.raises(TypeError, match=r""Train sampler should be torch DistributedSampler""):\n        train_sampler = RandomSampler([0, 1, 2, 3])\n        setup_common_training_handlers(trainer, train_sampler)\n\n\ndef test_setup_common_training_handlers(dirname, capsys):\n\n    _test_setup_common_training_handlers(dirname, device=""cpu"")\n\n    # Check epoch-wise pbar\n    captured = capsys.readouterr()\n    out = captured.err.split(""\\r"")\n    out = list(map(lambda x: x.strip(), out))\n    out = list(filter(None, out))\n    assert ""Epoch:"" in out[-1], ""{}"".format(out[-1])\n\n\ndef test_save_best_model_by_val_score(dirname, capsys):\n\n    trainer = Engine(lambda e, b: None)\n    evaluator = Engine(lambda e, b: None)\n    model = DummyModel()\n\n    acc_scores = [0.1, 0.2, 0.3, 0.4, 0.3, 0.5, 0.6, 0.61, 0.7, 0.5]\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def validate(engine):\n        evaluator.run(\n            [0,]\n        )\n\n    @evaluator.on(Events.EPOCH_COMPLETED)\n    def set_eval_metric(engine):\n        engine.state.metrics = {""acc"": acc_scores[trainer.state.epoch - 1]}\n\n    save_best_model_by_val_score(dirname, evaluator, model, metric_name=""acc"", n_saved=2, trainer=trainer)\n\n    data = [\n        0,\n    ]\n    trainer.run(data, max_epochs=len(acc_scores))\n\n    assert set(os.listdir(dirname)) == set([""best_model_8_val_acc=0.6100.pt"", ""best_model_9_val_acc=0.7000.pt""])\n\n\ndef test_add_early_stopping_by_val_score():\n    trainer = Engine(lambda e, b: None)\n    evaluator = Engine(lambda e, b: None)\n\n    acc_scores = [0.1, 0.2, 0.3, 0.4, 0.3, 0.3, 0.2, 0.1, 0.1, 0.0]\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def validate(engine):\n        evaluator.run(\n            [0,]\n        )\n\n    @evaluator.on(Events.EPOCH_COMPLETED)\n    def set_eval_metric(engine):\n        engine.state.metrics = {""acc"": acc_scores[trainer.state.epoch - 1]}\n\n    add_early_stopping_by_val_score(patience=3, evaluator=evaluator, trainer=trainer, metric_name=""acc"")\n\n    data = [\n        0,\n    ]\n    state = trainer.run(data, max_epochs=len(acc_scores))\n\n    assert state.epoch == 7\n\n\ndef test_deprecated_setup_any_logging():\n\n    with pytest.raises(DeprecationWarning, match=r""is deprecated since 0\\.4\\.0\\.""):\n        setup_any_logging(None, None, None, None, None, None)\n\n\ndef test__setup_logging_wrong_args():\n\n    with pytest.raises(TypeError, match=r""Argument optimizers should be either a single optimizer or""):\n        _setup_logging(MagicMock(), MagicMock(), ""abc"", MagicMock(), 1)\n\n    with pytest.raises(TypeError, match=r""Argument evaluators should be either a single engine or""):\n        _setup_logging(MagicMock(), MagicMock(), MagicMock(spec=torch.optim.SGD), ""abc"", 1)\n\n\ndef _test_setup_logging(\n    setup_logging_fn,\n    kwargs_dict,\n    output_handler_cls,\n    opt_params_handler_cls,\n    with_eval=True,\n    with_optim=True,\n    as_class=False,\n    log_every_iters=1,\n):\n    trainer = Engine(lambda e, b: b)\n    evaluators = None\n    optimizers = None\n\n    if with_eval:\n        evaluator = Engine(lambda e, b: None)\n        acc_scores = [0.1, 0.2, 0.3, 0.4, 0.3, 0.3, 0.2, 0.1, 0.1, 0.0]\n\n        @trainer.on(Events.EPOCH_COMPLETED)\n        def validate(engine):\n            evaluator.run(\n                [0,]\n            )\n\n        @evaluator.on(Events.EPOCH_COMPLETED)\n        def set_eval_metric(engine):\n            engine.state.metrics = {""acc"": acc_scores[trainer.state.epoch - 1]}\n\n        evaluators = {""validation"": evaluator}\n        if as_class:\n            evaluators = evaluators[""validation""]\n\n    if with_optim:\n        t = torch.tensor([0,])\n        optimizers = {""optimizer"": torch.optim.SGD([t,], lr=0.01)}\n        if as_class:\n            optimizers = optimizers[""optimizer""]\n\n    kwargs_dict[""trainer""] = trainer\n    kwargs_dict[""optimizers""] = optimizers\n    kwargs_dict[""evaluators""] = evaluators\n    kwargs_dict[""log_every_iters""] = log_every_iters\n\n    x_logger = setup_logging_fn(**kwargs_dict)\n\n    handlers = trainer._event_handlers[Events.ITERATION_COMPLETED]\n    for cls in [\n        output_handler_cls,\n    ]:\n        assert any([isinstance(h[0], cls) for h in handlers]), ""{}"".format(handlers)\n\n    if with_optim:\n        handlers = trainer._event_handlers[Events.ITERATION_STARTED]\n        for cls in [\n            opt_params_handler_cls,\n        ]:\n            assert any([isinstance(h[0], cls) for h in handlers]), ""{}"".format(handlers)\n\n    if with_eval:\n        handlers = evaluator._event_handlers[Events.COMPLETED]\n        for cls in [\n            output_handler_cls,\n        ]:\n            assert any([isinstance(h[0], cls) for h in handlers]), ""{}"".format(handlers)\n\n    data = [0, 1, 2]\n    trainer.run(data, max_epochs=10)\n\n    if ""output_path"" in kwargs_dict:\n        tb_files = list(os.listdir(kwargs_dict[""output_path""]))\n        assert len(tb_files) == 1\n        for v in [\n            ""events"",\n        ]:\n            assert any([v in c for c in tb_files]), ""{}"".format(tb_files)\n\n    return x_logger\n\n\ndef test_setup_tb_logging(dirname):\n\n    tb_logger = _test_setup_logging(\n        setup_logging_fn=setup_tb_logging,\n        kwargs_dict={""output_path"": os.path.join(dirname, ""t1"")},\n        output_handler_cls=handlers.tensorboard_logger.OutputHandler,\n        opt_params_handler_cls=handlers.tensorboard_logger.OptimizerParamsHandler,\n        with_eval=False,\n        with_optim=False,\n    )\n    tb_logger.close()\n    tb_logger = _test_setup_logging(\n        setup_logging_fn=setup_tb_logging,\n        kwargs_dict={""output_path"": os.path.join(dirname, ""t2"")},\n        output_handler_cls=handlers.tensorboard_logger.OutputHandler,\n        opt_params_handler_cls=handlers.tensorboard_logger.OptimizerParamsHandler,\n        with_eval=True,\n        with_optim=True,\n    )\n    tb_logger.close()\n    tb_logger = _test_setup_logging(\n        setup_logging_fn=setup_tb_logging,\n        kwargs_dict={""output_path"": os.path.join(dirname, ""t3"")},\n        output_handler_cls=handlers.tensorboard_logger.OutputHandler,\n        opt_params_handler_cls=handlers.tensorboard_logger.OptimizerParamsHandler,\n        with_eval=True,\n        with_optim=True,\n        as_class=True,\n        log_every_iters=None,\n    )\n    tb_logger.close()\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_setup_visdom_logging(visdom_server):\n    vis_logger = _test_setup_logging(\n        setup_logging_fn=setup_visdom_logging,\n        kwargs_dict={""server"": visdom_server[0], ""port"": str(visdom_server[1])},\n        output_handler_cls=handlers.visdom_logger.OutputHandler,\n        opt_params_handler_cls=handlers.visdom_logger.OptimizerParamsHandler,\n        with_eval=False,\n        with_optim=False,\n    )\n    vis_logger.close()\n\n    vis_logger = _test_setup_logging(\n        setup_logging_fn=setup_visdom_logging,\n        kwargs_dict={""server"": visdom_server[0], ""port"": str(visdom_server[1])},\n        output_handler_cls=handlers.visdom_logger.OutputHandler,\n        opt_params_handler_cls=handlers.visdom_logger.OptimizerParamsHandler,\n        with_eval=True,\n        with_optim=True,\n    )\n    vis_logger.close()\n\n\ndef test_setup_plx_logging():\n\n    os.environ[""POLYAXON_NO_OP""] = ""1""\n\n    _test_setup_logging(\n        setup_logging_fn=setup_plx_logging,\n        kwargs_dict={},\n        output_handler_cls=handlers.polyaxon_logger.OutputHandler,\n        opt_params_handler_cls=handlers.polyaxon_logger.OptimizerParamsHandler,\n        with_eval=False,\n        with_optim=False,\n    )\n    _test_setup_logging(\n        setup_logging_fn=setup_plx_logging,\n        kwargs_dict={},\n        output_handler_cls=handlers.polyaxon_logger.OutputHandler,\n        opt_params_handler_cls=handlers.polyaxon_logger.OptimizerParamsHandler,\n        with_eval=True,\n        with_optim=True,\n    )\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_setup_mlflow_logging(dirname):\n    mlf_logger = _test_setup_logging(\n        setup_logging_fn=setup_mlflow_logging,\n        kwargs_dict={""tracking_uri"": os.path.join(dirname, ""p1"")},\n        output_handler_cls=handlers.mlflow_logger.OutputHandler,\n        opt_params_handler_cls=handlers.mlflow_logger.OptimizerParamsHandler,\n        with_eval=False,\n        with_optim=False,\n    )\n    mlf_logger.close()\n    mlf_logger = _test_setup_logging(\n        setup_logging_fn=setup_mlflow_logging,\n        kwargs_dict={""tracking_uri"": os.path.join(dirname, ""p2"")},\n        output_handler_cls=handlers.mlflow_logger.OutputHandler,\n        opt_params_handler_cls=handlers.mlflow_logger.OptimizerParamsHandler,\n        with_eval=True,\n        with_optim=True,\n    )\n    mlf_logger.close()\n\n\ndef test_setup_wandb_logging(dirname):\n\n    from unittest.mock import patch\n\n    with patch(""ignite.contrib.engines.common.WandBLogger"") as _:\n        setup_wandb_logging(MagicMock())\n\n\ndef test_setup_trains_logging():\n\n    handlers.trains_logger.TrainsLogger.set_bypass_mode(True)\n\n    with pytest.warns(UserWarning, match=r""running in bypass mode""):\n        trains_logger = _test_setup_logging(\n            setup_logging_fn=setup_trains_logging,\n            kwargs_dict={},\n            output_handler_cls=handlers.trains_logger.OutputHandler,\n            opt_params_handler_cls=handlers.trains_logger.OptimizerParamsHandler,\n            with_eval=False,\n            with_optim=False,\n        )\n        trains_logger.close()\n        trains_logger = _test_setup_logging(\n            setup_logging_fn=setup_trains_logging,\n            kwargs_dict={},\n            output_handler_cls=handlers.trains_logger.OutputHandler,\n            opt_params_handler_cls=handlers.trains_logger.OptimizerParamsHandler,\n            with_eval=True,\n            with_optim=True,\n        )\n        trains_logger.close()\n\n\ndef test_setup_neptune_logging(dirname):\n    npt_logger = _test_setup_logging(\n        setup_logging_fn=setup_neptune_logging,\n        kwargs_dict={""offline_mode"": True},\n        output_handler_cls=handlers.neptune_logger.OutputHandler,\n        opt_params_handler_cls=handlers.neptune_logger.OptimizerParamsHandler,\n        with_eval=False,\n        with_optim=False,\n    )\n    npt_logger.close()\n    npt_logger = _test_setup_logging(\n        setup_logging_fn=setup_neptune_logging,\n        kwargs_dict={""offline_mode"": True},\n        output_handler_cls=handlers.neptune_logger.OutputHandler,\n        opt_params_handler_cls=handlers.neptune_logger.OptimizerParamsHandler,\n        with_eval=True,\n        with_optim=True,\n    )\n    npt_logger.close()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(dirname, distributed_context_single_node_nccl):\n    local_rank = distributed_context_single_node_nccl[""local_rank""]\n    device = ""cuda:{}"".format(local_rank)\n    _test_setup_common_training_handlers(dirname, device, rank=local_rank, local_rank=local_rank, distributed=True)\n    test_add_early_stopping_by_val_score()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(dirname, distributed_context_single_node_gloo):\n    device = ""cpu""\n    local_rank = distributed_context_single_node_gloo[""local_rank""]\n    _test_setup_common_training_handlers(dirname, device, rank=local_rank, local_rank=local_rank, distributed=True)\n    _test_setup_common_training_handlers(\n        dirname, device, rank=local_rank, local_rank=local_rank, distributed=True, lr_scheduler=""ignite|LRScheduler""\n    )\n    _test_setup_common_training_handlers(\n        dirname, device, rank=local_rank, local_rank=local_rank, distributed=True, lr_scheduler=""ignite""\n    )\n    test_add_early_stopping_by_val_score()\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_cpu(dirname, distributed_context_multi_node_gloo):\n    device = ""cpu""\n    rank = distributed_context_multi_node_gloo[""rank""]\n    _test_setup_common_training_handlers(dirname, device, rank=rank)\n    test_add_early_stopping_by_val_score()\n\n\n@pytest.mark.multinode_distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(""GPU_MULTINODE_DISTRIB"" not in os.environ, reason=""Skip if not multi-node distributed"")\ndef test_multinode_distrib_gpu(dirname, distributed_context_multi_node_nccl):\n    local_rank = distributed_context_multi_node_nccl[""local_rank""]\n    rank = distributed_context_multi_node_nccl[""rank""]\n    device = ""cuda:{}"".format(local_rank)\n    _test_setup_common_training_handlers(dirname, device, rank=rank, local_rank=local_rank, distributed=True)\n    test_add_early_stopping_by_val_score()\n'"
tests/ignite/contrib/engines/test_tbptt.py,10,"b'# coding: utf-8\n\nimport unittest.mock as mock\n\nimport pytest\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom ignite.contrib.engines import Tbptt_Events, create_supervised_tbptt_trainer\nfrom ignite.contrib.engines.tbptt import _detach_hidden\n\n\ndef test_detach_hidden_RNN():\n    # Create hidden vector (in tuple)\n    X = torch.ones(2, 3, 4)\n    model = nn.RNN(4, 1)\n    _, hidden = model(X)\n\n    # Function to test\n    hidden_ = _detach_hidden(hidden)\n\n    assert hidden_.grad_fn is None  # properly detached\n    assert (hidden == hidden_).all().item() == 1  # Equal values\n\n\ndef test_detach_hidden_LSTM():\n    # Create hidden vector (in tuple)\n    X = torch.ones(2, 3, 4)\n    model = nn.LSTM(4, 1)\n    _, hidden = model(X)\n\n    # Function to test\n    hidden_ = _detach_hidden(hidden)\n\n    for h, h_ in zip(hidden, hidden_):\n        assert h_.grad_fn is None  # properly detached\n        assert (h == h_).all().item() == 1  # Equal values\n\n\ndef test_detach_hidden_raise():\n    with pytest.raises(TypeError):\n        _detach_hidden(0)\n\n\n@mock.patch(""ignite.contrib.engines.tbptt._detach_hidden"")\ndef test_create_supervised_tbptt_trainer_callcounts(mock_detach_hidden):\n    # Mocking objects\n    model = mock.MagicMock()\n    # Necessary to unpack output\n    model.return_value = (1, 1)\n    optimizer = mock.MagicMock()\n    loss = mock.MagicMock()\n\n    trainer = create_supervised_tbptt_trainer(model, optimizer, loss, tbtt_step=2)\n\n    # Adding two mock handles to the trainer to monitor that TBPTT events are\n    # called correctly\n    handle_started = mock.MagicMock()\n    trainer.add_event_handler(Tbptt_Events.TIME_ITERATION_STARTED, handle_started)\n    handle_completed = mock.MagicMock()\n    trainer.add_event_handler(Tbptt_Events.TIME_ITERATION_COMPLETED, handle_completed)\n\n    # Fake data\n    X = torch.ones(6, 2, 1)\n    y = torch.ones(6, 2, 1)\n    data = [(X, y)]\n\n    # Running trainer\n    trainer.run(data)\n\n    # Verifications\n    assert handle_started.call_count == 3\n    assert handle_completed.call_count == 3\n    assert mock_detach_hidden.call_count == 2\n    assert model.call_count == 3\n    assert loss.call_count == 3\n    assert optimizer.zero_grad.call_count == 3\n    assert optimizer.step.call_count == 3\n    n_args_tuple = tuple(len(args) for args, kwargs in model.call_args_list)\n    assert n_args_tuple == (1, 2, 2)\n\n\ndef _test_create_supervised_tbptt_trainer(device):\n    # Defining dummy recurrent model with zero weights\n    model = nn.RNN(1, 1, bias=False)\n    model.to(device)  # Move model before creating optimizer\n    for p in model.parameters():\n        p.data.zero_()\n\n    # Set some mock on forward to monitor\n    forward_mock = mock.MagicMock()\n    forward_mock.return_value = None\n    model.register_forward_hook(forward_mock)\n\n    # Defning optimizer and trainer\n    optimizer = optim.SGD(model.parameters(), 1)\n    trainer = create_supervised_tbptt_trainer(model, optimizer, F.mse_loss, tbtt_step=2, device=device)\n\n    # Fake data\n    X = torch.ones(6, 2, 1)\n    y = torch.ones(6, 2, 1)\n    data = [(X, y)]\n\n    # Running trainer\n    trainer.run(data)\n\n    # If tbptt is not use (one gradient update), the hidden to hidden weight\n    # should stay zero\n    assert not model.weight_hh_l0.item() == pytest.approx(0)\n\n    # Cheking forward calls\n    assert forward_mock.call_count == 3\n    for i in range(3):\n        inputs = forward_mock.call_args_list[i][0][1]\n        if i == 0:\n            assert len(inputs) == 1\n        else:\n            assert len(inputs) == 2\n            x, h = inputs\n            assert h.is_leaf\n\n\ndef test_create_supervised_tbptt_trainer_with_cpu():\n    _test_create_supervised_tbptt_trainer(""cpu"")\n\n\n@pytest.mark.skipif(not torch.cuda.is_available(), reason=""Skip if no GPU"")\ndef test_create_supervised_tbptt_trainer_on_cuda():\n    _test_create_supervised_tbptt_trainer(""cuda"")\n'"
tests/ignite/contrib/handlers/__init__.py,0,b''
tests/ignite/contrib/handlers/conftest.py,7,"b'from unittest.mock import Mock\n\nimport numpy as np\nimport pytest\nimport torch\n\n\n@pytest.fixture()\ndef norm_mock():\n    def norm(x):\n        return np.linalg.norm(x)\n\n    norm_mock = Mock(side_effect=norm, spec=norm)\n    norm_mock.configure_mock(**{""__name__"": ""norm""})\n    norm_mock.reset_mock()\n    return norm_mock\n\n\n@pytest.fixture()\ndef dummy_model_factory():\n    class DummyModel(torch.nn.Module):\n        def __init__(self):\n            super(DummyModel, self).__init__()\n            self.fc1 = torch.nn.Linear(10, 10)\n            self.fc2 = torch.nn.Linear(12, 12)\n            self.fc1.weight.data.zero_()\n            self.fc1.bias.data.zero_()\n            self.fc2.weight.data.fill_(1.0)\n            self.fc2.bias.data.fill_(1.0)\n\n    def get_dummy_model(with_grads=True, with_frozen_layer=False):\n        model = DummyModel()\n        if with_grads:\n            model.fc2.weight.grad = torch.zeros_like(model.fc2.weight)\n            model.fc2.bias.grad = torch.zeros_like(model.fc2.bias)\n\n            if not with_frozen_layer:\n                model.fc1.weight.grad = torch.zeros_like(model.fc1.weight)\n                model.fc1.bias.grad = torch.zeros_like(model.fc1.bias)\n\n        if with_frozen_layer:\n            for param in model.fc1.parameters():\n                param.requires_grad = False\n        return model\n\n    return get_dummy_model\n'"
tests/ignite/contrib/handlers/test_base_logger.py,3,"b'import math\nfrom unittest.mock import MagicMock\n\nimport pytest\nimport torch\n\nfrom ignite.contrib.handlers import CustomPeriodicEvent\nfrom ignite.contrib.handlers.base_logger import BaseLogger, BaseOptimizerParamsHandler, BaseOutputHandler\nfrom ignite.engine import Engine, Events, State\n\n\nclass DummyOutputHandler(BaseOutputHandler):\n    def __call__(self, *args, **kwargs):\n        pass\n\n\nclass DummyOptParamsHandler(BaseOptimizerParamsHandler):\n    def __call__(self, *args, **kwargs):\n        pass\n\n\nclass DummyLogger(BaseLogger):\n    def _create_output_handler(self, *args, **kwargs):\n        return DummyOutputHandler(*args, **kwargs)\n\n    def _create_opt_params_handler(self, *args, **kwargs):\n        return DummyOptParamsHandler(*args, **kwargs)\n\n\ndef test_base_output_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""metric_names should be either a list or equal \'all\'""):\n        DummyOutputHandler(""tag"", metric_names=""abc"", output_transform=None)\n\n    with pytest.raises(TypeError, match=""output_transform should be a function""):\n        DummyOutputHandler(""tag"", metric_names=None, output_transform=""abc"")\n\n    with pytest.raises(ValueError, match=""Either metric_names or output_transform should be defined""):\n        DummyOutputHandler(""tag"", None, None)\n\n    with pytest.raises(TypeError, match=""global_step_transform should be a function""):\n        DummyOutputHandler(""tag"", metric_names=[""loss""], global_step_transform=""abc"")\n\n\ndef test_base_output_handler_setup_output_metrics():\n\n    engine = Engine(lambda engine, batch: None)\n    true_metrics = {""a"": 0, ""b"": 1}\n    engine.state = State(metrics=true_metrics)\n    engine.state.output = 12345\n\n    # Only metric_names\n    handler = DummyOutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=None)\n    metrics = handler._setup_output_metrics(engine=engine)\n    assert metrics == true_metrics\n\n    # Only metric_names with a warning\n    handler = DummyOutputHandler(""tag"", metric_names=[""a"", ""c""], output_transform=None)\n    with pytest.warns(UserWarning):\n        metrics = handler._setup_output_metrics(engine=engine)\n    assert metrics == {""a"": 0}\n\n    # Only output as ""output""\n    handler = DummyOutputHandler(""tag"", metric_names=None, output_transform=lambda x: x)\n    metrics = handler._setup_output_metrics(engine=engine)\n    assert metrics == {""output"": engine.state.output}\n\n    # Only output as ""loss""\n    handler = DummyOutputHandler(""tag"", metric_names=None, output_transform=lambda x: {""loss"": x})\n    metrics = handler._setup_output_metrics(engine=engine)\n    assert metrics == {""loss"": engine.state.output}\n\n    # Metrics and output\n    handler = DummyOutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=lambda x: {""loss"": x})\n    metrics = handler._setup_output_metrics(engine=engine)\n    assert metrics == {""a"": 0, ""b"": 1, ""loss"": engine.state.output}\n\n    # All metrics\n    handler = DummyOutputHandler(""tag"", metric_names=""all"", output_transform=None)\n    metrics = handler._setup_output_metrics(engine=engine)\n    assert metrics == true_metrics\n\n\ndef test_attach():\n\n    n_epochs = 5\n    data = list(range(50))\n\n    def _test(event, n_calls):\n\n        losses = torch.rand(n_epochs * len(data))\n        losses_iter = iter(losses)\n\n        def update_fn(engine, batch):\n            return next(losses_iter)\n\n        trainer = Engine(update_fn)\n\n        logger = DummyLogger()\n\n        mock_log_handler = MagicMock()\n\n        logger.attach(trainer, log_handler=mock_log_handler, event_name=event)\n\n        trainer.run(data, max_epochs=n_epochs)\n\n        mock_log_handler.assert_called_with(trainer, logger, event)\n        assert mock_log_handler.call_count == n_calls\n\n    _test(Events.ITERATION_STARTED, len(data) * n_epochs)\n    _test(Events.ITERATION_COMPLETED, len(data) * n_epochs)\n    _test(Events.EPOCH_STARTED, n_epochs)\n    _test(Events.EPOCH_COMPLETED, n_epochs)\n    _test(Events.STARTED, 1)\n    _test(Events.COMPLETED, 1)\n\n    _test(Events.ITERATION_STARTED(every=10), len(data) // 10 * n_epochs)\n\n\ndef test_attach_wrong_event_name():\n\n    trainer = Engine(lambda b, e: None)\n    logger = DummyLogger()\n    mock_log_handler = MagicMock()\n\n    with pytest.raises(RuntimeError, match=""Unknown event name""):\n        logger.attach(trainer, log_handler=mock_log_handler, event_name=""unknown"")\n\n\ndef test_attach_on_custom_event():\n    n_epochs = 10\n    data = list(range(150))\n\n    def _test(event, n_calls, cpe):\n\n        losses = torch.rand(n_epochs * len(data))\n        losses_iter = iter(losses)\n\n        def update_fn(engine, batch):\n            return next(losses_iter)\n\n        trainer = Engine(update_fn)\n        cpe.attach(trainer)\n\n        logger = DummyLogger()\n\n        mock_log_handler = MagicMock()\n\n        logger.attach(trainer, log_handler=mock_log_handler, event_name=event)\n\n        trainer.run(data, max_epochs=n_epochs)\n\n        mock_log_handler.assert_called_with(trainer, logger, event)\n        assert mock_log_handler.call_count == n_calls\n\n    with pytest.warns(DeprecationWarning, match=""CustomPeriodicEvent is deprecated""):\n        n_iterations = 10\n        cpe1 = CustomPeriodicEvent(n_iterations=n_iterations)\n        n = len(data) * n_epochs / n_iterations\n        nf = math.floor(n)\n        ns = nf + 1 if nf < n else nf\n        _test(cpe1.Events.ITERATIONS_10_STARTED, ns, cpe1)\n        _test(cpe1.Events.ITERATIONS_10_COMPLETED, nf, cpe1)\n\n    with pytest.warns(DeprecationWarning, match=""CustomPeriodicEvent is deprecated""):\n        n_iterations = 15\n        cpe2 = CustomPeriodicEvent(n_iterations=n_iterations)\n        n = len(data) * n_epochs / n_iterations\n        nf = math.floor(n)\n        ns = nf + 1 if nf < n else nf\n        _test(cpe2.Events.ITERATIONS_15_STARTED, ns, cpe2)\n        _test(cpe2.Events.ITERATIONS_15_COMPLETED, nf, cpe2)\n\n    with pytest.warns(DeprecationWarning, match=""CustomPeriodicEvent is deprecated""):\n        n_custom_epochs = 2\n        cpe3 = CustomPeriodicEvent(n_epochs=n_custom_epochs)\n        n = n_epochs / n_custom_epochs\n        nf = math.floor(n)\n        ns = nf + 1 if nf < n else nf\n        _test(cpe3.Events.EPOCHS_2_STARTED, ns, cpe3)\n        _test(cpe3.Events.EPOCHS_2_COMPLETED, nf, cpe3)\n\n\ndef test_as_context_manager():\n\n    n_epochs = 5\n    data = list(range(50))\n\n    class _DummyLogger(DummyLogger):\n        def __init__(self, writer):\n            self.writer = writer\n\n        def close(self):\n            self.writer.close()\n\n    def _test(event, n_calls):\n        global close_counter\n        close_counter = 0\n\n        losses = torch.rand(n_epochs * len(data))\n        losses_iter = iter(losses)\n\n        def update_fn(engine, batch):\n            return next(losses_iter)\n\n        writer = MagicMock()\n        writer.close = MagicMock()\n\n        with _DummyLogger(writer) as logger:\n            assert isinstance(logger, _DummyLogger)\n\n            trainer = Engine(update_fn)\n            mock_log_handler = MagicMock()\n\n            logger.attach(trainer, log_handler=mock_log_handler, event_name=event)\n\n            trainer.run(data, max_epochs=n_epochs)\n\n            mock_log_handler.assert_called_with(trainer, logger, event)\n            assert mock_log_handler.call_count == n_calls\n\n        writer.close.assert_called_once_with()\n\n    _test(Events.ITERATION_STARTED, len(data) * n_epochs)\n    _test(Events.ITERATION_COMPLETED, len(data) * n_epochs)\n    _test(Events.EPOCH_STARTED, n_epochs)\n    _test(Events.EPOCH_COMPLETED, n_epochs)\n    _test(Events.STARTED, 1)\n    _test(Events.COMPLETED, 1)\n\n    _test(Events.ITERATION_STARTED(every=10), len(data) // 10 * n_epochs)\n'"
tests/ignite/contrib/handlers/test_custom_events.py,0,"b'import math\n\nimport pytest\n\nfrom ignite.contrib.handlers.custom_events import CustomPeriodicEvent\nfrom ignite.engine import Engine\n\n\ndef test_bad_input():\n\n    with pytest.warns(DeprecationWarning, match=r""CustomPeriodicEvent is deprecated""):\n        with pytest.raises(ValueError, match=""Argument n_iterations should be positive integer number""):\n            CustomPeriodicEvent(n_iterations=""a"")\n        with pytest.raises(ValueError, match=""Argument n_iterations should be positive integer number""):\n            CustomPeriodicEvent(n_iterations=0)\n        with pytest.raises(ValueError, match=""Argument n_iterations should be positive integer number""):\n            CustomPeriodicEvent(n_iterations=10.0)\n        with pytest.raises(ValueError, match=""Argument n_epochs should be positive integer number""):\n            CustomPeriodicEvent(n_epochs=""a"")\n        with pytest.raises(ValueError, match=""Argument n_epochs should be positive integer number""):\n            CustomPeriodicEvent(n_epochs=0)\n        with pytest.raises(ValueError, match=""Argument n_epochs should be positive integer number""):\n            CustomPeriodicEvent(n_epochs=10.0)\n        with pytest.raises(ValueError, match=""Either n_iterations or n_epochs should be defined""):\n            CustomPeriodicEvent()\n        with pytest.raises(ValueError, match=""Either n_iterations or n_epochs should be defined""):\n            CustomPeriodicEvent(n_iterations=1, n_epochs=2)\n\n\ndef test_new_events():\n    def update(*args, **kwargs):\n        pass\n\n    with pytest.warns(DeprecationWarning, match=""CustomPeriodicEvent is deprecated""):\n        engine = Engine(update)\n        cpe = CustomPeriodicEvent(n_iterations=5)\n        cpe.attach(engine)\n\n        assert hasattr(cpe, ""Events"")\n        assert hasattr(cpe.Events, ""ITERATIONS_5_STARTED"")\n        assert hasattr(cpe.Events, ""ITERATIONS_5_COMPLETED"")\n\n        assert engine._allowed_events[-2] == getattr(cpe.Events, ""ITERATIONS_5_STARTED"")\n        assert engine._allowed_events[-1] == getattr(cpe.Events, ""ITERATIONS_5_COMPLETED"")\n\n    with pytest.warns(DeprecationWarning, match=""CustomPeriodicEvent is deprecated""):\n        cpe = CustomPeriodicEvent(n_epochs=5)\n        cpe.attach(engine)\n\n        assert hasattr(cpe, ""Events"")\n        assert hasattr(cpe.Events, ""EPOCHS_5_STARTED"")\n        assert hasattr(cpe.Events, ""EPOCHS_5_COMPLETED"")\n\n        assert engine._allowed_events[-2] == getattr(cpe.Events, ""EPOCHS_5_STARTED"")\n        assert engine._allowed_events[-1] == getattr(cpe.Events, ""EPOCHS_5_COMPLETED"")\n\n\ndef test_integration_iterations():\n    def _test(n_iterations, max_epochs, n_iters_per_epoch):\n        def update(*args, **kwargs):\n            pass\n\n        engine = Engine(update)\n        with pytest.warns(DeprecationWarning, match=""CustomPeriodicEvent is deprecated""):\n            cpe = CustomPeriodicEvent(n_iterations=n_iterations)\n            cpe.attach(engine)\n        data = list(range(n_iters_per_epoch))\n\n        custom_period = [0]\n        n_calls_iter_started = [0]\n        n_calls_iter_completed = [0]\n\n        event_started = getattr(cpe.Events, ""ITERATIONS_{}_STARTED"".format(n_iterations))\n\n        @engine.on(event_started)\n        def on_my_event_started(engine):\n            assert (engine.state.iteration - 1) % n_iterations == 0\n            custom_period[0] += 1\n            custom_iter = getattr(engine.state, ""iterations_{}"".format(n_iterations))\n            assert custom_iter == custom_period[0]\n            n_calls_iter_started[0] += 1\n\n        event_completed = getattr(cpe.Events, ""ITERATIONS_{}_COMPLETED"".format(n_iterations))\n\n        @engine.on(event_completed)\n        def on_my_event_ended(engine):\n            assert engine.state.iteration % n_iterations == 0\n            custom_iter = getattr(engine.state, ""iterations_{}"".format(n_iterations))\n            assert custom_iter == custom_period[0]\n            n_calls_iter_completed[0] += 1\n\n        engine.run(data, max_epochs=max_epochs)\n\n        n = len(data) * max_epochs / n_iterations\n        nf = math.floor(n)\n        assert custom_period[0] == n_calls_iter_started[0]\n        assert n_calls_iter_started[0] == nf + 1 if nf < n else nf\n        assert n_calls_iter_completed[0] == nf\n\n    _test(3, 5, 16)\n    _test(4, 5, 16)\n    _test(5, 5, 16)\n    _test(300, 50, 1000)\n\n\ndef test_integration_epochs():\n    def update(*args, **kwargs):\n        pass\n\n    engine = Engine(update)\n\n    n_epochs = 3\n    with pytest.warns(DeprecationWarning, match=""CustomPeriodicEvent is deprecated""):\n        cpe = CustomPeriodicEvent(n_epochs=n_epochs)\n        cpe.attach(engine)\n    data = list(range(16))\n\n    custom_period = [1]\n\n    @engine.on(cpe.Events.EPOCHS_3_STARTED)\n    def on_my_epoch_started(engine):\n        assert (engine.state.epoch - 1) % n_epochs == 0\n        assert engine.state.epochs_3 == custom_period[0]\n\n    @engine.on(cpe.Events.EPOCHS_3_COMPLETED)\n    def on_my_epoch_ended(engine):\n        assert engine.state.epoch % n_epochs == 0\n        assert engine.state.epochs_3 == custom_period[0]\n        custom_period[0] += 1\n\n    engine.run(data, max_epochs=10)\n\n    assert custom_period[0] == 4\n'"
tests/ignite/contrib/handlers/test_lr_finder.py,2,"b'import copy\n\nimport matplotlib\nimport pytest\nimport torch\nfrom torch import nn\nfrom torch.optim import SGD\n\nfrom ignite.contrib.handlers import FastaiLRFinder\nfrom ignite.engine import create_supervised_trainer\n\nmatplotlib.use(""agg"")\n\n\n@pytest.fixture\ndef no_site_packages():\n    import sys\n\n    matplotlib = sys.modules[""matplotlib""]\n    del sys.modules[""matplotlib""]\n    prev_path = list(sys.path)\n    sys.path = [p for p in sys.path if ""site-packages"" not in p]\n    yield ""no_site_packages""\n    sys.path = prev_path\n    sys.modules[""matplotlib""] = matplotlib\n\n\nclass DummyModel(nn.Module):\n    def __init__(self):\n        super(DummyModel, self).__init__()\n        self.net = nn.Linear(1, 1)\n\n    def forward(self, x):\n        return self.net(x)\n\n\n@pytest.fixture\ndef model():\n    model = DummyModel()\n    yield model\n\n\n@pytest.fixture\ndef optimizer(model):\n    yield SGD(model.parameters(), lr=1e-4, momentum=0.9)\n\n\n@pytest.fixture\ndef to_save(model, optimizer):\n    yield {""model"": model, ""optimizer"": optimizer}\n\n\n@pytest.fixture\ndef lr_finder():\n    yield FastaiLRFinder()\n\n\n@pytest.fixture\ndef dummy_engine(model, optimizer):\n    engine = create_supervised_trainer(model, optimizer, nn.MSELoss())\n    yield engine\n\n\n@pytest.fixture\ndef dataloader():\n    yield torch.rand(100, 2, 1)\n\n\ndef test_attach_incorrect_input_args(lr_finder, dummy_engine, model, optimizer, dataloader):\n\n    with pytest.raises(TypeError, match=r""Argument to_save should be a mapping""):\n        with lr_finder.attach(dummy_engine, to_save=123) as f:\n            pass\n\n    with pytest.raises(TypeError, match=r""Object <class \'int\'> should have `state_dict` method""):\n        with lr_finder.attach(dummy_engine, to_save={1: 2}) as f:\n            pass\n\n    with pytest.raises(ValueError, match=r""Mapping to_save should contain \'optimizer\' key""):\n        with lr_finder.attach(dummy_engine, to_save={""model"": model}) as f:\n            pass\n\n    to_save = {""model"": model, ""optimizer"": optimizer}\n    with pytest.raises(ValueError, match=r""smooth_f is outside the range \\[0, 1\\]""):\n        with lr_finder.attach(dummy_engine, to_save=to_save, smooth_f=234) as f:\n            pass\n\n    with pytest.raises(ValueError, match=r""diverge_th should be larger than 1""):\n        with lr_finder.attach(dummy_engine, to_save=to_save, diverge_th=0.0) as f:\n            pass\n\n    with pytest.raises(ValueError, match=r""if provided, num_iter should be a positive integer""):\n        with lr_finder.attach(dummy_engine, to_save=to_save, num_iter=0.0) as f:\n            pass\n\n    with lr_finder.attach(dummy_engine, to_save) as trainer_with_finder:\n        trainer_with_finder.run(dataloader)\n\n    with pytest.raises(ValueError, match=r""skip_start cannot be negative""):\n        lr_finder.plot(skip_start=-1)\n    with pytest.raises(ValueError, match=r""skip_end cannot be negative""):\n        lr_finder.plot(skip_end=-1)\n\n\ndef test_attach_without_with(lr_finder, dummy_engine, to_save):\n    _ = lr_finder.attach(dummy_engine, to_save=to_save)\n    for event in dummy_engine._event_handlers:\n        assert len(dummy_engine._event_handlers[event]) == 0\n\n    with lr_finder.attach(dummy_engine, to_save=to_save) as _:\n        assert any([len(dummy_engine._event_handlers[event]) != 0 for event in dummy_engine._event_handlers])\n\n        with pytest.raises(\n            RuntimeError, match=r""learning rate finder didn\'t run yet so lr_suggestion can\'t be returned""\n        ):\n            lr_finder.lr_suggestion()\n        with pytest.raises(RuntimeError, match=r""learning rate finder didn\'t run yet so results can\'t be plotted""):\n            lr_finder.plot()\n\n\ndef test_with_attach(lr_finder, to_save, dummy_engine, dataloader):\n    with lr_finder.attach(dummy_engine, to_save=to_save) as trainer_with_finder:\n        trainer_with_finder.run(dataloader)\n\n    assert lr_finder.get_results() is not None\n\n    for event in dummy_engine._event_handlers:\n        assert len(dummy_engine._event_handlers[event]) == 0\n\n\ndef test_model_optimizer_reset(lr_finder, to_save, dummy_engine, dataloader):\n    optimizer = to_save[""optimizer""]\n    model = to_save[""model""]\n\n    init_optimizer_sd = copy.deepcopy(optimizer.state_dict())\n    init_model_sd = copy.deepcopy(model.state_dict())\n    init_trainer_sd = copy.deepcopy(dummy_engine.state_dict())\n\n    with pytest.warns(UserWarning, match=r""Run completed without loss diverging""):\n        with lr_finder.attach(dummy_engine, to_save=to_save, diverge_th=float(""inf"")) as trainer_with_finder:\n            trainer_with_finder.run(dataloader)\n\n    assert init_optimizer_sd == optimizer.state_dict()\n    assert init_model_sd == model.state_dict()\n    assert init_trainer_sd == dummy_engine.state_dict()\n\n\ndef test_lr_policy(lr_finder, to_save, dummy_engine, dataloader):\n    with lr_finder.attach(dummy_engine, to_save=to_save, step_mode=""linear"") as trainer_with_finder:\n        trainer_with_finder.run(dataloader)\n\n    lr = lr_finder.get_results()[""lr""]\n    assert all([lr[i - 1] < lr[i] for i in range(1, len(lr))])\n\n    with lr_finder.attach(dummy_engine, to_save=to_save, step_mode=""exp"") as trainer_with_finder:\n        trainer_with_finder.run(dataloader)\n\n    lr = lr_finder.get_results()[""lr""]\n    assert all([lr[i - 1] < lr[i] for i in range(1, len(lr))])\n\n\ndef assert_output_sizes(lr_finder, dummy_engine):\n    iteration = dummy_engine.state.iteration\n    lr_finder_results = lr_finder.get_results()\n    lr, loss = lr_finder_results[""lr""], lr_finder_results[""loss""]\n    assert len(lr) == len(loss) == iteration\n\n\ndef test_num_iter_is_none(lr_finder, to_save, dummy_engine, dataloader):\n\n    with pytest.warns(UserWarning, match=r""Run completed without loss diverging""):\n        with lr_finder.attach(dummy_engine, to_save=to_save, diverge_th=float(""inf"")) as trainer_with_finder:\n            trainer_with_finder.run(dataloader)\n            assert_output_sizes(lr_finder, dummy_engine)\n            assert dummy_engine.state.iteration == len(dataloader)\n\n\ndef test_num_iter_is_enough(lr_finder, to_save, dummy_engine, dataloader):\n\n    with pytest.warns(UserWarning, match=r""Run completed without loss diverging""):\n        with lr_finder.attach(\n            dummy_engine, to_save=to_save, num_iter=50, diverge_th=float(""inf"")\n        ) as trainer_with_finder:\n            trainer_with_finder.run(dataloader)\n            assert_output_sizes(lr_finder, dummy_engine)\n            # -1 because it terminates when state.iteration > num_iter\n            assert dummy_engine.state.iteration - 1 == 50\n\n\ndef test_num_iter_is_not_enough(lr_finder, to_save, dummy_engine, dataloader):\n    with lr_finder.attach(dummy_engine, to_save, num_iter=150, diverge_th=float(""inf"")) as trainer_with_finder:\n        with pytest.warns(UserWarning):\n            trainer_with_finder.run(dataloader)\n        assert_output_sizes(lr_finder, dummy_engine)\n        assert dummy_engine.state.iteration == len(dataloader)\n\n\ndef test_detach_terminates(lr_finder, to_save, dummy_engine, dataloader):\n    with lr_finder.attach(dummy_engine, to_save, end_lr=100, diverge_th=2) as trainer_with_finder:\n        with pytest.warns(None) as record:\n            trainer_with_finder.run(dataloader)\n            assert len(record) == 0\n\n    dummy_engine.run(dataloader, max_epochs=3)\n    assert dummy_engine.state.epoch == 3\n\n\ndef test_lr_suggestion(lr_finder, to_save, dummy_engine, dataloader):\n    with lr_finder.attach(dummy_engine, to_save) as trainer_with_finder:\n        trainer_with_finder.run(dataloader)\n\n    assert 1e-4 <= lr_finder.lr_suggestion() <= 10\n\n\ndef test_plot(lr_finder, to_save, dummy_engine, dataloader):\n\n    with lr_finder.attach(dummy_engine, to_save) as trainer_with_finder:\n        trainer_with_finder.run(dataloader)\n\n    lr_finder.plot()\n    lr_finder.plot(skip_end=0)\n\n\ndef test_no_matplotlib(no_site_packages, lr_finder):\n\n    with pytest.raises(RuntimeError, match=r""This method requires matplotlib to be installed""):\n        lr_finder.plot()\n'"
tests/ignite/contrib/handlers/test_mlflow_logger.py,6,"b'import os\nimport sys\nfrom unittest.mock import MagicMock, call\n\nimport pytest\nimport torch\n\nfrom ignite.contrib.handlers.mlflow_logger import *\nfrom ignite.engine import Engine, Events, State\n\n\ndef test_output_handler_with_wrong_logger_type():\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'OutputHandler\' works only with MLflowLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_output_handler_output_transform():\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.output = 12345\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    mock_logger.log_metrics.assert_called_once_with({""tag output"": 12345}, step=123)\n\n    wrapper = OutputHandler(""another_tag"", output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metrics.assert_called_once_with(\n        {""another_tag loss"": 12345}, step=123,\n    )\n\n\ndef test_output_handler_metric_names():\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b"", ""c""])\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45, ""c"": torch.tensor(10.0)})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_called_once_with(\n        {""tag a"": 12.23, ""tag b"": 23.45, ""tag c"": 10.0}, step=5,\n    )\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"",])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": torch.Tensor([0.0, 1.0, 2.0, 3.0])})\n    mock_engine.state.iteration = 5\n\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_has_calls(\n        [call({""tag a 0"": 0.0, ""tag a 1"": 1.0, ""tag a 2"": 2.0, ""tag a 3"": 3.0}, step=5),], any_order=True\n    )\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""c""])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 55.56, ""c"": ""Some text""})\n    mock_engine.state.iteration = 7\n\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    with pytest.warns(UserWarning):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_has_calls([call({""tag a"": 55.56}, step=7)], any_order=True)\n\n\ndef test_output_handler_both():\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_called_once_with(\n        {""tag a"": 12.23, ""tag b"": 23.45, ""tag loss"": 12345}, step=5,\n    )\n\n\ndef test_output_handler_with_wrong_global_step_transform_output():\n    def global_step_transform(*args, **kwargs):\n        return ""a""\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    with pytest.raises(TypeError, match=""global_step must be int""):\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n\ndef test_output_handler_with_global_step_transform():\n    def global_step_transform(*args, **kwargs):\n        return 10\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    mock_logger.log_metrics.assert_called_once_with({""tag loss"": 12345}, step=10)\n\n\ndef test_output_handler_with_global_step_from_engine():\n\n    mock_another_engine = MagicMock()\n    mock_another_engine.state = State()\n    mock_another_engine.state.epoch = 10\n    mock_another_engine.state.output = 12.345\n\n    wrapper = OutputHandler(\n        ""tag"",\n        output_transform=lambda x: {""loss"": x},\n        global_step_transform=global_step_from_engine(mock_another_engine),\n    )\n\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 1\n    mock_engine.state.output = 0.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_has_calls(\n        [call({""tag loss"": mock_engine.state.output}, step=mock_another_engine.state.epoch)]\n    )\n\n    mock_another_engine.state.epoch = 11\n    mock_engine.state.output = 1.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.log_metrics.call_count == 2\n    mock_logger.log_metrics.assert_has_calls(\n        [call({""tag loss"": mock_engine.state.output}, step=mock_another_engine.state.epoch)]\n    )\n\n\ndef test_optimizer_params_handler_wrong_setup():\n\n    with pytest.raises(TypeError):\n        OptimizerParamsHandler(optimizer=None)\n\n    optimizer = MagicMock(spec=torch.optim.Optimizer)\n    handler = OptimizerParamsHandler(optimizer=optimizer)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OptimizerParamsHandler works only with MLflowLogger""):\n        handler(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_optimizer_params():\n\n    optimizer = torch.optim.SGD([torch.Tensor(0)], lr=0.01)\n    wrapper = OptimizerParamsHandler(optimizer=optimizer, param_name=""lr"")\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metrics.assert_called_once_with({""lr group_0"": 0.01}, step=123)\n\n    wrapper = OptimizerParamsHandler(optimizer, param_name=""lr"", tag=""generator"")\n    mock_logger = MagicMock(spec=MLflowLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metrics.assert_called_once_with({""generator lr group_0"": 0.01}, step=123)\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_integration(dirname):\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    trainer = Engine(update_fn)\n\n    mlflow_logger = MLflowLogger(tracking_uri=os.path.join(dirname, ""mlruns""))\n\n    true_values = []\n\n    def dummy_handler(engine, logger, event_name):\n        global_step = engine.state.get_event_attrib_value(event_name)\n        v = global_step * 0.1\n        true_values.append(v)\n        logger.log_metrics({""{}"".format(""test_value""): v}, step=global_step)\n\n    mlflow_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n    import mlflow\n\n    active_run = mlflow.active_run()\n\n    trainer.run(data, max_epochs=n_epochs)\n    mlflow_logger.close()\n\n    from mlflow.tracking import MlflowClient\n\n    client = MlflowClient(tracking_uri=os.path.join(dirname, ""mlruns""))\n    stored_values = client.get_metric_history(active_run.info.run_id, ""test_value"")\n\n    for t, s in zip(true_values, stored_values):\n        assert pytest.approx(t) == s.value\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_integration_as_context_manager(dirname):\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    true_values = []\n\n    with MLflowLogger(os.path.join(dirname, ""mlruns"")) as mlflow_logger:\n\n        trainer = Engine(update_fn)\n\n        def dummy_handler(engine, logger, event_name):\n            global_step = engine.state.get_event_attrib_value(event_name)\n            v = global_step * 0.1\n            true_values.append(v)\n            logger.log_metrics({""{}"".format(""test_value""): v}, step=global_step)\n\n        mlflow_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n        import mlflow\n\n        active_run = mlflow.active_run()\n\n        trainer.run(data, max_epochs=n_epochs)\n\n    from mlflow.tracking import MlflowClient\n\n    client = MlflowClient(tracking_uri=os.path.join(dirname, ""mlruns""))\n    stored_values = client.get_metric_history(active_run.info.run_id, ""test_value"")\n\n    for t, s in zip(true_values, stored_values):\n        assert pytest.approx(t) == s.value\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_mlflow_bad_metric_name_handling(dirname):\n    import mlflow\n\n    true_values = [123.0, 23.4, 333.4]\n    with MLflowLogger(os.path.join(dirname, ""mlruns"")) as mlflow_logger:\n\n        active_run = mlflow.active_run()\n\n        handler = OutputHandler(tag=""training"", metric_names=""all"")\n        engine = Engine(lambda e, b: None)\n        engine.state = State(metrics={""metric:0 in %"": 123.0, ""metric 0"": 1000.0,})\n\n        with pytest.warns(UserWarning, match=r""MLflowLogger output_handler encountered an invalid metric name""):\n\n            engine.state.epoch = 1\n            handler(engine, mlflow_logger, event_name=Events.EPOCH_COMPLETED)\n\n            for i, v in enumerate(true_values):\n                engine.state.epoch += 1\n                engine.state.metrics[""metric 0""] = v\n                handler(engine, mlflow_logger, event_name=Events.EPOCH_COMPLETED)\n\n    from mlflow.tracking import MlflowClient\n\n    client = MlflowClient(tracking_uri=os.path.join(dirname, ""mlruns""))\n    stored_values = client.get_metric_history(active_run.info.run_id, ""training metric 0"")\n\n    for t, s in zip([1000.0,] + true_values, stored_values):\n        assert t == s.value\n\n\n@pytest.fixture\ndef no_site_packages():\n    import sys\n\n    mlflow_client_modules = {}\n    for k in sys.modules:\n        if ""mlflow"" in k:\n            mlflow_client_modules[k] = sys.modules[k]\n    for k in mlflow_client_modules:\n        del sys.modules[k]\n\n    prev_path = list(sys.path)\n    sys.path = [p for p in sys.path if ""site-packages"" not in p]\n    yield ""no_site_packages""\n    sys.path = prev_path\n    for k in mlflow_client_modules:\n        sys.modules[k] = mlflow_client_modules[k]\n\n\ndef test_no_mlflow_client(no_site_packages):\n\n    with pytest.raises(RuntimeError, match=r""This contrib module requires mlflow to be installed.""):\n        MLflowLogger()\n'"
tests/ignite/contrib/handlers/test_neptune_logger.py,12,"b'import math\nimport os\nimport sys\nimport warnings\nfrom unittest.mock import ANY, MagicMock, call\n\nimport pytest\nimport torch\n\nimport ignite.distributed as idist\nfrom ignite.contrib.handlers.neptune_logger import *\nfrom ignite.engine import Engine, Events, State\nfrom ignite.handlers.checkpoint import Checkpoint\n\n\ndef test_optimizer_params_handler_wrong_setup():\n    with pytest.raises(TypeError):\n        OptimizerParamsHandler(optimizer=None)\n\n    optimizer = MagicMock(spec=torch.optim.Optimizer)\n    handler = OptimizerParamsHandler(optimizer=optimizer)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OptimizerParamsHandler works only with NeptuneLogger""):\n        handler(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_optimizer_params():\n    optimizer = torch.optim.SGD([torch.Tensor(0)], lr=0.01)\n    wrapper = OptimizerParamsHandler(optimizer=optimizer, param_name=""lr"")\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metric.assert_called_once_with(""lr/group_0"", y=0.01, x=123)\n\n    wrapper = OptimizerParamsHandler(optimizer, param_name=""lr"", tag=""generator"")\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metric.assert_called_once_with(""generator/lr/group_0"", y=0.01, x=123)\n\n\ndef test_output_handler_with_wrong_logger_type():\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OutputHandler works only with NeptuneLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_output_handler_output_transform():\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.output = 12345\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metric.assert_called_once_with(""tag/output"", y=12345, x=123)\n\n    wrapper = OutputHandler(""another_tag"", output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metric.assert_called_once_with(""another_tag/loss"", y=12345, x=123)\n\n\ndef test_output_handler_metric_names():\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""])\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metric.call_count == 2\n    mock_logger.log_metric.assert_has_calls([call(""tag/a"", y=12.23, x=5), call(""tag/b"", y=23.45, x=5),], any_order=True)\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"",])\n\n    mock_engine = MagicMock()\n    mock_logger.log_metric = MagicMock()\n    mock_engine.state = State(metrics={""a"": torch.Tensor([0.0, 1.0, 2.0, 3.0])})\n    mock_engine.state.iteration = 5\n\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metric.call_count == 4\n    mock_logger.log_metric.assert_has_calls(\n        [\n            call(""tag/a/0"", y=0.0, x=5),\n            call(""tag/a/1"", y=1.0, x=5),\n            call(""tag/a/2"", y=2.0, x=5),\n            call(""tag/a/3"", y=3.0, x=5),\n        ],\n        any_order=True,\n    )\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""c""])\n\n    mock_engine = MagicMock()\n    mock_logger.log_metric = MagicMock()\n    mock_engine.state = State(metrics={""a"": 55.56, ""c"": ""Some text""})\n    mock_engine.state.iteration = 7\n\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n\n    with pytest.warns(UserWarning):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metric.call_count == 1\n    mock_logger.log_metric.assert_has_calls([call(""tag/a"", y=55.56, x=7),], any_order=True)\n\n    # all metrics\n    wrapper = OutputHandler(""tag"", metric_names=""all"")\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metric.call_count == 2\n    mock_logger.log_metric.assert_has_calls([call(""tag/a"", y=12.23, x=5), call(""tag/b"", y=23.45, x=5),], any_order=True)\n\n\ndef test_output_handler_both():\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.log_metric.call_count == 3\n    mock_logger.log_metric.assert_has_calls(\n        [call(""tag/a"", y=12.23, x=5), call(""tag/b"", y=23.45, x=5), call(""tag/loss"", y=12345, x=5)], any_order=True\n    )\n\n\ndef test_output_handler_with_wrong_global_step_transform_output():\n    def global_step_transform(*args, **kwargs):\n        return ""a""\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    with pytest.raises(TypeError, match=""global_step must be int""):\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n\ndef test_output_handler_with_global_step_from_engine():\n    mock_another_engine = MagicMock()\n    mock_another_engine.state = State()\n    mock_another_engine.state.epoch = 10\n    mock_another_engine.state.output = 12.345\n\n    wrapper = OutputHandler(\n        ""tag"",\n        output_transform=lambda x: {""loss"": x},\n        global_step_transform=global_step_from_engine(mock_another_engine),\n    )\n\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 1\n    mock_engine.state.output = 0.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.log_metric.call_count == 1\n    mock_logger.log_metric.assert_has_calls(\n        [call(""tag/loss"", y=mock_engine.state.output, x=mock_another_engine.state.epoch)]\n    )\n\n    mock_another_engine.state.epoch = 11\n    mock_engine.state.output = 1.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.log_metric.call_count == 2\n    mock_logger.log_metric.assert_has_calls(\n        [call(""tag/loss"", y=mock_engine.state.output, x=mock_another_engine.state.epoch)]\n    )\n\n\ndef test_output_handler_with_global_step_transform():\n    def global_step_transform(*args, **kwargs):\n        return 10\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.log_metric.call_count == 1\n    mock_logger.log_metric.assert_has_calls([call(""tag/loss"", y=12345, x=10)])\n\n\ndef test_weights_scalar_handler_wrong_setup():\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        WeightsScalarHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    with pytest.raises(TypeError, match=""Argument reduction should be callable""):\n        WeightsScalarHandler(model, reduction=123)\n\n    with pytest.raises(ValueError, match=""Output of the reduction function should be a scalar""):\n        WeightsScalarHandler(model, reduction=lambda x: x)\n\n    wrapper = WeightsScalarHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler WeightsScalarHandler works only with NeptuneLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_weights_scalar_handler(dummy_model_factory):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = WeightsScalarHandler(model, tag=tag)\n        mock_logger = MagicMock(spec=NeptuneLogger)\n        mock_logger.log_metric = MagicMock()\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.log_metric.call_count == 4\n        mock_logger.log_metric.assert_has_calls(\n            [\n                call(tag_prefix + ""weights_norm/fc1/weight"", y=0.0, x=5),\n                call(tag_prefix + ""weights_norm/fc1/bias"", y=0.0, x=5),\n                call(tag_prefix + ""weights_norm/fc2/weight"", y=12.0, x=5),\n                call(tag_prefix + ""weights_norm/fc2/bias"", y=math.sqrt(12.0), x=5),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_weights_scalar_handler_frozen_layers(dummy_model_factory):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = WeightsScalarHandler(model)\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.log_metric.assert_has_calls(\n        [call(""weights_norm/fc2/weight"", y=12.0, x=5), call(""weights_norm/fc2/bias"", y=math.sqrt(12.0), x=5),],\n        any_order=True,\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.log_metric.assert_has_calls(\n            [call(""weights_norm/fc1/weight"", y=12.0, x=5), call(""weights_norm/fc1/bias"", y=math.sqrt(12.0), x=5),],\n            any_order=True,\n        )\n\n    assert mock_logger.log_metric.call_count == 2\n\n\ndef test_grads_scalar_handler_wrong_setup():\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        GradsScalarHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    with pytest.raises(TypeError, match=""Argument reduction should be callable""):\n        GradsScalarHandler(model, reduction=123)\n\n    wrapper = GradsScalarHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler GradsScalarHandler works only with NeptuneLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_grads_scalar_handler(dummy_model_factory, norm_mock):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = GradsScalarHandler(model, reduction=norm_mock, tag=tag)\n        mock_logger = MagicMock(spec=NeptuneLogger)\n        mock_logger.log_metric = MagicMock()\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n        norm_mock.reset_mock()\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        mock_logger.log_metric.assert_has_calls(\n            [\n                call(tag_prefix + ""grads_norm/fc1/weight"", y=ANY, x=5),\n                call(tag_prefix + ""grads_norm/fc1/bias"", y=ANY, x=5),\n                call(tag_prefix + ""grads_norm/fc2/weight"", y=ANY, x=5),\n                call(tag_prefix + ""grads_norm/fc2/bias"", y=ANY, x=5),\n            ],\n            any_order=True,\n        )\n        assert mock_logger.log_metric.call_count == 4\n        assert norm_mock.call_count == 4\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_grads_scalar_handler_frozen_layers(dummy_model_factory, norm_mock):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = GradsScalarHandler(model, reduction=norm_mock)\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_metric = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    norm_mock.reset_mock()\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.log_metric.assert_has_calls(\n        [call(""grads_norm/fc2/weight"", y=ANY, x=5), call(""grads_norm/fc2/bias"", y=ANY, x=5),], any_order=True\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.log_metric.assert_has_calls(\n            [call(""grads_norm/fc1/weight"", y=ANY, x=5), call(""grads_norm/fc1/bias"", y=ANY, x=5),], any_order=True\n        )\n    assert mock_logger.log_metric.call_count == 2\n    assert norm_mock.call_count == 2\n\n\ndef test_integration():\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    trainer = Engine(update_fn)\n\n    npt_logger = NeptuneLogger(offline_mode=True)\n\n    def dummy_handler(engine, logger, event_name):\n        global_step = engine.state.get_event_attrib_value(event_name)\n        logger.log_metric(""test_value"", global_step, global_step)\n\n    npt_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n    trainer.run(data, max_epochs=n_epochs)\n    npt_logger.close()\n\n\ndef test_integration_as_context_manager():\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    with NeptuneLogger(offline_mode=True) as npt_logger:\n        trainer = Engine(update_fn)\n\n        def dummy_handler(engine, logger, event_name):\n            global_step = engine.state.get_event_attrib_value(event_name)\n            logger.log_metric(""test_value"", global_step, global_step)\n\n        npt_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n        trainer.run(data, max_epochs=n_epochs)\n\n\ndef test_neptune_saver_serializable(dirname):\n\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_artifact = MagicMock()\n    model = torch.nn.Module()\n    to_save_serializable = {""model"": model}\n\n    saver = NeptuneSaver(mock_logger)\n    fname = os.path.join(dirname, ""test.pt"")\n    saver(to_save_serializable, fname)\n\n    assert mock_logger.log_artifact.call_count == 1\n\n\ndef _test_neptune_saver_integration(device):\n\n    model = torch.nn.Module().to(device)\n    to_save_serializable = {""model"": model}\n\n    mock_logger = None\n    if idist.get_rank() == 0:\n        mock_logger = MagicMock(spec=NeptuneLogger)\n        mock_logger.log_artifact = MagicMock()\n        mock_logger.delete_artifacts = MagicMock()\n\n    saver = NeptuneSaver(mock_logger)\n\n    checkpoint = Checkpoint(to_save=to_save_serializable, save_handler=saver, n_saved=1)\n\n    trainer = Engine(lambda e, b: None)\n    trainer.state = State(epoch=0, iteration=0)\n    checkpoint(trainer)\n    trainer.state.iteration = 1\n    checkpoint(trainer)\n    if idist.get_rank() == 0:\n        assert mock_logger.log_artifact.call_count == 2\n        assert mock_logger.delete_artifacts.call_count == 1\n\n\ndef test_neptune_saver_integration():\n    _test_neptune_saver_integration(""cpu"")\n\n\ndef test_neptune_saver_non_serializable():\n\n    mock_logger = MagicMock(spec=NeptuneLogger)\n    mock_logger.log_artifact = MagicMock()\n\n    to_save_non_serializable = {""model"": lambda x: x}\n\n    saver = NeptuneSaver(mock_logger)\n    fname = ""test.pt""\n    try:\n        with warnings.catch_warnings():\n            # Ignore torch/serialization.py:292: UserWarning: Couldn\'t retrieve source code for container of type\n            # DummyModel. It won\'t be checked for correctness upon loading.\n            warnings.simplefilter(""ignore"", category=UserWarning)\n            saver(to_save_non_serializable, fname)\n    except Exception:\n        pass\n\n    assert mock_logger.log_artifact.call_count == 0\n\n\n@pytest.fixture\ndef no_site_packages():\n\n    neptune_client_modules = {}\n    for k in sys.modules:\n        if ""neptune"" in k:\n            neptune_client_modules[k] = sys.modules[k]\n    for k in neptune_client_modules:\n        del sys.modules[k]\n\n    prev_path = list(sys.path)\n    sys.path = [p for p in sys.path if ""site-packages"" not in p]\n    yield ""no_site_packages""\n    sys.path = prev_path\n    for k in neptune_client_modules:\n        sys.modules[k] = neptune_client_modules[k]\n\n\ndef test_no_neptune_client(no_site_packages):\n\n    with pytest.raises(RuntimeError, match=r""This contrib module requires neptune-client to be installed.""):\n        NeptuneLogger()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    _test_neptune_saver_integration(""cpu"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl):\n    device = idist.device()\n    _test_neptune_saver_integration(device)\n'"
tests/ignite/contrib/handlers/test_param_scheduler.py,80,"b'import numpy as np\nimport pytest\nimport torch\nfrom torch.optim.lr_scheduler import ExponentialLR, StepLR\n\nfrom ignite.contrib.handlers.param_scheduler import (\n    ConcatScheduler,\n    CosineAnnealingScheduler,\n    LinearCyclicalScheduler,\n    LRScheduler,\n    ParamGroupScheduler,\n    ParamScheduler,\n    PiecewiseLinear,\n    create_lr_scheduler_with_warmup,\n)\nfrom ignite.engine import Engine, Events\n\ntry:\n    from torch.optim.lr_scheduler import MultiplicativeLR\nexcept ImportError:\n    has_multiplicative_lr = False\nelse:\n    from distutils.version import LooseVersion\n\n    # https://github.com/pytorch/pytorch/issues/32756\n    has_multiplicative_lr = LooseVersion(torch.__version__) >= LooseVersion(""1.5.0"")\n\n\ndef test_param_scheduler_asserts():\n    class FakeParamScheduler(ParamScheduler):\n        def get_param(self):\n            return [0]\n\n    t1 = torch.zeros([1], requires_grad=True)\n    t2 = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([{""params"": t1, ""lr"": 0.1}, {""params"": t2, ""lr"": 0.1}])\n\n    lr_scheduler = FakeParamScheduler(optimizer, ""lr"")\n\n    with pytest.raises(RuntimeError, match=r""size of value is different than optimizer_param_groups""):\n        lr_scheduler(None)\n\n    with pytest.raises(TypeError, match=r""Argument state_dict should be a dictionary, but given""):\n        lr_scheduler.load_state_dict(None)\n\n    with pytest.raises(ValueError, match=r""Required state attribute \'event_index\' is absent in provided state_dict""):\n        lr_scheduler.load_state_dict({})\n\n\ndef test_linear_scheduler():\n\n    with pytest.raises(TypeError, match=r""Argument optimizer should be torch.optim.Optimizer""):\n        LinearCyclicalScheduler({}, ""lr"", 1, 0, cycle_size=0)\n\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0.0)\n\n    with pytest.raises(ValueError, match=r""Argument cycle_size should be positive and larger than 1""):\n        LinearCyclicalScheduler(optimizer, ""lr"", 1, 0, cycle_size=0)\n\n    with pytest.raises(ValueError, match=r""Argument cycle_size should be positive and larger than 1""):\n        LinearCyclicalScheduler(optimizer, ""lr"", 1, 0, cycle_size=1)\n\n    scheduler = LinearCyclicalScheduler(optimizer, ""lr"", 1, 0, 10)\n    state_dict = scheduler.state_dict()\n\n    def save_lr(engine):\n        lrs.append(optimizer.param_groups[0][""lr""])\n\n    trainer = Engine(lambda engine, batch: None)\n    trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n    for _ in range(2):\n        lrs = []\n        trainer.run([0] * 9, max_epochs=2)\n\n        assert lrs == list(\n            map(\n                pytest.approx,\n                [\n                    # Cycle 1\n                    1.0,\n                    0.8,\n                    0.6,\n                    0.4,\n                    0.2,\n                    0.0,\n                    0.2,\n                    0.4,\n                    0.6,\n                    0.8,\n                    # Cycle 2\n                    1.0,\n                    0.8,\n                    0.6,\n                    0.4,\n                    0.2,\n                    0.0,\n                    0.2,\n                    0.4,  # 0.6, 0.8,\n                ],\n            )\n        )\n        scheduler.load_state_dict(state_dict)\n\n    optimizer = torch.optim.SGD([tensor], lr=0)\n    scheduler = LinearCyclicalScheduler(optimizer, ""lr"", 1, 0, 10, cycle_mult=2)\n    state_dict = scheduler.state_dict()\n\n    trainer = Engine(lambda engine, batch: None)\n    trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n    for _ in range(2):\n        lrs = []\n        trainer.run([0] * 10, max_epochs=3)\n\n        assert lrs == list(\n            map(\n                pytest.approx,\n                [\n                    # Cycle 1\n                    1.0,\n                    0.8,\n                    0.6,\n                    0.4,\n                    0.2,\n                    0.0,\n                    0.2,\n                    0.4,\n                    0.6,\n                    0.8,\n                    # Cycle 2\n                    1.0,\n                    0.9,\n                    0.8,\n                    0.7,\n                    0.6,\n                    0.5,\n                    0.4,\n                    0.3,\n                    0.2,\n                    0.1,\n                    0.0,\n                    0.1,\n                    0.2,\n                    0.3,\n                    0.4,\n                    0.5,\n                    0.6,\n                    0.7,\n                    0.8,\n                    0.9,\n                ],\n            )\n        )\n        scheduler.load_state_dict(state_dict)\n\n    # With float cycle_size\n    optimizer = torch.optim.SGD([tensor], lr=0)\n    scheduler = LinearCyclicalScheduler(\n        optimizer, ""lr"", start_value=1.2, end_value=0.2, cycle_size=10.00000012, cycle_mult=1.0\n    )\n    state_dict = scheduler.state_dict()\n\n    trainer = Engine(lambda engine, batch: None)\n    trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n    for _ in range(2):\n        lrs = []\n        trainer.run([0] * 9, max_epochs=2)\n        assert lrs == list(\n            map(\n                pytest.approx,\n                [\n                    # Cycle 1\n                    1.2,\n                    1.0,\n                    0.8,\n                    0.6,\n                    0.4,\n                    0.2,\n                    0.4,\n                    0.6,\n                    0.8,\n                    1.0,\n                    # Cycle 2\n                    1.2,\n                    1.0,\n                    0.8,\n                    0.6,\n                    0.4,\n                    0.2,\n                    0.4,\n                    0.6,  # 0.8, 1.0,\n                ],\n            )\n        )\n        scheduler.load_state_dict(state_dict)\n\n\ndef test_linear_scheduler_cycle_size_two():\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n\n    scheduler = LinearCyclicalScheduler(optimizer, ""lr"", 1, 0, cycle_size=2)\n\n    data = [0] * 10\n    max_epochs = 2\n    simulated_values = LinearCyclicalScheduler.simulate_values(\n        num_events=len(data) * max_epochs, param_name=""lr"", start_value=1, end_value=0, cycle_size=2\n    )\n\n    def save_lr(engine):\n        lrs.append(optimizer.param_groups[0][""lr""])\n\n    trainer = Engine(lambda engine, batch: None)\n    trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n    lrs = []\n    trainer.run(data, max_epochs=max_epochs)\n    assert lrs == list(\n        map(\n            pytest.approx,\n            [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n        )\n    )\n\n    assert lrs == pytest.approx([v for i, v in simulated_values])\n\n\ndef test_cosine_annealing_scheduler():\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n\n    scheduler = CosineAnnealingScheduler(optimizer, ""lr"", 0, 1, 10)\n    state_dict = scheduler.state_dict()\n\n    data = [0] * 9\n    max_epochs = 2\n    simulated_values = CosineAnnealingScheduler.simulate_values(\n        num_events=len(data) * max_epochs, param_name=""lr"", start_value=0, end_value=1, cycle_size=10\n    )\n\n    def save_lr(engine):\n        lrs.append(optimizer.param_groups[0][""lr""])\n\n    trainer = Engine(lambda engine, batch: None)\n    trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n    for _ in range(2):\n        lrs = []\n        trainer.run(data, max_epochs=max_epochs)\n\n        assert lrs == list(\n            map(\n                pytest.approx,\n                [\n                    0.0,\n                    0.02447174185242318,\n                    0.09549150281252627,\n                    0.20610737385376332,\n                    0.3454915028125263,\n                    0.5,\n                    0.6545084971874737,\n                    0.7938926261462365,\n                    0.9045084971874737,\n                    0.9755282581475768,\n                    0.0,\n                    0.02447174185242318,\n                    0.09549150281252627,\n                    0.20610737385376332,\n                    0.3454915028125263,\n                    0.5,\n                    0.6545084971874737,\n                    0.7938926261462365,  # 0.9045084971874737, 0.9755282581475768\n                ],\n            )\n        )\n        scheduler.load_state_dict(state_dict)\n\n        assert lrs == pytest.approx([v for i, v in simulated_values])\n\n\ndef test_concat_scheduler_asserts():\n\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n\n    scheduler_1 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=1.0, end_value=0.0, cycle_size=10)\n    scheduler_2 = CosineAnnealingScheduler(optimizer, ""lr"", start_value=0.0, end_value=1.0, cycle_size=10)\n\n    with pytest.raises(ValueError):\n        ConcatScheduler(schedulers=[], durations=[])\n\n    with pytest.raises(ValueError):\n        ConcatScheduler(schedulers=[scheduler_1], durations=[10])\n\n    with pytest.raises(TypeError):\n        ConcatScheduler(schedulers=[scheduler_1, 12], durations=[10])\n\n    with pytest.raises(ValueError):\n        ConcatScheduler(schedulers=[scheduler_1, scheduler_2], durations=[10, 5])\n\n    with pytest.raises(ValueError):\n        ConcatScheduler(schedulers=[scheduler_1, scheduler_2, scheduler_2], durations=[15, 12.0])\n\n    with pytest.raises(ValueError):\n        ConcatScheduler(schedulers=[scheduler_1, scheduler_2], durations=""abc"")\n\n    with pytest.raises(ValueError):\n        ConcatScheduler.simulate_values(\n            num_events=123, schedulers=[scheduler_1, scheduler_2], durations=[15], param_names=""abc""\n        )\n\n    optimizer_2 = torch.optim.SGD([tensor], lr=0)\n    scheduler_3 = CosineAnnealingScheduler(optimizer_2, ""lr"", start_value=0.0, end_value=1.0, cycle_size=10)\n\n    with pytest.raises(ValueError, match=r""schedulers should be related to same optimizer""):\n        ConcatScheduler([scheduler_1, scheduler_3], durations=[30,])\n\n\ndef test_concat_scheduler_state_dict():\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n    scheduler_1 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=1.0, end_value=0.0, cycle_size=10)\n    scheduler_2 = CosineAnnealingScheduler(optimizer, ""lr"", start_value=0.0, end_value=1.0, cycle_size=10)\n    durations = [10]\n    concat_scheduler = ConcatScheduler(schedulers=[scheduler_1, scheduler_2], durations=durations, save_history=False)\n    state_dict = concat_scheduler.state_dict()\n\n    assert state_dict[""durations""] == durations\n    assert state_dict[""_current_duration""] == durations[0]\n    assert state_dict[""_scheduler_index""] == 0\n\n    for _ in range(20):\n        concat_scheduler(None, None)\n\n    concat_scheduler.load_state_dict(state_dict)\n    assert concat_scheduler.durations == durations\n    assert concat_scheduler._current_duration == durations[0]\n    assert id(concat_scheduler._current_scheduler) == id(scheduler_1)\n\n    with pytest.raises(ValueError, match=r""Required state attribute \'schedulers\' is absent in provided state_dict""):\n        concat_scheduler.load_state_dict({""a"": 1})\n\n    with pytest.raises(ValueError, match=r""Input state_dict contains 0 state_dicts of concatenated schedulers""):\n        concat_scheduler.load_state_dict({""schedulers"": []})\n\n    with pytest.raises(TypeError, match=r""Argument state_dict should be a dictionary, but given""):\n        concat_scheduler.load_state_dict(None)\n\n\ndef test_concat_scheduler_two_schedulers():\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n\n    def _test(duration_vals_as_np_int):\n        scheduler_1 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=1.0, end_value=0.0, cycle_size=10)\n        scheduler_2 = CosineAnnealingScheduler(optimizer, ""lr"", start_value=0.0, end_value=1.0, cycle_size=10)\n\n        durations = [10]\n        if duration_vals_as_np_int:\n            durations = [np.int64(t) for t in durations]\n\n        concat_scheduler = ConcatScheduler(\n            schedulers=[scheduler_1, scheduler_2], durations=durations, save_history=True\n        )\n        state_dict = concat_scheduler.state_dict()\n\n        data = [0] * 10\n        max_epochs = 2\n        simulated_values = ConcatScheduler.simulate_values(\n            num_events=len(data) * max_epochs, schedulers=[scheduler_1, scheduler_2], durations=durations\n        )\n\n        def save_lr(engine):\n            lrs.append(optimizer.param_groups[0][""lr""])\n\n        trainer = Engine(lambda engine, batch: None)\n        trainer.add_event_handler(Events.ITERATION_STARTED, concat_scheduler)\n        trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n        for _ in range(2):\n            lrs = []\n            trainer.run(data, max_epochs=max_epochs)\n\n            assert lrs == list(\n                map(\n                    pytest.approx,\n                    [\n                        # Cycle 1 of the LinearCyclicalScheduler\n                        1.0,\n                        0.8,\n                        0.6,\n                        0.4,\n                        0.2,\n                        0.0,\n                        0.2,\n                        0.4,\n                        0.6,\n                        0.8,\n                        # Cycle 1 of the CosineAnnealingScheduler\n                        0.0,\n                        0.02447174185242318,\n                        0.09549150281252627,\n                        0.20610737385376332,\n                        0.3454915028125263,\n                        0.5,\n                        0.6545084971874737,\n                        0.7938926261462365,\n                        0.9045084971874737,\n                        0.9755282581475768,\n                    ],\n                )\n            )\n\n            state_lrs = trainer.state.param_history[""lr""]\n            assert len(state_lrs) == len(lrs)\n            # Unpack singleton lists\n            assert [group[0] for group in state_lrs] == lrs\n            assert lrs == pytest.approx([v for i, v in simulated_values])\n            concat_scheduler.load_state_dict(state_dict)\n\n            trainer.state.param_history = None\n\n    _test(duration_vals_as_np_int=False)\n    _test(duration_vals_as_np_int=True)\n\n\ndef test_concat_scheduler_two_linear():\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n\n    scheduler_1 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=0.0, end_value=0.1, cycle_size=2)\n    scheduler_2 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=0.2, end_value=1.0, cycle_size=2)\n\n    durations = [5]\n    concat_scheduler = ConcatScheduler(schedulers=[scheduler_1, scheduler_2], durations=durations, save_history=True)\n    state_dict = concat_scheduler.state_dict()\n\n    assert concat_scheduler.get_param() == 0.0\n\n    data = [0] * 10\n    max_epochs = 2\n    simulated_values = ConcatScheduler.simulate_values(\n        num_events=len(data) * max_epochs, schedulers=[scheduler_1, scheduler_2], durations=durations\n    )\n\n    def save_lr(engine):\n        lrs.append(optimizer.param_groups[0][""lr""])\n\n    trainer = Engine(lambda engine, batch: None)\n    trainer.add_event_handler(Events.ITERATION_STARTED, concat_scheduler)\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n    for _ in range(2):\n        lrs = []\n        trainer.run(data, max_epochs=max_epochs)\n\n        assert lrs == list(\n            map(\n                pytest.approx,\n                [\n                    # first LinearCyclicalScheduler\n                    0.0,\n                    0.1,\n                    0.0,\n                    0.1,\n                    0.0,\n                    # second LinearCyclicalScheduler\n                    0.2,\n                    1.0,\n                    0.2,\n                    1.0,\n                    0.2,\n                    1.0,\n                    0.2,\n                    1.0,\n                    0.2,\n                    1.0,\n                    0.2,\n                    1.0,\n                    0.2,\n                    1.0,\n                    0.2,\n                ],\n            )\n        )\n\n        state_lrs = trainer.state.param_history[""lr""]\n        assert len(state_lrs) == len(lrs)\n        # Unpack singleton lists\n        assert [group[0] for group in state_lrs] == lrs\n\n        assert lrs == pytest.approx([v for i, v in simulated_values])\n        concat_scheduler.load_state_dict(state_dict)\n\n        trainer.state.param_history = None\n\n\ndef test_concat_scheduler_3_schedulers():\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n\n    scheduler_1 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=1.0, end_value=0.5, cycle_size=20)\n    scheduler_2 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=0.5, end_value=0.45, cycle_size=10)\n    scheduler_3 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=0.5, end_value=0.0, cycle_size=20)\n    durations = [10, 5]\n\n    concat_scheduler = ConcatScheduler(\n        schedulers=[scheduler_1, scheduler_2, scheduler_3], durations=durations, save_history=True\n    )\n    state_dict = concat_scheduler.state_dict()\n\n    data = [0] * 10\n    max_epochs = 2\n    simulated_values = ConcatScheduler.simulate_values(\n        num_events=len(data) * max_epochs, schedulers=[scheduler_1, scheduler_2, scheduler_3], durations=durations\n    )\n\n    def save_lr(engine):\n        lrs.append(optimizer.param_groups[0][""lr""])\n\n    trainer = Engine(lambda engine, batch: None)\n    trainer.add_event_handler(Events.ITERATION_STARTED, concat_scheduler)\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n    for _ in range(2):\n        lrs = []\n        trainer.run(data, max_epochs=max_epochs)\n\n        assert lrs == list(\n            map(\n                pytest.approx,\n                [\n                    # Cycle 1 of the first LinearCyclicalScheduler\n                    1.0,\n                    0.95,\n                    0.9,\n                    0.85,\n                    0.8,\n                    0.75,\n                    0.7,\n                    0.65,\n                    0.6,\n                    0.55,\n                    # Cycle 1 of the second LinearCyclicalScheduler\n                    0.5,\n                    0.49,\n                    0.48,\n                    0.47,\n                    0.46,\n                    # Cycle 1 of the third LinearCyclicalScheduler\n                    0.5,\n                    0.45,\n                    0.4,\n                    0.35,\n                    0.3,\n                ],\n            )\n        )\n\n        state_lrs = trainer.state.param_history[""lr""]\n        assert len(state_lrs) == len(lrs)\n        # Unpack singleton lists\n        assert [group[0] for group in state_lrs] == lrs\n\n        assert lrs == pytest.approx([v for i, v in simulated_values])\n        concat_scheduler.load_state_dict(state_dict)\n\n        trainer.state.param_history = None\n\n\ndef test_save_param_history():\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n\n    scheduler = LinearCyclicalScheduler(optimizer, ""lr"", 1, 0, 10, save_history=True)\n    lrs = []\n\n    def save_lr(engine):\n        lrs.append(optimizer.param_groups[0][""lr""])\n\n    trainer = Engine(lambda engine, batch: None)\n    assert not hasattr(trainer.state, ""param_history"")\n\n    trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n    trainer.run([0] * 10, max_epochs=2)\n\n    state_lrs = trainer.state.param_history[""lr""]\n    assert len(state_lrs) == len(lrs)\n    # Unpack singleton lists\n    assert [group[0] for group in state_lrs] == lrs\n\n\ndef test_lr_scheduler_asserts():\n\n    with pytest.raises(TypeError):\n        LRScheduler(123)\n\n    with pytest.raises(TypeError):\n        LRScheduler.simulate_values(1, None)\n\n\ndef test_lr_scheduler():\n    def _test(torch_lr_scheduler_cls, **kwargs):\n\n        tensor = torch.zeros([1], requires_grad=True)\n        optimizer1 = torch.optim.SGD([tensor], lr=0.01)\n        optimizer2 = torch.optim.SGD([tensor], lr=0.01)\n        opt_state_dict1 = optimizer1.state_dict()\n        opt_state_dict2 = optimizer2.state_dict()\n\n        torch_lr_scheduler1 = torch_lr_scheduler_cls(optimizer=optimizer1, **kwargs)\n        scheduler = LRScheduler(torch_lr_scheduler1)\n        state_dict1 = scheduler.state_dict()\n        print(state_dict1)\n\n        torch_lr_scheduler2 = torch_lr_scheduler_cls(optimizer=optimizer2, **kwargs)\n        state_dict2 = torch_lr_scheduler2.state_dict()\n\n        def dummy_update(engine, batch):\n            optimizer1.step()\n            optimizer2.step()\n\n        trainer = Engine(dummy_update)\n\n        @trainer.on(Events.ITERATION_STARTED)\n        def save_lr(engine):\n            lrs.append(optimizer1.param_groups[0][""lr""])\n\n        @trainer.on(Events.ITERATION_STARTED)\n        def save_true_lr(engine):\n            lrs_true.append(optimizer2.param_groups[0][""lr""])\n\n        @trainer.on(Events.ITERATION_COMPLETED)\n        def torch_lr_scheduler_step(engine):\n            torch_lr_scheduler2.step()\n\n        trainer.add_event_handler(Events.ITERATION_COMPLETED, scheduler)\n\n        for _ in range(2):\n            lrs = []\n            lrs_true = []\n            data = [0] * 10\n            max_epochs = 2\n            trainer.run(data, max_epochs=max_epochs)\n            assert lrs_true == pytest.approx(lrs), ""{}: {} ({}) vs {} ({})"".format(\n                _, lrs_true, len(lrs_true), lrs, len(lrs)\n            )\n            optimizer1.load_state_dict(opt_state_dict1)\n            scheduler.load_state_dict(state_dict1)\n            optimizer2.load_state_dict(opt_state_dict2)\n            torch_lr_scheduler2.load_state_dict(state_dict2)\n\n        optimizer3 = torch.optim.SGD([tensor], lr=0.01)\n        torch_lr_scheduler3 = torch_lr_scheduler_cls(optimizer=optimizer3, **kwargs)\n\n        simulated_values = LRScheduler.simulate_values(\n            num_events=len(data) * max_epochs, lr_scheduler=torch_lr_scheduler3\n        )\n        assert lrs == pytest.approx([v for i, v in simulated_values])\n\n    _test(StepLR, step_size=5, gamma=0.5)\n    _test(ExponentialLR, gamma=0.78)\n    if has_multiplicative_lr:\n        _test(MultiplicativeLR, lr_lambda=lambda epoch: 0.95)\n\n\ndef test_piecewiselinear_asserts():\n\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0)\n\n    with pytest.raises(ValueError):\n        PiecewiseLinear(optimizer, ""lr"", milestones_values=[])\n\n    with pytest.raises(ValueError):\n        PiecewiseLinear(optimizer, ""lr"", milestones_values=[(0.5,)])\n\n    with pytest.raises(ValueError):\n        PiecewiseLinear(optimizer, ""lr"", milestones_values=[(10, 0.5), (0.6,)])\n\n    with pytest.raises(ValueError):\n        PiecewiseLinear(optimizer, ""lr"", milestones_values=[(10, 0.5), (5, 0.6)])\n\n    with pytest.raises(ValueError):\n        PiecewiseLinear(optimizer, ""lr"", milestones_values=[(0.5, 1)])\n\n\ndef test_piecewiselinear():\n    def _test(milestones_as_np_int):\n        tensor = torch.zeros([1], requires_grad=True)\n        optimizer = torch.optim.SGD([tensor], lr=0)\n\n        milestones_values = [(5, 0.5), (15, 1.0), (25, 0.0), (35, 1.0), (40, 0.5)]\n        if milestones_as_np_int:\n            milestones_values = [(np.int64(t), v) for t, v in milestones_values]\n\n        scheduler = PiecewiseLinear(optimizer, ""lr"", milestones_values=milestones_values)\n        state_dict = scheduler.state_dict()\n\n        def save_lr(engine):\n            lrs.append(optimizer.param_groups[0][""lr""])\n\n        trainer = Engine(lambda engine, batch: None)\n        trainer.add_event_handler(Events.ITERATION_COMPLETED, scheduler)\n        trainer.add_event_handler(Events.ITERATION_COMPLETED, save_lr)\n\n        for _ in range(2):\n            lrs = []\n            trainer.run([0] * 25, max_epochs=2)\n\n            assert lrs == list(\n                map(\n                    pytest.approx,\n                    [\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.55,\n                        0.6,\n                        0.65,\n                        0.7,\n                        0.75,\n                        0.8,\n                        0.85,\n                        0.9,\n                        0.95,\n                        1.0,\n                        0.9,\n                        0.8,\n                        0.7,\n                        0.6,\n                        0.5,\n                        0.4,\n                        0.3,\n                        0.2,\n                        0.1,\n                        0.0,\n                        0.1,\n                        0.2,\n                        0.3,\n                        0.4,\n                        0.5,\n                        0.6,\n                        0.7,\n                        0.8,\n                        0.9,\n                        1.0,\n                        0.9,\n                        0.8,\n                        0.7,\n                        0.6,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                        0.5,\n                    ],\n                )\n            )\n            scheduler.load_state_dict(state_dict)\n\n    _test(milestones_as_np_int=True)\n    _test(milestones_as_np_int=False)\n\n\ndef test_simulate_and_plot_values():\n\n    import matplotlib\n\n    matplotlib.use(""Agg"")\n\n    def _test(scheduler_cls, **scheduler_kwargs):\n\n        optimizer = None\n        event = Events.ITERATION_STARTED\n        if scheduler_cls == LRScheduler:\n            scheduler_kwargs[""optimizer""] = scheduler_kwargs[""lr_scheduler""].optimizer\n            optimizer = scheduler_kwargs[""optimizer""]\n            event = Events.ITERATION_COMPLETED\n        elif scheduler_cls == ConcatScheduler:\n            optimizer = scheduler_kwargs[""optimizer""]\n            del scheduler_kwargs[""optimizer""]\n        else:\n            tensor = torch.zeros([1], requires_grad=True)\n            scheduler_kwargs[""optimizer""] = torch.optim.SGD([tensor], lr=0.1)\n            optimizer = scheduler_kwargs[""optimizer""]\n\n        max_epochs = 2\n        data = [0] * 10\n        # simulated_values = scheduler_cls.simulate_values(num_events=len(data) * max_epochs, **scheduler_kwargs)\n\n        scheduler = scheduler_cls(**scheduler_kwargs)\n\n        lrs = []\n\n        def save_lr(engine):\n            lrs.append(optimizer.param_groups[0][""lr""])\n\n        trainer = Engine(lambda engine, batch: None)\n        trainer.add_event_handler(event, scheduler)\n        trainer.add_event_handler(Events.ITERATION_STARTED, save_lr)\n        trainer.run(data, max_epochs=max_epochs)\n\n        # assert lrs == pytest.approx([v for i, v in simulated_values])\n\n        if scheduler_cls == LRScheduler or scheduler_cls == ConcatScheduler:\n            # As internal state of torch lr scheduler has been changed the following checks will fail\n            return\n\n        # reexecute to check if no internal changes\n        # simulated_values = scheduler_cls.simulate_values(num_events=len(data) * max_epochs,\n        #                                                  save_history=True,  # this will be removed\n        #                                                  **scheduler_kwargs)\n        # assert lrs == pytest.approx([v for i, v in simulated_values])\n\n        # launch plot values\n        scheduler_cls.plot_values(num_events=len(data) * max_epochs, **scheduler_kwargs)\n\n    # LinearCyclicalScheduler\n    _test(LinearCyclicalScheduler, param_name=""lr"", start_value=1.0, end_value=0.0, cycle_size=10)\n\n    # CosineAnnealingScheduler\n    _test(CosineAnnealingScheduler, param_name=""lr"", start_value=1.0, end_value=0.0, cycle_size=10)\n\n    # LRScheduler\n    tensor = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0.1)\n    torch_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.5)\n\n    _test(LRScheduler, lr_scheduler=torch_lr_scheduler)\n\n    # ConcatScheduler = [LinearCyclicalScheduler, CosineAnnealingScheduler]\n    scheduler_1 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=1.0, end_value=0.0, cycle_size=20)\n    scheduler_2 = CosineAnnealingScheduler(optimizer, ""lr"", start_value=0.0, end_value=1.0, cycle_size=10)\n    durations = [10]\n    _test(ConcatScheduler, optimizer=optimizer, schedulers=[scheduler_1, scheduler_2], durations=durations)\n\n    # ConcatScheduler = [LinearCyclicalScheduler, LRScheduler]\n    tensor = torch.ones([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0.001)\n    torch_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=1.5)\n    scheduler_1 = LRScheduler(torch_lr_scheduler)\n    scheduler_2 = LinearCyclicalScheduler(optimizer, ""lr"", start_value=0.1, end_value=0.0, cycle_size=10)\n    durations = [10]\n    _test(ConcatScheduler, optimizer=optimizer, schedulers=[scheduler_1, scheduler_2], durations=durations)\n\n    # PiecewiseLinear\n    tensor = torch.ones([1], requires_grad=True)\n    optimizer = torch.optim.SGD([tensor], lr=0.001)\n    _test(\n        PiecewiseLinear,\n        optimizer=optimizer,\n        param_name=""lr"",\n        milestones_values=[(10, 0.5), (20, 0.45), (21, 0.3), (30, 0.1), (40, 0.1)],\n    )\n\n\ndef test_create_lr_scheduler_with_warmup():\n\n    with pytest.raises(TypeError, match=r""Argument lr_scheduler should be a subclass of""):\n        create_lr_scheduler_with_warmup(12, warmup_start_value=0.0, warmup_end_value=0.1, warmup_duration=10)\n\n    t1 = torch.zeros([1], requires_grad=True)\n    # A) opt lr != warmup_end_value\n    optimizer = torch.optim.SGD([t1], lr=0.2)\n    torch_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.98)\n\n    with pytest.raises(ValueError, match=r""Argument warmup_duration should be at least 2 events""):\n        create_lr_scheduler_with_warmup(\n            torch_lr_scheduler, warmup_start_value=0.0, warmup_end_value=0.1, warmup_duration=1\n        )\n\n    with pytest.raises(ValueError, match=r""Argument warmup_duration should be at least 2 events""):\n        create_lr_scheduler_with_warmup(\n            torch_lr_scheduler, warmup_start_value=0.0, warmup_end_value=0.1, warmup_duration=""abc""\n        )\n\n    with pytest.raises(TypeError, match=r""Argument output_simulated_values should be a list of None""):\n        simulated_values = ()\n        create_lr_scheduler_with_warmup(\n            torch_lr_scheduler,\n            warmup_start_value=0.0,\n            warmup_end_value=0.1,\n            warmup_duration=10,\n            output_simulated_values=simulated_values,\n        )\n\n    def _test(lr_scheduler, optimizer, warmup_start_value, warmup_end_value, warmup_duration, warmup_end_next_value):\n        num_iterations = 10\n        max_epochs = 20\n\n        simulated_values = [None] * (num_iterations * max_epochs)\n        scheduler = create_lr_scheduler_with_warmup(\n            lr_scheduler,\n            warmup_start_value=warmup_start_value,\n            warmup_end_value=warmup_end_value,\n            warmup_duration=warmup_duration,\n            output_simulated_values=simulated_values,\n        )\n        if warmup_end_value is None:\n            warmup_end_value = optimizer.param_groups[0][""lr""]\n\n        state_dict = scheduler.state_dict()\n        trainer = Engine(lambda engine, batch: None)\n\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n\n        @trainer.on(Events.ITERATION_STARTED)\n        def save_lr(engine):\n            lrs.append(optimizer.param_groups[0][""lr""])\n\n        data = [0] * num_iterations\n\n        for _ in range(2):\n            lrs = []\n            trainer.run(data, max_epochs=max_epochs)\n\n            assert lrs == pytest.approx([v for i, v in simulated_values])\n\n            assert lrs[0] == pytest.approx(warmup_start_value), ""lrs={}"".format(lrs[: warmup_duration + num_iterations])\n            assert lrs[warmup_duration - 1] == pytest.approx(warmup_end_value), ""lrs={}"".format(\n                lrs[: warmup_duration + num_iterations]\n            )\n            assert lrs[warmup_duration] == pytest.approx(warmup_end_next_value), ""lrs={}"".format(\n                lrs[: warmup_duration + num_iterations]\n            )\n            scheduler.load_state_dict(state_dict)\n\n    t1 = torch.zeros([1], requires_grad=True)\n    # A) opt lr != warmup_end_value\n    optimizer = torch.optim.SGD([t1], lr=0.2)\n    torch_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.98)\n    _test(torch_lr_scheduler, optimizer, 0.01, 0.05, 10, 0.2)\n    optimizer = torch.optim.SGD([t1], lr=0.2)\n    torch_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.98)\n    _test(torch_lr_scheduler, optimizer, 0.01, 0.05, 2, 0.2)\n\n    # B) opt lr == warmup_end_value\n    optimizer = torch.optim.SGD([t1], lr=0.2)\n    torch_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.98)\n    _test(torch_lr_scheduler, optimizer, 0.01, 0.2, 10, 0.2 * 0.98)\n    optimizer = torch.optim.SGD([t1], lr=0.2)\n    torch_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.98)\n    _test(torch_lr_scheduler, optimizer, 0.01, 0.2, 2, 0.2 * 0.98)\n\n    # C) lr_scheduler start_value != warmup_end_value\n    t1 = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([t1], lr=0.0)\n    lr_scheduler = LinearCyclicalScheduler(\n        optimizer=optimizer, param_name=""lr"", start_value=0.8, end_value=0.0, cycle_size=10\n    )\n    _test(lr_scheduler, optimizer, 0.01, 0.05, 10, 0.8)\n    optimizer = torch.optim.SGD([t1], lr=0.0)\n    lr_scheduler = LinearCyclicalScheduler(\n        optimizer=optimizer, param_name=""lr"", start_value=0.8, end_value=0.0, cycle_size=10\n    )\n    _test(lr_scheduler, optimizer, 0.01, 0.05, 2, 0.8)\n\n    # D) lr_scheduler start_value == warmup_end_value\n    t1 = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([t1], lr=0.0)\n    lr_scheduler = LinearCyclicalScheduler(\n        optimizer=optimizer, param_name=""lr"", start_value=0.8, end_value=0.0, cycle_size=10\n    )\n    _test(lr_scheduler, optimizer, 0.01, 0.8, 10, 0.8 - (0.8 / 5.0))\n    optimizer = torch.optim.SGD([t1], lr=0.0)\n    lr_scheduler = LinearCyclicalScheduler(\n        optimizer=optimizer, param_name=""lr"", start_value=0.8, end_value=0.0, cycle_size=10\n    )\n    _test(lr_scheduler, optimizer, 0.01, 0.8, 2, 0.8 - (0.8 / 5.0))\n\n    # E) warmup_end_value is None: fall back to case B)\n    optimizer = torch.optim.SGD([t1], lr=0.2)\n    torch_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.98)\n    _test(torch_lr_scheduler, optimizer, 0.01, None, 10, 0.2 * 0.98)\n\n\ndef test_create_lr_scheduler_with_warmup_on_combined_scheduler():\n    # Test with a complex scheduler\n    def _test(save_history):\n        tensor = torch.ones([1], requires_grad=True)\n        optimizer = torch.optim.SGD([tensor], lr=0.001)\n\n        max_epochs = 25\n        lr_max_value = 0.4\n        num_iterations_per_epoch = 128\n        num_iterations = max_epochs * num_iterations_per_epoch\n        warmup_duration = 5 * num_iterations_per_epoch\n        cooldown_duration = 5 * num_iterations_per_epoch\n\n        scheduler_1 = LinearCyclicalScheduler(\n            optimizer,\n            ""lr"",\n            start_value=lr_max_value,\n            end_value=lr_max_value * 0.9,\n            cycle_size=(num_iterations - warmup_duration - cooldown_duration) * 2,\n        )\n\n        scheduler_2 = LinearCyclicalScheduler(\n            optimizer, ""lr"", start_value=lr_max_value, end_value=0.0, cycle_size=cooldown_duration * 2\n        )\n\n        lr_scheduler = ConcatScheduler(\n            schedulers=[scheduler_1, scheduler_2],\n            durations=[num_iterations - warmup_duration - cooldown_duration],\n            save_history=False,\n        )\n        lr_values = [None] * num_iterations\n        scheduler = create_lr_scheduler_with_warmup(\n            lr_scheduler,\n            warmup_start_value=0.0,\n            warmup_end_value=lr_max_value,\n            warmup_duration=warmup_duration,\n            save_history=save_history,\n            output_simulated_values=lr_values,\n        )\n        state_dict = scheduler.state_dict()\n\n        trainer = Engine(lambda engine, batch: None)\n\n        @trainer.on(Events.ITERATION_COMPLETED)\n        def save_lr(engine):\n            lrs.append(optimizer.param_groups[0][""lr""])\n\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n\n        data = [0] * num_iterations_per_epoch\n\n        for _ in range(2):\n            lrs = []\n            trainer.run(data, max_epochs=max_epochs)\n\n            assert lrs == pytest.approx([v for i, v in lr_values])\n\n            if save_history:\n                param_history = trainer.state.param_history[""lr""]\n                assert lrs == pytest.approx([v[0] for v in param_history])\n\n                trainer.state.param_history = None\n\n            scheduler.load_state_dict(state_dict)\n\n    _test(save_history=False)\n    _test(save_history=True)\n\n\ndef test_create_lr_scheduler_with_warmup_with_real_model(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=False, with_frozen_layer=False)\n    init_lr = 0.01\n    optimizer = torch.optim.SGD(model.parameters(), lr=init_lr)\n    scaled_lr = 0.02\n    warmup_duration = 5\n    step_size = 2\n    gamma = 0.97\n\n    output_simulated_values = [None] * 50\n\n    create_lr_scheduler_with_warmup(\n        torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma),\n        warmup_start_value=0.0,\n        warmup_end_value=scaled_lr,\n        warmup_duration=warmup_duration,\n        output_simulated_values=output_simulated_values,\n    )\n\n    assert output_simulated_values[0] == [0, 0.0]\n    assert output_simulated_values[warmup_duration - 1] == [warmup_duration - 1, scaled_lr]\n    assert output_simulated_values[warmup_duration] == [warmup_duration, init_lr]\n    v = [warmup_duration + step_size, init_lr * gamma]\n    assert output_simulated_values[warmup_duration + step_size] == v\n\n\ndef test_param_group_scheduler_asserts():\n\n    t1 = torch.zeros([1], requires_grad=True)\n    t2 = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([{""params"": t1, ""lr"": 0.1}, {""params"": t2, ""lr"": 0.1}])\n\n    lr_scheduler1 = LinearCyclicalScheduler(\n        optimizer, ""lr"", param_group_index=0, start_value=1.0, end_value=0.0, cycle_size=10\n    )\n    lr_scheduler2 = LinearCyclicalScheduler(\n        optimizer, ""lr"", param_group_index=1, start_value=1.0, end_value=0.0, cycle_size=10\n    )\n\n    with pytest.raises(ValueError):\n        ParamGroupScheduler(schedulers=[0, 1, 2], names=[""a"", ""b"", ""c""])\n\n    with pytest.raises(ValueError):\n        ParamGroupScheduler(schedulers=[lr_scheduler1, ""2""], names=[""a"", ""b""])\n\n    with pytest.raises(ValueError):\n        ParamGroupScheduler(schedulers=[lr_scheduler1, lr_scheduler2], names=""ab"")\n\n    with pytest.raises(ValueError):\n        ParamGroupScheduler(schedulers=[lr_scheduler1, lr_scheduler2], names=[""a""])\n\n    scheduler = ParamGroupScheduler(schedulers=[lr_scheduler1, lr_scheduler2], names=[""a"", ""b""])\n    with pytest.raises(ValueError, match=r""Required state attribute \'schedulers\' is absent in provided state_dict""):\n        scheduler.load_state_dict({""a"": 1})\n\n    with pytest.raises(ValueError, match=r""Input state_dict contains 0 state_dicts of param group schedulers""):\n        scheduler.load_state_dict({""schedulers"": []})\n\n    with pytest.raises(ValueError, match=r""Required state attribute \'schedulers\' is absent in provided state_dict""):\n        scheduler.load_state_dict({})\n\n    with pytest.raises(\n        ValueError, match=r""Name of scheduler from input state dict does not "" r""correspond to required one""\n    ):\n        scheduler.load_state_dict({""schedulers"": [(""a"", lr_scheduler1.state_dict()), (""bad_name"", {})]})\n\n    optimizer2 = torch.optim.SGD([{""params"": t1, ""lr"": 0.1}, {""params"": t2, ""lr"": 0.1}])\n    lr_scheduler3 = LinearCyclicalScheduler(\n        optimizer2, ""lr"", param_group_index=0, start_value=1.0, end_value=0.0, cycle_size=10\n    )\n    with pytest.raises(ValueError, match=r""schedulers should be related to same optimizer""):\n        ParamGroupScheduler(schedulers=[lr_scheduler1, lr_scheduler3])\n\n\ndef test_param_group_scheduler():\n    def _test(lr_schedulers, optimizer):\n        num_iterations = 10\n        max_epochs = 20\n\n        scheduler = ParamGroupScheduler(lr_schedulers, names=[""s_{}"".format(i) for i in range(len(lr_schedulers))])\n        state_dict = scheduler.state_dict()\n\n        trainer = Engine(lambda engine, batch: None)\n\n        @trainer.on(Events.ITERATION_COMPLETED)\n        def save_lr(engine):\n            lrs.append((optimizer.param_groups[0][""lr""], optimizer.param_groups[1][""lr""]))\n\n        trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n\n        data = [0] * num_iterations\n\n        for _ in range(2):\n            lrs = []\n            trainer.run(data, max_epochs=max_epochs)\n            assert [lr[0] for lr in lrs] == pytest.approx([lr[1] for lr in lrs])\n            scheduler.load_state_dict(state_dict)\n\n            values = ParamGroupScheduler.simulate_values(max_epochs * num_iterations, lr_schedulers)\n            assert [lr[1] for lr in values] == pytest.approx([lr[2] for lr in values])\n            assert [lr[0] for lr in lrs] == pytest.approx([lr[1] for lr in values])\n\n    t1 = torch.zeros([1], requires_grad=True)\n    t2 = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([{""params"": t1, ""lr"": 0.1}, {""params"": t2, ""lr"": 0.1}])\n\n    lr_scheduler1 = LinearCyclicalScheduler(\n        optimizer, ""lr"", param_group_index=0, start_value=1.0, end_value=0.0, cycle_size=10\n    )\n    lr_scheduler2 = LinearCyclicalScheduler(\n        optimizer, ""lr"", param_group_index=1, start_value=1.0, end_value=0.0, cycle_size=10\n    )\n    _test([lr_scheduler1, lr_scheduler2], optimizer)\n\n\ndef test_scheduler_with_param_groups():\n    def _test(lr_scheduler, optimizer):\n        num_iterations = 10\n        max_epochs = 20\n\n        state_dict = lr_scheduler.state_dict()\n\n        trainer = Engine(lambda engine, batch: None)\n\n        @trainer.on(Events.ITERATION_COMPLETED)\n        def save_lr():\n            lrs.append((optimizer.param_groups[0][""lr""], optimizer.param_groups[1][""lr""]))\n\n        trainer.add_event_handler(Events.ITERATION_STARTED, lr_scheduler)\n\n        data = [0] * num_iterations\n\n        for _ in range(2):\n            lrs = []\n            trainer.run(data, max_epochs=max_epochs)\n            assert [lr[0] for lr in lrs] == pytest.approx([lr[1] for lr in lrs])\n            lr_scheduler.load_state_dict(state_dict)\n\n    t1 = torch.zeros([1], requires_grad=True)\n    t2 = torch.zeros([1], requires_grad=True)\n    optimizer = torch.optim.SGD([{""params"": t1, ""lr"": 0.1}, {""params"": t2, ""lr"": 0.1}])\n\n    lr_scheduler = LinearCyclicalScheduler(optimizer, ""lr"", start_value=1.0, end_value=0.0, cycle_size=10)\n    _test(lr_scheduler, optimizer)\n\n    lr_scheduler = PiecewiseLinear(\n        optimizer, ""lr"", milestones_values=[(5, 0.5), (15, 1.0), (25, 0.0), (35, 1.0), (40, 0.5)]\n    )\n    _test(lr_scheduler, optimizer)\n\n    lr_scheduler = CosineAnnealingScheduler(optimizer, ""lr"", start_value=0.0, end_value=1.0, cycle_size=10)\n    _test(lr_scheduler, optimizer)\n\n    torch_lr_scheduler = ExponentialLR(optimizer, gamma=0.98)\n    _test(LRScheduler(torch_lr_scheduler), optimizer)\n\n    torch_lr_scheduler = StepLR(optimizer, step_size=50, gamma=0.5)\n    _test(LRScheduler(torch_lr_scheduler), optimizer)\n'"
tests/ignite/contrib/handlers/test_polyaxon_logger.py,7,"b'import os\nfrom unittest.mock import MagicMock, call\n\nimport pytest\nimport torch\n\nfrom ignite.contrib.handlers.polyaxon_logger import *\nfrom ignite.engine import Engine, Events, State\n\nos.environ[""POLYAXON_NO_OP""] = ""1""\n\n\ndef test_output_handler_with_wrong_logger_type():\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'OutputHandler\' works only with PolyaxonLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_output_handler_output_transform():\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.output = 12345\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    mock_logger.log_metrics.assert_called_once_with(step=123, **{""tag/output"": 12345})\n\n    wrapper = OutputHandler(""another_tag"", output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metrics.assert_called_once_with(step=123, **{""another_tag/loss"": 12345})\n\n\ndef test_output_handler_metric_names():\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b"", ""c""])\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45, ""c"": torch.tensor(10.0)})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_called_once_with(step=5, **{""tag/a"": 12.23, ""tag/b"": 23.45, ""tag/c"": 10.0})\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"",])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": torch.Tensor([0.0, 1.0, 2.0, 3.0])})\n    mock_engine.state.iteration = 5\n\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_has_calls(\n        [call(step=5, **{""tag/a/0"": 0.0, ""tag/a/1"": 1.0, ""tag/a/2"": 2.0, ""tag/a/3"": 3.0}),], any_order=True\n    )\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""c""])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 55.56, ""c"": ""Some text""})\n    mock_engine.state.iteration = 7\n\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    with pytest.warns(UserWarning):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_has_calls([call(step=7, **{""tag/a"": 55.56})], any_order=True)\n\n    # all metrics\n    wrapper = OutputHandler(""tag"", metric_names=""all"")\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45, ""c"": torch.tensor(10.0)})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_called_once_with(step=5, **{""tag/a"": 12.23, ""tag/b"": 23.45, ""tag/c"": 10.0})\n\n\ndef test_output_handler_both():\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_called_once_with(step=5, **{""tag/a"": 12.23, ""tag/b"": 23.45, ""tag/loss"": 12345})\n\n\ndef test_output_handler_with_wrong_global_step_transform_output():\n    def global_step_transform(*args, **kwargs):\n        return ""a""\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    with pytest.raises(TypeError, match=""global_step must be int""):\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n\ndef test_output_handler_with_global_step_transform():\n    def global_step_transform(*args, **kwargs):\n        return 10\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    mock_logger.log_metrics.assert_called_once_with(step=10, **{""tag/loss"": 12345})\n\n\ndef test_output_handler_with_global_step_from_engine():\n\n    mock_another_engine = MagicMock()\n    mock_another_engine.state = State()\n    mock_another_engine.state.epoch = 10\n    mock_another_engine.state.output = 12.345\n\n    wrapper = OutputHandler(\n        ""tag"",\n        output_transform=lambda x: {""loss"": x},\n        global_step_transform=global_step_from_engine(mock_another_engine),\n    )\n\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 1\n    mock_engine.state.output = 0.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.log_metrics.call_count == 1\n    mock_logger.log_metrics.assert_has_calls(\n        [call(step=mock_another_engine.state.epoch, **{""tag/loss"": mock_engine.state.output})]\n    )\n\n    mock_another_engine.state.epoch = 11\n    mock_engine.state.output = 1.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.log_metrics.call_count == 2\n    mock_logger.log_metrics.assert_has_calls(\n        [call(step=mock_another_engine.state.epoch, **{""tag/loss"": mock_engine.state.output})]\n    )\n\n\ndef test_optimizer_params_handler_wrong_setup():\n\n    with pytest.raises(TypeError):\n        OptimizerParamsHandler(optimizer=None)\n\n    optimizer = MagicMock(spec=torch.optim.Optimizer)\n    handler = OptimizerParamsHandler(optimizer=optimizer)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OptimizerParamsHandler works only with PolyaxonLogger""):\n        handler(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_optimizer_params():\n\n    optimizer = torch.optim.SGD([torch.Tensor(0)], lr=0.01)\n    wrapper = OptimizerParamsHandler(optimizer=optimizer, param_name=""lr"")\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metrics.assert_called_once_with(**{""lr/group_0"": 0.01, ""step"": 123})\n\n    wrapper = OptimizerParamsHandler(optimizer, param_name=""lr"", tag=""generator"")\n    mock_logger = MagicMock(spec=PolyaxonLogger)\n    mock_logger.log_metrics = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log_metrics.assert_called_once_with(**{""generator/lr/group_0"": 0.01, ""step"": 123})\n\n\ndef test_integration():\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    trainer = Engine(update_fn)\n\n    plx_logger = PolyaxonLogger()\n\n    def dummy_handler(engine, logger, event_name):\n        global_step = engine.state.get_event_attrib_value(event_name)\n        logger.log_metrics(step=global_step, **{""{}"".format(""test_value""): global_step})\n\n    plx_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n    trainer.run(data, max_epochs=n_epochs)\n\n\ndef test_integration_as_context_manager():\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    with PolyaxonLogger() as plx_logger:\n\n        trainer = Engine(update_fn)\n\n        def dummy_handler(engine, logger, event_name):\n            global_step = engine.state.get_event_attrib_value(event_name)\n            logger.log_metrics(step=global_step, **{""{}"".format(""test_value""): global_step})\n\n        plx_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n        trainer.run(data, max_epochs=n_epochs)\n\n\n@pytest.fixture\ndef no_site_packages():\n    import sys\n\n    polyaxon_client_modules = {}\n    for k in sys.modules:\n        if ""polyaxon"" in k:\n            polyaxon_client_modules[k] = sys.modules[k]\n    for k in polyaxon_client_modules:\n        del sys.modules[k]\n\n    prev_path = list(sys.path)\n    sys.path = [p for p in sys.path if ""site-packages"" not in p]\n    yield ""no_site_packages""\n    sys.path = prev_path\n    for k in polyaxon_client_modules:\n        sys.modules[k] = polyaxon_client_modules[k]\n\n\ndef test_no_polyaxon_client(no_site_packages):\n\n    with pytest.raises(RuntimeError, match=r""This contrib module requires polyaxon-client to be installed""):\n        PolyaxonLogger()\n'"
tests/ignite/contrib/handlers/test_tensorboard_logger.py,16,"b'import math\nimport os\nfrom unittest.mock import ANY, MagicMock, call, patch\n\nimport pytest\nimport torch\n\nfrom ignite.contrib.handlers.tensorboard_logger import *\nfrom ignite.engine import Engine, Events, State\n\n\ndef test_optimizer_params_handler_wrong_setup():\n\n    with pytest.raises(TypeError):\n        OptimizerParamsHandler(optimizer=None)\n\n    optimizer = MagicMock(spec=torch.optim.Optimizer)\n    handler = OptimizerParamsHandler(optimizer=optimizer)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OptimizerParamsHandler works only with TensorboardLogger""):\n        handler(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_optimizer_params():\n\n    optimizer = torch.optim.SGD([torch.Tensor(0)], lr=0.01)\n    wrapper = OptimizerParamsHandler(optimizer=optimizer, param_name=""lr"")\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.writer.add_scalar.assert_called_once_with(""lr/group_0"", 0.01, 123)\n\n    wrapper = OptimizerParamsHandler(optimizer, param_name=""lr"", tag=""generator"")\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.writer.add_scalar.assert_called_once_with(""generator/lr/group_0"", 0.01, 123)\n\n\ndef test_output_handler_with_wrong_logger_type():\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'OutputHandler\' works only with TensorboardLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_output_handler_output_transform():\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.output = 12345\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    mock_logger.writer.add_scalar.assert_called_once_with(""tag/output"", 12345, 123)\n\n    wrapper = OutputHandler(""another_tag"", output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.writer.add_scalar.assert_called_once_with(""another_tag/loss"", 12345, 123)\n\n\ndef test_output_handler_metric_names():\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""])\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.writer.add_scalar.call_count == 2\n    mock_logger.writer.add_scalar.assert_has_calls([call(""tag/a"", 12.23, 5), call(""tag/b"", 23.45, 5),], any_order=True)\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"",])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": torch.Tensor([0.0, 1.0, 2.0, 3.0])})\n    mock_engine.state.iteration = 5\n\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.writer.add_scalar.call_count == 4\n    mock_logger.writer.add_scalar.assert_has_calls(\n        [call(""tag/a/0"", 0.0, 5), call(""tag/a/1"", 1.0, 5), call(""tag/a/2"", 2.0, 5), call(""tag/a/3"", 3.0, 5),],\n        any_order=True,\n    )\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""c""])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 55.56, ""c"": ""Some text""})\n    mock_engine.state.iteration = 7\n\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    with pytest.warns(UserWarning):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.writer.add_scalar.call_count == 1\n    mock_logger.writer.add_scalar.assert_has_calls([call(""tag/a"", 55.56, 7),], any_order=True)\n\n    # all metrics\n    wrapper = OutputHandler(""tag"", metric_names=""all"")\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.writer.add_scalar.call_count == 2\n    mock_logger.writer.add_scalar.assert_has_calls([call(""tag/a"", 12.23, 5), call(""tag/b"", 23.45, 5),], any_order=True)\n\n\ndef test_output_handler_both():\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.writer.add_scalar.call_count == 3\n    mock_logger.writer.add_scalar.assert_has_calls(\n        [call(""tag/a"", 12.23, 5), call(""tag/b"", 23.45, 5), call(""tag/loss"", 12345, 5)], any_order=True\n    )\n\n\ndef test_output_handler_with_wrong_global_step_transform_output():\n    def global_step_transform(*args, **kwargs):\n        return ""a""\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    with pytest.raises(TypeError, match=""global_step must be int""):\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n\ndef test_output_handler_with_global_step_from_engine():\n\n    mock_another_engine = MagicMock()\n    mock_another_engine.state = State()\n    mock_another_engine.state.epoch = 10\n    mock_another_engine.state.output = 12.345\n\n    wrapper = OutputHandler(\n        ""tag"",\n        output_transform=lambda x: {""loss"": x},\n        global_step_transform=global_step_from_engine(mock_another_engine),\n    )\n\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 1\n    mock_engine.state.output = 0.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.writer.add_scalar.call_count == 1\n    mock_logger.writer.add_scalar.assert_has_calls(\n        [call(""tag/loss"", mock_engine.state.output, mock_another_engine.state.epoch)]\n    )\n\n    mock_another_engine.state.epoch = 11\n    mock_engine.state.output = 1.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.writer.add_scalar.call_count == 2\n    mock_logger.writer.add_scalar.assert_has_calls(\n        [call(""tag/loss"", mock_engine.state.output, mock_another_engine.state.epoch)]\n    )\n\n\ndef test_output_handler_with_global_step_transform():\n    def global_step_transform(*args, **kwargs):\n        return 10\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.writer.add_scalar.call_count == 1\n    mock_logger.writer.add_scalar.assert_has_calls([call(""tag/loss"", 12345, 10)])\n\n\ndef test_weights_scalar_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        WeightsScalarHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    with pytest.raises(TypeError, match=""Argument reduction should be callable""):\n        WeightsScalarHandler(model, reduction=123)\n\n    with pytest.raises(ValueError, match=""Output of the reduction function should be a scalar""):\n        WeightsScalarHandler(model, reduction=lambda x: x)\n\n    wrapper = WeightsScalarHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'WeightsScalarHandler\' works only with TensorboardLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_weights_scalar_handler(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = WeightsScalarHandler(model, tag=tag)\n        mock_logger = MagicMock(spec=TensorboardLogger)\n        mock_logger.writer = MagicMock()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.writer.add_scalar.call_count == 4\n        mock_logger.writer.add_scalar.assert_has_calls(\n            [\n                call(tag_prefix + ""weights_norm/fc1/weight"", 0.0, 5),\n                call(tag_prefix + ""weights_norm/fc1/bias"", 0.0, 5),\n                call(tag_prefix + ""weights_norm/fc2/weight"", 12.0, 5),\n                call(tag_prefix + ""weights_norm/fc2/bias"", math.sqrt(12.0), 5),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_weights_scalar_handler_frozen_layers(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = WeightsScalarHandler(model)\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.writer.add_scalar.assert_has_calls(\n        [call(""weights_norm/fc2/weight"", 12.0, 5), call(""weights_norm/fc2/bias"", math.sqrt(12.0), 5),], any_order=True\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.writer.add_scalar.assert_has_calls(\n            [call(""weights_norm/fc1/weight"", 12.0, 5), call(""weights_norm/fc1/bias"", math.sqrt(12.0), 5),],\n            any_order=True,\n        )\n\n    assert mock_logger.writer.add_scalar.call_count == 2\n\n\ndef test_weights_hist_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        WeightsHistHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    wrapper = WeightsHistHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'WeightsHistHandler\' works only with TensorboardLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_weights_hist_handler(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = WeightsHistHandler(model, tag=tag)\n        mock_logger = MagicMock(spec=TensorboardLogger)\n        mock_logger.writer = MagicMock()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.writer.add_histogram.call_count == 4\n        mock_logger.writer.add_histogram.assert_has_calls(\n            [\n                call(tag=tag_prefix + ""weights/fc1/weight"", values=ANY, global_step=5),\n                call(tag=tag_prefix + ""weights/fc1/bias"", values=ANY, global_step=5),\n                call(tag=tag_prefix + ""weights/fc2/weight"", values=ANY, global_step=5),\n                call(tag=tag_prefix + ""weights/fc2/bias"", values=ANY, global_step=5),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_weights_hist_handler_frozen_layers(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = WeightsHistHandler(model)\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.writer.add_histogram.assert_has_calls(\n        [\n            call(tag=""weights/fc2/weight"", values=ANY, global_step=5),\n            call(tag=""weights/fc2/bias"", values=ANY, global_step=5),\n        ],\n        any_order=True,\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.writer.add_histogram.assert_has_calls(\n            [\n                call(tag=""weights/fc1/weight"", values=ANY, global_step=5),\n                call(tag=""weights/fc1/bias"", values=ANY, global_step=5),\n            ],\n            any_order=True,\n        )\n    assert mock_logger.writer.add_histogram.call_count == 2\n\n\ndef test_grads_scalar_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        GradsScalarHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    with pytest.raises(TypeError, match=""Argument reduction should be callable""):\n        GradsScalarHandler(model, reduction=123)\n\n    wrapper = GradsScalarHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'GradsScalarHandler\' works only with TensorboardLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_grads_scalar_handler(dummy_model_factory, norm_mock):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = GradsScalarHandler(model, reduction=norm_mock, tag=tag)\n        mock_logger = MagicMock(spec=TensorboardLogger)\n        mock_logger.writer = MagicMock()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n        norm_mock.reset_mock()\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        mock_logger.writer.add_scalar.assert_has_calls(\n            [\n                call(tag_prefix + ""grads_norm/fc1/weight"", ANY, 5),\n                call(tag_prefix + ""grads_norm/fc1/bias"", ANY, 5),\n                call(tag_prefix + ""grads_norm/fc2/weight"", ANY, 5),\n                call(tag_prefix + ""grads_norm/fc2/bias"", ANY, 5),\n            ],\n            any_order=True,\n        )\n        assert mock_logger.writer.add_scalar.call_count == 4\n        assert norm_mock.call_count == 4\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_grads_scalar_handler_frozen_layers(dummy_model_factory, norm_mock):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = GradsScalarHandler(model, reduction=norm_mock)\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    norm_mock.reset_mock()\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.writer.add_scalar.assert_has_calls(\n        [call(""grads_norm/fc2/weight"", ANY, 5), call(""grads_norm/fc2/bias"", ANY, 5),], any_order=True\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.writer.add_scalar.assert_has_calls(\n            [call(""grads_norm/fc1/weight"", ANY, 5), call(""grads_norm/fc1/bias"", ANY, 5),], any_order=True\n        )\n    assert mock_logger.writer.add_scalar.call_count == 2\n    assert norm_mock.call_count == 2\n\n\ndef test_grads_hist_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        GradsHistHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    wrapper = GradsHistHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'GradsHistHandler\' works only with TensorboardLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_grads_hist_handler(dummy_model_factory):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = GradsHistHandler(model, tag=tag)\n        mock_logger = MagicMock(spec=TensorboardLogger)\n        mock_logger.writer = MagicMock()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.writer.add_histogram.call_count == 4\n        mock_logger.writer.add_histogram.assert_has_calls(\n            [\n                call(tag=tag_prefix + ""grads/fc1/weight"", values=ANY, global_step=5),\n                call(tag=tag_prefix + ""grads/fc1/bias"", values=ANY, global_step=5),\n                call(tag=tag_prefix + ""grads/fc2/weight"", values=ANY, global_step=5),\n                call(tag=tag_prefix + ""grads/fc2/bias"", values=ANY, global_step=5),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_grads_hist_frozen_layers(dummy_model_factory):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = GradsHistHandler(model)\n    mock_logger = MagicMock(spec=TensorboardLogger)\n    mock_logger.writer = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.writer.add_histogram.call_count == 2\n    mock_logger.writer.add_histogram.assert_has_calls(\n        [\n            call(tag=""grads/fc2/weight"", values=ANY, global_step=5),\n            call(tag=""grads/fc2/bias"", values=ANY, global_step=5),\n        ],\n        any_order=True,\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.writer.add_histogram.assert_has_calls(\n            [\n                call(tag=""grads/fc1/weight"", values=ANY, global_step=5),\n                call(tag=""grads/fc1/bias"", values=ANY, global_step=5),\n            ],\n            any_order=True,\n        )\n\n\ndef test_integration(dirname):\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    trainer = Engine(update_fn)\n\n    tb_logger = TensorboardLogger(log_dir=dirname)\n\n    def dummy_handler(engine, logger, event_name):\n        global_step = engine.state.get_event_attrib_value(event_name)\n        logger.writer.add_scalar(""test_value"", global_step, global_step)\n\n    tb_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n    trainer.run(data, max_epochs=n_epochs)\n    tb_logger.close()\n\n    # Check if event files are present\n    written_files = os.listdir(dirname)\n    written_files = [f for f in written_files if ""tfevents"" in f]\n    assert len(written_files) > 0\n\n\ndef test_integration_as_context_manager(dirname):\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    with TensorboardLogger(log_dir=dirname) as tb_logger:\n\n        trainer = Engine(update_fn)\n\n        def dummy_handler(engine, logger, event_name):\n            global_step = engine.state.get_event_attrib_value(event_name)\n            logger.writer.add_scalar(""test_value"", global_step, global_step)\n\n        tb_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n        trainer.run(data, max_epochs=n_epochs)\n\n    # Check if event files are present\n    written_files = os.listdir(dirname)\n    written_files = [f for f in written_files if ""tfevents"" in f]\n    assert len(written_files) > 0\n\n\ndef test_no_tensorboardX_package(dirname):\n    from torch.utils.tensorboard import SummaryWriter\n\n    with patch.dict(""sys.modules"", {""tensorboardX"": None}):\n        tb_logger = TensorboardLogger(log_dir=dirname)\n        assert isinstance(tb_logger.writer, SummaryWriter), type(tb_logger.writer)\n        tb_logger.close()\n\n\ndef test_no_torch_utils_tensorboard_package(dirname):\n    from tensorboardX import SummaryWriter\n\n    with patch.dict(""sys.modules"", {""torch.utils.tensorboard"": None}):\n        tb_logger = TensorboardLogger(log_dir=dirname)\n        assert isinstance(tb_logger.writer, SummaryWriter), type(tb_logger.writer)\n        tb_logger.close()\n\n\ndef test_no_tensorboardX_nor_torch_utils_tensorboard():\n    with patch.dict(""sys.modules"", {""tensorboardX"": None, ""torch.utils.tensorboard"": None}):\n        with pytest.raises(RuntimeError, match=r""This contrib module requires either tensorboardX or torch""):\n            TensorboardLogger(log_dir=None)\n'"
tests/ignite/contrib/handlers/test_time_profilers.py,0,"b'import os\nimport sys\nimport time\n\nimport pytest\nfrom pytest import approx\n\nfrom ignite.contrib.handlers.time_profilers import BasicTimeProfiler\nfrom ignite.engine import Engine, Events\n\nif sys.platform.startswith(""darwin""):\n    pytest.skip(""Skip if on MacOS"", allow_module_level=True)\n\n\ndef _do_nothing_update_fn(engine, batch):\n    pass\n\n\ndef get_prepared_engine(true_event_handler_time):\n    dummy_trainer = Engine(_do_nothing_update_fn)\n\n    @dummy_trainer.on(Events.STARTED)\n    def delay_start(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.COMPLETED)\n    def delay_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.EPOCH_STARTED)\n    def delay_epoch_start(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.EPOCH_COMPLETED)\n    def delay_epoch_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.ITERATION_STARTED)\n    def delay_iter_start(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.ITERATION_COMPLETED)\n    def delay_iter_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.GET_BATCH_STARTED)\n    def delay_get_batch_started(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.GET_BATCH_COMPLETED)\n    def delay_get_batch_completed(engine):\n        time.sleep(true_event_handler_time)\n\n    return dummy_trainer\n\n\ndef test_dataflow_timer():\n    true_dataflow_time_per_ele = 0.1\n    true_max_epochs = 1\n    true_num_iters = 2\n\n    def dummy_data_loader(data):\n        while True:\n            for d in data:\n                time.sleep(true_dataflow_time_per_ele)\n                yield d\n\n    dummy_data = range(true_num_iters)\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n    dummy_trainer.run(dummy_data_loader(dummy_data), max_epochs=true_max_epochs, epoch_length=true_num_iters)\n    results = profiler.get_results()\n    dataflow_results = results[""dataflow_stats""]\n\n    assert dataflow_results[""min/index""][0] == approx(true_dataflow_time_per_ele, abs=1e-1)\n    assert dataflow_results[""max/index""][0] == approx(true_dataflow_time_per_ele, abs=1e-1)\n    assert dataflow_results[""mean""] == approx(true_dataflow_time_per_ele, abs=1e-1)\n    assert dataflow_results[""std""] == approx(0.0, abs=1e-1)\n    assert dataflow_results[""total""] == approx(true_num_iters * true_dataflow_time_per_ele, abs=1e-1)\n\n\ndef test_processing_timer():\n    true_processing_time = 0.1\n    true_max_epochs = 2\n    true_num_iters = 2\n\n    def train_updater(engine, batch):\n        time.sleep(true_processing_time)\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(train_updater)\n    profiler.attach(dummy_trainer)\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    processing_results = results[""processing_stats""]\n\n    assert processing_results[""min/index""][0] == approx(true_processing_time, abs=1e-1)\n    assert processing_results[""max/index""][0] == approx(true_processing_time, abs=1e-1)\n    assert processing_results[""mean""] == approx(true_processing_time, abs=1e-1)\n    assert processing_results[""std""] == approx(0.0, abs=1e-1)\n    assert processing_results[""total""] == approx(true_max_epochs * true_num_iters * true_processing_time, abs=1e-1)\n\n\ndef test_event_handler_started():\n    true_event_handler_time = 0.1\n    true_max_epochs = 2\n    true_num_iters = 2\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.STARTED)\n    def delay_start(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""][""STARTED""]\n\n    assert event_results[""total""] == approx(true_event_handler_time, abs=1e-1)\n\n\ndef test_event_handler_completed():\n    true_event_handler_time = 0.1\n    true_max_epochs = 2\n    true_num_iters = 2\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.COMPLETED)\n    def delay_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""][""COMPLETED""]\n\n    assert event_results[""total""] == approx(true_event_handler_time, abs=1e-1)\n\n\ndef test_event_handler_epoch_started():\n    true_event_handler_time = 0.1\n    true_max_epochs = 2\n    true_num_iters = 1\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.EPOCH_STARTED)\n    def delay_epoch_start(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""][""EPOCH_STARTED""]\n\n    assert event_results[""min/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""max/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""mean""] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""std""] == approx(0.0, abs=1e-1)\n    assert event_results[""total""] == approx(true_max_epochs * true_event_handler_time, abs=1e-1)\n\n\ndef test_event_handler_epoch_completed():\n    true_event_handler_time = 0.1\n    true_max_epochs = 2\n    true_num_iters = 1\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.EPOCH_COMPLETED)\n    def delay_epoch_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""][""EPOCH_COMPLETED""]\n\n    assert event_results[""min/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""max/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""mean""] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""std""] == approx(0.0, abs=1e-1)\n    assert event_results[""total""] == approx(true_max_epochs * true_event_handler_time, abs=1e-1)\n\n\ndef test_event_handler_iteration_started():\n    true_event_handler_time = 0.1\n    true_max_epochs = 1\n    true_num_iters = 2\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.ITERATION_STARTED)\n    def delay_iter_start(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""][""ITERATION_STARTED""]\n\n    assert event_results[""min/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""max/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""mean""] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""std""] == approx(0.0, abs=1e-1)\n    assert event_results[""total""] == approx(true_max_epochs * true_num_iters * true_event_handler_time, abs=1e-1)\n\n\ndef test_event_handler_iteration_completed():\n    true_event_handler_time = 0.1\n    true_max_epochs = 1\n    true_num_iters = 2\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.ITERATION_COMPLETED)\n    def delay_iter_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""][""ITERATION_COMPLETED""]\n\n    assert event_results[""min/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""max/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""mean""] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""std""] == approx(0.0, abs=1e-1)\n    assert event_results[""total""] == approx(true_max_epochs * true_num_iters * true_event_handler_time, abs=1e-1)\n\n\ndef test_event_handler_get_batch_started():\n    true_event_handler_time = 0.1\n    true_max_epochs = 1\n    true_num_iters = 2\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.GET_BATCH_STARTED)\n    def delay_get_batch_started(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""][""GET_BATCH_STARTED""]\n\n    assert event_results[""min/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""max/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""mean""] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""std""] == approx(0.0, abs=1e-1)\n    assert event_results[""total""] == approx(true_max_epochs * true_num_iters * true_event_handler_time, abs=1e-1)\n\n\ndef test_event_handler_get_batch_completed():\n    true_event_handler_time = 0.1\n    true_max_epochs = 1\n    true_num_iters = 2\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.GET_BATCH_COMPLETED)\n    def delay_get_batch_completed(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""][""GET_BATCH_COMPLETED""]\n\n    assert event_results[""min/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""max/index""][0] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""mean""] == approx(true_event_handler_time, abs=1e-1)\n    assert event_results[""std""] == approx(0.0, abs=1e-1)\n    assert event_results[""total""] == approx(true_max_epochs * true_num_iters * true_event_handler_time, abs=1e-1)\n\n\ndef test_event_handler_total_time():\n    true_event_handler_time = 0.125\n    true_max_epochs = 1\n    true_num_iters = 1\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = Engine(_do_nothing_update_fn)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.STARTED)\n    def delay_start(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.COMPLETED)\n    def delay_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.EPOCH_STARTED)\n    def delay_epoch_start(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.EPOCH_COMPLETED)\n    def delay_epoch_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.ITERATION_STARTED)\n    def delay_iter_start(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.ITERATION_COMPLETED)\n    def delay_iter_complete(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.GET_BATCH_STARTED)\n    def delay_get_batch_started(engine):\n        time.sleep(true_event_handler_time)\n\n    @dummy_trainer.on(Events.GET_BATCH_COMPLETED)\n    def delay_get_batch_completed(engine):\n        time.sleep(true_event_handler_time)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    results = profiler.get_results()\n    event_results = results[""event_handlers_stats""]\n\n    assert event_results[""total_time""].item() == approx(true_event_handler_time * 8, abs=1e-1)\n\n\ndef test_write_results(dirname):\n    true_event_handler_time = 0.125\n    true_max_epochs = 3\n    true_num_iters = 2\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = get_prepared_engine(true_event_handler_time)\n    profiler.attach(dummy_trainer)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    fp = os.path.join(dirname, ""test_log.csv"")\n    profiler.write_results(fp)\n\n    assert os.path.isfile(fp)\n\n    file_length = 0\n    with open(fp) as f:\n        for l in f:\n            file_length += 1\n\n    assert file_length == (true_max_epochs * true_num_iters) + 1\n\n\ndef test_print_results(capsys):\n\n    true_max_epochs = 1\n    true_num_iters = 5\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = get_prepared_engine(true_event_handler_time=0.0125)\n    profiler.attach(dummy_trainer)\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n    BasicTimeProfiler.print_results(profiler.get_results())\n\n    captured = capsys.readouterr()\n    out = captured.out\n    assert ""BasicTimeProfiler._"" not in out\n    assert ""nan"" not in out\n\n\ndef test_get_intermediate_results_during_run(capsys):\n    true_event_handler_time = 0.0645\n    true_max_epochs = 2\n    true_num_iters = 5\n\n    profiler = BasicTimeProfiler()\n    dummy_trainer = get_prepared_engine(true_event_handler_time)\n    profiler.attach(dummy_trainer)\n\n    @dummy_trainer.on(Events.ITERATION_COMPLETED(every=3))\n    def log_results(_):\n        results = profiler.get_results()\n        profiler.print_results(results)\n        captured = capsys.readouterr()\n        out = captured.out\n        assert ""BasicTimeProfiler._"" not in out\n        assert ""nan"" not in out\n        assert "" min/index: (0.0, "" not in out, out\n\n    dummy_trainer.run(range(true_num_iters), max_epochs=true_max_epochs)\n'"
tests/ignite/contrib/handlers/test_tqdm_logger.py,6,"b'# -*- coding: utf-8 -*-\nimport sys\nimport time\n\nimport numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.handlers import CustomPeriodicEvent, ProgressBar\nfrom ignite.engine import Engine, Events\nfrom ignite.handlers import TerminateOnNan\nfrom ignite.metrics import RunningAverage\n\nif sys.platform.startswith(""win""):\n    pytest.skip(""Skip if on Windows"", allow_module_level=True)\n\n\ndef update_fn(engine, batch):\n    a = 1\n    engine.state.metrics[""a""] = a\n    return a\n\n\ndef test_pbar(capsys):\n\n    n_epochs = 2\n    loader = [1, 2]\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar()\n    pbar.attach(engine, [""a""])\n\n    engine.run(loader, max_epochs=n_epochs)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    expected = ""Epoch [2/2]: [1/2]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88     , a=1 [00:00<00:00]""\n    assert err[-1] == expected\n\n\ndef test_pbar_file(tmp_path):\n    n_epochs = 2\n    loader = [1, 2]\n    engine = Engine(update_fn)\n\n    file_path = tmp_path / ""temp.txt""\n    file = open(str(file_path), ""w+"")\n\n    pbar = ProgressBar(file=file)\n    pbar.attach(engine, [""a""])\n    engine.run(loader, max_epochs=n_epochs)\n\n    file.close()  # Force a flush of the buffer. file.flush() does not work.\n\n    file = open(str(file_path), ""r"")\n    lines = file.readlines()\n\n    expected = ""Epoch [2/2]: [1/2]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88     , a=1 [00:00<00:00]\\n""\n    assert lines[-2] == expected\n\n\ndef test_pbar_log_message(capsys):\n    pbar = ProgressBar()\n\n    pbar.log_message(""test"")\n\n    captured = capsys.readouterr()\n    out = captured.out.split(""\\r"")\n    out = list(map(lambda x: x.strip(), out))\n    out = list(filter(None, out))\n    expected = ""test""\n    assert out[-1] == expected\n\n\ndef test_pbar_log_message_file(tmp_path):\n    file_path = tmp_path / ""temp.txt""\n    file = open(str(file_path), ""w+"")\n\n    pbar = ProgressBar(file=file)\n    pbar.log_message(""test"")\n\n    file.close()  # Force a flush of the buffer. file.flush() does not work.\n\n    file = open(str(file_path), ""r"")\n    lines = file.readlines()\n\n    expected = ""test\\n""\n    assert lines[0] == expected\n\n\ndef test_attach_fail_with_string():\n    engine = Engine(update_fn)\n    pbar = ProgressBar()\n\n    with pytest.raises(TypeError):\n        pbar.attach(engine, ""a"")\n\n\ndef test_pbar_batch_indeces(capsys):\n    engine = Engine(lambda e, b: time.sleep(0.1))\n\n    @engine.on(Events.ITERATION_STARTED)\n    def print_iter(_):\n        print(""iteration: "", engine.state.iteration)\n\n    ProgressBar(persist=True).attach(engine)\n    engine.run(list(range(4)), max_epochs=1)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    printed_batch_indeces = set(map(lambda x: int(x.split(""/"")[0][-1]), err))\n    expected_batch_indeces = list(range(1, 5))\n    assert sorted(list(printed_batch_indeces)) == expected_batch_indeces\n\n\ndef test_pbar_with_metric(capsys):\n\n    n_iters = 2\n    data = list(range(n_iters))\n    loss_values = iter(range(n_iters))\n\n    def step(engine, batch):\n        loss_value = next(loss_values)\n        return loss_value\n\n    trainer = Engine(step)\n\n    RunningAverage(alpha=0.5, output_transform=lambda x: x).attach(trainer, ""batchloss"")\n\n    pbar = ProgressBar()\n    pbar.attach(trainer, metric_names=[""batchloss"",])\n\n    trainer.run(data=data, max_epochs=1)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    actual = err[-1]\n    expected = ""Epoch: [1/2]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88     , batchloss=0.5 [00:00<00:00]""\n    assert actual == expected\n\n\ndef test_pbar_with_all_metric(capsys):\n\n    n_iters = 2\n    data = list(range(n_iters))\n    loss_values = iter(range(n_iters))\n    another_loss_values = iter(range(1, n_iters + 1))\n\n    def step(engine, batch):\n        loss_value = next(loss_values)\n        another_loss_value = next(another_loss_values)\n        return loss_value, another_loss_value\n\n    trainer = Engine(step)\n\n    RunningAverage(alpha=0.5, output_transform=lambda x: x[0]).attach(trainer, ""batchloss"")\n    RunningAverage(alpha=0.5, output_transform=lambda x: x[1]).attach(trainer, ""another batchloss"")\n\n    pbar = ProgressBar()\n    pbar.attach(trainer, metric_names=""all"")\n\n    trainer.run(data=data, max_epochs=1)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    actual = err[-1]\n    expected = ""Epoch: [1/2]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88     , another batchloss=1.5, batchloss=0.5 [00:00<00:00]""\n    assert actual == expected\n\n\ndef test_pbar_no_metric_names(capsys):\n\n    n_epochs = 2\n    loader = [1, 2]\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar()\n    pbar.attach(engine)\n\n    engine.run(loader, max_epochs=n_epochs)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    actual = err[-1]\n    expected = ""Epoch [2/2]: [1/2]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88      [00:00<00:00]""\n    assert actual == expected\n\n\ndef test_pbar_with_output(capsys):\n    n_epochs = 2\n    loader = [1, 2]\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar()\n    pbar.attach(engine, output_transform=lambda x: {""a"": x})\n\n    engine.run(loader, max_epochs=n_epochs)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    expected = ""Epoch [2/2]: [1/2]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88     , a=1 [00:00<00:00]""\n    assert err[-1] == expected\n\n\ndef test_pbar_fail_with_non_callable_transform():\n    engine = Engine(update_fn)\n    pbar = ProgressBar()\n\n    with pytest.raises(TypeError):\n        pbar.attach(engine, output_transform=1)\n\n\ndef test_pbar_with_scalar_output(capsys):\n    n_epochs = 2\n    loader = [1, 2]\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar()\n    pbar.attach(engine, output_transform=lambda x: x)\n\n    engine.run(loader, max_epochs=n_epochs)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    expected = ""Epoch [2/2]: [1/2]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88     , output=1 [00:00<00:00]""\n    assert err[-1] == expected\n\n\ndef test_pbar_with_str_output(capsys):\n    n_epochs = 2\n    loader = [1, 2]\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar()\n    pbar.attach(engine, output_transform=lambda x: ""red"")\n\n    engine.run(loader, max_epochs=n_epochs)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    expected = ""Epoch [2/2]: [1/2]  50%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88     , output=red [00:00<00:00]""\n    assert err[-1] == expected\n\n\ndef test_pbar_with_tqdm_kwargs(capsys):\n    n_epochs = 10\n    loader = [1, 2, 3, 4, 5]\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar(desc=""My description: "")\n    pbar.attach(engine, output_transform=lambda x: x)\n    engine.run(loader, max_epochs=n_epochs)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    expected = ""My description:  [10/10]: [4/5]  80%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88  , output=1 [00:00<00:00]""\n    assert err[-1] == expected\n\n\ndef test_pbar_for_validation(capsys):\n    loader = [1, 2, 3, 4, 5]\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar(desc=""Validation"")\n    pbar.attach(engine)\n    engine.run(loader, max_epochs=1)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    expected = ""Validation: [4/5]  80%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88   [00:00<00:00]""\n    assert err[-1] == expected\n\n\ndef test_pbar_output_tensor(capsys):\n    def _test(out_tensor, out_msg):\n        loader = [1, 2, 3, 4, 5]\n\n        def update_fn(engine, batch):\n            return out_tensor\n\n        engine = Engine(update_fn)\n\n        pbar = ProgressBar(desc=""Output tensor"")\n        pbar.attach(engine, output_transform=lambda x: x)\n        engine.run(loader, max_epochs=1)\n\n        captured = capsys.readouterr()\n        err = captured.err.split(""\\r"")\n        err = list(map(lambda x: x.strip(), err))\n        err = list(filter(None, err))\n        expected = ""Output tensor: [4/5]  80%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88  , {} [00:00<00:00]"".format(out_msg)\n        assert err[-1] == expected\n\n    _test(out_tensor=torch.tensor([5, 0]), out_msg=""output_0=5, output_1=0"")\n    _test(out_tensor=torch.tensor(123), out_msg=""output=123"")\n    _test(out_tensor=torch.tensor(1.234), out_msg=""output=1.23"")\n\n\ndef test_pbar_output_warning(capsys):\n    loader = [1, 2, 3, 4, 5]\n\n    def update_fn(engine, batch):\n        return torch.zeros(1, 2, 3, 4)\n\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar(desc=""Output tensor"")\n    pbar.attach(engine, output_transform=lambda x: x)\n    with pytest.warns(UserWarning):\n        engine.run(loader, max_epochs=1)\n\n\ndef test_pbar_on_epochs(capsys):\n\n    n_epochs = 10\n    loader = [1, 2, 3, 4, 5]\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar()\n    pbar.attach(engine, event_name=Events.EPOCH_STARTED, closing_event_name=Events.COMPLETED)\n    engine.run(loader, max_epochs=n_epochs)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    actual = err[-1]\n    expected = ""Epoch: [9/10]  90%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88  [00:00<00:00]""\n    assert actual == expected\n\n\ndef test_pbar_wrong_events_order():\n\n    engine = Engine(update_fn)\n    pbar = ProgressBar()\n\n    with pytest.raises(ValueError, match=""should be called before closing event""):\n        pbar.attach(engine, event_name=Events.COMPLETED, closing_event_name=Events.COMPLETED)\n\n    with pytest.raises(ValueError, match=""should be called before closing event""):\n        pbar.attach(engine, event_name=Events.COMPLETED, closing_event_name=Events.EPOCH_COMPLETED)\n\n    with pytest.raises(ValueError, match=""should be called before closing event""):\n        pbar.attach(engine, event_name=Events.COMPLETED, closing_event_name=Events.ITERATION_COMPLETED)\n\n    with pytest.raises(ValueError, match=""should be called before closing event""):\n        pbar.attach(engine, event_name=Events.EPOCH_COMPLETED, closing_event_name=Events.EPOCH_COMPLETED)\n\n    with pytest.raises(ValueError, match=""should be called before closing event""):\n        pbar.attach(engine, event_name=Events.ITERATION_COMPLETED, closing_event_name=Events.ITERATION_STARTED)\n\n    with pytest.raises(ValueError, match=""should not be a filtered event""):\n        pbar.attach(engine, event_name=Events.ITERATION_STARTED, closing_event_name=Events.EPOCH_COMPLETED(every=10))\n\n\ndef test_pbar_on_custom_events(capsys):\n\n    engine = Engine(update_fn)\n    pbar = ProgressBar()\n    with pytest.warns(DeprecationWarning, match=""CustomPeriodicEvent is deprecated""):\n        cpe = CustomPeriodicEvent(n_iterations=15)\n\n    with pytest.raises(ValueError, match=r""not in allowed events for this engine""):\n        pbar.attach(engine, event_name=cpe.Events.ITERATIONS_15_COMPLETED, closing_event_name=Events.EPOCH_COMPLETED)\n\n\ndef test_pbar_with_nan_input():\n    def update(engine, batch):\n        x = batch\n        return x.item()\n\n    def create_engine():\n        engine = Engine(update)\n        pbar = ProgressBar()\n\n        engine.add_event_handler(Events.ITERATION_COMPLETED, TerminateOnNan())\n        pbar.attach(engine, event_name=Events.EPOCH_COMPLETED, closing_event_name=Events.COMPLETED)\n        return engine\n\n    data = torch.from_numpy(np.array([np.nan] * 25))\n    engine = create_engine()\n    engine.run(data)\n    assert engine.should_terminate\n    assert engine.state.iteration == 1\n    assert engine.state.epoch == 1\n\n    data = torch.from_numpy(np.array([1] * 1000 + [np.nan] * 25))\n    engine = create_engine()\n    engine.run(data)\n    assert engine.should_terminate\n    assert engine.state.iteration == 1001\n    assert engine.state.epoch == 1\n\n\ndef test_pbar_on_callable_events(capsys):\n\n    n_epochs = 1\n    loader = list(range(100))\n    engine = Engine(update_fn)\n\n    pbar = ProgressBar()\n    pbar.attach(engine, event_name=Events.ITERATION_STARTED(every=10), closing_event_name=Events.EPOCH_COMPLETED)\n    engine.run(loader, max_epochs=n_epochs)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    actual = err[-1]\n    expected = ""Epoch: [90/100]  90%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88  [00:00<00:00]""\n    assert actual == expected\n\n\ndef test_tqdm_logger_epoch_length(capsys):\n    loader = list(range(100))\n    engine = Engine(update_fn)\n    pbar = ProgressBar(persist=True)\n    pbar.attach(engine)\n    engine.run(loader, epoch_length=50)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    actual = err[-1]\n    expected = ""Epoch: [50/50] 100%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88 [00:00<00:00]""\n    assert actual == expected\n\n\ndef test_tqdm_logger_iter_without_epoch_length(capsys):\n\n    size = 11\n\n    def finite_size_data_iter(size):\n        for i in range(size):\n            yield i\n\n    def train_step(trainer, batch):\n        pass\n\n    trainer = Engine(train_step)\n\n    @trainer.on(Events.ITERATION_COMPLETED(every=size))\n    def restart_iter():\n        trainer.state.dataloader = finite_size_data_iter(size)\n\n    pbar = ProgressBar(persist=True)\n    pbar.attach(trainer)\n\n    data_iter = finite_size_data_iter(size)\n    trainer.run(data_iter, max_epochs=5)\n\n    captured = capsys.readouterr()\n    err = captured.err.split(""\\r"")\n    err = list(map(lambda x: x.strip(), err))\n    err = list(filter(None, err))\n    actual = err[-1]\n    expected = ""Epoch [5/5]: [11/11] 100%|\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88\xe2\x96\x88 [00:00<00:00]""\n    assert actual == expected\n'"
tests/ignite/contrib/handlers/test_trains_logger.py,22,"b'import math\nimport os\nfrom unittest.mock import ANY, MagicMock, Mock, call\n\nimport pytest\nimport torch\nimport trains\n\nimport ignite.distributed as idist\nfrom ignite.contrib.handlers.trains_logger import *\nfrom ignite.engine import Engine, Events, State\nfrom ignite.handlers import Checkpoint\n\n\ndef test_optimizer_params_handler_wrong_setup():\n\n    with pytest.raises(TypeError):\n        OptimizerParamsHandler(optimizer=None)\n\n    optimizer = MagicMock(spec=torch.optim.Optimizer)\n    handler = OptimizerParamsHandler(optimizer=optimizer)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OptimizerParamsHandler works only with TrainsLogger""):\n        handler(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_optimizer_params():\n\n    optimizer = torch.optim.SGD([torch.Tensor(0)], lr=0.01)\n    wrapper = OptimizerParamsHandler(optimizer=optimizer, param_name=""lr"")\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.trains_logger.report_scalar.assert_called_once_with(iteration=123, series=""0"", title=""lr"", value=0.01)\n\n    wrapper = OptimizerParamsHandler(optimizer, param_name=""lr"", tag=""generator"")\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.trains_logger.report_scalar.assert_called_once_with(\n        iteration=123, series=""0"", title=""generator/lr"", value=0.01\n    )\n\n\ndef test_output_handler_with_wrong_logger_type():\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OutputHandler works only with TrainsLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_output_handler_output_transform(dirname):\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.output = 12345\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    mock_logger.trains_logger.report_scalar.assert_called_once_with(\n        iteration=123, series=""output"", title=""tag"", value=12345\n    )\n\n    wrapper = OutputHandler(""another_tag"", output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.trains_logger.report_scalar.assert_called_once_with(\n        iteration=123, series=""loss"", title=""another_tag"", value=12345\n    )\n\n\ndef test_output_handler_metric_names(dirname):\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""])\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.trains_logger.report_scalar.call_count == 2\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [\n            call(title=""tag"", series=""a"", iteration=5, value=12.23),\n            call(title=""tag"", series=""b"", iteration=5, value=23.45),\n        ],\n        any_order=True,\n    )\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""c""])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 55.56, ""c"": ""Some text""})\n    mock_engine.state.iteration = 7\n\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    with pytest.warns(UserWarning):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.trains_logger.report_scalar.call_count == 1\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [call(title=""tag"", series=""a"", iteration=7, value=55.56)], any_order=True\n    )\n\n    # all metrics\n    wrapper = OutputHandler(""tag"", metric_names=""all"")\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert mock_logger.trains_logger.report_scalar.call_count == 2\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [\n            call(title=""tag"", series=""a"", iteration=5, value=12.23),\n            call(title=""tag"", series=""b"", iteration=5, value=23.45),\n        ],\n        any_order=True,\n    )\n\n\ndef test_output_handler_both(dirname):\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.trains_logger.report_scalar.call_count == 3\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [\n            call(title=""tag"", series=""a"", iteration=5, value=12.23),\n            call(title=""tag"", series=""b"", iteration=5, value=23.45),\n            call(title=""tag"", series=""loss"", iteration=5, value=12345),\n        ],\n        any_order=True,\n    )\n\n\ndef test_output_handler_with_wrong_global_step_transform_output():\n    def global_step_transform(*args, **kwargs):\n        return ""a""\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    with pytest.raises(TypeError, match=""global_step must be int""):\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n\ndef test_output_handler_with_global_step_from_engine():\n\n    mock_another_engine = MagicMock()\n    mock_another_engine.state = State()\n    mock_another_engine.state.epoch = 10\n    mock_another_engine.state.output = 12.345\n\n    wrapper = OutputHandler(\n        ""tag"",\n        output_transform=lambda x: {""loss"": x},\n        global_step_transform=global_step_from_engine(mock_another_engine),\n    )\n\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 1\n    mock_engine.state.output = 0.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.trains_logger.report_scalar.call_count == 1\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [call(title=""tag"", series=""loss"", iteration=mock_another_engine.state.epoch, value=mock_engine.state.output)]\n    )\n\n    mock_another_engine.state.epoch = 11\n    mock_engine.state.output = 1.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.trains_logger.report_scalar.call_count == 2\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [call(title=""tag"", series=""loss"", iteration=mock_another_engine.state.epoch, value=mock_engine.state.output)]\n    )\n\n\ndef test_output_handler_with_global_step_transform():\n    def global_step_transform(*args, **kwargs):\n        return 10\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.trains_logger.report_scalar.call_count == 1\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [call(title=""tag"", series=""loss"", iteration=10, value=12345)]\n    )\n\n\ndef test_weights_scalar_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        WeightsScalarHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    with pytest.raises(TypeError, match=""Argument reduction should be callable""):\n        WeightsScalarHandler(model, reduction=123)\n\n    with pytest.raises(ValueError, match=""Output of the reduction function should be a scalar""):\n        WeightsScalarHandler(model, reduction=lambda x: x)\n\n    wrapper = WeightsScalarHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler WeightsScalarHandler works only with TrainsLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_weights_scalar_handler(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = WeightsScalarHandler(model, tag=tag)\n        mock_logger = MagicMock(spec=TrainsLogger)\n        mock_logger.trains_logger = MagicMock()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.trains_logger.report_scalar.call_count == 4\n        mock_logger.trains_logger.report_scalar.assert_has_calls(\n            [\n                call(title=tag_prefix + ""weights_norm/fc1"", series=""weight"", iteration=5, value=0.0),\n                call(title=tag_prefix + ""weights_norm/fc1"", series=""bias"", iteration=5, value=0.0),\n                call(title=tag_prefix + ""weights_norm/fc2"", series=""weight"", iteration=5, value=12.0),\n                call(title=tag_prefix + ""weights_norm/fc2"", series=""bias"", iteration=5, value=math.sqrt(12.0)),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_weights_scalar_handler_frozen_layers(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = WeightsScalarHandler(model)\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [\n            call(title=""weights_norm/fc2"", series=""weight"", iteration=5, value=12.0),\n            call(title=""weights_norm/fc2"", series=""bias"", iteration=5, value=math.sqrt(12.0)),\n        ],\n        any_order=True,\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.trains_logger.report_scalar.assert_has_calls(\n            [\n                call(title=""weights_norm/fc1"", series=""weight"", iteration=5, value=12.0),\n                call(title=""weights_norm/fc1"", series=""bias"", iteration=5, value=math.sqrt(12.0)),\n            ],\n            any_order=True,\n        )\n\n    assert mock_logger.trains_logger.report_scalar.call_count == 2\n\n\ndef test_weights_hist_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        WeightsHistHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    wrapper = WeightsHistHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'WeightsHistHandler\' works only with TrainsLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_weights_hist_handler(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = WeightsHistHandler(model, tag=tag)\n        mock_logger = MagicMock(spec=TrainsLogger)\n        mock_logger.grad_helper = MagicMock()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.grad_helper.add_histogram.call_count == 4\n        mock_logger.grad_helper.add_histogram.assert_has_calls(\n            [\n                call(title=tag_prefix + ""weights_fc1"", hist_data=ANY, series=""weight"", step=5),\n                call(title=tag_prefix + ""weights_fc1"", hist_data=ANY, series=""bias"", step=5),\n                call(title=tag_prefix + ""weights_fc2"", hist_data=ANY, series=""weight"", step=5),\n                call(title=tag_prefix + ""weights_fc2"", hist_data=ANY, series=""bias"", step=5),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_weights_hist_handler_frozen_layers(dummy_model_factory):\n\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = WeightsHistHandler(model)\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.grad_helper = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.grad_helper.add_histogram.assert_has_calls(\n        [\n            call(title=""weights_fc2"", hist_data=ANY, series=""weight"", step=5),\n            call(title=""weights_fc2"", hist_data=ANY, series=""bias"", step=5),\n        ],\n        any_order=True,\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.grad_helper.add_histogram.assert_has_calls(\n            [\n                call(title=""weights_fc1"", hist_data=ANY, series=""weight"", step=5),\n                call(title=""weights_fc1"", hist_data=ANY, series=""bias"", step=5),\n            ],\n            any_order=True,\n        )\n    assert mock_logger.grad_helper.add_histogram.call_count == 2\n\n\ndef test_grads_scalar_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        GradsScalarHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    with pytest.raises(TypeError, match=""Argument reduction should be callable""):\n        GradsScalarHandler(model, reduction=123)\n\n    wrapper = GradsScalarHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler GradsScalarHandler works only with TrainsLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_grads_scalar_handler(dummy_model_factory, norm_mock):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = GradsScalarHandler(model, reduction=norm_mock, tag=tag)\n        mock_logger = MagicMock(spec=TrainsLogger)\n        mock_logger.trains_logger = MagicMock()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n        norm_mock.reset_mock()\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        mock_logger.trains_logger.report_scalar.assert_has_calls(\n            [\n                call(\n                    title=tag_prefix + ""grads_norm/fc1"", value=ANY, series=""weight"", iteration=mock_engine.state.epoch\n                ),\n                call(title=tag_prefix + ""grads_norm/fc1"", value=ANY, series=""bias"", iteration=mock_engine.state.epoch),\n                call(\n                    title=tag_prefix + ""grads_norm/fc2"", value=ANY, series=""weight"", iteration=mock_engine.state.epoch\n                ),\n                call(title=tag_prefix + ""grads_norm/fc2"", value=ANY, series=""bias"", iteration=mock_engine.state.epoch),\n            ],\n            any_order=True,\n        )\n        assert mock_logger.trains_logger.report_scalar.call_count == 4\n        assert norm_mock.call_count == 4\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_grads_scalar_handler_frozen_layers(dummy_model_factory, norm_mock):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = GradsScalarHandler(model, reduction=norm_mock)\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.trains_logger = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    norm_mock.reset_mock()\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.trains_logger.report_scalar.assert_has_calls(\n        [\n            call(title=""grads_norm/fc2"", value=ANY, series=""weight"", iteration=mock_engine.state.epoch),\n            call(title=""grads_norm/fc2"", value=ANY, series=""bias"", iteration=mock_engine.state.epoch),\n        ],\n        any_order=True,\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.trains_logger.report_scalar.assert_has_calls(\n            [call(title=""grads_norm/fc1"", value=ANY, iteration=5), call(""grads_norm/fc1"", ANY, 5)], any_order=True\n        )\n    assert mock_logger.trains_logger.report_scalar.call_count == 2\n    assert norm_mock.call_count == 2\n\n\ndef test_grads_hist_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        GradsHistHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    wrapper = GradsHistHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'GradsHistHandler\' works only with TrainsLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_grads_hist_handler(dummy_model_factory):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=False)\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = GradsHistHandler(model, tag=tag)\n        mock_logger = MagicMock(spec=TrainsLogger)\n        mock_logger.grad_helper = MagicMock()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.grad_helper.add_histogram.call_count == 4\n        mock_logger.grad_helper.add_histogram.assert_has_calls(\n            [\n                call(title=tag_prefix + ""grads_fc1"", hist_data=ANY, series=""weight"", step=5),\n                call(title=tag_prefix + ""grads_fc1"", hist_data=ANY, series=""bias"", step=5),\n                call(title=tag_prefix + ""grads_fc2"", hist_data=ANY, series=""weight"", step=5),\n                call(title=tag_prefix + ""grads_fc2"", hist_data=ANY, series=""bias"", step=5),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_grads_hist_frozen_layers(dummy_model_factory):\n    model = dummy_model_factory(with_grads=True, with_frozen_layer=True)\n\n    wrapper = GradsHistHandler(model)\n    mock_logger = MagicMock(spec=TrainsLogger)\n    mock_logger.grad_helper = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.grad_helper.add_histogram.call_count == 2\n    mock_logger.grad_helper.add_histogram.assert_has_calls(\n        [\n            call(title=""grads_fc2"", hist_data=ANY, series=""weight"", step=5),\n            call(title=""grads_fc2"", hist_data=ANY, series=""bias"", step=5),\n        ],\n        any_order=True,\n    )\n\n    with pytest.raises(AssertionError):\n        mock_logger.grad_helper.add_histogram.assert_has_calls(\n            [\n                call(title=""grads_fc1"", hist_data=ANY, series=""weight"", step=5),\n                call(title=""grads_fc1"", hist_data=ANY, series=""bias"", step=5),\n            ],\n            any_order=True,\n        )\n\n\ndef test_integration(dirname):\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    trainer = Engine(update_fn)\n\n    with pytest.warns(UserWarning, match=""TrainsSaver: running in bypass mode""):\n        TrainsLogger.set_bypass_mode(True)\n        logger = TrainsLogger(output_uri=dirname)\n\n        def dummy_handler(engine, logger, event_name):\n            global_step = engine.state.get_event_attrib_value(event_name)\n            logger.trains_logger.report_scalar(title="""", series="""", value=""test_value"", iteration=global_step)\n\n        logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n        trainer.run(data, max_epochs=n_epochs)\n        logger.close()\n\n\ndef test_integration_as_context_manager(dirname):\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    with pytest.warns(UserWarning, match=""TrainsSaver: running in bypass mode""):\n        TrainsLogger.set_bypass_mode(True)\n        with TrainsLogger(output_uri=dirname) as trains_logger:\n\n            trainer = Engine(update_fn)\n\n            def dummy_handler(engine, logger, event_name):\n                global_step = engine.state.get_event_attrib_value(event_name)\n                logger.trains_logger.report_scalar(title="""", series="""", value=""test_value"", iteration=global_step)\n\n            trains_logger.attach(trainer, log_handler=dummy_handler, event_name=Events.EPOCH_COMPLETED)\n\n            trainer.run(data, max_epochs=n_epochs)\n\n\ndef test_trains_disk_saver_integration():\n    model = torch.nn.Module()\n    to_save_serializable = {""model"": model}\n    with pytest.warns(UserWarning, match=""TrainsSaver created a temporary checkpoints directory""):\n        mock_logger = MagicMock(spec=TrainsLogger)\n        trains.Task.current_task = Mock(return_value=object())\n        trains_saver = TrainsSaver(mock_logger)\n        trains.binding.frameworks.WeightsFileHandler.create_output_model = MagicMock()\n\n    checkpoint = Checkpoint(to_save=to_save_serializable, save_handler=trains_saver, n_saved=1)\n\n    trainer = Engine(lambda e, b: None)\n    trainer.state = State(epoch=0, iteration=0)\n    checkpoint(trainer)\n    trainer.state.iteration = 1\n    checkpoint(trainer)\n    if trains_saver._atomic:\n        assert trains.binding.frameworks.WeightsFileHandler.create_output_model.call_count == 2\n    else:\n        saved_files = list(os.listdir(trains_saver.dirname))\n        assert len(saved_files) == 1\n        assert saved_files[0] == ""model_1.pt""\n\n\ndef test_trains_disk_saver_integration_no_logger():\n    model = torch.nn.Module()\n    to_save_serializable = {""model"": model}\n\n    with pytest.warns(UserWarning, match=""TrainsSaver created a temporary checkpoints directory""):\n        trains.Task.current_task = Mock(return_value=object())\n        trains.binding.frameworks.WeightsFileHandler.create_output_model = MagicMock()\n        trains_saver = TrainsSaver()\n        checkpoint = Checkpoint(to_save=to_save_serializable, save_handler=trains_saver, n_saved=1)\n\n    trainer = Engine(lambda e, b: None)\n    trainer.state = State(epoch=0, iteration=0)\n    checkpoint(trainer)\n    trainer.state.iteration = 1\n    checkpoint(trainer)\n\n    if trains_saver._atomic:\n        assert trains.binding.frameworks.WeightsFileHandler.create_output_model.call_count == 2\n    else:\n        saved_files = list(os.listdir(trains_saver.dirname))\n        assert len(saved_files) == 1\n        assert saved_files[0] == ""model_1.pt""\n\n\nclass DummyModel(torch.nn.Module):\n    def __init__(self):\n        super(DummyModel, self).__init__()\n        self.net = torch.nn.Linear(2, 2)\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef _test_save_model_optimizer_lr_scheduler_with_state_dict(device, on_zero_rank=False):\n\n    if idist.get_rank() == 0:\n        trains.Task.current_task = Mock(return_value=object())\n        trains.binding.frameworks.WeightsFileHandler.create_output_model = MagicMock()\n\n    torch.manual_seed(23)\n\n    model = DummyModel().to(device)\n\n    optim = torch.optim.SGD(model.parameters(), lr=0.1)\n    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.5)\n\n    def update_fn(engine, batch):\n        x = torch.rand((4, 2)).to(device)\n        optim.zero_grad()\n        y = model(x)\n        loss = y.pow(2.0).sum()\n        loss.backward()\n        if idist.has_xla_support:\n            import torch_xla.core.xla_model as xm\n\n            xm.optimizer_step(optim, barrier=True)\n        else:\n            optim.step()\n        lr_scheduler.step()\n\n    engine = Engine(update_fn)\n\n    to_save = {""model"": model, ""optimizer"": optim, ""lr_scheduler"": lr_scheduler}\n\n    with pytest.warns(UserWarning, match=r""TrainsSaver created a temporary checkpoints directory""):\n        trains_saver = TrainsSaver()\n\n    if (not on_zero_rank) or (on_zero_rank and idist.get_rank() == 0):\n        checkpoint = Checkpoint(to_save=to_save, save_handler=trains_saver, n_saved=1)\n        engine.add_event_handler(Events.EPOCH_COMPLETED, checkpoint)\n\n    engine.run([0], max_epochs=4)\n\n    idist.barrier()\n\n    saved_objects = sorted(os.listdir(trains_saver.dirname))\n    # saved object is [\'PREFIX_checkpoint_3.pt\', ]\n    saved_checkpoint = os.path.join(trains_saver.dirname, saved_objects[0])\n\n    if idist.has_xla_support:\n        device = ""cpu""\n\n    loaded_obj = torch.load(saved_checkpoint, map_location=device)\n    for f in [""model"", ""optimizer"", ""lr_scheduler""]:\n        assert f in loaded_obj\n    loaded_model_state_dict = loaded_obj[""model""]\n    loaded_optimizer_state_dict = loaded_obj[""optimizer""]\n    loaded_lr_scheduler_state_dict = loaded_obj[""lr_scheduler""]\n\n    assert isinstance(loaded_model_state_dict, dict)\n    assert isinstance(loaded_optimizer_state_dict, dict)\n    assert isinstance(loaded_lr_scheduler_state_dict, dict)\n\n    # Specifically move device to CPU first\n    model_state_dict = model.cpu().state_dict()\n    for key in model_state_dict.keys():\n        assert key in loaded_model_state_dict\n        model_value = model_state_dict[key]\n        loaded_model_value = loaded_model_state_dict[key]\n        assert (model_value.cpu().numpy() == loaded_model_value.cpu().numpy()).all()\n\n    optim_state_dict = optim.state_dict()\n    for key in optim_state_dict.keys():\n        assert key in loaded_optimizer_state_dict\n        optim_value = optim_state_dict[key]\n        loaded_optim_value = loaded_optimizer_state_dict[key]\n        if idist.get_rank() == 0:\n            assert optim_value == loaded_optim_value\n\n    lr_scheduler_state_dict = lr_scheduler.state_dict()\n    for key in lr_scheduler_state_dict.keys():\n        assert key in loaded_lr_scheduler_state_dict\n        lr_scheduler_value = lr_scheduler_state_dict[key]\n        loaded_lr_scheduler_value = loaded_lr_scheduler_state_dict[key]\n        assert lr_scheduler_value == loaded_lr_scheduler_value\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\ndef test_distrib_cpu(distributed_context_single_node_gloo):\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(""cpu"")\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(""cpu"", on_zero_rank=True)\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(not idist.has_native_dist_support, reason=""Skip if no native dist support"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test_distrib_gpu(distributed_context_single_node_nccl):\n    device = idist.device()\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(device)\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(""cpu"", on_zero_rank=True)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Not on TPU device"")\ndef test_distrib_single_device_xla():\n    device = idist.device()\n    assert ""xla"" in device.type\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(device)\n\n\ndef _test_save_model_optimizer_lr_scheduler_with_state_dict_xla_nprocs(index):\n    device = idist.device()\n    _test_save_model_optimizer_lr_scheduler_with_state_dict(device)\n\n    import time\n\n    # hack to have all proc properly sync:\n    time.sleep(1)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not idist.has_xla_support, reason=""Not on TPU device"")\ndef test_distrib_single_device_xla_nprocs(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test_save_model_optimizer_lr_scheduler_with_state_dict_xla_nprocs, args=(), nprocs=n)\n'"
tests/ignite/contrib/handlers/test_visdom_logger.py,19,"b'import sys\nfrom unittest.mock import ANY, MagicMock, call\n\nimport pytest\nimport torch\n\nfrom ignite.contrib.handlers.visdom_logger import *\nfrom ignite.contrib.handlers.visdom_logger import _DummyExecutor\nfrom ignite.engine import Engine, Events, State\n\n\ndef test_optimizer_params_handler_wrong_setup():\n\n    with pytest.raises(TypeError):\n        OptimizerParamsHandler(optimizer=None)\n\n    optimizer = MagicMock(spec=torch.optim.Optimizer)\n    handler = OptimizerParamsHandler(optimizer=optimizer)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OptimizerParamsHandler works only with VisdomLogger""):\n        handler(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_optimizer_params():\n\n    optimizer = torch.optim.SGD([torch.Tensor(0)], lr=0.01)\n    wrapper = OptimizerParamsHandler(optimizer=optimizer, param_name=""lr"")\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    # mock_logger.vis.line.assert_called_once_with(""lr/group_0"", 0.01, 123)\n    assert len(wrapper.windows) == 1 and ""lr/group_0"" in wrapper.windows\n    assert wrapper.windows[""lr/group_0""][""win""] is not None\n\n    mock_logger.vis.line.assert_called_once_with(\n        X=[123,],\n        Y=[0.01,],\n        env=mock_logger.vis.env,\n        win=None,\n        update=None,\n        opts=wrapper.windows[""lr/group_0""][""opts""],\n        name=""lr/group_0"",\n    )\n\n    wrapper = OptimizerParamsHandler(optimizer=optimizer, param_name=""lr"", tag=""generator"")\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert len(wrapper.windows) == 1 and ""generator/lr/group_0"" in wrapper.windows\n    assert wrapper.windows[""generator/lr/group_0""][""win""] is not None\n\n    mock_logger.vis.line.assert_called_once_with(\n        X=[123,],\n        Y=[0.01,],\n        env=mock_logger.vis.env,\n        win=None,\n        update=None,\n        opts=wrapper.windows[""generator/lr/group_0""][""opts""],\n        name=""generator/lr/group_0"",\n    )\n\n\ndef test_output_handler_with_wrong_logger_type():\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'OutputHandler\' works only with VisdomLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_output_handler_output_transform(dirname):\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.output = 12345\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert len(wrapper.windows) == 1 and ""tag/output"" in wrapper.windows\n    assert wrapper.windows[""tag/output""][""win""] is not None\n\n    mock_logger.vis.line.assert_called_once_with(\n        X=[123,],\n        Y=[12345,],\n        env=mock_logger.vis.env,\n        win=None,\n        update=None,\n        opts=wrapper.windows[""tag/output""][""opts""],\n        name=""tag/output"",\n    )\n\n    wrapper = OutputHandler(""another_tag"", output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert len(wrapper.windows) == 1 and ""another_tag/loss"" in wrapper.windows\n    assert wrapper.windows[""another_tag/loss""][""win""] is not None\n\n    mock_logger.vis.line.assert_called_once_with(\n        X=[123,],\n        Y=[12345,],\n        env=mock_logger.vis.env,\n        win=None,\n        update=None,\n        opts=wrapper.windows[""another_tag/loss""][""opts""],\n        name=""another_tag/loss"",\n    )\n\n\ndef test_output_handler_metric_names(dirname):\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""])\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert len(wrapper.windows) == 2 and ""tag/a"" in wrapper.windows and ""tag/b"" in wrapper.windows\n    assert wrapper.windows[""tag/a""][""win""] is not None\n    assert wrapper.windows[""tag/b""][""win""] is not None\n\n    assert mock_logger.vis.line.call_count == 2\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[5,],\n                Y=[12.23,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/a""][""opts""],\n                name=""tag/a"",\n            ),\n            call(\n                X=[5,],\n                Y=[23.45,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/b""][""opts""],\n                name=""tag/b"",\n            ),\n        ],\n        any_order=True,\n    )\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"",])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": torch.Tensor([0.0, 1.0, 2.0, 3.0])})\n    mock_engine.state.iteration = 5\n\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert len(wrapper.windows) == 4 and all([""tag/a/{}"".format(i) in wrapper.windows for i in range(4)])\n    assert wrapper.windows[""tag/a/0""][""win""] is not None\n    assert wrapper.windows[""tag/a/1""][""win""] is not None\n    assert wrapper.windows[""tag/a/2""][""win""] is not None\n    assert wrapper.windows[""tag/a/3""][""win""] is not None\n\n    assert mock_logger.vis.line.call_count == 4\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[5,],\n                Y=[0.0,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/a/0""][""opts""],\n                name=""tag/a/0"",\n            ),\n            call(\n                X=[5,],\n                Y=[1.0,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/a/1""][""opts""],\n                name=""tag/a/1"",\n            ),\n            call(\n                X=[5,],\n                Y=[2.0,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/a/2""][""opts""],\n                name=""tag/a/2"",\n            ),\n            call(\n                X=[5,],\n                Y=[3.0,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/a/3""][""opts""],\n                name=""tag/a/3"",\n            ),\n        ],\n        any_order=True,\n    )\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""c""])\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 55.56, ""c"": ""Some text""})\n    mock_engine.state.iteration = 7\n\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    with pytest.warns(UserWarning):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert len(wrapper.windows) == 1 and ""tag/a"" in wrapper.windows\n    assert wrapper.windows[""tag/a""][""win""] is not None\n\n    assert mock_logger.vis.line.call_count == 1\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[7,],\n                Y=[55.56,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/a""][""opts""],\n                name=""tag/a"",\n            ),\n        ],\n        any_order=True,\n    )\n\n    # all metrics\n    wrapper = OutputHandler(""tag"", metric_names=""all"")\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    assert len(wrapper.windows) == 2 and ""tag/a"" in wrapper.windows and ""tag/b"" in wrapper.windows\n    assert wrapper.windows[""tag/a""][""win""] is not None\n    assert wrapper.windows[""tag/b""][""win""] is not None\n\n    assert mock_logger.vis.line.call_count == 2\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[5,],\n                Y=[12.23,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/a""][""opts""],\n                name=""tag/a"",\n            ),\n            call(\n                X=[5,],\n                Y=[23.45,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/b""][""opts""],\n                name=""tag/b"",\n            ),\n        ],\n        any_order=True,\n    )\n\n\ndef test_output_handler_both(dirname):\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.vis.line.call_count == 3\n    assert (\n        len(wrapper.windows) == 3\n        and ""tag/a"" in wrapper.windows\n        and ""tag/b"" in wrapper.windows\n        and ""tag/loss"" in wrapper.windows\n    )\n    assert wrapper.windows[""tag/a""][""win""] is not None\n    assert wrapper.windows[""tag/b""][""win""] is not None\n    assert wrapper.windows[""tag/loss""][""win""] is not None\n\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[5,],\n                Y=[12.23,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/a""][""opts""],\n                name=""tag/a"",\n            ),\n            call(\n                X=[5,],\n                Y=[23.45,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/b""][""opts""],\n                name=""tag/b"",\n            ),\n            call(\n                X=[5,],\n                Y=[12345,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/loss""][""opts""],\n                name=""tag/loss"",\n            ),\n        ],\n        any_order=True,\n    )\n\n    mock_engine.state.epoch = 6\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.vis.line.call_count == 6\n    assert (\n        len(wrapper.windows) == 3\n        and ""tag/a"" in wrapper.windows\n        and ""tag/b"" in wrapper.windows\n        and ""tag/loss"" in wrapper.windows\n    )\n    assert wrapper.windows[""tag/a""][""win""] is not None\n    assert wrapper.windows[""tag/b""][""win""] is not None\n    assert wrapper.windows[""tag/loss""][""win""] is not None\n\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[6,],\n                Y=[12.23,],\n                env=mock_logger.vis.env,\n                win=wrapper.windows[""tag/a""][""win""],\n                update=""append"",\n                opts=wrapper.windows[""tag/a""][""opts""],\n                name=""tag/a"",\n            ),\n            call(\n                X=[6,],\n                Y=[23.45,],\n                env=mock_logger.vis.env,\n                win=wrapper.windows[""tag/b""][""win""],\n                update=""append"",\n                opts=wrapper.windows[""tag/b""][""opts""],\n                name=""tag/b"",\n            ),\n            call(\n                X=[6,],\n                Y=[12345,],\n                env=mock_logger.vis.env,\n                win=wrapper.windows[""tag/loss""][""win""],\n                update=""append"",\n                opts=wrapper.windows[""tag/loss""][""opts""],\n                name=""tag/loss"",\n            ),\n        ],\n        any_order=True,\n    )\n\n\ndef test_output_handler_with_wrong_global_step_transform_output():\n    def global_step_transform(*args, **kwargs):\n        return ""a""\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    with pytest.raises(TypeError, match=""global_step must be int""):\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n\ndef test_output_handler_with_global_step_transform():\n    def global_step_transform(*args, **kwargs):\n        return 10\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.vis.line.call_count == 1\n    assert len(wrapper.windows) == 1 and ""tag/loss"" in wrapper.windows\n    assert wrapper.windows[""tag/loss""][""win""] is not None\n\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[10,],\n                Y=[12345,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/loss""][""opts""],\n                name=""tag/loss"",\n            )\n        ]\n    )\n\n\ndef test_output_handler_with_global_step_from_engine():\n\n    mock_another_engine = MagicMock()\n    mock_another_engine.state = State()\n    mock_another_engine.state.epoch = 10\n    mock_another_engine.state.output = 12.345\n\n    wrapper = OutputHandler(\n        ""tag"",\n        output_transform=lambda x: {""loss"": x},\n        global_step_transform=global_step_from_engine(mock_another_engine),\n    )\n\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 1\n    mock_engine.state.output = 0.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.vis.line.call_count == 1\n    assert len(wrapper.windows) == 1 and ""tag/loss"" in wrapper.windows\n    assert wrapper.windows[""tag/loss""][""win""] is not None\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[mock_another_engine.state.epoch,],\n                Y=[mock_engine.state.output,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""tag/loss""][""opts""],\n                name=""tag/loss"",\n            )\n        ]\n    )\n\n    mock_another_engine.state.epoch = 11\n    mock_engine.state.output = 1.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.vis.line.call_count == 2\n    assert len(wrapper.windows) == 1 and ""tag/loss"" in wrapper.windows\n    assert wrapper.windows[""tag/loss""][""win""] is not None\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[mock_another_engine.state.epoch,],\n                Y=[mock_engine.state.output,],\n                env=mock_logger.vis.env,\n                win=wrapper.windows[""tag/loss""][""win""],\n                update=""append"",\n                opts=wrapper.windows[""tag/loss""][""opts""],\n                name=""tag/loss"",\n            )\n        ]\n    )\n\n\ndef test_weights_scalar_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        WeightsScalarHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    with pytest.raises(TypeError, match=""Argument reduction should be callable""):\n        WeightsScalarHandler(model, reduction=123)\n\n    with pytest.raises(ValueError, match=""Output of the reduction function should be a scalar""):\n        WeightsScalarHandler(model, reduction=lambda x: x)\n\n    wrapper = WeightsScalarHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'WeightsScalarHandler\' works only with VisdomLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_weights_scalar_handler():\n    class DummyModel(torch.nn.Module):\n        def __init__(self):\n            super(DummyModel, self).__init__()\n            self.fc1 = torch.nn.Linear(10, 10)\n            self.fc2 = torch.nn.Linear(12, 12)\n            self.fc1.weight.data.zero_()\n            self.fc1.bias.data.zero_()\n            self.fc2.weight.data.fill_(1.0)\n            self.fc2.bias.data.fill_(1.0)\n\n    model = DummyModel()\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = WeightsScalarHandler(model, tag=tag)\n        mock_logger = MagicMock(spec=VisdomLogger)\n        mock_logger.vis = MagicMock()\n        mock_logger.executor = _DummyExecutor()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.vis.line.call_count == 4\n        mock_logger.vis.line.assert_has_calls(\n            [\n                call(\n                    X=[5,],\n                    Y=[0.0,],\n                    env=mock_logger.vis.env,\n                    win=None,\n                    update=None,\n                    opts=wrapper.windows[tag_prefix + ""weights_norm/fc1/weight""][""opts""],\n                    name=tag_prefix + ""weights_norm/fc1/weight"",\n                ),\n                call(\n                    X=[5,],\n                    Y=[0.0,],\n                    env=mock_logger.vis.env,\n                    win=None,\n                    update=None,\n                    opts=wrapper.windows[tag_prefix + ""weights_norm/fc1/bias""][""opts""],\n                    name=tag_prefix + ""weights_norm/fc1/bias"",\n                ),\n                call(\n                    X=[5,],\n                    Y=[12.0,],\n                    env=mock_logger.vis.env,\n                    win=None,\n                    update=None,\n                    opts=wrapper.windows[tag_prefix + ""weights_norm/fc2/weight""][""opts""],\n                    name=tag_prefix + ""weights_norm/fc2/weight"",\n                ),\n                call(\n                    X=[5,],\n                    Y=ANY,\n                    env=mock_logger.vis.env,\n                    win=None,\n                    update=None,\n                    opts=wrapper.windows[tag_prefix + ""weights_norm/fc2/bias""][""opts""],\n                    name=tag_prefix + ""weights_norm/fc2/bias"",\n                ),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\ndef test_weights_scalar_handler_custom_reduction():\n    class DummyModel(torch.nn.Module):\n        def __init__(self):\n            super(DummyModel, self).__init__()\n            self.fc1 = torch.nn.Linear(10, 10)\n            self.fc2 = torch.nn.Linear(12, 12)\n            self.fc1.weight.data.zero_()\n            self.fc1.bias.data.zero_()\n            self.fc2.weight.data.fill_(1.0)\n            self.fc2.bias.data.fill_(1.0)\n\n    model = DummyModel()\n\n    def norm(x):\n        return 12.34\n\n    wrapper = WeightsScalarHandler(model, reduction=norm, show_legend=True)\n    mock_logger = MagicMock(spec=VisdomLogger)\n    mock_logger.vis = MagicMock()\n    mock_logger.executor = _DummyExecutor()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    assert mock_logger.vis.line.call_count == 4\n    mock_logger.vis.line.assert_has_calls(\n        [\n            call(\n                X=[5,],\n                Y=[12.34,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""weights_norm/fc1/weight""][""opts""],\n                name=""weights_norm/fc1/weight"",\n            ),\n            call(\n                X=[5,],\n                Y=[12.34,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""weights_norm/fc1/bias""][""opts""],\n                name=""weights_norm/fc1/bias"",\n            ),\n            call(\n                X=[5,],\n                Y=[12.34,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""weights_norm/fc2/weight""][""opts""],\n                name=""weights_norm/fc2/weight"",\n            ),\n            call(\n                X=[5,],\n                Y=[12.34,],\n                env=mock_logger.vis.env,\n                win=None,\n                update=None,\n                opts=wrapper.windows[""weights_norm/fc2/bias""][""opts""],\n                name=""weights_norm/fc2/bias"",\n            ),\n        ],\n        any_order=True,\n    )\n\n\ndef test_grads_scalar_handler_wrong_setup():\n\n    with pytest.raises(TypeError, match=""Argument model should be of type torch.nn.Module""):\n        GradsScalarHandler(None)\n\n    model = MagicMock(spec=torch.nn.Module)\n    with pytest.raises(TypeError, match=""Argument reduction should be callable""):\n        GradsScalarHandler(model, reduction=123)\n\n    wrapper = GradsScalarHandler(model)\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'GradsScalarHandler\' works only with VisdomLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_grads_scalar_handler():\n    class DummyModel(torch.nn.Module):\n        def __init__(self):\n            super(DummyModel, self).__init__()\n            self.fc1 = torch.nn.Linear(10, 10)\n            self.fc2 = torch.nn.Linear(12, 12)\n            self.fc1.weight.data.zero_()\n            self.fc1.bias.data.zero_()\n            self.fc2.weight.data.fill_(1.0)\n            self.fc2.bias.data.fill_(1.0)\n\n    model = DummyModel()\n\n    def norm(x):\n        return 0.0\n\n    # define test wrapper to test with and without optional tag\n    def _test(tag=None):\n        wrapper = GradsScalarHandler(model, reduction=norm, tag=tag)\n        mock_logger = MagicMock(spec=VisdomLogger)\n        mock_logger.vis = MagicMock()\n        mock_logger.executor = _DummyExecutor()\n\n        mock_engine = MagicMock()\n        mock_engine.state = State()\n        mock_engine.state.epoch = 5\n\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n        tag_prefix = ""{}/"".format(tag) if tag else """"\n\n        assert mock_logger.vis.line.call_count == 4\n        mock_logger.vis.line.assert_has_calls(\n            [\n                call(\n                    X=[5,],\n                    Y=ANY,\n                    env=mock_logger.vis.env,\n                    win=None,\n                    update=None,\n                    opts=wrapper.windows[tag_prefix + ""grads_norm/fc1/weight""][""opts""],\n                    name=tag_prefix + ""grads_norm/fc1/weight"",\n                ),\n                call(\n                    X=[5,],\n                    Y=ANY,\n                    env=mock_logger.vis.env,\n                    win=None,\n                    update=None,\n                    opts=wrapper.windows[tag_prefix + ""grads_norm/fc1/bias""][""opts""],\n                    name=tag_prefix + ""grads_norm/fc1/bias"",\n                ),\n                call(\n                    X=[5,],\n                    Y=ANY,\n                    env=mock_logger.vis.env,\n                    win=None,\n                    update=None,\n                    opts=wrapper.windows[tag_prefix + ""grads_norm/fc2/weight""][""opts""],\n                    name=tag_prefix + ""grads_norm/fc2/weight"",\n                ),\n                call(\n                    X=[5,],\n                    Y=ANY,\n                    env=mock_logger.vis.env,\n                    win=None,\n                    update=None,\n                    opts=wrapper.windows[tag_prefix + ""grads_norm/fc2/bias""][""opts""],\n                    name=tag_prefix + ""grads_norm/fc2/bias"",\n                ),\n            ],\n            any_order=True,\n        )\n\n    _test()\n    _test(tag=""tag"")\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_integration_no_server():\n\n    with pytest.warns(\n        PendingDeprecationWarning, match=""Visdom is eventually changing to default to raising exceptions""\n    ):\n        with pytest.raises(RuntimeError, match=""Failed to connect to Visdom server""):\n            VisdomLogger()\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_logger_init_hostname_port(visdom_server):\n    # Explicit hostname, port\n    vd_logger = VisdomLogger(server=visdom_server[0], port=visdom_server[1], num_workers=0)\n    assert ""main"" in vd_logger.vis.get_env_list()\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_logger_init_env_vars(visdom_server):\n    # As env vars\n    import os\n\n    os.environ[""VISDOM_SERVER_URL""] = visdom_server[0]\n    os.environ[""VISDOM_PORT""] = str(visdom_server[1])\n    vd_logger = VisdomLogger(server=visdom_server[0], port=visdom_server[1], num_workers=0)\n    assert ""main"" in vd_logger.vis.get_env_list()\n\n\ndef _parse_content(content):\n    import json\n\n    return json.loads(content)\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_integration_no_executor(visdom_server):\n    vd_logger = VisdomLogger(server=visdom_server[0], port=visdom_server[1], num_workers=0)\n\n    # close all windows in \'main\' environment\n    vd_logger.vis.close()\n\n    n_epochs = 3\n    data = list(range(10))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    trainer = Engine(update_fn)\n    output_handler = OutputHandler(tag=""training"", output_transform=lambda x: {""loss"": x})\n    vd_logger.attach(trainer, log_handler=output_handler, event_name=Events.ITERATION_COMPLETED)\n\n    trainer.run(data, max_epochs=n_epochs)\n\n    assert len(output_handler.windows) == 1\n    assert ""training/loss"" in output_handler.windows\n    win_name = output_handler.windows[""training/loss""][""win""]\n    data = vd_logger.vis.get_window_data(win=win_name)\n    data = _parse_content(data)\n    assert ""content"" in data and ""data"" in data[""content""]\n    data = data[""content""][""data""][0]\n    assert ""x"" in data and ""y"" in data\n    x_vals, y_vals = data[""x""], data[""y""]\n    assert all([int(x) == x_true for x, x_true in zip(x_vals, list(range(1, n_epochs * len(data) + 1)))])\n    assert all([y == y_true for y, y_true in zip(y_vals, losses)])\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_integration_with_executor(visdom_server):\n    vd_logger = VisdomLogger(server=visdom_server[0], port=visdom_server[1], num_workers=1)\n\n    # close all windows in \'main\' environment\n    vd_logger.vis.close()\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    trainer = Engine(update_fn)\n    output_handler = OutputHandler(tag=""training"", output_transform=lambda x: {""loss"": x})\n    vd_logger.attach(trainer, log_handler=output_handler, event_name=Events.ITERATION_COMPLETED)\n\n    trainer.run(data, max_epochs=n_epochs)\n\n    assert len(output_handler.windows) == 1\n    assert ""training/loss"" in output_handler.windows\n    win_name = output_handler.windows[""training/loss""][""win""]\n    data = vd_logger.vis.get_window_data(win=win_name)\n    data = _parse_content(data)\n    assert ""content"" in data and ""data"" in data[""content""]\n    data = data[""content""][""data""][0]\n    assert ""x"" in data and ""y"" in data\n    x_vals, y_vals = data[""x""], data[""y""]\n    assert all([int(x) == x_true for x, x_true in zip(x_vals, list(range(1, n_epochs * len(data) + 1)))])\n    assert all([y == y_true for y, y_true in zip(y_vals, losses)])\n\n    vd_logger.close()\n\n\n@pytest.mark.skipif(sys.platform.startswith(""win""), reason=""Skip on Windows"")\ndef test_integration_with_executor_as_context_manager(visdom_server):\n\n    n_epochs = 5\n    data = list(range(50))\n\n    losses = torch.rand(n_epochs * len(data))\n    losses_iter = iter(losses)\n\n    def update_fn(engine, batch):\n        return next(losses_iter)\n\n    with VisdomLogger(server=visdom_server[0], port=visdom_server[1], num_workers=1) as vd_logger:\n\n        # close all windows in \'main\' environment\n        vd_logger.vis.close()\n\n        trainer = Engine(update_fn)\n        output_handler = OutputHandler(tag=""training"", output_transform=lambda x: {""loss"": x})\n        vd_logger.attach(trainer, log_handler=output_handler, event_name=Events.ITERATION_COMPLETED)\n\n        trainer.run(data, max_epochs=n_epochs)\n\n        assert len(output_handler.windows) == 1\n        assert ""training/loss"" in output_handler.windows\n        win_name = output_handler.windows[""training/loss""][""win""]\n        data = vd_logger.vis.get_window_data(win=win_name)\n        data = _parse_content(data)\n        assert ""content"" in data and ""data"" in data[""content""]\n        data = data[""content""][""data""][0]\n        assert ""x"" in data and ""y"" in data\n        x_vals, y_vals = data[""x""], data[""y""]\n        assert all([int(x) == x_true for x, x_true in zip(x_vals, list(range(1, n_epochs * len(data) + 1)))])\n        assert all([y == y_true for y, y_true in zip(y_vals, losses)])\n\n\n@pytest.fixture\ndef no_site_packages():\n    import sys\n    import visdom\n\n    plx_module = sys.modules[""visdom""]\n    del sys.modules[""visdom""]\n    prev_path = list(sys.path)\n    sys.path = [p for p in sys.path if ""site-packages"" not in p]\n    yield ""no_site_packages""\n    sys.path = prev_path\n    sys.modules[""visdom""] = plx_module\n\n\ndef test_no_visdom(no_site_packages):\n\n    with pytest.raises(RuntimeError, match=r""This contrib module requires visdom package""):\n        VisdomLogger()\n'"
tests/ignite/contrib/handlers/test_wandb_logger.py,2,"b'from unittest.mock import MagicMock, call\n\nimport pytest\nimport torch\n\nfrom ignite.contrib.handlers.wandb_logger import *\nfrom ignite.engine import Events, State\n\n\ndef test_optimizer_params_handler_wrong_setup():\n    with pytest.raises(TypeError):\n        OptimizerParamsHandler(optimizer=None)\n\n    optimizer = MagicMock(spec=torch.optim.Optimizer)\n    handler = OptimizerParamsHandler(optimizer=optimizer)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler OptimizerParamsHandler works only with WandBLogger""):\n        handler(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_optimizer_params():\n    optimizer = torch.optim.SGD([torch.Tensor(0)], lr=0.01)\n    wrapper = OptimizerParamsHandler(optimizer=optimizer, param_name=""lr"")\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log.assert_called_once_with({""lr/group_0"": 0.01}, step=123, sync=None)\n\n    wrapper = OptimizerParamsHandler(optimizer, param_name=""lr"", tag=""generator"")\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log.assert_called_once_with({""generator/lr/group_0"": 0.01}, step=123, sync=None)\n\n\ndef test_output_handler_with_wrong_logger_type():\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n\n    mock_logger = MagicMock()\n    mock_engine = MagicMock()\n    with pytest.raises(RuntimeError, match=""Handler \'OutputHandler\' works only with WandBLogger""):\n        wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n\ndef test_output_handler_output_transform():\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x)\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.output = 12345\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    mock_logger.log.assert_called_once_with({""tag/output"": 12345}, step=123, sync=None)\n\n    wrapper = OutputHandler(""another_tag"", output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log.assert_called_once_with({""another_tag/loss"": 12345}, step=123, sync=None)\n\n\ndef test_output_handler_output_transform_sync():\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: x, sync=False)\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.output = 12345\n    mock_engine.state.iteration = 123\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n\n    mock_logger.log.assert_called_once_with({""tag/output"": 12345}, step=123, sync=False)\n\n    wrapper = OutputHandler(""another_tag"", output_transform=lambda x: {""loss"": x}, sync=True)\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log.assert_called_once_with({""another_tag/loss"": 12345}, step=123, sync=True)\n\n\ndef test_output_handler_metric_names():\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""])\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 1, ""b"": 5})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log.assert_called_once_with({""tag/a"": 1, ""tag/b"": 5}, step=5, sync=None)\n\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""c""])\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 55.56, ""c"": ""Some text""})\n    mock_engine.state.iteration = 7\n\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log.assert_called_once_with({""tag/a"": 55.56, ""tag/c"": ""Some text""}, step=7, sync=None)\n\n    # all metrics\n    wrapper = OutputHandler(""tag"", metric_names=""all"")\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.iteration = 5\n\n    wrapper(mock_engine, mock_logger, Events.ITERATION_STARTED)\n    mock_logger.log.assert_called_once_with({""tag/a"": 12.23, ""tag/b"": 23.45}, step=5, sync=None)\n\n\ndef test_output_handler_both():\n    wrapper = OutputHandler(""tag"", metric_names=[""a"", ""b""], output_transform=lambda x: {""loss"": x})\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State(metrics={""a"": 12.23, ""b"": 23.45})\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n    mock_logger.log.assert_called_once_with({""tag/a"": 12.23, ""tag/b"": 23.45, ""tag/loss"": 12345}, step=5, sync=None)\n\n\ndef test_output_handler_with_wrong_global_step_transform_output():\n    def global_step_transform(*args, **kwargs):\n        return ""a""\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    with pytest.raises(TypeError, match=""global_step must be int""):\n        wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n\n\ndef test_output_handler_with_global_step_transform():\n    def global_step_transform(*args, **kwargs):\n        return 10\n\n    wrapper = OutputHandler(""tag"", output_transform=lambda x: {""loss"": x}, global_step_transform=global_step_transform)\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 5\n    mock_engine.state.output = 12345\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    mock_logger.log.assert_called_once_with({""tag/loss"": 12345}, step=10, sync=None)\n\n\ndef test_output_handler_with_global_step_from_engine():\n\n    mock_another_engine = MagicMock()\n    mock_another_engine.state = State()\n    mock_another_engine.state.epoch = 10\n    mock_another_engine.state.output = 12.345\n\n    wrapper = OutputHandler(\n        ""tag"",\n        output_transform=lambda x: {""loss"": x},\n        global_step_transform=global_step_from_engine(mock_another_engine),\n    )\n\n    mock_logger = MagicMock(spec=WandBLogger)\n    mock_logger.log = MagicMock()\n\n    mock_engine = MagicMock()\n    mock_engine.state = State()\n    mock_engine.state.epoch = 1\n    mock_engine.state.output = 0.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    mock_logger.log.assert_called_once_with(\n        {""tag/loss"": mock_engine.state.output}, step=mock_another_engine.state.epoch, sync=None\n    )\n\n    mock_another_engine.state.epoch = 11\n    mock_engine.state.output = 1.123\n\n    wrapper(mock_engine, mock_logger, Events.EPOCH_STARTED)\n    assert mock_logger.log.call_count == 2\n    mock_logger.log.assert_has_calls(\n        [call({""tag/loss"": mock_engine.state.output}, step=mock_another_engine.state.epoch, sync=None)]\n    )\n\n\n@pytest.fixture\ndef no_site_packages():\n    import sys\n\n    wandb_client_modules = {}\n    for k in sys.modules:\n        if ""wandb"" in k:\n            wandb_client_modules[k] = sys.modules[k]\n    for k in wandb_client_modules:\n        del sys.modules[k]\n\n    prev_path = list(sys.path)\n    sys.path = [p for p in sys.path if ""site-packages"" not in p]\n    yield ""no_site_packages""\n    sys.path = prev_path\n    for k in wandb_client_modules:\n        sys.modules[k] = wandb_client_modules[k]\n\n\ndef test_no_wandb_client(no_site_packages):\n\n    with pytest.raises(RuntimeError, match=r""This contrib module requires wandb to be installed.""):\n        WandBLogger()\n'"
tests/ignite/contrib/metrics/__init__.py,0,b''
tests/ignite/contrib/metrics/test_average_precision.py,8,"b'import numpy as np\nimport torch\nfrom sklearn.metrics import average_precision_score\n\nfrom ignite.contrib.metrics import AveragePrecision\nfrom ignite.engine import Engine\n\n\ndef test_ap_score():\n\n    size = 100\n    np_y_pred = np.random.rand(size, 5)\n    np_y = np.random.randint(0, 2, size=(size, 5), dtype=np.long)\n    np_ap = average_precision_score(np_y, np_y_pred)\n\n    ap_metric = AveragePrecision()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    ap_metric.reset()\n    ap_metric.update((y_pred, y))\n    ap = ap_metric.compute()\n\n    assert ap == np_ap\n\n\ndef test_ap_score_2():\n\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n    np_ap = average_precision_score(np_y, np_y_pred)\n\n    ap_metric = AveragePrecision()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    ap_metric.reset()\n    n_iters = 10\n    batch_size = size // n_iters\n    for i in range(n_iters):\n        idx = i * batch_size\n        ap_metric.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n    ap = ap_metric.compute()\n\n    assert ap == np_ap\n\n\ndef test_integration_ap_score_with_output_transform():\n\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n\n    np_ap = average_precision_score(np_y, np_y_pred)\n\n    batch_size = 10\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    ap_metric = AveragePrecision(output_transform=lambda x: (x[1], x[2]))\n    ap_metric.attach(engine, ""ap"")\n\n    data = list(range(size // batch_size))\n    ap = engine.run(data, max_epochs=1).metrics[""ap""]\n\n    assert ap == np_ap\n\n\ndef test_integration_ap_score_with_activated_output_transform():\n\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y_pred_softmax = torch.softmax(torch.from_numpy(np_y_pred), dim=1).numpy()\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n\n    np_ap = average_precision_score(np_y, np_y_pred_softmax)\n\n    batch_size = 10\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    ap_metric = AveragePrecision(output_transform=lambda x: (torch.softmax(x[1], dim=1), x[2]))\n    ap_metric.attach(engine, ""ap"")\n\n    data = list(range(size // batch_size))\n    ap = engine.run(data, max_epochs=1).metrics[""ap""]\n\n    assert ap == np_ap\n'"
tests/ignite/contrib/metrics/test_gpu_info.py,6,"b'import sys\nfrom unittest.mock import Mock, patch\n\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics import GpuInfo\nfrom ignite.engine import Engine, State\n\npython_below_36 = (sys.version[0] == ""3"" and int(sys.version[2]) < 6) or int(sys.version[0]) < 2\n\n\n@pytest.fixture\ndef no_site_packages():\n    import pynvml\n    import sys\n\n    assert ""pynvml"" in sys.modules\n    pynvml_module = sys.modules[""pynvml""]\n    del sys.modules[""pynvml""]\n    prev_path = list(sys.path)\n    sys.path = [p for p in sys.path if ""site-packages"" not in p]\n    yield ""no_site_packages""\n    sys.path = prev_path\n    sys.modules[""pynvml""] = pynvml_module\n\n\n@pytest.mark.skipif(python_below_36, reason=""No pynvml for python < 3.6"")\ndef test_no_pynvml_package(no_site_packages):\n\n    with pytest.raises(RuntimeError, match=""This contrib module requires pynvml to be installed.""):\n        GpuInfo()\n\n\n@pytest.mark.skipif(python_below_36 or torch.cuda.is_available(), reason=""No pynvml for python < 3.6"")\ndef test_no_gpu():\n\n    with pytest.raises(RuntimeError, match=""This contrib module requires available GPU""):\n        GpuInfo()\n\n\ndef _test_gpu_info(device=""cpu""):\n    gpu_info = GpuInfo()\n\n    # increase code cov\n    gpu_info.reset()\n    gpu_info.update(None)\n\n    t = torch.rand(4, 10, 100, 100).to(device)\n    data = gpu_info.compute()\n    assert len(data) > 0\n    assert ""fb_memory_usage"" in data[0]\n    mem_report = data[0][""fb_memory_usage""]\n    assert ""used"" in mem_report and ""total"" in mem_report\n    assert mem_report[""total""] > 0.0\n    assert mem_report[""used""] > t.shape[0] * t.shape[1] * t.shape[2] * t.shape[3] / 1024.0 / 1024.0\n\n    assert ""utilization"" in data[0]\n    util_report = data[0][""utilization""]\n    assert ""gpu_util"" in util_report\n\n    # with Engine\n    engine = Engine(lambda engine, batch: 0.0)\n    engine.state = State(metrics={})\n\n    gpu_info.completed(engine, name=""gpu"")\n\n    assert ""gpu:0 mem(%)"" in engine.state.metrics\n\n    assert isinstance(engine.state.metrics[""gpu:0 mem(%)""], int)\n    assert int(mem_report[""used""] * 100.0 / mem_report[""total""]) == engine.state.metrics[""gpu:0 mem(%)""]\n\n    if util_report[""gpu_util""] != ""N/A"":\n        assert ""gpu:0 util(%)"" in engine.state.metrics\n        assert isinstance(engine.state.metrics[""gpu:0 util(%)""], int)\n        assert int(util_report[""gpu_util""]) == engine.state.metrics[""gpu:0 util(%)""]\n    else:\n        assert ""gpu:0 util(%)"" not in engine.state.metrics\n\n\n@pytest.mark.skipif(python_below_36 or not (torch.cuda.is_available()), reason=""No pynvml for python < 3.6 and no GPU"")\ndef test_gpu_info_on_cuda():\n    _test_gpu_info(device=""cuda"")\n\n\nquery_resp = None\n\n\n@pytest.fixture\ndef mock_pynvml_module():\n\n    with patch.dict(\n        ""sys.modules"",\n        {\n            ""pynvml"": Mock(name=""pynvml""),\n            ""pynvml.smi"": Mock(name=""pynvml.smi""),\n            ""pynvml.smi.nvidia_smi"": Mock(name=""pynvml.smi.nvidia_smi""),\n        },\n    ):\n        import pynvml\n        from pynvml.smi import nvidia_smi\n\n        def query(*args, **kwargs):\n            return query_resp\n\n        def getInstance():\n            nvsmi = Mock()\n            nvsmi.DeviceQuery = Mock(side_effect=query)\n            return nvsmi\n\n        nvidia_smi.getInstance = Mock(side_effect=getInstance)\n        yield pynvml\n\n\n@pytest.fixture\ndef mock_gpu_is_available():\n\n    with patch(""ignite.contrib.metrics.gpu_info.torch.cuda"") as mock_cuda:\n        mock_cuda.is_available.return_value = True\n        yield mock_cuda\n\n\n@pytest.mark.skipif(torch.cuda.is_available(), reason=""No need to mock if has GPU"")\ndef test_gpu_info_mock(mock_pynvml_module, mock_gpu_is_available):\n    global query_resp\n\n    query_resp = {""gpu"": [{""fb_memory_usage"": {""used"": 100.0, ""total"": 11000.0}, ""utilization"": {""gpu_util"": 50.0}}]}\n\n    assert torch.cuda.is_available()\n    _test_gpu_info()\n\n    # Tests https://github.com/pytorch/ignite/issues/1040\n    query_resp = {""gpu"": [{""fb_memory_usage"": {""used"": 100.0, ""total"": 11000.0}, ""utilization"": {""gpu_util"": ""N/A""}}]}\n    _test_gpu_info()\n\n    def _test_with_custom_query(resp, warn_msg, check_compute=False):\n        from pynvml.smi import nvidia_smi\n\n        def query(*args, **kwargs):\n            return resp\n\n        def getInstance():\n            nvsmi = Mock()\n            nvsmi.DeviceQuery = Mock(side_effect=query)\n            return nvsmi\n\n        nvidia_smi.getInstance = Mock(side_effect=getInstance)\n        gpu_info = GpuInfo()\n        if check_compute:\n            with pytest.warns(UserWarning, match=warn_msg):\n                gpu_info.compute()\n\n        # with Engine\n        engine = Engine(lambda engine, batch: 0.0)\n        engine.state = State(metrics={})\n\n        with pytest.warns(UserWarning, match=warn_msg):\n            gpu_info.completed(engine, name=""gpu info"")\n\n    # No GPU info\n    _test_with_custom_query(resp={}, warn_msg=r""No GPU information available"", check_compute=True)\n\n    # No GPU memory info\n    _test_with_custom_query(resp={""gpu"": [{""utilization"": {}},]}, warn_msg=r""No GPU memory usage information available"")\n\n    # No GPU utilization info\n    _test_with_custom_query(\n        resp={""gpu"": [{""fb_memory_usage"": {}},]}, warn_msg=r""No GPU utilization information available""\n    )\n'"
tests/ignite/contrib/metrics/test_precision_recall_curve.py,6,"b'import numpy as np\nimport torch\nfrom sklearn.metrics import precision_recall_curve\n\nfrom ignite.contrib.metrics.precision_recall_curve import PrecisionRecallCurve\nfrom ignite.engine import Engine\n\n\ndef test_precision_recall_curve():\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    sk_precision, sk_recall, sk_thresholds = precision_recall_curve(np_y, np_y_pred)\n\n    precision_recall_curve_metric = PrecisionRecallCurve()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    precision_recall_curve_metric.update((y_pred, y))\n    precision, recall, thresholds = precision_recall_curve_metric.compute()\n\n    assert np.array_equal(precision, sk_precision)\n    assert np.array_equal(recall, sk_recall)\n    # assert thresholds almost equal, due to numpy->torch->numpy conversion\n    np.testing.assert_array_almost_equal(thresholds, sk_thresholds)\n\n\ndef test_integration_precision_recall_curve_with_output_transform():\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n\n    sk_precision, sk_recall, sk_thresholds = precision_recall_curve(np_y, np_y_pred)\n\n    batch_size = 10\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    precision_recall_curve_metric = PrecisionRecallCurve(output_transform=lambda x: (x[1], x[2]))\n    precision_recall_curve_metric.attach(engine, ""precision_recall_curve"")\n\n    data = list(range(size // batch_size))\n    precision, recall, thresholds = engine.run(data, max_epochs=1).metrics[""precision_recall_curve""]\n\n    assert np.array_equal(precision, sk_precision)\n    assert np.array_equal(recall, sk_recall)\n    # assert thresholds almost equal, due to numpy->torch->numpy conversion\n    np.testing.assert_array_almost_equal(thresholds, sk_thresholds)\n\n\ndef test_integration_precision_recall_curve_with_activated_output_transform():\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y_pred_sigmoid = torch.sigmoid(torch.from_numpy(np_y_pred)).numpy()\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n\n    sk_precision, sk_recall, sk_thresholds = precision_recall_curve(np_y, np_y_pred_sigmoid)\n\n    batch_size = 10\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    precision_recall_curve_metric = PrecisionRecallCurve(output_transform=lambda x: (torch.sigmoid(x[1]), x[2]))\n    precision_recall_curve_metric.attach(engine, ""precision_recall_curve"")\n\n    data = list(range(size // batch_size))\n    precision, recall, thresholds = engine.run(data, max_epochs=1).metrics[""precision_recall_curve""]\n\n    assert np.array_equal(precision, sk_precision)\n    assert np.array_equal(recall, sk_recall)\n    # assert thresholds almost equal, due to numpy->torch->numpy conversion\n    np.testing.assert_array_almost_equal(thresholds, sk_thresholds)\n'"
tests/ignite/contrib/metrics/test_roc_auc.py,8,"b'import numpy as np\nimport torch\nfrom sklearn.metrics import roc_auc_score\n\nfrom ignite.contrib.metrics import ROC_AUC\nfrom ignite.engine import Engine\n\n\ndef test_roc_auc_score():\n\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np_roc_auc = roc_auc_score(np_y, np_y_pred)\n\n    roc_auc_metric = ROC_AUC()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    roc_auc_metric.reset()\n    roc_auc_metric.update((y_pred, y))\n    roc_auc = roc_auc_metric.compute()\n\n    assert roc_auc == np_roc_auc\n\n\ndef test_roc_auc_score_2():\n\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n    np_roc_auc = roc_auc_score(np_y, np_y_pred)\n\n    roc_auc_metric = ROC_AUC()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    roc_auc_metric.reset()\n    n_iters = 10\n    batch_size = size // n_iters\n    for i in range(n_iters):\n        idx = i * batch_size\n        roc_auc_metric.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n    roc_auc = roc_auc_metric.compute()\n\n    assert roc_auc == np_roc_auc\n\n\ndef test_integration_roc_auc_score_with_output_transform():\n\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n\n    np_roc_auc = roc_auc_score(np_y, np_y_pred)\n\n    batch_size = 10\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    roc_auc_metric = ROC_AUC(output_transform=lambda x: (x[1], x[2]))\n    roc_auc_metric.attach(engine, ""roc_auc"")\n\n    data = list(range(size // batch_size))\n    roc_auc = engine.run(data, max_epochs=1).metrics[""roc_auc""]\n\n    assert roc_auc == np_roc_auc\n\n\ndef test_integration_roc_auc_score_with_activated_output_transform():\n\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y_pred_sigmoid = torch.sigmoid(torch.from_numpy(np_y_pred)).numpy()\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n\n    np_roc_auc = roc_auc_score(np_y, np_y_pred_sigmoid)\n\n    batch_size = 10\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    roc_auc_metric = ROC_AUC(output_transform=lambda x: (torch.sigmoid(x[1]), x[2]))\n    roc_auc_metric.attach(engine, ""roc_auc"")\n\n    data = list(range(size // batch_size))\n    roc_auc = engine.run(data, max_epochs=1).metrics[""roc_auc""]\n\n    assert roc_auc == np_roc_auc\n'"
tests/ignite/contrib/metrics/test_roc_curve.py,6,"b'import numpy as np\nimport torch\nfrom sklearn.metrics import roc_curve\n\nfrom ignite.contrib.metrics.roc_auc import RocCurve\nfrom ignite.engine import Engine\n\n\ndef test_roc_curve():\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    sk_fpr, sk_tpr, sk_thresholds = roc_curve(np_y, np_y_pred)\n\n    roc_curve_metric = RocCurve()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    roc_curve_metric.update((y_pred, y))\n    fpr, tpr, thresholds = roc_curve_metric.compute()\n\n    assert np.array_equal(fpr, sk_fpr)\n    assert np.array_equal(tpr, sk_tpr)\n    # assert thresholds almost equal, due to numpy->torch->numpy conversion\n    np.testing.assert_array_almost_equal(thresholds, sk_thresholds)\n\n\ndef test_integration_roc_curve_with_output_transform():\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n\n    sk_fpr, sk_tpr, sk_thresholds = roc_curve(np_y, np_y_pred)\n\n    batch_size = 10\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    roc_curve_metric = RocCurve(output_transform=lambda x: (x[1], x[2]))\n    roc_curve_metric.attach(engine, ""roc_curve"")\n\n    data = list(range(size // batch_size))\n    fpr, tpr, thresholds = engine.run(data, max_epochs=1).metrics[""roc_curve""]\n\n    assert np.array_equal(fpr, sk_fpr)\n    assert np.array_equal(tpr, sk_tpr)\n    # assert thresholds almost equal, due to numpy->torch->numpy conversion\n    np.testing.assert_array_almost_equal(thresholds, sk_thresholds)\n\n\ndef test_integration_roc_curve_with_activated_output_transform():\n    np.random.seed(1)\n    size = 100\n    np_y_pred = np.random.rand(size, 1)\n    np_y_pred_sigmoid = torch.sigmoid(torch.from_numpy(np_y_pred)).numpy()\n    np_y = np.zeros((size,), dtype=np.long)\n    np_y[size // 2 :] = 1\n    np.random.shuffle(np_y)\n\n    sk_fpr, sk_tpr, sk_thresholds = roc_curve(np_y, np_y_pred_sigmoid)\n\n    batch_size = 10\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    roc_curve_metric = RocCurve(output_transform=lambda x: (torch.sigmoid(x[1]), x[2]))\n    roc_curve_metric.attach(engine, ""roc_curve"")\n\n    data = list(range(size // batch_size))\n    fpr, tpr, thresholds = engine.run(data, max_epochs=1).metrics[""roc_curve""]\n\n    assert np.array_equal(fpr, sk_fpr)\n    assert np.array_equal(tpr, sk_tpr)\n    # assert thresholds almost equal, due to numpy->torch->numpy conversion\n    np.testing.assert_array_almost_equal(thresholds, sk_thresholds)\n'"
tests/ignite/distributed/comp_models/__init__.py,0,b''
tests/ignite/distributed/comp_models/test_base.py,3,"b'import pytest\nimport torch\n\nfrom ignite.distributed.comp_models.base import _SerialModel\n\n\ndef test_serial_model():\n    _SerialModel.create_from_backend()\n    model = _SerialModel.create_from_context()\n\n    assert model.get_local_rank() == 0\n    assert model.get_rank() == 0\n    assert model.get_world_size() == 1\n    assert model.get_ntasks_per_node() == 1\n    assert model.get_num_nodes() == 1\n    assert model.get_node_rank() == 0\n    if torch.cuda.is_available():\n        assert model.device().type == ""cuda""\n    else:\n        assert model.device().type == ""cpu""\n    assert model.backend() is None\n    model.finalize()\n\n    with pytest.raises(NotImplementedError, match=r""Serial computation model does not implement spawn method""):\n        model.spawn()\n\n    model.all_reduce(1)\n    model.all_gather(1)\n    model._do_all_reduce(torch.tensor(1))\n    model._do_all_gather(torch.tensor(1))\n    model.barrier()\n'"
tests/ignite/distributed/comp_models/test_native.py,8,"b'import os\n\nimport pytest\nimport torch\nimport torch.distributed as dist\n\nfrom ignite.distributed.comp_models import has_native_dist_support\n\nif not has_native_dist_support:\n    pytest.skip(""Skip if no native dist support"", allow_module_level=True)\nelse:\n    from ignite.distributed.comp_models.native import _NativeDistModel\n\n\n@pytest.mark.distributed\ndef test__native_dist_model():\n    available_backends = _NativeDistModel.available_backends\n\n    if dist.is_nccl_available():\n        assert ""nccl"" in available_backends\n    else:\n        assert ""nccl"" not in available_backends\n\n    if dist.is_gloo_available():\n        assert ""gloo"" in available_backends\n    else:\n        assert ""gloo"" not in available_backends\n\n    if dist.is_mpi_available():\n        assert ""mpi"" in available_backends\n    else:\n        assert ""mpi"" not in available_backends\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(""WORLD_SIZE"" in os.environ, reason=""Skip if launched as multiproc"")\ndef test__native_dist_model_create_from_backend_bad_config():\n    import os\n    from datetime import timedelta\n\n    os.environ[""RANK""] = ""1""\n\n    print(""ENV"", os.environ)\n\n    with pytest.raises(RuntimeError, match=r""PyTorch distributed configuration should define env variables""):\n        _NativeDistModel.create_from_backend(backend=""gloo"", timeout=timedelta(seconds=10))\n\n    del os.environ[""RANK""]\n\n\ndef _assert_model(model, true_conf):\n\n    assert model.device() == torch.device(true_conf[""device""])\n    assert model.get_local_rank() == true_conf[""local_rank""]\n    assert model.get_rank() == true_conf[""rank""]\n    assert model.get_world_size() == true_conf[""world_size""]\n\n    assert model.get_node_rank() == true_conf[""node_index""]\n    assert model.get_num_nodes() == true_conf[""num_nodes""]\n    assert model.get_ntasks_per_node() == true_conf[""ntasks_per_node""]\n\n\ndef _test__native_dist_model_create_from_backend_no_dist(backend, true_device):\n    from datetime import timedelta\n\n    model = _NativeDistModel.create_from_backend(backend=backend, timeout=timedelta(seconds=20))\n\n    assert dist.is_available() and dist.is_initialized()\n    assert dist.get_backend() == backend\n\n    _assert_model(\n        model,\n        {\n            ""device"": true_device,\n            ""local_rank"": 0,\n            ""rank"": 0,\n            ""world_size"": 1,\n            ""node_index"": 0,\n            ""num_nodes"": 1,\n            ""ntasks_per_node"": 1,\n        },\n    )\n\n    model.finalize()\n\n\ndef _test__native_dist_model_create_from_backend_dist(local_rank, rank, world_size, backend, true_device):\n    import os\n    from datetime import timedelta\n\n    timeout = timedelta(seconds=20)\n    os.environ[""RANK""] = ""{}"".format(rank)\n\n    model = _NativeDistModel.create_from_backend(backend=backend, timeout=timeout)\n\n    assert dist.is_available() and dist.is_initialized()\n    assert dist.get_backend() == backend\n\n    with pytest.raises(RuntimeError, match=r""Can not create new distributed process group if default one is""):\n        _NativeDistModel.create_from_backend(backend=backend, timeout=timeout)\n\n    _assert_model(\n        model,\n        {\n            ""device"": true_device,\n            ""local_rank"": local_rank,\n            ""rank"": rank,\n            ""world_size"": world_size,\n            ""node_index"": 0,\n            ""num_nodes"": 1,\n            ""ntasks_per_node"": world_size,\n        },\n    )\n\n    model.finalize()\n\n    del os.environ[""RANK""]\n\n\ndef _test__native_dist_model_create_from_context_no_local_rank():\n\n    if ""LOCAL_RANK"" in os.environ:\n        del os.environ[""LOCAL_RANK""]\n\n    from ignite.distributed.comp_models.base import ComputationModel\n\n    if ComputationModel._ext_local_rank is not None:\n        ComputationModel._ext_local_rank = None\n\n    with pytest.warns(UserWarning, match=r""Local rank information for native distributed setting will be initialized""):\n        _NativeDistModel.create_from_context()\n\n\ndef _test__native_dist_model_create_from_context_env_local_rank(true_conf):\n    import os\n\n    remove_lrank = False\n    if ""LOCAL_RANK"" not in os.environ:\n        os.environ[""LOCAL_RANK""] = str(true_conf[""local_rank""])\n        remove_lrank = True\n\n    model = _NativeDistModel.create_from_context()\n    _assert_model(model, true_conf)\n\n    if remove_lrank:\n        del os.environ[""LOCAL_RANK""]\n\n\ndef _test__native_dist_model_create_from_context_set_local_rank(true_conf):\n\n    from ignite.distributed.comp_models.base import ComputationModel\n\n    lrank = None\n    if ""LOCAL_RANK"" in os.environ:\n        lrank = os.environ[""LOCAL_RANK""]\n        del os.environ[""LOCAL_RANK""]\n\n    ComputationModel._ext_local_rank = true_conf[""local_rank""]\n\n    model = _NativeDistModel.create_from_context()\n    _assert_model(model, true_conf)\n\n    ComputationModel._ext_local_rank = None\n\n    if lrank is not None:\n        os.environ[""LOCAL_RANK""] = lrank\n\n\ndef _test__native_dist_model_create_from_context_no_dist(true_backend, true_device):\n\n    assert _NativeDistModel.create_from_context() is None\n\n    dist.init_process_group(true_backend, ""tcp://0.0.0.0:2222"", world_size=1, rank=0)\n    dist.barrier()\n\n    _test__native_dist_model_create_from_context_no_local_rank()\n\n    true_conf = {\n        ""device"": true_device,\n        ""local_rank"": 0,\n        ""rank"": 0,\n        ""world_size"": 1,\n        ""node_index"": 0,\n        ""num_nodes"": 1,\n        ""ntasks_per_node"": 1,\n    }\n\n    _test__native_dist_model_create_from_context_env_local_rank(true_conf)\n    _test__native_dist_model_create_from_context_set_local_rank(true_conf)\n\n    dist.destroy_process_group()\n\n\ndef _test__native_dist_model_create_from_context_dist(local_rank, rank, world_size, true_backend, true_device):\n\n    assert _NativeDistModel.create_from_context() is None\n\n    dist.init_process_group(true_backend, ""tcp://0.0.0.0:2222"", world_size=world_size, rank=rank)\n    dist.barrier()\n\n    true_conf = {\n        ""device"": true_device,\n        ""local_rank"": local_rank,\n        ""rank"": rank,\n        ""world_size"": world_size,\n        ""node_index"": 0,\n        ""num_nodes"": 1,\n        ""ntasks_per_node"": world_size,\n    }\n\n    _test__native_dist_model_create_from_context_env_local_rank(true_conf)\n    _test__native_dist_model_create_from_context_set_local_rank(true_conf)\n\n    dist.destroy_process_group()\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(""WORLD_SIZE"" in os.environ, reason=""Should be no-dist config"")\ndef test__native_dist_model_create_no_dist_gloo(clean_env):\n    _test__native_dist_model_create_from_backend_no_dist(""gloo"", ""cpu"")\n    _test__native_dist_model_create_from_context_no_dist(""gloo"", ""cpu"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(""WORLD_SIZE"" in os.environ, reason=""Should be no-dist config"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test__native_dist_model_create_no_dist_nccl(clean_env):\n    _test__native_dist_model_create_from_backend_no_dist(""nccl"", ""cuda:0"")\n    _test__native_dist_model_create_from_context_no_dist(""nccl"", ""cuda:0"")\n\n\n@pytest.mark.distributed\ndef test__native_dist_model_create_dist_gloo(local_rank, world_size):\n    _test__native_dist_model_create_from_backend_dist(local_rank, local_rank, world_size, ""gloo"", ""cpu"")\n    _test__native_dist_model_create_from_context_dist(local_rank, local_rank, world_size, ""gloo"", ""cpu"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test__native_dist_model_create_dist_nccl(local_rank, world_size):\n    _test__native_dist_model_create_from_backend_dist(\n        local_rank, local_rank, world_size, ""nccl"", ""cuda:{}"".format(local_rank)\n    )\n    _test__native_dist_model_create_from_context_dist(\n        local_rank, local_rank, world_size, ""nccl"", ""cuda:{}"".format(local_rank)\n    )\n\n\ndef _test_dist_spawn_fn(local_rank, backend, world_size, device):\n    from ignite.distributed.utils import _model\n\n    assert dist.is_available() and dist.is_initialized()\n    assert dist.get_backend() == backend\n\n    assert isinstance(_model, _NativeDistModel), ""{} vs _NativeDistModel"".format(type(_model))\n\n    assert _model.get_local_rank() == local_rank\n    assert _model.get_world_size() == world_size\n    if backend == ""nccl"":\n        assert _model.device() == torch.device(""{}:{}"".format(device, local_rank))\n    elif backend == ""gloo"":\n        assert _model.device() == torch.device(device)\n\n\ndef _test__native_dist_model_spawn(backend, num_workers_per_machine, device):\n    _NativeDistModel.spawn(\n        _test_dist_spawn_fn,\n        args=(backend, num_workers_per_machine, device),\n        kwargs_dict={},\n        backend=backend,\n        num_procs_per_node=num_workers_per_machine,\n    )\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(""WORLD_SIZE"" in os.environ, reason=""Skip if launched as multiproc"")\ndef test__native_dist_model_spawn_gloo():\n    _test__native_dist_model_spawn(""gloo"", num_workers_per_machine=4, device=""cpu"")\n\n\n@pytest.mark.distributed\n@pytest.mark.skipif(""WORLD_SIZE"" in os.environ, reason=""Skip if launched as multiproc"")\n@pytest.mark.skipif(torch.cuda.device_count() < 1, reason=""Skip if no GPU"")\ndef test__native_dist_model_spawn_nccl():\n    _test__native_dist_model_spawn(""nccl"", num_workers_per_machine=torch.cuda.device_count(), device=""cuda"")\n'"
tests/ignite/distributed/comp_models/test_xla.py,5,"b'import os\n\nimport pytest\nimport torch\n\nfrom ignite.distributed.comp_models import has_xla_support\n\nif not has_xla_support:\n    pytest.skip(""Skip if no XLA support"", allow_module_level=True)\nelse:\n    from ignite.distributed.comp_models.xla import _XlaDistModel\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test__xla_model():\n    available_backends = _XlaDistModel.available_backends\n    assert ""xla-tpu"" in available_backends\n\n\ndef _test_xla_spawn_fn(local_rank, world_size, device):\n    from ignite.distributed.utils import _model\n\n    assert isinstance(_model, _XlaDistModel), ""{} vs _XlaDistModel"".format(type(_model))\n\n    assert _model.get_local_rank() == local_rank\n    assert _model.get_world_size() == world_size\n    d = _model.device()\n    assert isinstance(d, torch.device) and d.type == device\n\n    assert _model.get_rank() == local_rank\n    assert _model.get_ntasks_per_node() == world_size\n    assert _model.get_node_rank() == 0\n    assert _model.get_num_nodes() == 1\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test__xla_dist_model_spawn_one_proc():\n    try:\n        _XlaDistModel.spawn(\n            _test_xla_spawn_fn, args=(1, ""xla""), kwargs_dict={}, num_procs_per_node=1,\n        )\n    except SystemExit:\n        pass\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test__xla_dist_model_spawn_n_procs():\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    try:\n        _XlaDistModel.spawn(\n            _test_xla_spawn_fn, args=(n, ""xla""), kwargs_dict={}, num_procs_per_node=n,\n        )\n    except SystemExit:\n        pass\n\n\ndef _assert_model(model, true_conf):\n\n    assert model.device() == true_conf[""device""]\n    assert model.get_local_rank() == true_conf[""local_rank""]\n    assert model.get_rank() == true_conf[""rank""]\n    assert model.get_world_size() == true_conf[""world_size""]\n\n    assert model.get_node_rank() == true_conf[""node_index""]\n    assert model.get_num_nodes() == true_conf[""num_nodes""]\n    assert model.get_ntasks_per_node() == true_conf[""ntasks_per_node""]\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test__xla_dist_model_create_from_backend():\n    # without spawn\n    model = _XlaDistModel.create_from_backend(""xla-tpu"")\n\n    import torch_xla.core.xla_model as xm\n\n    _assert_model(\n        model,\n        {\n            ""device"": xm.xla_device(),\n            ""local_rank"": 0,\n            ""rank"": 0,\n            ""world_size"": 1,\n            ""node_index"": 0,\n            ""num_nodes"": 1,\n            ""ntasks_per_node"": 1,\n        },\n    )\n\n    model.finalize()\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if NUM_TPU_WORKERS is in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test__xla_dist_model_create_from_context():\n    # without spawn\n    model = _XlaDistModel.create_from_context()\n\n    assert model.backend() == ""xla-tpu""\n\n    import torch_xla.core.xla_model as xm\n\n    _assert_model(\n        model,\n        {\n            ""device"": xm.xla_device(),\n            ""local_rank"": 0,\n            ""rank"": 0,\n            ""world_size"": 1,\n            ""node_index"": 0,\n            ""num_nodes"": 1,\n            ""ntasks_per_node"": 1,\n        },\n    )\n\n\ndef _test__xla_dist_model_create_from_context_in_child_proc(index):\n    model = _XlaDistModel.create_from_context()\n\n    assert model.backend() == ""xla-tpu""\n\n    import torch_xla.core.xla_model as xm\n\n    _assert_model(\n        model,\n        {\n            ""device"": xm.xla_device(),\n            ""local_rank"": index,\n            ""rank"": xm.get_ordinal(),\n            ""world_size"": xm.xrt_world_size(),\n            ""node_index"": 0,\n            ""num_nodes"": 1,\n            ""ntasks_per_node"": xm.xrt_world_size(),\n        },\n    )\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" not in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test__xla_dist_model_create_from_context_in_child_proc(xmp_executor):\n    n = int(os.environ[""NUM_TPU_WORKERS""])\n    xmp_executor(_test__xla_dist_model_create_from_context_in_child_proc, args=(), nprocs=n)\n\n\ndef main_fold(fold):\n    import time\n    import torch.nn as nn\n    import torch.optim as optim\n    import torch_xla.core.xla_model as xm\n    from ignite.engine import Engine, Events\n\n    device = xm.xla_device(fold)\n\n    comp_model = _XlaDistModel.create_from_context()\n    assert comp_model.device() == device\n\n    model = nn.Linear(100, 10)\n\n    model.to(device)  # Move model before creating optimizer\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\n    def training_step(engine, _):\n        data = torch.rand(4, 100, device=device)\n        model.train()\n        data = data.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = output.sum()\n        loss.backward()\n        xm.optimizer_step(optimizer, barrier=True)\n        return loss.item()\n\n    trainer = Engine(training_step)\n\n    # THIS CAN BE A CAUSE OF CRASH if DEVICE is OTHER THAN device\n    tensor = torch.tensor([fold + 1.0], dtype=torch.float).to(comp_model.device())\n    xm.all_reduce(""max"", [tensor,])\n\n    time.sleep(0.01 * fold)\n\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def log_progress():\n        print(""."", end="" "")\n\n    trainer.run([0] * 100, max_epochs=2)\n\n\n@pytest.mark.tpu\n@pytest.mark.skipif(""NUM_TPU_WORKERS"" in os.environ, reason=""Skip if no NUM_TPU_WORKERS in env vars"")\n@pytest.mark.skipif(not has_xla_support, reason=""Skip if no PyTorch XLA package"")\ndef test__xla_dist_model_run_parallel_n_threads_without_sync():\n    # tests issue : https://github.com/pytorch/ignite/issues/1096\n    from joblib import Parallel, delayed\n\n    import torch_xla.core.xla_model as xm\n\n    devices = xm.get_xla_supported_devices()\n    folds = 1\n    d = 0\n    if len(devices) > 5:\n        folds = 5\n        d = 1\n    Parallel(n_jobs=folds, backend=""threading"")(delayed(main_fold)(i + d) for i in range(folds))\n'"
examples/references/segmentation/pascal_voc2012/code/__init__.py,0,b''
tests/ignite/contrib/metrics/regression/__init__.py,0,b''
tests/ignite/contrib/metrics/regression/test__base.py,18,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression._base import _BaseRegression, _BaseRegressionEpoch\n\n\ndef test_base_regression_shapes():\n    class L1(_BaseRegression):\n        def reset(self):\n            self._sum_of_errors = 0.0\n\n        def _update(self, output):\n            y_pred, y = output\n            errors = torch.abs(y.view_as(y_pred) - y_pred)\n            self._sum_of_errors += torch.sum(errors).item()\n\n        def compute(self):\n            return self._sum_of_errors\n\n    m = L1()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 3), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 3)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 7), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 7)))\n\n\ndef test_base_regression_epoch_shapes():\n    def compute_fn(y_pred, y):\n        return 0.0\n\n    class ZeroEpoch(_BaseRegressionEpoch):\n        def __init__(self, output_transform=lambda x: x):\n            super(ZeroEpoch, self).__init__(compute_fn, output_transform)\n\n    m = ZeroEpoch()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 3), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 3)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 7), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 7)))\n\n\ndef test_base_regression_compute_fn():\n    # Wrong compute function\n    with pytest.raises(TypeError):\n        _BaseRegressionEpoch(12345)\n'"
tests/ignite/contrib/metrics/regression/test_canberra_metric.py,8,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import CanberraMetric\n\n\ndef test_wrong_input_shapes():\n    m = CanberraMetric()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_compute():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n\n    m = CanberraMetric()\n\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n    np_sum = (np.abs(ground_truth - a) / (a + ground_truth)).sum()\n    assert m.compute() == pytest.approx(np_sum)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    np_sum += ((np.abs(ground_truth - b)) / (b + ground_truth)).sum()\n    assert m.compute() == pytest.approx(np_sum)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    np_sum += ((np.abs(ground_truth - c)) / (c + ground_truth)).sum()\n    assert m.compute() == pytest.approx(np_sum)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    np_sum += (np.abs(ground_truth - d) / (d + ground_truth)).sum()\n    assert m.compute() == pytest.approx(np_sum)\n'"
tests/ignite/contrib/metrics/regression/test_fractional_absolute_error.py,8,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import FractionalAbsoluteError\nfrom ignite.exceptions import NotComputableError\n\n\ndef test_zero_div():\n    m = FractionalAbsoluteError()\n    with pytest.raises(NotComputableError):\n        m.compute()\n\n\ndef test_wrong_input_shapes():\n    m = FractionalAbsoluteError()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_compute():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n\n    m = FractionalAbsoluteError()\n\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n    np_sum = (2 * np.abs((a - ground_truth)) / (np.abs(a) + np.abs(ground_truth))).sum()\n    np_len = len(a)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    np_sum += (2 * np.abs((b - ground_truth)) / (np.abs(b) + np.abs(ground_truth))).sum()\n    np_len += len(b)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    np_sum += (2 * np.abs((c - ground_truth)) / (np.abs(c) + np.abs(ground_truth))).sum()\n    np_len += len(c)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    np_sum += (2 * np.abs((d - ground_truth)) / (np.abs(d) + np.abs(ground_truth))).sum()\n    np_len += len(d)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n'"
tests/ignite/contrib/metrics/regression/test_fractional_bias.py,8,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import FractionalBias\nfrom ignite.exceptions import NotComputableError\n\n\ndef test_zero_div():\n    m = FractionalBias()\n    with pytest.raises(NotComputableError):\n        m.compute()\n\n\ndef test_wrong_input_shapes():\n    m = FractionalBias()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_fractional_bias():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n\n    m = FractionalBias()\n\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n    np_sum = (2 * (ground_truth - a) / (a + ground_truth)).sum()\n    np_len = len(a)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    np_sum += (2 * (ground_truth - b) / (b + ground_truth)).sum()\n    np_len += len(b)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    np_sum += (2 * (ground_truth - c) / (c + ground_truth)).sum()\n    np_len += len(c)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    np_sum += (2 * (ground_truth - d) / (d + ground_truth)).sum()\n    np_len += len(d)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n'"
tests/ignite/contrib/metrics/regression/test_geometric_mean_absolute_error.py,8,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import GeometricMeanAbsoluteError\nfrom ignite.exceptions import NotComputableError\n\n\ndef test_zero_div():\n    m = GeometricMeanAbsoluteError()\n    with pytest.raises(NotComputableError):\n        m.compute()\n\n\ndef test_wrong_input_shapes():\n    m = GeometricMeanAbsoluteError()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_compute():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n    np_prod = 1.0\n\n    m = GeometricMeanAbsoluteError()\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n\n    errors = np.abs(ground_truth - a)\n    np_prod = np.multiply.reduce(errors) * np_prod\n    np_len = len(a)\n    np_ans = np.power(np_prod, 1.0 / np_len)\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    errors = np.abs(ground_truth - b)\n    np_prod = np.multiply.reduce(errors) * np_prod\n    np_len += len(b)\n    np_ans = np.power(np_prod, 1.0 / np_len)\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    errors = np.abs(ground_truth - c)\n    np_prod = np.multiply.reduce(errors) * np_prod\n    np_len += len(c)\n    np_ans = np.power(np_prod, 1.0 / np_len)\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    errors = np.abs(ground_truth - d)\n    np_prod = np.multiply.reduce(errors) * np_prod\n    np_len += len(d)\n    np_ans = np.power(np_prod, 1.0 / np_len)\n    assert m.compute() == pytest.approx(np_ans)\n'"
tests/ignite/contrib/metrics/regression/test_geometric_mean_relative_absolute_error.py,9,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import GeometricMeanRelativeAbsoluteError\nfrom ignite.engine import Engine\n\n\ndef test_wrong_input_shapes():\n    m = GeometricMeanRelativeAbsoluteError()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_geometric_mean_relative_absolute_error():\n    size = 51\n    np_y_pred = np.random.rand(size,)\n    np_y = np.random.rand(size,)\n    np_gmrae = np.exp(np.log(np.abs(np_y - np_y_pred) / np.abs(np_y - np_y.mean())).mean())\n\n    m = GeometricMeanRelativeAbsoluteError()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    m.update((y_pred, y))\n\n    assert np_gmrae == pytest.approx(m.compute())\n\n\ndef test_geometric_mean_relative_absolute_error_2():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n\n    np_y_sum = 0\n    num_examples = 0\n    num_sum_of_errors = 0\n    np_gmrae = 0\n\n    m = GeometricMeanRelativeAbsoluteError()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    n_iters = 15\n    batch_size = size // n_iters\n    for i in range(n_iters + 1):\n        idx = i * batch_size\n        np_y_i = np_y[idx : idx + batch_size]\n        np_y_pred_i = np_y_pred[idx : idx + batch_size]\n\n        np_y_sum += np_y_i.sum()\n        num_examples += np_y_i.shape[0]\n        np_mean = np_y_sum / num_examples\n\n        np_gmrae += np.log(np.abs(np_y_i - np_y_pred_i) / np.abs(np_y_i - np_mean)).sum()\n        m.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n    assert np.exp(np_gmrae / num_examples) == pytest.approx(m.compute())\n\n\ndef test_integration_geometric_mean_relative_absolute_error_with_output_transform():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n\n    np_y_sum = 0\n    num_examples = 0\n    num_sum_of_errors = 0\n    np_gmrae = 0\n\n    n_iters = 15\n    batch_size = size // n_iters\n    for i in range(n_iters + 1):\n        idx = i * batch_size\n        np_y_i = np_y[idx : idx + batch_size]\n        np_y_pred_i = np_y_pred[idx : idx + batch_size]\n\n        np_y_sum += np_y_i.sum()\n        num_examples += np_y_i.shape[0]\n        np_mean = np_y_sum / num_examples\n\n        np_gmrae += np.log(np.abs(np_y_i - np_y_pred_i) / np.abs(np_y_i - np_mean)).sum()\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    m = GeometricMeanRelativeAbsoluteError(output_transform=lambda x: (x[1], x[2]))\n    m.attach(engine, ""geometric_mean_relative_absolute_error"")\n\n    data = list(range(size // batch_size))\n    gmrae = engine.run(data, max_epochs=1).metrics[""geometric_mean_relative_absolute_error""]\n\n    assert np.exp(np_gmrae / num_examples) == pytest.approx(m.compute())\n'"
tests/ignite/contrib/metrics/regression/test_manhattan_distance.py,8,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import ManhattanDistance\n\n\ndef test_wrong_input_shapes():\n    m = ManhattanDistance()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_mahattan_distance():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n\n    m = ManhattanDistance()\n\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n    np_ans = (ground_truth - a).sum()\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    np_ans += (ground_truth - b).sum()\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    np_ans += (ground_truth - c).sum()\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    np_ans += (ground_truth - d).sum()\n    assert m.compute() == pytest.approx(np_ans)\n'"
tests/ignite/contrib/metrics/regression/test_maximum_absolute_error.py,8,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import MaximumAbsoluteError\nfrom ignite.exceptions import NotComputableError\n\n\ndef test_zero_div():\n    m = MaximumAbsoluteError()\n    with pytest.raises(NotComputableError):\n        m.compute()\n\n\ndef test_wrong_input_shapes():\n    m = MaximumAbsoluteError()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_maximum_absolute_error():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n\n    m = MaximumAbsoluteError()\n\n    np_ans = -1\n\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n    np_max = np.max(np.abs((a - ground_truth)))\n    np_ans = np_max if np_max > np_ans else np_ans\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    np_max = np.max(np.abs((b - ground_truth)))\n    np_ans = np_max if np_max > np_ans else np_ans\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    np_max = np.max(np.abs((c - ground_truth)))\n    np_ans = np_max if np_max > np_ans else np_ans\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    np_max = np.max(np.abs((d - ground_truth)))\n    np_ans = np_max if np_max > np_ans else np_ans\n    assert m.compute() == pytest.approx(np_ans)\n'"
tests/ignite/contrib/metrics/regression/test_mean_absolute_relative_error.py,15,"b'import torch\nfrom pytest import approx, raises\n\nfrom ignite.contrib.metrics.regression import MeanAbsoluteRelativeError\nfrom ignite.exceptions import NotComputableError\n\n\ndef test_wrong_input_shapes():\n    m = MeanAbsoluteRelativeError()\n\n    with raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_mean_absolute_relative_error():\n    a = torch.rand(4)\n    b = torch.rand(4)\n    c = torch.rand(4)\n    d = torch.rand(4)\n    ground_truth = torch.rand(4)\n\n    m = MeanAbsoluteRelativeError()\n\n    m.update((a, ground_truth))\n    abs_error_a = torch.sum(torch.abs(ground_truth - a) / torch.abs(ground_truth))\n    num_samples_a = a.size()[0]\n    sum_error = abs_error_a\n    sum_samples = num_samples_a\n    MARE_a = sum_error / sum_samples\n    assert m.compute() == approx(MARE_a.item())\n\n    m.update((b, ground_truth))\n    abs_error_b = torch.sum(torch.abs(ground_truth - b) / torch.abs(ground_truth))\n    num_samples_b = b.size()[0]\n    sum_error += abs_error_b\n    sum_samples += num_samples_b\n    MARE_b = sum_error / sum_samples\n    assert m.compute() == approx(MARE_b.item())\n\n    m.update((c, ground_truth))\n    abs_error_c = torch.sum(torch.abs(ground_truth - c) / torch.abs(ground_truth))\n    num_samples_c = c.size()[0]\n    sum_error += abs_error_c\n    sum_samples += num_samples_c\n    MARE_c = sum_error / sum_samples\n    assert m.compute() == approx(MARE_c.item())\n\n    m.update((d, ground_truth))\n    abs_error_d = torch.sum(torch.abs(ground_truth - d) / torch.abs(ground_truth))\n    num_samples_d = d.size()[0]\n    sum_error += abs_error_d\n    sum_samples += num_samples_d\n    MARE_d = sum_error / sum_samples\n    assert m.compute() == approx(MARE_d.item())\n\n\ndef test_zero_div():\n    a = torch.tensor([2.0, -1.0, -1.0, 2.0])\n    ground_truth = torch.tensor([0.0, 0.5, 0.2, 1.0])\n\n    m = MeanAbsoluteRelativeError()\n    with raises(NotComputableError):\n        m.update((a, ground_truth))\n\n\ndef test_zero_sample():\n    m = MeanAbsoluteRelativeError()\n    with raises(NotComputableError):\n        m.compute()\n'"
tests/ignite/contrib/metrics/regression/test_mean_error.py,8,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import MeanError\nfrom ignite.exceptions import NotComputableError\n\n\ndef test_zero_div():\n    m = MeanError()\n    with pytest.raises(NotComputableError):\n        m.compute()\n\n\ndef test_wrong_input_shapes():\n    m = MeanError()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_mean_error():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n\n    m = MeanError()\n\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n    np_sum = (ground_truth - a).sum()\n    np_len = len(a)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    np_sum += (ground_truth - b).sum()\n    np_len += len(b)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    np_sum += (ground_truth - c).sum()\n    np_len += len(c)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    np_sum += (ground_truth - d).sum()\n    np_len += len(d)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n'"
tests/ignite/contrib/metrics/regression/test_mean_normalized_bias.py,9,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import MeanNormalizedBias\nfrom ignite.exceptions import NotComputableError\n\n\ndef test_zero_div():\n    m = MeanNormalizedBias()\n    with pytest.raises(NotComputableError):\n        m.compute()\n\n\ndef test_zero_gt():\n    a = np.random.randn(4)\n    ground_truth = np.zeros(4)\n\n    m = MeanNormalizedBias()\n\n    with pytest.raises(NotComputableError):\n        m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n\n\ndef test_wrong_input_shapes():\n    m = MeanNormalizedBias()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_mean_error():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n\n    m = MeanNormalizedBias()\n\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n    np_sum = ((ground_truth - a) / ground_truth).sum()\n    np_len = len(a)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    np_sum += ((ground_truth - b) / ground_truth).sum()\n    np_len += len(b)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    np_sum += ((ground_truth - c) / ground_truth).sum()\n    np_len += len(c)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    np_sum += ((ground_truth - d) / ground_truth).sum()\n    np_len += len(d)\n    np_ans = np_sum / np_len\n    assert m.compute() == pytest.approx(np_ans)\n'"
tests/ignite/contrib/metrics/regression/test_median_absolute_error.py,9,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import MedianAbsoluteError\nfrom ignite.engine import Engine\n\n\ndef test_wrong_input_shapes():\n    m = MedianAbsoluteError()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_median_absolute_error():\n\n    # See https://github.com/torch/torch7/pull/182\n    # For even number of elements, PyTorch returns middle element\n    # NumPy returns average of middle elements\n    # Size of dataset will be odd for these tests\n\n    size = 51\n    np_y_pred = np.random.rand(size,)\n    np_y = np.random.rand(size,)\n    np_median_absolute_error = np.median(np.abs(np_y - np_y_pred))\n\n    m = MedianAbsoluteError()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    m.update((y_pred, y))\n\n    assert np_median_absolute_error == pytest.approx(m.compute())\n\n\ndef test_median_absolute_error_2():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n    np_median_absolute_error = np.median(np.abs(np_y - np_y_pred))\n\n    m = MedianAbsoluteError()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    batch_size = 16\n    n_iters = size // batch_size + 1\n    for i in range(n_iters):\n        idx = i * batch_size\n        m.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n    assert np_median_absolute_error == pytest.approx(m.compute())\n\n\ndef test_integration_median_absolute_error_with_output_transform():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n    np_median_absolute_error = np.median(np.abs(np_y - np_y_pred))\n\n    batch_size = 15\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    m = MedianAbsoluteError(output_transform=lambda x: (x[1], x[2]))\n    m.attach(engine, ""median_absolute_error"")\n\n    data = list(range(size // batch_size))\n    median_absolute_error = engine.run(data, max_epochs=1).metrics[""median_absolute_error""]\n\n    assert np_median_absolute_error == pytest.approx(median_absolute_error)\n'"
tests/ignite/contrib/metrics/regression/test_median_absolute_percentage_error.py,9,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import MedianAbsolutePercentageError\nfrom ignite.engine import Engine\n\n\ndef test_wrong_input_shapes():\n    m = MedianAbsolutePercentageError()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_median_absolute_percentage_error():\n\n    # See https://github.com/torch/torch7/pull/182\n    # For even number of elements, PyTorch returns middle element\n    # NumPy returns average of middle elements\n    # Size of dataset will be odd for these tests\n\n    size = 51\n    np_y_pred = np.random.rand(size,)\n    np_y = np.random.rand(size,)\n    np_median_absolute_percentage_error = 100.0 * np.median(np.abs(np_y - np_y_pred) / np.abs(np_y))\n\n    m = MedianAbsolutePercentageError()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    m.update((y_pred, y))\n\n    assert np_median_absolute_percentage_error == pytest.approx(m.compute())\n\n\ndef test_median_absolute_percentage_error_2():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n    np_median_absolute_percentage_error = 100.0 * np.median(np.abs(np_y - np_y_pred) / np.abs(np_y))\n\n    m = MedianAbsolutePercentageError()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    batch_size = 16\n    n_iters = size // batch_size + 1\n    for i in range(n_iters):\n        idx = i * batch_size\n        m.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n    assert np_median_absolute_percentage_error == pytest.approx(m.compute())\n\n\ndef test_integration_median_absolute_percentage_error_with_output_transform():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n    np_median_absolute_percentage_error = 100.0 * np.median(np.abs(np_y - np_y_pred) / np.abs(np_y))\n\n    batch_size = 15\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    m = MedianAbsolutePercentageError(output_transform=lambda x: (x[1], x[2]))\n    m.attach(engine, ""median_absolute_percentage_error"")\n\n    data = list(range(size // batch_size))\n    median_absolute_percentage_error = engine.run(data, max_epochs=1).metrics[""median_absolute_percentage_error""]\n\n    assert np_median_absolute_percentage_error == pytest.approx(median_absolute_percentage_error)\n'"
tests/ignite/contrib/metrics/regression/test_median_relative_absolute_error.py,9,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import MedianRelativeAbsoluteError\nfrom ignite.engine import Engine\n\n\ndef test_wrong_input_shapes():\n    m = MedianRelativeAbsoluteError()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_median_relative_absolute_error():\n\n    # See https://github.com/torch/torch7/pull/182\n    # For even number of elements, PyTorch returns middle element\n    # NumPy returns average of middle elements\n    # Size of dataset will be odd for these tests\n\n    size = 51\n    np_y_pred = np.random.rand(size,)\n    np_y = np.random.rand(size,)\n    np_median_absolute_relative_error = np.median(np.abs(np_y - np_y_pred) / np.abs(np_y - np_y.mean()))\n\n    m = MedianRelativeAbsoluteError()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    m.update((y_pred, y))\n\n    assert np_median_absolute_relative_error == pytest.approx(m.compute())\n\n\ndef test_median_relative_absolute_error_2():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n    np_median_absolute_relative_error = np.median(np.abs(np_y - np_y_pred) / np.abs(np_y - np_y.mean()))\n\n    m = MedianRelativeAbsoluteError()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    batch_size = 16\n    n_iters = size // batch_size + 1\n    for i in range(n_iters + 1):\n        idx = i * batch_size\n        m.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n    assert np_median_absolute_relative_error == pytest.approx(m.compute())\n\n\ndef test_integration_median_relative_absolute_error_with_output_transform():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n    np_median_absolute_relative_error = np.median(np.abs(np_y - np_y_pred) / np.abs(np_y - np_y.mean()))\n\n    batch_size = 15\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    m = MedianRelativeAbsoluteError(output_transform=lambda x: (x[1], x[2]))\n    m.attach(engine, ""median_absolute_relative_error"")\n\n    data = list(range(size // batch_size))\n    median_absolute_relative_error = engine.run(data, max_epochs=1).metrics[""median_absolute_relative_error""]\n\n    assert np_median_absolute_relative_error == pytest.approx(median_absolute_relative_error)\n'"
tests/ignite/contrib/metrics/regression/test_r2_score.py,9,"b'import numpy as np\nimport pytest\nimport torch\nfrom sklearn.metrics import r2_score\n\nfrom ignite.contrib.metrics.regression import R2Score\nfrom ignite.engine import Engine\n\n\ndef test_wrong_input_shapes():\n    m = R2Score()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_r2_score():\n\n    size = 51\n    np_y_pred = np.random.rand(size,)\n    np_y = np.random.rand(size,)\n\n    m = R2Score()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    m.update((y_pred, y))\n\n    assert r2_score(np_y, np_y_pred) == pytest.approx(m.compute())\n\n\ndef test_r2_score_2():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n\n    m = R2Score()\n    y_pred = torch.from_numpy(np_y_pred)\n    y = torch.from_numpy(np_y)\n\n    m.reset()\n    batch_size = 16\n    n_iters = size // batch_size + 1\n    for i in range(n_iters):\n        idx = i * batch_size\n        m.update((y_pred[idx : idx + batch_size], y[idx : idx + batch_size]))\n\n    assert r2_score(np_y, np_y_pred) == pytest.approx(m.compute())\n\n\ndef test_integration_r2_score_with_output_transform():\n\n    np.random.seed(1)\n    size = 105\n    np_y_pred = np.random.rand(size, 1)\n    np_y = np.random.rand(size, 1)\n    np.random.shuffle(np_y)\n\n    batch_size = 15\n\n    def update_fn(engine, batch):\n        idx = (engine.state.iteration - 1) * batch_size\n        y_true_batch = np_y[idx : idx + batch_size]\n        y_pred_batch = np_y_pred[idx : idx + batch_size]\n        return idx, torch.from_numpy(y_pred_batch), torch.from_numpy(y_true_batch)\n\n    engine = Engine(update_fn)\n\n    m = R2Score(output_transform=lambda x: (x[1], x[2]))\n    m.attach(engine, ""r2_score"")\n\n    data = list(range(size // batch_size))\n    r_squared = engine.run(data, max_epochs=1).metrics[""r2_score""]\n\n    assert r2_score(np_y, np_y_pred) == pytest.approx(r_squared)\n'"
tests/ignite/contrib/metrics/regression/test_wave_hedges_distance.py,8,"b'import numpy as np\nimport pytest\nimport torch\n\nfrom ignite.contrib.metrics.regression import WaveHedgesDistance\n\n\ndef test_wrong_input_shapes():\n    m = WaveHedgesDistance()\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4, 1)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1), torch.rand(4, 1, 2)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4, 1, 2), torch.rand(4,)))\n\n    with pytest.raises(ValueError):\n        m.update((torch.rand(4,), torch.rand(4, 1, 2)))\n\n\ndef test_compute():\n    a = np.random.randn(4)\n    b = np.random.randn(4)\n    c = np.random.randn(4)\n    d = np.random.randn(4)\n    ground_truth = np.random.randn(4)\n\n    m = WaveHedgesDistance()\n\n    m.update((torch.from_numpy(a), torch.from_numpy(ground_truth)))\n    np_sum = (np.abs(ground_truth - a) / np.maximum.reduce([a, ground_truth])).sum()\n    assert m.compute() == pytest.approx(np_sum)\n\n    m.update((torch.from_numpy(b), torch.from_numpy(ground_truth)))\n    np_sum += (np.abs(ground_truth - b) / np.maximum.reduce([b, ground_truth])).sum()\n    assert m.compute() == pytest.approx(np_sum)\n\n    m.update((torch.from_numpy(c), torch.from_numpy(ground_truth)))\n    np_sum += (np.abs(ground_truth - c) / np.maximum.reduce([c, ground_truth])).sum()\n    assert m.compute() == pytest.approx(np_sum)\n\n    m.update((torch.from_numpy(d), torch.from_numpy(ground_truth)))\n    np_sum += (np.abs(ground_truth - d) / np.maximum.reduce([d, ground_truth])).sum()\n    assert m.compute() == pytest.approx(np_sum)\n'"
examples/references/classification/imagenet/code/dataflow/__init__.py,0,b''
examples/references/classification/imagenet/code/dataflow/dataloaders.py,3,"b'from typing import Callable, Optional, Tuple, Union\n\nimport numpy as np\nimport cv2\n\nfrom torch.utils.data import DataLoader, Sampler\nfrom torch.utils.data.dataset import Subset\nimport torch.utils.data.distributed as data_dist\nfrom torchvision.datasets import ImageNet\n\n\ndef opencv_loader(path):\n    img = cv2.imread(path)\n    assert img is not None, ""Image at \'{}\' has a problem"".format(path)\n    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n\ndef get_train_val_loaders(\n    root_path: str,\n    train_transforms: Callable,\n    val_transforms: Callable,\n    batch_size: int = 16,\n    num_workers: int = 8,\n    val_batch_size: Optional[int] = None,\n    pin_memory: bool = True,\n    random_seed: Optional[int] = None,\n    train_sampler: Optional[Union[Sampler, str]] = None,\n    val_sampler: Optional[Union[Sampler, str]] = None,\n    limit_train_num_samples: Optional[int] = None,\n    limit_val_num_samples: Optional[int] = None,\n) -> Tuple[DataLoader, DataLoader, DataLoader]:\n\n    train_ds = ImageNet(\n        root_path, split=""train"", transform=lambda sample: train_transforms(image=sample)[""image""], loader=opencv_loader\n    )\n    val_ds = ImageNet(\n        root_path, split=""val"", transform=lambda sample: val_transforms(image=sample)[""image""], loader=opencv_loader\n    )\n\n    if limit_train_num_samples is not None:\n        if random_seed is not None:\n            np.random.seed(random_seed)\n        train_indices = np.random.permutation(len(train_ds))[:limit_train_num_samples]\n        train_ds = Subset(train_ds, train_indices)\n\n    if limit_val_num_samples is not None:\n        val_indices = np.random.permutation(len(val_ds))[:limit_val_num_samples]\n        val_ds = Subset(val_ds, val_indices)\n\n    # random samples for evaluation on training dataset\n    if len(val_ds) < len(train_ds):\n        train_eval_indices = np.random.permutation(len(train_ds))[: len(val_ds)]\n        train_eval_ds = Subset(train_ds, train_eval_indices)\n    else:\n        train_eval_ds = train_ds\n\n    if isinstance(train_sampler, str):\n        assert train_sampler == ""distributed""\n        train_sampler = data_dist.DistributedSampler(train_ds)\n\n    train_eval_sampler = None\n    if isinstance(val_sampler, str):\n        assert val_sampler == ""distributed""\n        val_sampler = data_dist.DistributedSampler(val_ds, shuffle=False)\n        train_eval_sampler = data_dist.DistributedSampler(train_eval_ds, shuffle=False)\n\n    train_loader = DataLoader(\n        train_ds,\n        shuffle=train_sampler is None,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        sampler=train_sampler,\n        pin_memory=pin_memory,\n        drop_last=True,\n    )\n\n    val_batch_size = batch_size * 4 if val_batch_size is None else val_batch_size\n    val_loader = DataLoader(\n        val_ds,\n        shuffle=False,\n        sampler=val_sampler,\n        batch_size=val_batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        drop_last=False,\n    )\n\n    train_eval_loader = DataLoader(\n        train_eval_ds,\n        shuffle=False,\n        sampler=train_eval_sampler,\n        batch_size=val_batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        drop_last=False,\n    )\n\n    return train_loader, val_loader, train_eval_loader\n'"
examples/references/classification/imagenet/code/dataflow/transforms.py,3,"b'from typing import Type, Callable\n\nimport torch\n\n\ndef denormalize(t, mean, std, max_pixel_value=255):\n    assert isinstance(t, torch.Tensor), ""{}"".format(type(t))\n    assert t.ndim == 3\n    d = t.device\n    mean = torch.tensor(mean, device=d).unsqueeze(-1).unsqueeze(-1)\n    std = torch.tensor(std, device=d).unsqueeze(-1).unsqueeze(-1)\n    tensor = std * t + mean\n    tensor *= max_pixel_value\n    return tensor\n'"
examples/references/classification/imagenet/code/dataflow/vis.py,9,"b'from typing import Callable, Optional\nimport numpy as np\n\nimport torch\n\ntry:\n    from image_dataset_viz import render_datapoint\nexcept ImportError:\n    raise RuntimeError(""Install it via pip install --upgrade git+https://github.com/vfdev-5/ImageDatasetViz.git"")\n\n\ndef tensor_to_numpy(t: torch.Tensor) -> np.ndarray:\n    img = t.cpu().numpy().transpose((1, 2, 0))\n    return img.astype(np.uint8)\n\n\ndef make_grid(\n    batch_img: torch.Tensor,\n    batch_preds: torch.Tensor,\n    img_denormalize_fn: Callable,\n    batch_gt: Optional[torch.Tensor] = None,\n):\n    """"""Create a grid from batch image and mask as\n\n        i+l1+gt1  | i+l2+gt2  | i+l3+gt3  | i+l4+gt4  | ...\n\n        where i+l+gt = image + predicted label + ground truth\n\n    Args:\n        batch_img (torch.Tensor) batch of images of any type\n        batch_preds (torch.Tensor) batch of masks\n        img_denormalize_fn (Callable): function to denormalize batch of images\n        batch_gt (torch.Tensor, optional): batch of ground truth masks.\n    """"""\n    assert isinstance(batch_img, torch.Tensor) and isinstance(batch_preds, torch.Tensor)\n    assert len(batch_img) == len(batch_preds), ""{} vs {}"".format(len(batch_img), len(batch_preds))\n    assert batch_preds.ndim == 1, ""{}"".format(batch_preds.ndim)\n\n    if batch_gt is not None:\n        assert isinstance(batch_gt, torch.Tensor)\n        assert len(batch_preds) == len(batch_gt)\n        assert batch_gt.ndim == 1, ""{}"".format(batch_gt.ndim)\n\n    b = batch_img.shape[0]\n    h, w = batch_img.shape[2:]\n\n    le = 1\n    out_image = np.zeros((h * le, w * b, 3), dtype=""uint8"")\n\n    for i in range(b):\n        img = batch_img[i]\n        y_preds = batch_preds[i]\n\n        img = img_denormalize_fn(img)\n        img = tensor_to_numpy(img)\n        pred_label = y_preds.cpu().item()\n\n        target = ""p={}"".format(pred_label)\n\n        if batch_gt is not None:\n            gt_label = batch_gt[i]\n            gt_label = gt_label.cpu().item()\n            target += "" | gt={}"".format(gt_label)\n\n        out_image[0:h, i * w : (i + 1) * w, :] = render_datapoint(img, target, text_size=12)\n\n    return out_image\n'"
examples/references/classification/imagenet/code/scripts/common_training.py,4,"b'# This a training script launched with py_config_runner\n# It should obligatory contain `run(config, **kwargs)` method\n\nimport torch\nimport torch.distributed as dist\n\nfrom apex import amp\nfrom apex.parallel import DistributedDataParallel as DDP\n\nfrom ignite.engine import Engine, Events, _prepare_batch, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, TopKCategoricalAccuracy\n\nfrom ignite.contrib.handlers import ProgressBar\nfrom ignite.contrib.engines import common\n\nfrom py_config_runner.utils import set_seed\n\nfrom utils.handlers import predictions_gt_images_handler\n\n\ndef training(config, local_rank=None, with_mlflow_logging=False, with_plx_logging=False):\n\n    if not getattr(config, ""use_fp16"", True):\n        raise RuntimeError(""This training script uses by default fp16 AMP"")\n\n    set_seed(config.seed + local_rank)\n    torch.cuda.set_device(local_rank)\n    device = ""cuda""\n\n    torch.backends.cudnn.benchmark = True\n\n    train_loader = config.train_loader\n    train_sampler = getattr(train_loader, ""sampler"", None)\n    assert train_sampler is not None, ""Train loader of type \'{}\' "" ""should have attribute \'sampler\'"".format(\n        type(train_loader)\n    )\n    assert hasattr(train_sampler, ""set_epoch"") and callable(\n        train_sampler.set_epoch\n    ), ""Train sampler should have a callable method `set_epoch`""\n\n    train_eval_loader = config.train_eval_loader\n    val_loader = config.val_loader\n\n    model = config.model.to(device)\n    optimizer = config.optimizer\n    model, optimizer = amp.initialize(model, optimizer, opt_level=getattr(config, ""fp16_opt_level"", ""O2""), num_losses=1)\n    model = DDP(model, delay_allreduce=True)\n    criterion = config.criterion.to(device)\n\n    prepare_batch = getattr(config, ""prepare_batch"", _prepare_batch)\n    non_blocking = getattr(config, ""non_blocking"", True)\n\n    # Setup trainer\n    accumulation_steps = getattr(config, ""accumulation_steps"", 1)\n    model_output_transform = getattr(config, ""model_output_transform"", lambda x: x)\n\n    def train_update_function(engine, batch):\n\n        model.train()\n\n        x, y = prepare_batch(batch, device=device, non_blocking=non_blocking)\n        y_pred = model(x)\n        y_pred = model_output_transform(y_pred)\n        loss = criterion(y_pred, y) / accumulation_steps\n\n        with amp.scale_loss(loss, optimizer, loss_id=0) as scaled_loss:\n            scaled_loss.backward()\n\n        if engine.state.iteration % accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n\n        return {\n            ""supervised batch loss"": loss.item(),\n        }\n\n    trainer = Engine(train_update_function)\n\n    lr_scheduler = config.lr_scheduler\n    to_save = {""model"": model, ""optimizer"": optimizer, ""lr_scheduler"": lr_scheduler, ""trainer"": trainer}\n    common.setup_common_training_handlers(\n        trainer,\n        train_sampler,\n        to_save=to_save,\n        save_every_iters=1000,\n        output_path=config.output_path.as_posix(),\n        lr_scheduler=lr_scheduler,\n        with_gpu_stats=True,\n        output_names=[""supervised batch loss"",],\n        with_pbars=True,\n        with_pbar_on_iters=with_mlflow_logging,\n        log_every_iters=1,\n    )\n\n    if getattr(config, ""benchmark_dataflow"", False):\n        benchmark_dataflow_num_iters = getattr(config, ""benchmark_dataflow_num_iters"", 1000)\n        DataflowBenchmark(benchmark_dataflow_num_iters, prepare_batch=prepare_batch, device=device).attach(\n            trainer, train_loader\n        )\n\n    # Setup evaluators\n    val_metrics = {\n        ""Accuracy"": Accuracy(device=device),\n        ""Top-5 Accuracy"": TopKCategoricalAccuracy(k=5, device=device),\n    }\n\n    if hasattr(config, ""val_metrics"") and isinstance(config.val_metrics, dict):\n        val_metrics.update(config.val_metrics)\n\n    model_output_transform = getattr(config, ""model_output_transform"", lambda x: x)\n\n    evaluator_args = dict(\n        model=model,\n        metrics=val_metrics,\n        device=device,\n        non_blocking=non_blocking,\n        prepare_batch=prepare_batch,\n        output_transform=lambda x, y, y_pred: (model_output_transform(y_pred), y,),\n    )\n    train_evaluator = create_supervised_evaluator(**evaluator_args)\n    evaluator = create_supervised_evaluator(**evaluator_args)\n\n    if dist.get_rank() == 0 and with_mlflow_logging:\n        ProgressBar(persist=False, desc=""Train Evaluation"").attach(train_evaluator)\n        ProgressBar(persist=False, desc=""Val Evaluation"").attach(evaluator)\n\n    def run_validation(_):\n        train_evaluator.run(train_eval_loader)\n        evaluator.run(val_loader)\n\n    if getattr(config, ""start_by_validation"", False):\n        trainer.add_event_handler(Events.STARTED, run_validation)\n    trainer.add_event_handler(Events.EPOCH_COMPLETED(every=getattr(config, ""val_interval"", 1)), run_validation)\n    trainer.add_event_handler(Events.COMPLETED, run_validation)\n\n    score_metric_name = ""Accuracy""\n\n    if hasattr(config, ""es_patience""):\n        common.add_early_stopping_by_val_score(config.es_patience, evaluator, trainer, metric_name=score_metric_name)\n\n    if dist.get_rank() == 0:\n\n        tb_logger = common.setup_tb_logging(\n            config.output_path.as_posix(),\n            trainer,\n            optimizer,\n            evaluators={""training"": train_evaluator, ""validation"": evaluator},\n        )\n        if with_mlflow_logging:\n            common.setup_mlflow_logging(\n                trainer, optimizer, evaluators={""training"": train_evaluator, ""validation"": evaluator}\n            )\n\n        if with_plx_logging:\n            common.setup_plx_logging(\n                trainer, optimizer, evaluators={""training"": train_evaluator, ""validation"": evaluator}\n            )\n\n        common.save_best_model_by_val_score(\n            config.output_path.as_posix(), evaluator, model, metric_name=score_metric_name, trainer=trainer\n        )\n\n        # Log train/val predictions:\n        tb_logger.attach(\n            evaluator,\n            log_handler=predictions_gt_images_handler(\n                img_denormalize_fn=config.img_denormalize, n_images=15, another_engine=trainer, prefix_tag=""validation""\n            ),\n            event_name=Events.ITERATION_COMPLETED(once=len(val_loader) // 2),\n        )\n\n        tb_logger.attach(\n            train_evaluator,\n            log_handler=predictions_gt_images_handler(\n                img_denormalize_fn=config.img_denormalize, n_images=15, another_engine=trainer, prefix_tag=""training""\n            ),\n            event_name=Events.ITERATION_COMPLETED(once=len(train_eval_loader) // 2),\n        )\n\n    trainer.run(train_loader, max_epochs=config.num_epochs)\n\n\nclass DataflowBenchmark:\n    def __init__(self, num_iters=100, prepare_batch=None, device=""cuda""):\n\n        from ignite.handlers import Timer\n\n        def upload_to_gpu(engine, batch):\n            if prepare_batch is not None:\n                x, y = prepare_batch(batch, device=device, non_blocking=False)\n\n        self.num_iters = num_iters\n        self.benchmark_dataflow = Engine(upload_to_gpu)\n\n        @self.benchmark_dataflow.on(Events.ITERATION_COMPLETED(once=num_iters))\n        def stop_benchmark_dataflow(engine):\n            engine.terminate()\n\n        if dist.is_available() and dist.get_rank() == 0:\n\n            @self.benchmark_dataflow.on(Events.ITERATION_COMPLETED(every=num_iters // 100))\n            def show_progress_benchmark_dataflow(engine):\n                print(""."", end="" "")\n\n        self.timer = Timer(average=False)\n        self.timer.attach(\n            self.benchmark_dataflow,\n            start=Events.EPOCH_STARTED,\n            resume=Events.ITERATION_STARTED,\n            pause=Events.ITERATION_COMPLETED,\n            step=Events.ITERATION_COMPLETED,\n        )\n\n    def attach(self, trainer, train_loader):\n\n        from torch.utils.data import DataLoader\n\n        @trainer.on(Events.STARTED)\n        def run_benchmark(_):\n            if dist.is_available() and dist.get_rank() == 0:\n                print(""-"" * 50)\n                print("" - Dataflow benchmark"")\n\n            self.benchmark_dataflow.run(train_loader)\n            t = self.timer.value()\n\n            if dist.is_available() and dist.get_rank() == 0:\n                print("" "")\n                print("" Total time ({} iterations) : {:.5f} seconds"".format(self.num_iters, t))\n                print("" time per iteration         : {} seconds"".format(t / self.num_iters))\n\n                if isinstance(train_loader, DataLoader):\n                    num_images = train_loader.batch_size * self.num_iters\n                    print("" number of images / s       : {}"".format(num_images / t))\n\n                print(""-"" * 50)\n'"
examples/references/classification/imagenet/code/scripts/mlflow_training.py,4,"b'# This a training script launched with py_config_runner\n# It should obligatory contain `run(config, **kwargs)` method\n\nfrom pathlib import Path\n\nimport torch\nimport torch.distributed as dist\n\nimport mlflow\nimport ignite\n\nfrom py_config_runner.config_utils import get_params, TRAINVAL_CONFIG, assert_config\n\nfrom common_training import training\n\n\ndef run(config, logger=None, local_rank=0, **kwargs):\n\n    assert torch.cuda.is_available()\n    assert torch.backends.cudnn.enabled, ""Nvidia/Amp requires cudnn backend to be enabled.""\n\n    dist.init_process_group(""nccl"", init_method=""env://"")\n\n    # As we passed config with option --manual_config_load\n    assert hasattr(config, ""setup""), (\n        ""We need to manually setup the configuration, please set --manual_config_load "" ""to py_config_runner""\n    )\n\n    config = config.setup()\n\n    assert_config(config, TRAINVAL_CONFIG)\n    # The following attributes are automatically added by py_config_runner\n    assert hasattr(config, ""config_filepath"") and isinstance(config.config_filepath, Path)\n    assert hasattr(config, ""script_filepath"") and isinstance(config.script_filepath, Path)\n\n    # dump python files to reproduce the run\n    mlflow.log_artifact(config.config_filepath.as_posix())\n    mlflow.log_artifact(config.script_filepath.as_posix())\n\n    output_path = mlflow.get_artifact_uri()\n    config.output_path = Path(output_path)\n\n    if dist.get_rank() == 0:\n        mlflow.log_params(\n            {""pytorch version"": torch.__version__, ""ignite version"": ignite.__version__,}\n        )\n        mlflow.log_params(get_params(config, TRAINVAL_CONFIG))\n\n    try:\n        training(config, local_rank=local_rank, with_mlflow_logging=True, with_plx_logging=False)\n    except KeyboardInterrupt:\n        logger.info(""Catched KeyboardInterrupt -> exit"")\n    except Exception as e:  # noqa\n        logger.exception("""")\n        mlflow.log_param(""Run Status"", ""FAILED"")\n        dist.destroy_process_group()\n        raise e\n\n    mlflow.log_param(""Run Status"", ""OK"")\n    dist.destroy_process_group()\n'"
examples/references/classification/imagenet/code/scripts/plx_training.py,4,"b'# This a training script launched with py_config_runner\n# It should obligatory contain `run(config, **kwargs)` method\n\nfrom pathlib import Path\n\nimport torch\nimport torch.distributed as dist\n\nimport ignite\nfrom polyaxon_client.tracking import get_outputs_path, Experiment\n\nfrom py_config_runner.config_utils import get_params, TRAINVAL_CONFIG, assert_config\n\nfrom common_training import training\n\n\ndef run(config, logger=None, local_rank=0, **kwargs):\n\n    assert torch.cuda.is_available(), torch.cuda.is_available()\n    assert torch.backends.cudnn.enabled, ""Nvidia/Amp requires cudnn backend to be enabled.""\n\n    dist.init_process_group(""nccl"", init_method=""env://"")\n\n    # As we passed config with option --manual_config_load\n    assert hasattr(config, ""setup""), (\n        ""We need to manually setup the configuration, please set --manual_config_load "" ""to py_config_runner""\n    )\n\n    config = config.setup()\n\n    assert_config(config, TRAINVAL_CONFIG)\n    # The following attributes are automatically added by py_config_runner\n    assert hasattr(config, ""config_filepath"") and isinstance(config.config_filepath, Path)\n    assert hasattr(config, ""script_filepath"") and isinstance(config.script_filepath, Path)\n\n    config.output_path = Path(get_outputs_path())\n\n    if dist.get_rank() == 0:\n        plx_exp = Experiment()\n        plx_exp.log_params(\n            **{""pytorch version"": torch.__version__, ""ignite version"": ignite.__version__,}\n        )\n        plx_exp.log_params(**get_params(config, TRAINVAL_CONFIG))\n\n    try:\n        training(config, local_rank=local_rank, with_mlflow_logging=False, with_plx_logging=True)\n    except KeyboardInterrupt:\n        logger.info(""Catched KeyboardInterrupt -> exit"")\n    except Exception as e:  # noqa\n        logger.exception("""")\n        dist.destroy_process_group()\n        raise e\n\n    dist.destroy_process_group()\n'"
examples/references/classification/imagenet/code/utils/__init__.py,0,b''
examples/references/classification/imagenet/code/utils/handlers.py,2,"b'import torch\n\nfrom dataflow.vis import make_grid\n\n\ndef predictions_gt_images_handler(img_denormalize_fn, n_images=None, another_engine=None, prefix_tag=None):\n    def wrapper(engine, logger, event_name):\n        batch = engine.state.batch\n        output = engine.state.output\n        x, y = batch\n        y_pred = output[0]\n\n        if y.shape == y_pred.shape and y.ndim == 4:\n            # Case of y of shape (B, C, H, W)\n            y = torch.argmax(y, dim=1)\n\n        y_pred = torch.argmax(y_pred, dim=1).byte()\n\n        if n_images is not None:\n            x = x[:n_images, ...]\n            y = y[:n_images, ...]\n            y_pred = y_pred[:n_images, ...]\n\n        grid_pred_gt = make_grid(x, y_pred, img_denormalize_fn, batch_gt=y)\n\n        state = engine.state if another_engine is None else another_engine.state\n        global_step = state.get_event_attrib_value(event_name)\n\n        tag = ""predictions_with_gt""\n        if prefix_tag is not None:\n            tag = ""{}: {}"".format(prefix_tag, tag)\n        logger.writer.add_image(tag=tag, img_tensor=grid_pred_gt, global_step=global_step, dataformats=""HWC"")\n\n    return wrapper\n'"
examples/references/classification/imagenet/configs/train/baseline_resnet50.py,4,"b'# Basic training configuration\nimport os\nfrom functools import partial\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lrs\nimport torch.distributed as dist\n\nfrom torchvision.models.resnet import resnet50\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2 as ToTensor\n\nfrom dataflow.dataloaders import get_train_val_loaders\nfrom dataflow.transforms import denormalize\n\n# ##############################\n# Global configs\n# ##############################\n\nseed = 19\ndevice = ""cuda""\ndebug = False\n\n# config to measure time passed to prepare batches and report measured time before the training\nbenchmark_dataflow = True\nbenchmark_dataflow_num_iters = 100\n\nfp16_opt_level = ""O2""\nval_interval = 2\n\ntrain_crop_size = 224\nval_crop_size = 320\n\nbatch_size = 64  # batch size per local rank\nnum_workers = 10  # num_workers per local rank\n\n\n# ##############################\n# Setup Dataflow\n# ##############################\n\nassert ""DATASET_PATH"" in os.environ\ndata_path = os.environ[""DATASET_PATH""]\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transforms = A.Compose(\n    [\n        A.RandomResizedCrop(train_crop_size, train_crop_size, scale=(0.08, 1.0)),\n        A.HorizontalFlip(),\n        A.CoarseDropout(max_height=32, max_width=32),\n        A.HueSaturationValue(),\n        A.Normalize(mean=mean, std=std),\n        ToTensor(),\n    ]\n)\n\nval_transforms = A.Compose(\n    [\n        # https://github.com/facebookresearch/FixRes/blob/b27575208a7c48a3a6e0fa9efb57baa4021d1305/imnet_resnet50_scratch/transforms.py#L76\n        A.Resize(int((256 / 224) * val_crop_size), int((256 / 224) * val_crop_size)),\n        A.CenterCrop(val_crop_size, val_crop_size),\n        A.Normalize(mean=mean, std=std),\n        ToTensor(),\n    ]\n)\n\ntrain_loader, val_loader, train_eval_loader = get_train_val_loaders(\n    data_path,\n    train_transforms=train_transforms,\n    val_transforms=val_transforms,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    val_batch_size=batch_size,\n    pin_memory=True,\n    train_sampler=""distributed"",\n    val_sampler=""distributed"",\n)\n\n# Image denormalization function to plot predictions with images\nimg_denormalize = partial(denormalize, mean=mean, std=std)\n\n# ##############################\n# Setup Model\n# ##############################\n\nmodel = resnet50(pretrained=False)\n\n\n# ##############################\n# Setup Solver\n# ##############################\n\nnum_epochs = 105\n\ncriterion = nn.CrossEntropyLoss()\n\nle = len(train_loader)\n\nbase_lr = 0.1 * (batch_size * dist.get_world_size() / 256.0)\noptimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\nlr_scheduler = lrs.MultiStepLR(optimizer, milestones=[30 * le, 60 * le, 90 * le, 100 * le], gamma=0.1)\n'"
examples/references/classification/imagenet/configs/train/check_baseline_resnet50.py,4,"b'# Basic training configuration\nimport os\nfrom functools import partial\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lrs\nimport torch.distributed as dist\n\nfrom torchvision.models.resnet import resnet50\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2 as ToTensor\n\nfrom dataflow.dataloaders import get_train_val_loaders\nfrom dataflow.transforms import denormalize\n\n# ##############################\n# Global configs\n# ##############################\n\nseed = 19\ndevice = ""cuda""\ndebug = False\n\n# config to measure time passed to prepare batches and report measured time before the training\nbenchmark_dataflow = True\nbenchmark_dataflow_num_iters = 100\n\nfp16_opt_level = ""O2""\nval_interval = 2\n\ntrain_crop_size = 224\nval_crop_size = 320\n\nbatch_size = 64  # batch size per local rank\nnum_workers = 10  # num_workers per local rank\n\n\n# ##############################\n# Setup Dataflow\n# ##############################\n\nassert ""DATASET_PATH"" in os.environ\ndata_path = os.environ[""DATASET_PATH""]\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transforms = A.Compose(\n    [\n        A.RandomResizedCrop(train_crop_size, train_crop_size, scale=(0.08, 1.0)),\n        A.HorizontalFlip(),\n        A.CoarseDropout(max_height=32, max_width=32),\n        A.HueSaturationValue(),\n        A.Normalize(mean=mean, std=std),\n        ToTensor(),\n    ]\n)\n\nval_transforms = A.Compose(\n    [\n        # https://github.com/facebookresearch/FixRes/blob/b27575208a7c48a3a6e0fa9efb57baa4021d1305/imnet_resnet50_scratch/transforms.py#L76\n        A.Resize(int((256 / 224) * val_crop_size), int((256 / 224) * val_crop_size)),\n        A.CenterCrop(val_crop_size, val_crop_size),\n        A.Normalize(mean=mean, std=std),\n        ToTensor(),\n    ]\n)\n\ntrain_loader, val_loader, train_eval_loader = get_train_val_loaders(\n    data_path,\n    train_transforms=train_transforms,\n    val_transforms=val_transforms,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    val_batch_size=batch_size,\n    pin_memory=True,\n    train_sampler=""distributed"",\n    val_sampler=""distributed"",\n)\n\n# Image denormalization function to plot predictions with images\nimg_denormalize = partial(denormalize, mean=mean, std=std)\n\n# ##############################\n# Setup Model\n# ##############################\n\nmodel = resnet50(pretrained=False)\n\n\n# ##############################\n# Setup Solver\n# ##############################\n\nnum_epochs = 1\n\ncriterion = nn.CrossEntropyLoss()\n\nle = len(train_loader)\n\nbase_lr = 0.1 * (batch_size * dist.get_world_size() / 256.0)\noptimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\nlr_scheduler = lrs.MultiStepLR(optimizer, milestones=[30 * le, 60 * le, 90 * le, 100 * le], gamma=0.1)\n'"
examples/references/segmentation/pascal_voc2012/code/dataflow/__init__.py,0,b''
examples/references/segmentation/pascal_voc2012/code/dataflow/dataloaders.py,3,"b'from typing import Callable, Optional, Tuple, Union\n\nimport numpy as np\n\nfrom torch.utils.data import DataLoader, Sampler\nfrom torch.utils.data.dataset import Subset, ConcatDataset\nimport torch.utils.data.distributed as data_dist\n\nfrom dataflow.datasets import get_train_dataset, get_val_dataset, TransformedDataset, get_train_noval_sbdataset\n\n\ndef get_train_val_loaders(\n    root_path: str,\n    train_transforms: Callable,\n    val_transforms: Callable,\n    batch_size: int = 16,\n    num_workers: int = 8,\n    val_batch_size: Optional[int] = None,\n    pin_memory: bool = True,\n    random_seed: Optional[int] = None,\n    train_sampler: Optional[Union[Sampler, str]] = None,\n    val_sampler: Optional[Union[Sampler, str]] = None,\n    with_sbd: Optional[str] = None,\n    limit_train_num_samples: Optional[int] = None,\n    limit_val_num_samples: Optional[int] = None,\n) -> Tuple[DataLoader, DataLoader, DataLoader]:\n\n    train_ds = get_train_dataset(root_path)\n    val_ds = get_val_dataset(root_path)\n\n    if with_sbd is not None:\n        sbd_train_ds = get_train_noval_sbdataset(with_sbd)\n        train_ds = ConcatDataset([train_ds, sbd_train_ds])\n\n    if random_seed is not None:\n        np.random.seed(random_seed)\n\n    if limit_train_num_samples is not None:\n        train_indices = np.random.permutation(len(train_ds))[:limit_train_num_samples]\n        train_ds = Subset(train_ds, train_indices)\n\n    if limit_val_num_samples is not None:\n        val_indices = np.random.permutation(len(val_ds))[:limit_val_num_samples]\n        val_ds = Subset(val_ds, val_indices)\n\n    # random samples for evaluation on training dataset\n    if len(val_ds) < len(train_ds):\n        train_eval_indices = np.random.permutation(len(train_ds))[: len(val_ds)]\n        train_eval_ds = Subset(train_ds, train_eval_indices)\n    else:\n        train_eval_ds = train_ds\n\n    train_ds = TransformedDataset(train_ds, transform_fn=train_transforms)\n    val_ds = TransformedDataset(val_ds, transform_fn=val_transforms)\n    train_eval_ds = TransformedDataset(train_eval_ds, transform_fn=val_transforms)\n\n    if isinstance(train_sampler, str):\n        assert train_sampler == ""distributed""\n        train_sampler = data_dist.DistributedSampler(train_ds)\n\n    if isinstance(val_sampler, str):\n        assert val_sampler == ""distributed""\n        val_sampler = data_dist.DistributedSampler(val_ds, shuffle=False)\n\n    train_loader = DataLoader(\n        train_ds,\n        shuffle=train_sampler is None,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        sampler=train_sampler,\n        pin_memory=pin_memory,\n        drop_last=True,\n    )\n\n    val_batch_size = batch_size * 4 if val_batch_size is None else val_batch_size\n    val_loader = DataLoader(\n        val_ds,\n        shuffle=False,\n        sampler=val_sampler,\n        batch_size=val_batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        drop_last=False,\n    )\n\n    train_eval_loader = DataLoader(\n        train_eval_ds,\n        shuffle=False,\n        sampler=val_sampler,\n        batch_size=val_batch_size,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n        drop_last=False,\n    )\n\n    return train_loader, val_loader, train_eval_loader\n\n\ndef get_inference_dataloader(\n    root_path: str,\n    mode: str,\n    transforms: Callable,\n    batch_size: int = 16,\n    num_workers: int = 8,\n    pin_memory: bool = True,\n    limit_num_samples: Optional[int] = None,\n) -> DataLoader:\n    assert mode in (""train"", ""test""), ""Mode should be \'train\' or \'test\'""\n\n    get_dataset_fn = get_train_dataset if mode == ""train"" else get_val_dataset\n\n    dataset = get_dataset_fn(root_path, return_meta=True)\n\n    if limit_num_samples is not None:\n        indices = np.random.permutation(len(dataset))[:limit_num_samples]\n        dataset = Subset(dataset, indices)\n\n    dataset = TransformedDataset(dataset, transform_fn=transforms)\n\n    loader = DataLoader(\n        dataset, shuffle=False, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, drop_last=False\n    )\n    return loader\n'"
examples/references/segmentation/pascal_voc2012/code/dataflow/datasets.py,1,"b'from typing import Type, Callable\n\nimport numpy as np\n\nimport cv2\n\nfrom PIL import Image\n\n\nfrom torch.utils.data import Dataset\nfrom torchvision.datasets.voc import VOCSegmentation\nfrom torchvision.datasets.sbd import SBDataset\n\n\nclass TransformedDataset(Dataset):\n    def __init__(self, ds: Dataset, transform_fn: Callable):\n        assert isinstance(ds, Dataset)\n        assert callable(transform_fn)\n        self.ds = ds\n        self.transform_fn = transform_fn\n\n    def __len__(self):\n        return len(self.ds)\n\n    def __getitem__(self, index):\n        dp = self.ds[index]\n        return self.transform_fn(**dp)\n\n\nclass VOCSegmentationOpencv(VOCSegmentation):\n    def __init__(self, *args, return_meta: bool = False, **kwargs):\n        super(VOCSegmentationOpencv, self).__init__(*args, **kwargs)\n        self.return_meta = return_meta\n\n    def __getitem__(self, index):\n        img = cv2.imread(self.images[index])\n        assert img is not None, ""Image at \'{}\' has a problem"".format(self.images[index])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = np.asarray(Image.open(self.masks[index]))\n\n        if self.return_meta:\n            return {\n                ""image"": img,\n                ""mask"": mask,\n                ""meta"": {""index"": index, ""image_path"": self.images[index], ""mask_path"": self.masks[index]},\n            }\n\n        return {""image"": img, ""mask"": mask}\n\n\nclass SBDatasetOpencv(SBDataset):\n    def __init__(self, *args, return_meta: bool = False, **kwargs):\n        super(SBDatasetOpencv, self).__init__(*args, **kwargs)\n        assert self.mode == ""segmentation"", ""SBDatasetOpencv should be in segmentation mode only""\n        self.return_meta = return_meta\n\n    def _get_segmentation_target(self, filepath):\n        mat = self._loadmat(filepath)\n        return mat[""GTcls""][0][""Segmentation""][0]\n\n    def __getitem__(self, index):\n        img = cv2.imread(self.images[index])\n        assert img is not None, ""Image at \'{}\' has a problem"".format(self.images[index])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        mask = self._get_target(self.masks[index])\n\n        if self.return_meta:\n            return {\n                ""image"": img,\n                ""mask"": mask,\n                ""meta"": {""index"": index, ""image_path"": self.images[index], ""mask_path"": self.masks[index]},\n            }\n\n        return {""image"": img, ""mask"": mask}\n\n\ndef get_train_dataset(root_path: str, return_meta: bool = False):\n    return VOCSegmentationOpencv(\n        root=root_path, year=""2012"", image_set=""train"", download=False, return_meta=return_meta\n    )\n\n\ndef get_val_dataset(root_path: str, return_meta: bool = False):\n    return VOCSegmentationOpencv(root=root_path, year=""2012"", image_set=""val"", download=False, return_meta=return_meta)\n\n\ndef get_train_noval_sbdataset(root_path: str, return_meta: bool = False):\n    return SBDatasetOpencv(root_path, image_set=""train_noval"", mode=""segmentation"", return_meta=return_meta)\n'"
examples/references/segmentation/pascal_voc2012/code/dataflow/transforms.py,3,"b'import torch\n\nfrom ignite.utils import convert_tensor\n\n\ndef ignore_mask_boundaries(force_apply, **kwargs):\n    assert ""mask"" in kwargs, ""Input should contain \'mask\'""\n    mask = kwargs[""mask""]\n    mask[mask == 255] = 0\n    kwargs[""mask""] = mask\n    return kwargs\n\n\ndef denormalize(t, mean, std, max_pixel_value=255):\n    assert isinstance(t, torch.Tensor), ""{}"".format(type(t))\n    assert t.ndim == 3\n    d = t.device\n    mean = torch.tensor(mean, device=d).unsqueeze(-1).unsqueeze(-1)\n    std = torch.tensor(std, device=d).unsqueeze(-1).unsqueeze(-1)\n    tensor = std * t + mean\n    tensor *= max_pixel_value\n    return tensor\n\n\ndef prepare_batch_fp32(batch, device, non_blocking):\n    x, y = batch[""image""], batch[""mask""]\n    x = convert_tensor(x, device, non_blocking=non_blocking)\n    y = convert_tensor(y, device, non_blocking=non_blocking).long()\n    return x, y\n'"
examples/references/segmentation/pascal_voc2012/code/dataflow/vis.py,9,"b'from typing import Union, Callable, Optional\n\nimport numpy as np\nfrom PIL import Image\n\nimport torch\n\ntry:\n    from image_dataset_viz import render_datapoint\nexcept ImportError:\n    raise RuntimeError(""Install it via pip install --upgrade git+https://github.com/vfdev-5/ImageDatasetViz.git"")\n\n\ndef _getvocpallete(num_cls):\n    n = num_cls\n    pallete = [0] * (n * 3)\n    for j in range(0, n):\n        lab = j\n        pallete[j * 3 + 0] = 0\n        pallete[j * 3 + 1] = 0\n        pallete[j * 3 + 2] = 0\n        i = 0\n        while lab > 0:\n            pallete[j * 3 + 0] |= ((lab >> 0) & 1) << (7 - i)\n            pallete[j * 3 + 1] |= ((lab >> 1) & 1) << (7 - i)\n            pallete[j * 3 + 2] |= ((lab >> 2) & 1) << (7 - i)\n            i = i + 1\n            lab >>= 3\n    return pallete\n\n\nvocpallete = _getvocpallete(256)\n\n\ndef render_mask(mask: Union[np.ndarray, Image.Image]) -> Image.Image:\n    if isinstance(mask, np.ndarray):\n        mask = Image.fromarray(mask)\n    mask.putpalette(vocpallete)\n    mask = mask.convert(mode=""RGB"")\n    return mask\n\n\ndef tensor_to_rgb(t: torch.Tensor) -> np.ndarray:\n    img = t.cpu().numpy().transpose((1, 2, 0))\n    return img.astype(np.uint8)\n\n\ndef make_grid(\n    batch_img: torch.Tensor,\n    batch_mask: torch.Tensor,\n    img_denormalize_fn: Callable,\n    batch_gt_mask: Optional[torch.Tensor] = None,\n):\n    """"""Create a grid from batch image and mask as\n\n        img1  | img2  | img3  | img4  | ...\n        i+m1  | i+m2  | i+m3  | i+m4  | ...\n        mask1 | mask2 | mask3 | mask4 | ...\n        i+M1  | i+M2  | i+M3  | i+M4  | ...\n        Mask1 | Mask2 | Mask3 | Mask4 | ...\n\n        i+m = image + mask blended with alpha=0.4\n        - maskN is predicted mask\n        - MaskN is ground-truth mask if given\n\n    Args:\n        batch_img (torch.Tensor) batch of images of any type\n        batch_mask (torch.Tensor) batch of masks\n        img_denormalize_fn (Callable): function to denormalize batch of images\n        batch_gt_mask (torch.Tensor, optional): batch of ground truth masks.\n    """"""\n    assert isinstance(batch_img, torch.Tensor) and isinstance(batch_mask, torch.Tensor)\n    assert len(batch_img) == len(batch_mask)\n\n    if batch_gt_mask is not None:\n        assert isinstance(batch_gt_mask, torch.Tensor)\n        assert len(batch_mask) == len(batch_gt_mask)\n\n    b = batch_img.shape[0]\n    h, w = batch_img.shape[2:]\n\n    le = 3 if batch_gt_mask is None else 3 + 2\n    out_image = np.zeros((h * le, w * b, 3), dtype=""uint8"")\n\n    for i in range(b):\n        img = batch_img[i]\n        mask = batch_mask[i]\n\n        img = img_denormalize_fn(img)\n        img = tensor_to_rgb(img)\n        mask = mask.cpu().numpy()\n        mask = render_mask(mask)\n\n        out_image[0:h, i * w : (i + 1) * w, :] = img\n        out_image[1 * h : 2 * h, i * w : (i + 1) * w, :] = render_datapoint(img, mask, blend_alpha=0.4)\n        out_image[2 * h : 3 * h, i * w : (i + 1) * w, :] = mask\n\n        if batch_gt_mask is not None:\n            gt_mask = batch_gt_mask[i]\n            gt_mask = gt_mask.cpu().numpy()\n            gt_mask = render_mask(gt_mask)\n            out_image[3 * h : 4 * h, i * w : (i + 1) * w, :] = render_datapoint(img, gt_mask, blend_alpha=0.4)\n            out_image[4 * h : 5 * h, i * w : (i + 1) * w, :] = gt_mask\n\n    return out_image\n'"
examples/references/segmentation/pascal_voc2012/code/scripts/__init__.py,0,b''
examples/references/segmentation/pascal_voc2012/code/scripts/common_training.py,3,"b'# This a training script launched with py_config_runner\n# It should obligatory contain `run(config, **kwargs)` method\n\nfrom collections.abc import Mapping\n\nimport torch\nimport torch.distributed as dist\n\nfrom apex import amp\nfrom apex.parallel import DistributedDataParallel as DDP\n\nfrom ignite.engine import Engine, Events, _prepare_batch, create_supervised_evaluator\nfrom ignite.metrics import ConfusionMatrix, IoU, mIoU\n\nfrom ignite.contrib.handlers import ProgressBar\nfrom ignite.contrib.engines import common\n\nfrom py_config_runner.utils import set_seed\n\nfrom utils.handlers import predictions_gt_images_handler\n\n\ndef training(config, local_rank=None, with_mlflow_logging=False, with_plx_logging=False, with_trains_logging=False):\n\n    if not getattr(config, ""use_fp16"", True):\n        raise RuntimeError(""This training script uses by default fp16 AMP"")\n\n    set_seed(config.seed + local_rank)\n    torch.cuda.set_device(local_rank)\n    device = ""cuda""\n\n    torch.backends.cudnn.benchmark = True\n\n    train_loader = config.train_loader\n    train_sampler = getattr(train_loader, ""sampler"", None)\n    assert train_sampler is not None, ""Train loader of type \'{}\' "" ""should have attribute \'sampler\'"".format(\n        type(train_loader)\n    )\n    assert hasattr(train_sampler, ""set_epoch"") and callable(\n        train_sampler.set_epoch\n    ), ""Train sampler should have a callable method `set_epoch`""\n\n    train_eval_loader = config.train_eval_loader\n    val_loader = config.val_loader\n\n    model = config.model.to(device)\n    optimizer = config.optimizer\n    model, optimizer = amp.initialize(model, optimizer, opt_level=getattr(config, ""fp16_opt_level"", ""O2""), num_losses=1)\n    model = DDP(model, delay_allreduce=True)\n    criterion = config.criterion.to(device)\n\n    prepare_batch = getattr(config, ""prepare_batch"", _prepare_batch)\n    non_blocking = getattr(config, ""non_blocking"", True)\n\n    # Setup trainer\n    accumulation_steps = getattr(config, ""accumulation_steps"", 1)\n    model_output_transform = getattr(config, ""model_output_transform"", lambda x: x)\n\n    def train_update_function(engine, batch):\n\n        model.train()\n\n        x, y = prepare_batch(batch, device=device, non_blocking=non_blocking)\n        y_pred = model(x)\n        y_pred = model_output_transform(y_pred)\n        loss = criterion(y_pred, y)\n\n        if isinstance(loss, Mapping):\n            assert ""supervised batch loss"" in loss\n            loss_dict = loss\n            output = {k: v.item() for k, v in loss_dict.items()}\n            loss = loss_dict[""supervised batch loss""] / accumulation_steps\n        else:\n            output = {""supervised batch loss"": loss.item()}\n\n        with amp.scale_loss(loss, optimizer, loss_id=0) as scaled_loss:\n            scaled_loss.backward()\n\n        if engine.state.iteration % accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n\n        return output\n\n    output_names = getattr(config, ""output_names"", [""supervised batch loss"",])\n\n    trainer = Engine(train_update_function)\n    common.setup_common_distrib_training_handlers(\n        trainer,\n        train_sampler,\n        to_save={""model"": model, ""optimizer"": optimizer},\n        save_every_iters=1000,\n        output_path=config.output_path.as_posix(),\n        lr_scheduler=config.lr_scheduler,\n        with_gpu_stats=True,\n        output_names=output_names,\n        with_pbars=True,\n        with_pbar_on_iters=with_mlflow_logging,\n        log_every_iters=1,\n    )\n\n    # Setup evaluators\n    num_classes = config.num_classes\n    cm_metric = ConfusionMatrix(num_classes=num_classes)\n\n    val_metrics = {\n        ""IoU"": IoU(cm_metric),\n        ""mIoU_bg"": mIoU(cm_metric),\n    }\n\n    if hasattr(config, ""val_metrics"") and isinstance(config.val_metrics, dict):\n        val_metrics.update(config.val_metrics)\n\n    model_output_transform = getattr(config, ""model_output_transform"", lambda x: x)\n\n    evaluator_args = dict(\n        model=model,\n        metrics=val_metrics,\n        device=device,\n        non_blocking=non_blocking,\n        prepare_batch=prepare_batch,\n        output_transform=lambda x, y, y_pred: (model_output_transform(y_pred), y,),\n    )\n    train_evaluator = create_supervised_evaluator(**evaluator_args)\n    evaluator = create_supervised_evaluator(**evaluator_args)\n\n    if dist.get_rank() == 0 and with_mlflow_logging:\n        ProgressBar(persist=False, desc=""Train Evaluation"").attach(train_evaluator)\n        ProgressBar(persist=False, desc=""Val Evaluation"").attach(evaluator)\n\n    def run_validation(_):\n        train_evaluator.run(train_eval_loader)\n        evaluator.run(val_loader)\n\n    if getattr(config, ""start_by_validation"", False):\n        trainer.add_event_handler(Events.STARTED, run_validation)\n    trainer.add_event_handler(Events.EPOCH_COMPLETED(every=getattr(config, ""val_interval"", 1)), run_validation)\n    trainer.add_event_handler(Events.COMPLETED, run_validation)\n\n    score_metric_name = ""mIoU_bg""\n\n    if hasattr(config, ""es_patience""):\n        common.add_early_stopping_by_val_score(config.es_patience, evaluator, trainer, metric_name=score_metric_name)\n\n    if dist.get_rank() == 0:\n\n        tb_logger = common.setup_tb_logging(\n            config.output_path.as_posix(),\n            trainer,\n            optimizer,\n            evaluators={""training"": train_evaluator, ""validation"": evaluator},\n        )\n        if with_mlflow_logging:\n            common.setup_mlflow_logging(\n                trainer, optimizer, evaluators={""training"": train_evaluator, ""validation"": evaluator}\n            )\n\n        if with_plx_logging:\n            common.setup_plx_logging(\n                trainer, optimizer, evaluators={""training"": train_evaluator, ""validation"": evaluator}\n            )\n\n        if with_trains_logging:\n            common.setup_trains_logging(\n                trainer, optimizer, evaluators={""training"": train_evaluator, ""validation"": evaluator}\n            )\n\n        common.save_best_model_by_val_score(\n            config.output_path.as_posix(), evaluator, model, metric_name=score_metric_name, trainer=trainer\n        )\n\n        # Log train/val predictions:\n        tb_logger.attach(\n            evaluator,\n            log_handler=predictions_gt_images_handler(\n                img_denormalize_fn=config.img_denormalize, n_images=15, another_engine=trainer, prefix_tag=""validation""\n            ),\n            event_name=Events.EPOCH_COMPLETED,\n        )\n\n        log_train_predictions = getattr(config, ""log_train_predictions"", False)\n        if log_train_predictions:\n            tb_logger.attach(\n                train_evaluator,\n                log_handler=predictions_gt_images_handler(\n                    img_denormalize_fn=config.img_denormalize,\n                    n_images=15,\n                    another_engine=trainer,\n                    prefix_tag=""validation"",\n                ),\n                event_name=Events.EPOCH_COMPLETED,\n            )\n\n    trainer.run(train_loader, max_epochs=config.num_epochs)\n'"
examples/references/segmentation/pascal_voc2012/code/scripts/download_dataset.py,0,"b'import os\nimport argparse\n\nfrom torchvision.datasets.voc import VOCSegmentation\nfrom torchvision.datasets.sbd import SBDataset\n\n\nif __name__ == ""__main__"":\n    parser = argparse.ArgumentParser(""Download Pascal VOC 2012 and SBD segmentation datasets"")\n    parser.add_argument(""output_path"", type=str, help=""Path where to download and unzip the dataset"")\n\n    args = parser.parse_args()\n\n    print(""Download Pascal VOC 2012 - Training"")\n    VOCSegmentation(args.output_path, image_set=""train"", download=True)\n    print(""Download Pascal VOC 2012 - Validation"")\n    VOCSegmentation(args.output_path, image_set=""val"", download=True)\n    print(""Download SBD - Training without Pascal VOC validation part"")\n    sbd_path = os.path.join(args.output_path, ""SBD"")\n    os.makedirs(sbd_path, exist_ok=True)\n    SBDataset(sbd_path, image_set=""train_noval"", mode=""segmentation"", download=True)\n    print(""Done"")\n    print(""Pascal VOC 2012 is at : {}"".format(os.path.join(args.output_path, ""VOCdevkit"")))\n    print(""SBD is at : {}"".format(sbd_path))\n'"
examples/references/segmentation/pascal_voc2012/code/scripts/mlflow_training.py,4,"b'# This a training script launched with py_config_runner\n# It should obligatory contain `run(config, **kwargs)` method\n\nfrom pathlib import Path\n\nimport torch\nimport torch.distributed as dist\n\nimport mlflow\nimport ignite\n\nfrom py_config_runner.config_utils import get_params, TRAINVAL_CONFIG, assert_config\n\nfrom common_training import training\n\n\ndef run(config, logger=None, local_rank=0, **kwargs):\n\n    assert torch.cuda.is_available()\n    assert torch.backends.cudnn.enabled, ""Nvidia/Amp requires cudnn backend to be enabled.""\n\n    dist.init_process_group(""nccl"", init_method=""env://"")\n\n    # As we passed config with option --manual_config_load\n    assert hasattr(config, ""setup""), (\n        ""We need to manually setup the configuration, please set --manual_config_load "" ""to py_config_runner""\n    )\n\n    config = config.setup()\n\n    assert_config(config, TRAINVAL_CONFIG)\n    # The following attributes are automatically added by py_config_runner\n    assert hasattr(config, ""config_filepath"") and isinstance(config.config_filepath, Path)\n    assert hasattr(config, ""script_filepath"") and isinstance(config.script_filepath, Path)\n\n    # dump python files to reproduce the run\n    mlflow.log_artifact(config.config_filepath.as_posix())\n    mlflow.log_artifact(config.script_filepath.as_posix())\n\n    output_path = mlflow.get_artifact_uri()\n    config.output_path = Path(output_path)\n\n    if dist.get_rank() == 0:\n        mlflow.log_params(\n            {""pytorch version"": torch.__version__, ""ignite version"": ignite.__version__,}\n        )\n        mlflow.log_params(get_params(config, TRAINVAL_CONFIG))\n\n    try:\n        training(config, local_rank=local_rank, with_mlflow_logging=True, with_plx_logging=False)\n    except KeyboardInterrupt:\n        logger.info(""Catched KeyboardInterrupt -> exit"")\n    except Exception as e:  # noqa\n        logger.exception("""")\n        mlflow.log_param(""Run Status"", ""FAILED"")\n        dist.destroy_process_group()\n        raise e\n\n    mlflow.log_param(""Run Status"", ""OK"")\n    dist.destroy_process_group()\n'"
examples/references/segmentation/pascal_voc2012/code/scripts/plx_training.py,4,"b'# This a training script launched with py_config_runner\n# It should obligatory contain `run(config, **kwargs)` method\n\nfrom pathlib import Path\n\nimport torch\nimport torch.distributed as dist\n\nimport ignite\nfrom polyaxon_client.tracking import get_outputs_path, Experiment\n\nfrom py_config_runner.config_utils import get_params, TRAINVAL_CONFIG, assert_config\n\nfrom common_training import training\n\n\ndef run(config, logger=None, local_rank=0, **kwargs):\n\n    assert torch.cuda.is_available(), torch.cuda.is_available()\n    assert torch.backends.cudnn.enabled, ""Nvidia/Amp requires cudnn backend to be enabled.""\n\n    dist.init_process_group(""nccl"", init_method=""env://"")\n\n    # As we passed config with option --manual_config_load\n    assert hasattr(config, ""setup""), (\n        ""We need to manually setup the configuration, please set --manual_config_load "" ""to py_config_runner""\n    )\n\n    config = config.setup()\n\n    assert_config(config, TRAINVAL_CONFIG)\n    # The following attributes are automatically added by py_config_runner\n    assert hasattr(config, ""config_filepath"") and isinstance(config.config_filepath, Path)\n    assert hasattr(config, ""script_filepath"") and isinstance(config.script_filepath, Path)\n\n    config.output_path = Path(get_outputs_path())\n\n    if dist.get_rank() == 0:\n        plx_exp = Experiment()\n        plx_exp.log_params(\n            **{""pytorch version"": torch.__version__, ""ignite version"": ignite.__version__,}\n        )\n        plx_exp.log_params(**get_params(config, TRAINVAL_CONFIG))\n\n    try:\n        training(config, local_rank=local_rank, with_mlflow_logging=False, with_plx_logging=True)\n    except KeyboardInterrupt:\n        logger.info(""Catched KeyboardInterrupt -> exit"")\n    except Exception as e:  # noqa\n        logger.exception("""")\n        dist.destroy_process_group()\n        raise e\n\n    dist.destroy_process_group()\n'"
examples/references/segmentation/pascal_voc2012/code/scripts/trains_training.py,3,"b'# This a training script launched with py_config_runner\n# It should obligatory contain `run(config, **kwargs)` method\n\nimport sys\nfrom pathlib import Path\n\nimport torch\nimport torch.distributed as dist\n\nfrom trains import Task\nimport ignite\n\nfrom py_config_runner.config_utils import get_params, TRAINVAL_CONFIG, assert_config\n\n# add our directories to sys path\nsys.path.append(Path(__file__).parent.parent.as_posix())\nsys.path.append((Path(__file__).parent.parent / ""dataflow"").as_posix())\n\nfrom common_training import training\n\n\ndef run(config, logger=None, local_rank=0, **kwargs):\n\n    assert torch.cuda.is_available()\n    assert torch.backends.cudnn.enabled, ""Nvidia/Amp requires cudnn backend to be enabled.""\n\n    task = Task.init(""ignite"", ""DeeplabV3_ResNet101 pascal_voc2012 segmentation example"")\n\n    dist.init_process_group(""nccl"", init_method=""env://"")\n\n    # As we passed config with option --manual_config_load\n    assert hasattr(config, ""setup""), (\n        ""We need to manually setup the configuration, please set --manual_config_load "" ""to py_config_runner""\n    )\n\n    config = config.setup()\n\n    assert_config(config, TRAINVAL_CONFIG)\n    # The following attributes are automatically added by py_config_runner\n    assert hasattr(config, ""config_filepath"") and isinstance(config.config_filepath, Path)\n    assert hasattr(config, ""script_filepath"") and isinstance(config.script_filepath, Path)\n\n    # dump python files to reproduce the run\n    task.connect_configuration(config.config_filepath.as_posix())\n    task.upload_artifact(""script"", config.script_filepath)\n\n    config.output_path = Path(""./artifacts"")\n\n    # log the configuration, if we are the master node\n    if dist.get_rank() == 0:\n        task.connect(get_params(config, TRAINVAL_CONFIG))\n\n    try:\n        training(config, local_rank=local_rank, with_trains_logging=True)\n    except KeyboardInterrupt:\n        logger.info(""Caught KeyboardInterrupt -> exit"")\n    except Exception as e:  # noqa\n        logger.exception("""")\n        dist.destroy_process_group()\n        raise e\n\n    dist.destroy_process_group()\n'"
examples/references/segmentation/pascal_voc2012/code/utils/__init__.py,0,b''
examples/references/segmentation/pascal_voc2012/code/utils/handlers.py,2,"b'import torch\n\nfrom dataflow.vis import make_grid, tensor_to_rgb\n\n\ndef predictions_gt_images_handler(img_denormalize_fn, n_images=None, another_engine=None, prefix_tag=None):\n    def wrapper(engine, logger, event_name):\n        batch = engine.state.batch\n        output = engine.state.output\n        x = batch[""image""]\n        y = batch[""mask""]\n        y_pred = output[0]\n\n        if y.shape == y_pred.shape and y.ndim == 4:\n            # Case of y of shape (B, C, H, W)\n            y = torch.argmax(y, dim=1)\n\n        y_pred = torch.argmax(y_pred, dim=1).byte()\n\n        if n_images is not None:\n            x = x[:n_images, ...]\n            y = y[:n_images, ...]\n            y_pred = y_pred[:n_images, ...]\n\n        grid_pred_gt = make_grid(x, y_pred, img_denormalize_fn, batch_gt_mask=y)\n\n        state = engine.state if another_engine is None else another_engine.state\n        global_step = state.get_event_attrib_value(event_name)\n\n        tag = ""predictions_with_gt""\n        if prefix_tag is not None:\n            tag = ""{}: {}"".format(prefix_tag, tag)\n        logger.writer.add_image(tag=tag, img_tensor=grid_pred_gt, global_step=global_step, dataformats=""HWC"")\n\n    return wrapper\n'"
examples/references/segmentation/pascal_voc2012/configs/train/baseline_resnet101.py,4,"b'# Basic training configuration\nimport os\nfrom functools import partial\n\nimport cv2\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lrs\nimport torch.distributed as dist\n\nfrom torchvision.models.segmentation import deeplabv3_resnet101\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2 as ToTensor\n\nfrom dataflow.dataloaders import get_train_val_loaders\nfrom dataflow.transforms import ignore_mask_boundaries, prepare_batch_fp32, denormalize\n\n\nassert ""DATASET_PATH"" in os.environ\ndata_path = os.environ[""DATASET_PATH""]\n\n\ndebug = False\nseed = 12\n\ndevice = ""cuda""\n\nfp16_opt_level = ""O2""\n\nnum_classes = 21\n\n\nbatch_size = 16\nval_batch_size = 20\nnon_blocking = True\nnum_workers = 12 // dist.get_world_size()\nval_interval = 3\n\nval_img_size = 513\ntrain_img_size = 480\n\n# ##############################\n# Setup Dataflow\n# ##############################\n\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\n\ntrain_transforms = A.Compose(\n    [\n        A.RandomScale(scale_limit=(0.0, 1.5), interpolation=cv2.INTER_LINEAR, p=1.0),\n        A.PadIfNeeded(val_img_size, val_img_size, border_mode=cv2.BORDER_CONSTANT),\n        A.RandomCrop(train_img_size, train_img_size),\n        A.HorizontalFlip(),\n        A.Blur(blur_limit=3),\n        A.Normalize(mean=mean, std=std),\n        ignore_mask_boundaries,\n        ToTensor(),\n    ]\n)\n\nval_transforms = A.Compose(\n    [\n        A.PadIfNeeded(val_img_size, val_img_size, border_mode=cv2.BORDER_CONSTANT),\n        A.Normalize(mean=mean, std=std),\n        ignore_mask_boundaries,\n        ToTensor(),\n    ]\n)\n\n\ntrain_loader, val_loader, train_eval_loader = get_train_val_loaders(\n    root_path=data_path,\n    train_transforms=train_transforms,\n    val_transforms=val_transforms,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    val_batch_size=val_batch_size,\n    train_sampler=""distributed"",\n    val_sampler=""distributed"",\n    limit_train_num_samples=100 if debug else None,\n    limit_val_num_samples=100 if debug else None,\n    random_seed=seed,\n)\n\nprepare_batch = prepare_batch_fp32\n\n# Image denormalization function to plot predictions with images\nimg_denormalize = partial(denormalize, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n\n# ##############################\n# Setup models\n# ##############################\n\nnum_classes = 21\nmodel = deeplabv3_resnet101(num_classes=num_classes)\n\n\ndef model_output_transform(output):\n    return output[""out""]\n\n\n# ##############################\n# Setup solver\n# ##############################\n\nnum_epochs = 100\n\ncriterion = nn.CrossEntropyLoss()\n\nlr = 0.007\nweight_decay = 5e-4\nmomentum = 0.9\nnesterov = False\n\noptimizer = optim.SGD(\n    [{""params"": model.backbone.parameters()}, {""params"": model.classifier.parameters()}],\n    lr=1.0,\n    momentum=momentum,\n    weight_decay=weight_decay,\n    nesterov=nesterov,\n)\n\n\nle = len(train_loader)\n\n\ndef lambda_lr_scheduler(iteration, lr0, n, a):\n    return lr0 * pow((1.0 - 1.0 * iteration / n), a)\n\n\nlr_scheduler = lrs.LambdaLR(\n    optimizer,\n    lr_lambda=[\n        partial(lambda_lr_scheduler, lr0=lr, n=num_epochs * le, a=0.9),\n        partial(lambda_lr_scheduler, lr0=lr * 10.0, n=num_epochs * le, a=0.9),\n    ],\n)\n'"
examples/references/segmentation/pascal_voc2012/configs/train/baseline_resnet101_sbd.py,4,"b'# Basic training configuration\nimport os\nfrom functools import partial\n\nimport cv2\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lrs\nimport torch.distributed as dist\n\nfrom torchvision.models.segmentation import deeplabv3_resnet101\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2 as ToTensor\n\nfrom dataflow.dataloaders import get_train_val_loaders\nfrom dataflow.transforms import ignore_mask_boundaries, prepare_batch_fp32, denormalize\n\n\nassert ""DATASET_PATH"" in os.environ\ndata_path = os.environ[""DATASET_PATH""]\n\nassert ""SBD_DATASET_PATH"" in os.environ\nsbd_data_path = os.environ[""SBD_DATASET_PATH""]\n\n\ndebug = False\nseed = 12\n\ndevice = ""cuda""\n\nfp16_opt_level = ""O2""\n\nnum_classes = 21\n\n\nbatch_size = 9  # ~9GB GPU RAM\nval_batch_size = 24\nnon_blocking = True\nnum_workers = 12 // dist.get_world_size()\nval_interval = 1\naccumulation_steps = 4\n\n\nval_img_size = 513\ntrain_img_size = 480\n\n# ##############################\n# Setup Dataflow\n# ##############################\n\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\n\ntrain_transforms = A.Compose(\n    [\n        A.RandomScale(scale_limit=(0.0, 1.5), interpolation=cv2.INTER_LINEAR, p=1.0),\n        A.PadIfNeeded(val_img_size, val_img_size, border_mode=cv2.BORDER_CONSTANT),\n        A.RandomCrop(train_img_size, train_img_size),\n        A.HorizontalFlip(),\n        A.Blur(blur_limit=3),\n        A.Normalize(mean=mean, std=std),\n        ignore_mask_boundaries,\n        ToTensor(),\n    ]\n)\n\nval_transforms = A.Compose(\n    [\n        A.PadIfNeeded(val_img_size, val_img_size, border_mode=cv2.BORDER_CONSTANT),\n        A.Normalize(mean=mean, std=std),\n        ignore_mask_boundaries,\n        ToTensor(),\n    ]\n)\n\n\ntrain_loader, val_loader, train_eval_loader = get_train_val_loaders(\n    root_path=data_path,\n    train_transforms=train_transforms,\n    val_transforms=val_transforms,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    val_batch_size=val_batch_size,\n    with_sbd=sbd_data_path,\n    train_sampler=""distributed"",\n    val_sampler=""distributed"",\n    limit_train_num_samples=100 if debug else None,\n    limit_val_num_samples=100 if debug else None,\n    random_seed=seed,\n)\n\nprepare_batch = prepare_batch_fp32\n\n# Image denormalization function to plot predictions with images\nimg_denormalize = partial(denormalize, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n\n# ##############################\n# Setup models\n# ##############################\n\nnum_classes = 21\nmodel = deeplabv3_resnet101(num_classes=num_classes)\n\n\ndef model_output_transform(output):\n    return output[""out""]\n\n\n# ##############################\n# Setup solver\n# ##############################\n\nnum_epochs = 100\n\ncriterion = nn.CrossEntropyLoss()\n\nlr = 0.007\nweight_decay = 5e-4\nmomentum = 0.9\nnesterov = False\n\noptimizer = optim.SGD(\n    [{""params"": model.backbone.parameters()}, {""params"": model.classifier.parameters()}],\n    lr=1.0,\n    momentum=momentum,\n    weight_decay=weight_decay,\n    nesterov=nesterov,\n)\n\n\nle = len(train_loader)\n\n\ndef lambda_lr_scheduler(iteration, lr0, n, a):\n    return lr0 * pow((1.0 - 1.0 * iteration / n), a)\n\n\nlr_scheduler = lrs.LambdaLR(\n    optimizer,\n    lr_lambda=[\n        partial(lambda_lr_scheduler, lr0=lr, n=num_epochs * le, a=0.9),\n        partial(lambda_lr_scheduler, lr0=lr * 10.0, n=num_epochs * le, a=0.9),\n    ],\n)\n'"
