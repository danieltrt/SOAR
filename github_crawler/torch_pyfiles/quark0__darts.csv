file_path,api_count,code
cnn/architect.py,8,"b""import torch\nimport numpy as np\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef _concat(xs):\n  return torch.cat([x.view(-1) for x in xs])\n\n\nclass Architect(object):\n\n  def __init__(self, model, args):\n    self.network_momentum = args.momentum\n    self.network_weight_decay = args.weight_decay\n    self.model = model\n    self.optimizer = torch.optim.Adam(self.model.arch_parameters(),\n        lr=args.arch_learning_rate, betas=(0.5, 0.999), weight_decay=args.arch_weight_decay)\n\n  def _compute_unrolled_model(self, input, target, eta, network_optimizer):\n    loss = self.model._loss(input, target)\n    theta = _concat(self.model.parameters()).data\n    try:\n      moment = _concat(network_optimizer.state[v]['momentum_buffer'] for v in self.model.parameters()).mul_(self.network_momentum)\n    except:\n      moment = torch.zeros_like(theta)\n    dtheta = _concat(torch.autograd.grad(loss, self.model.parameters())).data + self.network_weight_decay*theta\n    unrolled_model = self._construct_model_from_theta(theta.sub(eta, moment+dtheta))\n    return unrolled_model\n\n  def step(self, input_train, target_train, input_valid, target_valid, eta, network_optimizer, unrolled):\n    self.optimizer.zero_grad()\n    if unrolled:\n        self._backward_step_unrolled(input_train, target_train, input_valid, target_valid, eta, network_optimizer)\n    else:\n        self._backward_step(input_valid, target_valid)\n    self.optimizer.step()\n\n  def _backward_step(self, input_valid, target_valid):\n    loss = self.model._loss(input_valid, target_valid)\n    loss.backward()\n\n  def _backward_step_unrolled(self, input_train, target_train, input_valid, target_valid, eta, network_optimizer):\n    unrolled_model = self._compute_unrolled_model(input_train, target_train, eta, network_optimizer)\n    unrolled_loss = unrolled_model._loss(input_valid, target_valid)\n\n    unrolled_loss.backward()\n    dalpha = [v.grad for v in unrolled_model.arch_parameters()]\n    vector = [v.grad.data for v in unrolled_model.parameters()]\n    implicit_grads = self._hessian_vector_product(vector, input_train, target_train)\n\n    for g, ig in zip(dalpha, implicit_grads):\n      g.data.sub_(eta, ig.data)\n\n    for v, g in zip(self.model.arch_parameters(), dalpha):\n      if v.grad is None:\n        v.grad = Variable(g.data)\n      else:\n        v.grad.data.copy_(g.data)\n\n  def _construct_model_from_theta(self, theta):\n    model_new = self.model.new()\n    model_dict = self.model.state_dict()\n\n    params, offset = {}, 0\n    for k, v in self.model.named_parameters():\n      v_length = np.prod(v.size())\n      params[k] = theta[offset: offset+v_length].view(v.size())\n      offset += v_length\n\n    assert offset == len(theta)\n    model_dict.update(params)\n    model_new.load_state_dict(model_dict)\n    return model_new.cuda()\n\n  def _hessian_vector_product(self, vector, input, target, r=1e-2):\n    R = r / _concat(vector).norm()\n    for p, v in zip(self.model.parameters(), vector):\n      p.data.add_(R, v)\n    loss = self.model._loss(input, target)\n    grads_p = torch.autograd.grad(loss, self.model.arch_parameters())\n\n    for p, v in zip(self.model.parameters(), vector):\n      p.data.sub_(2*R, v)\n    loss = self.model._loss(input, target)\n    grads_n = torch.autograd.grad(loss, self.model.arch_parameters())\n\n    for p, v in zip(self.model.parameters(), vector):\n      p.data.add_(R, v)\n\n    return [(x-y).div_(2*R) for x, y in zip(grads_p, grads_n)]\n\n"""
cnn/genotypes.py,0,"b""from collections import namedtuple\n\nGenotype = namedtuple('Genotype', 'normal normal_concat reduce reduce_concat')\n\nPRIMITIVES = [\n    'none',\n    'max_pool_3x3',\n    'avg_pool_3x3',\n    'skip_connect',\n    'sep_conv_3x3',\n    'sep_conv_5x5',\n    'dil_conv_3x3',\n    'dil_conv_5x5'\n]\n\nNASNet = Genotype(\n  normal = [\n    ('sep_conv_5x5', 1),\n    ('sep_conv_3x3', 0),\n    ('sep_conv_5x5', 0),\n    ('sep_conv_3x3', 0),\n    ('avg_pool_3x3', 1),\n    ('skip_connect', 0),\n    ('avg_pool_3x3', 0),\n    ('avg_pool_3x3', 0),\n    ('sep_conv_3x3', 1),\n    ('skip_connect', 1),\n  ],\n  normal_concat = [2, 3, 4, 5, 6],\n  reduce = [\n    ('sep_conv_5x5', 1),\n    ('sep_conv_7x7', 0),\n    ('max_pool_3x3', 1),\n    ('sep_conv_7x7', 0),\n    ('avg_pool_3x3', 1),\n    ('sep_conv_5x5', 0),\n    ('skip_connect', 3),\n    ('avg_pool_3x3', 2),\n    ('sep_conv_3x3', 2),\n    ('max_pool_3x3', 1),\n  ],\n  reduce_concat = [4, 5, 6],\n)\n    \nAmoebaNet = Genotype(\n  normal = [\n    ('avg_pool_3x3', 0),\n    ('max_pool_3x3', 1),\n    ('sep_conv_3x3', 0),\n    ('sep_conv_5x5', 2),\n    ('sep_conv_3x3', 0),\n    ('avg_pool_3x3', 3),\n    ('sep_conv_3x3', 1),\n    ('skip_connect', 1),\n    ('skip_connect', 0),\n    ('avg_pool_3x3', 1),\n    ],\n  normal_concat = [4, 5, 6],\n  reduce = [\n    ('avg_pool_3x3', 0),\n    ('sep_conv_3x3', 1),\n    ('max_pool_3x3', 0),\n    ('sep_conv_7x7', 2),\n    ('sep_conv_7x7', 0),\n    ('avg_pool_3x3', 1),\n    ('max_pool_3x3', 0),\n    ('max_pool_3x3', 1),\n    ('conv_7x1_1x7', 0),\n    ('sep_conv_3x3', 5),\n  ],\n  reduce_concat = [3, 4, 6]\n)\n\nDARTS_V1 = Genotype(normal=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('skip_connect', 0), ('sep_conv_3x3', 1), ('skip_connect', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('skip_connect', 2)], normal_concat=[2, 3, 4, 5], reduce=[('max_pool_3x3', 0), ('max_pool_3x3', 1), ('skip_connect', 2), ('max_pool_3x3', 0), ('max_pool_3x3', 0), ('skip_connect', 2), ('skip_connect', 2), ('avg_pool_3x3', 0)], reduce_concat=[2, 3, 4, 5])\nDARTS_V2 = Genotype(normal=[('sep_conv_3x3', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 1), ('skip_connect', 0), ('skip_connect', 0), ('dil_conv_3x3', 2)], normal_concat=[2, 3, 4, 5], reduce=[('max_pool_3x3', 0), ('max_pool_3x3', 1), ('skip_connect', 2), ('max_pool_3x3', 1), ('max_pool_3x3', 0), ('skip_connect', 2), ('skip_connect', 2), ('max_pool_3x3', 1)], reduce_concat=[2, 3, 4, 5])\n\nDARTS = DARTS_V2\n\n"""
cnn/model.py,3,"b'import torch\nimport torch.nn as nn\nfrom operations import *\nfrom torch.autograd import Variable\nfrom utils import drop_path\n\n\nclass Cell(nn.Module):\n\n  def __init__(self, genotype, C_prev_prev, C_prev, C, reduction, reduction_prev):\n    super(Cell, self).__init__()\n    print(C_prev_prev, C_prev, C)\n\n    if reduction_prev:\n      self.preprocess0 = FactorizedReduce(C_prev_prev, C)\n    else:\n      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0)\n    self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0)\n    \n    if reduction:\n      op_names, indices = zip(*genotype.reduce)\n      concat = genotype.reduce_concat\n    else:\n      op_names, indices = zip(*genotype.normal)\n      concat = genotype.normal_concat\n    self._compile(C, op_names, indices, concat, reduction)\n\n  def _compile(self, C, op_names, indices, concat, reduction):\n    assert len(op_names) == len(indices)\n    self._steps = len(op_names) // 2\n    self._concat = concat\n    self.multiplier = len(concat)\n\n    self._ops = nn.ModuleList()\n    for name, index in zip(op_names, indices):\n      stride = 2 if reduction and index < 2 else 1\n      op = OPS[name](C, stride, True)\n      self._ops += [op]\n    self._indices = indices\n\n  def forward(self, s0, s1, drop_prob):\n    s0 = self.preprocess0(s0)\n    s1 = self.preprocess1(s1)\n\n    states = [s0, s1]\n    for i in range(self._steps):\n      h1 = states[self._indices[2*i]]\n      h2 = states[self._indices[2*i+1]]\n      op1 = self._ops[2*i]\n      op2 = self._ops[2*i+1]\n      h1 = op1(h1)\n      h2 = op2(h2)\n      if self.training and drop_prob > 0.:\n        if not isinstance(op1, Identity):\n          h1 = drop_path(h1, drop_prob)\n        if not isinstance(op2, Identity):\n          h2 = drop_path(h2, drop_prob)\n      s = h1 + h2\n      states += [s]\n    return torch.cat([states[i] for i in self._concat], dim=1)\n\n\nclass AuxiliaryHeadCIFAR(nn.Module):\n\n  def __init__(self, C, num_classes):\n    """"""assuming input size 8x8""""""\n    super(AuxiliaryHeadCIFAR, self).__init__()\n    self.features = nn.Sequential(\n      nn.ReLU(inplace=True),\n      nn.AvgPool2d(5, stride=3, padding=0, count_include_pad=False), # image size = 2 x 2\n      nn.Conv2d(C, 128, 1, bias=False),\n      nn.BatchNorm2d(128),\n      nn.ReLU(inplace=True),\n      nn.Conv2d(128, 768, 2, bias=False),\n      nn.BatchNorm2d(768),\n      nn.ReLU(inplace=True)\n    )\n    self.classifier = nn.Linear(768, num_classes)\n\n  def forward(self, x):\n    x = self.features(x)\n    x = self.classifier(x.view(x.size(0),-1))\n    return x\n\n\nclass AuxiliaryHeadImageNet(nn.Module):\n\n  def __init__(self, C, num_classes):\n    """"""assuming input size 14x14""""""\n    super(AuxiliaryHeadImageNet, self).__init__()\n    self.features = nn.Sequential(\n      nn.ReLU(inplace=True),\n      nn.AvgPool2d(5, stride=2, padding=0, count_include_pad=False),\n      nn.Conv2d(C, 128, 1, bias=False),\n      nn.BatchNorm2d(128),\n      nn.ReLU(inplace=True),\n      nn.Conv2d(128, 768, 2, bias=False),\n      # NOTE: This batchnorm was omitted in my earlier implementation due to a typo.\n      # Commenting it out for consistency with the experiments in the paper.\n      # nn.BatchNorm2d(768),\n      nn.ReLU(inplace=True)\n    )\n    self.classifier = nn.Linear(768, num_classes)\n\n  def forward(self, x):\n    x = self.features(x)\n    x = self.classifier(x.view(x.size(0),-1))\n    return x\n\n\nclass NetworkCIFAR(nn.Module):\n\n  def __init__(self, C, num_classes, layers, auxiliary, genotype):\n    super(NetworkCIFAR, self).__init__()\n    self._layers = layers\n    self._auxiliary = auxiliary\n\n    stem_multiplier = 3\n    C_curr = stem_multiplier*C\n    self.stem = nn.Sequential(\n      nn.Conv2d(3, C_curr, 3, padding=1, bias=False),\n      nn.BatchNorm2d(C_curr)\n    )\n    \n    C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n    self.cells = nn.ModuleList()\n    reduction_prev = False\n    for i in range(layers):\n      if i in [layers//3, 2*layers//3]:\n        C_curr *= 2\n        reduction = True\n      else:\n        reduction = False\n      cell = Cell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n      reduction_prev = reduction\n      self.cells += [cell]\n      C_prev_prev, C_prev = C_prev, cell.multiplier*C_curr\n      if i == 2*layers//3:\n        C_to_auxiliary = C_prev\n\n    if auxiliary:\n      self.auxiliary_head = AuxiliaryHeadCIFAR(C_to_auxiliary, num_classes)\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n\n  def forward(self, input):\n    logits_aux = None\n    s0 = s1 = self.stem(input)\n    for i, cell in enumerate(self.cells):\n      s0, s1 = s1, cell(s0, s1, self.drop_path_prob)\n      if i == 2*self._layers//3:\n        if self._auxiliary and self.training:\n          logits_aux = self.auxiliary_head(s1)\n    out = self.global_pooling(s1)\n    logits = self.classifier(out.view(out.size(0),-1))\n    return logits, logits_aux\n\n\nclass NetworkImageNet(nn.Module):\n\n  def __init__(self, C, num_classes, layers, auxiliary, genotype):\n    super(NetworkImageNet, self).__init__()\n    self._layers = layers\n    self._auxiliary = auxiliary\n\n    self.stem0 = nn.Sequential(\n      nn.Conv2d(3, C // 2, kernel_size=3, stride=2, padding=1, bias=False),\n      nn.BatchNorm2d(C // 2),\n      nn.ReLU(inplace=True),\n      nn.Conv2d(C // 2, C, 3, stride=2, padding=1, bias=False),\n      nn.BatchNorm2d(C),\n    )\n\n    self.stem1 = nn.Sequential(\n      nn.ReLU(inplace=True),\n      nn.Conv2d(C, C, 3, stride=2, padding=1, bias=False),\n      nn.BatchNorm2d(C),\n    )\n\n    C_prev_prev, C_prev, C_curr = C, C, C\n\n    self.cells = nn.ModuleList()\n    reduction_prev = True\n    for i in range(layers):\n      if i in [layers // 3, 2 * layers // 3]:\n        C_curr *= 2\n        reduction = True\n      else:\n        reduction = False\n      cell = Cell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n      reduction_prev = reduction\n      self.cells += [cell]\n      C_prev_prev, C_prev = C_prev, cell.multiplier * C_curr\n      if i == 2 * layers // 3:\n        C_to_auxiliary = C_prev\n\n    if auxiliary:\n      self.auxiliary_head = AuxiliaryHeadImageNet(C_to_auxiliary, num_classes)\n    self.global_pooling = nn.AvgPool2d(7)\n    self.classifier = nn.Linear(C_prev, num_classes)\n\n  def forward(self, input):\n    logits_aux = None\n    s0 = self.stem0(input)\n    s1 = self.stem1(s0)\n    for i, cell in enumerate(self.cells):\n      s0, s1 = s1, cell(s0, s1, self.drop_path_prob)\n      if i == 2 * self._layers // 3:\n        if self._auxiliary and self.training:\n          logits_aux = self.auxiliary_head(s1)\n    out = self.global_pooling(s1)\n    logits = self.classifier(out.view(out.size(0), -1))\n    return logits, logits_aux\n\n'"
cnn/model_search.py,6,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom operations import *\nfrom torch.autograd import Variable\nfrom genotypes import PRIMITIVES\nfrom genotypes import Genotype\n\n\nclass MixedOp(nn.Module):\n\n  def __init__(self, C, stride):\n    super(MixedOp, self).__init__()\n    self._ops = nn.ModuleList()\n    for primitive in PRIMITIVES:\n      op = OPS[primitive](C, stride, False)\n      if 'pool' in primitive:\n        op = nn.Sequential(op, nn.BatchNorm2d(C, affine=False))\n      self._ops.append(op)\n\n  def forward(self, x, weights):\n    return sum(w * op(x) for w, op in zip(weights, self._ops))\n\n\nclass Cell(nn.Module):\n\n  def __init__(self, steps, multiplier, C_prev_prev, C_prev, C, reduction, reduction_prev):\n    super(Cell, self).__init__()\n    self.reduction = reduction\n\n    if reduction_prev:\n      self.preprocess0 = FactorizedReduce(C_prev_prev, C, affine=False)\n    else:\n      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0, affine=False)\n    self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0, affine=False)\n    self._steps = steps\n    self._multiplier = multiplier\n\n    self._ops = nn.ModuleList()\n    self._bns = nn.ModuleList()\n    for i in range(self._steps):\n      for j in range(2+i):\n        stride = 2 if reduction and j < 2 else 1\n        op = MixedOp(C, stride)\n        self._ops.append(op)\n\n  def forward(self, s0, s1, weights):\n    s0 = self.preprocess0(s0)\n    s1 = self.preprocess1(s1)\n\n    states = [s0, s1]\n    offset = 0\n    for i in range(self._steps):\n      s = sum(self._ops[offset+j](h, weights[offset+j]) for j, h in enumerate(states))\n      offset += len(states)\n      states.append(s)\n\n    return torch.cat(states[-self._multiplier:], dim=1)\n\n\nclass Network(nn.Module):\n\n  def __init__(self, C, num_classes, layers, criterion, steps=4, multiplier=4, stem_multiplier=3):\n    super(Network, self).__init__()\n    self._C = C\n    self._num_classes = num_classes\n    self._layers = layers\n    self._criterion = criterion\n    self._steps = steps\n    self._multiplier = multiplier\n\n    C_curr = stem_multiplier*C\n    self.stem = nn.Sequential(\n      nn.Conv2d(3, C_curr, 3, padding=1, bias=False),\n      nn.BatchNorm2d(C_curr)\n    )\n \n    C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n    self.cells = nn.ModuleList()\n    reduction_prev = False\n    for i in range(layers):\n      if i in [layers//3, 2*layers//3]:\n        C_curr *= 2\n        reduction = True\n      else:\n        reduction = False\n      cell = Cell(steps, multiplier, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n      reduction_prev = reduction\n      self.cells += [cell]\n      C_prev_prev, C_prev = C_prev, multiplier*C_curr\n\n    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n    self.classifier = nn.Linear(C_prev, num_classes)\n\n    self._initialize_alphas()\n\n  def new(self):\n    model_new = Network(self._C, self._num_classes, self._layers, self._criterion).cuda()\n    for x, y in zip(model_new.arch_parameters(), self.arch_parameters()):\n        x.data.copy_(y.data)\n    return model_new\n\n  def forward(self, input):\n    s0 = s1 = self.stem(input)\n    for i, cell in enumerate(self.cells):\n      if cell.reduction:\n        weights = F.softmax(self.alphas_reduce, dim=-1)\n      else:\n        weights = F.softmax(self.alphas_normal, dim=-1)\n      s0, s1 = s1, cell(s0, s1, weights)\n    out = self.global_pooling(s1)\n    logits = self.classifier(out.view(out.size(0),-1))\n    return logits\n\n  def _loss(self, input, target):\n    logits = self(input)\n    return self._criterion(logits, target) \n\n  def _initialize_alphas(self):\n    k = sum(1 for i in range(self._steps) for n in range(2+i))\n    num_ops = len(PRIMITIVES)\n\n    self.alphas_normal = Variable(1e-3*torch.randn(k, num_ops).cuda(), requires_grad=True)\n    self.alphas_reduce = Variable(1e-3*torch.randn(k, num_ops).cuda(), requires_grad=True)\n    self._arch_parameters = [\n      self.alphas_normal,\n      self.alphas_reduce,\n    ]\n\n  def arch_parameters(self):\n    return self._arch_parameters\n\n  def genotype(self):\n\n    def _parse(weights):\n      gene = []\n      n = 2\n      start = 0\n      for i in range(self._steps):\n        end = start + n\n        W = weights[start:end].copy()\n        edges = sorted(range(i + 2), key=lambda x: -max(W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n        for j in edges:\n          k_best = None\n          for k in range(len(W[j])):\n            if k != PRIMITIVES.index('none'):\n              if k_best is None or W[j][k] > W[j][k_best]:\n                k_best = k\n          gene.append((PRIMITIVES[k_best], j))\n        start = end\n        n += 1\n      return gene\n\n    gene_normal = _parse(F.softmax(self.alphas_normal, dim=-1).data.cpu().numpy())\n    gene_reduce = _parse(F.softmax(self.alphas_reduce, dim=-1).data.cpu().numpy())\n\n    concat = range(2+self._steps-self._multiplier, self._steps+2)\n    genotype = Genotype(\n      normal=gene_normal, normal_concat=concat,\n      reduce=gene_reduce, reduce_concat=concat\n    )\n    return genotype\n\n"""
cnn/operations.py,2,"b""import torch\nimport torch.nn as nn\n\nOPS = {\n  'none' : lambda C, stride, affine: Zero(stride),\n  'avg_pool_3x3' : lambda C, stride, affine: nn.AvgPool2d(3, stride=stride, padding=1, count_include_pad=False),\n  'max_pool_3x3' : lambda C, stride, affine: nn.MaxPool2d(3, stride=stride, padding=1),\n  'skip_connect' : lambda C, stride, affine: Identity() if stride == 1 else FactorizedReduce(C, C, affine=affine),\n  'sep_conv_3x3' : lambda C, stride, affine: SepConv(C, C, 3, stride, 1, affine=affine),\n  'sep_conv_5x5' : lambda C, stride, affine: SepConv(C, C, 5, stride, 2, affine=affine),\n  'sep_conv_7x7' : lambda C, stride, affine: SepConv(C, C, 7, stride, 3, affine=affine),\n  'dil_conv_3x3' : lambda C, stride, affine: DilConv(C, C, 3, stride, 2, 2, affine=affine),\n  'dil_conv_5x5' : lambda C, stride, affine: DilConv(C, C, 5, stride, 4, 2, affine=affine),\n  'conv_7x1_1x7' : lambda C, stride, affine: nn.Sequential(\n    nn.ReLU(inplace=False),\n    nn.Conv2d(C, C, (1,7), stride=(1, stride), padding=(0, 3), bias=False),\n    nn.Conv2d(C, C, (7,1), stride=(stride, 1), padding=(3, 0), bias=False),\n    nn.BatchNorm2d(C, affine=affine)\n    ),\n}\n\nclass ReLUConvBN(nn.Module):\n\n  def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True):\n    super(ReLUConvBN, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_out, kernel_size, stride=stride, padding=padding, bias=False),\n      nn.BatchNorm2d(C_out, affine=affine)\n    )\n\n  def forward(self, x):\n    return self.op(x)\n\nclass DilConv(nn.Module):\n    \n  def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation, affine=True):\n    super(DilConv, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=C_in, bias=False),\n      nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),\n      nn.BatchNorm2d(C_out, affine=affine),\n      )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass SepConv(nn.Module):\n    \n  def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True):\n    super(SepConv, self).__init__()\n    self.op = nn.Sequential(\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, groups=C_in, bias=False),\n      nn.Conv2d(C_in, C_in, kernel_size=1, padding=0, bias=False),\n      nn.BatchNorm2d(C_in, affine=affine),\n      nn.ReLU(inplace=False),\n      nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=1, padding=padding, groups=C_in, bias=False),\n      nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),\n      nn.BatchNorm2d(C_out, affine=affine),\n      )\n\n  def forward(self, x):\n    return self.op(x)\n\n\nclass Identity(nn.Module):\n\n  def __init__(self):\n    super(Identity, self).__init__()\n\n  def forward(self, x):\n    return x\n\n\nclass Zero(nn.Module):\n\n  def __init__(self, stride):\n    super(Zero, self).__init__()\n    self.stride = stride\n\n  def forward(self, x):\n    if self.stride == 1:\n      return x.mul(0.)\n    return x[:,:,::self.stride,::self.stride].mul(0.)\n\n\nclass FactorizedReduce(nn.Module):\n\n  def __init__(self, C_in, C_out, affine=True):\n    super(FactorizedReduce, self).__init__()\n    assert C_out % 2 == 0\n    self.relu = nn.ReLU(inplace=False)\n    self.conv_1 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False)\n    self.conv_2 = nn.Conv2d(C_in, C_out // 2, 1, stride=2, padding=0, bias=False) \n    self.bn = nn.BatchNorm2d(C_out, affine=affine)\n\n  def forward(self, x):\n    x = self.relu(x)\n    out = torch.cat([self.conv_1(x), self.conv_2(x[:,:,1:,1:])], dim=1)\n    out = self.bn(out)\n    return out\n\n"""
cnn/test.py,9,"b'import os\nimport sys\nimport glob\nimport numpy as np\nimport torch\nimport utils\nimport logging\nimport argparse\nimport torch.nn as nn\nimport genotypes\nimport torch.utils\nimport torchvision.datasets as dset\nimport torch.backends.cudnn as cudnn\n\nfrom torch.autograd import Variable\nfrom model import NetworkCIFAR as Network\n\n\nparser = argparse.ArgumentParser(""cifar"")\nparser.add_argument(\'--data\', type=str, default=\'../data\', help=\'location of the data corpus\')\nparser.add_argument(\'--batch_size\', type=int, default=96, help=\'batch size\')\nparser.add_argument(\'--report_freq\', type=float, default=50, help=\'report frequency\')\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'gpu device id\')\nparser.add_argument(\'--init_channels\', type=int, default=36, help=\'num of init channels\')\nparser.add_argument(\'--layers\', type=int, default=20, help=\'total number of layers\')\nparser.add_argument(\'--model_path\', type=str, default=\'EXP/model.pt\', help=\'path of pretrained model\')\nparser.add_argument(\'--auxiliary\', action=\'store_true\', default=False, help=\'use auxiliary tower\')\nparser.add_argument(\'--cutout\', action=\'store_true\', default=False, help=\'use cutout\')\nparser.add_argument(\'--cutout_length\', type=int, default=16, help=\'cutout length\')\nparser.add_argument(\'--drop_path_prob\', type=float, default=0.2, help=\'drop path probability\')\nparser.add_argument(\'--seed\', type=int, default=0, help=\'random seed\')\nparser.add_argument(\'--arch\', type=str, default=\'DARTS\', help=\'which architecture to use\')\nargs = parser.parse_args()\n\nlog_format = \'%(asctime)s %(message)s\'\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO,\n    format=log_format, datefmt=\'%m/%d %I:%M:%S %p\')\n\nCIFAR_CLASSES = 10\n\n\ndef main():\n  if not torch.cuda.is_available():\n    logging.info(\'no gpu device available\')\n    sys.exit(1)\n\n  np.random.seed(args.seed)\n  torch.cuda.set_device(args.gpu)\n  cudnn.benchmark = True\n  torch.manual_seed(args.seed)\n  cudnn.enabled=True\n  torch.cuda.manual_seed(args.seed)\n  logging.info(\'gpu device = %d\' % args.gpu)\n  logging.info(""args = %s"", args)\n\n  genotype = eval(""genotypes.%s"" % args.arch)\n  model = Network(args.init_channels, CIFAR_CLASSES, args.layers, args.auxiliary, genotype)\n  model = model.cuda()\n  utils.load(model, args.model_path)\n\n  logging.info(""param size = %fMB"", utils.count_parameters_in_MB(model))\n\n  criterion = nn.CrossEntropyLoss()\n  criterion = criterion.cuda()\n\n  _, test_transform = utils._data_transforms_cifar10(args)\n  test_data = dset.CIFAR10(root=args.data, train=False, download=True, transform=test_transform)\n\n  test_queue = torch.utils.data.DataLoader(\n      test_data, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=2)\n\n  model.drop_path_prob = args.drop_path_prob\n  test_acc, test_obj = infer(test_queue, model, criterion)\n  logging.info(\'test_acc %f\', test_acc)\n\n\ndef infer(test_queue, model, criterion):\n  objs = utils.AvgrageMeter()\n  top1 = utils.AvgrageMeter()\n  top5 = utils.AvgrageMeter()\n  model.eval()\n\n  for step, (input, target) in enumerate(test_queue):\n    input = Variable(input, volatile=True).cuda()\n    target = Variable(target, volatile=True).cuda(async=True)\n\n    logits, _ = model(input)\n    loss = criterion(logits, target)\n\n    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n    n = input.size(0)\n    objs.update(loss.data[0], n)\n    top1.update(prec1.data[0], n)\n    top5.update(prec5.data[0], n)\n\n    if step % args.report_freq == 0:\n      logging.info(\'test %03d %e %f %f\', step, objs.avg, top1.avg, top5.avg)\n\n  return top1.avg, objs.avg\n\n\nif __name__ == \'__main__\':\n  main() \n\n'"
cnn/test_imagenet.py,10,"b'import os\nimport sys\nimport numpy as np\nimport torch\nimport utils\nimport glob\nimport random\nimport logging\nimport argparse\nimport torch.nn as nn\nimport genotypes\nimport torch.utils\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torch.backends.cudnn as cudnn\n\nfrom torch.autograd import Variable\nfrom model import NetworkImageNet as Network\n\n\nparser = argparse.ArgumentParser(""imagenet"")\nparser.add_argument(\'--data\', type=str, default=\'../data/imagenet/\', help=\'location of the data corpus\')\nparser.add_argument(\'--batch_size\', type=int, default=128, help=\'batch size\')\nparser.add_argument(\'--report_freq\', type=float, default=100, help=\'report frequency\')\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'gpu device id\')\nparser.add_argument(\'--init_channels\', type=int, default=48, help=\'num of init channels\')\nparser.add_argument(\'--layers\', type=int, default=14, help=\'total number of layers\')\nparser.add_argument(\'--model_path\', type=str, default=\'EXP/model.pt\', help=\'path of pretrained model\')\nparser.add_argument(\'--auxiliary\', action=\'store_true\', default=False, help=\'use auxiliary tower\')\nparser.add_argument(\'--drop_path_prob\', type=float, default=0, help=\'drop path probability\')\nparser.add_argument(\'--seed\', type=int, default=0, help=\'random seed\')\nparser.add_argument(\'--arch\', type=str, default=\'DARTS\', help=\'which architecture to use\')\nargs = parser.parse_args()\n\nlog_format = \'%(asctime)s %(message)s\'\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO,\n    format=log_format, datefmt=\'%m/%d %I:%M:%S %p\')\n\nCLASSES = 1000\n\n\ndef main():\n  if not torch.cuda.is_available():\n    logging.info(\'no gpu device available\')\n    sys.exit(1)\n\n  np.random.seed(args.seed)\n  torch.cuda.set_device(args.gpu)\n  cudnn.benchmark = True\n  torch.manual_seed(args.seed)\n  cudnn.enabled=True\n  torch.cuda.manual_seed(args.seed)\n  logging.info(\'gpu device = %d\' % args.gpu)\n  logging.info(""args = %s"", args)\n\n  genotype = eval(""genotypes.%s"" % args.arch)\n  model = Network(args.init_channels, CLASSES, args.layers, args.auxiliary, genotype)\n  model = model.cuda()\n  model.load_state_dict(torch.load(args.model_path)[\'state_dict\'])\n\n  logging.info(""param size = %fMB"", utils.count_parameters_in_MB(model))\n\n  criterion = nn.CrossEntropyLoss()\n  criterion = criterion.cuda()\n\n  validdir = os.path.join(args.data, \'val\')\n  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n  valid_data = dset.ImageFolder(\n    validdir,\n    transforms.Compose([\n      transforms.Resize(256),\n      transforms.CenterCrop(224),\n      transforms.ToTensor(),\n      normalize,\n    ]))\n\n  valid_queue = torch.utils.data.DataLoader(\n    valid_data, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=4)\n\n  model.drop_path_prob = args.drop_path_prob\n  valid_acc_top1, valid_acc_top5, valid_obj = infer(valid_queue, model, criterion)\n  logging.info(\'valid_acc_top1 %f\', valid_acc_top1)\n  logging.info(\'valid_acc_top5 %f\', valid_acc_top5)\n\n\ndef infer(valid_queue, model, criterion):\n  objs = utils.AvgrageMeter()\n  top1 = utils.AvgrageMeter()\n  top5 = utils.AvgrageMeter()\n  model.eval()\n\n  for step, (input, target) in enumerate(valid_queue):\n    input = Variable(input, volatile=True).cuda()\n    target = Variable(target, volatile=True).cuda(async=True)\n\n    logits, _ = model(input)\n    loss = criterion(logits, target)\n\n    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n    n = input.size(0)\n    objs.update(loss.data[0], n)\n    top1.update(prec1.data[0], n)\n    top5.update(prec5.data[0], n)\n\n    if step % args.report_freq == 0:\n      logging.info(\'valid %03d %e %f %f\', step, objs.avg, top1.avg, top5.avg)\n\n  return top1.avg, top5.avg, objs.avg\n\n\nif __name__ == \'__main__\':\n  main() \n'"
cnn/train.py,12,"b'import os\nimport sys\nimport time\nimport glob\nimport numpy as np\nimport torch\nimport utils\nimport logging\nimport argparse\nimport torch.nn as nn\nimport genotypes\nimport torch.utils\nimport torchvision.datasets as dset\nimport torch.backends.cudnn as cudnn\n\nfrom torch.autograd import Variable\nfrom model import NetworkCIFAR as Network\n\n\nparser = argparse.ArgumentParser(""cifar"")\nparser.add_argument(\'--data\', type=str, default=\'../data\', help=\'location of the data corpus\')\nparser.add_argument(\'--batch_size\', type=int, default=96, help=\'batch size\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.025, help=\'init learning rate\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'momentum\')\nparser.add_argument(\'--weight_decay\', type=float, default=3e-4, help=\'weight decay\')\nparser.add_argument(\'--report_freq\', type=float, default=50, help=\'report frequency\')\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'gpu device id\')\nparser.add_argument(\'--epochs\', type=int, default=600, help=\'num of training epochs\')\nparser.add_argument(\'--init_channels\', type=int, default=36, help=\'num of init channels\')\nparser.add_argument(\'--layers\', type=int, default=20, help=\'total number of layers\')\nparser.add_argument(\'--model_path\', type=str, default=\'saved_models\', help=\'path to save the model\')\nparser.add_argument(\'--auxiliary\', action=\'store_true\', default=False, help=\'use auxiliary tower\')\nparser.add_argument(\'--auxiliary_weight\', type=float, default=0.4, help=\'weight for auxiliary loss\')\nparser.add_argument(\'--cutout\', action=\'store_true\', default=False, help=\'use cutout\')\nparser.add_argument(\'--cutout_length\', type=int, default=16, help=\'cutout length\')\nparser.add_argument(\'--drop_path_prob\', type=float, default=0.2, help=\'drop path probability\')\nparser.add_argument(\'--save\', type=str, default=\'EXP\', help=\'experiment name\')\nparser.add_argument(\'--seed\', type=int, default=0, help=\'random seed\')\nparser.add_argument(\'--arch\', type=str, default=\'DARTS\', help=\'which architecture to use\')\nparser.add_argument(\'--grad_clip\', type=float, default=5, help=\'gradient clipping\')\nargs = parser.parse_args()\n\nargs.save = \'eval-{}-{}\'.format(args.save, time.strftime(""%Y%m%d-%H%M%S""))\nutils.create_exp_dir(args.save, scripts_to_save=glob.glob(\'*.py\'))\n\nlog_format = \'%(asctime)s %(message)s\'\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO,\n    format=log_format, datefmt=\'%m/%d %I:%M:%S %p\')\nfh = logging.FileHandler(os.path.join(args.save, \'log.txt\'))\nfh.setFormatter(logging.Formatter(log_format))\nlogging.getLogger().addHandler(fh)\n\nCIFAR_CLASSES = 10\n\n\ndef main():\n  if not torch.cuda.is_available():\n    logging.info(\'no gpu device available\')\n    sys.exit(1)\n\n  np.random.seed(args.seed)\n  torch.cuda.set_device(args.gpu)\n  cudnn.benchmark = True\n  torch.manual_seed(args.seed)\n  cudnn.enabled=True\n  torch.cuda.manual_seed(args.seed)\n  logging.info(\'gpu device = %d\' % args.gpu)\n  logging.info(""args = %s"", args)\n\n  genotype = eval(""genotypes.%s"" % args.arch)\n  model = Network(args.init_channels, CIFAR_CLASSES, args.layers, args.auxiliary, genotype)\n  model = model.cuda()\n\n  logging.info(""param size = %fMB"", utils.count_parameters_in_MB(model))\n\n  criterion = nn.CrossEntropyLoss()\n  criterion = criterion.cuda()\n  optimizer = torch.optim.SGD(\n      model.parameters(),\n      args.learning_rate,\n      momentum=args.momentum,\n      weight_decay=args.weight_decay\n      )\n\n  train_transform, valid_transform = utils._data_transforms_cifar10(args)\n  train_data = dset.CIFAR10(root=args.data, train=True, download=True, transform=train_transform)\n  valid_data = dset.CIFAR10(root=args.data, train=False, download=True, transform=valid_transform)\n\n  train_queue = torch.utils.data.DataLoader(\n      train_data, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=2)\n\n  valid_queue = torch.utils.data.DataLoader(\n      valid_data, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=2)\n\n  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, float(args.epochs))\n\n  for epoch in range(args.epochs):\n    scheduler.step()\n    logging.info(\'epoch %d lr %e\', epoch, scheduler.get_lr()[0])\n    model.drop_path_prob = args.drop_path_prob * epoch / args.epochs\n\n    train_acc, train_obj = train(train_queue, model, criterion, optimizer)\n    logging.info(\'train_acc %f\', train_acc)\n\n    valid_acc, valid_obj = infer(valid_queue, model, criterion)\n    logging.info(\'valid_acc %f\', valid_acc)\n\n    utils.save(model, os.path.join(args.save, \'weights.pt\'))\n\n\ndef train(train_queue, model, criterion, optimizer):\n  objs = utils.AvgrageMeter()\n  top1 = utils.AvgrageMeter()\n  top5 = utils.AvgrageMeter()\n  model.train()\n\n  for step, (input, target) in enumerate(train_queue):\n    input = Variable(input).cuda()\n    target = Variable(target).cuda(async=True)\n\n    optimizer.zero_grad()\n    logits, logits_aux = model(input)\n    loss = criterion(logits, target)\n    if args.auxiliary:\n      loss_aux = criterion(logits_aux, target)\n      loss += args.auxiliary_weight*loss_aux\n    loss.backward()\n    nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n    optimizer.step()\n\n    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n    n = input.size(0)\n    objs.update(loss.data[0], n)\n    top1.update(prec1.data[0], n)\n    top5.update(prec5.data[0], n)\n\n    if step % args.report_freq == 0:\n      logging.info(\'train %03d %e %f %f\', step, objs.avg, top1.avg, top5.avg)\n\n  return top1.avg, objs.avg\n\n\ndef infer(valid_queue, model, criterion):\n  objs = utils.AvgrageMeter()\n  top1 = utils.AvgrageMeter()\n  top5 = utils.AvgrageMeter()\n  model.eval()\n\n  for step, (input, target) in enumerate(valid_queue):\n    input = Variable(input, volatile=True).cuda()\n    target = Variable(target, volatile=True).cuda(async=True)\n\n    logits, _ = model(input)\n    loss = criterion(logits, target)\n\n    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n    n = input.size(0)\n    objs.update(loss.data[0], n)\n    top1.update(prec1.data[0], n)\n    top5.update(prec5.data[0], n)\n\n    if step % args.report_freq == 0:\n      logging.info(\'valid %03d %e %f %f\', step, objs.avg, top1.avg, top5.avg)\n\n  return top1.avg, objs.avg\n\n\nif __name__ == \'__main__\':\n  main() \n\n'"
cnn/train_imagenet.py,13,"b'import os\nimport sys\nimport numpy as np\nimport time\nimport torch\nimport utils\nimport glob\nimport random\nimport logging\nimport argparse\nimport torch.nn as nn\nimport genotypes\nimport torch.utils\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torch.backends.cudnn as cudnn\n\nfrom torch.autograd import Variable\nfrom model import NetworkImageNet as Network\n\n\nparser = argparse.ArgumentParser(""imagenet"")\nparser.add_argument(\'--data\', type=str, default=\'../data/imagenet/\', help=\'location of the data corpus\')\nparser.add_argument(\'--batch_size\', type=int, default=128, help=\'batch size\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.1, help=\'init learning rate\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'momentum\')\nparser.add_argument(\'--weight_decay\', type=float, default=3e-5, help=\'weight decay\')\nparser.add_argument(\'--report_freq\', type=float, default=100, help=\'report frequency\')\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'gpu device id\')\nparser.add_argument(\'--epochs\', type=int, default=250, help=\'num of training epochs\')\nparser.add_argument(\'--init_channels\', type=int, default=48, help=\'num of init channels\')\nparser.add_argument(\'--layers\', type=int, default=14, help=\'total number of layers\')\nparser.add_argument(\'--auxiliary\', action=\'store_true\', default=False, help=\'use auxiliary tower\')\nparser.add_argument(\'--auxiliary_weight\', type=float, default=0.4, help=\'weight for auxiliary loss\')\nparser.add_argument(\'--drop_path_prob\', type=float, default=0, help=\'drop path probability\')\nparser.add_argument(\'--save\', type=str, default=\'EXP\', help=\'experiment name\')\nparser.add_argument(\'--seed\', type=int, default=0, help=\'random seed\')\nparser.add_argument(\'--arch\', type=str, default=\'DARTS\', help=\'which architecture to use\')\nparser.add_argument(\'--grad_clip\', type=float, default=5., help=\'gradient clipping\')\nparser.add_argument(\'--label_smooth\', type=float, default=0.1, help=\'label smoothing\')\nparser.add_argument(\'--gamma\', type=float, default=0.97, help=\'learning rate decay\')\nparser.add_argument(\'--decay_period\', type=int, default=1, help=\'epochs between two learning rate decays\')\nparser.add_argument(\'--parallel\', action=\'store_true\', default=False, help=\'data parallelism\')\nargs = parser.parse_args()\n\nargs.save = \'eval-{}-{}\'.format(args.save, time.strftime(""%Y%m%d-%H%M%S""))\nutils.create_exp_dir(args.save, scripts_to_save=glob.glob(\'*.py\'))\n\nlog_format = \'%(asctime)s %(message)s\'\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO,\n    format=log_format, datefmt=\'%m/%d %I:%M:%S %p\')\nfh = logging.FileHandler(os.path.join(args.save, \'log.txt\'))\nfh.setFormatter(logging.Formatter(log_format))\nlogging.getLogger().addHandler(fh)\n\nCLASSES = 1000\n\n\nclass CrossEntropyLabelSmooth(nn.Module):\n\n  def __init__(self, num_classes, epsilon):\n    super(CrossEntropyLabelSmooth, self).__init__()\n    self.num_classes = num_classes\n    self.epsilon = epsilon\n    self.logsoftmax = nn.LogSoftmax(dim=1)\n\n  def forward(self, inputs, targets):\n    log_probs = self.logsoftmax(inputs)\n    targets = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n    targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n    loss = (-targets * log_probs).mean(0).sum()\n    return loss\n\n\ndef main():\n  if not torch.cuda.is_available():\n    logging.info(\'no gpu device available\')\n    sys.exit(1)\n\n  np.random.seed(args.seed)\n  torch.cuda.set_device(args.gpu)\n  cudnn.benchmark = True\n  torch.manual_seed(args.seed)\n  cudnn.enabled=True\n  torch.cuda.manual_seed(args.seed)\n  logging.info(\'gpu device = %d\' % args.gpu)\n  logging.info(""args = %s"", args)\n\n  genotype = eval(""genotypes.%s"" % args.arch)\n  model = Network(args.init_channels, CLASSES, args.layers, args.auxiliary, genotype)\n  if args.parallel:\n    model = nn.DataParallel(model).cuda()\n  else:\n    model = model.cuda()\n\n  logging.info(""param size = %fMB"", utils.count_parameters_in_MB(model))\n\n  criterion = nn.CrossEntropyLoss()\n  criterion = criterion.cuda()\n  criterion_smooth = CrossEntropyLabelSmooth(CLASSES, args.label_smooth)\n  criterion_smooth = criterion_smooth.cuda()\n\n  optimizer = torch.optim.SGD(\n    model.parameters(),\n    args.learning_rate,\n    momentum=args.momentum,\n    weight_decay=args.weight_decay\n    )\n\n  traindir = os.path.join(args.data, \'train\')\n  validdir = os.path.join(args.data, \'val\')\n  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n  train_data = dset.ImageFolder(\n    traindir,\n    transforms.Compose([\n      transforms.RandomResizedCrop(224),\n      transforms.RandomHorizontalFlip(),\n      transforms.ColorJitter(\n        brightness=0.4,\n        contrast=0.4,\n        saturation=0.4,\n        hue=0.2),\n      transforms.ToTensor(),\n      normalize,\n    ]))\n  valid_data = dset.ImageFolder(\n    validdir,\n    transforms.Compose([\n      transforms.Resize(256),\n      transforms.CenterCrop(224),\n      transforms.ToTensor(),\n      normalize,\n    ]))\n\n  train_queue = torch.utils.data.DataLoader(\n    train_data, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n\n  valid_queue = torch.utils.data.DataLoader(\n    valid_data, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=4)\n\n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.decay_period, gamma=args.gamma)\n\n  best_acc_top1 = 0\n  for epoch in range(args.epochs):\n    scheduler.step()\n    logging.info(\'epoch %d lr %e\', epoch, scheduler.get_lr()[0])\n    model.drop_path_prob = args.drop_path_prob * epoch / args.epochs\n\n    train_acc, train_obj = train(train_queue, model, criterion_smooth, optimizer)\n    logging.info(\'train_acc %f\', train_acc)\n\n    valid_acc_top1, valid_acc_top5, valid_obj = infer(valid_queue, model, criterion)\n    logging.info(\'valid_acc_top1 %f\', valid_acc_top1)\n    logging.info(\'valid_acc_top5 %f\', valid_acc_top5)\n\n    is_best = False\n    if valid_acc_top1 > best_acc_top1:\n      best_acc_top1 = valid_acc_top1\n      is_best = True\n\n    utils.save_checkpoint({\n      \'epoch\': epoch + 1,\n      \'state_dict\': model.state_dict(),\n      \'best_acc_top1\': best_acc_top1,\n      \'optimizer\' : optimizer.state_dict(),\n      }, is_best, args.save)\n\n\ndef train(train_queue, model, criterion, optimizer):\n  objs = utils.AvgrageMeter()\n  top1 = utils.AvgrageMeter()\n  top5 = utils.AvgrageMeter()\n  model.train()\n\n  for step, (input, target) in enumerate(train_queue):\n    target = target.cuda(async=True)\n    input = input.cuda()\n    input = Variable(input)\n    target = Variable(target)\n\n    optimizer.zero_grad()\n    logits, logits_aux = model(input)\n    loss = criterion(logits, target)\n    if args.auxiliary:\n      loss_aux = criterion(logits_aux, target)\n      loss += args.auxiliary_weight*loss_aux\n\n    loss.backward()\n    nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n    optimizer.step()\n\n    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n    n = input.size(0)\n    objs.update(loss.data[0], n)\n    top1.update(prec1.data[0], n)\n    top5.update(prec5.data[0], n)\n\n    if step % args.report_freq == 0:\n      logging.info(\'train %03d %e %f %f\', step, objs.avg, top1.avg, top5.avg)\n\n  return top1.avg, objs.avg\n\n\ndef infer(valid_queue, model, criterion):\n  objs = utils.AvgrageMeter()\n  top1 = utils.AvgrageMeter()\n  top5 = utils.AvgrageMeter()\n  model.eval()\n\n  for step, (input, target) in enumerate(valid_queue):\n    input = Variable(input, volatile=True).cuda()\n    target = Variable(target, volatile=True).cuda(async=True)\n\n    logits, _ = model(input)\n    loss = criterion(logits, target)\n\n    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n    n = input.size(0)\n    objs.update(loss.data[0], n)\n    top1.update(prec1.data[0], n)\n    top5.update(prec5.data[0], n)\n\n    if step % args.report_freq == 0:\n      logging.info(\'valid %03d %e %f %f\', step, objs.avg, top1.avg, top5.avg)\n\n  return top1.avg, top5.avg, objs.avg\n\n\nif __name__ == \'__main__\':\n  main() \n'"
cnn/train_search.py,15,"b'import os\nimport sys\nimport time\nimport glob\nimport numpy as np\nimport torch\nimport utils\nimport logging\nimport argparse\nimport torch.nn as nn\nimport torch.utils\nimport torch.nn.functional as F\nimport torchvision.datasets as dset\nimport torch.backends.cudnn as cudnn\n\nfrom torch.autograd import Variable\nfrom model_search import Network\nfrom architect import Architect\n\n\nparser = argparse.ArgumentParser(""cifar"")\nparser.add_argument(\'--data\', type=str, default=\'../data\', help=\'location of the data corpus\')\nparser.add_argument(\'--batch_size\', type=int, default=64, help=\'batch size\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.025, help=\'init learning rate\')\nparser.add_argument(\'--learning_rate_min\', type=float, default=0.001, help=\'min learning rate\')\nparser.add_argument(\'--momentum\', type=float, default=0.9, help=\'momentum\')\nparser.add_argument(\'--weight_decay\', type=float, default=3e-4, help=\'weight decay\')\nparser.add_argument(\'--report_freq\', type=float, default=50, help=\'report frequency\')\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'gpu device id\')\nparser.add_argument(\'--epochs\', type=int, default=50, help=\'num of training epochs\')\nparser.add_argument(\'--init_channels\', type=int, default=16, help=\'num of init channels\')\nparser.add_argument(\'--layers\', type=int, default=8, help=\'total number of layers\')\nparser.add_argument(\'--model_path\', type=str, default=\'saved_models\', help=\'path to save the model\')\nparser.add_argument(\'--cutout\', action=\'store_true\', default=False, help=\'use cutout\')\nparser.add_argument(\'--cutout_length\', type=int, default=16, help=\'cutout length\')\nparser.add_argument(\'--drop_path_prob\', type=float, default=0.3, help=\'drop path probability\')\nparser.add_argument(\'--save\', type=str, default=\'EXP\', help=\'experiment name\')\nparser.add_argument(\'--seed\', type=int, default=2, help=\'random seed\')\nparser.add_argument(\'--grad_clip\', type=float, default=5, help=\'gradient clipping\')\nparser.add_argument(\'--train_portion\', type=float, default=0.5, help=\'portion of training data\')\nparser.add_argument(\'--unrolled\', action=\'store_true\', default=False, help=\'use one-step unrolled validation loss\')\nparser.add_argument(\'--arch_learning_rate\', type=float, default=3e-4, help=\'learning rate for arch encoding\')\nparser.add_argument(\'--arch_weight_decay\', type=float, default=1e-3, help=\'weight decay for arch encoding\')\nargs = parser.parse_args()\n\nargs.save = \'search-{}-{}\'.format(args.save, time.strftime(""%Y%m%d-%H%M%S""))\nutils.create_exp_dir(args.save, scripts_to_save=glob.glob(\'*.py\'))\n\nlog_format = \'%(asctime)s %(message)s\'\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO,\n    format=log_format, datefmt=\'%m/%d %I:%M:%S %p\')\nfh = logging.FileHandler(os.path.join(args.save, \'log.txt\'))\nfh.setFormatter(logging.Formatter(log_format))\nlogging.getLogger().addHandler(fh)\n\n\nCIFAR_CLASSES = 10\n\n\ndef main():\n  if not torch.cuda.is_available():\n    logging.info(\'no gpu device available\')\n    sys.exit(1)\n\n  np.random.seed(args.seed)\n  torch.cuda.set_device(args.gpu)\n  cudnn.benchmark = True\n  torch.manual_seed(args.seed)\n  cudnn.enabled=True\n  torch.cuda.manual_seed(args.seed)\n  logging.info(\'gpu device = %d\' % args.gpu)\n  logging.info(""args = %s"", args)\n\n  criterion = nn.CrossEntropyLoss()\n  criterion = criterion.cuda()\n  model = Network(args.init_channels, CIFAR_CLASSES, args.layers, criterion)\n  model = model.cuda()\n  logging.info(""param size = %fMB"", utils.count_parameters_in_MB(model))\n\n  optimizer = torch.optim.SGD(\n      model.parameters(),\n      args.learning_rate,\n      momentum=args.momentum,\n      weight_decay=args.weight_decay)\n\n  train_transform, valid_transform = utils._data_transforms_cifar10(args)\n  train_data = dset.CIFAR10(root=args.data, train=True, download=True, transform=train_transform)\n\n  num_train = len(train_data)\n  indices = list(range(num_train))\n  split = int(np.floor(args.train_portion * num_train))\n\n  train_queue = torch.utils.data.DataLoader(\n      train_data, batch_size=args.batch_size,\n      sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n      pin_memory=True, num_workers=2)\n\n  valid_queue = torch.utils.data.DataLoader(\n      train_data, batch_size=args.batch_size,\n      sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:num_train]),\n      pin_memory=True, num_workers=2)\n\n  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, float(args.epochs), eta_min=args.learning_rate_min)\n\n  architect = Architect(model, args)\n\n  for epoch in range(args.epochs):\n    scheduler.step()\n    lr = scheduler.get_lr()[0]\n    logging.info(\'epoch %d lr %e\', epoch, lr)\n\n    genotype = model.genotype()\n    logging.info(\'genotype = %s\', genotype)\n\n    print(F.softmax(model.alphas_normal, dim=-1))\n    print(F.softmax(model.alphas_reduce, dim=-1))\n\n    # training\n    train_acc, train_obj = train(train_queue, valid_queue, model, architect, criterion, optimizer, lr)\n    logging.info(\'train_acc %f\', train_acc)\n\n    # validation\n    valid_acc, valid_obj = infer(valid_queue, model, criterion)\n    logging.info(\'valid_acc %f\', valid_acc)\n\n    utils.save(model, os.path.join(args.save, \'weights.pt\'))\n\n\ndef train(train_queue, valid_queue, model, architect, criterion, optimizer, lr):\n  objs = utils.AvgrageMeter()\n  top1 = utils.AvgrageMeter()\n  top5 = utils.AvgrageMeter()\n\n  for step, (input, target) in enumerate(train_queue):\n    model.train()\n    n = input.size(0)\n\n    input = Variable(input, requires_grad=False).cuda()\n    target = Variable(target, requires_grad=False).cuda(async=True)\n\n    # get a random minibatch from the search queue with replacement\n    input_search, target_search = next(iter(valid_queue))\n    input_search = Variable(input_search, requires_grad=False).cuda()\n    target_search = Variable(target_search, requires_grad=False).cuda(async=True)\n\n    architect.step(input, target, input_search, target_search, lr, optimizer, unrolled=args.unrolled)\n\n    optimizer.zero_grad()\n    logits = model(input)\n    loss = criterion(logits, target)\n\n    loss.backward()\n    nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n    optimizer.step()\n\n    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n    objs.update(loss.data[0], n)\n    top1.update(prec1.data[0], n)\n    top5.update(prec5.data[0], n)\n\n    if step % args.report_freq == 0:\n      logging.info(\'train %03d %e %f %f\', step, objs.avg, top1.avg, top5.avg)\n\n  return top1.avg, objs.avg\n\n\ndef infer(valid_queue, model, criterion):\n  objs = utils.AvgrageMeter()\n  top1 = utils.AvgrageMeter()\n  top5 = utils.AvgrageMeter()\n  model.eval()\n\n  for step, (input, target) in enumerate(valid_queue):\n    input = Variable(input, volatile=True).cuda()\n    target = Variable(target, volatile=True).cuda(async=True)\n\n    logits = model(input)\n    loss = criterion(logits, target)\n\n    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n    n = input.size(0)\n    objs.update(loss.data[0], n)\n    top1.update(prec1.data[0], n)\n    top5.update(prec5.data[0], n)\n\n    if step % args.report_freq == 0:\n      logging.info(\'valid %03d %e %f %f\', step, objs.avg, top1.avg, top5.avg)\n\n  return top1.avg, objs.avg\n\n\nif __name__ == \'__main__\':\n  main() \n\n'"
cnn/utils.py,6,"b'import os\nimport numpy as np\nimport torch\nimport shutil\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\n\n\nclass AvgrageMeter(object):\n\n  def __init__(self):\n    self.reset()\n\n  def reset(self):\n    self.avg = 0\n    self.sum = 0\n    self.cnt = 0\n\n  def update(self, val, n=1):\n    self.sum += val * n\n    self.cnt += n\n    self.avg = self.sum / self.cnt\n\n\ndef accuracy(output, target, topk=(1,)):\n  maxk = max(topk)\n  batch_size = target.size(0)\n\n  _, pred = output.topk(maxk, 1, True, True)\n  pred = pred.t()\n  correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n  res = []\n  for k in topk:\n    correct_k = correct[:k].view(-1).float().sum(0)\n    res.append(correct_k.mul_(100.0/batch_size))\n  return res\n\n\nclass Cutout(object):\n    def __init__(self, length):\n        self.length = length\n\n    def __call__(self, img):\n        h, w = img.size(1), img.size(2)\n        mask = np.ones((h, w), np.float32)\n        y = np.random.randint(h)\n        x = np.random.randint(w)\n\n        y1 = np.clip(y - self.length // 2, 0, h)\n        y2 = np.clip(y + self.length // 2, 0, h)\n        x1 = np.clip(x - self.length // 2, 0, w)\n        x2 = np.clip(x + self.length // 2, 0, w)\n\n        mask[y1: y2, x1: x2] = 0.\n        mask = torch.from_numpy(mask)\n        mask = mask.expand_as(img)\n        img *= mask\n        return img\n\n\ndef _data_transforms_cifar10(args):\n  CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n  CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n\n  train_transform = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n  ])\n  if args.cutout:\n    train_transform.transforms.append(Cutout(args.cutout_length))\n\n  valid_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n    ])\n  return train_transform, valid_transform\n\n\ndef count_parameters_in_MB(model):\n  return np.sum(np.prod(v.size()) for name, v in model.named_parameters() if ""auxiliary"" not in name)/1e6\n\n\ndef save_checkpoint(state, is_best, save):\n  filename = os.path.join(save, \'checkpoint.pth.tar\')\n  torch.save(state, filename)\n  if is_best:\n    best_filename = os.path.join(save, \'model_best.pth.tar\')\n    shutil.copyfile(filename, best_filename)\n\n\ndef save(model, model_path):\n  torch.save(model.state_dict(), model_path)\n\n\ndef load(model, model_path):\n  model.load_state_dict(torch.load(model_path))\n\n\ndef drop_path(x, drop_prob):\n  if drop_prob > 0.:\n    keep_prob = 1.-drop_prob\n    mask = Variable(torch.cuda.FloatTensor(x.size(0), 1, 1, 1).bernoulli_(keep_prob))\n    x.div_(keep_prob)\n    x.mul_(mask)\n  return x\n\n\ndef create_exp_dir(path, scripts_to_save=None):\n  if not os.path.exists(path):\n    os.mkdir(path)\n  print(\'Experiment dir : {}\'.format(path))\n\n  if scripts_to_save is not None:\n    os.mkdir(os.path.join(path, \'scripts\'))\n    for script in scripts_to_save:\n      dst_file = os.path.join(path, \'scripts\', os.path.basename(script))\n      shutil.copyfile(script, dst_file)\n\n'"
cnn/visualize.py,0,"b'import sys\nimport genotypes\nfrom graphviz import Digraph\n\n\ndef plot(genotype, filename):\n  g = Digraph(\n      format=\'pdf\',\n      edge_attr=dict(fontsize=\'20\', fontname=""times""),\n      node_attr=dict(style=\'filled\', shape=\'rect\', align=\'center\', fontsize=\'20\', height=\'0.5\', width=\'0.5\', penwidth=\'2\', fontname=""times""),\n      engine=\'dot\')\n  g.body.extend([\'rankdir=LR\'])\n\n  g.node(""c_{k-2}"", fillcolor=\'darkseagreen2\')\n  g.node(""c_{k-1}"", fillcolor=\'darkseagreen2\')\n  assert len(genotype) % 2 == 0\n  steps = len(genotype) // 2\n\n  for i in range(steps):\n    g.node(str(i), fillcolor=\'lightblue\')\n\n  for i in range(steps):\n    for k in [2*i, 2*i + 1]:\n      op, j = genotype[k]\n      if j == 0:\n        u = ""c_{k-2}""\n      elif j == 1:\n        u = ""c_{k-1}""\n      else:\n        u = str(j-2)\n      v = str(i)\n      g.edge(u, v, label=op, fillcolor=""gray"")\n\n  g.node(""c_{k}"", fillcolor=\'palegoldenrod\')\n  for i in range(steps):\n    g.edge(str(i), ""c_{k}"", fillcolor=""gray"")\n\n  g.render(filename, view=True)\n\n\nif __name__ == \'__main__\':\n  if len(sys.argv) != 2:\n    print(""usage:\\n python {} ARCH_NAME"".format(sys.argv[0]))\n    sys.exit(1)\n\n  genotype_name = sys.argv[1]\n  try:\n    genotype = eval(\'genotypes.{}\'.format(genotype_name))\n  except AttributeError:\n    print(""{} is not specified in genotypes.py"".format(genotype_name)) \n    sys.exit(1)\n\n  plot(genotype.normal, ""normal"")\n  plot(genotype.reduce, ""reduction"")\n\n'"
rnn/architect.py,7,"b""import torch\nimport numpy as np\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n\ndef _concat(xs):\n  return torch.cat([x.view(-1) for x in xs])\n\n\ndef _clip(grads, max_norm):\n    total_norm = 0\n    for g in grads:\n        param_norm = g.data.norm(2)\n        total_norm += param_norm ** 2\n    total_norm = total_norm ** 0.5\n    clip_coef = max_norm / (total_norm + 1e-6)\n    if clip_coef < 1:\n        for g in grads:\n            g.data.mul_(clip_coef)\n    return clip_coef\n\n\nclass Architect(object):\n\n  def __init__(self, model, args):\n    self.network_weight_decay = args.wdecay\n    self.network_clip = args.clip\n    self.model = model\n    self.optimizer = torch.optim.Adam(self.model.arch_parameters(), lr=args.arch_lr, weight_decay=args.arch_wdecay)\n\n  def _compute_unrolled_model(self, hidden, input, target, eta):\n    loss, hidden_next = self.model._loss(hidden, input, target)\n    theta = _concat(self.model.parameters()).data\n    grads = torch.autograd.grad(loss, self.model.parameters())\n    clip_coef = _clip(grads, self.network_clip)\n    dtheta = _concat(grads).data + self.network_weight_decay*theta\n    unrolled_model = self._construct_model_from_theta(theta.sub(eta, dtheta))\n    return unrolled_model, clip_coef\n\n  def step(self,\n          hidden_train, input_train, target_train,\n          hidden_valid, input_valid, target_valid,\n          network_optimizer, unrolled):\n    eta = network_optimizer.param_groups[0]['lr']\n    self.optimizer.zero_grad()\n    if unrolled:\n        hidden = self._backward_step_unrolled(hidden_train, input_train, target_train, hidden_valid, input_valid, target_valid, eta)\n    else:\n        hidden = self._backward_step(hidden_valid, input_valid, target_valid)\n    self.optimizer.step()\n    return hidden, None\n\n  def _backward_step(self, hidden, input, target):\n    loss, hidden_next = self.model._loss(hidden, input, target)\n    loss.backward()\n    return hidden_next\n\n  def _backward_step_unrolled(self,\n          hidden_train, input_train, target_train,\n          hidden_valid, input_valid, target_valid, eta):\n    unrolled_model, clip_coef = self._compute_unrolled_model(hidden_train, input_train, target_train, eta)\n    unrolled_loss, hidden_next = unrolled_model._loss(hidden_valid, input_valid, target_valid)\n\n    unrolled_loss.backward()\n    dalpha = [v.grad for v in unrolled_model.arch_parameters()]\n    dtheta = [v.grad for v in unrolled_model.parameters()]\n    _clip(dtheta, self.network_clip)\n    vector = [dt.data for dt in dtheta]\n    implicit_grads = self._hessian_vector_product(vector, hidden_train, input_train, target_train, r=1e-2)\n\n    for g, ig in zip(dalpha, implicit_grads):\n      g.data.sub_(eta * clip_coef, ig.data)\n\n    for v, g in zip(self.model.arch_parameters(), dalpha):\n      if v.grad is None:\n        v.grad = Variable(g.data)\n      else:\n        v.grad.data.copy_(g.data)\n    return hidden_next\n\n  def _construct_model_from_theta(self, theta):\n    model_new = self.model.new()\n    model_dict = self.model.state_dict()\n\n    params, offset = {}, 0\n    for k, v in self.model.named_parameters():\n      v_length = np.prod(v.size())\n      params[k] = theta[offset: offset+v_length].view(v.size())\n      offset += v_length\n\n    assert offset == len(theta)\n    model_dict.update(params)\n    model_new.load_state_dict(model_dict)\n    return model_new.cuda()\n\n  def _hessian_vector_product(self, vector, hidden, input, target, r=1e-2):\n    R = r / _concat(vector).norm()\n    for p, v in zip(self.model.parameters(), vector):\n      p.data.add_(R, v)\n    loss, _ = self.model._loss(hidden, input, target)\n    grads_p = torch.autograd.grad(loss, self.model.arch_parameters())\n\n    for p, v in zip(self.model.parameters(), vector):\n      p.data.sub_(2*R, v)\n    loss, _ = self.model._loss(hidden, input, target)\n    grads_n = torch.autograd.grad(loss, self.model.arch_parameters())\n\n    for p, v in zip(self.model.parameters(), vector):\n      p.data.add_(R, v)\n\n    return [(x-y).div_(2*R) for x, y in zip(grads_p, grads_n)]\n\n"""
rnn/data.py,3,"b'import os\nimport torch\n\nfrom collections import Counter\n\n\nclass Dictionary(object):\n    def __init__(self):\n        self.word2idx = {}\n        self.idx2word = []\n        self.counter = Counter()\n        self.total = 0\n\n    def add_word(self, word):\n        if word not in self.word2idx:\n            self.idx2word.append(word)\n            self.word2idx[word] = len(self.idx2word) - 1\n        token_id = self.word2idx[word]\n        self.counter[token_id] += 1\n        self.total += 1\n        return self.word2idx[word]\n\n    def __len__(self):\n        return len(self.idx2word)\n\n\nclass Corpus(object):\n    def __init__(self, path):\n        self.dictionary = Dictionary()\n        self.train = self.tokenize(os.path.join(path, \'train.txt\'))\n        self.valid = self.tokenize(os.path.join(path, \'valid.txt\'))\n        self.test = self.tokenize(os.path.join(path, \'test.txt\'))\n\n    def tokenize(self, path):\n        """"""Tokenizes a text file.""""""\n        assert os.path.exists(path)\n        # Add words to the dictionary\n        with open(path, \'r\', encoding=\'utf-8\') as f:\n            tokens = 0\n            for line in f:\n                words = line.split() + [\'<eos>\']\n                tokens += len(words)\n                for word in words:\n                    self.dictionary.add_word(word)\n\n        # Tokenize file content\n        with open(path, \'r\', encoding=\'utf-8\') as f:\n            ids = torch.LongTensor(tokens)\n            token = 0\n            for line in f:\n                words = line.split() + [\'<eos>\']\n                for word in words:\n                    ids[token] = self.dictionary.word2idx[word]\n                    token += 1\n\n        return ids\n\nclass SentCorpus(object):\n    def __init__(self, path):\n        self.dictionary = Dictionary()\n        self.train = self.tokenize(os.path.join(path, \'train.txt\'))\n        self.valid = self.tokenize(os.path.join(path, \'valid.txt\'))\n        self.test = self.tokenize(os.path.join(path, \'test.txt\'))\n\n    def tokenize(self, path):\n        """"""Tokenizes a text file.""""""\n        assert os.path.exists(path)\n        # Add words to the dictionary\n        with open(path, \'r\', encoding=\'utf-8\') as f:\n            tokens = 0\n            for line in f:\n                words = line.split() + [\'<eos>\']\n                tokens += len(words)\n                for word in words:\n                    self.dictionary.add_word(word)\n\n        # Tokenize file content\n        sents = []\n        with open(path, \'r\', encoding=\'utf-8\') as f:\n            for line in f:\n                if not line:\n                    continue\n                words = line.split() + [\'<eos>\']\n                sent = torch.LongTensor(len(words))\n                for i, word in enumerate(words):\n                    sent[i] = self.dictionary.word2idx[word]\n                sents.append(sent)\n\n        return sents\n\nclass BatchSentLoader(object):\n    def __init__(self, sents, batch_size, pad_id=0, cuda=False, volatile=False):\n        self.sents = sents\n        self.batch_size = batch_size\n        self.sort_sents = sorted(sents, key=lambda x: x.size(0))\n        self.cuda = cuda\n        self.volatile = volatile\n        self.pad_id = pad_id\n\n    def __next__(self):\n        if self.idx >= len(self.sort_sents):\n            raise StopIteration\n\n        batch_size = min(self.batch_size, len(self.sort_sents)-self.idx)\n        batch = self.sort_sents[self.idx:self.idx+batch_size]\n        max_len = max([s.size(0) for s in batch])\n        tensor = torch.LongTensor(max_len, batch_size).fill_(self.pad_id)\n        for i in range(len(batch)):\n            s = batch[i]\n            tensor[:s.size(0),i].copy_(s)\n        if self.cuda:\n            tensor = tensor.cuda()\n\n        self.idx += batch_size\n\n        return tensor\n    \n    next = __next__\n\n    def __iter__(self):\n        self.idx = 0\n        return self\n\nif __name__ == \'__main__\':\n    corpus = SentCorpus(\'../penn\')\n    loader = BatchSentLoader(corpus.test, 10)\n    for i, d in enumerate(loader):\n        print(i, d.size())\n'"
rnn/genotypes.py,0,"b""from collections import namedtuple\n\nGenotype = namedtuple('Genotype', 'recurrent concat')\n\nPRIMITIVES = [\n    'none',\n    'tanh',\n    'relu',\n    'sigmoid',\n    'identity'\n]\nSTEPS = 8\nCONCAT = 8\n\nENAS = Genotype(\n    recurrent = [\n        ('tanh', 0),\n        ('tanh', 1),\n        ('relu', 1),\n        ('tanh', 3),\n        ('tanh', 3),\n        ('relu', 3),\n        ('relu', 4),\n        ('relu', 7),\n        ('relu', 8),\n        ('relu', 8),\n        ('relu', 8),\n    ],\n    concat = [2, 5, 6, 9, 10, 11]\n)\n\nDARTS_V1 = Genotype(recurrent=[('relu', 0), ('relu', 1), ('tanh', 2), ('relu', 3), ('relu', 4), ('identity', 1), ('relu', 5), ('relu', 1)], concat=range(1, 9))\nDARTS_V2 = Genotype(recurrent=[('sigmoid', 0), ('relu', 1), ('relu', 1), ('identity', 1), ('tanh', 2), ('sigmoid', 5), ('tanh', 3), ('relu', 5)], concat=range(1, 9))\n\nDARTS = DARTS_V2\n\n"""
rnn/model.py,12,"b'import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom genotypes import STEPS\nfrom utils import mask2d\nfrom utils import LockedDropout\nfrom utils import embedded_dropout\nfrom torch.autograd import Variable\n\nINITRANGE = 0.04\n\n\nclass DARTSCell(nn.Module):\n\n  def __init__(self, ninp, nhid, dropouth, dropoutx, genotype):\n    super(DARTSCell, self).__init__()\n    self.nhid = nhid\n    self.dropouth = dropouth\n    self.dropoutx = dropoutx\n    self.genotype = genotype\n\n    # genotype is None when doing arch search\n    steps = len(self.genotype.recurrent) if self.genotype is not None else STEPS\n    self._W0 = nn.Parameter(torch.Tensor(ninp+nhid, 2*nhid).uniform_(-INITRANGE, INITRANGE))\n    self._Ws = nn.ParameterList([\n        nn.Parameter(torch.Tensor(nhid, 2*nhid).uniform_(-INITRANGE, INITRANGE)) for i in range(steps)\n    ])\n\n  def forward(self, inputs, hidden):\n    T, B = inputs.size(0), inputs.size(1)\n\n    if self.training:\n      x_mask = mask2d(B, inputs.size(2), keep_prob=1.-self.dropoutx)\n      h_mask = mask2d(B, hidden.size(2), keep_prob=1.-self.dropouth)\n    else:\n      x_mask = h_mask = None\n\n    hidden = hidden[0]\n    hiddens = []\n    for t in range(T):\n      hidden = self.cell(inputs[t], hidden, x_mask, h_mask)\n      hiddens.append(hidden)\n    hiddens = torch.stack(hiddens)\n    return hiddens, hiddens[-1].unsqueeze(0)\n\n  def _compute_init_state(self, x, h_prev, x_mask, h_mask):\n    if self.training:\n      xh_prev = torch.cat([x * x_mask, h_prev * h_mask], dim=-1)\n    else:\n      xh_prev = torch.cat([x, h_prev], dim=-1)\n    c0, h0 = torch.split(xh_prev.mm(self._W0), self.nhid, dim=-1)\n    c0 = c0.sigmoid()\n    h0 = h0.tanh()\n    s0 = h_prev + c0 * (h0-h_prev)\n    return s0\n\n  def _get_activation(self, name):\n    if name == \'tanh\':\n      f = F.tanh\n    elif name == \'relu\':\n      f = F.relu\n    elif name == \'sigmoid\':\n      f = F.sigmoid\n    elif name == \'identity\':\n      f = lambda x: x\n    else:\n      raise NotImplementedError\n    return f\n\n  def cell(self, x, h_prev, x_mask, h_mask):\n    s0 = self._compute_init_state(x, h_prev, x_mask, h_mask)\n\n    states = [s0]\n    for i, (name, pred) in enumerate(self.genotype.recurrent):\n      s_prev = states[pred]\n      if self.training:\n        ch = (s_prev * h_mask).mm(self._Ws[i])\n      else:\n        ch = s_prev.mm(self._Ws[i])\n      c, h = torch.split(ch, self.nhid, dim=-1)\n      c = c.sigmoid()\n      fn = self._get_activation(name)\n      h = fn(h)\n      s = s_prev + c * (h-s_prev)\n      states += [s]\n    output = torch.mean(torch.stack([states[i] for i in self.genotype.concat], -1), -1)\n    return output\n\n\nclass RNNModel(nn.Module):\n    """"""Container module with an encoder, a recurrent module, and a decoder.""""""\n\n    def __init__(self, ntoken, ninp, nhid, nhidlast, \n                 dropout=0.5, dropouth=0.5, dropoutx=0.5, dropouti=0.5, dropoute=0.1,\n                 cell_cls=DARTSCell, genotype=None):\n        super(RNNModel, self).__init__()\n        self.lockdrop = LockedDropout()\n        self.encoder = nn.Embedding(ntoken, ninp)\n        \n        assert ninp == nhid == nhidlast\n        if cell_cls == DARTSCell:\n            assert genotype is not None\n            self.rnns = [cell_cls(ninp, nhid, dropouth, dropoutx, genotype)]\n        else:\n            assert genotype is None\n            self.rnns = [cell_cls(ninp, nhid, dropouth, dropoutx)]\n\n        self.rnns = torch.nn.ModuleList(self.rnns)\n        self.decoder = nn.Linear(ninp, ntoken)\n        self.decoder.weight = self.encoder.weight\n        self.init_weights()\n\n        self.ninp = ninp\n        self.nhid = nhid\n        self.nhidlast = nhidlast\n        self.dropout = dropout\n        self.dropouti = dropouti\n        self.dropoute = dropoute\n        self.ntoken = ntoken\n        self.cell_cls = cell_cls\n\n    def init_weights(self):\n        self.encoder.weight.data.uniform_(-INITRANGE, INITRANGE)\n        self.decoder.bias.data.fill_(0)\n        self.decoder.weight.data.uniform_(-INITRANGE, INITRANGE)\n\n    def forward(self, input, hidden, return_h=False):\n        batch_size = input.size(1)\n\n        emb = embedded_dropout(self.encoder, input, dropout=self.dropoute if self.training else 0)\n        emb = self.lockdrop(emb, self.dropouti)\n\n        raw_output = emb\n        new_hidden = []\n        raw_outputs = []\n        outputs = []\n        for l, rnn in enumerate(self.rnns):\n            current_input = raw_output\n            raw_output, new_h = rnn(raw_output, hidden[l])\n            new_hidden.append(new_h)\n            raw_outputs.append(raw_output)\n        hidden = new_hidden\n\n        output = self.lockdrop(raw_output, self.dropout)\n        outputs.append(output)\n\n        logit = self.decoder(output.view(-1, self.ninp))\n        log_prob = nn.functional.log_softmax(logit, dim=-1)\n        model_output = log_prob\n        model_output = model_output.view(-1, batch_size, self.ntoken)\n\n        if return_h:\n            return model_output, hidden, raw_outputs, outputs\n        return model_output, hidden\n\n    def init_hidden(self, bsz):\n      weight = next(self.parameters()).data\n      return [Variable(weight.new(1, bsz, self.nhid).zero_())]\n\n'"
rnn/model_search.py,9,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom genotypes import PRIMITIVES, STEPS, CONCAT, Genotype\nfrom torch.autograd import Variable\nfrom collections import namedtuple\nfrom model import DARTSCell, RNNModel\n\n\nclass DARTSCellSearch(DARTSCell):\n\n  def __init__(self, ninp, nhid, dropouth, dropoutx):\n    super(DARTSCellSearch, self).__init__(ninp, nhid, dropouth, dropoutx, genotype=None)\n    self.bn = nn.BatchNorm1d(nhid, affine=False)\n\n  def cell(self, x, h_prev, x_mask, h_mask):\n    s0 = self._compute_init_state(x, h_prev, x_mask, h_mask)\n    s0 = self.bn(s0)\n    probs = F.softmax(self.weights, dim=-1)\n\n    offset = 0\n    states = s0.unsqueeze(0)\n    for i in range(STEPS):\n      if self.training:\n        masked_states = states * h_mask.unsqueeze(0)\n      else:\n        masked_states = states\n      ch = masked_states.view(-1, self.nhid).mm(self._Ws[i]).view(i+1, -1, 2*self.nhid)\n      c, h = torch.split(ch, self.nhid, dim=-1)\n      c = c.sigmoid()\n\n      s = torch.zeros_like(s0)\n      for k, name in enumerate(PRIMITIVES):\n        if name == 'none':\n          continue\n        fn = self._get_activation(name)\n        unweighted = states + c * (fn(h) - states)\n        s += torch.sum(probs[offset:offset+i+1, k].unsqueeze(-1).unsqueeze(-1) * unweighted, dim=0)\n      s = self.bn(s)\n      states = torch.cat([states, s.unsqueeze(0)], 0)\n      offset += i+1\n    output = torch.mean(states[-CONCAT:], dim=0)\n    return output\n\n\nclass RNNModelSearch(RNNModel):\n\n    def __init__(self, *args):\n        super(RNNModelSearch, self).__init__(*args, cell_cls=DARTSCellSearch, genotype=None)\n        self._args = args\n        self._initialize_arch_parameters()\n\n    def new(self):\n        model_new = RNNModelSearch(*self._args)\n        for x, y in zip(model_new.arch_parameters(), self.arch_parameters()):\n            x.data.copy_(y.data)\n        return model_new\n\n    def _initialize_arch_parameters(self):\n      k = sum(i for i in range(1, STEPS+1))\n      weights_data = torch.randn(k, len(PRIMITIVES)).mul_(1e-3)\n      self.weights = Variable(weights_data.cuda(), requires_grad=True)\n      self._arch_parameters = [self.weights]\n      for rnn in self.rnns:\n        rnn.weights = self.weights\n\n    def arch_parameters(self):\n      return self._arch_parameters\n\n    def _loss(self, hidden, input, target):\n      log_prob, hidden_next = self(input, hidden, return_h=False)\n      loss = nn.functional.nll_loss(log_prob.view(-1, log_prob.size(2)), target)\n      return loss, hidden_next\n\n    def genotype(self):\n\n      def _parse(probs):\n        gene = []\n        start = 0\n        for i in range(STEPS):\n          end = start + i + 1\n          W = probs[start:end].copy()\n          j = sorted(range(i + 1), key=lambda x: -max(W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[0]\n          k_best = None\n          for k in range(len(W[j])):\n            if k != PRIMITIVES.index('none'):\n              if k_best is None or W[j][k] > W[j][k_best]:\n                k_best = k\n          gene.append((PRIMITIVES[k_best], j))\n          start = end\n        return gene\n\n      gene = _parse(F.softmax(self.weights, dim=-1).data.cpu().numpy())\n      genotype = Genotype(recurrent=gene, concat=range(STEPS+1)[-CONCAT:])\n      return genotype\n\n"""
rnn/test.py,7,"b'import argparse\nimport os, sys\nimport time\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\n\nimport data\nimport model\n\nfrom utils import batchify, get_batch, repackage_hidden, create_exp_dir, save_checkpoint\n\nparser = argparse.ArgumentParser(description=\'PyTorch PennTreeBank/WikiText2 Language Model\')\nparser.add_argument(\'--data\', type=str, default=\'../data/penn/\',\n                    help=\'location of the data corpus\')\nparser.add_argument(\'--emsize\', type=int, default=850,\n                    help=\'size of word embeddings\')\nparser.add_argument(\'--nhid\', type=int, default=850,\n                    help=\'number of hidden units per layer\')\nparser.add_argument(\'--nhidlast\', type=int, default=850,\n                    help=\'number of hidden units for the last rnn layer\')\nparser.add_argument(\'--lr\', type=float, default=20,\n                    help=\'initial learning rate\')\nparser.add_argument(\'--clip\', type=float, default=0.25,\n                    help=\'gradient clipping\')\nparser.add_argument(\'--epochs\', type=int, default=8000,\n                    help=\'upper epoch limit\')\nparser.add_argument(\'--batch_size\', type=int, default=64, metavar=\'N\',\n                    help=\'batch size\')\nparser.add_argument(\'--bptt\', type=int, default=35,\n                    help=\'sequence length\')\nparser.add_argument(\'--dropout\', type=float, default=0.75,\n                    help=\'dropout applied to layers (0 = no dropout)\')\nparser.add_argument(\'--dropouth\', type=float, default=0.3,\n                    help=\'dropout for rnn layers (0 = no dropout)\')\nparser.add_argument(\'--dropouti\', type=float, default=0.2,\n                    help=\'dropout for input embedding layers (0 = no dropout)\')\nparser.add_argument(\'--dropoute\', type=float, default=0.2,\n                    help=\'dropout to remove words from embedding layer (0 = no dropout)\')\nparser.add_argument(\'--seed\', type=int, default=1267,\n                    help=\'random seed\')\nparser.add_argument(\'--nonmono\', type=int, default=5,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda\', action=\'store_false\',\n                    help=\'use CUDA\')\nparser.add_argument(\'--log-interval\', type=int, default=200, metavar=\'N\',\n                    help=\'report interval\')\nparser.add_argument(\'--model_path\', type=str,  default=\'EXP/model.pt\',\n                    help=\'path to load the pretrained model\')\nparser.add_argument(\'--alpha\', type=float, default=0,\n                    help=\'alpha L2 regularization on RNN activation (alpha = 0 means no regularization)\')\nparser.add_argument(\'--beta\', type=float, default=1e-3,\n                    help=\'beta slowness regularization applied on RNN activiation (beta = 0 means no regularization)\')\nparser.add_argument(\'--wdecay\', type=float, default=5e-7,\n                    help=\'weight decay applied to all weights\')\nparser.add_argument(\'--continue_train\', action=\'store_true\',\n                    help=\'continue train from a checkpoint\')\nparser.add_argument(\'--n_experts\', type=int, default=1,\n                    help=\'number of experts\')\nparser.add_argument(\'--max_seq_len_delta\', type=int, default=20,\n                    help=\'max sequence length\')\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU device to use\')\nargs = parser.parse_args()\n\ndef logging(s, print_=True, log_=True):\n    print(s)\n\n# Set the random seed manually for reproducibility.\nnp.random.seed(args.seed)\ntorch.manual_seed(args.seed)\nif torch.cuda.is_available():\n    if not args.cuda:\n        print(""WARNING: You have a CUDA device, so you should probably run with --cuda"")\n    else:\n        torch.cuda.set_device(args.gpu)\n        cudnn.benchmark = True\n        cudnn.enabled=True\n        torch.cuda.manual_seed_all(args.seed)\n\n\ncorpus = data.Corpus(args.data)\ntest_batch_size = 1\ntest_data = batchify(corpus.test, test_batch_size, args)\n\n\ndef evaluate(data_source, batch_size=10):\n    # Turn on evaluation mode which disables dropout.\n    model.eval()\n    total_loss = 0\n    ntokens = len(corpus.dictionary)\n    hidden = model.init_hidden(batch_size)\n    for i in range(0, data_source.size(0) - 1, args.bptt):\n        print(i, data_source.size(0)-1)\n        data, targets = get_batch(data_source, i, args, evaluation=True)\n        targets = targets.view(-1)\n\n        log_prob, hidden = parallel_model(data, hidden)\n        loss = nn.functional.nll_loss(log_prob.view(-1, log_prob.size(2)), targets).data\n\n        total_loss += loss * len(data)\n\n        hidden = repackage_hidden(hidden)\n    return total_loss[0] / len(data_source)\n\n# Load the best saved model.\nmodel = torch.load(args.model_path)\n\ntotal_params = sum(x.data.nelement() for x in model.parameters())\nlogging(\'Args: {}\'.format(args))\nlogging(\'Model total parameters: {}\'.format(total_params))\nparallel_model = model.cuda()\n\n# Run on test data.\ntest_loss = evaluate(test_data, test_batch_size)\nlogging(\'=\' * 89)\nlogging(\'| End of training | test loss {:5.2f} | test ppl {:8.2f}\'.format(\n    test_loss, math.exp(test_loss)))\nlogging(\'=\' * 89)\n\n'"
rnn/train.py,21,"b'import os\nimport gc\nimport sys\nimport glob\nimport time\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport logging\nimport argparse\nimport genotypes\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nimport data\nimport model\n\nfrom torch.autograd import Variable\nfrom utils import batchify, get_batch, repackage_hidden, create_exp_dir, save_checkpoint\n\nparser = argparse.ArgumentParser(description=\'PyTorch PennTreeBank/WikiText2 Language Model\')\nparser.add_argument(\'--data\', type=str, default=\'../data/penn/\',\n                    help=\'location of the data corpus\')\nparser.add_argument(\'--emsize\', type=int, default=850,\n                    help=\'size of word embeddings\')\nparser.add_argument(\'--nhid\', type=int, default=850,\n                    help=\'number of hidden units per layer\')\nparser.add_argument(\'--nhidlast\', type=int, default=850,\n                    help=\'number of hidden units for the last rnn layer\')\nparser.add_argument(\'--lr\', type=float, default=20,\n                    help=\'initial learning rate\')\nparser.add_argument(\'--clip\', type=float, default=0.25,\n                    help=\'gradient clipping\')\nparser.add_argument(\'--epochs\', type=int, default=8000,\n                    help=\'upper epoch limit\')\nparser.add_argument(\'--batch_size\', type=int, default=64, metavar=\'N\',\n                    help=\'batch size\')\nparser.add_argument(\'--bptt\', type=int, default=35,\n                    help=\'sequence length\')\nparser.add_argument(\'--dropout\', type=float, default=0.75,\n                    help=\'dropout applied to layers (0 = no dropout)\')\nparser.add_argument(\'--dropouth\', type=float, default=0.25,\n                    help=\'dropout for hidden nodes in rnn layers (0 = no dropout)\')\nparser.add_argument(\'--dropoutx\', type=float, default=0.75,\n                    help=\'dropout for input nodes rnn layers (0 = no dropout)\')\nparser.add_argument(\'--dropouti\', type=float, default=0.2,\n                    help=\'dropout for input embedding layers (0 = no dropout)\')\nparser.add_argument(\'--dropoute\', type=float, default=0.1,\n                    help=\'dropout to remove words from embedding layer (0 = no dropout)\')\nparser.add_argument(\'--seed\', type=int, default=1267,\n                    help=\'random seed\')\nparser.add_argument(\'--nonmono\', type=int, default=5,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda\', action=\'store_false\',\n                    help=\'use CUDA\')\nparser.add_argument(\'--log-interval\', type=int, default=200, metavar=\'N\',\n                    help=\'report interval\')\nparser.add_argument(\'--save\', type=str,  default=\'EXP\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--alpha\', type=float, default=0,\n                    help=\'alpha L2 regularization on RNN activation (alpha = 0 means no regularization)\')\nparser.add_argument(\'--beta\', type=float, default=1e-3,\n                    help=\'beta slowness regularization applied on RNN activiation (beta = 0 means no regularization)\')\nparser.add_argument(\'--wdecay\', type=float, default=8e-7,\n                    help=\'weight decay applied to all weights\')\nparser.add_argument(\'--continue_train\', action=\'store_true\',\n                    help=\'continue train from a checkpoint\')\nparser.add_argument(\'--small_batch_size\', type=int, default=-1,\n                    help=\'the batch size for computation. batch_size should be divisible by small_batch_size.\\\n                     In our implementation, we compute gradients with small_batch_size multiple times, and accumulate the gradients\\\n                     until batch_size is reached. An update step is then performed.\')\nparser.add_argument(\'--max_seq_len_delta\', type=int, default=20,\n                    help=\'max sequence length\')\nparser.add_argument(\'--single_gpu\', default=True, action=\'store_false\', \n                    help=\'use single GPU\')\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU device to use\')\nparser.add_argument(\'--arch\', type=str, default=\'DARTS\', help=\'which architecture to use\')\nargs = parser.parse_args()\n\nif args.nhidlast < 0:\n    args.nhidlast = args.emsize\nif args.small_batch_size < 0:\n    args.small_batch_size = args.batch_size\n\nif not args.continue_train:\n    args.save = \'eval-{}-{}\'.format(args.save, time.strftime(""%Y%m%d-%H%M%S""))\n    create_exp_dir(args.save, scripts_to_save=glob.glob(\'*.py\'))\n\nlog_format = \'%(asctime)s %(message)s\'\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO,\n    format=log_format, datefmt=\'%m/%d %I:%M:%S %p\')\nfh = logging.FileHandler(os.path.join(args.save, \'log.txt\'))\nfh.setFormatter(logging.Formatter(log_format))\nlogging.getLogger().addHandler(fh)\n\n# Set the random seed manually for reproducibility.\nnp.random.seed(args.seed)\ntorch.manual_seed(args.seed)\nif torch.cuda.is_available():\n    if not args.cuda:\n        print(""WARNING: You have a CUDA device, so you should probably run with --cuda"")\n    else:\n        torch.cuda.set_device(args.gpu)\n        cudnn.benchmark = True\n        cudnn.enabled=True\n        torch.cuda.manual_seed_all(args.seed)\n\ncorpus = data.Corpus(args.data)\n\neval_batch_size = 10\ntest_batch_size = 1\ntrain_data = batchify(corpus.train, args.batch_size, args)\nval_data = batchify(corpus.valid, eval_batch_size, args)\ntest_data = batchify(corpus.test, test_batch_size, args)\n\n\nntokens = len(corpus.dictionary)\nif args.continue_train:\n    model = torch.load(os.path.join(args.save, \'model.pt\'))\nelse:\n    genotype = eval(""genotypes.%s"" % args.arch)\n    model = model.RNNModel(ntokens, args.emsize, args.nhid, args.nhidlast, \n                       args.dropout, args.dropouth, args.dropoutx, args.dropouti, args.dropoute, \n                       cell_cls=model.DARTSCell, genotype=genotype)\n\nif args.cuda:\n    if args.single_gpu:\n        parallel_model = model.cuda()\n    else:\n        parallel_model = nn.DataParallel(model, dim=1).cuda()\nelse:\n    parallel_model = model\n\ntotal_params = sum(x.data.nelement() for x in model.parameters())\nlogging.info(\'Args: {}\'.format(args))\nlogging.info(\'Model total parameters: {}\'.format(total_params))\nlogging.info(\'Genotype: {}\'.format(genotype))\n\n\ndef evaluate(data_source, batch_size=10):\n    # Turn on evaluation mode which disables dropout.\n    model.eval()\n    total_loss = 0\n    ntokens = len(corpus.dictionary)\n    hidden = model.init_hidden(batch_size)\n    for i in range(0, data_source.size(0) - 1, args.bptt):\n        data, targets = get_batch(data_source, i, args, evaluation=True)\n        targets = targets.view(-1)\n\n        log_prob, hidden = parallel_model(data, hidden)\n        loss = nn.functional.nll_loss(log_prob.view(-1, log_prob.size(2)), targets).data\n\n        total_loss += loss * len(data)\n\n        hidden = repackage_hidden(hidden)\n    return total_loss[0] / len(data_source)\n\n\ndef train():\n    assert args.batch_size % args.small_batch_size == 0, \'batch_size must be divisible by small_batch_size\'\n\n    # Turn on training mode which enables dropout.\n    total_loss = 0\n    start_time = time.time()\n    ntokens = len(corpus.dictionary)\n    hidden = [model.init_hidden(args.small_batch_size) for _ in range(args.batch_size // args.small_batch_size)]\n    batch, i = 0, 0\n    while i < train_data.size(0) - 1 - 1:\n        bptt = args.bptt if np.random.random() < 0.95 else args.bptt / 2.\n        # Prevent excessively small or negative sequence lengths\n        seq_len = max(5, int(np.random.normal(bptt, 5)))\n        # There\'s a very small chance that it could select a very long sequence length resulting in OOM\n        seq_len = min(seq_len, args.bptt + args.max_seq_len_delta)\n\n        lr2 = optimizer.param_groups[0][\'lr\']\n        optimizer.param_groups[0][\'lr\'] = lr2 * seq_len / args.bptt\n        model.train()\n        data, targets = get_batch(train_data, i, args, seq_len=seq_len)\n\n        optimizer.zero_grad()\n\n        start, end, s_id = 0, args.small_batch_size, 0\n        while start < args.batch_size:\n            cur_data, cur_targets = data[:, start: end], targets[:, start: end].contiguous().view(-1)\n\n            # Starting each batch, we detach the hidden state from how it was previously produced.\n            # If we didn\'t, the model would try backpropagating all the way to start of the dataset.\n            hidden[s_id] = repackage_hidden(hidden[s_id])\n\n            log_prob, hidden[s_id], rnn_hs, dropped_rnn_hs = parallel_model(cur_data, hidden[s_id], return_h=True)\n            raw_loss = nn.functional.nll_loss(log_prob.view(-1, log_prob.size(2)), cur_targets)\n\n            loss = raw_loss\n            # Activiation Regularization\n            if args.alpha > 0:\n              loss = loss + sum(args.alpha * dropped_rnn_h.pow(2).mean() for dropped_rnn_h in dropped_rnn_hs[-1:])\n            # Temporal Activation Regularization (slowness)\n            loss = loss + sum(args.beta * (rnn_h[1:] - rnn_h[:-1]).pow(2).mean() for rnn_h in rnn_hs[-1:])\n            loss *= args.small_batch_size / args.batch_size\n            total_loss += raw_loss.data * args.small_batch_size / args.batch_size\n            loss.backward()\n\n            s_id += 1\n            start = end\n            end = start + args.small_batch_size\n\n            gc.collect()\n\n        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs.\n        torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n        optimizer.step()\n\n        # total_loss += raw_loss.data\n        optimizer.param_groups[0][\'lr\'] = lr2\n\n        if np.isnan(total_loss[0]):\n          raise\n\n        if batch % args.log_interval == 0 and batch > 0:\n            cur_loss = total_loss[0] / args.log_interval\n            elapsed = time.time() - start_time\n            logging.info(\'| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | \'\n                    \'loss {:5.2f} | ppl {:8.2f}\'.format(\n                epoch, batch, len(train_data) // args.bptt, optimizer.param_groups[0][\'lr\'],\n                elapsed * 1000 / args.log_interval, cur_loss, math.exp(cur_loss)))\n            total_loss = 0\n            start_time = time.time()\n        batch += 1\n        i += seq_len\n\n# Loop over epochs.\nlr = args.lr\nbest_val_loss = []\nstored_loss = 100000000\n\n# At any point you can hit Ctrl + C to break out of training early.\ntry:\n    if args.continue_train:\n        optimizer_state = torch.load(os.path.join(args.save, \'optimizer.pt\'))\n        if \'t0\' in optimizer_state[\'param_groups\'][0]:\n            optimizer = torch.optim.ASGD(model.parameters(), lr=args.lr, t0=0, lambd=0., weight_decay=args.wdecay)\n        else:\n            optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n        optimizer.load_state_dict(optimizer_state)\n    else:\n        optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n\n    epoch = 1\n    while epoch < args.epochs + 1:\n        epoch_start_time = time.time()\n        try:\n          train()\n        except:\n          logging.info(\'rolling back to the previous best model ...\')\n          model = torch.load(os.path.join(args.save, \'model.pt\'))\n          parallel_model = model.cuda()\n          \n          optimizer_state = torch.load(os.path.join(args.save, \'optimizer.pt\'))\n          if \'t0\' in optimizer_state[\'param_groups\'][0]:\n            optimizer = torch.optim.ASGD(model.parameters(), lr=args.lr, t0=0, lambd=0., weight_decay=args.wdecay)\n          else:\n            optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n          optimizer.load_state_dict(optimizer_state)\n\n          epoch = torch.load(os.path.join(args.save, \'misc.pt\'))[\'epoch\']\n          continue\n\n        if \'t0\' in optimizer.param_groups[0]:\n            tmp = {}\n            for prm in model.parameters():\n                tmp[prm] = prm.data.clone()\n                prm.data = optimizer.state[prm][\'ax\'].clone()\n\n            val_loss2 = evaluate(val_data)\n            logging.info(\'-\' * 89)\n            logging.info(\'| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | \'\n                    \'valid ppl {:8.2f}\'.format(epoch, (time.time() - epoch_start_time),\n                                               val_loss2, math.exp(val_loss2)))\n            logging.info(\'-\' * 89)\n\n            if val_loss2 < stored_loss:\n                save_checkpoint(model, optimizer, epoch, args.save)\n                logging.info(\'Saving Averaged!\')\n                stored_loss = val_loss2\n\n            for prm in model.parameters():\n                prm.data = tmp[prm].clone()\n\n        else:\n            val_loss = evaluate(val_data, eval_batch_size)\n            logging.info(\'-\' * 89)\n            logging.info(\'| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | \'\n                    \'valid ppl {:8.2f}\'.format(epoch, (time.time() - epoch_start_time),\n                                               val_loss, math.exp(val_loss)))\n            logging.info(\'-\' * 89)\n\n            if val_loss < stored_loss:\n                save_checkpoint(model, optimizer, epoch, args.save)\n                logging.info(\'Saving Normal!\')\n                stored_loss = val_loss\n\n            if \'t0\' not in optimizer.param_groups[0] and (len(best_val_loss)>args.nonmono and val_loss > min(best_val_loss[:-args.nonmono])):\n                logging.info(\'Switching!\')\n                optimizer = torch.optim.ASGD(model.parameters(), lr=args.lr, t0=0, lambd=0., weight_decay=args.wdecay)\n            best_val_loss.append(val_loss)\n\n        epoch += 1\n\nexcept KeyboardInterrupt:\n    logging.info(\'-\' * 89)\n    logging.info(\'Exiting from training early\')\n\n# Load the best saved model.\nmodel = torch.load(os.path.join(args.save, \'model.pt\'))\nparallel_model = model.cuda()\n\n# Run on test data.\ntest_loss = evaluate(test_data, test_batch_size)\nlogging.info(\'=\' * 89)\nlogging.info(\'| End of training | test loss {:5.2f} | test ppl {:8.2f}\'.format(\n    test_loss, math.exp(test_loss)))\nlogging.info(\'=\' * 89)\n'"
rnn/train_search.py,13,"b'import argparse\nimport os, sys, glob\nimport time\nimport math\nimport numpy as np\nimport torch\nimport logging\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\nfrom architect import Architect\n\nimport gc\n\nimport data\nimport model_search as model\n\nfrom utils import batchify, get_batch, repackage_hidden, create_exp_dir, save_checkpoint\n\nparser = argparse.ArgumentParser(description=\'PyTorch PennTreeBank/WikiText2 Language Model\')\nparser.add_argument(\'--data\', type=str, default=\'../data/penn/\',\n                    help=\'location of the data corpus\')\nparser.add_argument(\'--emsize\', type=int, default=300,\n                    help=\'size of word embeddings\')\nparser.add_argument(\'--nhid\', type=int, default=300,\n                    help=\'number of hidden units per layer\')\nparser.add_argument(\'--nhidlast\', type=int, default=300,\n                    help=\'number of hidden units for the last rnn layer\')\nparser.add_argument(\'--lr\', type=float, default=20,\n                    help=\'initial learning rate\')\nparser.add_argument(\'--clip\', type=float, default=0.25,\n                    help=\'gradient clipping\')\nparser.add_argument(\'--epochs\', type=int, default=50,\n                    help=\'upper epoch limit\')\nparser.add_argument(\'--batch_size\', type=int, default=256, metavar=\'N\',\n                    help=\'batch size\')\nparser.add_argument(\'--bptt\', type=int, default=35,\n                    help=\'sequence length\')\nparser.add_argument(\'--dropout\', type=float, default=0.75,\n                    help=\'dropout applied to layers (0 = no dropout)\')\nparser.add_argument(\'--dropouth\', type=float, default=0.25,\n                    help=\'dropout for hidden nodes in rnn layers (0 = no dropout)\')\nparser.add_argument(\'--dropoutx\', type=float, default=0.75,\n                    help=\'dropout for input nodes in rnn layers (0 = no dropout)\')\nparser.add_argument(\'--dropouti\', type=float, default=0.2,\n                    help=\'dropout for input embedding layers (0 = no dropout)\')\nparser.add_argument(\'--dropoute\', type=float, default=0,\n                    help=\'dropout to remove words from embedding layer (0 = no dropout)\')\nparser.add_argument(\'--seed\', type=int, default=3,\n                    help=\'random seed\')\nparser.add_argument(\'--nonmono\', type=int, default=5,\n                    help=\'random seed\')\nparser.add_argument(\'--cuda\', action=\'store_false\',\n                    help=\'use CUDA\')\nparser.add_argument(\'--log-interval\', type=int, default=50, metavar=\'N\',\n                    help=\'report interval\')\nparser.add_argument(\'--save\', type=str,  default=\'EXP\',\n                    help=\'path to save the final model\')\nparser.add_argument(\'--alpha\', type=float, default=0,\n                    help=\'alpha L2 regularization on RNN activation (alpha = 0 means no regularization)\')\nparser.add_argument(\'--beta\', type=float, default=1e-3,\n                    help=\'beta slowness regularization applied on RNN activiation (beta = 0 means no regularization)\')\nparser.add_argument(\'--wdecay\', type=float, default=5e-7,\n                    help=\'weight decay applied to all weights\')\nparser.add_argument(\'--continue_train\', action=\'store_true\',\n                    help=\'continue train from a checkpoint\')\nparser.add_argument(\'--small_batch_size\', type=int, default=-1,\n                    help=\'the batch size for computation. batch_size should be divisible by small_batch_size.\\\n                     In our implementation, we compute gradients with small_batch_size multiple times, and accumulate the gradients\\\n                     until batch_size is reached. An update step is then performed.\')\nparser.add_argument(\'--max_seq_len_delta\', type=int, default=20,\n                    help=\'max sequence length\')\nparser.add_argument(\'--single_gpu\', default=True, action=\'store_false\', \n                    help=\'use single GPU\')\nparser.add_argument(\'--gpu\', type=int, default=0, help=\'GPU device to use\')\nparser.add_argument(\'--unrolled\', action=\'store_true\', default=False, help=\'use one-step unrolled validation loss\')\nparser.add_argument(\'--arch_wdecay\', type=float, default=1e-3,\n                    help=\'weight decay for the architecture encoding alpha\')\nparser.add_argument(\'--arch_lr\', type=float, default=3e-3,\n                    help=\'learning rate for the architecture encoding alpha\')\nargs = parser.parse_args()\n\nif args.nhidlast < 0:\n    args.nhidlast = args.emsize\nif args.small_batch_size < 0:\n    args.small_batch_size = args.batch_size\n\nif not args.continue_train:\n    args.save = \'search-{}-{}\'.format(args.save, time.strftime(""%Y%m%d-%H%M%S""))\n    create_exp_dir(args.save, scripts_to_save=glob.glob(\'*.py\'))\n\nlog_format = \'%(asctime)s %(message)s\'\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO,\n    format=log_format, datefmt=\'%m/%d %I:%M:%S %p\')\nfh = logging.FileHandler(os.path.join(args.save, \'log.txt\'))\nfh.setFormatter(logging.Formatter(log_format))\nlogging.getLogger().addHandler(fh)\n\n# Set the random seed manually for reproducibility.\nnp.random.seed(args.seed)\ntorch.manual_seed(args.seed)\nif torch.cuda.is_available():\n    if not args.cuda:\n        print(""WARNING: You have a CUDA device, so you should probably run with --cuda"")\n    else:\n        torch.cuda.set_device(args.gpu)\n        cudnn.benchmark = True\n        cudnn.enabled=True\n        torch.cuda.manual_seed_all(args.seed)\n\ncorpus = data.Corpus(args.data)\n\neval_batch_size = 10\ntest_batch_size = 1\n\ntrain_data = batchify(corpus.train, args.batch_size, args)\nsearch_data = batchify(corpus.valid, args.batch_size, args)\nval_data = batchify(corpus.valid, eval_batch_size, args)\ntest_data = batchify(corpus.test, test_batch_size, args)\n\n\nntokens = len(corpus.dictionary)\nif args.continue_train:\n    model = torch.load(os.path.join(args.save, \'model.pt\'))\nelse:\n    model = model.RNNModelSearch(ntokens, args.emsize, args.nhid, args.nhidlast, \n                       args.dropout, args.dropouth, args.dropoutx, args.dropouti, args.dropoute)\n\nsize = 0\nfor p in model.parameters():\n    size += p.nelement()\nlogging.info(\'param size: {}\'.format(size))\nlogging.info(\'initial genotype:\')\nlogging.info(model.genotype())\n\nif args.cuda:\n    if args.single_gpu:\n        parallel_model = model.cuda()\n    else:\n        parallel_model = nn.DataParallel(model, dim=1).cuda()\nelse:\n    parallel_model = model\narchitect = Architect(parallel_model, args)\n\ntotal_params = sum(x.data.nelement() for x in model.parameters())\nlogging.info(\'Args: {}\'.format(args))\nlogging.info(\'Model total parameters: {}\'.format(total_params))\n\n\ndef evaluate(data_source, batch_size=10):\n    # Turn on evaluation mode which disables dropout.\n    model.eval()\n    total_loss = 0\n    ntokens = len(corpus.dictionary)\n    hidden = model.init_hidden(batch_size)\n    for i in range(0, data_source.size(0) - 1, args.bptt):\n        data, targets = get_batch(data_source, i, args, evaluation=True)\n        targets = targets.view(-1)\n\n        log_prob, hidden = parallel_model(data, hidden)\n        loss = nn.functional.nll_loss(log_prob.view(-1, log_prob.size(2)), targets).data\n\n        total_loss += loss * len(data)\n\n        hidden = repackage_hidden(hidden)\n    return total_loss[0] / len(data_source)\n\n\ndef train():\n    assert args.batch_size % args.small_batch_size == 0, \'batch_size must be divisible by small_batch_size\'\n\n    # Turn on training mode which enables dropout.\n    total_loss = 0\n    start_time = time.time()\n    ntokens = len(corpus.dictionary)\n    hidden = [model.init_hidden(args.small_batch_size) for _ in range(args.batch_size // args.small_batch_size)]\n    hidden_valid = [model.init_hidden(args.small_batch_size) for _ in range(args.batch_size // args.small_batch_size)]\n    batch, i = 0, 0\n    while i < train_data.size(0) - 1 - 1:\n        bptt = args.bptt if np.random.random() < 0.95 else args.bptt / 2.\n        # Prevent excessively small or negative sequence lengths\n        # seq_len = max(5, int(np.random.normal(bptt, 5)))\n        # # There\'s a very small chance that it could select a very long sequence length resulting in OOM\n        # seq_len = min(seq_len, args.bptt + args.max_seq_len_delta)\n        seq_len = int(bptt)\n\n        lr2 = optimizer.param_groups[0][\'lr\']\n        optimizer.param_groups[0][\'lr\'] = lr2 * seq_len / args.bptt\n        model.train()\n\n        data_valid, targets_valid = get_batch(search_data, i % (search_data.size(0) - 1), args)\n        data, targets = get_batch(train_data, i, args, seq_len=seq_len)\n\n        optimizer.zero_grad()\n\n        start, end, s_id = 0, args.small_batch_size, 0\n        while start < args.batch_size:\n            cur_data, cur_targets = data[:, start: end], targets[:, start: end].contiguous().view(-1)\n            cur_data_valid, cur_targets_valid = data_valid[:, start: end], targets_valid[:, start: end].contiguous().view(-1)\n\n            # Starting each batch, we detach the hidden state from how it was previously produced.\n            # If we didn\'t, the model would try backpropagating all the way to start of the dataset.\n            hidden[s_id] = repackage_hidden(hidden[s_id])\n            hidden_valid[s_id] = repackage_hidden(hidden_valid[s_id])\n\n            hidden_valid[s_id], grad_norm = architect.step(\n                    hidden[s_id], cur_data, cur_targets,\n                    hidden_valid[s_id], cur_data_valid, cur_targets_valid,\n                    optimizer,\n                    args.unrolled)\n\n            # assuming small_batch_size = batch_size so we don\'t accumulate gradients\n            optimizer.zero_grad()\n            hidden[s_id] = repackage_hidden(hidden[s_id])\n\n            log_prob, hidden[s_id], rnn_hs, dropped_rnn_hs = parallel_model(cur_data, hidden[s_id], return_h=True)\n            raw_loss = nn.functional.nll_loss(log_prob.view(-1, log_prob.size(2)), cur_targets)\n\n            loss = raw_loss\n            # Activiation Regularization\n            if args.alpha > 0:\n              loss = loss + sum(args.alpha * dropped_rnn_h.pow(2).mean() for dropped_rnn_h in dropped_rnn_hs[-1:])\n            # Temporal Activation Regularization (slowness)\n            loss = loss + sum(args.beta * (rnn_h[1:] - rnn_h[:-1]).pow(2).mean() for rnn_h in rnn_hs[-1:])\n            loss *= args.small_batch_size / args.batch_size\n            total_loss += raw_loss.data * args.small_batch_size / args.batch_size\n            loss.backward()\n\n            s_id += 1\n            start = end\n            end = start + args.small_batch_size\n\n            gc.collect()\n\n        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs.\n        torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n        optimizer.step()\n\n        # total_loss += raw_loss.data\n        optimizer.param_groups[0][\'lr\'] = lr2\n        if batch % args.log_interval == 0 and batch > 0:\n            logging.info(parallel_model.genotype())\n            print(F.softmax(parallel_model.weights, dim=-1))\n            cur_loss = total_loss[0] / args.log_interval\n            elapsed = time.time() - start_time\n            logging.info(\'| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | \'\n                    \'loss {:5.2f} | ppl {:8.2f}\'.format(\n                epoch, batch, len(train_data) // args.bptt, optimizer.param_groups[0][\'lr\'],\n                elapsed * 1000 / args.log_interval, cur_loss, math.exp(cur_loss)))\n            total_loss = 0\n            start_time = time.time()\n        batch += 1\n        i += seq_len\n\n# Loop over epochs.\nlr = args.lr\nbest_val_loss = []\nstored_loss = 100000000\n\nif args.continue_train:\n    optimizer_state = torch.load(os.path.join(args.save, \'optimizer.pt\'))\n    if \'t0\' in optimizer_state[\'param_groups\'][0]:\n        optimizer = torch.optim.ASGD(model.parameters(), lr=args.lr, t0=0, lambd=0., weight_decay=args.wdecay)\n    else:\n        optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n    optimizer.load_state_dict(optimizer_state)\nelse:\n    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.wdecay)\n\nfor epoch in range(1, args.epochs+1):\n    epoch_start_time = time.time()\n    train()\n\n    val_loss = evaluate(val_data, eval_batch_size)\n    logging.info(\'-\' * 89)\n    logging.info(\'| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | \'\n            \'valid ppl {:8.2f}\'.format(epoch, (time.time() - epoch_start_time),\n                                       val_loss, math.exp(val_loss)))\n    logging.info(\'-\' * 89)\n\n    if val_loss < stored_loss:\n        save_checkpoint(model, optimizer, epoch, args.save)\n        logging.info(\'Saving Normal!\')\n        stored_loss = val_loss\n\n    best_val_loss.append(val_loss)\n'"
rnn/utils.py,8,"b""import torch\nimport torch.nn as nn\nimport os, shutil\nimport numpy as np\nfrom torch.autograd import Variable\n\n\ndef repackage_hidden(h):\n    if type(h) == Variable:\n        return Variable(h.data)\n    else:\n        return tuple(repackage_hidden(v) for v in h)\n\n\ndef batchify(data, bsz, args):\n    nbatch = data.size(0) // bsz\n    data = data.narrow(0, 0, nbatch * bsz)\n    data = data.view(bsz, -1).t().contiguous()\n    print(data.size())\n    if args.cuda:\n        data = data.cuda()\n    return data\n\n\ndef get_batch(source, i, args, seq_len=None, evaluation=False):\n    seq_len = min(seq_len if seq_len else args.bptt, len(source) - 1 - i)\n    data = Variable(source[i:i+seq_len], volatile=evaluation)\n    target = Variable(source[i+1:i+1+seq_len])\n    return data, target\n\n\ndef create_exp_dir(path, scripts_to_save=None):\n    if not os.path.exists(path):\n        os.mkdir(path)\n\n    print('Experiment dir : {}'.format(path))\n    if scripts_to_save is not None:\n        os.mkdir(os.path.join(path, 'scripts'))\n        for script in scripts_to_save:\n            dst_file = os.path.join(path, 'scripts', os.path.basename(script))\n            shutil.copyfile(script, dst_file)\n\n\ndef save_checkpoint(model, optimizer, epoch, path, finetune=False):\n    if finetune:\n        torch.save(model, os.path.join(path, 'finetune_model.pt'))\n        torch.save(optimizer.state_dict(), os.path.join(path, 'finetune_optimizer.pt'))\n    else:\n        torch.save(model, os.path.join(path, 'model.pt'))\n        torch.save(optimizer.state_dict(), os.path.join(path, 'optimizer.pt'))\n    torch.save({'epoch': epoch+1}, os.path.join(path, 'misc.pt'))\n\n\ndef embedded_dropout(embed, words, dropout=0.1, scale=None):\n    if dropout:\n        mask = embed.weight.data.new().resize_((embed.weight.size(0), 1)).bernoulli_(1 - dropout).expand_as(embed.weight) / (1 - dropout)\n        mask = Variable(mask)\n        masked_embed_weight = mask * embed.weight\n    else:\n        masked_embed_weight = embed.weight\n    if scale:\n        masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n\n    padding_idx = embed.padding_idx\n    if padding_idx is None:\n        padding_idx = -1\n    X = embed._backend.Embedding.apply(words, masked_embed_weight,\n        padding_idx, embed.max_norm, embed.norm_type,\n        embed.scale_grad_by_freq, embed.sparse\n    )\n    return X\n\n\nclass LockedDropout(nn.Module):\n    def __init__(self):\n        super(LockedDropout, self).__init__()\n\n    def forward(self, x, dropout=0.5):\n        if not self.training or not dropout:\n            return x\n        m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - dropout)\n        mask = Variable(m.div_(1 - dropout), requires_grad=False)\n        mask = mask.expand_as(x)\n        return mask * x\n\n\ndef mask2d(B, D, keep_prob, cuda=True):\n    m = torch.floor(torch.rand(B, D) + keep_prob) / keep_prob\n    m = Variable(m, requires_grad=False)\n    if cuda:\n        m = m.cuda()\n    return m\n\n"""
rnn/visualize.py,0,"b'import sys\nimport genotypes\nfrom graphviz import Digraph\n\n\ndef plot(genotype, filename):\n  g = Digraph(\n      format=\'pdf\',\n      edge_attr=dict(fontsize=\'20\', fontname=""times""),\n      node_attr=dict(style=\'filled\', shape=\'rect\', align=\'center\', fontsize=\'20\', height=\'0.5\', width=\'0.5\', penwidth=\'2\', fontname=""times""),\n      engine=\'dot\')\n  g.body.extend([\'rankdir=LR\'])\n\n  g.node(""x_{t}"", fillcolor=\'darkseagreen2\')\n  g.node(""h_{t-1}"", fillcolor=\'darkseagreen2\')\n  g.node(""0"", fillcolor=\'lightblue\')\n  g.edge(""x_{t}"", ""0"", fillcolor=""gray"")\n  g.edge(""h_{t-1}"", ""0"", fillcolor=""gray"")\n  steps = len(genotype)\n\n  for i in range(1, steps + 1):\n    g.node(str(i), fillcolor=\'lightblue\')\n\n  for i, (op, j) in enumerate(genotype):\n    g.edge(str(j), str(i + 1), label=op, fillcolor=""gray"")\n\n  g.node(""h_{t}"", fillcolor=\'palegoldenrod\')\n  for i in range(1, steps + 1):\n    g.edge(str(i), ""h_{t}"", fillcolor=""gray"")\n\n  g.render(filename, view=True)\n\n\nif __name__ == \'__main__\':\n  if len(sys.argv) != 2:\n    print(""usage:\\n python {} ARCH_NAME"".format(sys.argv[0]))\n    sys.exit(1)\n\n  genotype_name = sys.argv[1]\n  try:\n    genotype = eval(\'genotypes.{}\'.format(genotype_name))\n  except AttributeError:\n    print(""{} is not specified in genotypes.py"".format(genotype_name)) \n    sys.exit(1)\n\n  plot(genotype.recurrent, ""recurrent"")\n\n'"
