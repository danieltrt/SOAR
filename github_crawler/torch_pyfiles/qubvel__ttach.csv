file_path,api_count,code
__init__.py,0,b'from .ttach import *\n'
setup.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n# Note: To use the \'upload\' functionality of this file, you must:\n#   $ pip install twine\n\nimport io\nimport os\nimport sys\nfrom shutil import rmtree\n\nfrom setuptools import find_packages, setup, Command\n\n# Package meta-data.\nNAME = \'ttach\'\nDESCRIPTION = \'Images test time augmentation with PyTorch.\'\nURL = \'https://github.com/qubvel/ttach\'\nEMAIL = \'qubvel@gmail.com\'\nAUTHOR = \'Pavel Yakubovskiy\'\nREQUIRES_PYTHON = \'>=3.0.0\'\nVERSION = None\n\n# The rest you shouldn\'t have to touch too much :)\n# ------------------------------------------------\n# Except, perhaps the License and Trove Classifiers!\n# If you do change the License, remember to change the Trove Classifier for that!\n\nhere = os.path.abspath(os.path.dirname(__file__))\n\n# What packages are required for this module to be executed?\ntry:\n    with open(os.path.join(here, \'requirements.txt\'), encoding=\'utf-8\') as f:\n        REQUIRED = f.read().split(\'\\n\')\nexcept:\n    REQUIRED = []\n\n# What packages are optional?\nEXTRAS = {\n    \'test\': [\'pytest\']\n}\n\n# Import the README and use it as the long-description.\n# Note: this will only work if \'README.md\' is present in your MANIFEST.in file!\ntry:\n    with io.open(os.path.join(here, \'README.md\'), encoding=\'utf-8\') as f:\n        long_description = \'\\n\' + f.read()\nexcept FileNotFoundError:\n    long_description = DESCRIPTION\n\n# Load the package\'s __version__.py module as a dictionary.\nabout = {}\nif not VERSION:\n    with open(os.path.join(here, NAME, \'__version__.py\')) as f:\n        exec(f.read(), about)\nelse:\n    about[\'__version__\'] = VERSION\n\n\nclass UploadCommand(Command):\n    """"""Support setup.py upload.""""""\n\n    description = \'Build and publish the package.\'\n    user_options = []\n\n    @staticmethod\n    def status(s):\n        """"""Prints things in bold.""""""\n        print(s)\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        pass\n\n    def run(self):\n        try:\n            self.status(\'Removing previous builds...\')\n            rmtree(os.path.join(here, \'dist\'))\n        except OSError:\n            pass\n\n        self.status(\'Building Source and Wheel (universal) distribution...\')\n        os.system(\'{0} setup.py sdist bdist_wheel --universal\'.format(sys.executable))\n\n        self.status(\'Uploading the package to PyPI via Twine...\')\n        os.system(\'twine upload dist/*\')\n\n        self.status(\'Pushing git tags...\')\n        os.system(\'git tag v{0}\'.format(about[\'__version__\']))\n        os.system(\'git push --tags\')\n\n        sys.exit()\n\n\n# Where the magic happens:\nsetup(\n    name=NAME,\n    version=about[\'__version__\'],\n    description=DESCRIPTION,\n    long_description=long_description,\n    long_description_content_type=\'text/markdown\',\n    author=AUTHOR,\n    author_email=EMAIL,\n    python_requires=REQUIRES_PYTHON,\n    url=URL,\n    packages=find_packages(exclude=(\'tests\', \'docs\', \'images\')),\n    # If your package is a single module, use this instead of \'packages\':\n    # py_modules=[\'mypackage\'],\n\n    # entry_points={\n    #     \'console_scripts\': [\'mycli=mymodule:cli\'],\n    # },\n    install_requires=REQUIRED,\n    extras_require=EXTRAS,\n    include_package_data=True,\n    license=\'MIT\',\n    classifiers=[\n        # Trove classifiers\n        # Full list: https://pypi.python.org/pypi?%3Aaction=list_classifiers\n        \'License :: OSI Approved :: MIT License\',\n        \'Programming Language :: Python\',\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: Implementation :: CPython\',\n        \'Programming Language :: Python :: Implementation :: PyPy\'\n    ],\n    # $ setup.py publish support.\n    cmdclass={\n        \'upload\': UploadCommand,\n    },\n)\n'"
tests/test_base.py,6,"b'import pytest\nimport torch\nimport ttach as tta\n\n\ndef test_compose_1():\n    transform = tta.Compose(\n        [\n            tta.HorizontalFlip(),\n            tta.VerticalFlip(),\n            tta.Rotate90(angles=[0, 90, 180, 270]),\n            tta.Scale(scales=[1, 2, 4], interpolation=""nearest""),\n        ]\n    )\n\n    assert len(transform) == 2 * 2 * 4 * 3  # all combinations for aug parameters\n\n    dummy_label = torch.ones(2).reshape(2, 1).float()\n    dummy_image = torch.arange(2 * 3 * 4 * 5).reshape(2, 3, 4, 5).float()\n    dummy_model = lambda x: {""label"": dummy_label, ""mask"": x}\n\n    for augmenter in transform:\n        augmented_image = augmenter.augment_image(dummy_image)\n        model_output = dummy_model(augmented_image)\n        deaugmented_mask = augmenter.deaugment_mask(model_output[""mask""])\n        deaugmented_label = augmenter.deaugment_label(model_output[""label""])\n        assert torch.allclose(deaugmented_mask, dummy_image)\n        assert torch.allclose(deaugmented_label, dummy_label)\n\n\n@pytest.mark.parametrize(\n    ""case"",\n    [\n        (""mean"", 0.5),\n        (""gmean"", 0.0),\n        (""max"", 1.0),\n        (""min"", 0.0),\n        (""sum"", 1.5),\n        (""tsharpen"", 0.56903558),\n    ],\n)\ndef test_merger(case):\n    merge_type, output = case\n    input = [1.0, 0.0, 0.5]\n    merger = tta.base.Merger(type=merge_type, n=len(input))\n    for i in input:\n        merger.append(torch.tensor(i))\n    assert torch.allclose(merger.result, torch.tensor(output))\n'"
tests/test_transforms.py,10,"b'import pytest\nimport torch\nimport ttach as tta\n\n\n@pytest.mark.parametrize(\n    ""transform"",\n    [\n        tta.HorizontalFlip(),\n        tta.VerticalFlip(),\n        tta.Rotate90(angles=[0, 90, 180, 270]),\n        tta.Scale(scales=[1, 2, 4], interpolation=""nearest""),\n        tta.Resize(sizes=[(4, 5), (8, 10)], original_size=(4, 5), interpolation=""nearest"")\n    ],\n)\ndef test_aug_deaug_mask(transform):\n    a = torch.arange(20).reshape(1, 1, 4, 5).float()\n    for p in transform.params:\n        aug = transform.apply_aug_image(a, **{transform.pname: p})\n        deaug = transform.apply_deaug_mask(aug, **{transform.pname: p})\n        assert torch.allclose(a, deaug)\n\n\n@pytest.mark.parametrize(\n    ""transform"",\n    [\n        tta.HorizontalFlip(),\n        tta.VerticalFlip(),\n        tta.Rotate90(angles=[0, 90, 180, 270]),\n        tta.Scale(scales=[1, 2, 4], interpolation=""nearest""),\n        tta.Add(values=[-1, 0, 1, 2]),\n        tta.Multiply(factors=[-1, 0, 1, 2]),\n        tta.FiveCrops(crop_height=3, crop_width=5),\n        tta.Resize(sizes=[(4, 5), (8, 10), (2, 2)], interpolation=""nearest"")\n    ],\n)\ndef test_label_is_same(transform):\n    a = torch.arange(20).reshape(1, 1, 4, 5).float()\n    for p in transform.params:\n        aug = transform.apply_aug_image(a, **{transform.pname: p})\n        deaug = transform.apply_deaug_label(aug, **{transform.pname: p})\n        assert torch.allclose(aug, deaug)\n\n\ndef test_add_transform():\n    transform = tta.Add(values=[-1, 0, 1])\n    a = torch.arange(20).reshape(1, 1, 4, 5).float()\n    for p in transform.params:\n        aug = transform.apply_aug_image(a, **{transform.pname: p})\n        assert torch.allclose(aug, a + p)\n\n\ndef test_multiply_transform():\n    transform = tta.Multiply(factors=[-1, 0, 1])\n    a = torch.arange(20).reshape(1, 1, 4, 5).float()\n    for p in transform.params:\n        aug = transform.apply_aug_image(a, **{transform.pname: p})\n        assert torch.allclose(aug, a * p)\n\n\ndef test_fivecrop_transform():\n    transform = tta.FiveCrops(crop_height=1, crop_width=1)\n    a = torch.arange(25).reshape(1, 1, 5, 5).float()\n    output = [0, 20, 24, 4, 12]\n    for i, p in enumerate(transform.params):\n        aug = transform.apply_aug_image(a, **{transform.pname: p})\n        assert aug.item() == output[i]\n\n#\n# def test_resize_transform():\n#     transform = tta.Resize(sizes=[(10, 10), (5, 5)], original_size=(5, 5))\n#     a = torch.arange(25).reshape(1, 1, 5, 5).float()\n#     for i, p in enumerate(transform.params):\n#         aug = transform.apply_aug_image(a, **{transform.pname: p})\n#         assert aug.item() == output[i]'"
ttach/__init__.py,0,"b'from .wrappers import (\n    SegmentationTTAWrapper,\n    ClassificationTTAWrapper,\n)\nfrom .base import Compose\n\nfrom .transforms import (\n    HorizontalFlip, VerticalFlip, Rotate90, Scale, Add, Multiply, FiveCrops, Resize\n)\n\nfrom . import aliases\n'"
ttach/__version__.py,0,"b""VERSION = (0, 0, 2)\n\n__version__ = '.'.join(map(str, VERSION))\n"""
ttach/aliases.py,0,"b'from .base import Compose\nfrom . import transforms as tta\n\n\ndef flip_transform():\n    return Compose([tta.HorizontalFlip(), tta.VerticalFlip()])\n\n\ndef hflip_transform():\n    return Compose([tta.HorizontalFlip()])\n\n\ndef vlip_transform():\n    return Compose([tta.VerticalFlip()])\n\n\ndef d4_transform():\n    return Compose(\n        [\n            tta.HorizontalFlip(),\n            tta.Rotate90(angles=[0, 90, 180, 270]),\n        ]\n    )\n\ndef multiscale_transform(scales, interpolation=""nearest""):\n    return Compose([tta.Scale(scales, interpolation=interpolation)])\n\n\ndef five_crop_transform(crop_height, crop_width):\n    return Compose([tta.FiveCrops(crop_height, crop_width)])\n\n\ndef ten_crop_transform(crop_height, crop_width):\n    return Compose([tta.HorizontalFlip(), tta.FiveCrops(crop_height, crop_width)])\n'"
ttach/base.py,0,"b""import itertools\nfrom functools import partial\nfrom typing import List, Optional, Union\n\nfrom . import functional as F\n\n\nclass BaseTransform:\n    identity_param = None\n\n    def __init__(\n            self,\n            name: str,\n            params: Union[list, tuple],\n    ):\n        self.params = params\n        self.pname = name\n\n    def apply_aug_image(self, image, *args, **params):\n        raise NotImplementedError\n\n    def apply_deaug_mask(self, mask, *args, **params):\n        raise NotImplementedError\n\n    def apply_deaug_label(self, label, *args, **params):\n        raise NotImplementedError\n\n\nclass ImageOnlyTransform(BaseTransform):\n\n    def apply_deaug_mask(self, mask, *args, **params):\n        return mask\n\n    def apply_deaug_label(self, label, *args, **params):\n        return label\n\n\nclass DualTransform(BaseTransform):\n    pass\n\n\nclass Chain:\n\n    def __init__(\n            self,\n            functions: List[callable]\n    ):\n        self.functions = functions or []\n\n    def __call__(self, x):\n        for f in self.functions:\n            x = f(x)\n        return x\n\n\nclass Transformer:\n    def __init__(\n            self,\n            image_pipeline: Chain,\n            mask_pipeline: Chain,\n            label_pipeline: Chain,\n    ):\n        self.image_pipeline = image_pipeline\n        self.mask_pipeline = mask_pipeline\n        self.label_pipeline = label_pipeline\n\n    def augment_image(self, image):\n        return self.image_pipeline(image)\n\n    def deaugment_mask(self, mask):\n        return self.mask_pipeline(mask)\n\n    def deaugment_label(self, label):\n        return self.label_pipeline(label)\n\n\nclass Compose:\n\n    def __init__(\n            self,\n            transforms: List[BaseTransform],\n    ):\n        self.aug_transforms = transforms\n        self.aug_transform_parameters = list(itertools.product(*[t.params for t in self.aug_transforms]))\n        self.deaug_transforms = transforms[::-1]\n        self.deaug_transform_parameters = [p[::-1] for p in self.aug_transform_parameters]\n\n    def __iter__(self) -> Transformer:\n        for aug_params, deaug_params in zip(self.aug_transform_parameters, self.deaug_transform_parameters):\n            image_aug_chain = Chain([partial(t.apply_aug_image, **{t.pname: p})\n                                     for t, p in zip(self.aug_transforms, aug_params)])\n            mask_deaug_chain = Chain([partial(t.apply_deaug_mask, **{t.pname: p})\n                                      for t, p in zip(self.deaug_transforms, deaug_params)])\n            label_deaug_chain = Chain([partial(t.apply_deaug_label, **{t.pname: p})\n                                       for t, p in zip(self.deaug_transforms, deaug_params)])\n            yield Transformer(\n                image_pipeline=image_aug_chain,\n                mask_pipeline=mask_deaug_chain,\n                label_pipeline=label_deaug_chain,\n            )\n\n    def __len__(self) -> int:\n        return len(self.aug_transform_parameters)\n\n\nclass Merger:\n\n    def __init__(\n            self,\n            type: str = 'mean',\n            n: int = 1,\n    ):\n\n        if type not in ['mean', 'gmean', 'sum', 'max', 'min', 'tsharpen']:\n            raise ValueError('Not correct merge type `{}`.'.format(type))\n\n        self.output = None\n        self.type = type\n        self.n = n\n\n    def append(self, x):\n\n        if self.type == 'tsharpen':\n            x = x ** 0.5\n\n        if self.output is None:\n            self.output = x\n        elif self.type in ['mean', 'sum', 'tsharpen']:\n            self.output = self.output + x\n        elif self.type == 'gmean':\n            self.output = self.output * x\n        elif self.type == 'max':\n            self.output = F.max(self.output, x)\n        elif self.type == 'min':\n            self.output = F.min(self.output, x)\n\n    @property\n    def result(self):\n        if self.type in ['sum', 'max', 'min']:\n            result = self.output\n        elif self.type in ['mean', 'tsharpen']:\n            result = self.output / self.n\n        elif self.type in ['gmean']:\n            result = self.output ** (1 / self.n)\n        else:\n            raise ValueError('Not correct merge type `{}`.'.format(self.type))\n        return result\n"""
ttach/functional.py,4,"b'import torch\nimport torch.nn.functional as F\n\n\ndef rot90(x, k=1):\n    """"""rotate batch of images by 90 degrees k times""""""\n    return torch.rot90(x, k, (2, 3))\n\n\ndef hflip(x):\n    """"""flip batch of images horizontally""""""\n    return x.flip(3)\n\n\ndef vflip(x):\n    """"""flip batch of images vertically""""""\n    return x.flip(2)\n\n\ndef sum(x1, x2):\n    """"""sum of two tensors""""""\n    return x1 + x2\n\n\ndef add(x, value):\n    """"""add value to tensor""""""\n    return x + value\n\n\ndef max(x1, x2):\n    """"""compare 2 tensors and take max values""""""\n    return torch.max(x1, x2)\n\n\ndef min(x1, x2):\n    """"""compare 2 tensors and take min values""""""\n    return torch.min(x1, x2)\n\n\ndef multiply(x, factor):\n    """"""multiply tensor by factor""""""\n    return x * factor\n\n\ndef scale(x, scale_factor, interpolation=""nearest"", align_corners=None):\n    """"""scale batch of images by `scale_factor` with given interpolation mode""""""\n    h, w = x.shape[2:]\n    new_h = int(h * scale_factor)\n    new_w = int(w * scale_factor)\n    return F.interpolate(\n        x, size=(new_h, new_w), mode=interpolation, align_corners=align_corners\n    )\n\n\ndef resize(x, size, interpolation=""nearest"", align_corners=None):\n    """"""resize batch of images to given spatial size with given interpolation mode""""""\n    return F.interpolate(x, size=size, mode=interpolation, align_corners=align_corners)\n\n\ndef crop(x, x_min=None, x_max=None, y_min=None, y_max=None):\n    """"""perform crop on batch of images""""""\n    return x[:, :, y_min:y_max, x_min:x_max]\n\n\ndef crop_lt(x, crop_h, crop_w):\n    """"""crop left top corner""""""\n    return x[:, :, 0:crop_h, 0:crop_w]\n\n\ndef crop_lb(x, crop_h, crop_w):\n    """"""crop left bottom corner""""""\n    return x[:, :, -crop_h:, 0:crop_w]\n\n\ndef crop_rt(x, crop_h, crop_w):\n    """"""crop right top corner""""""\n    return x[:, :, 0:crop_h, -crop_w:]\n\n\ndef crop_rb(x, crop_h, crop_w):\n    """"""crop right bottom corner""""""\n    return x[:, :, -crop_h:, -crop_w:]\n\n\ndef center_crop(x, crop_h, crop_w):\n    """"""make center crop""""""\n\n    center_h = x.shape[2] // 2\n    center_w = x.shape[3] // 2\n    half_crop_h = crop_h // 2\n    half_crop_w = crop_w // 2\n\n    y_min = center_h - half_crop_h\n    y_max = center_h + half_crop_h + crop_h % 2\n    x_min = center_w - half_crop_w\n    x_max = center_w + half_crop_w + crop_w % 2\n\n    return x[:, :, y_min:y_max, x_min:x_max]\n'"
ttach/transforms.py,4,"b'from functools import partial\nfrom typing import Optional, List, Union, Tuple\nfrom . import functional as F\nfrom .base import DualTransform, ImageOnlyTransform\n\n\nclass HorizontalFlip(DualTransform):\n    """"""Flip images horizontally (left->right)""""""\n\n    identity_param = False\n\n    def __init__(self):\n        super().__init__(""apply"", [False, True])\n\n    def apply_aug_image(self, image, apply=False, **kwargs):\n        if apply:\n            image = F.hflip(image)\n        return image\n\n    def apply_deaug_mask(self, mask, apply=False, **kwargs):\n        if apply:\n            mask = F.hflip(mask)\n        return mask\n\n    def apply_deaug_label(self, label, apply=False, **kwargs):\n        return label\n\n\nclass VerticalFlip(DualTransform):\n    """"""Flip images vertically (up->down)""""""\n\n    identity_param = False\n\n    def __init__(self):\n        super().__init__(""apply"", [False, True])\n\n    def apply_aug_image(self, image, apply=False, **kwargs):\n        if apply:\n            image = F.vflip(image)\n        return image\n\n    def apply_deaug_mask(self, mask, apply=False, **kwargs):\n        if apply:\n            mask = F.vflip(mask)\n        return mask\n\n    def apply_deaug_label(self, label, apply=False, **kwargs):\n        return label\n\n\nclass Rotate90(DualTransform):\n    """"""Rotate images 0/90/180/270 degrees\n\n    Args:\n        angles (list): angles to rotate images\n    """"""\n\n    identity_param = 0\n\n    def __init__(self, angles: List[int]):\n        if self.identity_param not in angles:\n            angles = [self.identity_param] + list(angles)\n\n        super().__init__(""angle"", angles)\n\n    def apply_aug_image(self, image, angle=0, **kwargs):\n        k = angle // 90 if angle >= 0 else (angle + 360) // 90\n        return F.rot90(image, k)\n\n    def apply_deaug_mask(self, mask, angle=0, **kwargs):\n        return self.apply_aug_image(mask, -angle)\n\n    def apply_deaug_label(self, label, angle=0, **kwargs):\n        return label\n\n\nclass Scale(DualTransform):\n    """"""Scale images\n\n    Args:\n        scales (List[Union[int, float]]): scale factors for spatial image dimensions\n        interpolation (str): one of ""nearest""/""lenear"" (see more in torch.nn.interpolate)\n        align_corners (bool): see more in torch.nn.interpolate\n    """"""\n\n    identity_param = 1\n\n    def __init__(\n        self,\n        scales: List[Union[int, float]],\n        interpolation: str = ""nearest"",\n        align_corners: Optional[bool] = None,\n    ):\n        if self.identity_param not in scales:\n            scales = [self.identity_param] + list(scales)\n        self.interpolation = interpolation\n        self.align_corners = align_corners\n\n        super().__init__(""scale"", scales)\n\n    def apply_aug_image(self, image, scale=1, **kwargs):\n        if scale != self.identity_param:\n            image = F.scale(\n                image,\n                scale,\n                interpolation=self.interpolation,\n                align_corners=self.align_corners,\n            )\n        return image\n\n    def apply_deaug_mask(self, mask, scale=1, **kwargs):\n        if scale != self.identity_param:\n            mask = F.scale(\n                mask,\n                1 / scale,\n                interpolation=self.interpolation,\n                align_corners=self.align_corners,\n            )\n        return mask\n\n    def apply_deaug_label(self, label, scale=1, **kwargs):\n        return label\n\n\nclass Resize(DualTransform):\n    """"""Resize images\n\n    Args:\n        sizes (List[Tuple[int, int]): scale factors for spatial image dimensions\n        original_size Tuple(int, int): optional, image original size for deaugmenting mask\n        interpolation (str): one of ""nearest""/""lenear"" (see more in torch.nn.interpolate)\n        align_corners (bool): see more in torch.nn.interpolate\n    """"""\n\n    def __init__(\n        self,\n        sizes: List[Tuple[int, int]],\n        original_size: Tuple[int, int] = None,\n        interpolation: str = ""nearest"",\n        align_corners: Optional[bool] = None,\n    ):\n        if original_size is not None and original_size not in sizes:\n            sizes = [original_size] + list(sizes)\n        self.interpolation = interpolation\n        self.align_corners = align_corners\n        self.original_size = original_size\n\n        super().__init__(""size"", sizes)\n\n    def apply_aug_image(self, image, size, **kwargs):\n        if size != self.original_size:\n            image = F.resize(\n                image,\n                size,\n                interpolation=self.interpolation,\n                align_corners=self.align_corners,\n            )\n        return image\n\n    def apply_deaug_mask(self, mask, size, **kwargs):\n        if self.original_size is None:\n            raise ValueError(\n                ""Provide original image size to make mask backward transformation""\n            )\n        if size != self.original_size:\n            mask = F.resize(\n                mask,\n                self.original_size,\n                interpolation=self.interpolation,\n                align_corners=self.align_corners,\n            )\n        return mask\n\n    def apply_deaug_label(self, label, size=1, **kwargs):\n        return label\n\n\nclass Add(ImageOnlyTransform):\n    """"""Add value to images\n\n    Args:\n        values (List[float]): values to add to each pixel\n    """"""\n\n    identity_param = 0\n\n    def __init__(self, values: List[float]):\n\n        if self.identity_param not in values:\n            values = [self.identity_param] + list(values)\n        super().__init__(""value"", values)\n\n    def apply_aug_image(self, image, value=0, **kwargs):\n        if value != self.identity_param:\n            image = F.add(image, value)\n        return image\n\n\nclass Multiply(ImageOnlyTransform):\n    """"""Multiply images by factor\n\n    Args:\n        factors (List[float]): factor to multiply each pixel by\n    """"""\n\n    identity_param = 1\n\n    def __init__(self, factors: List[float]):\n        if self.identity_param not in factors:\n            factors = [self.identity_param] + list(factors)\n        super().__init__(""factor"", factors)\n\n    def apply_aug_image(self, image, factor=1, **kwargs):\n        if factor != self.identity_param:\n            image = F.multiply(image, factor)\n        return image\n\n\nclass FiveCrops(ImageOnlyTransform):\n    """"""Makes 4 crops for each corner + center crop\n\n    Args:\n        crop_height (int): crop height in pixels\n        crop_width (int): crop width in pixels \n    """"""\n\n    def __init__(self, crop_height, crop_width):\n        crop_functions = (\n            partial(F.crop_lt, crop_h=crop_height, crop_w=crop_width),\n            partial(F.crop_lb, crop_h=crop_height, crop_w=crop_width),\n            partial(F.crop_rb, crop_h=crop_height, crop_w=crop_width),\n            partial(F.crop_rt, crop_h=crop_height, crop_w=crop_width),\n            partial(F.center_crop, crop_h=crop_height, crop_w=crop_width),\n        )\n        super().__init__(""crop_fn"", crop_functions)\n\n    def apply_aug_image(self, image, crop_fn=None, **kwargs):\n        return crop_fn(image)\n\n    def apply_deaug_mask(self, mask, **kwargs):\n        raise ValueError(""`FiveCrop` augmentation is not suitable for mask!"")\n'"
ttach/wrappers.py,9,"b'import torch\nimport torch.nn as nn\nfrom typing import Optional, Mapping, Union\n\nfrom .base import Merger, Compose\n\n\nclass SegmentationTTAWrapper(nn.Module):\n    """"""Wrap PyTorch nn.Module (segmentation model) with test time augmentation transforms\n\n    Args:\n        model (torch.nn.Module): segmentation model with single input and single output\n            (.forward(x) should return either torch.Tensor or Mapping[str, torch.Tensor])\n        transforms (ttach.Compose): composition of test time transforms\n        merge_mode (str): method to merge augmented predictions mean/gmean/max/min/sum/tsharpen\n        output_mask_key (str): if model output is `dict`, specify which key belong to `mask`\n    """"""\n\n    def __init__(\n        self,\n        model: nn.Module,\n        transforms: Compose,\n        merge_mode: str = ""mean"",\n        output_mask_key: Optional[str] = None,\n    ):\n        super().__init__()\n        self.model = model\n        self.transforms = transforms\n        self.merge_mode = merge_mode\n        self.output_key = output_mask_key\n\n    def forward(\n        self, image: torch.Tensor, *args\n    ) -> Union[torch.Tensor, Mapping[str, torch.Tensor]]:\n        merger = Merger(type=self.merge_mode, n=len(self.transforms))\n\n        for transformer in self.transforms:\n            augmented_image = transformer.augment_image(image)\n            augmented_output = self.model(augmented_image, *args)\n            if self.output_key is not None:\n                augmented_output = augmented_output[self.output_key]\n            deaugmented_output = transformer.deaugment_mask(augmented_output)\n            merger.append(deaugmented_output)\n\n        result = merger.result\n        if self.output_key is not None:\n            result = {self.output_key: result}\n\n        return result\n\n\nclass ClassificationTTAWrapper(nn.Module):\n    """"""Wrap PyTorch nn.Module (classification model) with test time augmentation transforms\n\n    Args:\n        model (torch.nn.Module): classification model with single input and single output\n            (.forward(x) should return either torch.Tensor or Mapping[str, torch.Tensor])\n        transforms (ttach.Compose): composition of test time transforms\n        merge_mode (str): method to merge augmented predictions mean/gmean/max/min/sum/tsharpen\n        output_mask_key (str): if model output is `dict`, specify which key belong to `label`\n    """"""\n\n    def __init__(\n        self,\n        model: nn.Module,\n        transforms: Compose,\n        merge_mode: str = ""mean"",\n        output_label_key: Optional[str] = None,\n    ):\n        super().__init__()\n        self.model = model\n        self.transforms = transforms\n        self.merge_mode = merge_mode\n        self.output_key = output_label_key\n\n    def forward(\n        self, image: torch.Tensor, *args\n    ) -> Union[torch.Tensor, Mapping[str, torch.Tensor]]:\n        merger = Merger(type=self.merge_mode, n=len(self.transforms))\n\n        for transformer in self.transforms:\n            augmented_image = transformer.augment_image(image)\n            augmented_output = self.model(augmented_image, *args)\n            if self.output_key is not None:\n                augmented_output = augmented_output[self.output_key]\n            deaugmented_output = transformer.deaugment_label(augmented_output)\n            merger.append(deaugmented_output)\n\n        result = merger.result\n        if self.output_key is not None:\n            result = {self.output_key: result}\n\n        return result\n'"
