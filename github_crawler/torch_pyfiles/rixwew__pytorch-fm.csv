file_path,api_count,code
setup.py,0,"b'from pathlib import Path\n\nfrom setuptools import setup, find_packages\n\n\nif __name__ == \'__main__\':\n\n    with open(Path(__file__).parent / \'README.md\', encoding=\'utf-8\') as f:\n        long_description = f.read()\n\n    setup(\n        name=""torchfm"",\n        version=""0.7.0"",\n        description=""PyTorch implementation of Factorization Machine Models"",\n        long_description=long_description,\n        long_description_content_type=""text/markdown"",\n        url=""https://github.com/rixwew/torchfm"",\n        author=""rixwew"",\n        author_email=""rixwew@gmail.com"",\n        packages=find_packages(exclude=[""examples"", ""docs""]),\n    )\n'"
docs/conf.py,0,"b'# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# http://www.sphinx-doc.org/en/master/config\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath(\'..\'))\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \'pytorch-fm\'\ncopyright = \'2019, rixwew@gmail.com\'\nauthor = \'rixwew@gmail.com\'\n\n# The full version, including alpha/beta/rc tags\nrelease = \'0.1\'\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    \'sphinx.ext.todo\',\n    \'sphinx.ext.autosummary\',\n    \'sphinx.ext.viewcode\',\n    \'sphinx.ext.autodoc\'\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\'_templates\']\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\'_build\', \'Thumbs.db\', \'.DS_Store\']\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = \'sphinx_rtd_theme\'\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [\'_static\']\n'"
examples/main.py,7,"b'import torch\nimport tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom torch.utils.data import DataLoader\n\nfrom torchfm.dataset.avazu import AvazuDataset\nfrom torchfm.dataset.criteo import CriteoDataset\nfrom torchfm.dataset.movielens import MovieLens1MDataset, MovieLens20MDataset\nfrom torchfm.model.afi import AutomaticFeatureInteractionModel\nfrom torchfm.model.afm import AttentionalFactorizationMachineModel\nfrom torchfm.model.dcn import DeepCrossNetworkModel\nfrom torchfm.model.dfm import DeepFactorizationMachineModel\nfrom torchfm.model.ffm import FieldAwareFactorizationMachineModel\nfrom torchfm.model.fm import FactorizationMachineModel\nfrom torchfm.model.fnfm import FieldAwareNeuralFactorizationMachineModel\nfrom torchfm.model.fnn import FactorizationSupportedNeuralNetworkModel\nfrom torchfm.model.lr import LogisticRegressionModel\nfrom torchfm.model.ncf import NeuralCollaborativeFiltering\nfrom torchfm.model.nfm import NeuralFactorizationMachineModel\nfrom torchfm.model.pnn import ProductNeuralNetworkModel\nfrom torchfm.model.wd import WideAndDeepModel\nfrom torchfm.model.xdfm import ExtremeDeepFactorizationMachineModel\nfrom torchfm.model.afn import AdaptiveFactorizationNetwork\n\n\ndef get_dataset(name, path):\n    if name == \'movielens1M\':\n        return MovieLens1MDataset(path)\n    elif name == \'movielens20M\':\n        return MovieLens20MDataset(path)\n    elif name == \'criteo\':\n        return CriteoDataset(path)\n    elif name == \'avazu\':\n        return AvazuDataset(path)\n    else:\n        raise ValueError(\'unknown dataset name: \' + name)\n\n\ndef get_model(name, dataset):\n    """"""\n    Hyperparameters are empirically determined, not opitmized.\n    """"""\n    field_dims = dataset.field_dims\n    if name == \'lr\':\n        return LogisticRegressionModel(field_dims)\n    elif name == \'fm\':\n        return FactorizationMachineModel(field_dims, embed_dim=16)\n    elif name == \'ffm\':\n        return FieldAwareFactorizationMachineModel(field_dims, embed_dim=4)\n    elif name == \'fnn\':\n        return FactorizationSupportedNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n    elif name == \'wd\':\n        return WideAndDeepModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n    elif name == \'ipnn\':\n        return ProductNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16,), method=\'inner\', dropout=0.2)\n    elif name == \'opnn\':\n        return ProductNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16,), method=\'outer\', dropout=0.2)\n    elif name == \'dcn\':\n        return DeepCrossNetworkModel(field_dims, embed_dim=16, num_layers=3, mlp_dims=(16, 16), dropout=0.2)\n    elif name == \'nfm\':\n        return NeuralFactorizationMachineModel(field_dims, embed_dim=64, mlp_dims=(64,), dropouts=(0.2, 0.2))\n    elif name == \'ncf\':\n        # only supports MovieLens dataset because for other datasets user/item colums are indistinguishable\n        assert isinstance(dataset, MovieLens20MDataset) or isinstance(dataset, MovieLens1MDataset)\n        return NeuralCollaborativeFiltering(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2,\n                                            user_field_idx=dataset.user_field_idx,\n                                            item_field_idx=dataset.item_field_idx)\n    elif name == \'fnfm\':\n        return FieldAwareNeuralFactorizationMachineModel(field_dims, embed_dim=4, mlp_dims=(64,), dropouts=(0.2, 0.2))\n    elif name == \'dfm\':\n        return DeepFactorizationMachineModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n    elif name == \'xdfm\':\n        return ExtremeDeepFactorizationMachineModel(\n            field_dims, embed_dim=16, cross_layer_sizes=(16, 16), split_half=False, mlp_dims=(16, 16), dropout=0.2)\n    elif name == \'afm\':\n        return AttentionalFactorizationMachineModel(field_dims, embed_dim=16, attn_size=16, dropouts=(0.2, 0.2))\n    elif name == \'afi\':\n        return AutomaticFeatureInteractionModel(\n             field_dims, embed_dim=16, atten_embed_dim=64, num_heads=2, num_layers=3, mlp_dims=(400, 400), dropouts=(0, 0, 0))\n    elif name == \'afn\':\n        print(""Model:AFN"")\n        return AdaptiveFactorizationNetwork(\n            field_dims, embed_dim=16, LNN_dim=1500, mlp_dims=(400,400,400), dropouts=(0, 0, 0))\n    else:\n        raise ValueError(\'unknown model name: \' + name)\n\n\ndef train(model, optimizer, data_loader, criterion, device, log_interval=1000):\n    model.train()\n    total_loss = 0\n    for i, (fields, target) in enumerate(tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0)):\n        fields, target = fields.to(device), target.to(device)\n        y = model(fields)\n        loss = criterion(y, target.float())\n        model.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        if (i + 1) % log_interval == 0:\n            print(\'    - loss:\', total_loss / log_interval)\n            total_loss = 0\n\n\ndef test(model, data_loader, device):\n    model.eval()\n    targets, predicts = list(), list()\n    with torch.no_grad():\n        for fields, target in tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0):\n            fields, target = fields.to(device), target.to(device)\n            y = model(fields)\n            targets.extend(target.tolist())\n            predicts.extend(y.tolist())\n    return roc_auc_score(targets, predicts)\n\n\ndef main(dataset_name,\n         dataset_path,\n         model_name,\n         epoch,\n         learning_rate,\n         batch_size,\n         weight_decay,\n         device,\n         save_dir):\n    device = torch.device(device)\n    dataset = get_dataset(dataset_name, dataset_path)\n    train_length = int(len(dataset) * 0.8)\n    valid_length = int(len(dataset) * 0.1)\n    test_length = len(dataset) - train_length - valid_length\n    train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n        dataset, (train_length, valid_length, test_length))\n    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8)\n    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=8)\n    test_data_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8)\n    model = get_model(model_name, dataset).to(device)\n    criterion = torch.nn.BCELoss()\n    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    for epoch_i in range(epoch):\n        train(model, optimizer, train_data_loader, criterion, device)\n        auc = test(model, valid_data_loader, device)\n        print(\'epoch:\', epoch_i, \'validation: auc:\', auc)\n    auc = test(model, test_data_loader, device)\n    print(\'test auc:\', auc)\n    torch.save(model, f\'{save_dir}/{model_name}.pt\')\n\n\nif __name__ == \'__main__\':\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--dataset_name\', default=\'criteo\')\n    parser.add_argument(\'--dataset_path\', help=\'criteo/train.txt, avazu/train, or ml-1m/ratings.dat\')\n    parser.add_argument(\'--model_name\', default=\'afi\')\n    parser.add_argument(\'--epoch\', type=int, default=15)\n    parser.add_argument(\'--learning_rate\', type=float, default=0.001)\n    parser.add_argument(\'--batch_size\', type=int, default=2048)\n    parser.add_argument(\'--weight_decay\', type=float, default=1e-6)\n    parser.add_argument(\'--device\', default=\'cuda:0\')\n    parser.add_argument(\'--save_dir\', default=\'chkpt\')\n    args = parser.parse_args()\n    main(args.dataset_name,\n         args.dataset_path,\n         args.model_name,\n         args.epoch,\n         args.learning_rate,\n         args.batch_size,\n         args.weight_decay,\n         args.device,\n         args.save_dir)\n'"
torchfm/__init__.py,0,b''
torchfm/layer.py,48,"b'import numpy as np\nimport torch\nimport torch.nn.functional as F\n\n\nclass FeaturesLinear(torch.nn.Module):\n\n    def __init__(self, field_dims, output_dim=1):\n        super().__init__()\n        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n        return torch.sum(self.fc(x), dim=1) + self.bias\n\n\nclass FeaturesEmbedding(torch.nn.Module):\n\n    def __init__(self, field_dims, embed_dim):\n        super().__init__()\n        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n        return self.embedding(x)\n\n\nclass FieldAwareFactorizationMachine(torch.nn.Module):\n\n    def __init__(self, field_dims, embed_dim):\n        super().__init__()\n        self.num_fields = len(field_dims)\n        self.embeddings = torch.nn.ModuleList([\n            torch.nn.Embedding(sum(field_dims), embed_dim) for _ in range(self.num_fields)\n        ])\n        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n        for embedding in self.embeddings:\n            torch.nn.init.xavier_uniform_(embedding.weight.data)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n        xs = [self.embeddings[i](x) for i in range(self.num_fields)]\n        ix = list()\n        for i in range(self.num_fields - 1):\n            for j in range(i + 1, self.num_fields):\n                ix.append(xs[j][:, i] * xs[i][:, j])\n        ix = torch.stack(ix, dim=1)\n        return ix\n\n\nclass FactorizationMachine(torch.nn.Module):\n\n    def __init__(self, reduce_sum=True):\n        super().__init__()\n        self.reduce_sum = reduce_sum\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        square_of_sum = torch.sum(x, dim=1) ** 2\n        sum_of_square = torch.sum(x ** 2, dim=1)\n        ix = square_of_sum - sum_of_square\n        if self.reduce_sum:\n            ix = torch.sum(ix, dim=1, keepdim=True)\n        return 0.5 * ix\n\n\nclass MultiLayerPerceptron(torch.nn.Module):\n\n    def __init__(self, input_dim, embed_dims, dropout, output_layer=True):\n        super().__init__()\n        layers = list()\n        for embed_dim in embed_dims:\n            layers.append(torch.nn.Linear(input_dim, embed_dim))\n            layers.append(torch.nn.BatchNorm1d(embed_dim))\n            layers.append(torch.nn.ReLU())\n            layers.append(torch.nn.Dropout(p=dropout))\n            input_dim = embed_dim\n        if output_layer:\n            layers.append(torch.nn.Linear(input_dim, 1))\n        self.mlp = torch.nn.Sequential(*layers)\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        return self.mlp(x)\n\n\nclass InnerProductNetwork(torch.nn.Module):\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        num_fields = x.shape[1]\n        row, col = list(), list()\n        for i in range(num_fields - 1):\n            for j in range(i + 1, num_fields):\n                row.append(i), col.append(j)\n        return torch.sum(x[:, row] * x[:, col], dim=2)\n\n\nclass OuterProductNetwork(torch.nn.Module):\n\n    def __init__(self, num_fields, embed_dim, kernel_type=\'mat\'):\n        super().__init__()\n        num_ix = num_fields * (num_fields - 1) // 2\n        if kernel_type == \'mat\':\n            kernel_shape = embed_dim, num_ix, embed_dim\n        elif kernel_type == \'vec\':\n            kernel_shape = num_ix, embed_dim\n        elif kernel_type == \'num\':\n            kernel_shape = num_ix, 1\n        else:\n            raise ValueError(\'unknown kernel type: \' + kernel_type)\n        self.kernel_type = kernel_type\n        self.kernel = torch.nn.Parameter(torch.zeros(kernel_shape))\n        torch.nn.init.xavier_uniform_(self.kernel.data)\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        num_fields = x.shape[1]\n        row, col = list(), list()\n        for i in range(num_fields - 1):\n            for j in range(i + 1, num_fields):\n                row.append(i), col.append(j)\n        p, q = x[:, row], x[:, col]\n        if self.kernel_type == \'mat\':\n            kp = torch.sum(p.unsqueeze(1) * self.kernel, dim=-1).permute(0, 2, 1)\n            return torch.sum(kp * q, -1)\n        else:\n            return torch.sum(p * q * self.kernel.unsqueeze(0), -1)\n\n\nclass CrossNetwork(torch.nn.Module):\n\n    def __init__(self, input_dim, num_layers):\n        super().__init__()\n        self.num_layers = num_layers\n        self.w = torch.nn.ModuleList([\n            torch.nn.Linear(input_dim, 1, bias=False) for _ in range(num_layers)\n        ])\n        self.b = torch.nn.ParameterList([\n            torch.nn.Parameter(torch.zeros((input_dim,))) for _ in range(num_layers)\n        ])\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        x0 = x\n        for i in range(self.num_layers):\n            xw = self.w[i](x)\n            x = x0 * xw + self.b[i] + x\n        return x\n\n\nclass AttentionalFactorizationMachine(torch.nn.Module):\n\n    def __init__(self, embed_dim, attn_size, dropouts):\n        super().__init__()\n        self.attention = torch.nn.Linear(embed_dim, attn_size)\n        self.projection = torch.nn.Linear(attn_size, 1)\n        self.fc = torch.nn.Linear(embed_dim, 1)\n        self.dropouts = dropouts\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        num_fields = x.shape[1]\n        row, col = list(), list()\n        for i in range(num_fields - 1):\n            for j in range(i + 1, num_fields):\n                row.append(i), col.append(j)\n        p, q = x[:, row], x[:, col]\n        inner_product = p * q\n        attn_scores = F.relu(self.attention(inner_product))\n        attn_scores = F.softmax(self.projection(attn_scores), dim=1)\n        attn_scores = F.dropout(attn_scores, p=self.dropouts[0])\n        attn_output = torch.sum(attn_scores * inner_product, dim=1)\n        attn_output = F.dropout(attn_output, p=self.dropouts[1])\n        return self.fc(attn_output)\n\n\nclass CompressedInteractionNetwork(torch.nn.Module):\n\n    def __init__(self, input_dim, cross_layer_sizes, split_half=True):\n        super().__init__()\n        self.num_layers = len(cross_layer_sizes)\n        self.split_half = split_half\n        self.conv_layers = torch.nn.ModuleList()\n        prev_dim, fc_input_dim = input_dim, 0\n        for i in range(self.num_layers):\n            cross_layer_size = cross_layer_sizes[i]\n            self.conv_layers.append(torch.nn.Conv1d(input_dim * prev_dim, cross_layer_size, 1,\n                                                    stride=1, dilation=1, bias=True))\n            if self.split_half and i != self.num_layers - 1:\n                cross_layer_size //= 2\n            prev_dim = cross_layer_size\n            fc_input_dim += prev_dim\n        self.fc = torch.nn.Linear(fc_input_dim, 1)\n\n    def forward(self, x):\n        """"""\n        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n        """"""\n        xs = list()\n        x0, h = x.unsqueeze(2), x\n        for i in range(self.num_layers):\n            x = x0 * h.unsqueeze(1)\n            batch_size, f0_dim, fin_dim, embed_dim = x.shape\n            x = x.view(batch_size, f0_dim * fin_dim, embed_dim)\n            x = F.relu(self.conv_layers[i](x))\n            if self.split_half and i != self.num_layers - 1:\n                x, h = torch.split(x, x.shape[1] // 2, dim=1)\n            else:\n                h = x\n            xs.append(x)\n        return self.fc(torch.sum(torch.cat(xs, dim=1), 2))\n'"
torchfm/dataset/__init__.py,0,b''
torchfm/dataset/avazu.py,2,"b'import shutil\nimport struct\nfrom collections import defaultdict\nfrom pathlib import Path\n\nimport lmdb\nimport numpy as np\nimport torch.utils.data\nfrom tqdm import tqdm\n\n\nclass AvazuDataset(torch.utils.data.Dataset):\n    """"""\n    Avazu Click-Through Rate Prediction Dataset\n\n    Dataset preparation\n        Remove the infrequent features (appearing in less than threshold instances) and treat them as a single feature\n\n    :param dataset_path: avazu train path\n    :param cache_path: lmdb cache path\n    :param rebuild_cache: If True, lmdb cache is refreshed\n    :param min_threshold: infrequent feature threshold\n\n    Reference\n        https://www.kaggle.com/c/avazu-ctr-prediction\n    """"""\n\n    def __init__(self, dataset_path=None, cache_path=\'.avazu\', rebuild_cache=False, min_threshold=4):\n        self.NUM_FEATS = 22\n        self.min_threshold = min_threshold\n        if rebuild_cache or not Path(cache_path).exists():\n            shutil.rmtree(cache_path, ignore_errors=True)\n            if dataset_path is None:\n                raise ValueError(\'create cache: failed: dataset_path is None\')\n            self.__build_cache(dataset_path, cache_path)\n        self.env = lmdb.open(cache_path, create=False, lock=False, readonly=True)\n        with self.env.begin(write=False) as txn:\n            self.length = txn.stat()[\'entries\'] - 1\n            self.field_dims = np.frombuffer(txn.get(b\'field_dims\'), dtype=np.uint32)\n\n    def __getitem__(self, index):\n        with self.env.begin(write=False) as txn:\n            np_array = np.frombuffer(\n                txn.get(struct.pack(\'>I\', index)), dtype=np.uint32).astype(dtype=np.long)\n        return np_array[1:], np_array[0]\n\n    def __len__(self):\n        return self.length\n\n    def __build_cache(self, path, cache_path):\n        feat_mapper, defaults = self.__get_feat_mapper(path)\n        with lmdb.open(cache_path, map_size=int(1e11)) as env:\n            field_dims = np.zeros(self.NUM_FEATS, dtype=np.uint32)\n            for i, fm in feat_mapper.items():\n                field_dims[i - 1] = len(fm) + 1\n            with env.begin(write=True) as txn:\n                txn.put(b\'field_dims\', field_dims.tobytes())\n            for buffer in self.__yield_buffer(path, feat_mapper, defaults):\n                with env.begin(write=True) as txn:\n                    for key, value in buffer:\n                        txn.put(key, value)\n\n    def __get_feat_mapper(self, path):\n        feat_cnts = defaultdict(lambda: defaultdict(int))\n        with open(path) as f:\n            f.readline()\n            pbar = tqdm(f, mininterval=1, smoothing=0.1)\n            pbar.set_description(\'Create avazu dataset cache: counting features\')\n            for line in pbar:\n                values = line.rstrip(\'\\n\').split(\',\')\n                if len(values) != self.NUM_FEATS + 2:\n                    continue\n                for i in range(1, self.NUM_FEATS + 1):\n                    feat_cnts[i][values[i + 1]] += 1\n        feat_mapper = {i: {feat for feat, c in cnt.items() if c >= self.min_threshold} for i, cnt in feat_cnts.items()}\n        feat_mapper = {i: {feat: idx for idx, feat in enumerate(cnt)} for i, cnt in feat_mapper.items()}\n        defaults = {i: len(cnt) for i, cnt in feat_mapper.items()}\n        return feat_mapper, defaults\n\n    def __yield_buffer(self, path, feat_mapper, defaults, buffer_size=int(1e5)):\n        item_idx = 0\n        buffer = list()\n        with open(path) as f:\n            f.readline()\n            pbar = tqdm(f, mininterval=1, smoothing=0.1)\n            pbar.set_description(\'Create avazu dataset cache: setup lmdb\')\n            for line in pbar:\n                values = line.rstrip(\'\\n\').split(\',\')\n                if len(values) != self.NUM_FEATS + 2:\n                    continue\n                np_array = np.zeros(self.NUM_FEATS + 1, dtype=np.uint32)\n                np_array[0] = int(values[1])\n                for i in range(1, self.NUM_FEATS + 1):\n                    np_array[i] = feat_mapper[i].get(values[i+1], defaults[i])\n                buffer.append((struct.pack(\'>I\', item_idx), np_array.tobytes()))\n                item_idx += 1\n                if item_idx % buffer_size == 0:\n                    yield buffer\n                    buffer.clear()\n            yield buffer\n'"
torchfm/dataset/criteo.py,2,"b'import math\nimport shutil\nimport struct\nfrom collections import defaultdict\nfrom functools import lru_cache\nfrom pathlib import Path\n\nimport lmdb\nimport numpy as np\nimport torch.utils.data\nfrom tqdm import tqdm\n\n\nclass CriteoDataset(torch.utils.data.Dataset):\n    """"""\n    Criteo Display Advertising Challenge Dataset\n\n    Data prepration:\n        * Remove the infrequent features (appearing in less than threshold instances) and treat them as a single feature\n        * Discretize numerical values by log2 transformation which is proposed by the winner of Criteo Competition\n\n    :param dataset_path: criteo train.txt path.\n    :param cache_path: lmdb cache path.\n    :param rebuild_cache: If True, lmdb cache is refreshed.\n    :param min_threshold: infrequent feature threshold.\n\n    Reference:\n        https://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset\n        https://www.csie.ntu.edu.tw/~r01922136/kaggle-2014-criteo.pdf\n    """"""\n\n    def __init__(self, dataset_path=None, cache_path=\'.criteo\', rebuild_cache=False, min_threshold=10):\n        self.NUM_FEATS = 39\n        self.NUM_INT_FEATS = 13\n        self.min_threshold = min_threshold\n        if rebuild_cache or not Path(cache_path).exists():\n            shutil.rmtree(cache_path, ignore_errors=True)\n            if dataset_path is None:\n                raise ValueError(\'create cache: failed: dataset_path is None\')\n            self.__build_cache(dataset_path, cache_path)\n        self.env = lmdb.open(cache_path, create=False, lock=False, readonly=True)\n        with self.env.begin(write=False) as txn:\n            self.length = txn.stat()[\'entries\'] - 1\n            self.field_dims = np.frombuffer(txn.get(b\'field_dims\'), dtype=np.uint32)\n\n    def __getitem__(self, index):\n        with self.env.begin(write=False) as txn:\n            np_array = np.frombuffer(\n                txn.get(struct.pack(\'>I\', index)), dtype=np.uint32).astype(dtype=np.long)\n        return np_array[1:], np_array[0]\n\n    def __len__(self):\n        return self.length\n\n    def __build_cache(self, path, cache_path):\n        feat_mapper, defaults = self.__get_feat_mapper(path)\n        with lmdb.open(cache_path, map_size=int(1e11)) as env:\n            field_dims = np.zeros(self.NUM_FEATS, dtype=np.uint32)\n            for i, fm in feat_mapper.items():\n                field_dims[i - 1] = len(fm) + 1\n            with env.begin(write=True) as txn:\n                txn.put(b\'field_dims\', field_dims.tobytes())\n            for buffer in self.__yield_buffer(path, feat_mapper, defaults):\n                with env.begin(write=True) as txn:\n                    for key, value in buffer:\n                        txn.put(key, value)\n\n    def __get_feat_mapper(self, path):\n        feat_cnts = defaultdict(lambda: defaultdict(int))\n        with open(path) as f:\n            pbar = tqdm(f, mininterval=1, smoothing=0.1)\n            pbar.set_description(\'Create criteo dataset cache: counting features\')\n            for line in pbar:\n                values = line.rstrip(\'\\n\').split(\'\\t\')\n                if len(values) != self.NUM_FEATS + 1:\n                    continue\n                for i in range(1, self.NUM_INT_FEATS + 1):\n                    feat_cnts[i][convert_numeric_feature(values[i])] += 1\n                for i in range(self.NUM_INT_FEATS + 1, self.NUM_FEATS + 1):\n                    feat_cnts[i][values[i]] += 1\n        feat_mapper = {i: {feat for feat, c in cnt.items() if c >= self.min_threshold} for i, cnt in feat_cnts.items()}\n        feat_mapper = {i: {feat: idx for idx, feat in enumerate(cnt)} for i, cnt in feat_mapper.items()}\n        defaults = {i: len(cnt) for i, cnt in feat_mapper.items()}\n        return feat_mapper, defaults\n\n    def __yield_buffer(self, path, feat_mapper, defaults, buffer_size=int(1e5)):\n        item_idx = 0\n        buffer = list()\n        with open(path) as f:\n            pbar = tqdm(f, mininterval=1, smoothing=0.1)\n            pbar.set_description(\'Create criteo dataset cache: setup lmdb\')\n            for line in pbar:\n                values = line.rstrip(\'\\n\').split(\'\\t\')\n                if len(values) != self.NUM_FEATS + 1:\n                    continue\n                np_array = np.zeros(self.NUM_FEATS + 1, dtype=np.uint32)\n                np_array[0] = int(values[0])\n                for i in range(1, self.NUM_INT_FEATS + 1):\n                    np_array[i] = feat_mapper[i].get(convert_numeric_feature(values[i]), defaults[i])\n                for i in range(self.NUM_INT_FEATS + 1, self.NUM_FEATS + 1):\n                    np_array[i] = feat_mapper[i].get(values[i], defaults[i])\n                buffer.append((struct.pack(\'>I\', item_idx), np_array.tobytes()))\n                item_idx += 1\n                if item_idx % buffer_size == 0:\n                    yield buffer\n                    buffer.clear()\n            yield buffer\n\n\n@lru_cache(maxsize=None)\ndef convert_numeric_feature(val: str):\n    if val == \'\':\n        return \'NULL\'\n    v = int(val)\n    if v > 2:\n        return str(int(math.log(v) ** 2))\n    else:\n        return str(v - 2)\n'"
torchfm/dataset/movielens.py,2,"b'import numpy as np\nimport pandas as pd\nimport torch.utils.data\n\n\nclass MovieLens20MDataset(torch.utils.data.Dataset):\n    """"""\n    MovieLens 20M Dataset\n\n    Data preparation\n        treat samples with a rating less than 3 as negative samples\n\n    :param dataset_path: MovieLens dataset path\n\n    Reference:\n        https://grouplens.org/datasets/movielens\n    """"""\n\n    def __init__(self, dataset_path, sep=\',\', engine=\'c\', header=\'infer\'):\n        data = pd.read_csv(dataset_path, sep=sep, engine=engine, header=header).to_numpy()[:, :3]\n        self.items = data[:, :2].astype(np.int) - 1  # -1 because ID begins from 1\n        self.targets = self.__preprocess_target(data[:, 2]).astype(np.float32)\n        self.field_dims = np.max(self.items, axis=0) + 1\n        self.user_field_idx = np.array((0, ), dtype=np.long)\n        self.item_field_idx = np.array((1,), dtype=np.long)\n\n    def __len__(self):\n        return self.targets.shape[0]\n\n    def __getitem__(self, index):\n        return self.items[index], self.targets[index]\n\n    def __preprocess_target(self, target):\n        target[target <= 3] = 0\n        target[target > 3] = 1\n        return target\n\n\nclass MovieLens1MDataset(MovieLens20MDataset):\n    """"""\n    MovieLens 1M Dataset\n\n    Data preparation\n        treat samples with a rating less than 3 as negative samples\n\n    :param dataset_path: MovieLens dataset path\n\n    Reference:\n        https://grouplens.org/datasets/movielens\n    """"""\n\n    def __init__(self, dataset_path):\n        super().__init__(dataset_path, sep=\'::\', engine=\'python\', header=None)\n'"
torchfm/model/__init__.py,0,b''
torchfm/model/afi.py,8,"b'import torch\nimport torch.nn.functional as F\n\nfrom torchfm.layer import FeaturesEmbedding, FeaturesLinear, MultiLayerPerceptron\n\n\nclass AutomaticFeatureInteractionModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of AutoInt.\n\n    Reference:\n        W Song, et al. AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks, 2018.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, atten_embed_dim, num_heads, num_layers, mlp_dims, dropouts, has_residual=True):\n        super().__init__()\n        self.num_fields = len(field_dims)\n        self.linear = FeaturesLinear(field_dims)\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.atten_embedding = torch.nn.Linear(embed_dim, atten_embed_dim)\n        self.embed_output_dim = len(field_dims) * embed_dim\n        self.atten_output_dim = len(field_dims) * atten_embed_dim\n        self.has_residual = has_residual\n        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropouts[1])\n        self.self_attns = torch.nn.ModuleList([\n            torch.nn.MultiheadAttention(atten_embed_dim, num_heads, dropout=dropouts[0]) for _ in range(num_layers)\n        ])\n        self.attn_fc = torch.nn.Linear(self.atten_output_dim, 1)\n        if self.has_residual:\n            self.V_res_embedding = torch.nn.Linear(embed_dim, atten_embed_dim)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        embed_x = self.embedding(x)\n        atten_x = self.atten_embedding(embed_x)\n        cross_term = atten_x.transpose(0, 1)\n        for self_attn in self.self_attns:\n            cross_term, _ = self_attn(cross_term, cross_term, cross_term)\n        cross_term = cross_term.transpose(0, 1)\n        if self.has_residual:\n            V_res = self.V_res_embedding(embed_x)\n            cross_term += V_res\n        cross_term = F.relu(cross_term).contiguous().view(-1, self.atten_output_dim)\n        x = self.linear(x) + self.attn_fc(cross_term) + self.mlp(embed_x.view(-1, self.embed_output_dim))\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/afm.py,2,"b'import torch\n\nfrom torchfm.layer import FeaturesEmbedding, FeaturesLinear, AttentionalFactorizationMachine\n\n\nclass AttentionalFactorizationMachineModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Attentional Factorization Machine.\n\n    Reference:\n        J Xiao, et al. Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks, 2017.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, attn_size, dropouts):\n        super().__init__()\n        self.num_fields = len(field_dims)\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.linear = FeaturesLinear(field_dims)\n        self.afm = AttentionalFactorizationMachine(embed_dim, attn_size, dropouts)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        x = self.linear(x) + self.afm(self.embedding(x))\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/afn.py,11,"b'import math\nimport torch\nimport torch.nn.functional as F\n\nfrom torchfm.layer import FeaturesEmbedding, FeaturesLinear, MultiLayerPerceptron\n\nclass LNN(torch.nn.Module):\n    """"""\n    A pytorch implementation of LNN layer\n    Input shape\n        - A 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n    Output shape\n        - 2D tensor with shape:``(batch_size,LNN_dim*embedding_size)``.\n    Arguments\n        - **in_features** : Embedding of feature.\n        - **num_fields**: int.The field size of feature.\n        - **LNN_dim**: int.The number of Logarithmic neuron.\n        - **bias**: bool.Whether or not use bias in LNN.\n    """"""\n    def __init__(self, num_fields, embed_dim, LNN_dim, bias=False):\n        super(LNN, self).__init__()\n        self.num_fields = num_fields\n        self.embed_dim = embed_dim\n        self.LNN_dim = LNN_dim\n        self.lnn_output_dim = LNN_dim * embed_dim\n        self.weight = torch.nn.Parameter(torch.Tensor(LNN_dim, num_fields))\n        if bias:\n            self.bias = torch.nn.Parameter(torch.Tensor(LNN_dim, embed_dim))\n        else:\n            self.register_parameter(\'bias\', None)\n        self.reset_parameters()\n    \n    def reset_parameters(self):\n        stdv = 1. / math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n        if self.bias is not None:\n            self.bias.data.uniform_(-stdv, stdv)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields, embedding_size)``\n        """"""\n        embed_x_abs = torch.abs(x) # Computes the element-wise absolute value of the given input tensor.\n        embed_x_afn = torch.add(embed_x_abs, 1e-7)\n        # Logarithmic Transformation\n        embed_x_log = torch.log1p(embed_x_afn) # torch.log1p and torch.expm1\n        lnn_out = torch.matmul(self.weight, embed_x_log)\n        if self.bias is not None:\n            lnn_out += self.bias\n        lnn_exp = torch.expm1(lnn_out)\n        output = F.relu(lnn_exp).contiguous().view(-1, self.lnn_output_dim)\n        return output\n\n\n\n\n\n\nclass AdaptiveFactorizationNetwork(torch.nn.Module):\n    """"""\n    A pytorch implementation of AFN.\n\n    Reference:\n        Cheng W, et al. Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions, 2019.\n    """"""\n    def __init__(self, field_dims, embed_dim, LNN_dim, mlp_dims, dropouts):\n        super().__init__()\n        self.num_fields = len(field_dims)\n        self.linear = FeaturesLinear(field_dims)    # Linear\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)   # Embedding\n        self.LNN_dim = LNN_dim\n        self.LNN_output_dim = self.LNN_dim * embed_dim\n        self.LNN = LNN(self.num_fields, embed_dim, LNN_dim)\n        self.mlp = MultiLayerPerceptron(self.LNN_output_dim, mlp_dims, dropouts[0])\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        embed_x = self.embedding(x)\n        lnn_out = self.LNN(embed_x)\n        x = self.linear(x) + self.mlp(lnn_out)\n        return torch.sigmoid(x.squeeze(1))\n\n'"
torchfm/model/dcn.py,4,"b'import torch\n\nfrom torchfm.layer import FeaturesEmbedding, CrossNetwork, MultiLayerPerceptron\n\n\nclass DeepCrossNetworkModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Deep & Cross Network.\n\n    Reference:\n        R Wang, et al. Deep & Cross Network for Ad Click Predictions, 2017.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, num_layers, mlp_dims, dropout):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.embed_output_dim = len(field_dims) * embed_dim\n        self.cn = CrossNetwork(self.embed_output_dim, num_layers)\n        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout, output_layer=False)\n        self.linear = torch.nn.Linear(mlp_dims[-1] + self.embed_output_dim, 1)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        embed_x = self.embedding(x).view(-1, self.embed_output_dim)\n        x_l1 = self.cn(embed_x)\n        h_l2 = self.mlp(embed_x)\n        x_stack = torch.cat([x_l1, h_l2], dim=1)\n        p = self.linear(x_stack)\n        return torch.sigmoid(p.squeeze(1))\n'"
torchfm/model/dfm.py,2,"b'import torch\n\nfrom torchfm.layer import FactorizationMachine, FeaturesEmbedding, FeaturesLinear, MultiLayerPerceptron\n\n\nclass DeepFactorizationMachineModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of DeepFM.\n\n    Reference:\n        H Guo, et al. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, 2017.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropout):\n        super().__init__()\n        self.linear = FeaturesLinear(field_dims)\n        self.fm = FactorizationMachine(reduce_sum=True)\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.embed_output_dim = len(field_dims) * embed_dim\n        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        embed_x = self.embedding(x)\n        x = self.linear(x) + self.fm(embed_x) + self.mlp(embed_x.view(-1, self.embed_output_dim))\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/ffm.py,3,"b'import torch\n\nfrom torchfm.layer import FeaturesLinear, FieldAwareFactorizationMachine\n\n\nclass FieldAwareFactorizationMachineModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Field-aware Factorization Machine.\n\n    Reference:\n        Y Juan, et al. Field-aware Factorization Machines for CTR Prediction, 2015.\n    """"""\n\n    def __init__(self, field_dims, embed_dim):\n        super().__init__()\n        self.linear = FeaturesLinear(field_dims)\n        self.ffm = FieldAwareFactorizationMachine(field_dims, embed_dim)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        ffm_term = torch.sum(torch.sum(self.ffm(x), dim=1), dim=1, keepdim=True)\n        x = self.linear(x) + ffm_term\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/fm.py,2,"b'import torch\n\nfrom torchfm.layer import FactorizationMachine, FeaturesEmbedding, FeaturesLinear\n\n\nclass FactorizationMachineModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Factorization Machine.\n\n    Reference:\n        S Rendle, Factorization Machines, 2010.\n    """"""\n\n    def __init__(self, field_dims, embed_dim):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.linear = FeaturesLinear(field_dims)\n        self.fm = FactorizationMachine(reduce_sum=True)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        x = self.linear(x) + self.fm(self.embedding(x))\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/fnfm.py,4,"b'import torch\n\nfrom torchfm.layer import FieldAwareFactorizationMachine, MultiLayerPerceptron, FeaturesLinear\n\n\nclass FieldAwareNeuralFactorizationMachineModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Field-aware Neural Factorization Machine.\n\n    Reference:\n        L Zhang, et al. Field-aware Neural Factorization Machine for Click-Through Rate Prediction, 2019.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropouts):\n        super().__init__()\n        self.linear = FeaturesLinear(field_dims)\n        self.ffm = FieldAwareFactorizationMachine(field_dims, embed_dim)\n        self.ffm_output_dim = len(field_dims) * (len(field_dims) - 1) // 2 * embed_dim\n        self.bn = torch.nn.BatchNorm1d(self.ffm_output_dim)\n        self.dropout = torch.nn.Dropout(dropouts[0])\n        self.mlp = MultiLayerPerceptron(self.ffm_output_dim, mlp_dims, dropouts[1])\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        cross_term = self.ffm(x).view(-1, self.ffm_output_dim)\n        cross_term = self.bn(cross_term)\n        cross_term = self.dropout(cross_term)\n        x = self.linear(x) + self.mlp(cross_term)\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/fnn.py,2,"b'import torch\n\nfrom torchfm.layer import FeaturesEmbedding, MultiLayerPerceptron\n\n\nclass FactorizationSupportedNeuralNetworkModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Neural Factorization Machine.\n\n    Reference:\n        W Zhang, et al. Deep Learning over Multi-field Categorical Data - A Case Study on User Response Prediction, 2016.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropout):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.embed_output_dim = len(field_dims) * embed_dim\n        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        embed_x = self.embedding(x)\n        x = self.mlp(embed_x.view(-1, self.embed_output_dim))\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/lr.py,2,"b'import torch\n\nfrom torchfm.layer import FeaturesLinear\n\n\nclass LogisticRegressionModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Logistic Regression.\n    """"""\n\n    def __init__(self, field_dims):\n        super().__init__()\n        self.linear = FeaturesLinear(field_dims)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        return torch.sigmoid(self.linear(x).squeeze(1))\n'"
torchfm/model/ncf.py,4,"b'import torch\nfrom torchfm.layer import FeaturesEmbedding, MultiLayerPerceptron\n\n\nclass NeuralCollaborativeFiltering(torch.nn.Module):\n    """"""\n    A pytorch implementation of Neural Collaborative Filtering.\n\n    Reference:\n        X He, et al. Neural Collaborative Filtering, 2017.\n    """"""\n\n    def __init__(self, field_dims, user_field_idx, item_field_idx, embed_dim, mlp_dims, dropout):\n        super().__init__()\n        self.user_field_idx = user_field_idx\n        self.item_field_idx = item_field_idx\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.embed_output_dim = len(field_dims) * embed_dim\n        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout, output_layer=False)\n        self.fc = torch.nn.Linear(mlp_dims[-1] + embed_dim, 1)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_user_fields)``\n        """"""\n        x = self.embedding(x)\n        user_x = x[:, self.user_field_idx].squeeze(1)\n        item_x = x[:, self.item_field_idx].squeeze(1)\n        x = self.mlp(x.view(-1, self.embed_output_dim))\n        gmf = user_x * item_x\n        x = torch.cat([gmf, x], dim=1)\n        x = self.fc(x).squeeze(1)\n        return torch.sigmoid(x)\n'"
torchfm/model/nfm.py,5,"b'import torch\n\nfrom torchfm.layer import FactorizationMachine, FeaturesEmbedding, MultiLayerPerceptron, FeaturesLinear\n\n\nclass NeuralFactorizationMachineModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of Neural Factorization Machine.\n\n    Reference:\n        X He and TS Chua, Neural Factorization Machines for Sparse Predictive Analytics, 2017.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropouts):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.linear = FeaturesLinear(field_dims)\n        self.fm = torch.nn.Sequential(\n            FactorizationMachine(reduce_sum=False),\n            torch.nn.BatchNorm1d(embed_dim),\n            torch.nn.Dropout(dropouts[0])\n        )\n        self.mlp = MultiLayerPerceptron(embed_dim, mlp_dims, dropouts[1])\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        cross_term = self.fm(self.embedding(x))\n        x = self.linear(x) + self.mlp(cross_term)\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/pnn.py,3,"b'import torch\n\nfrom torchfm.layer import FeaturesEmbedding, FeaturesLinear, InnerProductNetwork, \\\n    OuterProductNetwork, MultiLayerPerceptron\n\n\nclass ProductNeuralNetworkModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of inner/outer Product Neural Network.\n    Reference:\n        Y Qu, et al. Product-based Neural Networks for User Response Prediction, 2016.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropout, method=\'inner\'):\n        super().__init__()\n        num_fields = len(field_dims)\n        if method == \'inner\':\n            self.pn = InnerProductNetwork()\n        elif method == \'outer\':\n            self.pn = OuterProductNetwork(num_fields, embed_dim)\n        else:\n            raise ValueError(\'unknown product type: \' + method)\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.linear = FeaturesLinear(field_dims, embed_dim)\n        self.embed_output_dim = num_fields * embed_dim\n        self.mlp = MultiLayerPerceptron(num_fields * (num_fields - 1) // 2 + self.embed_output_dim, mlp_dims, dropout)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        embed_x = self.embedding(x)\n        cross_term = self.pn(embed_x)\n        x = torch.cat([embed_x.view(-1, self.embed_output_dim), cross_term], dim=1)\n        x = self.mlp(x)\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/wd.py,2,"b'import torch\n\nfrom torchfm.layer import FeaturesLinear, MultiLayerPerceptron, FeaturesEmbedding\n\n\nclass WideAndDeepModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of wide and deep learning.\n\n    Reference:\n        HT Cheng, et al. Wide & Deep Learning for Recommender Systems, 2016.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropout):\n        super().__init__()\n        self.linear = FeaturesLinear(field_dims)\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.embed_output_dim = len(field_dims) * embed_dim\n        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        embed_x = self.embedding(x)\n        x = self.linear(x) + self.mlp(embed_x.view(-1, self.embed_output_dim))\n        return torch.sigmoid(x.squeeze(1))\n'"
torchfm/model/xdfm.py,2,"b'import torch\n\nfrom torchfm.layer import CompressedInteractionNetwork, FeaturesEmbedding, FeaturesLinear, MultiLayerPerceptron\n\n\nclass ExtremeDeepFactorizationMachineModel(torch.nn.Module):\n    """"""\n    A pytorch implementation of xDeepFM.\n\n    Reference:\n        J Lian, et al. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems, 2018.\n    """"""\n\n    def __init__(self, field_dims, embed_dim, mlp_dims, dropout, cross_layer_sizes, split_half=True):\n        super().__init__()\n        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n        self.embed_output_dim = len(field_dims) * embed_dim\n        self.cin = CompressedInteractionNetwork(len(field_dims), cross_layer_sizes, split_half)\n        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout)\n        self.linear = FeaturesLinear(field_dims)\n\n    def forward(self, x):\n        """"""\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        """"""\n        embed_x = self.embedding(x)\n        x = self.linear(x) + self.cin(embed_x) + self.mlp(embed_x.view(-1, self.embed_output_dim))\n        return torch.sigmoid(x.squeeze(1))\n'"
