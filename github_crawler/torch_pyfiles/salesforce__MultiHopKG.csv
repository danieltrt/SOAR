file_path,api_count,code
src/data_utils.py,0,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Data processing utilities.\n""""""\n\nimport collections\nimport numpy as np\nimport os\nimport pickle\n\nSTART_RELATION = \'START_RELATION\'\nNO_OP_RELATION = \'NO_OP_RELATION\'\nNO_OP_ENTITY = \'NO_OP_ENTITY\'\nDUMMY_RELATION = \'DUMMY_RELATION\'\nDUMMY_ENTITY = \'DUMMY_ENTITY\'\n\nDUMMY_RELATION_ID = 0\nSTART_RELATION_ID = 1\nNO_OP_RELATION_ID = 2\nDUMMY_ENTITY_ID = 0\nNO_OP_ENTITY_ID = 1\n\n\ndef check_answer_ratio(examples):\n    entity_dict = {}\n    for e1, e2, r in examples:\n        if not e1 in entity_dict:\n            entity_dict[e1] = set()\n        entity_dict[e1].add(e2)\n    answer_ratio = 0\n    for e1 in entity_dict:\n        answer_ratio += len(entity_dict[e1])\n    return answer_ratio / len(entity_dict)\n\ndef check_relation_answer_ratio(input_file, kg):\n    example_dict = {}\n    with open(input_file) as f:\n        for line in f:\n            e1, e2, r = line.strip().split()\n            e1 = kg.entity2id[e1]\n            e2 = kg.entity2id[e2]\n            r = kg.relation2id[r]\n            if not r in example_dict:\n                example_dict[r] = []\n            example_dict[r].append((e1, e2, r))\n    r_answer_ratio = {}\n    for r in example_dict:\n        r_answer_ratio[r] = check_answer_ratio(example_dict[r])\n    return r_answer_ratio\n\ndef change_to_test_model_path(dataset, model_path):\n    model_dir = os.path.dirname(os.path.dirname(model_path))\n    model_subdir = os.path.basename(os.path.dirname(model_path))\n    file_name = os.path.basename(model_path)\n    new_model_subdir = dataset + \'.test\' + model_subdir[len(dataset):]\n    new_model_subdir += \'-test\'\n    new_model_path = os.path.join(model_dir, new_model_subdir, file_name)\n    return new_model_path\n\ndef get_train_path(args):\n    if \'NELL\' in args.data_dir:\n        if not args.model.startswith(\'point\'):\n            if args.test:\n                train_path = os.path.join(args.data_dir, \'train.dev.large.triples\')\n            else:\n                train_path = os.path.join(args.data_dir, \'train.large.triples\')\n        else:\n            if args.test:\n                train_path = os.path.join(args.data_dir, \'train.dev.triples\')\n            else:\n                train_path = os.path.join(args.data_dir, \'train.triples\')\n    else:\n        train_path = os.path.join(args.data_dir, \'train.triples\')\n\n    return train_path\n\ndef load_seen_entities(adj_list_path, entity_index_path):\n    _, id2entity = load_index(entity_index_path)\n    with open(adj_list_path, \'rb\') as f:\n        adj_list = pickle.load(f)\n    seen_entities = set()\n    for e1 in adj_list:\n        seen_entities.add(id2entity[e1])\n        for r in adj_list[e1]:\n            for e2 in adj_list[e1][r]:\n                seen_entities.add(id2entity[e2])\n    print(\'{} seen entities loaded...\'.format(len(seen_entities)))\n    return seen_entities\n \ndef load_triples_with_label(data_path, r, entity_index_path, relation_index_path, seen_entities=None, verbose=False):\n    entity2id, _ = load_index(entity_index_path)\n    relation2id, _ = load_index(relation_index_path)\n\n    def triple2ids(e1, e2, r):\n        return entity2id[e1], entity2id[e2], relation2id[r]\n\n    triples, labels = [], []\n    with open(data_path) as f:\n        num_skipped = 0\n        for line in f:\n            pair, label = line.strip().split(\': \')\n            e1, e2 = pair.strip().split(\',\')\n            if seen_entities and (not e1 in seen_entities or not e2 in seen_entities):\n                num_skipped += 1\n                if verbose:\n                    print(\'Skip triple ({}) with unseen entity: {}\'.format(num_skipped, line.strip())) \n                continue\n            triples.append(triple2ids(e1, e2, r))\n            labels.append(label.strip())\n    return triples, labels\n\ndef load_triples(data_path, entity_index_path, relation_index_path, group_examples_by_query=False,\n                 add_reverse_relations=False, seen_entities=None, verbose=False):\n    """"""\n    Convert triples stored on disc into indices.\n    """"""\n    entity2id, _ = load_index(entity_index_path)\n    relation2id, _ = load_index(relation_index_path)\n\n    def triple2ids(e1, e2, r):\n        return entity2id[e1], entity2id[e2], relation2id[r]\n\n    triples = []\n    if group_examples_by_query:\n        triple_dict = {}\n    with open(data_path) as f:\n        num_skipped = 0\n        for line in f:\n            e1, e2, r = line.strip().split()\n            if seen_entities and (not e1 in seen_entities or not e2 in seen_entities):\n                num_skipped += 1\n                if verbose:\n                    print(\'Skip triple ({}) with unseen entity: {}\'.format(num_skipped, line.strip())) \n                continue\n            # if r in [\'concept:agentbelongstoorganization\', \'concept:teamplaysinleague\']:\n            #     continue\n            if group_examples_by_query:\n                e1_id, e2_id, r_id = triple2ids(e1, e2, r)\n                if e1_id not in triple_dict:\n                    triple_dict[e1_id] = {}\n                if r_id not in triple_dict[e1_id]:\n                    triple_dict[e1_id][r_id] = set()\n                triple_dict[e1_id][r_id].add(e2_id)\n                if add_reverse_relations:\n                    r_inv = r + \'_inv\'\n                    e2_id, e1_id, r_inv_id = triple2ids(e2, e1, r_inv)\n                    if e2_id not in triple_dict:\n                        triple_dict[e2_id] = {}\n                    if r_inv_id not in triple_dict[e2_id]:\n                        triple_dict[e2_id][r_inv_id] = set()\n                    triple_dict[e2_id][r_inv_id].add(e1_id)\n            else:\n                triples.append(triple2ids(e1, e2, r))\n                if add_reverse_relations:\n                    triples.append(triple2ids(e2, e1, r + \'_inv\'))\n    if group_examples_by_query:\n        for e1_id in triple_dict:\n            for r_id in triple_dict[e1_id]:\n                triples.append((e1_id, list(triple_dict[e1_id][r_id]), r_id))\n    print(\'{} triples loaded from {}\'.format(len(triples), data_path))\n    return triples\n\ndef load_entity_hist(input_path):\n    entity_hist = {}\n    with open(input_path) as f:\n        for line in f.readlines():\n            v, f = line.strip().split()\n            entity_hist[v] = int(f)\n    return entity_hist\n\ndef load_index(input_path):\n    index, rev_index = {}, {}\n    with open(input_path) as f:\n        for i, line in enumerate(f.readlines()):\n            v, _ = line.strip().split()\n            index[v] = i\n            rev_index[i] = v\n    return index, rev_index\n\ndef prepare_kb_envrioment(raw_kb_path, train_path, dev_path, test_path, test_mode, add_reverse_relations=True):\n    """"""\n    Process KB data which was saved as a set of triples.\n        (a) Remove train and test triples from the KB envrionment.\n        (b) Add reverse triples on demand.\n        (c) Index unique entities and relations appeared in the KB.\n\n    :param raw_kb_path: Path to the raw KB triples.\n    :param train_path: Path to the train set KB triples.\n    :param dev_path: Path to the dev set KB triples.\n    :param test_path: Path to the test set KB triples.\n    :param add_reverse_relations: If set, add reverse triples to the KB environment.\n    """"""\n    data_dir = os.path.dirname(raw_kb_path)\n\n    def get_type(e_name):\n        if e_name == DUMMY_ENTITY:\n            return DUMMY_ENTITY\n        if \'nell-995\' in data_dir.lower():\n            if \'_\' in e_name:\n                return e_name.split(\'_\')[1]\n            else:\n                return \'numerical\'\n        else:\n            return \'entity\'\n\n    def hist_to_vocab(_dict):\n        return sorted(sorted(_dict.items(), key=lambda x: x[0]), key=lambda x: x[1], reverse=True)\n\n    # Create entity and relation indices\n    entity_hist = collections.defaultdict(int)\n    relation_hist = collections.defaultdict(int)\n    type_hist = collections.defaultdict(int)\n    with open(raw_kb_path) as f:\n        raw_kb_triples = [l.strip() for l in f.readlines()]\n    with open(train_path) as f:\n        train_triples = [l.strip() for l in f.readlines()]\n    with open(dev_path) as f:\n        dev_triples = [l.strip() for l in f.readlines()]\n    with open(test_path) as f:\n        test_triples = [l.strip() for l in f.readlines()]\n\n    if test_mode:\n        keep_triples = train_triples + dev_triples\n        removed_triples = test_triples\n    else:\n        keep_triples = train_triples\n        removed_triples = dev_triples + test_triples\n\n    # Index entities and relations\n    for line in set(raw_kb_triples + keep_triples + removed_triples):\n        e1, e2, r = line.strip().split()\n        entity_hist[e1] += 1\n        entity_hist[e2] += 1\n        if \'nell-995\' in data_dir.lower():\n            t1 = e1.split(\'_\')[1] if \'_\' in e1 else \'numerical\'\n            t2 = e2.split(\'_\')[1] if \'_\' in e2 else \'numerical\'\n        else:\n            t1 = get_type(e1)\n            t2 = get_type(e2)\n        type_hist[t1] += 1\n        type_hist[t2] += 1\n        relation_hist[r] += 1\n        if add_reverse_relations:\n            inv_r = r + \'_inv\'\n            relation_hist[inv_r] += 1\n    # Save the entity and relation indices sorted by decreasing frequency\n    with open(os.path.join(data_dir, \'entity2id.txt\'), \'w\') as o_f:\n        o_f.write(\'{}\\t{}\\n\'.format(DUMMY_ENTITY, DUMMY_ENTITY_ID))\n        o_f.write(\'{}\\t{}\\n\'.format(NO_OP_ENTITY, NO_OP_ENTITY_ID))\n        for e, freq in hist_to_vocab(entity_hist):\n            o_f.write(\'{}\\t{}\\n\'.format(e, freq))\n    with open(os.path.join(data_dir, \'relation2id.txt\'), \'w\') as o_f:\n        o_f.write(\'{}\\t{}\\n\'.format(DUMMY_RELATION, DUMMY_RELATION_ID))\n        o_f.write(\'{}\\t{}\\n\'.format(START_RELATION, START_RELATION_ID))\n        o_f.write(\'{}\\t{}\\n\'.format(NO_OP_RELATION, NO_OP_RELATION_ID))\n        for r, freq in hist_to_vocab(relation_hist):\n            o_f.write(\'{}\\t{}\\n\'.format(r, freq))\n    with open(os.path.join(data_dir, \'type2id.txt\'), \'w\') as o_f:\n        for t, freq in hist_to_vocab(type_hist):\n            o_f.write(\'{}\\t{}\\n\'.format(t, freq))\n    print(\'{} entities indexed\'.format(len(entity_hist)))\n    print(\'{} relations indexed\'.format(len(relation_hist)))\n    print(\'{} types indexed\'.format(len(type_hist)))\n    entity2id, id2entity = load_index(os.path.join(data_dir, \'entity2id.txt\'))\n    relation2id, id2relation = load_index(os.path.join(data_dir, \'relation2id.txt\'))\n    type2id, id2type = load_index(os.path.join(data_dir, \'type2id.txt\'))\n\n    removed_triples = set(removed_triples)\n    adj_list = collections.defaultdict(collections.defaultdict)\n    entity2typeid = [0 for i in range(len(entity2id))]\n    num_facts = 0\n    for line in set(raw_kb_triples + keep_triples):\n        e1, e2, r = line.strip().split()\n        triple_signature = \'{}\\t{}\\t{}\'.format(e1, e2, r)\n        e1_id = entity2id[e1]\n        e2_id = entity2id[e2]\n        t1 = get_type(e1)\n        t2 = get_type(e2)\n        t1_id = type2id[t1]\n        t2_id = type2id[t2]\n        entity2typeid[e1_id] = t1_id\n        entity2typeid[e2_id] = t2_id\n        if not triple_signature in removed_triples:\n            r_id = relation2id[r]\n            if not r_id in adj_list[e1_id]:\n                adj_list[e1_id][r_id] = set()\n            if e2_id in adj_list[e1_id][r_id]:\n                print(\'Duplicate fact: {} ({}, {}, {})!\'.format(\n                    line.strip(), id2entity[e1_id], id2relation[r_id], id2entity[e2_id]))\n            adj_list[e1_id][r_id].add(e2_id)\n            num_facts += 1\n            if add_reverse_relations:\n                inv_r = r + \'_inv\'\n                inv_r_id = relation2id[inv_r]\n                if not inv_r_id in adj_list[e2_id]:\n                    adj_list[e2_id][inv_r_id] = set([])\n                if e1_id in adj_list[e2_id][inv_r_id]:\n                    print(\'Duplicate fact: {} ({}, {}, {})!\'.format(\n                        line.strip(), id2entity[e2_id], id2relation[inv_r_id], id2entity[e1_id]))\n                adj_list[e2_id][inv_r_id].add(e1_id)\n                num_facts += 1\n    print(\'{} facts processed\'.format(num_facts))\n    # Save adjacency list\n    adj_list_path = os.path.join(data_dir, \'adj_list.pkl\')\n    with open(adj_list_path, \'wb\') as o_f:\n        pickle.dump(dict(adj_list), o_f)\n    with open(os.path.join(data_dir, \'entity2typeid.pkl\'), \'wb\') as o_f:\n        pickle.dump(entity2typeid, o_f)\n\ndef get_seen_queries(data_dir, entity_index_path, relation_index_path):\n    entity2id, _ = load_index(entity_index_path)\n    relation2id, _ = load_index(relation_index_path)\n    seen_queries = set()\n    with open(os.path.join(data_dir, \'train.triples\')) as f:\n        for line in f:\n            e1, e2, r = line.strip().split(\'\\t\')\n            e1_id = entity2id[e1]\n            r_id = relation2id[r]\n            seen_queries.add((e1_id, r_id))\n\n    seen_exps = []\n    unseen_exps = []\n    num_exps = 0\n    with open(os.path.join(data_dir, \'dev.triples\')) as f:\n        for line in f:\n            num_exps += 1\n            e1, e2, r = line.strip().split(\'\\t\')\n            e1_id = entity2id[e1]\n            r_id = relation2id[r]\n            if (e1_id, r_id) in seen_queries:\n                seen_exps.append(line)\n            else:\n                unseen_exps.append(line)\n    num_seen_exps = len(seen_exps) + 0.0\n    num_unseen_exps = len(unseen_exps) + 0.0\n    seen_ratio = num_seen_exps / num_exps\n    unseen_ratio = num_unseen_exps / num_exps\n    print(\'Seen examples: {}/{} {}\'.format(num_seen_exps, num_exps, seen_ratio))\n    print(\'Unseen examples: {}/{} {}\'.format(num_unseen_exps, num_exps, unseen_ratio))\n\n    return seen_queries, (seen_ratio, unseen_ratio)\n\ndef get_relations_by_type(data_dir, relation_index_path):\n    with open(os.path.join(data_dir, \'raw.kb\')) as f:\n        triples = list(f.readlines())\n    with open(os.path.join(data_dir, \'train.triples\')) as f:\n        triples += list(f.readlines())\n    triples = list(set(triples))\n\n    query_answers = dict()\n\n    theta_1_to_M = 1.5\n\n    for triple_str in triples:\n        e1, e2, r = triple_str.strip().split(\'\\t\')\n        if not r in query_answers:\n            query_answers[r] = dict()\n        if not e1 in query_answers[r]:\n            query_answers[r][e1] = set()\n        query_answers[r][e1].add(e2)\n\n    to_M_rels = set()\n    to_1_rels = set()\n\n    dev_rels = set()\n    with open(os.path.join(data_dir, \'dev.triples\')) as f:\n        for line in f:\n            e1, e2, r = line.strip().split(\'\\t\')\n            dev_rels.add(r)\n\n    relation2id, _ = load_index(relation_index_path)\n    num_rels = len(dev_rels)\n    print(\'{} relations in dev dataset in total\'.format(num_rels))\n    for r in dev_rels:\n        ratio = np.mean([len(x) for x in query_answers[r].values()])\n        if ratio > theta_1_to_M:\n            to_M_rels.add(relation2id[r])\n        else:\n            to_1_rels.add(relation2id[r])\n    num_to_M = len(to_M_rels) + 0.0\n    num_to_1 = len(to_1_rels) + 0.0\n\n    print(\'to-M relations: {}/{} ({})\'.format(num_to_M, num_rels, num_to_M / num_rels))\n    print(\'to-1 relations: {}/{} ({})\'.format(num_to_1, num_rels, num_to_1 / num_rels))\n\n    to_M_examples = []\n    to_1_examples = []\n    num_exps = 0\n    with open(os.path.join(data_dir, \'dev.triples\')) as f:\n        for line in f:\n            num_exps += 1\n            e1, e2, r = line.strip().split(\'\\t\')\n            if relation2id[r] in to_M_rels:\n                to_M_examples.append(line)\n            elif relation2id[r] in to_1_rels:\n                to_1_examples.append(line)\n    num_to_M_exps = len(to_M_examples) + 0.0\n    num_to_1_exps = len(to_1_examples) + 0.0\n    to_M_ratio = num_to_M_exps / num_exps\n    to_1_ratio = num_to_1_exps / num_exps\n    print(\'to-M examples: {}/{} ({})\'.format(num_to_M_exps, num_exps, to_M_ratio))\n    print(\'to-1 examples: {}/{} ({})\'.format(num_to_1_exps, num_exps, to_1_ratio))\n\n    return to_M_rels, to_1_rels, (to_M_ratio, to_1_ratio)\n\ndef load_configs(args, config_path):\n    with open(config_path) as f:\n        print(\'loading configuration file {}\'.format(config_path))\n        for line in f:\n            if not \'=\' in line:\n                continue\n            arg_name, arg_value = line.strip().split(\'=\')\n            if arg_value.startswith(\'""\') and arg_value.endswith(\'""\'):\n                arg_value = arg_value[1:-1]\n            if hasattr(args, arg_name):\n                print(\'{} = {}\'.format(arg_name, arg_value))\n                arg_value2 = getattr(args, arg_name)\n                if type(arg_value2) is str:\n                    setattr(args, arg_name, arg_value)\n                elif type(arg_value2) is bool:\n                    if arg_value == \'True\':\n                        setattr(args, arg_name, True)\n                    elif arg_value == \'False\':\n                        setattr(args, arg_name, False)\n                    else:\n                        raise ValueError(\'Unrecognized boolean value description: {}\'.format(arg_value))\n                elif type(arg_value2) is int:\n                    setattr(args, arg_name, int(arg_value))\n                elif type(arg_value2) is float:\n                    setattr(args, arg_name, float(arg_value))\n                else:\n                    raise ValueError(\'Unrecognized attribute type: {}: {}\'.format(arg_name, type(arg_value2)))\n            else:\n                raise ValueError(\'Unrecognized argument: {}\'.format(arg_name))\n    return args\n'"
src/eval.py,3,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Compute Evaluation Metrics.\n Code adapted from https://github.com/TimDettmers/ConvE/blob/master/evaluation.py\n""""""\n\nimport numpy as np\nimport pickle\n\nimport torch\n\nfrom src.parse_args import args\nfrom src.data_utils import NO_OP_ENTITY_ID, DUMMY_ENTITY_ID\n\n\ndef hits_and_ranks(examples, scores, all_answers, verbose=False):\n    """"""\n    Compute ranking based metrics.\n    """"""\n    assert (len(examples) == scores.shape[0])\n    # mask false negatives in the predictions\n    dummy_mask = [DUMMY_ENTITY_ID, NO_OP_ENTITY_ID]\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        e2_multi = dummy_mask + list(all_answers[e1][r]) \n        # save the relevant prediction\n        target_score = float(scores[i, e2])\n        # mask all false negatives\n        scores[i, e2_multi] = 0\n        # write back the save prediction\n        scores[i, e2] = target_score\n    \n    # sort and rank\n    top_k_scores, top_k_targets = torch.topk(scores, min(scores.size(1), args.beam_size))\n    top_k_targets = top_k_targets.cpu().numpy()\n\n    hits_at_1 = 0\n    hits_at_3 = 0\n    hits_at_5 = 0\n    hits_at_10 = 0\n    mrr = 0\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        pos = np.where(top_k_targets[i] == e2)[0]\n        if len(pos) > 0:\n            pos = pos[0]\n            if pos < 10:\n                hits_at_10 += 1\n                if pos < 5:\n                    hits_at_5 += 1\n                    if pos < 3:\n                        hits_at_3 += 1\n                        if pos < 1:\n                            hits_at_1 += 1\n            mrr += 1.0 / (pos + 1)\n\n    hits_at_1 = float(hits_at_1) / len(examples)\n    hits_at_3 = float(hits_at_3) / len(examples)\n    hits_at_5 = float(hits_at_5) / len(examples)\n    hits_at_10 = float(hits_at_10) / len(examples)\n    mrr = float(mrr) / len(examples)\n\n    if verbose:\n        print(\'Hits@1 = {:.3f}\'.format(hits_at_1))\n        print(\'Hits@3 = {:.3f}\'.format(hits_at_3))\n        print(\'Hits@5 = {:.3f}\'.format(hits_at_5))\n        print(\'Hits@10 = {:.3f}\'.format(hits_at_10))\n        print(\'MRR = {:.3f}\'.format(mrr))\n\n    return hits_at_1, hits_at_3, hits_at_5, hits_at_10, mrr\n\ndef hits_at_k(examples, scores, all_answers, verbose=False):\n    """"""\n    Hits at k metrics.\n    :param examples: List of triples and labels (+/-).\n    :param pred_targets:\n    :param scores:\n    :param all_answers:\n    :param verbose:\n    """"""\n    assert(len(examples) == scores.shape[0])\n    # mask false negatives in the predictions\n    dummy_mask = [DUMMY_ENTITY_ID, NO_OP_ENTITY_ID]\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        e2_multi = list(all_answers[e1][r]) + dummy_mask\n        # save the relevant prediction\n        target_score = scores[i, e2]\n        # mask all false negatives\n        scores[i][e2_multi] = 0\n        scores[i][dummy_mask] = 0\n        # write back the save prediction\n        scores[i][e2] = target_score\n        \n    # sort and rank\n    top_k_scores, top_k_targets = torch.topk(scores, min(scores.size(1), args.beam_size))\n    top_k_targets = top_k_targets.cpu().numpy()\n\n    hits_at_1 = 0\n    hits_at_3 = 0\n    hits_at_5 = 0\n    hits_at_10 = 0\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        pos = np.where(top_k_targets[i] == e2)[0]\n        if pos:\n            pos = pos[0]\n            if pos < 10:\n                hits_at_10 += 1\n                if pos < 5:\n                    hits_at_5 += 1\n                    if pos < 3:\n                        hits_at_3 += 1\n                        if pos < 1:\n                            hits_at_1 += 1\n\n    hits_at_1 = float(hits_at_1) / len(examples)\n    hits_at_3 = float(hits_at_3) / len(examples)\n    hits_at_5 = float(hits_at_5) / len(examples)\n    hits_at_10 = float(hits_at_10) / len(examples)\n\n    if verbose:\n        print(\'Hits@1 = {:.3f}\'.format(hits_at_1))\n        print(\'Hits@3 = {:.3f}\'.format(hits_at_3))\n        print(\'Hits@5 = {:.3f}\'.format(hits_at_5))\n        print(\'Hits@10 = {:.3f}\'.format(hits_at_10))\n\n    return hits_at_1, hits_at_3, hits_at_5, hits_at_10\n\ndef hits_and_ranks_by_seen_queries(examples, scores, all_answers, seen_queries, verbose=False):\n    seen_exps, unseen_exps = [], []\n    seen_ids, unseen_ids = [], []\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        if (e1, r) in seen_queries:\n            seen_exps.append(example)\n            seen_ids.append(i)\n        else:\n            unseen_exps.append(example)\n            unseen_ids.append(i)\n\n    _, _, _, _, seen_mrr = hits_and_ranks(seen_exps, scores[seen_ids], all_answers, verbose=False)\n    _, _, _, _, unseen_mrr = hits_and_ranks(unseen_exps, scores[unseen_ids], all_answers, verbose=False)\n    if verbose:\n        print(\'MRR on seen queries: {:.3f}\'.format(seen_mrr))\n        print(\'MRR on unseen queries: {:.3f}\'.format(unseen_mrr))\n    return seen_mrr, unseen_mrr\n\ndef hits_and_ranks_by_relation_type(examples, scores, all_answers, relation_by_types, verbose=False):\n    to_M_rels, to_1_rels = relation_by_types\n    to_M_exps, to_1_exps = [], []\n    to_M_ids, to_1_ids = [], []\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        if r in to_M_rels:\n            to_M_exps.append(example)\n            to_M_ids.append(i)\n        else:\n            to_1_exps.append(example)\n            to_1_ids.append(i)\n\n    _, _, _, _, to_m_mrr = hits_and_ranks(to_M_exps, scores[to_M_ids], all_answers, verbose=False)\n    _, _, _, _, to_1_mrr = hits_and_ranks(to_1_exps, scores[to_1_ids], all_answers, verbose=False)\n    if verbose:\n        print(\'MRR on to-M relations: {:.3f}\'.format(to_m_mrr))\n        print(\'MRR on to-1 relations: {:.3f}\'.format(to_1_mrr))\n    return to_m_mrr, to_1_mrr\n\ndef link_MAP(examples, scores, labels, all_answers, verbose=False):\n    """"""\n    Per-query mean average precision.\n    """"""\n    assert (len(examples) == len(scores))\n    queries = {}\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        if not e1 in queries:\n            queries[e1] = []\n        queries[e1].append((examples[i], labels[i], scores[i][e2]))\n\n    aps = []\n    dummy_mask = [DUMMY_ENTITY_ID, NO_OP_ENTITY_ID]\n\n    for e1 in queries:\n        ranked_examples = sorted(queries[e1], key=lambda x:x[2], reverse=True)\n        acc_precision, offset, num_pos = 0, 0, 0\n        for i in range(len(ranked_examples)):\n            triple, label, score = ranked_examples[i]\n            _, r, e2 = triple\n            if label == \'+\':\n                num_pos += 1\n                acc_precision += float(num_pos) / (i + 1 - offset)\n            else:\n                answer_set = {}\n                if e1 in all_answers and r in all_answers[e1]:\n                    answer_set = all_answers[e1][r]\n                if e2 in answer_set or e2 in dummy_mask:\n                    print(\'False negative found: {}\'.format(triple))\n                    offset += 1 \n        if num_pos > 0:\n            ap = acc_precision / num_pos\n            aps.append(ap)\n    map = np.mean(aps)\n    if verbose:\n        print(\'MAP = {:.3f}\'.format(map))\n    return map\n\ndef export_error_cases(examples, scores, all_answers, output_path):\n    """"""\n    Export indices of examples to which the top-1 prediction is incorrect.\n    """"""\n    assert (len(examples) == scores.shape[0])\n    # mask false negatives in the predictions\n    dummy_mask = [DUMMY_ENTITY_ID, NO_OP_ENTITY_ID]\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        e2_multi = dummy_mask + list(all_answers[e1][r])\n        # save the relevant prediction\n        target_score = float(scores[i, e2])\n        # mask all false negatives\n        scores[i, e2_multi] = 0\n        # write back the save prediction\n        scores[i, e2] = target_score\n\n    # sort and rank\n    top_k_scores, top_k_targets = torch.topk(scores, min(scores.size(1), args.beam_size))\n    top_k_targets = top_k_targets.cpu().numpy()\n\n    top_1_errors, top_10_errors = [], []\n    for i, example in enumerate(examples):\n        e1, e2, r = example\n        pos = np.where(top_k_targets[i] == e2)[0]\n        if len(pos) <= 0 or pos[0] > 0:\n            top_1_errors.append(i)\n        if len(pos) <= 0 or pos[0] > 9:\n            top_10_errors.append(i)\n    with open(output_path, \'wb\') as o_f:\n        pickle.dump([top_1_errors, top_10_errors], o_f)        \n                 \n    print(\'{}/{} top-1 error cases written to {}\'.format(len(top_1_errors), len(examples), output_path))\n    print(\'{}/{} top-10 error cases written to {}\'.format(len(top_10_errors), len(examples), output_path))\n\n'"
src/experiments.py,11,"b'#!/usr/bin/env python3\n\n""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Experiment Portal.\n""""""\n\nimport copy\nimport itertools\nimport numpy as np\nimport os, sys\nimport random\n\nimport torch\n\nfrom src.parse_args import parser\nfrom src.parse_args import args\nimport src.data_utils as data_utils\nimport src.eval\nfrom src.hyperparameter_range import hp_range\nfrom src.knowledge_graph import KnowledgeGraph\nfrom src.emb.fact_network import ComplEx, ConvE, DistMult\nfrom src.emb.fact_network import get_conve_kg_state_dict, get_complex_kg_state_dict, get_distmult_kg_state_dict\nfrom src.emb.emb import EmbeddingBasedMethod\nfrom src.rl.graph_search.pn import GraphSearchPolicy\nfrom src.rl.graph_search.pg import PolicyGradient\nfrom src.rl.graph_search.rs_pg import RewardShapingPolicyGradient\nfrom src.utils.ops import flatten\n\ntorch.cuda.set_device(args.gpu)\n\ntorch.manual_seed(args.seed)\ntorch.cuda.manual_seed_all(args.seed)\n\ndef process_data():\n    data_dir = args.data_dir\n    raw_kb_path = os.path.join(data_dir, \'raw.kb\')\n    train_path = data_utils.get_train_path(args)\n    dev_path = os.path.join(data_dir, \'dev.triples\')\n    test_path = os.path.join(data_dir, \'test.triples\')\n    data_utils.prepare_kb_envrioment(raw_kb_path, train_path, dev_path, test_path, args.test, args.add_reverse_relations)\n\ndef initialize_model_directory(args, random_seed=None):\n    # add model parameter info to model directory\n    model_root_dir = args.model_root_dir\n    dataset = os.path.basename(os.path.normpath(args.data_dir))\n\n    reverse_edge_tag = \'-RV\' if args.add_reversed_training_edges else \'\'\n    entire_graph_tag = \'-EG\' if args.train_entire_graph else \'\'\n    if args.xavier_initialization:\n        initialization_tag = \'-xavier\'\n    elif args.uniform_entity_initialization:\n        initialization_tag = \'-uniform\'\n    else:\n        initialization_tag = \'\'\n\n    # Hyperparameter signature\n    if args.model in [\'rule\']:\n        hyperparam_sig = \'{}-{}-{}-{}-{}-{}-{}-{}-{}-{}\'.format(\n            args.baseline,\n            args.entity_dim,\n            args.relation_dim,\n            args.history_num_layers,\n            args.learning_rate,\n            args.emb_dropout_rate,\n            args.ff_dropout_rate,\n            args.action_dropout_rate,\n            args.bandwidth,\n            args.beta\n        )\n    elif args.model.startswith(\'point\'):\n        if args.baseline == \'avg_reward\':\n            print(\'* Policy Gradient Baseline: average reward\')\n        elif args.baseline == \'avg_reward_normalized\':\n            print(\'* Policy Gradient Baseline: average reward baseline plus normalization\')\n        else:\n            print(\'* Policy Gradient Baseline: None\')\n        if args.action_dropout_anneal_interval < 1000:\n            hyperparam_sig = \'{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}-{}\'.format(\n                args.baseline,\n                args.entity_dim,\n                args.relation_dim,\n                args.history_num_layers,\n                args.learning_rate,\n                args.emb_dropout_rate,\n                args.ff_dropout_rate,\n                args.action_dropout_rate,\n                args.action_dropout_anneal_factor,\n                args.action_dropout_anneal_interval,\n                args.bandwidth,\n                args.beta\n            )\n            if args.mu != 1.0:\n                hyperparam_sig += \'-{}\'.format(args.mu)\n        else:\n            hyperparam_sig = \'{}-{}-{}-{}-{}-{}-{}-{}-{}-{}\'.format(\n                args.baseline,\n                args.entity_dim,\n                args.relation_dim,\n                args.history_num_layers,\n                args.learning_rate,\n                args.emb_dropout_rate,\n                args.ff_dropout_rate,\n                args.action_dropout_rate,\n                args.bandwidth,\n                args.beta\n            )\n        if args.reward_shaping_threshold > 0:\n            hyperparam_sig += \'-{}\'.format(args.reward_shaping_threshold)\n    elif args.model == \'distmult\':\n        hyperparam_sig = \'{}-{}-{}-{}-{}\'.format(\n            args.entity_dim,\n            args.relation_dim,\n            args.learning_rate,\n            args.emb_dropout_rate,\n            args.label_smoothing_epsilon\n        )\n    elif args.model == \'complex\':\n        hyperparam_sig = \'{}-{}-{}-{}-{}\'.format(\n            args.entity_dim,\n            args.relation_dim,\n            args.learning_rate,\n            args.emb_dropout_rate,\n            args.label_smoothing_epsilon\n        )\n    elif args.model in [\'conve\', \'hypere\', \'triplee\']:\n        hyperparam_sig = \'{}-{}-{}-{}-{}-{}-{}-{}-{}\'.format(\n            args.entity_dim,\n            args.relation_dim,\n            args.learning_rate,\n            args.num_out_channels,\n            args.kernel_size,\n            args.emb_dropout_rate,\n            args.hidden_dropout_rate,\n            args.feat_dropout_rate,\n            args.label_smoothing_epsilon\n        )\n    else:\n        raise NotImplementedError\n\n    model_sub_dir = \'{}-{}{}{}{}-{}\'.format(\n        dataset,\n        args.model,\n        reverse_edge_tag,\n        entire_graph_tag,\n        initialization_tag,\n        hyperparam_sig\n    )\n    if args.model == \'set\':\n        model_sub_dir += \'-{}\'.format(args.beam_size)\n        model_sub_dir += \'-{}\'.format(args.num_paths_per_entity)\n    if args.relation_only:\n        model_sub_dir += \'-ro\'\n    elif args.relation_only_in_path:\n        model_sub_dir += \'-rpo\'\n    elif args.type_only:\n        model_sub_dir += \'-to\'\n\n    if args.test:\n        model_sub_dir += \'-test\'\n\n    if random_seed:\n        model_sub_dir += \'.{}\'.format(random_seed)\n\n    model_dir = os.path.join(model_root_dir, model_sub_dir)\n\n    if not os.path.exists(model_dir):\n        os.makedirs(model_dir)\n        print(\'Model directory created: {}\'.format(model_dir))\n    else:\n        print(\'Model directory exists: {}\'.format(model_dir))\n\n    args.model_dir = model_dir\n\ndef construct_model(args):\n    """"""\n    Construct NN graph.\n    """"""\n    kg = KnowledgeGraph(args)\n    if args.model.endswith(\'.gc\'):\n        kg.load_fuzzy_facts()\n\n    if args.model in [\'point\', \'point.gc\']:\n        pn = GraphSearchPolicy(args)\n        lf = PolicyGradient(args, kg, pn)\n    elif args.model.startswith(\'point.rs\'):\n        pn = GraphSearchPolicy(args)\n        fn_model = args.model.split(\'.\')[2]\n        fn_args = copy.deepcopy(args)\n        fn_args.model = fn_model\n        fn_args.relation_only = False\n        if fn_model == \'complex\':\n            fn = ComplEx(fn_args)\n            fn_kg = KnowledgeGraph(fn_args)\n        elif fn_model == \'distmult\':\n            fn = DistMult(fn_args)\n            fn_kg = KnowledgeGraph(fn_args)\n        elif fn_model == \'conve\':\n            fn = ConvE(fn_args, kg.num_entities)\n            fn_kg = KnowledgeGraph(fn_args)\n        lf = RewardShapingPolicyGradient(args, kg, pn, fn_kg, fn)\n    elif args.model == \'complex\':\n        fn = ComplEx(args)\n        lf = EmbeddingBasedMethod(args, kg, fn)\n    elif args.model == \'distmult\':\n        fn = DistMult(args)\n        lf = EmbeddingBasedMethod(args, kg, fn)\n    elif args.model == \'conve\':\n        fn = ConvE(args, kg.num_entities)\n        lf = EmbeddingBasedMethod(args, kg, fn)\n    else:\n        raise NotImplementedError\n    return lf\n\ndef train(lf):\n    train_path = data_utils.get_train_path(args)\n    dev_path = os.path.join(args.data_dir, \'dev.triples\')\n    entity_index_path = os.path.join(args.data_dir, \'entity2id.txt\')\n    relation_index_path = os.path.join(args.data_dir, \'relation2id.txt\')\n    train_data = data_utils.load_triples(\n        train_path, entity_index_path, relation_index_path, group_examples_by_query=args.group_examples_by_query,\n        add_reverse_relations=args.add_reversed_training_edges)\n    if \'NELL\' in args.data_dir:\n        adj_list_path = os.path.join(args.data_dir, \'adj_list.pkl\')\n        seen_entities = data_utils.load_seen_entities(adj_list_path, entity_index_path)\n    else:\n        seen_entities = set()\n    dev_data = data_utils.load_triples(dev_path, entity_index_path, relation_index_path, seen_entities=seen_entities)\n    if args.checkpoint_path is not None:\n        lf.load_checkpoint(args.checkpoint_path)\n    lf.run_train(train_data, dev_data)\n\ndef inference(lf):\n    lf.batch_size = args.dev_batch_size\n    lf.eval()\n    if args.model == \'hypere\':\n        conve_kg_state_dict = get_conve_kg_state_dict(torch.load(args.conve_state_dict_path))\n        lf.kg.load_state_dict(conve_kg_state_dict)\n        secondary_kg_state_dict = get_complex_kg_state_dict(torch.load(args.complex_state_dict_path))\n        lf.secondary_kg.load_state_dict(secondary_kg_state_dict)\n    elif args.model == \'triplee\':\n        conve_kg_state_dict = get_conve_kg_state_dict(torch.load(args.conve_state_dict_path))\n        lf.kg.load_state_dict(conve_kg_state_dict)\n        complex_kg_state_dict = get_complex_kg_state_dict(torch.load(args.complex_state_dict_path))\n        lf.secondary_kg.load_state_dict(complex_kg_state_dict)\n        distmult_kg_state_dict = get_distmult_kg_state_dict(torch.load(args.distmult_state_dict_path))\n        lf.tertiary_kg.load_state_dict(distmult_kg_state_dict)\n    else:\n        lf.load_checkpoint(get_checkpoint_path(args))\n    entity_index_path = os.path.join(args.data_dir, \'entity2id.txt\')\n    relation_index_path = os.path.join(args.data_dir, \'relation2id.txt\')\n    if \'NELL\' in args.data_dir:\n        adj_list_path = os.path.join(args.data_dir, \'adj_list.pkl\')\n        seen_entities = data_utils.load_seen_entities(adj_list_path, entity_index_path)\n    else:\n        seen_entities = set()\n\n    eval_metrics = {\n        \'dev\': {},\n        \'test\': {}\n    }\n\n    if args.compute_map:\n        relation_sets = [\n            \'concept:athletehomestadium\',\n            \'concept:athleteplaysforteam\',\n            \'concept:athleteplaysinleague\',\n            \'concept:athleteplayssport\',\n            \'concept:organizationheadquarteredincity\',\n            \'concept:organizationhiredperson\',\n            \'concept:personborninlocation\',\n            \'concept:teamplayssport\',\n            \'concept:worksfor\'\n        ]\n        mps = []\n        for r in relation_sets:\n            print(\'* relation: {}\'.format(r))\n            test_path = os.path.join(args.data_dir, \'tasks\', r, \'test.pairs\')\n            test_data, labels = data_utils.load_triples_with_label(\n                test_path, r, entity_index_path, relation_index_path, seen_entities=seen_entities)\n            pred_scores = lf.forward(test_data, verbose=False)\n            mp = src.eval.link_MAP(test_data, pred_scores, labels, lf.kg.all_objects, verbose=True)\n            mps.append(mp)\n        map_ = np.mean(mps)\n        print(\'Overall MAP = {}\'.format(map_))\n        eval_metrics[\'test\'][\'avg_map\'] = map\n    elif args.eval_by_relation_type:\n        dev_path = os.path.join(args.data_dir, \'dev.triples\')\n        dev_data = data_utils.load_triples(dev_path, entity_index_path, relation_index_path, seen_entities=seen_entities)\n        pred_scores = lf.forward(dev_data, verbose=False)\n        to_m_rels, to_1_rels, _ = data_utils.get_relations_by_type(args.data_dir, relation_index_path)\n        relation_by_types = (to_m_rels, to_1_rels)\n        print(\'Dev set evaluation by relation type (partial graph)\')\n        src.eval.hits_and_ranks_by_relation_type(\n            dev_data, pred_scores, lf.kg.dev_objects, relation_by_types, verbose=True)\n        print(\'Dev set evaluation by relation type (full graph)\')\n        src.eval.hits_and_ranks_by_relation_type(\n            dev_data, pred_scores, lf.kg.all_objects, relation_by_types, verbose=True)\n    elif args.eval_by_seen_queries:\n        dev_path = os.path.join(args.data_dir, \'dev.triples\')\n        dev_data = data_utils.load_triples(dev_path, entity_index_path, relation_index_path, seen_entities=seen_entities)\n        pred_scores = lf.forward(dev_data, verbose=False)\n        seen_queries = data_utils.get_seen_queries(args.data_dir, entity_index_path, relation_index_path)\n        print(\'Dev set evaluation by seen queries (partial graph)\')\n        src.eval.hits_and_ranks_by_seen_queries(\n            dev_data, pred_scores, lf.kg.dev_objects, seen_queries, verbose=True)\n        print(\'Dev set evaluation by seen queries (full graph)\')\n        src.eval.hits_and_ranks_by_seen_queries(\n            dev_data, pred_scores, lf.kg.all_objects, seen_queries, verbose=True)\n    else:\n        dev_path = os.path.join(args.data_dir, \'dev.triples\')\n        test_path = os.path.join(args.data_dir, \'test.triples\')\n        dev_data = data_utils.load_triples(\n            dev_path, entity_index_path, relation_index_path, seen_entities=seen_entities, verbose=False)\n        test_data = data_utils.load_triples(\n            test_path, entity_index_path, relation_index_path, seen_entities=seen_entities, verbose=False)\n        print(\'Dev set performance:\')\n        pred_scores = lf.forward(dev_data, verbose=args.save_beam_search_paths)\n        dev_metrics = src.eval.hits_and_ranks(dev_data, pred_scores, lf.kg.dev_objects, verbose=True)\n        eval_metrics[\'dev\'] = {}\n        eval_metrics[\'dev\'][\'hits_at_1\'] = dev_metrics[0]\n        eval_metrics[\'dev\'][\'hits_at_3\'] = dev_metrics[1]\n        eval_metrics[\'dev\'][\'hits_at_5\'] = dev_metrics[2]\n        eval_metrics[\'dev\'][\'hits_at_10\'] = dev_metrics[3]\n        eval_metrics[\'dev\'][\'mrr\'] = dev_metrics[4]\n        src.eval.hits_and_ranks(dev_data, pred_scores, lf.kg.all_objects, verbose=True)\n        print(\'Test set performance:\')\n        pred_scores = lf.forward(test_data, verbose=False)\n        test_metrics = src.eval.hits_and_ranks(test_data, pred_scores, lf.kg.all_objects, verbose=True)\n        eval_metrics[\'test\'][\'hits_at_1\'] = test_metrics[0]\n        eval_metrics[\'test\'][\'hits_at_3\'] = test_metrics[1]\n        eval_metrics[\'test\'][\'hits_at_5\'] = test_metrics[2]\n        eval_metrics[\'test\'][\'hits_at_10\'] = test_metrics[3]\n        eval_metrics[\'test\'][\'mrr\'] = test_metrics[4]\n\n    return eval_metrics\n\ndef run_ablation_studies(args):\n    """"""\n    Run the ablation study experiments reported in the paper.\n    """"""\n    def set_up_lf_for_inference(args):\n        initialize_model_directory(args)\n        lf = construct_model(args)\n        lf.cuda()\n        lf.batch_size = args.dev_batch_size\n        lf.load_checkpoint(get_checkpoint_path(args))\n        lf.eval()\n        return lf\n\n    def rel_change(metrics, ab_system, kg_portion):\n        ab_system_metrics = metrics[ab_system][kg_portion]\n        base_metrics = metrics[\'ours\'][kg_portion]\n        return int(np.round((ab_system_metrics - base_metrics) / base_metrics * 100))\n\n    entity_index_path = os.path.join(args.data_dir, \'entity2id.txt\')\n    relation_index_path = os.path.join(args.data_dir, \'relation2id.txt\')\n    if \'NELL\' in args.data_dir:\n        adj_list_path = os.path.join(args.data_dir, \'adj_list.pkl\')\n        seen_entities = data_utils.load_seen_entities(adj_list_path, entity_index_path)\n    else:\n        seen_entities = set()\n    dataset = os.path.basename(args.data_dir)\n    dev_path = os.path.join(args.data_dir, \'dev.triples\')\n    dev_data = data_utils.load_triples(\n        dev_path, entity_index_path, relation_index_path, seen_entities=seen_entities, verbose=False)\n    to_m_rels, to_1_rels, (to_m_ratio, to_1_ratio) = data_utils.get_relations_by_type(args.data_dir, relation_index_path)\n    relation_by_types = (to_m_rels, to_1_rels)\n    to_m_ratio *= 100\n    to_1_ratio *= 100\n    seen_queries, (seen_ratio, unseen_ratio) = data_utils.get_seen_queries(args.data_dir, entity_index_path, relation_index_path)\n    seen_ratio *= 100\n    unseen_ratio *= 100\n\n    systems = [\'ours\', \'-ad\', \'-rs\']\n    mrrs, to_m_mrrs, to_1_mrrs, seen_mrrs, unseen_mrrs = {}, {}, {}, {}, {}\n    for system in systems:\n        print(\'** Evaluating {} system **\'.format(system))\n        if system == \'-ad\':\n            args.action_dropout_rate = 0.0\n            if dataset == \'umls\':\n                # adjust dropout hyperparameters\n                args.emb_dropout_rate = 0.3\n                args.ff_dropout_rate = 0.1\n        elif system == \'-rs\':\n            config_path = os.path.join(\'configs\', \'{}.sh\'.format(dataset.lower()))\n            args = parser.parse_args()\n            args = data_utils.load_configs(args, config_path)\n        \n        lf = set_up_lf_for_inference(args)\n        pred_scores = lf.forward(dev_data, verbose=False)\n        _, _, _, _, mrr = src.eval.hits_and_ranks(dev_data, pred_scores, lf.kg.dev_objects, verbose=True)\n        if to_1_ratio == 0:\n            to_m_mrr = mrr\n            to_1_mrr = -1\n        else:\n            to_m_mrr, to_1_mrr = src.eval.hits_and_ranks_by_relation_type(\n                dev_data, pred_scores, lf.kg.dev_objects, relation_by_types, verbose=True)\n        seen_mrr, unseen_mrr = src.eval.hits_and_ranks_by_seen_queries(\n            dev_data, pred_scores, lf.kg.dev_objects, seen_queries, verbose=True)\n        mrrs[system] = {\'\': mrr * 100}\n        to_m_mrrs[system] = {\'\': to_m_mrr * 100}\n        to_1_mrrs[system] = {\'\': to_1_mrr  * 100}\n        seen_mrrs[system] = {\'\': seen_mrr * 100}\n        unseen_mrrs[system] = {\'\': unseen_mrr * 100}\n        _, _, _, _, mrr_full_kg = src.eval.hits_and_ranks(dev_data, pred_scores, lf.kg.all_objects, verbose=True)\n        if to_1_ratio == 0:\n            to_m_mrr_full_kg = mrr_full_kg\n            to_1_mrr_full_kg = -1\n        else:\n            to_m_mrr_full_kg, to_1_mrr_full_kg = src.eval.hits_and_ranks_by_relation_type(\n                dev_data, pred_scores, lf.kg.all_objects, relation_by_types, verbose=True)\n        seen_mrr_full_kg, unseen_mrr_full_kg = src.eval.hits_and_ranks_by_seen_queries(\n            dev_data, pred_scores, lf.kg.all_objects, seen_queries, verbose=True)\n        mrrs[system][\'full_kg\'] = mrr_full_kg * 100\n        to_m_mrrs[system][\'full_kg\'] = to_m_mrr_full_kg * 100\n        to_1_mrrs[system][\'full_kg\'] = to_1_mrr_full_kg * 100\n        seen_mrrs[system][\'full_kg\'] = seen_mrr_full_kg * 100\n        unseen_mrrs[system][\'full_kg\'] = unseen_mrr_full_kg * 100\n\n    # overall system comparison (table 3)\n    print(\'Partial graph evaluation\')\n    print(\'--------------------------\')\n    print(\'Overall system performance\')\n    print(\'Ours(ConvE)\\t-RS\\t-AD\')\n    print(\'{:.1f}\\t{:.1f}\\t{:.1f}\'.format(mrrs[\'ours\'][\'\'], mrrs[\'-rs\'][\'\'], mrrs[\'-ad\'][\'\']))\n    print(\'--------------------------\')\n    # performance w.r.t. relation types (table 4, 6)\n    print(\'Performance w.r.t. relation types\')\n    print(\'\\tTo-many\\t\\t\\t\\tTo-one\\t\\t\')\n    print(\'%\\tOurs\\t-RS\\t-AD\\t%\\tOurs\\t-RS\\t-AD\')\n    print(\'{:.1f}\\t{:.1f}\\t{:.1f} ({:d})\\t{:.1f} ({:d})\\t{:.1f}\\t{:.1f}\\t{:.1f} ({:d})\\t{:.1f} ({:d})\'.format(\n        to_m_ratio, to_m_mrrs[\'ours\'][\'\'], to_m_mrrs[\'-rs\'][\'\'], rel_change(to_m_mrrs, \'-rs\', \'\'), to_m_mrrs[\'-ad\'][\'\'], rel_change(to_m_mrrs, \'-ad\', \'\'),\n        to_1_ratio, to_1_mrrs[\'ours\'][\'\'], to_1_mrrs[\'-rs\'][\'\'], rel_change(to_1_mrrs, \'-rs\', \'\'), to_1_mrrs[\'-ad\'][\'\'], rel_change(to_1_mrrs, \'-ad\', \'\')))\n    print(\'--------------------------\')\n    # performance w.r.t. seen queries (table 5, 7)\n    print(\'Performance w.r.t. seen/unseen queries\')\n    print(\'\\tSeen\\t\\t\\t\\tUnseen\\t\\t\')\n    print(\'%\\tOurs\\t-RS\\t-AD\\t%\\tOurs\\t-RS\\t-AD\')\n    print(\'{:.1f}\\t{:.1f}\\t{:.1f} ({:d})\\t{:.1f} ({:d})\\t{:.1f}\\t{:.1f}\\t{:.1f} ({:d})\\t{:.1f} ({:d})\'.format(\n        seen_ratio, seen_mrrs[\'ours\'][\'\'], seen_mrrs[\'-rs\'][\'\'], rel_change(seen_mrrs, \'-rs\', \'\'), seen_mrrs[\'-ad\'][\'\'], rel_change(seen_mrrs, \'-ad\', \'\'),\n        unseen_ratio, unseen_mrrs[\'ours\'][\'\'], unseen_mrrs[\'-rs\'][\'\'], rel_change(unseen_mrrs, \'-rs\', \'\'), unseen_mrrs[\'-ad\'][\'\'], rel_change(unseen_mrrs, \'-ad\', \'\')))\n    print()\n    print(\'Full graph evaluation\')\n    print(\'--------------------------\')\n    print(\'Overall system performance\')\n    print(\'Ours(ConvE)\\t-RS\\t-AD\')\n    print(\'{:.1f}\\t{:.1f}\\t{:.1f}\'.format(mrrs[\'ours\'][\'full_kg\'], mrrs[\'-rs\'][\'full_kg\'], mrrs[\'-ad\'][\'full_kg\']))\n    print(\'--------------------------\')\n    print(\'Performance w.r.t. relation types\')\n    print(\'\\tTo-many\\t\\t\\t\\tTo-one\\t\\t\')\n    print(\'%\\tOurs\\t-RS\\t-AD\\t%\\tOurs\\t-RS\\t-AD\')\n    print(\'{:.1f}\\t{:.1f}\\t{:.1f} ({:d})\\t{:.1f} ({:d})\\t{:.1f}\\t{:.1f}\\t{:.1f} ({:d})\\t{:.1f} ({:d})\'.format(\n        to_m_ratio, to_m_mrrs[\'ours\'][\'full_kg\'], to_m_mrrs[\'-rs\'][\'full_kg\'], rel_change(to_m_mrrs, \'-rs\', \'full_kg\'), to_m_mrrs[\'-ad\'][\'full_kg\'], rel_change(to_m_mrrs, \'-ad\', \'full_kg\'),\n        to_1_ratio, to_1_mrrs[\'ours\'][\'full_kg\'], to_1_mrrs[\'-rs\'][\'full_kg\'], rel_change(to_1_mrrs, \'-rs\', \'full_kg\'), to_1_mrrs[\'-ad\'][\'full_kg\'], rel_change(to_1_mrrs, \'-ad\', \'full_kg\')))\n    print(\'--------------------------\')\n    print(\'Performance w.r.t. seen/unseen queries\')\n    print(\'\\tSeen\\t\\t\\t\\tUnseen\\t\\t\')\n    print(\'%\\tOurs\\t-RS\\t-AD\\t%\\tOurs\\t-RS\\t-AD\')\n    print(\'{:.1f}\\t{:.1f}\\t{:.1f} ({:d})\\t{:.1f} ({:d})\\t{:.1f}\\t{:.1f}\\t{:.1f} ({:d})\\t{:.1f} ({:d})\'.format(\n        seen_ratio, seen_mrrs[\'ours\'][\'full_kg\'], seen_mrrs[\'-rs\'][\'full_kg\'], rel_change(seen_mrrs, \'-rs\', \'full_kg\'), seen_mrrs[\'-ad\'][\'full_kg\'], rel_change(seen_mrrs, \'-ad\', \'full_kg\'),\n        unseen_ratio, unseen_mrrs[\'ours\'][\'full_kg\'], unseen_mrrs[\'-rs\'][\'full_kg\'], rel_change(unseen_mrrs, \'-rs\', \'full_kg\'), unseen_mrrs[\'-ad\'][\'full_kg\'], rel_change(unseen_mrrs, \'-ad\', \'full_kg\')))\n\ndef export_to_embedding_projector(lf):\n    lf.load_checkpoint(get_checkpoint_path(args))\n    lf.export_to_embedding_projector()\n\ndef export_reward_shaping_parameters(lf):\n    lf.load_checkpoint(get_checkpoint_path(args))\n    lf.export_reward_shaping_parameters()\n\ndef export_fuzzy_facts(lf):\n    lf.load_checkpoint(get_checkpoint_path(args))\n    lf.export_fuzzy_facts()\n\ndef export_error_cases(lf):\n    lf.load_checkpoint(get_checkpoint_path(args))\n    lf.batch_size = args.dev_batch_size\n    lf.eval()\n    entity_index_path = os.path.join(args.data_dir, \'entity2id.txt\')\n    relation_index_path = os.path.join(args.data_dir, \'relation2id.txt\')\n    dev_path = os.path.join(args.data_dir, \'dev.triples\')\n    dev_data = data_utils.load_triples(dev_path, entity_index_path, relation_index_path)\n    lf.load_checkpoint(get_checkpoint_path(args))\n    print(\'Dev set performance:\')\n    pred_scores = lf.forward(dev_data, verbose=False)\n    src.eval.hits_and_ranks(dev_data, pred_scores, lf.kg.dev_objects, verbose=True)\n    src.eval.export_error_cases(dev_data, pred_scores, lf.kg.dev_objects, os.path.join(lf.model_dir, \'error_cases.pkl\'))\n\ndef compute_fact_scores(lf):\n    data_dir = args.data_dir\n    train_path = os.path.join(data_dir, \'train.triples\')\n    dev_path = os.path.join(data_dir, \'dev.triples\')\n    test_path = os.path.join(data_dir, \'test.triples\')\n    entity_index_path = os.path.join(args.data_dir, \'entity2id.txt\')\n    relation_index_path = os.path.join(args.data_dir, \'relation2id.txt\')\n    train_data = data_utils.load_triples(train_path, entity_index_path, relation_index_path)\n    dev_data = data_utils.load_triples(dev_path, entity_index_path, relation_index_path)\n    test_data = data_utils.load_triples(test_path, entity_index_path, relation_index_path)\n    lf.eval()\n    lf.load_checkpoint(get_checkpoint_path(args))\n    train_scores = lf.forward_fact(train_data)\n    dev_scores = lf.forward_fact(dev_data)\n    test_scores = lf.forward_fact(test_data)\n\n    print(\'Train set average fact score: {}\'.format(float(train_scores.mean())))\n    print(\'Dev set average fact score: {}\'.format(float(dev_scores.mean())))\n    print(\'Test set average fact score: {}\'.format(float(test_scores.mean())))\n\ndef get_checkpoint_path(args):\n    if not args.checkpoint_path:\n        return os.path.join(args.model_dir, \'model_best.tar\')\n    else:\n        return args.checkpoint_path\n\ndef load_configs(config_path):\n    with open(config_path) as f:\n        print(\'loading configuration file {}\'.format(config_path))\n        for line in f:\n            if not \'=\' in line:\n                continue\n            arg_name, arg_value = line.strip().split(\'=\')\n            if arg_value.startswith(\'""\') and arg_value.endswith(\'""\'):\n                arg_value = arg_value[1:-1]\n            if hasattr(args, arg_name):\n                print(\'{} = {}\'.format(arg_name, arg_value))\n                arg_value2 = getattr(args, arg_name)\n                if type(arg_value2) is str:\n                    setattr(args, arg_name, arg_value)\n                elif type(arg_value2) is bool:\n                    if arg_value == \'True\':\n                        setattr(args, arg_name, True)\n                    elif arg_value == \'False\':\n                        setattr(args, arg_name, False)\n                    else:\n                        raise ValueError(\'Unrecognized boolean value description: {}\'.format(arg_value))\n                elif type(arg_value2) is int:\n                    setattr(args, arg_name, int(arg_value))\n                elif type(arg_value2) is float:\n                    setattr(args, arg_name, float(arg_value))\n                else:\n                    raise ValueError(\'Unrecognized attribute type: {}: {}\'.format(arg_name, type(arg_value2)))\n            else:\n                raise ValueError(\'Unrecognized argument: {}\'.format(arg_name))\n    return args\n\ndef run_experiment(args):\n\n    if args.test:\n        if \'NELL\' in args.data_dir:\n            dataset = os.path.basename(args.data_dir)\n            args.distmult_state_dict_path = data_utils.change_to_test_model_path(dataset, args.distmult_state_dict_path)\n            args.complex_state_dict_path = data_utils.change_to_test_model_path(dataset, args.complex_state_dict_path)\n            args.conve_state_dict_path = data_utils.change_to_test_model_path(dataset, args.conve_state_dict_path)\n        args.data_dir += \'.test\'\n\n    if args.process_data:\n\n        # Process knowledge graph data\n\n        process_data()\n    else:\n        with torch.set_grad_enabled(args.train or args.search_random_seed or args.grid_search):\n            if args.search_random_seed:\n\n                # Search for best random seed\n\n                # search log file\n                task = os.path.basename(os.path.normpath(args.data_dir))\n                out_log = \'{}.{}.rss\'.format(task, args.model)\n                o_f = open(out_log, \'w\')\n\n                print(\'** Search Random Seed **\')\n                o_f.write(\'** Search Random Seed **\\n\')\n                o_f.close()\n                num_runs = 5\n\n                hits_at_1s = {}\n                hits_at_10s = {}\n                mrrs = {}\n                mrrs_search = {}\n                for i in range(num_runs):\n\n                    o_f = open(out_log, \'a\')\n\n                    random_seed = random.randint(0, 1e16)\n                    print(""\\nRandom seed = {}\\n"".format(random_seed))\n                    o_f.write(""\\nRandom seed = {}\\n\\n"".format(random_seed))\n                    torch.manual_seed(random_seed)\n                    torch.cuda.manual_seed_all(args, random_seed)\n                    initialize_model_directory(args, random_seed)\n                    lf = construct_model(args)\n                    lf.cuda()\n                    train(lf)\n                    metrics = inference(lf)\n                    hits_at_1s[random_seed] = metrics[\'test\'][\'hits_at_1\']\n                    hits_at_10s[random_seed] = metrics[\'test\'][\'hits_at_10\']\n                    mrrs[random_seed] = metrics[\'test\'][\'mrr\']\n                    mrrs_search[random_seed] = metrics[\'dev\'][\'mrr\']\n                    # print the results of the hyperparameter combinations searched so far\n                    print(\'------------------------------------------\')\n                    print(\'Random Seed\\t@1\\t@10\\tMRR\')\n                    for key in hits_at_1s:\n                        print(\'{}\\t{:.3f}\\t{:.3f}\\t{:.3f}\'.format(\n                            key, hits_at_1s[key], hits_at_10s[key], mrrs[key]))\n                    print(\'------------------------------------------\')\n                    o_f.write(\'------------------------------------------\\n\')\n                    o_f.write(\'Random Seed\\t@1\\t@10\\tMRR\\n\')\n                    for key in hits_at_1s:\n                        o_f.write(\'{}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\n\'.format(\n                            key, hits_at_1s[key], hits_at_10s[key], mrrs[key]))\n                    o_f.write(\'------------------------------------------\\n\')\n\n                    # compute result variance\n                    import numpy as np\n                    hits_at_1s_ = list(hits_at_1s.values())\n                    hits_at_10s_ = list(hits_at_10s.values())\n                    mrrs_ = list(mrrs.values())\n                    print(\'Hits@1 mean: {:.3f}\\tstd: {:.6f}\'.format(np.mean(hits_at_1s_), np.std(hits_at_1s_)))\n                    print(\'Hits@10 mean: {:.3f}\\tstd: {:.6f}\'.format(np.mean(hits_at_10s_), np.std(hits_at_10s_)))\n                    print(\'MRR mean: {:.3f}\\tstd: {:.6f}\'.format(np.mean(mrrs_), np.std(mrrs_)))\n                    o_f.write(\'Hits@1 mean: {:.3f}\\tstd: {:.6f}\\n\'.format(np.mean(hits_at_1s_), np.std(hits_at_1s_)))\n                    o_f.write(\'Hits@10 mean: {:.3f}\\tstd: {:.6f}\\n\'.format(np.mean(hits_at_10s_), np.std(hits_at_10s_)))\n                    o_f.write(\'MRR mean: {:.3f}\\tstd: {:.6f}\\n\'.format(np.mean(mrrs_), np.std(mrrs_)))\n                    o_f.close()\n                    \n                # find best random seed\n                best_random_seed, best_mrr = sorted(mrrs_search.items(), key=lambda x: x[1], reverse=True)[0]\n                print(\'* Best Random Seed = {}\'.format(best_random_seed))\n                print(\'* @1: {:.3f}\\t@10: {:.3f}\\tMRR: {:.3f}\'.format(\n                    hits_at_1s[best_random_seed],\n                    hits_at_10s[best_random_seed],\n                    mrrs[best_random_seed]))\n                with open(out_log, \'a\'):\n                    o_f.write(\'* Best Random Seed = {}\\n\'.format(best_random_seed))\n                    o_f.write(\'* @1: {:.3f}\\t@10: {:.3f}\\tMRR: {:.3f}\\n\'.format(\n                        hits_at_1s[best_random_seed],\n                        hits_at_10s[best_random_seed],\n                        mrrs[best_random_seed])\n                    )\n                    o_f.close()\n\n            elif args.grid_search:\n\n                # Grid search\n\n                # search log file\n                task = os.path.basename(os.path.normpath(args.data_dir))\n                out_log = \'{}.{}.gs\'.format(task, args.model)\n                o_f = open(out_log, \'w\')\n\n                print(""** Grid Search **"")\n                o_f.write(""** Grid Search **\\n"")\n                hyperparameters = args.tune.split(\',\')\n\n                if args.tune == \'\' or len(hyperparameters) < 1:\n                    print(""No hyperparameter specified."")\n                    sys.exit(0)\n\n                grid = hp_range[hyperparameters[0]]\n                for hp in hyperparameters[1:]:\n                    grid = itertools.product(grid, hp_range[hp])\n\n                hits_at_1s = {}\n                hits_at_10s = {}\n                mrrs = {}\n                grid = list(grid)\n                print(\'* {} hyperparameter combinations to try\'.format(len(grid)))\n                o_f.write(\'* {} hyperparameter combinations to try\\n\'.format(len(grid)))\n                o_f.close()\n\n                for i, grid_entry in enumerate(list(grid)):\n\n                    o_f = open(out_log, \'a\')\n\n                    if not (type(grid_entry) is list or type(grid_entry) is list):\n                        grid_entry = [grid_entry]\n                    grid_entry = flatten(grid_entry)\n                    print(\'* Hyperparameter Set {}:\'.format(i))\n                    o_f.write(\'* Hyperparameter Set {}:\\n\'.format(i))\n                    signature = \'\'\n                    for j in range(len(grid_entry)):\n                        hp = hyperparameters[j]\n                        value = grid_entry[j]\n                        if hp == \'bandwidth\':\n                            setattr(args, hp, int(value))\n                        else:\n                            setattr(args, hp, float(value))\n                        signature += \':{}\'.format(value)\n                        print(\'* {}: {}\'.format(hp, value))\n                    initialize_model_directory(args)\n                    lf = construct_model(args)\n                    lf.cuda()\n                    train(lf)\n                    metrics = inference(lf)\n                    hits_at_1s[signature] = metrics[\'dev\'][\'hits_at_1\']\n                    hits_at_10s[signature] = metrics[\'dev\'][\'hits_at_10\']\n                    mrrs[signature] = metrics[\'dev\'][\'mrr\']\n                    # print the results of the hyperparameter combinations searched so far\n                    print(\'------------------------------------------\')\n                    print(\'Signature\\t@1\\t@10\\tMRR\')\n                    for key in hits_at_1s:\n                        print(\'{}\\t{:.3f}\\t{:.3f}\\t{:.3f}\'.format(\n                            key, hits_at_1s[key], hits_at_10s[key], mrrs[key]))\n                    print(\'------------------------------------------\\n\')\n                    o_f.write(\'------------------------------------------\\n\')\n                    o_f.write(\'Signature\\t@1\\t@10\\tMRR\\n\')\n                    for key in hits_at_1s:\n                        o_f.write(\'{}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\n\'.format(\n                            key, hits_at_1s[key], hits_at_10s[key], mrrs[key]))\n                    o_f.write(\'------------------------------------------\\n\')\n                    # find best hyperparameter set\n                    best_signature, best_mrr = sorted(mrrs.items(), key=lambda x:x[1], reverse=True)[0]\n                    print(\'* best hyperparameter set\')\n                    o_f.write(\'* best hyperparameter set\\n\')\n                    best_hp_values = best_signature.split(\':\')[1:]\n                    for i, value in enumerate(best_hp_values):\n                        hp_name = hyperparameters[i]\n                        hp_value = best_hp_values[i]\n                        print(\'* {}: {}\'.format(hp_name, hp_value))\n                    print(\'* @1: {:.3f}\\t@10: {:.3f}\\tMRR: {:.3f}\'.format(\n                        hits_at_1s[best_signature],\n                        hits_at_10s[best_signature],\n                        mrrs[best_signature]\n                    ))\n                    o_f.write(\'* @1: {:.3f}\\t@10: {:.3f}\\tMRR: {:.3f}\\ns\'.format(\n                        hits_at_1s[best_signature],\n                        hits_at_10s[best_signature],\n                        mrrs[best_signature]\n                    ))\n\n                    o_f.close()\n\n            elif args.run_ablation_studies:\n                run_ablation_studies(args)\n            else:\n                initialize_model_directory(args)\n                lf = construct_model(args)\n                lf.cuda()\n\n                if args.train:\n                    train(lf)\n                elif args.inference:\n                    inference(lf)\n                elif args.eval_by_relation_type:\n                    inference(lf)\n                elif args.eval_by_seen_queries:\n                    inference(lf)\n                elif args.export_to_embedding_projector:\n                    export_to_embedding_projector(lf)\n                elif args.export_reward_shaping_parameters:\n                    export_reward_shaping_parameters(lf)\n                elif args.compute_fact_scores:\n                    compute_fact_scores(lf)\n                elif args.export_fuzzy_facts:\n                    export_fuzzy_facts(lf)\n                elif args.export_error_cases:\n                    export_error_cases(lf)\n\nif __name__ == \'__main__\':\n    run_experiment(args)\n'"
src/hyperparameter_range.py,0,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Hyperparameter range specification.\n""""""\n\nhp_range = {\n    ""beta"": [0., .01, .02, .05, .1],\n    ""emb_dropout_rate"": [0, .1, .2, .3],\n    ""ff_dropout_rate"": [0, .1, .2, .3],\n    ""action_dropout_rate"": [.95],\n    ""bandwidth"": [200, 256, 400, 512],\n    ""relation_only"": [True, False]\n}\n'"
src/knowledge_graph.py,7,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Knowledge Graph Environment.\n""""""\n\nimport collections\nimport os\nimport pickle\n\nimport torch\nimport torch.nn as nn\n\nfrom src.data_utils import load_index\nfrom src.data_utils import NO_OP_ENTITY_ID, NO_OP_RELATION_ID\nfrom src.data_utils import DUMMY_ENTITY_ID, DUMMY_RELATION_ID\nfrom src.data_utils import START_RELATION_ID\nimport src.utils.ops as ops\nfrom src.utils.ops import int_var_cuda, var_cuda\n\n\nclass KnowledgeGraph(nn.Module):\n    """"""\n    The discrete knowledge graph is stored with an adjacency list.\n    """"""\n    def __init__(self, args):\n        super(KnowledgeGraph, self).__init__()\n        self.entity2id, self.id2entity = {}, {}\n        self.relation2id, self.id2relation = {}, {}\n        self.type2id, self.id2type = {}, {}\n        self.entity2typeid = {}\n        self.adj_list = None\n        self.bandwidth = args.bandwidth\n        self.args = args\n\n        self.action_space = None\n        self.action_space_buckets = None\n        self.unique_r_space = None\n\n        self.train_subjects = None\n        self.train_objects = None\n        self.dev_subjects = None\n        self.dev_objects = None\n        self.all_subjects = None\n        self.all_objects = None\n        self.train_subject_vectors = None\n        self.train_object_vectors = None\n        self.dev_subject_vectors = None\n        self.dev_object_vectors = None\n        self.all_subject_vectors = None\n        self.all_object_vectors = None\n\n        print(\'** Create {} knowledge graph **\'.format(args.model))\n        self.load_graph_data(args.data_dir)\n        self.load_all_answers(args.data_dir)\n\n        # Define NN Modules\n        self.entity_dim = args.entity_dim\n        self.relation_dim = args.relation_dim\n        self.emb_dropout_rate = args.emb_dropout_rate\n        self.num_graph_convolution_layers = args.num_graph_convolution_layers\n        self.entity_embeddings = None\n        self.relation_embeddings = None\n        self.entity_img_embeddings = None\n        self.relation_img_embeddings = None\n        self.EDropout = None\n        self.RDropout = None\n        \n        self.define_modules()\n        self.initialize_modules()\n\n    def load_graph_data(self, data_dir):\n        # Load indices\n        self.entity2id, self.id2entity = load_index(os.path.join(data_dir, \'entity2id.txt\'))\n        print(\'Sanity check: {} entities loaded\'.format(len(self.entity2id)))\n        self.type2id, self.id2type = load_index(os.path.join(data_dir, \'type2id.txt\'))\n        print(\'Sanity check: {} types loaded\'.format(len(self.type2id)))\n        with open(os.path.join(data_dir, \'entity2typeid.pkl\'), \'rb\') as f:\n            self.entity2typeid = pickle.load(f)\n        self.relation2id, self.id2relation = load_index(os.path.join(data_dir, \'relation2id.txt\'))\n        print(\'Sanity check: {} relations loaded\'.format(len(self.relation2id)))\n       \n        # Load graph structures\n        if self.args.model.startswith(\'point\'): \n            # Base graph structure used for training and test\n            adj_list_path = os.path.join(data_dir, \'adj_list.pkl\')\n            with open(adj_list_path, \'rb\') as f:\n                self.adj_list = pickle.load(f)\n            self.vectorize_action_space(data_dir)\n\n    def vectorize_action_space(self, data_dir):\n        """"""\n        Pre-process and numericalize the knowledge graph structure.\n        """"""\n        def load_page_rank_scores(input_path):\n            pgrk_scores = collections.defaultdict(float)\n            with open(input_path) as f:\n                for line in f:\n                    e, score = line.strip().split(\':\')\n                    e_id = self.entity2id[e.strip()]\n                    score = float(score)\n                    pgrk_scores[e_id] = score\n            return pgrk_scores\n                    \n        # Sanity check\n        num_facts = 0\n        out_degrees = collections.defaultdict(int)\n        for e1 in self.adj_list:\n            for r in self.adj_list[e1]:\n                num_facts += len(self.adj_list[e1][r])\n                out_degrees[e1] += len(self.adj_list[e1][r])\n        print(""Sanity check: maximum out degree: {}"".format(max(out_degrees.values())))\n        print(\'Sanity check: {} facts in knowledge graph\'.format(num_facts))\n\n        # load page rank scores\n        page_rank_scores = load_page_rank_scores(os.path.join(data_dir, \'raw.pgrk\'))\n        \n        def get_action_space(e1):\n            action_space = []\n            if e1 in self.adj_list:\n                for r in self.adj_list[e1]:\n                    targets = self.adj_list[e1][r]\n                    for e2 in targets:\n                        action_space.append((r, e2))\n                if len(action_space) + 1 >= self.bandwidth:\n                    # Base graph pruning\n                    sorted_action_space = \\\n                        sorted(action_space, key=lambda x: page_rank_scores[x[1]], reverse=True)\n                    action_space = sorted_action_space[:self.bandwidth]\n            action_space.insert(0, (NO_OP_RELATION_ID, e1))\n            return action_space\n\n        def get_unique_r_space(e1):\n            if e1 in self.adj_list:\n                return list(self.adj_list[e1].keys())\n            else:\n                return []\n\n        def vectorize_action_space(action_space_list, action_space_size):\n            bucket_size = len(action_space_list)\n            r_space = torch.zeros(bucket_size, action_space_size) + self.dummy_r\n            e_space = torch.zeros(bucket_size, action_space_size) + self.dummy_e\n            action_mask = torch.zeros(bucket_size, action_space_size)\n            for i, action_space in enumerate(action_space_list):\n                for j, (r, e) in enumerate(action_space):\n                    r_space[i, j] = r\n                    e_space[i, j] = e\n                    action_mask[i, j] = 1\n            return (int_var_cuda(r_space), int_var_cuda(e_space)), var_cuda(action_mask)\n\n        def vectorize_unique_r_space(unique_r_space_list, unique_r_space_size, volatile):\n            bucket_size = len(unique_r_space_list)\n            unique_r_space = torch.zeros(bucket_size, unique_r_space_size) + self.dummy_r\n            for i, u_r_s in enumerate(unique_r_space_list):\n                for j, r in enumerate(u_r_s):\n                    unique_r_space[i, j] = r\n            return int_var_cuda(unique_r_space)\n\n        if self.args.use_action_space_bucketing:\n            """"""\n            Store action spaces in buckets.\n            """"""\n            self.action_space_buckets = {}\n            action_space_buckets_discrete = collections.defaultdict(list)\n            self.entity2bucketid = torch.zeros(self.num_entities, 2).long()\n            num_facts_saved_in_action_table = 0\n            for e1 in range(self.num_entities):\n                action_space = get_action_space(e1)\n                key = int(len(action_space) / self.args.bucket_interval) + 1\n                self.entity2bucketid[e1, 0] = key\n                self.entity2bucketid[e1, 1] = len(action_space_buckets_discrete[key])\n                action_space_buckets_discrete[key].append(action_space)\n                num_facts_saved_in_action_table += len(action_space)\n            print(\'Sanity check: {} facts saved in action table\'.format(\n                num_facts_saved_in_action_table - self.num_entities))\n            for key in action_space_buckets_discrete:\n                print(\'Vectorizing action spaces bucket {}...\'.format(key))\n                self.action_space_buckets[key] = vectorize_action_space(\n                    action_space_buckets_discrete[key], key * self.args.bucket_interval)\n        else:\n            action_space_list = []\n            max_num_actions = 0\n            for e1 in range(self.num_entities):\n                action_space = get_action_space(e1)\n                action_space_list.append(action_space)\n                if len(action_space) > max_num_actions:\n                    max_num_actions = len(action_space)\n            print(\'Vectorizing action spaces...\')\n            self.action_space = vectorize_action_space(action_space_list, max_num_actions)\n            \n            if self.args.model.startswith(\'rule\'):\n                unique_r_space_list = []\n                max_num_unique_rs = 0\n                for e1 in sorted(self.adj_list.keys()):\n                    unique_r_space = get_unique_r_space(e1)\n                    unique_r_space_list.append(unique_r_space)\n                    if len(unique_r_space) > max_num_unique_rs:\n                        max_num_unique_rs = len(unique_r_space)\n                self.unique_r_space = vectorize_unique_r_space(unique_r_space_list, max_num_unique_rs)\n\n    def load_all_answers(self, data_dir, add_reversed_edges=False):\n        def add_subject(e1, e2, r, d):\n            if not e2 in d:\n                d[e2] = {}\n            if not r in d[e2]:\n                d[e2][r] = set()\n            d[e2][r].add(e1)\n\n        def add_object(e1, e2, r, d):\n            if not e1 in d:\n                d[e1] = {}\n            if not r in d[e1]:\n                d[e1][r] = set()\n            d[e1][r].add(e2)\n\n        # store subjects for all (rel, object) queries and\n        # objects for all (subject, rel) queries\n        train_subjects, train_objects = {}, {}\n        dev_subjects, dev_objects = {}, {}\n        all_subjects, all_objects = {}, {}\n        # include dummy examples\n        add_subject(self.dummy_e, self.dummy_e, self.dummy_r, train_subjects)\n        add_subject(self.dummy_e, self.dummy_e, self.dummy_r, dev_subjects)\n        add_subject(self.dummy_e, self.dummy_e, self.dummy_r, all_subjects)\n        add_object(self.dummy_e, self.dummy_e, self.dummy_r, train_objects)\n        add_object(self.dummy_e, self.dummy_e, self.dummy_r, dev_objects)\n        add_object(self.dummy_e, self.dummy_e, self.dummy_r, all_objects)\n        for file_name in [\'raw.kb\', \'train.triples\', \'dev.triples\', \'test.triples\']:\n            if \'NELL\' in self.args.data_dir and self.args.test and file_name == \'train.triples\':\n                continue\n            with open(os.path.join(data_dir, file_name)) as f:\n                for line in f:\n                    e1, e2, r = line.strip().split()\n                    e1, e2, r = self.triple2ids((e1, e2, r))\n                    if file_name in [\'raw.kb\', \'train.triples\']:\n                        add_subject(e1, e2, r, train_subjects)\n                        add_object(e1, e2, r, train_objects)\n                        if add_reversed_edges:\n                            add_subject(e2, e1, self.get_inv_relation_id(r), train_subjects)\n                            add_object(e2, e1, self.get_inv_relation_id(r), train_objects)\n                    if file_name in [\'raw.kb\', \'train.triples\', \'dev.triples\']:\n                        add_subject(e1, e2, r, dev_subjects)\n                        add_object(e1, e2, r, dev_objects)\n                        if add_reversed_edges:\n                            add_subject(e2, e1, self.get_inv_relation_id(r), dev_subjects)\n                            add_object(e2, e1, self.get_inv_relation_id(r), dev_objects)\n                    add_subject(e1, e2, r, all_subjects)\n                    add_object(e1, e2, r, all_objects)\n                    if add_reversed_edges:\n                        add_subject(e2, e1, self.get_inv_relation_id(r), all_subjects)\n                        add_object(e2, e1, self.get_inv_relation_id(r), all_objects)\n        self.train_subjects = train_subjects\n        self.train_objects = train_objects\n        self.dev_subjects = dev_subjects\n        self.dev_objects = dev_objects\n        self.all_subjects = all_subjects\n        self.all_objects = all_objects\n       \n        # change the answer set into a variable\n        def answers_to_var(d_l):\n            d_v = collections.defaultdict(collections.defaultdict)\n            for x in d_l:\n                for y in d_l[x]:\n                    v = torch.LongTensor(list(d_l[x][y])).unsqueeze(1)\n                    d_v[x][y] = int_var_cuda(v)\n            return d_v\n        \n        self.train_subject_vectors = answers_to_var(train_subjects)\n        self.train_object_vectors = answers_to_var(train_objects)\n        self.dev_subject_vectors = answers_to_var(dev_subjects)\n        self.dev_object_vectors = answers_to_var(dev_objects)\n        self.all_subject_vectors = answers_to_var(all_subjects)\n        self.all_object_vectors = answers_to_var(all_objects)\n\n    def load_fuzzy_facts(self):\n        # extend current adjacency list with fuzzy facts\n        dev_path = os.path.join(self.args.data_dir, \'dev.triples\')\n        test_path = os.path.join(self.args.data_dir, \'test.triples\')\n        with open(dev_path) as f:\n            dev_triples = [l.strip() for l in f.readlines()]\n        with open(test_path) as f:\n            test_triples = [l.strip() for l in f.readlines()]\n        removed_triples = set(dev_triples + test_triples)\n        theta = 0.5\n        fuzzy_fact_path = os.path.join(self.args.data_dir, \'train.fuzzy.triples\')\n        count = 0\n        with open(fuzzy_fact_path) as f:\n            for line in f:\n                e1, e2, r, score = line.strip().split()\n                score = float(score)\n                if score < theta:\n                    continue\n                print(line)\n                if \'{}\\t{}\\t{}\'.format(e1, e2, r) in removed_triples:\n                    continue\n                e1_id = self.entity2id[e1]\n                e2_id = self.entity2id[e2]\n                r_id = self.relation2id[r]\n                if not r_id in self.adj_list[e1_id]:\n                    self.adj_list[e1_id][r_id] = set()\n                if not e2_id in self.adj_list[e1_id][r_id]:\n                    self.adj_list[e1_id][r_id].add(e2_id)\n                    count += 1\n                    if count > 0 and count % 1000 == 0:\n                        print(\'{} fuzzy facts added\'.format(count))\n\n        self.vectorize_action_space(self.args.data_dir)\n\n    def get_inv_relation_id(self, r_id):\n        return r_id + 1\n\n    def get_all_entity_embeddings(self):\n        return self.EDropout(self.entity_embeddings.weight)\n\n    def get_entity_embeddings(self, e):\n        return self.EDropout(self.entity_embeddings(e))\n\n    def get_all_relation_embeddings(self):\n        return self.RDropout(self.relation_embeddings.weight)\n\n    def get_relation_embeddings(self, r):\n        return self.RDropout(self.relation_embeddings(r))\n\n    def get_all_entity_img_embeddings(self):\n        return self.EDropout(self.entity_img_embeddings.weight)\n\n    def get_entity_img_embeddings(self, e):\n        return self.EDropout(self.entity_img_embeddings(e))\n\n    def get_relation_img_embeddings(self, r):\n        return self.RDropout(self.relation_img_embeddings(r))\n\n    def virtual_step(self, e_set, r):\n        """"""\n        Given a set of entities (e_set), find the set of entities (e_set_out) which has at least one incoming edge\n        labeled r and the source entity is in e_set.\n        """"""\n        batch_size = len(e_set)\n        e_set_1D = e_set.view(-1)\n        r_space = self.action_space[0][0][e_set_1D]\n        e_space = self.action_space[0][1][e_set_1D]\n        e_space = (r_space.view(batch_size, -1) == r.unsqueeze(1)).long() * e_space.view(batch_size, -1)\n        e_set_out = []\n        for i in range(len(e_space)):\n            e_set_out_b = var_cuda(unique(e_space[i].data))\n            e_set_out.append(e_set_out_b.unsqueeze(0))\n        e_set_out = ops.pad_and_cat(e_set_out, padding_value=self.dummy_e)\n        return e_set_out\n\n    def id2triples(self, triple):\n        e1, e2, r = triple\n        return self.id2entity[e1], self.id2entity[e2], self.id2relation[r]\n\n    def triple2ids(self, triple):\n        e1, e2, r = triple\n        return self.entity2id[e1], self.entity2id[e2], self.relation2id[r]\n\n    def define_modules(self):\n        if not self.args.relation_only:\n            self.entity_embeddings = nn.Embedding(self.num_entities, self.entity_dim)\n            if self.args.model == \'complex\':\n                self.entity_img_embeddings = nn.Embedding(self.num_entities, self.entity_dim)\n            self.EDropout = nn.Dropout(self.emb_dropout_rate)\n        self.relation_embeddings = nn.Embedding(self.num_relations, self.relation_dim)\n        if self.args.model == \'complex\':\n            self.relation_img_embeddings = nn.Embedding(self.num_relations, self.relation_dim)\n        self.RDropout = nn.Dropout(self.emb_dropout_rate)\n\n    def initialize_modules(self):\n        if not self.args.relation_only:\n            nn.init.xavier_normal_(self.entity_embeddings.weight)\n        nn.init.xavier_normal_(self.relation_embeddings.weight)\n\n    @property\n    def num_entities(self):\n        return len(self.entity2id)\n\n    @property\n    def num_relations(self):\n        return len(self.relation2id)\n\n    @property\n    def self_edge(self):\n        return NO_OP_RELATION_ID\n\n    @property\n    def self_e(self):\n        return NO_OP_ENTITY_ID        \n\n    @property\n    def dummy_r(self):\n        return DUMMY_RELATION_ID\n\n    @property\n    def dummy_e(self):\n        return DUMMY_ENTITY_ID\n\n    @property\n    def dummy_start_r(self):\n        return START_RELATION_ID\n'"
src/learn_framework.py,11,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Base learning framework.\n""""""\n\nimport os\nimport random\nimport shutil\nfrom tqdm import tqdm\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn.utils import clip_grad_norm_\n\nimport src.eval\nfrom src.utils.ops import var_cuda, zeros_var_cuda\nimport src.utils.ops as ops\n\n\nclass LFramework(nn.Module):\n    def __init__(self, args, kg, mdl):\n        super(LFramework, self).__init__()\n        self.args = args\n        self.data_dir = args.data_dir\n        self.model_dir = args.model_dir\n        self.model = args.model\n\n        # Training hyperparameters\n        self.batch_size = args.batch_size\n        self.train_batch_size = args.train_batch_size\n        self.dev_batch_size = args.dev_batch_size\n        self.start_epoch = args.start_epoch\n        self.num_epochs = args.num_epochs\n        self.num_wait_epochs = args.num_wait_epochs\n        self.num_peek_epochs = args.num_peek_epochs\n        self.learning_rate = args.learning_rate\n        self.grad_norm = args.grad_norm\n        self.adam_beta1 = args.adam_beta1\n        self.adam_beta2 = args.adam_beta2\n        self.optim = None\n\n        self.inference = not args.train\n        self.run_analysis = args.run_analysis\n\n        self.kg = kg\n        self.mdl = mdl\n        print(\'{} module created\'.format(self.model))\n\n    def print_all_model_parameters(self):\n        print(\'\\nModel Parameters\')\n        print(\'--------------------------\')\n        for name, param in self.named_parameters():\n            print(name, param.numel(), \'requires_grad={}\'.format(param.requires_grad))\n        param_sizes = [param.numel() for param in self.parameters()]\n        print(\'Total # parameters = {}\'.format(sum(param_sizes)))\n        print(\'--------------------------\')\n        print()\n\n    def run_train(self, train_data, dev_data):\n        self.print_all_model_parameters()\n\n        if self.optim is None:\n            self.optim = optim.Adam(\n                filter(lambda p: p.requires_grad, self.parameters()), lr=self.learning_rate)\n\n        # Track dev metrics changes\n        best_dev_metrics = 0\n        dev_metrics_history = []\n\n        for epoch_id in range(self.start_epoch, self.num_epochs):\n            print(\'Epoch {}\'.format(epoch_id))\n            if self.rl_variation_tag.startswith(\'rs\'):\n                # Reward shaping module sanity check:\n                #   Make sure the reward shaping module output value is in the correct range\n                train_scores = self.test_fn(train_data)\n                dev_scores = self.test_fn(dev_data)\n                print(\'Train set average fact score: {}\'.format(float(train_scores.mean())))\n                print(\'Dev set average fact score: {}\'.format(float(dev_scores.mean())))\n\n            # Update model parameters\n            self.train()\n            if self.rl_variation_tag.startswith(\'rs\'):\n                self.fn.eval()\n                self.fn_kg.eval()\n                if self.model.endswith(\'hypere\'):\n                    self.fn_secondary_kg.eval()\n            self.batch_size = self.train_batch_size\n            random.shuffle(train_data)\n            batch_losses = []\n            entropies = []\n            if self.run_analysis:\n                rewards = None\n                fns = None\n            for example_id in tqdm(range(0, len(train_data), self.batch_size)):\n\n                self.optim.zero_grad()\n\n                mini_batch = train_data[example_id:example_id + self.batch_size]\n                if len(mini_batch) < self.batch_size:\n                    continue\n                loss = self.loss(mini_batch)\n                loss[\'model_loss\'].backward()\n                if self.grad_norm > 0:\n                    clip_grad_norm_(self.parameters(), self.grad_norm)\n\n                self.optim.step()\n\n                batch_losses.append(loss[\'print_loss\'])\n                if \'entropy\' in loss:\n                    entropies.append(loss[\'entropy\'])\n                if self.run_analysis:\n                    if rewards is None:\n                        rewards = loss[\'reward\']\n                    else:\n                        rewards = torch.cat([rewards, loss[\'reward\']])\n                    if fns is None:\n                        fns = loss[\'fn\']\n                    else:\n                        fns = torch.cat([fns, loss[\'fn\']])\n            # Check training statistics\n            stdout_msg = \'Epoch {}: average training loss = {}\'.format(epoch_id, np.mean(batch_losses))\n            if entropies:\n                stdout_msg += \' entropy = {}\'.format(np.mean(entropies))\n            print(stdout_msg)\n            self.save_checkpoint(checkpoint_id=epoch_id, epoch_id=epoch_id)\n            if self.run_analysis:\n                print(\'* Analysis: # path types seen = {}\'.format(self.num_path_types))\n                num_hits = float(rewards.sum())\n                hit_ratio = num_hits / len(rewards)\n                print(\'* Analysis: # hits = {} ({})\'.format(num_hits, hit_ratio))\n                num_fns = float(fns.sum())\n                fn_ratio = num_fns / len(fns)\n                print(\'* Analysis: false negative ratio = {}\'.format(fn_ratio))\n\n            # Check dev set performance\n            if self.run_analysis or (epoch_id > 0 and epoch_id % self.num_peek_epochs == 0):\n                self.eval()\n                self.batch_size = self.dev_batch_size\n                dev_scores = self.forward(dev_data, verbose=False)\n                print(\'Dev set performance: (correct evaluation)\')\n                _, _, _, _, mrr = src.eval.hits_and_ranks(dev_data, dev_scores, self.kg.dev_objects, verbose=True)\n                metrics = mrr\n                print(\'Dev set performance: (include test set labels)\')\n                src.eval.hits_and_ranks(dev_data, dev_scores, self.kg.all_objects, verbose=True)\n                # Action dropout anneaking\n                if self.model.startswith(\'point\'):\n                    eta = self.action_dropout_anneal_interval\n                    if len(dev_metrics_history) > eta and metrics < min(dev_metrics_history[-eta:]):\n                        old_action_dropout_rate = self.action_dropout_rate\n                        self.action_dropout_rate *= self.action_dropout_anneal_factor \n                        print(\'Decreasing action dropout rate: {} -> {}\'.format(\n                            old_action_dropout_rate, self.action_dropout_rate))\n                # Save checkpoint\n                if metrics > best_dev_metrics:\n                    self.save_checkpoint(checkpoint_id=epoch_id, epoch_id=epoch_id, is_best=True)\n                    best_dev_metrics = metrics\n                    with open(os.path.join(self.model_dir, \'best_dev_iteration.dat\'), \'w\') as o_f:\n                        o_f.write(\'{}\'.format(epoch_id))\n                else:\n                    # Early stopping\n                    if epoch_id >= self.num_wait_epochs and metrics < np.mean(dev_metrics_history[-self.num_wait_epochs:]):\n                        break\n                dev_metrics_history.append(metrics)\n                if self.run_analysis:\n                    num_path_types_file = os.path.join(self.model_dir, \'num_path_types.dat\')\n                    dev_metrics_file = os.path.join(self.model_dir, \'dev_metrics.dat\')\n                    hit_ratio_file = os.path.join(self.model_dir, \'hit_ratio.dat\')\n                    fn_ratio_file = os.path.join(self.model_dir, \'fn_ratio.dat\')\n                    if epoch_id == 0:\n                        with open(num_path_types_file, \'w\') as o_f:\n                            o_f.write(\'{}\\n\'.format(self.num_path_types))\n                        with open(dev_metrics_file, \'w\') as o_f:\n                            o_f.write(\'{}\\n\'.format(metrics))\n                        with open(hit_ratio_file, \'w\') as o_f:\n                            o_f.write(\'{}\\n\'.format(hit_ratio))\n                        with open(fn_ratio_file, \'w\') as o_f:\n                            o_f.write(\'{}\\n\'.format(fn_ratio))\n                    else:\n                        with open(num_path_types_file, \'a\') as o_f:\n                            o_f.write(\'{}\\n\'.format(self.num_path_types))\n                        with open(dev_metrics_file, \'a\') as o_f:\n                            o_f.write(\'{}\\n\'.format(metrics))\n                        with open(hit_ratio_file, \'a\') as o_f:\n                            o_f.write(\'{}\\n\'.format(hit_ratio))\n                        with open(fn_ratio_file, \'a\') as o_f:\n                            o_f.write(\'{}\\n\'.format(fn_ratio))\n\n    def forward(self, examples, verbose=False):\n        pred_scores = []\n        for example_id in tqdm(range(0, len(examples), self.batch_size)):\n            mini_batch = examples[example_id:example_id + self.batch_size]\n            mini_batch_size = len(mini_batch)\n            if len(mini_batch) < self.batch_size:\n                self.make_full_batch(mini_batch, self.batch_size)\n            pred_score = self.predict(mini_batch, verbose=verbose)\n            pred_scores.append(pred_score[:mini_batch_size])\n        scores = torch.cat(pred_scores)\n        return scores\n\n    def format_batch(self, batch_data, num_labels=-1, num_tiles=1):\n        """"""\n        Convert batched tuples to the tensors accepted by the NN.\n        """"""\n        def convert_to_binary_multi_subject(e1):\n            e1_label = zeros_var_cuda([len(e1), num_labels])\n            for i in range(len(e1)):\n                e1_label[i][e1[i]] = 1\n            return e1_label\n\n        def convert_to_binary_multi_object(e2):\n            e2_label = zeros_var_cuda([len(e2), num_labels])\n            for i in range(len(e2)):\n                e2_label[i][e2[i]] = 1\n            return e2_label\n\n        batch_e1, batch_e2, batch_r = [], [], []\n        for i in range(len(batch_data)):\n            e1, e2, r = batch_data[i]\n            batch_e1.append(e1)\n            batch_e2.append(e2)\n            batch_r.append(r)\n        batch_e1 = var_cuda(torch.LongTensor(batch_e1), requires_grad=False)\n        batch_r = var_cuda(torch.LongTensor(batch_r), requires_grad=False)\n        if type(batch_e2[0]) is list:\n            batch_e2 = convert_to_binary_multi_object(batch_e2)\n        elif type(batch_e1[0]) is list:\n            batch_e1 = convert_to_binary_multi_subject(batch_e1)\n        else:\n            batch_e2 = var_cuda(torch.LongTensor(batch_e2), requires_grad=False)\n        # Rollout multiple times for each example\n        if num_tiles > 1:\n            batch_e1 = ops.tile_along_beam(batch_e1, num_tiles)\n            batch_r = ops.tile_along_beam(batch_r, num_tiles)\n            batch_e2 = ops.tile_along_beam(batch_e2, num_tiles)\n        return batch_e1, batch_e2, batch_r\n\n    def make_full_batch(self, mini_batch, batch_size, multi_answers=False):\n        dummy_e = self.kg.dummy_e\n        dummy_r = self.kg.dummy_r\n        if multi_answers:\n            dummy_example = (dummy_e, [dummy_e], dummy_r)\n        else:\n            dummy_example = (dummy_e, dummy_e, dummy_r)\n        for _ in range(batch_size - len(mini_batch)):\n            mini_batch.append(dummy_example)\n\n    def save_checkpoint(self, checkpoint_id, epoch_id=None, is_best=False):\n        """"""\n        Save model checkpoint.\n        :param checkpoint_id: Model checkpoint index assigned by training loop.\n        :param epoch_id: Model epoch index assigned by training loop.\n        :param is_best: if set, the model being saved is the best model on dev set.\n        """"""\n        checkpoint_dict = dict()\n        checkpoint_dict[\'state_dict\'] = self.state_dict()\n        checkpoint_dict[\'epoch_id\'] = epoch_id\n\n        out_tar = os.path.join(self.model_dir, \'checkpoint-{}.tar\'.format(checkpoint_id))\n        if is_best:\n            best_path = os.path.join(self.model_dir, \'model_best.tar\')\n            shutil.copyfile(out_tar, best_path)\n            print(\'=> best model updated \\\'{}\\\'\'.format(best_path))\n        else:\n            torch.save(checkpoint_dict, out_tar)\n            print(\'=> saving checkpoint to \\\'{}\\\'\'.format(out_tar))\n\n    def load_checkpoint(self, input_file):\n        """"""\n        Load model checkpoint.\n        :param n: Neural network module.\n        :param kg: Knowledge graph module.\n        :param input_file: Checkpoint file path.\n        """"""\n        if os.path.isfile(input_file):\n            print(\'=> loading checkpoint \\\'{}\\\'\'.format(input_file))\n            checkpoint = torch.load(input_file, map_location=""cuda:{}"".format(self.args.gpu))\n            self.load_state_dict(checkpoint[\'state_dict\'])\n            if not self.inference:\n                self.start_epoch = checkpoint[\'epoch_id\'] + 1\n                assert (self.start_epoch <= self.num_epochs)\n        else:\n            print(\'=> no checkpoint found at \\\'{}\\\'\'.format(input_file))\n\n    def export_to_embedding_projector(self):\n        """"""\n        Export knowledge base embeddings into .tsv files accepted by the Tensorflow Embedding Projector.\n        """"""\n        vector_path = os.path.join(self.model_dir, \'vector.tsv\')\n        meta_data_path = os.path.join(self.model_dir, \'metadata.tsv\')\n        v_o_f = open(vector_path, \'w\')\n        m_o_f = open(meta_data_path, \'w\')\n        for r in self.kg.relation2id:\n            if r.endswith(\'_inv\'):\n                continue\n            r_id = self.kg.relation2id[r]\n            R = self.kg.relation_embeddings.weight[r_id]\n            r_print = \'\'\n            for i in range(len(R)):\n                r_print += \'{}\\t\'.format(float(R[i]))\n            v_o_f.write(\'{}\\n\'.format(r_print.strip()))\n            m_o_f.write(\'{}\\n\'.format(r))\n            print(r, \'{}\'.format(float(R.norm())))\n        v_o_f.close()\n        m_o_f.close()\n        print(\'KG embeddings exported to {}\'.format(vector_path))\n        print(\'KG meta data exported to {}\'.format(meta_data_path))\n\n    @property\n    def rl_variation_tag(self):\n        parts = self.model.split(\'.\')\n        if len(parts) > 1:\n            return parts[1]\n        else:\n            return \'\'\n'"
src/parse_args.py,0,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Experiment Hyperparameters.\n""""""\n\nimport argparse\nimport os\n\n\nparser = argparse.ArgumentParser(description=\'Multi-Hop Knowledge Graph Reasoning with Reward Shaping\')\n\n# Experiment control\nparser.add_argument(\'--process_data\', action=\'store_true\',\n                    help=\'process knowledge graph (default: False)\')\nparser.add_argument(\'--train\', action=\'store_true\',\n                    help=\'run path selection set_policy training (default: False)\')\nparser.add_argument(\'--inference\', action=\'store_true\',\n                    help=\'run knowledge graph inference (default: False)\')\nparser.add_argument(\'--search_random_seed\', action=\'store_true\',\n                    help=\'run experiments with multiple random initializations and compute the result statistics \'\n                         \'(default: False)\')\nparser.add_argument(\'--eval\', action=\'store_true\',\n                    help=\'compute evaluation metrics (default: False)\')\nparser.add_argument(\'--eval_by_relation_type\', action=\'store_true\',\n                    help=\'compute evaluation metrics for to-M and to-1 relations separately (default: False)\')\nparser.add_argument(\'--eval_by_seen_queries\', action=\'store_true\',\n                    help=\'compute evaluation metrics for seen queries and unseen queries separately (default: False)\')\nparser.add_argument(\'--run_ablation_studies\', action=\'store_true\',\n                    help=\'run ablation studies\')\nparser.add_argument(\'--run_analysis\', action=\'store_true\',\n                    help=\'run algorithm analysis and print intermediate results (default: False)\')\nparser.add_argument(\'--data_dir\', type=str, default=os.path.join(os.path.dirname(os.path.dirname(__file__)), \'data\'),\n                    help=\'directory where the knowledge graph data is stored (default: None)\')\nparser.add_argument(\'--model_root_dir\', type=str, default=os.path.join(os.path.dirname(os.path.dirname(__file__)), \'model\'),\n                    help=\'root directory where the model parameters are stored (default: None)\')\nparser.add_argument(\'--model_dir\', type=str, default=os.path.join(os.path.dirname(os.path.dirname(__file__)), \'model\'),\n                    help=\'directory where the model parameters are stored (default: None)\')\nparser.add_argument(\'--gpu\', type=int, default=0,\n                    help=\'gpu device (default: 0)\')\nparser.add_argument(\'--checkpoint_path\', type=str, default=None,\n                    help=\'path to a pretrained checkpoint\')\n\n# Data\nparser.add_argument(\'--test\', action=\'store_true\',\n                    help=\'perform inference on the test set (default: False)\')\nparser.add_argument(\'--group_examples_by_query\', action=\'store_true\',\n                    help=\'group examples by topic entity + query relation (default: False)\')\n\n# Network Architecture\nparser.add_argument(\'--model\', type=str, default=\'point\',\n                    help=\'knowledge graph QA model (default: point)\')\nparser.add_argument(\'--entity_dim\', type=int, default=200, metavar=\'E\',\n                    help=\'entity embedding dimension (default: 200)\')\nparser.add_argument(\'--relation_dim\', type=int, default=200, metavar=\'R\',\n                    help=\'relation embedding dimension (default: 200)\')\nparser.add_argument(\'--history_dim\', type=int, default=400, metavar=\'H\',\n                    help=\'action history encoding LSTM hidden states dimension (default: 400)\')\nparser.add_argument(\'--history_num_layers\', type=int, default=3, metavar=\'L\',\n                    help=\'action history encoding LSTM number of layers (default: 1)\')\nparser.add_argument(\'--use_action_space_bucketing\', action=\'store_true\',\n                    help=\'bucket adjacency list by outgoing degree to avoid memory blow-up (default: False)\')\nparser.add_argument(\'--bucket_interval\', type=int, default=10,\n                    help=\'adjacency list bucket size (default: 32)\')\nparser.add_argument(\'--type_only\', action=\'store_true\',\n                    help=\'use denote knowledge graph node by entity types only (default: False)\')\nparser.add_argument(\'--relation_only\', action=\'store_true\',\n                    help=\'search with relation information only, ignoring entity representation (default: False)\')\nparser.add_argument(\'--relation_only_in_path\', action=\'store_true\',\n                    help=\'include intermediate entities in path (default: False)\')\n\n# Knowledge Graph\nparser.add_argument(\'--num_graph_convolution_layers\', type=int, default=0,\n                    help=\'number of graph convolution layers to use (default: 0, no GC is used)\')\nparser.add_argument(\'--graph_convolution_rank\', type=int, default=10,\n                    help=\'number of ranks \')\nparser.add_argument(\'--add_reverse_relations\', type=bool, default=True,\n                    help=\'add reverse relations to KB (default: True)\')\nparser.add_argument(\'--add_reversed_training_edges\', action=\'store_true\',\n                    help=\'add reversed edges to extend training set (default: False)\')\nparser.add_argument(\'--train_entire_graph\', type=bool, default=False,\n                    help=\'add all edges in the graph to extend training set (default: False)\')\nparser.add_argument(\'--emb_dropout_rate\', type=float, default=0.3,\n                    help=\'Knowledge graph embedding dropout rate (default: 0.3)\')\nparser.add_argument(\'--zero_entity_initialization\', type=bool, default=False,\n                    help=\'Initialize all entities to zero (default: False)\')\nparser.add_argument(\'--uniform_entity_initialization\', type=bool, default=False,\n                    help=\'Initialize all entities with the same random embedding (default: False)\')\n\n# Optimization\nparser.add_argument(\'--num_epochs\', type=int, default=200,\n                    help=\'maximum number of pass over the entire training set (default: 20)\')\nparser.add_argument(\'--num_wait_epochs\', type=int, default=5,\n                    help=\'number of epochs to wait before stopping training if dev set performance drops\')\nparser.add_argument(\'--num_peek_epochs\', type=int, default=2,\n                    help=\'number of epochs to wait for next dev set result check (default: 2)\')\nparser.add_argument(\'--start_epoch\', type=int, default=0,\n                    help=\'epoch from which the training should start (default: 0)\')\nparser.add_argument(\'--batch_size\', type=int, default=256,\n                    help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--train_batch_size\', type=int, default=256,\n                    help=\'mini-batch size during training (default: 256)\')\nparser.add_argument(\'--dev_batch_size\', type=int, default=64,\n                    help=\'mini-batch size during inferece (default: 64)\')\nparser.add_argument(\'--margin\', type=float, default=0,\n                    help=\'margin used for base MAMES training (default: 0)\')\nparser.add_argument(\'--learning_rate\', type=float, default=0.0001,\n                    help=\'learning rate (default: 0.0001)\')\nparser.add_argument(\'--learning_rate_decay\', type=float, default=1.0,\n                    help=\'learning rate decay factor for the Adam optimizer (default: 1)\')\nparser.add_argument(\'--adam_beta1\', type=float, default=0.9,\n                    help=\'Adam: decay rates for the first movement estimate (default: 0.9)\')\nparser.add_argument(\'--adam_beta2\', type=float, default=0.999,\n                    help=\'Adam: decay rates for the second raw movement estimate (default: 0.999)\')\nparser.add_argument(\'--grad_norm\', type=float, default=10000,\n                    help=\'norm threshold for gradient clipping (default 10000)\')\nparser.add_argument(\'--xavier_initialization\', type=bool, default=True,\n                    help=\'Initialize all model parameters using xavier initialization (default: True)\')\nparser.add_argument(\'--random_parameters\', type=bool, default=False,\n                    help=\'Inference with random parameters (default: False)\')\n\n# Fact Network\nparser.add_argument(\'--label_smoothing_epsilon\', type=float, default=0.1,\n                    help=\'epsilon used for label smoothing\')\nparser.add_argument(\'--hidden_dropout_rate\', type=float, default=0.3,\n                    help=\'ConvE hidden layer dropout rate (default: 0.3)\')\nparser.add_argument(\'--feat_dropout_rate\', type=float, default=0.2,\n                    help=\'ConvE feature dropout rate (default: 0.2)\')\nparser.add_argument(\'--emb_2D_d1\', type=int, default=10,\n                    help=\'ConvE embedding 2D shape dimension 1 (default: 10)\')\nparser.add_argument(\'--emb_2D_d2\', type=int, default=20,\n                    help=\'ConvE embedding 2D shape dimension 2 (default: 20)\')\nparser.add_argument(\'--num_out_channels\', type=int, default=32,\n                    help=\'ConvE number of output channels of the convolution layer (default: 32)\')\nparser.add_argument(\'--kernel_size\', type=int, default=3,\n                    help=\'ConvE kernel size (default: 3)\')\nparser.add_argument(\'--distmult_state_dict_path\', type=str, default=\'\',\n                    help=\'Path to the DistMult network state_dict (default: \'\')\')\nparser.add_argument(\'--complex_state_dict_path\', type=str, default=\'\',\n                    help=\'Path to the ComplEx network state dict (default: \'\')\')\nparser.add_argument(\'--conve_state_dict_path\', type=str, default=\'\',\n                    help=\'Path to the ConvE network state dict (default: \'\')\')\n\n# Policy Network\nparser.add_argument(\'--ff_dropout_rate\', type=float, default=0.1,\n                    help=\'Feed-forward layer dropout rate (default: 0.1)\')\nparser.add_argument(\'--rnn_dropout_rate\', type=float, default=0.0,\n                    help=\'RNN Variational Dropout Rate (default: 0.0)\')\nparser.add_argument(\'--action_dropout_rate\', type=float, default=0.1,\n                    help=\'Dropout rate for randomly masking out knowledge graph edges (default: 0.1)\')\nparser.add_argument(\'--action_dropout_anneal_factor\', type=float, default=0.95,\n\t                help=\'Decrease the action dropout rate once the dev set results stopped increase (default: 0.95)\')\nparser.add_argument(\'--action_dropout_anneal_interval\', type=int, default=1000,\n\t\t            help=\'Number of epochs to wait before decreasing the action dropout rate (default: 1000. Action \'\n                         \'dropout annealing is not used when the value is >= 1000.)\')\nparser.add_argument(\'--num_negative_samples\', type=int, default=10,\n                    help=\'Number of negative samples to use for embedding-based methods\')\n\n# Reward Shaping\nparser.add_argument(\'--fn_state_dict_path\', type=str, default=\'\',\n                    help=\'(Aborted) Path to the saved fact network model\')\nparser.add_argument(\'--fn_kg_state_dict_path\', type=str, default=\'\',\n                    help=\'(Aborted) Path to the saved knowledge graph embeddings used by a fact network\')\nparser.add_argument(\'--reward_shaping_threshold\', type=float, default=0,\n\t\t            help=\'Threshold cut off of reward shaping scores (default: 0)\')\nparser.add_argument(\'--mu\', type=float, default=1.0,\n                    help=\'Weight over the estimated reward (default: 1.0)\')\n\n# Graph Completion\nparser.add_argument(\'--theta\', type=float, default=0.2,\n                    help=\'Threshold for sifting high-confidence facts (default: 0.2)\')\n\n# Reinforcement Learning\nparser.add_argument(\'--num_rollouts\', type=int, default=20,\n                    help=\'number of rollouts (default: 20)\')\nparser.add_argument(\'--num_rollout_steps\', type=int, default=3,\n                    help=\'maximum path length (default: 3)\')\nparser.add_argument(\'--bandwidth\', type=int, default=300,\n                    help=\'maximum number of outgoing edges to explore at each step (default: 300)\')\nparser.add_argument(\'--r_bandwidth\', type=int, default=10,\n                    help=\'maximum number of unique relation types connecting a pair of entities (default: 10)\')\nparser.add_argument(\'--num_paths_per_entity\', type=int, default=3,\n                    help=\'number of paths used to calculate entity potential (default: 3)\')\nparser.add_argument(\'--beta\', type=float, default=0.0,\n                    help=\'entropy regularization weight (default: 0.0)\')\nparser.add_argument(\'--gamma\', type=float, default=1,\n                    help=\'moving average weight (default: 1)\')\n\n# Policy Gradient\nparser.add_argument(\'--baseline\', type=str, default=\'n/a\',\n                    help=\'baseline used by the policy gradient algorithm (default: n/a)\')\n\nparser.add_argument(\'--seed\', type=int, default=543, metavar=\'S\',\n                    help=\'random seed (default: 543)\')\n\n# Search Decoding\nparser.add_argument(\'--beam_size\', type=int, default=100,\n                    help=\'size of beam used in beam search inference (default: 100)\')\nparser.add_argument(\'--mask_test_false_negatives\', type=bool, default=False,\n                    help=\'mask false negative examples in the dev/test set during decoding (default: False. This flag \'\n                         \'was implemented for sanity checking and was not used in any experiment.)\')\nparser.add_argument(\'--visualize_paths\', action=\'store_true\',\n                    help=\'generate path visualizations during inference (default: False)\')\nparser.add_argument(\'--save_beam_search_paths\', action=\'store_true\',\n                    help=\'save the decoded path into a CSV file (default: False)\')\n\n# Separate Experiments\nparser.add_argument(\'--export_to_embedding_projector\', action=\'store_true\',\n                    help=\'export model embeddings to the Tensorflow Embedding Projector format (default: False)\')\nparser.add_argument(\'--export_reward_shaping_parameters\', action=\'store_true\',\n                    help=\'export KG embeddings and fact network parameters for reward shaping models (default: False)\')\nparser.add_argument(\'--compute_fact_scores\', action=\'store_true\',\n                    help=\'[Debugging Option] compute embedding based model scores (default: False)\')\nparser.add_argument(\'--export_fuzzy_facts\', action=\'store_true\',\n                    help=\'export the facts recovered by embedding based method (default: False)\')\nparser.add_argument(\'--export_error_cases\', action=\'store_true\',\n                    help=\'export the error cases of a model\')\nparser.add_argument(\'--compute_map\', action=\'store_true\',\n                    help=\'compute the Mean Average Precision evaluation metrics (default: False)\')\n\n# Hyperparameter Search\nparser.add_argument(\'--tune\', type=str, default=\'\',\n                    help=\'Specify the hyperparameters to tune during the search, separated by commas (default: None)\')\nparser.add_argument(\'--grid_search\', action=\'store_true\',\n                    help=\'Conduct grid search of hyperparameters\')\n\nargs = parser.parse_args()\n'"
src/emb/emb.py,13,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Embedding-based knowledge base completion baselines.\n""""""\n\nimport os\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\n\nfrom src.learn_framework import LFramework\nfrom src.data_utils import NO_OP_ENTITY_ID, DUMMY_ENTITY_ID\nfrom src.utils.ops import var_cuda, int_var_cuda, int_fill_var_cuda\n\n\nclass EmbeddingBasedMethod(LFramework):\n    def __init__(self, args, kg, mdl, secondary_kg=None, tertiary_kg=None):\n        super(EmbeddingBasedMethod, self).__init__(args, kg, mdl)\n        self.num_negative_samples = args.num_negative_samples\n        self.label_smoothing_epsilon = args.label_smoothing_epsilon\n        self.loss_fun = nn.BCELoss()\n\n        self.theta = args.theta\n        self.secondary_kg = secondary_kg\n        self.tertiary_kg = tertiary_kg\n\n    def forward_fact(self, examples):\n        kg, mdl = self.kg, self.mdl\n        pred_scores = []\n        for example_id in tqdm(range(0, len(examples), self.batch_size)):\n            mini_batch = examples[example_id:example_id + self.batch_size]\n            mini_batch_size = len(mini_batch)\n            if len(mini_batch) < self.batch_size:\n                self.make_full_batch(mini_batch, self.batch_size)\n            e1, e2, r = self.format_batch(mini_batch)\n            pred_score = mdl.forward_fact(e1, r, e2, kg)\n            pred_scores.append(pred_score[:mini_batch_size])\n        return torch.cat(pred_scores)\n\n    def loss(self, mini_batch):\n        kg, mdl = self.kg, self.mdl\n        # compute object training loss\n        e1, e2, r = self.format_batch(mini_batch, num_labels=kg.num_entities)\n        e2_label = ((1 - self.label_smoothing_epsilon) * e2) + (1.0 / e2.size(1))\n        pred_scores = mdl.forward(e1, r, kg)\n        loss = self.loss_fun(pred_scores, e2_label)\n        loss_dict = {}\n        loss_dict[\'model_loss\'] = loss\n        loss_dict[\'print_loss\'] = float(loss)\n        return loss_dict\n\n    def predict(self, mini_batch, verbose=False):\n        kg, mdl = self.kg, self.mdl\n        e1, e2, r = self.format_batch(mini_batch)\n        if self.model == \'hypere\':\n            pred_scores = mdl.forward(e1, r, kg, [self.secondary_kg])\n        elif self.model == \'triplee\':\n            pred_scores = mdl.forward(e1, r, kg, [self.secondary_kg, self.tertiary_kg])\n        else:\n            pred_scores = mdl.forward(e1, r, kg)\n        return pred_scores\n\n    def get_subject_mask(self, e1_space, e2, q):\n        kg = self.kg\n        if kg.args.mask_test_false_negatives:\n            answer_vectors = kg.all_subject_vectors\n        else:\n            answer_vectors = kg.train_subject_vectors\n        subject_masks = []\n        for i in range(len(e1_space)):\n            _e2, _q = int(e2[i]), int(q[i])\n            if not _e2 in answer_vectors or not _q in answer_vectors[_e2]:\n                answer_vector = var_cuda(torch.LongTensor([[kg.num_entities]]))\n            else:\n                answer_vector = answer_vectors[_e2][_q]\n            subject_mask = torch.sum(e1_space[i].unsqueeze(0) == answer_vector, dim=0)\n            subject_masks.append(subject_mask)\n        subject_mask = torch.cat(subject_masks).view(len(e1_space), -1)\n        return subject_mask\n\n    def get_object_mask(self, e2_space, e1, q):\n        kg = self.kg\n        if kg.args.mask_test_false_negatives:\n            answer_vectors = kg.all_object_vectors\n        else:\n            answer_vectors = kg.train_object_vectors\n        object_masks = []\n        for i in range(len(e2_space)):\n            _e1, _q = int(e1[i]), int(q[i])\n            if not e1 in answer_vectors or not q in answer_vectors[_e1]:\n                answer_vector = var_cuda(torch.LongTensor([[kg.num_entities]]))\n            else:\n                answer_vector = answer_vectors[_e1][_q]\n            object_mask = torch.sum(e2_space[i].unsqueeze(0) == answer_vector, dim=0)\n            object_masks.append(object_mask)\n        object_mask = torch.cat(object_masks).view(len(e2_space), -1)\n        return object_mask\n\n    def export_reward_shaping_parameters(self):\n        """"""\n        Export knowledge graph embeddings and fact network parameters for reward shaping models.\n        """"""\n        fn_state_dict_path = os.path.join(self.model_dir, \'fn_state_dict\')\n        fn_kg_state_dict_path = os.path.join(self.model_dir, \'fn_kg_state_dict\')\n        torch.save(self.mdl.state_dict(), fn_state_dict_path)\n        print(\'Fact network parameters export to {}\'.format(fn_state_dict_path))\n        torch.save(self.kg.state_dict(), fn_kg_state_dict_path)\n        print(\'Knowledge graph embeddings export to {}\'.format(fn_kg_state_dict_path))\n\n    def export_fuzzy_facts(self):\n        """"""\n        Export high confidence facts according to the model.\n        """"""\n        kg, mdl = self.kg, self.mdl\n\n        # Gather all possible (subject, relation) and (relation, object) pairs\n        sub_rel, rel_obj = {}, {}\n        for file_name in [\'raw.kb\', \'train.triples\', \'dev.triples\', \'test.triples\']:\n            with open(os.path.join(self.data_dir, file_name)) as f:\n                for line in f:\n                    e1, e2, r = line.strip().split()\n                    e1_id, e2_id, r_id = kg.triple2ids((e1, e2, r))\n                    if not e1_id in sub_rel:\n                        sub_rel[e1_id] = {}\n                    if not r_id in sub_rel[e1_id]:\n                        sub_rel[e1_id][r_id] = set()\n                    sub_rel[e1_id][r_id].add(e2_id)\n                    if not e2_id in rel_obj:\n                        rel_obj[e2_id] = {}\n                    if not r_id in rel_obj[e2_id]:\n                        rel_obj[e2_id][r_id] = set()\n                    rel_obj[e2_id][r_id].add(e1_id)\n\n        o_f = open(os.path.join(self.data_dir, \'train.fuzzy.triples\'), \'w\')\n        print(\'Saving fuzzy facts to {}\'.format(os.path.join(self.data_dir, \'train.fuzzy.triples\')))\n        count = 0\n        # Save recovered objects\n        e1_ids, r_ids = [], []\n        for e1_id in sub_rel:\n            for r_id in sub_rel[e1_id]:\n                e1_ids.append(e1_id)\n                r_ids.append(r_id)\n        for i in range(0, len(e1_ids), self.batch_size):\n            e1_ids_b = e1_ids[i:i+self.batch_size]\n            r_ids_b = r_ids[i:i+self.batch_size]\n            e1 = var_cuda(torch.LongTensor(e1_ids_b))\n            r = var_cuda(torch.LongTensor(r_ids_b))\n            pred_scores = mdl.forward(e1, r, kg)\n            for j in range(pred_scores.size(0)):\n                for _e2 in range(pred_scores.size(1)):\n                    if _e2 in [NO_OP_ENTITY_ID, DUMMY_ENTITY_ID]:\n                        continue\n                    if pred_scores[j, _e2] >= self.theta:\n                        _e1 = int(e1[j])\n                        _r = int(r[j])\n                        o_f.write(\'{}\\t{}\\t{}\\t{}\\n\'.format(\n                            kg.id2entity[_e1], kg.id2entity[_e2], kg.id2relation[_r], float(pred_scores[j, _e2])))\n                        count += 1\n                        if count % 1000 == 0:\n                            print(\'{} fuzzy facts exported\'.format(count))\n        # Save recovered subjects\n        e2_ids, r_ids = [], []\n        for e2_id in rel_obj:\n            for r_id in rel_obj[e2_id]:\n                e2_ids.append(e2_id)\n                r_ids.append(r_id)\n        e1 = int_var_cuda(torch.arange(kg.num_entities))\n        for i in range(len(e2_ids)):\n            r = int_fill_var_cuda(e1.size(), r_ids[i])\n            e2 = int_fill_var_cuda(e1.size(), e2_ids[i])\n            pred_scores = mdl.forward_fact(e1, r, e2, kg)\n            for j in range(pred_scores.size(1)):\n                if pred_scores[j] > self.theta:\n                    _e1 = int(e1[j])\n                    if _e1 in [NO_OP_ENTITY_ID, DUMMY_ENTITY_ID]:\n                        continue\n                    _r = int(r[j])\n                    _e2 = int(e2[j])\n                    if _e1 in sub_rel and _r in sub_rel[_e1]:\n                        continue\n                    o_f.write(\'{}\\t{}\\t{}\\t{}\\n\'.format(\n                        kg.id2entity[_e1], kg.id2entity[_e2], kg.id2relation[_r], float(pred_scores[j])))\n                    count += 1\n                    if count % 1000 == 0:\n                        print(\'{} fuzzy facts exported\'.format(count))\n'"
src/emb/fact_network.py,13,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Fact scoring networks.\n Code adapted from https://github.com/TimDettmers/ConvE/blob/master/model.py\n""""""\n\nimport copy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass TripleE(nn.Module):\n    def __init__(self, args, num_entities):\n        super(TripleE, self).__init__()\n        conve_args = copy.deepcopy(args)    \n        conve_args.model = \'conve\'\n        self.conve_nn = ConvE(conve_args, num_entities)\n        conve_state_dict = torch.load(args.conve_state_dict_path)\n        conve_nn_state_dict = get_conve_nn_state_dict(conve_state_dict)\n        self.conve_nn.load_state_dict(conve_nn_state_dict)\n\n        complex_args = copy.deepcopy(args)\n        complex_args.model = \'complex\'\n        self.complex_nn = ComplEx(complex_args)\n\n        distmult_args = copy.deepcopy(args)\n        distmult_args.model = \'distmult\'\n        self.distmult_nn = DistMult(distmult_args)\n\n    def forward(self, e1, r, conve_kg, secondary_kgs):\n        complex_kg = secondary_kgs[0]\n        distmult_kg = secondary_kgs[1]\n        return (self.conve_nn.forward(e1, r, conve_kg)\n                + self.complex_nn.forward(e1, r, complex_kg)\n                + self.distmult_nn.forward(e1, r, distmult_kg)) / 3\n\n    def forward_fact(self, e1, r, conve_kg, secondary_kgs):\n        complex_kg = secondary_kgs[0]\n        distmult_kg = secondary_kgs[1]\n        return (self.conve_nn.forward_fact(e1, r, conve_kg)\n                + self.complex_nn.forward_fact(e1, r, complex_kg)\n                + self.distmult_nn.forward_fact(e1, r, distmult_kg)) / 3\n\nclass HyperE(nn.Module):\n    def __init__(self, args, num_entities):\n        super(HyperE, self).__init__()\n        self.conve_nn = ConvE(args, num_entities)\n        conve_state_dict = torch.load(args.conve_state_dict_path)\n        conve_nn_state_dict = get_conve_nn_state_dict(conve_state_dict)\n        self.conve_nn.load_state_dict(conve_nn_state_dict)\n\n        complex_args = copy.deepcopy(args)\n        complex_args.model = \'complex\'\n        self.complex_nn = ComplEx(complex_args)\n\n    def forward(self, e1, r, conve_kg, secondary_kgs):\n        complex_kg = secondary_kgs[0]\n        return (self.conve_nn.forward(e1, r, conve_kg)\n                + self.complex_nn.forward(e1, r, complex_kg)) / 2\n\n    def forward_fact(self, e1, r, e2, conve_kg, secondary_kgs):\n        complex_kg = secondary_kgs[0]\n        return (self.conve_nn.forward_fact(e1, r, e2, conve_kg)\n                + self.complex_nn.forward_fact(e1, r, e2, complex_kg)) / 2\n\nclass ComplEx(nn.Module):\n    def __init__(self, args):\n        super(ComplEx, self).__init__()\n\n    def forward(self, e1, r, kg):\n        def dist_mult(E1, R, E2):\n            return torch.mm(E1 * R, E2.transpose(1, 0))\n\n        E1_real = kg.get_entity_embeddings(e1)\n        R_real = kg.get_relation_embeddings(r)\n        E2_real = kg.get_all_entity_embeddings()\n        E1_img = kg.get_entity_img_embeddings(e1)\n        R_img = kg.get_relation_img_embeddings(r)\n        E2_img = kg.get_all_entity_img_embeddings()\n\n        rrr = dist_mult(R_real, E1_real, E2_real)\n        rii = dist_mult(R_real, E1_img, E2_img)\n        iri = dist_mult(R_img, E1_real, E2_img)\n        iir = dist_mult(R_img, E1_img, E2_real)\n        S = rrr + rii + iri - iir\n        S = F.sigmoid(S)\n        return S\n\n    def forward_fact(self, e1, r, e2, kg):\n        def dist_mult_fact(E1, R, E2):\n            return torch.sum(E1 * R * E2, dim=1, keepdim=True)\n\n        E1_real = kg.get_entity_embeddings(e1)\n        R_real = kg.get_relation_embeddings(r)\n        E2_real = kg.get_entity_embeddings(e2)\n        E1_img = kg.get_entity_img_embeddings(e1)\n        R_img = kg.get_relation_img_embeddings(r)\n        E2_img = kg.get_entity_img_embeddings(e2)\n\n        rrr = dist_mult_fact(R_real, E1_real, E2_real)\n        rii = dist_mult_fact(R_real, E1_img, E2_img)\n        iri = dist_mult_fact(R_img, E1_real, E2_img)\n        iir = dist_mult_fact(R_img, E1_img, E2_real)\n        S = rrr + rii + iri - iir\n        S = F.sigmoid(S)\n        return S\n\nclass ConvE(nn.Module):\n    def __init__(self, args, num_entities):\n        super(ConvE, self).__init__()\n        self.entity_dim = args.entity_dim\n        self.relation_dim = args.relation_dim\n        assert(args.emb_2D_d1 * args.emb_2D_d2 == args.entity_dim)\n        assert(args.emb_2D_d1 * args.emb_2D_d2 == args.relation_dim)\n        self.emb_2D_d1 = args.emb_2D_d1\n        self.emb_2D_d2 = args.emb_2D_d2\n        self.num_out_channels = args.num_out_channels\n        self.w_d = args.kernel_size\n        self.HiddenDropout = nn.Dropout(args.hidden_dropout_rate)\n        self.FeatureDropout = nn.Dropout(args.feat_dropout_rate)\n\n        # stride = 1, padding = 0, dilation = 1, groups = 1\n        self.conv1 = nn.Conv2d(1, self.num_out_channels, (self.w_d, self.w_d), 1, 0)\n        self.bn0 = nn.BatchNorm2d(1)\n        self.bn1 = nn.BatchNorm2d(self.num_out_channels)\n        self.bn2 = nn.BatchNorm1d(self.entity_dim)\n        self.register_parameter(\'b\', nn.Parameter(torch.zeros(num_entities)))\n        h_out = 2 * self.emb_2D_d1 - self.w_d + 1\n        w_out = self.emb_2D_d2 - self.w_d + 1\n        self.feat_dim = self.num_out_channels * h_out * w_out\n        self.fc = nn.Linear(self.feat_dim, self.entity_dim)\n\n    def forward(self, e1, r, kg):\n        E1 = kg.get_entity_embeddings(e1).view(-1, 1, self.emb_2D_d1, self.emb_2D_d2)\n        R = kg.get_relation_embeddings(r).view(-1, 1, self.emb_2D_d1, self.emb_2D_d2)\n        E2 = kg.get_all_entity_embeddings()\n\n        stacked_inputs = torch.cat([E1, R], 2)\n        stacked_inputs = self.bn0(stacked_inputs)\n\n        X = self.conv1(stacked_inputs)\n        # X = self.bn1(X)\n        X = F.relu(X)\n        X = self.FeatureDropout(X)\n        X = X.view(-1, self.feat_dim)\n        X = self.fc(X)\n        X = self.HiddenDropout(X)\n        X = self.bn2(X)\n        X = F.relu(X)\n        X = torch.mm(X, E2.transpose(1, 0))\n        X += self.b.expand_as(X)\n\n        S = F.sigmoid(X)\n        return S\n\n    def forward_fact(self, e1, r, e2, kg):\n        """"""\n        Compute network scores of the given facts.\n        :param e1: [batch_size]\n        :param r:  [batch_size]\n        :param e2: [batch_size]\n        :param kg:\n        """"""\n        # print(e1.size(), r.size(), e2.size())\n        # print(e1.is_contiguous(), r.is_contiguous(), e2.is_contiguous())\n        # print(e1.min(), r.min(), e2.min())\n        # print(e1.max(), r.max(), e2.max())\n        E1 = kg.get_entity_embeddings(e1).view(-1, 1, self.emb_2D_d1, self.emb_2D_d2)\n        R = kg.get_relation_embeddings(r).view(-1, 1, self.emb_2D_d1, self.emb_2D_d2)\n        E2 = kg.get_entity_embeddings(e2)\n\n        stacked_inputs = torch.cat([E1, R], 2)\n        stacked_inputs = self.bn0(stacked_inputs)\n\n        X = self.conv1(stacked_inputs)\n        # X = self.bn1(X)\n        X = F.relu(X)\n        X = self.FeatureDropout(X)\n        X = X.view(-1, self.feat_dim)\n        X = self.fc(X)\n        X = self.HiddenDropout(X)\n        X = self.bn2(X)\n        X = F.relu(X)\n        X = torch.matmul(X.unsqueeze(1), E2.unsqueeze(2)).squeeze(2)\n        X += self.b[e2].unsqueeze(1)\n\n        S = F.sigmoid(X)\n        return S\n\nclass DistMult(nn.Module):\n    def __init__(self, args):\n        super(DistMult, self).__init__()\n\n    def forward(self, e1, r, kg):\n        E1 = kg.get_entity_embeddings(e1)\n        R = kg.get_relation_embeddings(r)\n        E2 = kg.get_all_entity_embeddings()\n        S = torch.mm(E1 * R, E2.transpose(1, 0))\n        S = F.sigmoid(S)\n        return S\n\n    def forward_fact(self, e1, r, e2, kg):\n        E1 = kg.get_entity_embeddings(e1)\n        R = kg.get_relation_embeddings(r)\n        E2 = kg.get_entity_embeddings(e2)\n        S = torch.sum(E1 * R * E2, dim=1, keepdim=True)\n        S = F.sigmoid(S)\n        return S\n\ndef get_conve_nn_state_dict(state_dict):\n    conve_nn_state_dict = {}\n    for param_name in [\'mdl.b\', \'mdl.conv1.weight\', \'mdl.conv1.bias\', \'mdl.bn0.weight\', \'mdl.bn0.bias\',\n                       \'mdl.bn0.running_mean\', \'mdl.bn0.running_var\', \'mdl.bn1.weight\', \'mdl.bn1.bias\',\n                       \'mdl.bn1.running_mean\', \'mdl.bn1.running_var\', \'mdl.bn2.weight\', \'mdl.bn2.bias\',\n                       \'mdl.bn2.running_mean\', \'mdl.bn2.running_var\', \'mdl.fc.weight\', \'mdl.fc.bias\']:\n        conve_nn_state_dict[param_name.split(\'.\', 1)[1]] = state_dict[\'state_dict\'][param_name]\n    return conve_nn_state_dict\n\ndef get_conve_kg_state_dict(state_dict):\n    kg_state_dict = dict()\n    for param_name in [\'kg.entity_embeddings.weight\', \'kg.relation_embeddings.weight\']:\n        kg_state_dict[param_name.split(\'.\', 1)[1]] = state_dict[\'state_dict\'][param_name]\n    return kg_state_dict\n\ndef get_complex_kg_state_dict(state_dict):\n    kg_state_dict = dict()\n    for param_name in [\'kg.entity_embeddings.weight\', \'kg.relation_embeddings.weight\',\n                       \'kg.entity_img_embeddings.weight\', \'kg.relation_img_embeddings.weight\']:\n        kg_state_dict[param_name.split(\'.\', 1)[1]] = state_dict[\'state_dict\'][param_name]\n    return kg_state_dict\n\ndef get_distmult_kg_state_dict(state_dict):\n    kg_state_dict = dict()\n    for param_name in [\'kg.entity_embeddings.weight\', \'kg.relation_embeddings.weight\']:\n        kg_state_dict[param_name.split(\'.\', 1)[1]] = state_dict[\'state_dict\'][param_name]\n    return kg_state_dict\n\n\n'"
src/error_analysis/analysis_modules.py,0,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Error Analysis Modules.\n""""""\n\nclass ModelErrors(object):\n    def __init__(self, model_name):\n        self.name = model_name\n        self.top_1_error_cases = None\n        self.top_10_error_cases = None\n\ndef compute_venn_areas(model_error_list):\n    def intersect(m_e1, m_e2):\n        if m_e1.name:\n            inter_model_errors = ModelErrors(\'{} & {}\'.format(m_e1.name, m_e2.name))\n            inter_model_errors.top_1_error_cases = m_e1.top_1_error_cases & m_e2.top_1_error_cases\n            inter_model_errors.top_10_error_cases = m_e1.top_10_error_cases & m_e2.top_10_error_cases\n        else:\n            inter_model_errors  = m_e2\n        return inter_model_errors\n\n    assert(len(model_error_list) > 1)\n    all_top_1_errors = set([e for m_e in model_error_list for e in m_e.top_1_error_cases ])\n    all_top_10_errors = set([e for m_e in model_error_list for e in m_e.top_10_error_cases])\n    all_model_errors = ModelErrors(\'\')\n    all_model_errors.top_1_error_cases = all_top_1_errors\n    all_model_errors.top_10_error_cases = all_top_10_errors\n    subset_overlap = {\n        0: all_model_errors,\n        1: model_error_list[0]\n    }\n    num_sets = len(model_error_list)\n    j = 1\n    for i in range(2, 1 << num_sets):\n        if i >= pow(2, j+1):\n            j += 1\n        res = i - pow(2, j)\n        subset_overlap[i] = intersect(subset_overlap[res], model_error_list[j])\n\n    print(\'Top 1 Error Cases\')\n    for i in sorted(subset_overlap.keys()):\n        print(\'|{}|: {}\'.format(subset_overlap[i].name, len(subset_overlap[i].top_1_error_cases)))\n    print()\n    print(\'Top 10 Error Cases\')\n    for i in sorted(subset_overlap.keys()):\n        print(\'|{}|: {}\'.format(subset_overlap[i].name, len(subset_overlap[i].top_10_error_cases)))\n\n    return subset_overlap\n'"
src/error_analysis/error_analysis.py,0,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Error Analysis.\n""""""\n\nimport json\nimport os\nimport pickle\n\nfrom src.error_analysis.analysis_modules import ModelErrors\nfrom src.error_analysis.analysis_modules import compute_venn_areas\n\n\nmodel_paths = {}\nmodel_paths[\'umls\'] = {\n    \'conve\': ""model/umls-conve-RV-xavier-200-200-0.003-32-3-0.3-0.3-0.2-0.1"",\n    \'distmult\': ""model/umls-distmult-xavier-200-200-0.003-0.3-0.1"",\n    \'complex\': ""model/umls-complex-xavier-200-200-0.003-0.3-0.1"",\n    \'pg\': ""model/umls-point-xavier-n/a-200-200-3-0.001-0.3-0.1-0.7-256-0.05"",\n    \'pg+conve\': ""model/umls-point.rs-xavier-n/a-200-200-3-0.001-0.3-0.1-0.7-256-0.05""\n}\nmodel_paths[\'kinship\'] = {\n    \'conve\': ""model/kinship-conve-RV-xavier-200-200-0.003-32-3-0.2-0.3-0.2-0.1"",\n    \'distmult\': ""model/kinship-distmult-xavier-200-200-0.003-0.3-0.1"",\n    \'complex\': ""model/kinship-complex-RV-xavier-200-200-0.003-0.3-0.1"",\n    \'pg\': ""model/kinship-point-xavier-n/a-200-200-3-0.001-0.3-0.1-0.9-256-0.05"",\n    \'pg+conve\': ""model/kinship-point.rs-xavier-n/a-200-200-3-0.001-0.3-0.1-0.9-256-0.05""\n}\nmodel_paths[\'fb15k-237\'] = {\n    \'conve\': ""model/FB15K-237-conve-RV-xavier-200-200-0.003-32-3-0.3-0.3-0.2-0.1"",\n    \'distmult\': ""model/FB15K-237-distmult-xavier-200-200-0.003-0.3-0.1"",\n    \'complex\': ""model/FB15K-237-complex-RV-xavier-200-200-0.003-0.3-0.1"",\n    \'pg\': ""model/FB15K-237-point-xavier-n/a-200-200-3-0.001-0.3-0.1-0.5-256-0.02"",\n    \'pg+conve\': ""model/FB15K-237-point.rs-xavier-n/a-200-200-3-0.001-0.3-0.1-0.5-256-0.02""\n}\nmodel_paths[\'wn18rr\'] = {\n    \'conve\': \'model/WN18RR-conve-RV-xavier-200-200-0.003-32-3-0.3-0.3-0.2-0.1\',\n    \'distmult\': \'model/WN18RR-distmult-xavier-200-200-0.003-0.2-0.1\',\n    \'complex\': \'model/WN18RR-complex-xavier-200-200-0.003-0.3-0.1\',\n    \'pg\': \'model/WN18RR-point-xavier-n/a-200-200-3-0.001-0.5-0.3-0.5-500-0.0\',\n    \'pg+conve\': \'\'\n}\nmodel_paths[\'nell-995\'] = {}\n\ndef compare_models(dataset, model_names):\n\n    def read_error_cases(input_dir):\n        input_path = os.path.join(input_dir, \'error_cases.txt\')\n        print(\'loading error cases from: {}\'.format(input_path))\n        base_dir = input_dir.split(\'/\')[1]\n        if base_dir.startswith(\'FB15K-237\'):\n            model_name = base_dir.split(\'-\')[2]\n        else:\n            model_name = base_dir.split(\'-\')[1]\n        model_errors = ModelErrors(model_name.upper())\n        with open(input_path, \'rb\') as f:\n            top_1_ecs, top_10_ecs = pickle.load(f)\n            model_errors.top_1_error_cases = set(top_1_ecs)\n            model_errors.top_10_error_cases = set(top_10_ecs)\n        return model_errors\n\n    model_error_list = []\n    for model_name in model_names:\n        model_error_list.append(read_error_cases(model_paths[dataset][model_name]))\n\n    subset_overlap = compute_venn_areas(model_error_list)\n    experiment = {}\n    experiment[\'dataset\'] = dataset.upper()    \n    experiment[\'top-1\'] = []\n    experiment[\'top-10\'] = []\n    for i in sorted(subset_overlap.keys()):\n        if subset_overlap[i].name:\n            experiment[\'top-1\'].append({\'name\': \'{}\'.format(subset_overlap[i].name.replace(\' & \', \',\')),\n                                        \'value\': len(subset_overlap[i].top_1_error_cases)})\n            experiment[\'top-10\'].append({\'name\': \'{}\'.format(subset_overlap[i].name.replace(\' & \', \',\')),\n                                        \'value\': len(subset_overlap[i].top_10_error_cases)})\n    print(json.dumps(experiment, indent=4, sort_keys=True))\n\ndef main():\n    dataset = \'fb15k-237\'\n    model_names = [\'conve\', \'distmult\', \'complex\']\n    compare_models(dataset, model_names)\n\nif __name__ == \'__main__\':\n    main()\n'"
src/utils/ops.py,17,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Customized operators and utility functions.\n""""""\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nEPSILON = float(np.finfo(float).eps)\nHUGE_INT = 1e31\n\n\ndef batch_lookup(M, idx, vector_output=True):\n    """"""\n    Perform batch lookup on matrix M using indices idx.\n    :param M: (Variable) [batch_size, seq_len] Each row of M is an independent population.\n    :param idx: (Variable) [batch_size, sample_size] Each row of idx is a list of sample indices.\n    :param vector_output: If set, return a 1-D vector when sample size is 1.\n    :return samples: [batch_size, sample_size] samples[i, j] = M[idx[i, j]]\n    """"""\n    batch_size, w = M.size()\n    batch_size2, sample_size = idx.size()\n    assert(batch_size == batch_size2)\n\n    if sample_size == 1 and vector_output:\n        samples = torch.gather(M, 1, idx).view(-1)\n    else:\n        samples = torch.gather(M, 1, idx)\n    return samples\n\n\ndef convert_to_dist(x):\n    x += EPSILON\n    return x / x.sum(1, keepdim=True)\n\n\ndef detach_module(mdl):\n    for param in mdl.parameters():\n        param.requires_grad = False\n\n\ndef entropy(p):\n    return torch.sum(-p * safe_log(p), 1)\n\n\ndef weighted_softmax(v, w, dim=-1):\n    exp_v = torch.exp(v)\n    weighted_exp_v = w * exp_v\n    return weighted_exp_v / torch.sum(weighted_exp_v, dim, keepdim=True)\n\n\ndef format_triple(triple, kg):\n    e1, e2, r = triple\n    rel = kg.id2relation[r] if r != kg.self_edge else \'<null>\'\n    if not rel.endswith(\'_inv\'):\n        return \'{} -{}-> {}\'.format(\n            kg.id2entity[e1], rel, kg.id2entity[e2])\n    else:\n        return \'{} <-{}- {}\'.format(\n            kg.id2entity[e1], rel, kg.id2entity[e2])\n\n\ndef format_path(path_trace, kg):\n    def get_most_recent_relation(j):\n        relation_id = int(path_trace[j][0])\n        if relation_id == kg.self_edge:\n            return \'<null>\'\n        else:\n            return kg.id2relation[relation_id]\n\n    def get_most_recent_entity(j):\n        return kg.id2entity[int(path_trace[j][1])]\n\n    path_str = get_most_recent_entity(0)\n    for j in range(1, len(path_trace)):\n        rel = get_most_recent_relation(j)\n        if not rel.endswith(\'_inv\'):\n            path_str += \' -{}-> \'.format(rel)\n        else:\n            path_str += \' <-{}- \'.format(rel[:-4])\n        path_str += get_most_recent_entity(j)\n    return path_str\n\n\ndef format_rule(rule, kg):\n    rule_str = \'\'\n    for j in range(len(rule)):\n        relation_id = int(rule[j])\n        rel = kg.id2relation[relation_id]\n        if not rel.endswith(\'_inv\'):\n            rule_str += \'-{}-> \'.format(rel)\n        else:\n            rule_str += \'<-{}-\'.format(rel)\n    return rule_str\n\n\ndef ones_var_cuda(s, requires_grad=False):\n    return Variable(torch.ones(s), requires_grad=requires_grad).cuda()\n\n\ndef zeros_var_cuda(s, requires_grad=False):\n    return Variable(torch.zeros(s), requires_grad=requires_grad).cuda()\n\n\ndef int_fill_var_cuda(s, value, requires_grad=False):\n    return int_var_cuda((torch.zeros(s) + value), requires_grad=requires_grad)\n\n\ndef int_var_cuda(x, requires_grad=False):\n    return Variable(x, requires_grad=requires_grad).long().cuda()\n\n\ndef var_cuda(x, requires_grad=False):\n    return Variable(x, requires_grad=requires_grad).cuda()\n\n\ndef var_to_numpy(x):\n    return x.data.cpu().numpy()\n\n\ndef pad_and_cat(a, padding_value, padding_dim=1):\n    max_dim_size = max([x.size()[padding_dim] for x in a])\n    padded_a = []\n    for x in a:\n        if x.size()[padding_dim] < max_dim_size:\n            res_len = max_dim_size - x.size()[1]\n            pad = nn.ConstantPad1d((0, res_len), padding_value)\n            padded_a.append(pad(x))\n        else:\n            padded_a.append(x)\n    return torch.cat(padded_a, dim=0)\n\n\ndef rearrange_vector_list(l, offset):\n    for i, v in enumerate(l):\n        l[i] = v[offset]\n\ndef safe_log(x):\n    return torch.log(x + EPSILON)\n\n\ndef tile_along_beam(v, beam_size, dim=0):\n    """"""\n    Tile a tensor along a specified dimension for the specified beam size.\n    :param v: Input tensor.\n    :param beam_size: Beam size.\n    """"""\n    if dim == -1:\n        dim = len(v.size()) - 1\n    v = v.unsqueeze(dim + 1)\n    v = torch.cat([v] * beam_size, dim=dim+1)\n    new_size = []\n    for i, d in enumerate(v.size()):\n        if i == dim + 1:\n            new_size[-1] *= d\n        else:\n            new_size.append(d)\n    return v.view(new_size)\n\n\n# Flatten and pack nested lists using recursion\ndef flatten(l):\n    flatten_l = []\n    for c in l:\n        if type(c) is list or type(c) is tuple:\n            flatten_l.extend(flatten(c))\n        else:\n            flatten_l.append(c)\n    return flatten_l\n\n\ndef pack(l, a):\n    """"""\n    Pack a flattened list l into the structure of the nested list a.\n    """"""\n    nested_l = []\n    for c in a:\n        if type(c) is not list:\n            nested_l.insert(l[0], 0)\n            l.pop(0)\n\n\ndef unique_max(unique_x, x, values, marker_2D=None):\n    unique_interval = 100\n    unique_values, unique_indices = [], []\n    # prevent memory explotion during decoding\n    for i in range(0, len(unique_x), unique_interval):\n        unique_x_b = unique_x[i:i+unique_interval]\n        marker_2D = (unique_x_b.unsqueeze(1) == x.unsqueeze(0)).float()\n        values_2D = marker_2D * values.unsqueeze(0) - (1 - marker_2D) * HUGE_INT\n        unique_values_b, unique_idx_b = values_2D.max(dim=1)\n        unique_values.append(unique_values_b)\n        unique_indices.append(unique_idx_b)\n    unique_values = torch.cat(unique_values)\n    unique_idx = torch.cat(unique_indices)\n    return unique_values, unique_idx\n\n\nif __name__ == \'__main__\':\n    a = torch.randn(2)\n    print(a)\n    print(tile_along_beam(a, 4))\n    print(\'--------------------------\')\n    b = torch.randn(2, 3)\n    print(b)\n    c = tile_along_beam(b, 4)\n    print(c)\n    print(\'--------------------------\')\n    print(c.view(2, -1))\n'"
src/utils/vis.py,0,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Visualize beam search in the knowledge graph.\n""""""\n\nimport matplotlib\nmatplotlib.use(\'Agg\')\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ndef visualize_step(action_dist, e, action_space, plot):\n    action_space_size = len(action_space)\n    plt_obj = plot.imshow(np.expand_dims(action_dist, 1), interpolation=\'nearest\', cmap=plt.cm.Blues)\n    plt.setp(plot, xticks=[0], xticklabels=[e], yticks=range(action_space_size), yticklabels=action_space)\n    plot.xaxis.tick_top()\n    plot.yaxis.tick_right()\n    plot.tick_params(axis=\'both\', which=\'major\', labelsize=6)\n    return plt_obj\n\n\ndef visualize_path(query, path_components, output_path=None):\n    """"""\n    :param query: String representation of the query.\n    :param path_components:\n        List of path component (e, action_space, action_dist)\n            e - current node name\n            (Numpy array) action_space - names of top k actions in the action space\n            (Numpy array) action_dist - probabilities of top k actions in the action space\n    :param output_path: Path to save the result graph.\n\n    Visualize probabilities of all actions along a beam search paths and save the plots.\n    """"""\n    plt.clf()\n    num_steps = len(path_components)\n    gridspec_kwargs = dict(top=0.9, bottom=0.1, left=0.1, right=0.9, wspace=8, hspace=0.4)\n    f, axarr = plt.subplots(num_steps, 1, gridspec_kw=gridspec_kwargs)\n    for i, (e, action_space, action_dist) in enumerate(path_components):\n        visualize_step(action_dist, e, action_space, axarr[i])\n\n    plt.suptitle(query, fontsize=6)\n    # f.colorbar(plt_obj)\n    plt.show()\n\n    if output_path:\n        plt.savefig(output_path, bbox_inches=\'tight\', format=\'png\')\n        print(\'path visualization saved to {}\'.format(output_path))\n\n    plt.close(f)\n'"
src/rl/graph_search/beam_search.py,5,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Beam search on the graph.\n""""""\n\nimport torch\n\nimport src.utils.ops as ops\nfrom src.utils.ops import unique_max, var_cuda, zeros_var_cuda, int_var_cuda, int_fill_var_cuda, var_to_numpy\n\n\ndef beam_search(pn, e_s, q, e_t, kg, num_steps, beam_size, return_path_components=False):\n    """"""\n    Beam search from source.\n\n    :param pn: Policy network.\n    :param e_s: (Variable:batch) source entity indices.\n    :param q: (Variable:batch) query relation indices.\n    :param e_t: (Variable:batch) target entity indices.\n    :param kg: Knowledge graph environment.\n    :param num_steps: Number of search steps.\n    :param beam_size: Beam size used in search.\n    :param return_path_components: If set, return all path components at the end of search.\n    """"""\n    assert (num_steps >= 1)\n    batch_size = len(e_s)\n\n    def top_k_action(log_action_dist, action_space):\n        """"""\n        Get top k actions.\n            - k = beam_size if the beam size is smaller than or equal to the beam action space size\n            - k = beam_action_space_size otherwise\n        :param log_action_dist: [batch_size*k, action_space_size]\n        :param action_space (r_space, e_space):\n            r_space: [batch_size*k, action_space_size]\n            e_space: [batch_size*k, action_space_size]\n        :return:\n            (next_r, next_e), action_prob, action_offset: [batch_size*new_k]\n        """"""\n        full_size = len(log_action_dist)\n        assert (full_size % batch_size == 0)\n        last_k = int(full_size / batch_size)\n\n        (r_space, e_space), _ = action_space\n        action_space_size = r_space.size()[1]\n        # => [batch_size, k\'*action_space_size]\n        log_action_dist = log_action_dist.view(batch_size, -1)\n        beam_action_space_size = log_action_dist.size()[1]\n        k = min(beam_size, beam_action_space_size)\n        # [batch_size, k]\n        log_action_prob, action_ind = torch.topk(log_action_dist, k)\n        next_r = ops.batch_lookup(r_space.view(batch_size, -1), action_ind).view(-1)\n        next_e = ops.batch_lookup(e_space.view(batch_size, -1), action_ind).view(-1)\n        # [batch_size, k] => [batch_size*k]\n        log_action_prob = log_action_prob.view(-1)\n        # *** compute parent offset\n        # [batch_size, k]\n        action_beam_offset = action_ind / action_space_size\n        # [batch_size, 1]\n        action_batch_offset = int_var_cuda(torch.arange(batch_size) * last_k).unsqueeze(1)\n        # [batch_size, k] => [batch_size*k]\n        action_offset = (action_batch_offset + action_beam_offset).view(-1)\n        return (next_r, next_e), log_action_prob, action_offset\n\n    def top_k_answer_unique(log_action_dist, action_space):\n        """"""\n        Get top k unique entities\n            - k = beam_size if the beam size is smaller than or equal to the beam action space size\n            - k = beam_action_space_size otherwise\n        :param log_action_dist: [batch_size*beam_size, action_space_size]\n        :param action_space (r_space, e_space):\n            r_space: [batch_size*beam_size, action_space_size]\n            e_space: [batch_size*beam_size, action_space_size]\n        :return:\n            (next_r, next_e), action_prob, action_offset: [batch_size*k]\n        """"""\n        full_size = len(log_action_dist)\n        assert (full_size % batch_size == 0)\n        last_k = int(full_size / batch_size)\n        (r_space, e_space), _ = action_space\n        action_space_size = r_space.size()[1]\n\n        r_space = r_space.view(batch_size, -1)\n        e_space = e_space.view(batch_size, -1)\n        log_action_dist = log_action_dist.view(batch_size, -1)\n        beam_action_space_size = log_action_dist.size()[1]\n        assert (beam_action_space_size % action_space_size == 0)\n        k = min(beam_size, beam_action_space_size)\n        next_r_list, next_e_list = [], []\n        log_action_prob_list = []\n        action_offset_list = []\n        for i in range(batch_size):\n            log_action_dist_b = log_action_dist[i]\n            r_space_b = r_space[i]\n            e_space_b = e_space[i]\n            unique_e_space_b = var_cuda(torch.unique(e_space_b.data.cpu()))\n            unique_log_action_dist, unique_idx = unique_max(unique_e_space_b, e_space_b, log_action_dist_b)\n            k_prime = min(len(unique_e_space_b), k)\n            top_unique_log_action_dist, top_unique_idx2 = torch.topk(unique_log_action_dist, k_prime)\n            top_unique_idx = unique_idx[top_unique_idx2]\n            top_unique_beam_offset = top_unique_idx / action_space_size\n            top_r = r_space_b[top_unique_idx]\n            top_e = e_space_b[top_unique_idx]\n            next_r_list.append(top_r.unsqueeze(0))\n            next_e_list.append(top_e.unsqueeze(0))\n            log_action_prob_list.append(top_unique_log_action_dist.unsqueeze(0))\n            top_unique_batch_offset = i * last_k\n            top_unique_action_offset = top_unique_batch_offset + top_unique_beam_offset\n            action_offset_list.append(top_unique_action_offset.unsqueeze(0))\n        next_r = ops.pad_and_cat(next_r_list, padding_value=kg.dummy_r).view(-1)\n        next_e = ops.pad_and_cat(next_e_list, padding_value=kg.dummy_e).view(-1)\n        log_action_prob = ops.pad_and_cat(log_action_prob_list, padding_value=-ops.HUGE_INT)\n        action_offset = ops.pad_and_cat(action_offset_list, padding_value=-1)\n        return (next_r, next_e), log_action_prob.view(-1), action_offset.view(-1)\n    \n    def adjust_search_trace(search_trace, action_offset):\n        for i, (r, e) in enumerate(search_trace):\n            new_r = r[action_offset]\n            new_e = e[action_offset]\n            search_trace[i] = (new_r, new_e)\n\n    # Initialization\n    r_s = int_fill_var_cuda(e_s.size(), kg.dummy_start_r)\n    seen_nodes = int_fill_var_cuda(e_s.size(), kg.dummy_e).unsqueeze(1)\n    init_action = (r_s, e_s)\n    # path encoder\n    pn.initialize_path(init_action, kg)\n    if kg.args.save_beam_search_paths:\n        search_trace = [(r_s, e_s)]\n\n    # Run beam search for num_steps\n    # [batch_size*k], k=1\n    log_action_prob = zeros_var_cuda(batch_size)\n    if return_path_components:\n        log_action_probs = []\n\n    action = init_action\n    for t in range(num_steps):\n        last_r, e = action\n        assert(q.size() == e_s.size())\n        assert(q.size() == e_t.size())\n        assert(e.size()[0] % batch_size == 0)\n        assert(q.size()[0] % batch_size == 0)\n        k = int(e.size()[0] / batch_size)\n        # => [batch_size*k]\n        q = ops.tile_along_beam(q.view(batch_size, -1)[:, 0], k)\n        e_s = ops.tile_along_beam(e_s.view(batch_size, -1)[:, 0], k)\n        e_t = ops.tile_along_beam(e_t.view(batch_size, -1)[:, 0], k)\n        obs = [e_s, q, e_t, t==(num_steps-1), last_r, seen_nodes]\n        # one step forward in search\n        db_outcomes, _, _ = pn.transit(\n            e, obs, kg, use_action_space_bucketing=True, merge_aspace_batching_outcome=True)\n        action_space, action_dist = db_outcomes[0]\n        # => [batch_size*k, action_space_size]\n        log_action_dist = log_action_prob.view(-1, 1) + ops.safe_log(action_dist)\n        # [batch_size*k, action_space_size] => [batch_size*new_k]\n        if t == num_steps - 1:\n            action, log_action_prob, action_offset = top_k_answer_unique(log_action_dist, action_space)\n        else:\n            action, log_action_prob, action_offset = top_k_action(log_action_dist, action_space)\n        if return_path_components:\n            ops.rearrange_vector_list(log_action_probs, action_offset)\n            log_action_probs.append(log_action_prob)\n        pn.update_path(action, kg, offset=action_offset)\n        seen_nodes = torch.cat([seen_nodes[action_offset], action[1].unsqueeze(1)], dim=1)\n        if kg.args.save_beam_search_paths:\n            adjust_search_trace(search_trace, action_offset)\n            search_trace.append(action)\n\n    output_beam_size = int(action[0].size()[0] / batch_size)\n    # [batch_size*beam_size] => [batch_size, beam_size]\n    beam_search_output = dict()\n    beam_search_output[\'pred_e2s\'] = action[1].view(batch_size, -1)\n    beam_search_output[\'pred_e2_scores\'] = log_action_prob.view(batch_size, -1)\n    if kg.args.save_beam_search_paths:\n        beam_search_output[\'search_traces\'] = search_trace\n\n    if return_path_components:\n        path_width = 10\n        path_components_list = []\n        for i in range(batch_size):\n            p_c = []\n            for k, log_action_prob in enumerate(log_action_probs):\n                top_k_edge_labels = []\n                for j in range(min(output_beam_size, path_width)):\n                    ind = i * output_beam_size + j\n                    r = kg.id2relation[int(search_trace[k+1][0][ind])]\n                    e = kg.id2entity[int(search_trace[k+1][1][ind])]\n                    if r.endswith(\'_inv\'):\n                        edge_label = \' <-{}- {} {}\'.format(r[:-4], e, float(log_action_probs[k][ind]))\n                    else:\n                        edge_label = \' -{}-> {} {}\'.format(r, e, float(log_action_probs[k][ind]))\n                    top_k_edge_labels.append(edge_label)\n                top_k_action_prob = log_action_prob[:path_width]\n                e_name = kg.id2entity[int(search_trace[1][0][i * output_beam_size])] if k == 0 else \'\'\n                p_c.append((e_name, top_k_edge_labels, var_to_numpy(top_k_action_prob)))\n            path_components_list.append(p_c)\n        beam_search_output[\'path_components_list\'] = path_components_list\n\n    return beam_search_output\n'"
src/rl/graph_search/pg.py,12,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Policy gradient (REINFORCE algorithm) training and inference.\n""""""\n\nimport torch\n\nfrom src.learn_framework import LFramework\nimport src.rl.graph_search.beam_search as search\nimport src.utils.ops as ops\nfrom src.utils.ops import int_fill_var_cuda, var_cuda, zeros_var_cuda\n\n\nclass PolicyGradient(LFramework):\n    def __init__(self, args, kg, pn):\n        super(PolicyGradient, self).__init__(args, kg, pn)\n\n        # Training hyperparameters\n        self.relation_only = args.relation_only\n        self.use_action_space_bucketing = args.use_action_space_bucketing\n        self.num_rollouts = args.num_rollouts\n        self.num_rollout_steps = args.num_rollout_steps\n        self.baseline = args.baseline\n        self.beta = args.beta  # entropy regularization parameter\n        self.gamma = args.gamma  # shrinking factor\n        self.action_dropout_rate = args.action_dropout_rate\n        self.action_dropout_anneal_factor = args.action_dropout_anneal_factor\n        self.action_dropout_anneal_interval = args.action_dropout_anneal_interval\n\n        # Inference hyperparameters\n        self.beam_size = args.beam_size\n\n        # Analysis\n        self.path_types = dict()\n        self.num_path_types = 0\n\n    def reward_fun(self, e1, r, e2, pred_e2):\n        return (pred_e2 == e2).float()\n\n    def loss(self, mini_batch):\n        \n        def stablize_reward(r):\n            r_2D = r.view(-1, self.num_rollouts)\n            if self.baseline == \'avg_reward\':\n                stabled_r_2D = r_2D - r_2D.mean(dim=1, keepdim=True)\n            elif self.baseline == \'avg_reward_normalized\':\n                stabled_r_2D = (r_2D - r_2D.mean(dim=1, keepdim=True)) / (r_2D.std(dim=1, keepdim=True) + ops.EPSILON)\n            else:\n                raise ValueError(\'Unrecognized baseline function: {}\'.format(self.baseline))\n            stabled_r = stabled_r_2D.view(-1)\n            return stabled_r\n    \n        e1, e2, r = self.format_batch(mini_batch, num_tiles=self.num_rollouts)\n        output = self.rollout(e1, r, e2, num_steps=self.num_rollout_steps)\n\n        # Compute policy gradient loss\n        pred_e2 = output[\'pred_e2\']\n        log_action_probs = output[\'log_action_probs\']\n        action_entropy = output[\'action_entropy\']\n\n        # Compute discounted reward\n        final_reward = self.reward_fun(e1, r, e2, pred_e2)\n        if self.baseline != \'n/a\':\n            final_reward = stablize_reward(final_reward)\n        cum_discounted_rewards = [0] * self.num_rollout_steps\n        cum_discounted_rewards[-1] = final_reward\n        R = 0\n        for i in range(self.num_rollout_steps - 1, -1, -1):\n            R = self.gamma * R + cum_discounted_rewards[i]\n            cum_discounted_rewards[i] = R\n\n        # Compute policy gradient\n        pg_loss, pt_loss = 0, 0\n        for i in range(self.num_rollout_steps):\n            log_action_prob = log_action_probs[i]\n            pg_loss += -cum_discounted_rewards[i] * log_action_prob\n            pt_loss += -cum_discounted_rewards[i] * torch.exp(log_action_prob)\n\n        # Entropy regularization\n        entropy = torch.cat([x.unsqueeze(1) for x in action_entropy], dim=1).mean(dim=1)\n        pg_loss = (pg_loss - entropy * self.beta).mean()\n        pt_loss = (pt_loss - entropy * self.beta).mean()\n\n        loss_dict = {}\n        loss_dict[\'model_loss\'] = pg_loss\n        loss_dict[\'print_loss\'] = float(pt_loss)\n        loss_dict[\'reward\'] = final_reward\n        loss_dict[\'entropy\'] = float(entropy.mean())\n        if self.run_analysis:\n            fn = torch.zeros(final_reward.size())\n            for i in range(len(final_reward)):\n                if not final_reward[i]:\n                    if int(pred_e2[i]) in self.kg.all_objects[int(e1[i])][int(r[i])]:\n                        fn[i] = 1\n            loss_dict[\'fn\'] = fn\n\n        return loss_dict\n\n    def rollout(self, e_s, q, e_t, num_steps, visualize_action_probs=False):\n        """"""\n        Perform multi-step rollout from the source entity conditioned on the query relation.\n        :param pn: Policy network.\n        :param e_s: (Variable:batch) source entity indices.\n        :param q: (Variable:batch) query relation indices.\n        :param e_t: (Variable:batch) target entity indices.\n        :param kg: Knowledge graph environment.\n        :param num_steps: Number of rollout steps.\n        :param visualize_action_probs: If set, save action probabilities for visualization.\n        :return pred_e2: Target entities reached at the end of rollout.\n        :return log_path_prob: Log probability of the sampled path.\n        :return action_entropy: Entropy regularization term.\n        """"""\n        assert (num_steps > 0)\n        kg, pn = self.kg, self.mdl\n\n        # Initialization\n        log_action_probs = []\n        action_entropy = []\n        r_s = int_fill_var_cuda(e_s.size(), kg.dummy_start_r)\n        seen_nodes = int_fill_var_cuda(e_s.size(), kg.dummy_e).unsqueeze(1)\n        path_components = []\n\n        path_trace = [(r_s, e_s)]\n        pn.initialize_path((r_s, e_s), kg)\n\n        for t in range(num_steps):\n            last_r, e = path_trace[-1]\n            obs = [e_s, q, e_t, t==(num_steps-1), last_r, seen_nodes]\n            db_outcomes, inv_offset, policy_entropy = pn.transit(\n                e, obs, kg, use_action_space_bucketing=self.use_action_space_bucketing)\n            sample_outcome = self.sample_action(db_outcomes, inv_offset)\n            action = sample_outcome[\'action_sample\']\n            pn.update_path(action, kg)\n            action_prob = sample_outcome[\'action_prob\']\n            log_action_probs.append(ops.safe_log(action_prob))\n            action_entropy.append(policy_entropy)\n            seen_nodes = torch.cat([seen_nodes, e.unsqueeze(1)], dim=1)\n            path_trace.append(action)\n\n            if visualize_action_probs:\n                top_k_action = sample_outcome[\'top_actions\']\n                top_k_action_prob = sample_outcome[\'top_action_probs\']\n                path_components.append((e, top_k_action, top_k_action_prob))\n\n        pred_e2 = path_trace[-1][1]\n        self.record_path_trace(path_trace)\n\n        return {\n            \'pred_e2\': pred_e2,\n            \'log_action_probs\': log_action_probs,\n            \'action_entropy\': action_entropy,\n            \'path_trace\': path_trace,\n            \'path_components\': path_components\n        }\n\n    def sample_action(self, db_outcomes, inv_offset=None):\n        """"""\n        Sample an action based on current policy.\n        :param db_outcomes (((r_space, e_space), action_mask), action_dist):\n                r_space: (Variable:batch) relation space\n                e_space: (Variable:batch) target entity space\n                action_mask: (Variable:batch) binary mask indicating padding actions.\n                action_dist: (Variable:batch) action distribution of the current step based on set_policy\n                    network parameters\n        :param inv_offset: Indexes for restoring original order in a batch.\n        :return next_action (next_r, next_e): Sampled next action.\n        :return action_prob: Probability of the sampled action.\n        """"""\n\n        def apply_action_dropout_mask(action_dist, action_mask):\n            if self.action_dropout_rate > 0:\n                rand = torch.rand(action_dist.size())\n                action_keep_mask = var_cuda(rand > self.action_dropout_rate).float()\n                # There is a small chance that that action_keep_mask is accidentally set to zero.\n                # When this happen, we take a random sample from the available actions.\n                # sample_action_dist = action_dist * (action_keep_mask + ops.EPSILON)\n                sample_action_dist = \\\n                    action_dist * action_keep_mask + ops.EPSILON * (1 - action_keep_mask) * action_mask\n                return sample_action_dist\n            else:\n                return action_dist\n\n        def sample(action_space, action_dist):\n            sample_outcome = {}\n            ((r_space, e_space), action_mask) = action_space\n            sample_action_dist = apply_action_dropout_mask(action_dist, action_mask)\n            idx = torch.multinomial(sample_action_dist, 1, replacement=True)\n            next_r = ops.batch_lookup(r_space, idx)\n            next_e = ops.batch_lookup(e_space, idx)\n            action_prob = ops.batch_lookup(action_dist, idx)\n            sample_outcome[\'action_sample\'] = (next_r, next_e)\n            sample_outcome[\'action_prob\'] = action_prob\n            return sample_outcome\n\n        if inv_offset is not None:\n            next_r_list = []\n            next_e_list = []\n            action_dist_list = []\n            action_prob_list = []\n            for action_space, action_dist in db_outcomes:\n                sample_outcome = sample(action_space, action_dist)\n                next_r_list.append(sample_outcome[\'action_sample\'][0])\n                next_e_list.append(sample_outcome[\'action_sample\'][1])\n                action_prob_list.append(sample_outcome[\'action_prob\'])\n                action_dist_list.append(action_dist)\n            next_r = torch.cat(next_r_list, dim=0)[inv_offset]\n            next_e = torch.cat(next_e_list, dim=0)[inv_offset]\n            action_sample = (next_r, next_e)\n            action_prob = torch.cat(action_prob_list, dim=0)[inv_offset]\n            sample_outcome = {}\n            sample_outcome[\'action_sample\'] = action_sample\n            sample_outcome[\'action_prob\'] = action_prob\n        else:\n            sample_outcome = sample(db_outcomes[0][0], db_outcomes[0][1])\n\n        return sample_outcome\n\n    def predict(self, mini_batch, verbose=False):\n        kg, pn = self.kg, self.mdl\n        e1, e2, r = self.format_batch(mini_batch)\n        beam_search_output = search.beam_search(\n            pn, e1, r, e2, kg, self.num_rollout_steps, self.beam_size)\n        pred_e2s = beam_search_output[\'pred_e2s\']\n        pred_e2_scores = beam_search_output[\'pred_e2_scores\']\n        if verbose:\n            # print inference paths\n            search_traces = beam_search_output[\'search_traces\']\n            output_beam_size = min(self.beam_size, pred_e2_scores.shape[1])\n            for i in range(len(e1)):\n                for j in range(output_beam_size):\n                    ind = i * output_beam_size + j\n                    if pred_e2s[i][j] == kg.dummy_e:\n                        break\n                    search_trace = []\n                    for k in range(len(search_traces)):\n                        search_trace.append((int(search_traces[k][0][ind]), int(search_traces[k][1][ind])))\n                    print(\'beam {}: score = {} \\n<PATH> {}\'.format(\n                        j, float(pred_e2_scores[i][j]), ops.format_path(search_trace, kg)))\n        with torch.no_grad():\n            pred_scores = zeros_var_cuda([len(e1), kg.num_entities])\n            for i in range(len(e1)):\n                pred_scores[i][pred_e2s[i]] = torch.exp(pred_e2_scores[i])\n        return pred_scores\n\n    def record_path_trace(self, path_trace):\n        path_length = len(path_trace)\n        flattened_path_trace = [x for t in path_trace for x in t]\n        path_trace_mat = torch.cat(flattened_path_trace).reshape(-1, path_length)\n        path_trace_mat = path_trace_mat.data.cpu().numpy()\n\n        for i in range(path_trace_mat.shape[0]):\n            path_recorder = self.path_types\n            for j in range(path_trace_mat.shape[1]):\n                e = path_trace_mat[i, j]\n                if not e in path_recorder:\n                    if j == path_trace_mat.shape[1] - 1:\n                        path_recorder[e] = 1\n                        self.num_path_types += 1\n                    else:\n                        path_recorder[e] = {}\n                else:\n                    if j == path_trace_mat.shape[1] - 1:\n                        path_recorder[e] += 1\n                path_recorder = path_recorder[e]\n'"
src/rl/graph_search/pn.py,12,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Graph Search Policy Network.\n""""""\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport src.utils.ops as ops\nfrom src.utils.ops import var_cuda, zeros_var_cuda\n\n\nclass GraphSearchPolicy(nn.Module):\n    def __init__(self, args):\n        super(GraphSearchPolicy, self).__init__()\n        self.model = args.model\n        self.relation_only = args.relation_only\n\n        self.history_dim = args.history_dim\n        self.history_num_layers = args.history_num_layers\n        self.entity_dim = args.entity_dim\n        self.relation_dim = args.relation_dim\n        if self.relation_only:\n            self.action_dim = args.relation_dim\n        else:\n            self.action_dim = args.entity_dim + args.relation_dim\n        self.ff_dropout_rate = args.ff_dropout_rate\n        self.rnn_dropout_rate = args.rnn_dropout_rate\n        self.action_dropout_rate = args.action_dropout_rate\n\n        self.xavier_initialization = args.xavier_initialization\n\n        self.relation_only_in_path = args.relation_only_in_path\n        self.path = None\n\n        # Set policy network modules\n        self.define_modules()\n        self.initialize_modules()\n\n        # Fact network modules\n        self.fn = None\n        self.fn_kg = None\n\n    def transit(self, e, obs, kg, use_action_space_bucketing=True, merge_aspace_batching_outcome=False):\n        """"""\n        Compute the next action distribution based on\n            (a) the current node (entity) in KG and the query relation\n            (b) action history representation\n        :param e: agent location (node) at step t.\n        :param obs: agent observation at step t.\n            e_s: source node\n            q: query relation\n            e_t: target node\n            last_step: If set, the agent is carrying out the last step.\n            last_r: label of edge traversed in the previous step\n            seen_nodes: notes seen on the paths\n        :param kg: Knowledge graph environment.\n        :param use_action_space_bucketing: If set, group the action space of different nodes \n            into buckets by their sizes.\n        :param merge_aspace_batch_outcome: If set, merge the transition probability distribution\n            generated of different action space bucket into a single batch.\n        :return\n            With aspace batching and without merging the outcomes:\n                db_outcomes: (Dynamic Batch) (action_space, action_dist)\n                    action_space: (Batch) padded possible action indices\n                    action_dist: (Batch) distribution over actions.\n                inv_offset: Indices to set the dynamic batching output back to the original order.\n                entropy: (Batch) entropy of action distribution.\n            Else:\n                action_dist: (Batch) distribution over actions.\n                entropy: (Batch) entropy of action distribution.\n        """"""\n        e_s, q, e_t, last_step, last_r, seen_nodes = obs\n\n        # Representation of the current state (current node and other observations)\n        Q = kg.get_relation_embeddings(q)\n        H = self.path[-1][0][-1, :, :]\n        if self.relation_only:\n            X = torch.cat([H, Q], dim=-1)\n        elif self.relation_only_in_path:\n            E_s = kg.get_entity_embeddings(e_s)\n            E = kg.get_entity_embeddings(e)\n            X = torch.cat([E, H, E_s, Q], dim=-1)\n        else:\n            E = kg.get_entity_embeddings(e)\n            X = torch.cat([E, H, Q], dim=-1)\n\n        # MLP\n        X = self.W1(X)\n        X = F.relu(X)\n        X = self.W1Dropout(X)\n        X = self.W2(X)\n        X2 = self.W2Dropout(X)\n\n        def policy_nn_fun(X2, action_space):\n            (r_space, e_space), action_mask = action_space\n            A = self.get_action_embedding((r_space, e_space), kg)\n            action_dist = F.softmax(\n                torch.squeeze(A @ torch.unsqueeze(X2, 2), 2) - (1 - action_mask) * ops.HUGE_INT, dim=-1)\n            # action_dist = ops.weighted_softmax(torch.squeeze(A @ torch.unsqueeze(X2, 2), 2), action_mask)\n            return action_dist, ops.entropy(action_dist)\n\n        def pad_and_cat_action_space(action_spaces, inv_offset):\n            db_r_space, db_e_space, db_action_mask = [], [], []\n            for (r_space, e_space), action_mask in action_spaces:\n                db_r_space.append(r_space)\n                db_e_space.append(e_space)\n                db_action_mask.append(action_mask)\n            r_space = ops.pad_and_cat(db_r_space, padding_value=kg.dummy_r)[inv_offset]\n            e_space = ops.pad_and_cat(db_e_space, padding_value=kg.dummy_e)[inv_offset]\n            action_mask = ops.pad_and_cat(db_action_mask, padding_value=0)[inv_offset]\n            action_space = ((r_space, e_space), action_mask)\n            return action_space\n\n        if use_action_space_bucketing:\n            """"""\n            \n            """"""\n            db_outcomes = []\n            entropy_list = []\n            references = []\n            db_action_spaces, db_references = self.get_action_space_in_buckets(e, obs, kg)\n            for action_space_b, reference_b in zip(db_action_spaces, db_references):\n                X2_b = X2[reference_b, :]\n                action_dist_b, entropy_b = policy_nn_fun(X2_b, action_space_b)\n                references.extend(reference_b)\n                db_outcomes.append((action_space_b, action_dist_b))\n                entropy_list.append(entropy_b)\n            inv_offset = [i for i, _ in sorted(enumerate(references), key=lambda x: x[1])]\n            entropy = torch.cat(entropy_list, dim=0)[inv_offset]\n            if merge_aspace_batching_outcome:\n                db_action_dist = []\n                for _, action_dist in db_outcomes:\n                    db_action_dist.append(action_dist)\n                action_space = pad_and_cat_action_space(db_action_spaces, inv_offset)\n                action_dist = ops.pad_and_cat(db_action_dist, padding_value=0)[inv_offset]\n                db_outcomes = [(action_space, action_dist)]\n                inv_offset = None\n        else:\n            action_space = self.get_action_space(e, obs, kg)\n            action_dist, entropy = policy_nn_fun(X2, action_space)\n            db_outcomes = [(action_space, action_dist)]\n            inv_offset = None\n\n        return db_outcomes, inv_offset, entropy\n\n    def initialize_path(self, init_action, kg):\n        # [batch_size, action_dim]\n        if self.relation_only_in_path:\n            init_action_embedding = kg.get_relation_embeddings(init_action[0])\n        else:\n            init_action_embedding = self.get_action_embedding(init_action, kg)\n        init_action_embedding.unsqueeze_(1)\n        # [num_layers, batch_size, dim]\n        init_h = zeros_var_cuda([self.history_num_layers, len(init_action_embedding), self.history_dim])\n        init_c = zeros_var_cuda([self.history_num_layers, len(init_action_embedding), self.history_dim])\n        self.path = [self.path_encoder(init_action_embedding, (init_h, init_c))[1]]\n\n    def update_path(self, action, kg, offset=None):\n        """"""\n        Once an action was selected, update the action history.\n        :param action (r, e): (Variable:batch) indices of the most recent action\n            - r is the most recently traversed edge;\n            - e is the destination entity.\n        :param offset: (Variable:batch) if None, adjust path history with the given offset, used for search\n        :param KG: Knowledge graph environment.\n        """"""\n        def offset_path_history(p, offset):\n            for i, x in enumerate(p):\n                if type(x) is tuple:\n                    new_tuple = tuple([_x[:, offset, :] for _x in x])\n                    p[i] = new_tuple\n                else:\n                    p[i] = x[offset, :]\n\n        # update action history\n        if self.relation_only_in_path:\n            action_embedding = kg.get_relation_embeddings(action[0])\n        else:\n            action_embedding = self.get_action_embedding(action, kg)\n        if offset is not None:\n            offset_path_history(self.path, offset)\n\n        self.path.append(self.path_encoder(action_embedding.unsqueeze(1), self.path[-1])[1])\n\n    def get_action_space_in_buckets(self, e, obs, kg, collapse_entities=False):\n        """"""\n        To compute the search operation in batch, we group the action spaces of different states\n        (i.e. the set of outgoing edges of different nodes) into buckets based on their sizes to\n        save the memory consumption of paddings.\n\n        For example, in large knowledge graphs, certain nodes may have thousands of outgoing\n        edges while a long tail of nodes only have a small amount of outgoing edges. If a batch\n        contains a node with 1000 outgoing edges while the rest of the nodes have a maximum of\n        5 outgoing edges, we need to pad the action spaces of all nodes to 1000, which consumes\n        lots of memory.\n\n        With the bucketing approach, each bucket is padded separately. In this case the node\n        with 1000 outgoing edges will be in its own bucket and the rest of the nodes will suffer\n        little from padding the action space to 5.\n\n        Once we grouped the action spaces in buckets, the policy network computation is carried\n        out for every bucket iteratively. Once all the computation is done, we concatenate the\n        results of all buckets and restore their original order in the batch. The computation\n        outside the policy network module is thus unaffected.\n\n        :return db_action_spaces:\n            [((r_space_b0, r_space_b0), action_mask_b0),\n             ((r_space_b1, r_space_b1), action_mask_b1),\n             ...\n             ((r_space_bn, r_space_bn), action_mask_bn)]\n\n            A list of action space tensor representations grouped in n buckets, s.t.\n            r_space_b0.size(0) + r_space_b1.size(0) + ... + r_space_bn.size(0) = e.size(0)\n\n        :return db_references:\n            [l_batch_refs0, l_batch_refs1, ..., l_batch_refsn]\n            l_batch_refsi stores the indices of the examples in bucket i in the current batch,\n            which is used later to restore the output results to the original order.\n        """"""\n        e_s, q, e_t, last_step, last_r, seen_nodes = obs\n        assert(len(e) == len(last_r))\n        assert(len(e) == len(e_s))\n        assert(len(e) == len(q))\n        assert(len(e) == len(e_t))\n        db_action_spaces, db_references = [], []\n\n        if collapse_entities:\n            raise NotImplementedError\n        else:\n            entity2bucketid = kg.entity2bucketid[e.tolist()]\n            key1 = entity2bucketid[:, 0]\n            key2 = entity2bucketid[:, 1]\n            batch_ref = {}\n            for i in range(len(e)):\n                key = int(key1[i])\n                if not key in batch_ref:\n                    batch_ref[key] = []\n                batch_ref[key].append(i)\n            for key in batch_ref:\n                action_space = kg.action_space_buckets[key]\n                # l_batch_refs: ids of the examples in the current batch of examples\n                # g_bucket_ids: ids of the examples in the corresponding KG action space bucket\n                l_batch_refs = batch_ref[key]\n                g_bucket_ids = key2[l_batch_refs].tolist()\n                r_space_b = action_space[0][0][g_bucket_ids]\n                e_space_b = action_space[0][1][g_bucket_ids]\n                action_mask_b = action_space[1][g_bucket_ids]\n                e_b = e[l_batch_refs]\n                last_r_b = last_r[l_batch_refs]\n                e_s_b = e_s[l_batch_refs]\n                q_b = q[l_batch_refs]\n                e_t_b = e_t[l_batch_refs]\n                seen_nodes_b = seen_nodes[l_batch_refs]\n                obs_b = [e_s_b, q_b, e_t_b, last_step, last_r_b, seen_nodes_b]\n                action_space_b = ((r_space_b, e_space_b), action_mask_b)\n                action_space_b = self.apply_action_masks(action_space_b, e_b, obs_b, kg)\n                db_action_spaces.append(action_space_b)\n                db_references.append(l_batch_refs)\n\n        return db_action_spaces, db_references\n\n    def get_action_space(self, e, obs, kg):\n        r_space, e_space = kg.action_space[0][0][e], kg.action_space[0][1][e]\n        action_mask = kg.action_space[1][e]\n        action_space = ((r_space, e_space), action_mask)\n        return self.apply_action_masks(action_space, e, obs, kg)\n\n    def apply_action_masks(self, action_space, e, obs, kg):\n        (r_space, e_space), action_mask = action_space\n        e_s, q, e_t, last_step, last_r, seen_nodes = obs\n\n        # Prevent the agent from selecting the ground truth edge\n        ground_truth_edge_mask = self.get_ground_truth_edge_mask(e, r_space, e_space, e_s, q, e_t, kg)\n        action_mask -= ground_truth_edge_mask\n        self.validate_action_mask(action_mask)\n\n        # Mask out false negatives in the final step\n        if last_step:\n            false_negative_mask = self.get_false_negative_mask(e_space, e_s, q, e_t, kg)\n            action_mask *= (1 - false_negative_mask)\n            self.validate_action_mask(action_mask)\n\n        # Prevent the agent from stopping in the middle of a path\n        # stop_mask = (last_r == NO_OP_RELATION_ID).unsqueeze(1).float()\n        # action_mask = (1 - stop_mask) * action_mask + stop_mask * (r_space == NO_OP_RELATION_ID).float()\n        # Prevent loops\n        # Note: avoid duplicate removal of self-loops\n        # seen_nodes_b = seen_nodes[l_batch_refs]\n        # loop_mask_b = (((seen_nodes_b.unsqueeze(1) == e_space.unsqueeze(2)).sum(2) > 0) *\n        #      (r_space != NO_OP_RELATION_ID)).float()\n        # action_mask *= (1 - loop_mask_b)\n        return (r_space, e_space), action_mask\n\n    def get_ground_truth_edge_mask(self, e, r_space, e_space, e_s, q, e_t, kg):\n        ground_truth_edge_mask = \\\n            ((e == e_s).unsqueeze(1) * (r_space == q.unsqueeze(1)) * (e_space == e_t.unsqueeze(1)))\n        inv_q = kg.get_inv_relation_id(q)\n        inv_ground_truth_edge_mask = \\\n            ((e == e_t).unsqueeze(1) * (r_space == inv_q.unsqueeze(1)) * (e_space == e_s.unsqueeze(1)))\n        return ((ground_truth_edge_mask + inv_ground_truth_edge_mask) * (e_s.unsqueeze(1) != kg.dummy_e)).float()\n\n    def get_answer_mask(self, e_space, e_s, q, kg):\n        if kg.args.mask_test_false_negatives:\n            answer_vectors = kg.all_object_vectors\n        else:\n            answer_vectors = kg.train_object_vectors\n        answer_masks = []\n        for i in range(len(e_space)):\n            _e_s, _q = int(e_s[i]), int(q[i])\n            if not _e_s in answer_vectors or not _q in answer_vectors[_e_s]:\n                answer_vector = var_cuda(torch.LongTensor([[kg.num_entities]]))\n            else:\n                answer_vector = answer_vectors[_e_s][_q]\n            answer_mask = torch.sum(e_space[i].unsqueeze(0) == answer_vector, dim=0).long()\n            answer_masks.append(answer_mask)\n        answer_mask = torch.cat(answer_masks).view(len(e_space), -1)\n        return answer_mask\n\n    def get_false_negative_mask(self, e_space, e_s, q, e_t, kg):\n        answer_mask = self.get_answer_mask(e_space, e_s, q, kg)\n        # This is a trick applied during training where we convert a multi-answer predction problem into several\n        # single-answer prediction problems. By masking out the other answers in the training set, we are forcing\n        # the agent to walk towards a particular answer.\n        # This trick does not affect inference on the test set: at inference time the ground truth answer will not \n        # appear in the answer mask. This can be checked by uncommenting the following assertion statement. \n        # Note that the assertion statement can trigger in the last batch if you\'re using a batch_size > 1 since\n        # we append dummy examples to the last batch to make it the required batch size.\n        # The assertion statement will also trigger in the dev set inference of NELL-995 since we randomly \n        # sampled the dev set from the training data.\n        # assert(float((answer_mask * (e_space == e_t.unsqueeze(1)).long()).sum()) == 0)\n        false_negative_mask = (answer_mask * (e_space != e_t.unsqueeze(1)).long()).float()\n        return false_negative_mask\n\n    def validate_action_mask(self, action_mask):\n        action_mask_min = action_mask.min()\n        action_mask_max = action_mask.max()\n        assert (action_mask_min == 0 or action_mask_min == 1)\n        assert (action_mask_max == 0 or action_mask_max == 1)\n\n    def get_action_embedding(self, action, kg):\n        """"""\n        Return (batch) action embedding which is the concatenation of the embeddings of\n        the traversed edge and the target node.\n\n        :param action (r, e):\n            (Variable:batch) indices of the most recent action\n                - r is the most recently traversed edge\n                - e is the destination entity.\n        :param kg: Knowledge graph enviroment.\n        """"""\n        r, e = action\n        relation_embedding = kg.get_relation_embeddings(r)\n        if self.relation_only:\n            action_embedding = relation_embedding\n        else:\n            entity_embedding = kg.get_entity_embeddings(e)\n            action_embedding = torch.cat([relation_embedding, entity_embedding], dim=-1)\n        return action_embedding\n\n    def define_modules(self):\n        if self.relation_only:\n            input_dim = self.history_dim + self.relation_dim\n        elif self.relation_only_in_path:\n            input_dim = self.history_dim + self.entity_dim * 2 + self.relation_dim\n        else:\n            input_dim = self.history_dim + self.entity_dim + self.relation_dim\n        self.W1 = nn.Linear(input_dim, self.action_dim)\n        self.W2 = nn.Linear(self.action_dim, self.action_dim)\n        self.W1Dropout = nn.Dropout(p=self.ff_dropout_rate)\n        self.W2Dropout = nn.Dropout(p=self.ff_dropout_rate)\n        if self.relation_only_in_path:\n            self.path_encoder = nn.LSTM(input_size=self.relation_dim,\n                                        hidden_size=self.history_dim,\n                                        num_layers=self.history_num_layers,\n                                        batch_first=True)\n        else:\n            self.path_encoder = nn.LSTM(input_size=self.action_dim,\n                                        hidden_size=self.history_dim,\n                                        num_layers=self.history_num_layers,\n                                        batch_first=True)\n\n    def initialize_modules(self):\n        if self.xavier_initialization:\n            nn.init.xavier_uniform_(self.W1.weight)\n            nn.init.xavier_uniform_(self.W2.weight)\n            for name, param in self.path_encoder.named_parameters():\n                if \'bias\' in name:\n                    nn.init.constant_(param, 0.0)\n                elif \'weight\' in name:\n                    nn.init.xavier_normal_(param)\n'"
src/rl/graph_search/rs_pg.py,6,"b'""""""\n Copyright (c) 2018, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n \n Policy gradient with reward shaping.\n""""""\n\nfrom tqdm import tqdm\n\nimport torch\n\nfrom src.emb.fact_network import get_conve_nn_state_dict, get_conve_kg_state_dict, \\\n    get_complex_kg_state_dict, get_distmult_kg_state_dict\nfrom src.rl.graph_search.pg import PolicyGradient\nimport src.utils.ops as ops\nfrom src.utils.ops import zeros_var_cuda\n\n\nclass RewardShapingPolicyGradient(PolicyGradient):\n    def __init__(self, args, kg, pn, fn_kg, fn, fn_secondary_kg=None):\n        super(RewardShapingPolicyGradient, self).__init__(args, kg, pn)\n        self.reward_shaping_threshold = args.reward_shaping_threshold\n\n        # Fact network modules\n        self.fn_kg = fn_kg\n        self.fn = fn\n        self.fn_secondary_kg = fn_secondary_kg\n        self.mu = args.mu\n\n        fn_model = self.fn_model\n        if fn_model in [\'conve\']:\n            fn_state_dict = torch.load(args.conve_state_dict_path)\n            fn_nn_state_dict = get_conve_nn_state_dict(fn_state_dict)\n            fn_kg_state_dict = get_conve_kg_state_dict(fn_state_dict)\n            self.fn.load_state_dict(fn_nn_state_dict)\n        elif fn_model == \'distmult\':\n            fn_state_dict = torch.load(args.distmult_state_dict_path)\n            fn_kg_state_dict = get_distmult_kg_state_dict(fn_state_dict)\n        elif fn_model == \'complex\':\n            fn_state_dict = torch.load(args.complex_state_dict_path)\n            fn_kg_state_dict = get_complex_kg_state_dict(fn_state_dict)\n        elif fn_model == \'hypere\':\n            fn_state_dict = torch.load(args.conve_state_dict_path)\n            fn_kg_state_dict = get_conve_kg_state_dict(fn_state_dict)\n        else:\n            raise NotImplementedError\n        self.fn_kg.load_state_dict(fn_kg_state_dict)\n        if fn_model == \'hypere\':\n            complex_state_dict = torch.load(args.complex_state_dict_path)\n            complex_kg_state_dict = get_complex_kg_state_dict(complex_state_dict)\n            self.fn_secondary_kg.load_state_dict(complex_kg_state_dict)\n\n        self.fn.eval()\n        self.fn_kg.eval()\n        ops.detach_module(self.fn)\n        ops.detach_module(self.fn_kg)\n        if fn_model == \'hypere\':\n            self.fn_secondary_kg.eval()\n            ops.detach_module(self.fn_secondary_kg)\n\n    def reward_fun(self, e1, r, e2, pred_e2):\n        if self.model.endswith(\'.rso\'):\n            oracle_reward = forward_fact_oracle(e1, r, pred_e2, self.kg)\n            return oracle_reward\n        else:\n            if self.fn_secondary_kg:\n                real_reward = self.fn.forward_fact(e1, r, pred_e2, self.fn_kg, [self.fn_secondary_kg]).squeeze(1)\n            else:\n                real_reward = self.fn.forward_fact(e1, r, pred_e2, self.fn_kg).squeeze(1)\n            real_reward_mask = (real_reward > self.reward_shaping_threshold).float()\n            real_reward *= real_reward_mask\n            if self.model.endswith(\'rsc\'):\n                return real_reward\n            else:\n                binary_reward = (pred_e2 == e2).float()\n                return binary_reward + self.mu * (1 - binary_reward) * real_reward\n\n    def test_fn(self, examples):\n        fn_kg, fn = self.fn_kg, self.fn\n        pred_scores = []\n        for example_id in tqdm(range(0, len(examples), self.batch_size)):\n            mini_batch = examples[example_id:example_id + self.batch_size]\n            mini_batch_size = len(mini_batch)\n            if len(mini_batch) < self.batch_size:\n                self.make_full_batch(mini_batch, self.batch_size)\n            e1, e2, r = self.format_batch(mini_batch)\n            if self.fn_secondary_kg:\n                pred_score = fn.forward_fact(e1, r, e2, fn_kg, [self.fn_secondary_kg])\n            else:\n                pred_score = fn.forward_fact(e1, r, e2, fn_kg)\n            pred_scores.append(pred_score[:mini_batch_size])\n        return torch.cat(pred_scores)\n\n    @property\n    def fn_model(self):\n        return self.model.split(\'.\')[2]\n\ndef forward_fact_oracle(e1, r, e2, kg):\n    oracle = zeros_var_cuda([len(e1), kg.num_entities]).cuda()\n    for i in range(len(e1)):\n        _e1, _r = int(e1[i]), int(r[i])\n        if _e1 in kg.all_object_vectors and _r in kg.all_object_vectors[_e1]:\n            answer_vector = kg.all_object_vectors[_e1][_r]\n            oracle[i][answer_vector] = 1\n        else:\n            raise ValueError(\'Query answer not found\')\n    oracle_e2 = ops.batch_lookup(oracle, e2.unsqueeze(1))\n    return oracle_e2\n'"
