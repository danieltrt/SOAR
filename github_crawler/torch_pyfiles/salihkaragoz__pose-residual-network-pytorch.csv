file_path,api_count,code
opt.py,0,"b'import argparse\nfrom pprint import pprint\n\n\nclass Options:\n    def __init__(self):\n        self.parser = argparse.ArgumentParser()\n        self.opt = None\n\n    def _initial(self):\n\n        # --------------------------  General Training Options\n        self.parser.add_argument(\'--lr\', type=float, default=1.0e-3, help=\'Learning Rate\')\n        self.parser.add_argument(\'--lr_gamma\', type=float, default=0.9, help=\'Gamma Rate\')\n        self.parser.add_argument(\'--number_of_epoch\', type=int, default=16)\n        self.parser.add_argument(\'--num_workers\', type=int, default=4)\n        self.parser.add_argument(\'--batch_size\', type=int, default=8)\n        self.parser.add_argument(\'--node_count\', type=int, default=1024, help=\'Hidden Layer Node Count\')\n        # --------------------------  General Training Options\n\n        self.parser.add_argument(\'--exp\', type=str, default=\'test/\', help=\'Experiment name\')\n\n        # --------------------------\n        self.parser.add_argument(\'--coeff\', type=int, default=2, help=\'Coefficient of bbox size\')\n        self.parser.add_argument(\'--threshold\', type=int, default=0.21, help=\'BBOX threshold\')\n        self.parser.add_argument(\'--test_cp\', type=str,default=\'checkpoint/test/default.pth.tar\' ,help=\'Path to model for testing\')\n        self.parser.add_argument(\'--num_of_keypoints\', type=int, default=3, help=\'Minimum number of keypoints for each bbox in training\')\n        self.parser.add_argument(\'--test_keypoint_count\', type=int, default=0, help=\'Validating with different keypoint count\')\n        self.parser.add_argument(\'--window_size\', type=int, default=15, help=\'Windows size for cropping\')\n        # --------------------------\n\n    def _print(self):\n        print(""\\n==================Options================="")\n        pprint(vars(self.opt), indent=4)\n        print(""==========================================\\n"")\n\n    def parse(self):\n        self._initial()\n        self.opt = self.parser.parse_args()\n        self._print()\n        return self.opt\n\n'"
test.py,1,"b'import argparse\nimport torch\nfrom opt import Options\nfrom src.eval import Evaluation\nfrom src.model import PRN\n\n\n\nif __name__ == ""__main__"":\n    option = Options().parse()\n    \n    model = PRN(option.node_count, option.coeff).cuda()\n    checkpoint = torch.load(option.test_cp)\n    model.load_state_dict(checkpoint[\'state_dict\'])\n\n    Evaluation(model, option)\n\n \n'"
train.py,5,"b'import os\nfrom tqdm import tqdm\nfrom progress.bar import Bar\nfrom pycocotools.coco import COCO\n\nimport torch\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader\n\nfrom opt import Options\nfrom src.model import PRN\nfrom src.eval import Evaluation\nfrom src.utils import save_options\nfrom src.utils import save_model, adjust_lr\nfrom src.data_loader import CocoDataset\n\n\ndef main(optin):\n    if not os.path.exists(\'checkpoint/\'+optin.exp):\n        os.makedirs(\'checkpoint/\'+optin.exp)\n\n    model = PRN(optin.node_count,optin.coeff).cuda()\n    #model = torch.nn.DataParallel(model).cuda()\n    optimizer = torch.optim.Adam(model.parameters(), lr=optin.lr)\n    criterion = torch.nn.BCELoss().cuda()\n\n    print (model)\n    print("">>> total params: {:.2f}M"".format(sum(p.numel() for p in model.parameters()) / 1000000.0))\n\n    save_options(optin, os.path.join(\'checkpoint/\' + optin.exp), model.__str__(), criterion.__str__(), optimizer.__str__())\n\n    print (\'---------Loading Coco Training Set--------\')\n    coco_train = COCO(os.path.join(\'data/annotations/person_keypoints_train2017.json\'))\n    trainloader = DataLoader(dataset=CocoDataset(coco_train,optin),batch_size=optin.batch_size, num_workers=optin.num_workers, shuffle=True)\n\n    bar = Bar(\'-->\', fill=\'>\', max=len(trainloader))\n\n    cudnn.benchmark = True\n    for epoch in range(optin.number_of_epoch):\n        print (\'-------------Training Epoch {}-------------\'.format(epoch))\n        print (\'Total Step:\', len(trainloader), \'| Total Epoch:\', optin.number_of_epoch)\n        lr = adjust_lr(optimizer, epoch, optin.lr_gamma)\n        print(\'\\nEpoch: %d | LR: %.8f\' % (epoch + 1, lr))\n        for idx, (input, label) in tqdm(enumerate(trainloader)):\n\n            input = input.cuda().float()\n            label = label.cuda().float()\n\n            outputs = model(input)\n\n            optimizer.zero_grad()\n            loss = criterion(outputs, label)\n            loss.backward()\n            optimizer.step()\n\n            if idx % 200 == 0:\n                bar.suffix = \'Epoch: {epoch} Total: {ttl} | ETA: {eta:} | loss:{loss}\' \\\n                .format(ttl=bar.elapsed_td, eta=bar.eta_td, loss=loss.data, epoch=epoch)\n                bar.next()\n\n        Evaluation(model, optin)\n\n        save_model({\n            \'epoch\': epoch + 1,\n            \'state_dict\': model.state_dict(),\n            \'optimizer\' : optimizer.state_dict(),\n        }, checkpoint=\'checkpoint/\' + optin.exp)\n\n        model.train()\n\nif __name__ == ""__main__"":\n    option = Options().parse()\n    main(option)\n'"
src/__init__.py,0,"b'import os\nimport sys\n\nsys.path.append(os.path.join(os.path.dirname(__file__), ""progress""))\n'"
src/data_loader.py,1,"b""import math\nimport numpy as np\nfrom skimage.filters import gaussian\nfrom torch.utils.data import Dataset\n\nclass CocoDataset(Dataset):\n    def __init__(self,coco_train,opt):\n        self.coco_train = coco_train\n        self.num_of_keypoints = opt.num_of_keypoints\n        self.anns = self.get_anns(self.coco_train)\n        self.bbox_height = opt.coeff *28\n        self.bbox_width = opt.coeff *18\n        self.threshold = opt.threshold\n\n    def __len__(self):\n        return len(self.anns)\n\n    def __getitem__(self, item):\n        ann_data = self.anns[item]\n\n        input, label = self.get_data(ann_data, self.coco_train )\n\n        return input, label\n\n    def get_data(self, ann_data, coco):\n        weights = np.zeros((self.bbox_height, self.bbox_width, 17))\n        output = np.zeros((self.bbox_height, self.bbox_width, 17))\n\n        bbox = ann_data['bbox']\n        x = int(bbox[0])\n        y = int(bbox[1])\n        w = float(bbox[2])\n        h = float(bbox[3])\n\n        x_scale = float(self.bbox_width) / math.ceil(w)\n        y_scale = float(self.bbox_height) / math.ceil(h)\n\n        kpx = ann_data['keypoints'][0::3]\n        kpy = ann_data['keypoints'][1::3]\n        kpv = ann_data['keypoints'][2::3]\n\n\n        for j in range(17):\n            if kpv[j] > 0:\n                x0 = int((kpx[j] - x) * x_scale)\n                y0 = int((kpy[j] - y) * y_scale)\n\n                if x0 >= self.bbox_width and y0 >= self.bbox_height:\n                    output[self.bbox_height - 1, self.bbox_width - 1, j] = 1\n                elif x0 >= self.bbox_width:\n                    output[y0, self.bbox_width - 1, j] = 1\n                elif y0 >= self.bbox_height:\n                    try:\n                        output[self.bbox_height - 1, x0, j] = 1\n                    except:\n                        output[self.bbox_height - 1, 0, j] = 1\n                elif x0 < 0 and y0 < 0:\n                    output[0, 0, j] = 1\n                elif x0 < 0:\n                    output[y0, 0, j] = 1\n                elif y0 < 0:\n                    output[0, x0, j] = 1\n                else:\n                    output[y0, x0, j] = 1\n\n        img_id = ann_data['image_id']\n        img_data = coco.loadImgs(img_id)[0]\n        ann_data = coco.loadAnns(coco.getAnnIds(img_data['id']))\n\n        for ann in ann_data:\n            kpx = ann['keypoints'][0::3]\n            kpy = ann['keypoints'][1::3]\n            kpv = ann['keypoints'][2::3]\n\n            for j in range(17):\n                if kpv[j] > 0:\n                    if (kpx[j] > bbox[0] - bbox[2] * self.threshold and kpx[j] < bbox[0] + bbox[2] * (1 + self.threshold)):\n                        if (kpy[j] > bbox[1] - bbox[3] * self.threshold and kpy[j] < bbox[1] + bbox[3] * (1 + self.threshold)):\n                            x0 = int((kpx[j] - x) * x_scale)\n                            y0 = int((kpy[j] - y) * y_scale)\n\n                            if x0 >= self.bbox_width and y0 >= self.bbox_height:\n                                weights[self.bbox_height - 1, self.bbox_width - 1, j] = 1\n                            elif x0 >= self.bbox_width:\n                                weights[y0, self.bbox_width - 1, j] = 1\n                            elif y0 >= self.bbox_height:\n                                weights[self.bbox_height - 1, x0, j] = 1\n                            elif x0 < 0 and y0 < 0:\n                                weights[0, 0, j] = 1\n                            elif x0 < 0:\n                                weights[y0, 0, j] = 1\n                            elif y0 < 0:\n                                weights[0, x0, j] = 1\n                            else:\n                                weights[y0, x0, j] = 1\n\n        for t in range(17):\n            weights[:, :, t] = gaussian(weights[:, :, t])\n        output = gaussian(output, sigma=2, mode='constant', multichannel=True)\n        # weights = gaussian_multi_input_mp(weights)\n        # output = gaussian_multi_output(output)\n        return weights, output\n\n    def get_anns(self, coco):\n        #:param coco: COCO instance\n        #:return: anns: List of annotations that contain person with at least 6 keypoints\n        ann_ids = coco.getAnnIds()\n        anns = []\n        for i in ann_ids:\n            ann = coco.loadAnns(i)[0]\n            if ann['iscrowd'] == 0 and ann['num_keypoints'] > self.num_of_keypoints:\n                anns.append(ann)  # ann\n        sorted_list = sorted(anns, key=lambda k: k['num_keypoints'], reverse=True)\n        return sorted_list\n"""
src/eval.py,1,"b""import os\nimport math\nimport json\nimport argparse\nimport numpy as np\nfrom tqdm import tqdm\nfrom random import shuffle\n\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nfrom .gaussian import gaussian, crop, gaussian_multi_input_mp\n\nimport torch\n\ndef Evaluation(model,optin):\n    print ('------------Evaulation Started------------')\n    coeff = optin.coeff\n    in_thres = optin.threshold\n    test_keypoint_count = optin.test_keypoint_count\n    n_kernel = optin.window_size\n    modelname = 'temporary'\n\n    model.eval()\n\n    cocodir = 'data/annotations/person_keypoints_val2017.json'\n    ann = json.load(open(cocodir))\n    bbox_results = ann['annotations']\n\n    coco = COCO(cocodir)\n    img_ids = coco.getImgIds(catIds=[1])\n\n    peak_results = []\n\n    for i in img_ids:\n        anns = coco.loadAnns(coco.getAnnIds(imgIds=i))\n        kps = [a['keypoints'] for a in anns]\n\n        idx = 0\n\n        ks = []\n        for i in range(17):\n            t = []\n            for k in kps:\n                x = k[0::3][i]\n                y = k[1::3][i]\n                v = k[2::3][i]\n\n                if v > 0:\n                    t.append([x, y, 1, idx])\n                    idx += 1\n            ks.append(t)\n        image_id = anns[0]['image_id']\n        peaks = ks\n\n        element = {\n            'image_id': image_id,\n            'peaks': peaks,\n            'file_name': coco.loadImgs(image_id)[0]['file_name']\n        }\n\n        peak_results.append(element)\n\n    shuffle(peak_results)\n\n    my_results = []\n    image_ids = []\n\n    w = int(18 * coeff)\n    h = int(28 * coeff)\n\n    temporary_peak_res = []\n    for p in peak_results:\n        if (sum(1 for i in p['peaks'] if i != []) >= test_keypoint_count):\n            temporary_peak_res.append(p)\n    peak_results = temporary_peak_res\n\n    for p in tqdm(peak_results):\n        idx = p['image_id']\n        image_ids.append(idx)\n\n        peaks = p['peaks']\n        bboxes = [k['bbox'] for k in bbox_results if k['image_id'] == idx]\n\n\n        if len(bboxes) == 0 or len(peaks) == 0:\n            continue\n\n        weights_bbox = np.zeros((len(bboxes), h, w, 4, 17))\n\n        for joint_id, peak in enumerate(peaks):\n\n\n            for instance_id, instance in enumerate(peak):\n\n                p_x = instance[0]\n                p_y = instance[1]\n\n                for bbox_id, b in enumerate(bboxes):\n\n                    is_inside = p_x > b[0] - b[2] * in_thres and \\\n                                p_y > b[1] - b[3] * in_thres and \\\n                                p_x < b[0] + b[2] * (1.0 + in_thres) and \\\n                                p_y < b[1] + b[3] * (1.0 + in_thres)\n\n                    if is_inside:\n                        x_scale = float(w) / math.ceil(b[2])\n                        y_scale = float(h) / math.ceil(b[3])\n\n                        x0 = int((p_x - b[0]) * x_scale)\n                        y0 = int((p_y - b[1]) * y_scale)\n\n                        if x0 >= w and y0 >= h:\n                            x0 = w - 1\n                            y0 = h - 1\n                        elif x0 >= w:\n                            x0 = w - 1\n                        elif y0 >= h:\n                            y0 = h - 1\n                        elif x0 < 0 and y0 < 0:\n                            x0 = 0\n                            y0 = 0\n                        elif x0 < 0:\n                            x0 = 0\n                        elif y0 < 0:\n                            y0 = 0\n\n                        p = 1e-9\n\n                        weights_bbox[bbox_id, y0, x0, :, joint_id] = [1, instance[2], instance[3], p]\n\n        old_weights_bbox = np.copy(weights_bbox)\n\n        for j in range(weights_bbox.shape[0]):\n            for t in range(17):\n                weights_bbox[j, :, :, 0, t] = gaussian(weights_bbox[j, :, :, 0, t])\n            # weights_bbox[j, :, :, 0, :]      = gaussian_multi_input_mp(weights_bbox[j, :, :, 0, :])\n\n        output_bbox = []\n        for j in range(weights_bbox.shape[0]):\n            inp = weights_bbox[j, :, :, 0, :]\n            input = torch.from_numpy(np.expand_dims(inp, axis=0)).cuda().float()\n            output = model(input)\n            temp = np.reshape(output.data.cpu().numpy(), (56,36,17))\n            output_bbox.append(temp)\n\n        output_bbox = np.array(output_bbox)\n\n        keypoints_score = []\n\n        for t in range(17):\n            indexes = np.argwhere(old_weights_bbox[:, :, :, 0, t] == 1)\n            keypoint = []\n            for i in indexes:\n                cr = crop(output_bbox[i[0], :, :, t], (i[1], i[2]), N=n_kernel)\n                score = np.sum(cr)\n\n                kp_id = old_weights_bbox[i[0], i[1], i[2], 2, t]\n                kp_score = old_weights_bbox[i[0], i[1], i[2], 1, t]\n                p_score = old_weights_bbox[i[0], i[1], i[2], 3, t]  ## ??\n                bbox_id = i[0]\n\n                score = kp_score * score\n\n                s = [kp_id, bbox_id, kp_score, score]\n\n                keypoint.append(s)\n            keypoints_score.append(keypoint)\n\n        bbox_keypoints = np.zeros((weights_bbox.shape[0], 17, 3))\n        bbox_ids = np.arange(len(bboxes)).tolist()\n\n        # kp_id, bbox_id, kp_score, my_score\n        for i in range(17):\n            joint_keypoints = keypoints_score[i]\n            if len(joint_keypoints) > 0:\n\n                kp_ids = list(set([x[0] for x in joint_keypoints]))\n\n                table = np.zeros((len(bbox_ids), len(kp_ids), 4))\n\n                for b_id, bbox in enumerate(bbox_ids):\n                    for k_id, kp in enumerate(kp_ids):\n                        own = [x for x in joint_keypoints if x[0] == kp and x[1] == bbox]\n\n                        if len(own) > 0:\n                            table[bbox, k_id] = own[0]\n                        else:\n                            table[bbox, k_id] = [0] * 4\n\n                for b_id, bbox in enumerate(bbox_ids):\n\n                    row = np.argsort(-table[bbox, :, 3])\n\n                    if table[bbox, row[0], 3] > 0:\n                        for r in row:\n                            if table[bbox, r, 3] > 0:\n                                column = np.argsort(-table[:, r, 3])\n\n                                if bbox == column[0]:\n                                    bbox_keypoints[bbox, i, :] = [x[:3] for x in peaks[i] if x[3] == table[bbox, r, 0]][0]\n                                    break\n                                else:\n                                    row2 = np.argsort(table[column[0], :, 3])\n                                    if row2[0] == r:\n                                        bbox_keypoints[bbox, i, :] = \\\n                                        [x[:3] for x in peaks[i] if x[3] == table[bbox, r, 0]][0]\n                                        break\n            else:\n                for j in range(weights_bbox.shape[0]):\n                    b = bboxes[j]\n                    x_scale = float(w) / math.ceil(b[2])\n                    y_scale = float(h) / math.ceil(b[3])\n\n                    for t in range(17):\n                        indexes = np.argwhere(old_weights_bbox[j, :, :, 0, t] == 1)\n                        if len(indexes) == 0:\n                            max_index = np.argwhere(output_bbox[j, :, :, t] == np.max(output_bbox[j, :, :, t]))\n                            bbox_keypoints[j, t, :] = [max_index[0][1] / x_scale + b[0],\n                                                       max_index[0][0] / y_scale + b[1], 0]\n\n        my_keypoints = []\n\n        for i in range(bbox_keypoints.shape[0]):\n            k = np.zeros(51)\n            k[0::3] = bbox_keypoints[i, :, 0]\n            k[1::3] = bbox_keypoints[i, :, 1]\n            k[2::3] = [2] * 17\n\n            pose_score = 0\n            count = 0\n            for f in range(17):\n                if bbox_keypoints[i, f, 0] != 0 and bbox_keypoints[i, f, 1] != 0:\n                    count += 1\n                pose_score += bbox_keypoints[i, f, 2]\n            pose_score /= 17.0\n\n            my_keypoints.append(k)\n\n            image_data = {\n                'image_id': idx,\n                'bbox': bboxes[i],\n                'score': pose_score,\n                'category_id': 1,\n                'keypoints': k.tolist()\n            }\n            my_results.append(image_data)\n\n\n    ann_filename = 'data/val2017_PRN_keypoint_results_{}.json'.format(modelname)\n    # write output\n    json.dump(my_results, open(ann_filename, 'w'), indent=4)\n\n    # load results in COCO evaluation tool\n    coco_pred = coco.loadRes(ann_filename)\n\n    # run COCO evaluation\n    coco_eval = COCOeval(coco, coco_pred, 'keypoints')\n    coco_eval.params.imgIds = image_ids\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n\n    os.remove(ann_filename)\n\n\n"""
src/gaussian.py,0,"b""import numpy as np\nfrom skimage.filters import gaussian\n\nsigmas = np.array([.26, .25, .25, .35, .35, .79, .79, .72, .72, .62, .62, 1.07, 1.07, .87, .87, .89, .89] * 100)\n\n\ndef multivariate_gaussian(N, sigma=2):\n    t = 4\n    X = np.linspace(-t, t, N)\n    Y = np.linspace(-t, t, N)\n    X, Y = np.meshgrid(X, Y)\n    pos = np.empty(X.shape + (2,))\n    pos[:, :, 0] = X\n    pos[:, :, 1] = Y\n    mu = np.array([0., 0.])\n    sigma = np.array([[sigma, 0], [0, sigma]])\n    n = mu.shape[0]\n    Sigma_det = np.linalg.det(sigma)\n    Sigma_inv = np.linalg.inv(sigma)\n    N = np.sqrt((2 * np.pi) ** n * Sigma_det)\n    fac = np.einsum('...k,kl,...l->...', pos - mu, Sigma_inv, pos - mu)\n    return np.exp(-fac / 2) / N\n\n\ndef crop_paste(img, c, N=13, sigma=2):\n    Z = multivariate_gaussian(N, sigma)\n\n    H = img.shape[1]\n    W = img.shape[0]\n\n    h = (Z.shape[0] - 1) / 2\n\n    N = Z.shape[0]\n    x1 = (c[0] - h)\n    y1 = (c[1] - h)\n\n    x2 = (c[0] + h) + 1\n    y2 = (c[1] + h) + 1\n\n    zx1 = 0\n    zy1 = 0\n    zx2 = N + 1\n    zy2 = N + 1\n\n    if x1 < 0:\n        x1 = 0\n        zx1 = 0 - (c[0] - h)\n\n    if y1 < 0:\n        y1 = 0\n        zy1 = 0 - (c[1] - h)\n\n    if x2 > W - 1:\n        x2 = W - 1\n        zx2 = x2 - x1 + 1\n        x2 = W\n\n    if y2 > H - 1:\n        y2 = H - 1\n        zy2 = y2 - y1 + 1\n        y2 = H\n\n    img[x1:x2, y1:y2] = np.maximum(Z[zx1:zx2, zy1:zy2], img[x1:x2, y1:y2])\n\n\n'''\ndef gaussian(img, N = 13, sigma=2):\n    cs = np.where(img==1)\n    img = np.zeros_like(img)\n    for c in zip(cs[0], cs[1]):\n        crop_paste(img, c, N, sigma)\n    return img\n'''\n\n\ndef gaussian_multi_input_mp(inp):\n    '''\n    :param inp: Multi person ground truth heatmap input (17 ch) Each channel contains multiple joints.\n    :return: out: Gaussian augmented output. Values are between 0. and 1.\n    '''\n\n    h, w, ch = inp.shape\n    out = np.zeros_like(inp)\n    for i in range(ch):\n        layer = inp[:, :, i]\n        ind = np.argwhere(layer == 1)\n        b = []\n        if len(ind) > 0:\n            for j in ind:\n                t = np.zeros((h, w))\n                t[j[0], j[1]] = 1\n                t = gaussian(t, sigma=2, mode='constant')\n                t = t * (1 / t.max())\n                b.append(t)\n\n            out[:, :, i] = np.maximum.reduce(b)\n        else:\n            out[:, :, i] = np.zeros((h, w))\n    return out\n\n\ndef gaussian_multi_output(inp):\n    '''\n    :param inp: Single person ground truth heatmap input (17 ch) Each channel contains one joint.\n    :return: out: Gaussian augmented output. Values are between 0. and 1.\n    '''\n    h, w, ch = inp.shape\n    out = np.zeros_like(inp)\n    for i in range(ch):\n        j = np.argwhere(inp[:, :, i] == 1)\n        if len(j) == 0:\n            out[:, :, i] = np.zeros((h, w))\n            continue\n        j = j[0]\n        t = np.zeros((h, w))\n        t[j[0], j[1]] = 1\n        t = gaussian(t, sigma=5, mode='constant')\n        out[:, :, i] = t * (1 / t.max())\n    return out\n\n\ndef crop(img, c, N=13):\n    H = img.shape[1]\n    W = img.shape[0]\n\n    h = (N - 1) / 2\n\n    x1 = int(c[0] - h)\n    y1 = int(c[1] - h)\n\n    x2 = int(c[0] + h) + 1\n    y2 = int(c[1] + h) + 1\n\n    if x1 < 0:\n        x1 = 0\n\n    if y1 < 0:\n        y1 = 0\n\n    if x2 > W - 1:\n        x2 = W\n\n    if y2 > H - 1:\n        y2 = H\n\n    return img[x1:x2, y1:y2]\n\n"""
src/model.py,2,"b'\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nclass Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n\n\nclass Add(nn.Module):\n    def forward(self, input1, input2):\n        return torch.add(input1, input2)\n\nclass PRN(nn.Module):\n    def __init__(self,node_count,coeff):\n        super(PRN, self).__init__()\n        self.flatten   = Flatten()\n        self.height    = coeff*28\n        self.width     = coeff*18\n        self.dens1     = nn.Linear(self.height*self.width*17, node_count)\n        self.bneck     = nn.Linear(node_count, node_count)\n        self.dens2     = nn.Linear(node_count, self.height*self.width*17)\n        self.drop      = nn.Dropout()\n        self.add       = Add()\n        self.softmax   = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        res = self.flatten(x)\n        out = self.drop(F.relu(self.dens1(res)))\n        out = self.drop(F.relu(self.bneck(out)))\n        out = F.relu(self.dens2(out))\n        out = self.add(out,res)\n        out = self.softmax(out)\n        out = out.view(out.size()[0],self.height, self.width, 17)\n\n        return out\n\n'"
src/utils.py,1,"b'import os\nimport json\nimport torch\n\ndef save_options(opt, path,model,criterion, optimizer):\n    file_path = os.path.join(path, \'opt.json\')\n    model_struc = model.__str__()\n    model_struc = {\'Model\': model_struc, \'Loss Function\': criterion, \'Optimizer\': optimizer}\n\n    with open(file_path, \'w\') as f:\n        f.write(json.dumps(vars(opt), sort_keys=True, indent=4))\n        f.write(json.dumps(model_struc, sort_keys=True, indent=4))\n\n\ndef save_model(state, checkpoint, filename=\'checkpoint.pth.tar\'):\n    filename = \'epoch\'+str(state[\'epoch\']) + filename\n    filepath = os.path.join(checkpoint, filename)\n    torch.save(state, filepath)\n\ndef adjust_lr(optimizer, epoch, gamma):\n    schedule = list(range(3,32,2))\n    """"""Sets the learning rate to the initial LR decayed by schedule""""""\n    if epoch in schedule:\n        for param_group in optimizer.param_groups:\n            param_group[\'lr\'] *= gamma\n    return optimizer.state_dict()[\'param_groups\'][0][\'lr\']\n'"
