file_path,api_count,code
wae_gan.py,16,"b'import argparse\nimport torch\nimport os\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import transforms\nfrom torchvision.utils import save_image\nfrom torch.optim.lr_scheduler import StepLR\n\ntorch.manual_seed(123)\n\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST WAE-GAN\')\nparser.add_argument(\'-batch_size\', type=int, default=100, metavar=\'N\', help=\'input batch size for training (default: 100)\')\nparser.add_argument(\'-epochs\', type=int, default=100, help=\'number of epochs to train (default: 100)\')\nparser.add_argument(\'-lr\', type=float, default=0.0001, help=\'learning rate (default: 0.0001)\')\nparser.add_argument(\'-dim_h\', type=int, default=128, help=\'hidden dimension (default: 128)\')\nparser.add_argument(\'-n_z\', type=int, default=8, help=\'hidden dimension of z (default: 8)\')\nparser.add_argument(\'-LAMBDA\', type=float, default=10, help=\'regularization coef MMD term (default: 10)\')\nparser.add_argument(\'-n_channel\', type=int, default=1, help=\'input channels (default: 1)\')\nparser.add_argument(\'-sigma\', type=float, default=1, help=\'variance of hidden dimension (default: 1)\')\nargs = parser.parse_args()\n\ntrainset = MNIST(root=\'./data/\',\n                 train=True,\n                 transform=transforms.ToTensor(),\n                 download=True)\n\ntestset = MNIST(root=\'./data/\',\n                 train=False,\n                 transform=transforms.ToTensor(),\n                 download=True)\n\ntrain_loader = DataLoader(dataset=trainset,\n                          batch_size=args.batch_size,\n                          shuffle=True)\n\ntest_loader = DataLoader(dataset=testset,\n                         batch_size=104,\n                         shuffle=False)\n\ndef free_params(module: nn.Module):\n    for p in module.parameters():\n        p.requires_grad = True\n\ndef frozen_params(module: nn.Module):\n    for p in module.parameters():\n        p.requires_grad = False\n\nclass Encoder(nn.Module):\n    def __init__(self, args):\n        super(Encoder, self).__init__()\n\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n\n        self.main = nn.Sequential(\n            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 2),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 4),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 8),\n            nn.ReLU(True),\n        )\n        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n\n    def forward(self, x):\n        x = self.main(x)\n        x = x.squeeze()\n        x = self.fc(x)\n        return x\n\nclass Decoder(nn.Module):\n    def __init__(self, args):\n        super(Decoder, self).__init__()\n\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n\n        self.proj = nn.Sequential(\n            nn.Linear(self.n_z, self.dim_h * 8 * 7 * 7),\n            nn.ReLU()\n        )\n\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),\n            nn.BatchNorm2d(self.dim_h * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),\n            nn.BatchNorm2d(self.dim_h * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(self.dim_h * 2, 1, 4, stride=2),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.proj(x)\n        x = x.view(-1, self.dim_h * 8, 7, 7)\n        x = self.main(x)\n        return x\n\nclass Discriminator(nn.Module):\n    def __init__(self, args):\n        super(Discriminator, self).__init__()\n\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n\n        self.main = nn.Sequential(\n            nn.Linear(self.n_z, self.dim_h * 4),\n            nn.ReLU(True),\n            nn.Linear(self.dim_h * 4, self.dim_h * 4),\n            nn.ReLU(True),\n            nn.Linear(self.dim_h * 4, self.dim_h * 4),\n            nn.ReLU(True),\n            nn.Linear(self.dim_h * 4, self.dim_h * 4),\n            nn.ReLU(True),\n            nn.Linear(self.dim_h * 4, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.main(x)\n        return x\n\nencoder, decoder, discriminator = Encoder(args), Decoder(args), Discriminator(args)\ncriterion = nn.MSELoss()\n\nencoder.train()\ndecoder.train()\ndiscriminator.train()\n\n# Optimizers\nenc_optim = optim.Adam(encoder.parameters(), lr = args.lr)\ndec_optim = optim.Adam(decoder.parameters(), lr = args.lr)\ndis_optim = optim.Adam(discriminator.parameters(), lr = 0.5 * args.lr)\n\nenc_scheduler = StepLR(enc_optim, step_size=30, gamma=0.5)\ndec_scheduler = StepLR(dec_optim, step_size=30, gamma=0.5)\ndis_scheduler = StepLR(dis_optim, step_size=30, gamma=0.5)\n\nif torch.cuda.is_available():\n    encoder, decoder, discriminator = encoder.cuda(), decoder.cuda(), discriminator.cuda()\n\none = torch.Tensor([1])\nmone = one * -1\n\nif torch.cuda.is_available():\n    one = one.cuda()\n    mone = mone.cuda()\n\nfor epoch in range(args.epochs):\n    step = 0\n\n    for images, _ in tqdm(train_loader):\n\n        if torch.cuda.is_available():\n            images = images.cuda()\n\n        encoder.zero_grad()\n        decoder.zero_grad()\n        discriminator.zero_grad()\n\n        # ======== Train Discriminator ======== #\n\n        frozen_params(decoder)\n        frozen_params(encoder)\n        free_params(discriminator)\n\n        z_fake = torch.randn(images.size()[0], args.n_z) * args.sigma\n\n        if torch.cuda.is_available():\n            z_fake = z_fake.cuda()\n\n        d_fake = discriminator(z_fake)\n\n        z_real = encoder(images)\n        d_real = discriminator(z_real)\n\n        torch.log(d_fake).mean().backward(mone)\n        torch.log(1 - d_real).mean().backward(mone)\n\n        dis_optim.step()\n\n        # ======== Train Generator ======== #\n\n        free_params(decoder)\n        free_params(encoder)\n        frozen_params(discriminator)\n\n        batch_size = images.size()[0]\n\n        z_real = encoder(images)\n        x_recon = decoder(z_real)\n        d_real = discriminator(encoder(Variable(images.data)))\n\n        recon_loss = criterion(x_recon, images)\n        d_loss = args.LAMBDA * (torch.log(d_real)).mean()\n\n        recon_loss.backward(one)\n        d_loss.backward(mone)\n\n        enc_optim.step()\n        dec_optim.step()\n\n        step += 1\n\n        if (step + 1) % 300 == 0:\n            print(""Epoch: [%d/%d], Step: [%d/%d], Reconstruction Loss: %.4f"" %\n                  (epoch + 1, args.epochs, step + 1, len(train_loader), recon_loss.data.item()))\n\n    if (epoch + 1) % 1 == 0:\n        batch_size = 104\n        test_iter = iter(test_loader)\n        test_data = next(test_iter)\n\n        z_real = encoder(Variable(test_data[0]).cuda())\n        reconst = decoder(torch.randn_like(z_real)).cpu().view(batch_size, 1, 28, 28)\n\n        if not os.path.isdir(\'./data/reconst_images\'):\n            os.makedirs(\'data/reconst_images\')\n\n        save_image(test_data[0].view(batch_size, 1, 28, 28), \'./data/reconst_images/wae_gan_input.png\')\n        save_image(reconst.data, \'./data/reconst_images/wae_gan_images_%d.png\' % (epoch + 1))'"
wae_mmd.py,33,"b'import argparse\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import transforms\nfrom torchvision.utils import save_image\nfrom torch.optim.lr_scheduler import StepLR\n\ntorch.manual_seed(123)\n\nparser = argparse.ArgumentParser(description=\'PyTorch MNIST WAE-MMD\')\nparser.add_argument(\'-batch_size\', type=int, default=100, metavar=\'N\',\n                    help=\'input batch size for training (default: 100)\')\nparser.add_argument(\'-epochs\', type=int, default=100, help=\'number of epochs to train (default: 100)\')\nparser.add_argument(\'-lr\', type=float, default=0.0001, help=\'learning rate (default: 0.0001)\')\nparser.add_argument(\'-dim_h\', type=int, default=128, help=\'hidden dimension (default: 128)\')\nparser.add_argument(\'-n_z\', type=int, default=8, help=\'hidden dimension of z (default: 8)\')\nparser.add_argument(\'-LAMBDA\', type=float, default=10, help=\'regularization coef MMD term (default: 10)\')\nparser.add_argument(\'-n_channel\', type=int, default=1, help=\'input channels (default: 1)\')\nparser.add_argument(\'-sigma\', type=float, default=1, help=\'variance of hidden dimension (default: 1)\')\nargs = parser.parse_args()\n\ntrainset = MNIST(root=\'./data/\',\n                 train=True,\n                 transform=transforms.ToTensor(),\n                 download=True)\n\ntestset = MNIST(root=\'./data/\',\n                train=False,\n                transform=transforms.ToTensor(),\n                download=True)\n\ntrain_loader = DataLoader(dataset=trainset,\n                          batch_size=args.batch_size,\n                          shuffle=True)\n\ntest_loader = DataLoader(dataset=testset,\n                         batch_size=104,\n                         shuffle=False)\n\n\ndef free_params(module: nn.Module):\n    for p in module.parameters():\n        p.requires_grad = True\n\n\ndef frozen_params(module: nn.Module):\n    for p in module.parameters():\n        p.requires_grad = False\n\n\nclass Encoder(nn.Module):\n    def __init__(self, args):\n        super(Encoder, self).__init__()\n\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n\n        self.main = nn.Sequential(\n            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 2),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 4),\n            nn.ReLU(True),\n            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(self.dim_h * 8),\n            nn.ReLU(True),\n        )\n        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n\n    def forward(self, x):\n        x = self.main(x)\n        x = x.squeeze()\n        x = self.fc(x)\n        return x\n\n\nclass Decoder(nn.Module):\n    def __init__(self, args):\n        super(Decoder, self).__init__()\n\n        self.n_channel = args.n_channel\n        self.dim_h = args.dim_h\n        self.n_z = args.n_z\n\n        self.proj = nn.Sequential(\n            nn.Linear(self.n_z, self.dim_h * 8 * 7 * 7),\n            nn.ReLU()\n        )\n\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),\n            nn.BatchNorm2d(self.dim_h * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),\n            nn.BatchNorm2d(self.dim_h * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(self.dim_h * 2, 1, 4, stride=2),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.proj(x)\n        x = x.view(-1, self.dim_h * 8, 7, 7)\n        x = self.main(x)\n        return x\n\n\ndef imq_kernel(X: torch.Tensor,\n               Y: torch.Tensor,\n               h_dim: int):\n    batch_size = X.size(0)\n\n    p2_norm_x = X.pow(2).sum(1).unsqueeze(0)\n    norms_x = X.sum(1).unsqueeze(0)\n    prods_x = torch.mm(norms_x, norms_x.t())\n    dists_x = p2_norm_x + p2_norm_x.t() - 2 * prods_x\n\n    p2_norm_y = Y.pow(2).sum(1).unsqueeze(0)\n    norms_y = X.sum(1).unsqueeze(0)\n    prods_y = torch.mm(norms_y, norms_y.t())\n    dists_y = p2_norm_y + p2_norm_y.t() - 2 * prods_y\n\n    dot_prd = torch.mm(norms_x, norms_y.t())\n    dists_c = p2_norm_x + p2_norm_y.t() - 2 * dot_prd\n\n    stats = 0\n    for scale in [.1, .2, .5, 1., 2., 5., 10.]:\n        C = 2 * h_dim * 1.0 * scale\n        res1 = C / (C + dists_x)\n        res1 += C / (C + dists_y)\n\n        if torch.cuda.is_available():\n            res1 = (1 - torch.eye(batch_size).cuda()) * res1\n        else:\n            res1 = (1 - torch.eye(batch_size)) * res1\n\n        res1 = res1.sum() / (batch_size - 1)\n        res2 = C / (C + dists_c)\n        res2 = res2.sum() * 2. / (batch_size)\n        stats += res1 - res2\n\n    return stats\n\n\ndef rbf_kernel(X: torch.Tensor,\n               Y: torch.Tensor,\n               h_dim: int):\n    batch_size = X.size(0)\n\n    p2_norm_x = X.pow(2).sum(1).unsqueeze(0)\n    norms_x = X.sum(1).unsqueeze(0)\n    prods_x = torch.mm(norms_x, norms_x.t())\n    dists_x = p2_norm_x + p2_norm_x.t() - 2 * prods_x\n\n    p2_norm_y = Y.pow(2).sum(1).unsqueeze(0)\n    norms_y = X.sum(1).unsqueeze(0)\n    prods_y = torch.mm(norms_y, norms_y.t())\n    dists_y = p2_norm_y + p2_norm_y.t() - 2 * prods_y\n\n    dot_prd = torch.mm(norms_x, norms_y.t())\n    dists_c = p2_norm_x + p2_norm_y.t() - 2 * dot_prd\n\n    stats = 0\n    for scale in [.1, .2, .5, 1., 2., 5., 10.]:\n        C = 2 * h_dim * 1.0 / scale\n        res1 = torch.exp(-C * dists_x)\n        res1 += torch.exp(-C * dists_y)\n\n        if torch.cuda.is_available():\n            res1 = (1 - torch.eye(batch_size).cuda()) * res1\n        else:\n            res1 = (1 - torch.eye(batch_size)) * res1\n\n        res1 = res1.sum() / (batch_size - 1)\n        res2 = torch.exp(-C * dists_c)\n        res2 = res2.sum() * 2. / batch_size\n        stats += res1 - res2\n\n    return stats\n\n\nencoder, decoder = Encoder(args), Decoder(args)\ncriterion = nn.MSELoss()\n\nencoder.train()\ndecoder.train()\n\nif torch.cuda.is_available():\n    encoder, decoder = encoder.cuda(), decoder.cuda()\n\none = torch.Tensor([1])\nmone = one * -1\n\nif torch.cuda.is_available():\n    one = one.cuda()\n    mone = mone.cuda()\n\n# Optimizers\nenc_optim = optim.Adam(encoder.parameters(), lr=args.lr)\ndec_optim = optim.Adam(decoder.parameters(), lr=args.lr)\n\nenc_scheduler = StepLR(enc_optim, step_size=30, gamma=0.5)\ndec_scheduler = StepLR(dec_optim, step_size=30, gamma=0.5)\n\nfor epoch in range(args.epochs):\n    step = 0\n    for (images, _) in tqdm(train_loader):\n\n        if torch.cuda.is_available():\n            images = images.cuda()\n\n        enc_optim.zero_grad()\n        dec_optim.zero_grad()\n\n        # ======== Train Generator ======== #\n\n        batch_size = images.size()[0]\n\n        z = encoder(images)\n        x_recon = decoder(z)\n\n        recon_loss = criterion(x_recon, images)\n\n        # ======== MMD Kernel Loss ======== #\n\n        z_fake = Variable(torch.randn(images.size()[0], args.n_z) * args.sigma)\n        if torch.cuda.is_available():\n            z_fake = z_fake.cuda()\n\n        z_real = encoder(images)\n\n        mmd_loss = imq_kernel(z_real, z_fake, h_dim=encoder.n_z)\n        mmd_loss = mmd_loss.mean()\n\n        total_loss = recon_loss - mmd_loss\n        total_loss.backward()\n\n        enc_optim.step()\n        dec_optim.step()\n\n        step += 1\n\n        if (step + 1) % 300 == 0:\n            print(""Epoch: [%d/%d], Step: [%d/%d], Reconstruction Loss: %.4f"" %\n                  (epoch + 1, args.epochs, step + 1, len(train_loader), recon_loss.data.item()))\n\n    if (epoch + 1) % 1 == 0:\n        batch_size = 104\n        test_iter = iter(test_loader)\n        test_data = next(test_iter)\n\n        z_real = encoder(Variable(test_data[0]).cuda())\n        reconst = decoder(torch.randn_like(z_real)).cpu().view(batch_size, 1, 28, 28)\n\n        if not os.path.isdir(\'./data/reconst_images\'):\n            os.makedirs(\'data/reconst_images\')\n\n        save_image(test_data[0].view(-1, 1, 28, 28), \'./data/reconst_images/wae_mmd_input.png\')\n        save_image(reconst.data, \'./data/reconst_images/wae_mmd_images_%d.png\' % (epoch + 1))'"
