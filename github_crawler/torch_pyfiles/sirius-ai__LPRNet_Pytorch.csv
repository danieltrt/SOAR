file_path,api_count,code
test_LPRNet.py,9,"b'# -*- coding: utf-8 -*-\n# /usr/bin/env/python3\n\n\'\'\'\ntest pretrained model.\nAuthor: aiboy.wei@outlook.com .\n\'\'\'\n\nfrom data.load_data import CHARS, CHARS_DICT, LPRDataLoader\nfrom PIL import Image, ImageDraw, ImageFont\nfrom model.LPRNet import build_lprnet\n# import torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.utils.data import *\nfrom torch import optim\nimport torch.nn as nn\nimport numpy as np\nimport argparse\nimport torch\nimport time\nimport cv2\nimport os\n\ndef get_parser():\n    parser = argparse.ArgumentParser(description=\'parameters to train net\')\n    parser.add_argument(\'--img_size\', default=[94, 24], help=\'the image size\')\n    parser.add_argument(\'--test_img_dirs\', default=""./data/test"", help=\'the test images path\')\n    parser.add_argument(\'--dropout_rate\', default=0, help=\'dropout rate.\')\n    parser.add_argument(\'--lpr_max_len\', default=8, help=\'license plate number max length.\')\n    parser.add_argument(\'--test_batch_size\', default=100, help=\'testing batch size.\')\n    parser.add_argument(\'--phase_train\', default=False, type=bool, help=\'train or test phase flag.\')\n    parser.add_argument(\'--num_workers\', default=8, type=int, help=\'Number of workers used in dataloading\')\n    parser.add_argument(\'--cuda\', default=True, type=bool, help=\'Use cuda to train model\')\n    parser.add_argument(\'--show\', default=False, type=bool, help=\'show test image and its predict result or not.\')\n    parser.add_argument(\'--pretrained_model\', default=\'./weights/Final_LPRNet_model.pth\', help=\'pretrained base model\')\n\n    args = parser.parse_args()\n\n    return args\n\ndef collate_fn(batch):\n    imgs = []\n    labels = []\n    lengths = []\n    for _, sample in enumerate(batch):\n        img, label, length = sample\n        imgs.append(torch.from_numpy(img))\n        labels.extend(label)\n        lengths.append(length)\n    labels = np.asarray(labels).flatten().astype(np.float32)\n\n    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n\ndef test():\n    args = get_parser()\n\n    lprnet = build_lprnet(lpr_max_len=args.lpr_max_len, phase=args.phase_train, class_num=len(CHARS), dropout_rate=args.dropout_rate)\n    device = torch.device(""cuda:0"" if args.cuda else ""cpu"")\n    lprnet.to(device)\n    print(""Successful to build network!"")\n\n    # load pretrained model\n    if args.pretrained_model:\n        lprnet.load_state_dict(torch.load(args.pretrained_model))\n        print(""load pretrained model successful!"")\n    else:\n        print(""[Error] Can\'t found pretrained mode, please check!"")\n        return False\n\n    test_img_dirs = os.path.expanduser(args.test_img_dirs)\n    test_dataset = LPRDataLoader(test_img_dirs.split(\',\'), args.img_size, args.lpr_max_len)\n    try:\n        Greedy_Decode_Eval(lprnet, test_dataset, args)\n    finally:\n        cv2.destroyAllWindows()\n\ndef Greedy_Decode_Eval(Net, datasets, args):\n    # TestNet = Net.eval()\n    epoch_size = len(datasets) // args.test_batch_size\n    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n\n    Tp = 0\n    Tn_1 = 0\n    Tn_2 = 0\n    t1 = time.time()\n    for i in range(epoch_size):\n        # load train data\n        images, labels, lengths = next(batch_iterator)\n        start = 0\n        targets = []\n        for length in lengths:\n            label = labels[start:start+length]\n            targets.append(label)\n            start += length\n        targets = np.array([el.numpy() for el in targets])\n        imgs = images.numpy().copy()\n\n        if args.cuda:\n            images = Variable(images.cuda())\n        else:\n            images = Variable(images)\n\n        # forward\n        prebs = Net(images)\n        # greedy decode\n        prebs = prebs.cpu().detach().numpy()\n        preb_labels = list()\n        for i in range(prebs.shape[0]):\n            preb = prebs[i, :, :]\n            preb_label = list()\n            for j in range(preb.shape[1]):\n                preb_label.append(np.argmax(preb[:, j], axis=0))\n            no_repeat_blank_label = list()\n            pre_c = preb_label[0]\n            if pre_c != len(CHARS) - 1:\n                no_repeat_blank_label.append(pre_c)\n            for c in preb_label: # dropout repeate label and blank label\n                if (pre_c == c) or (c == len(CHARS) - 1):\n                    if c == len(CHARS) - 1:\n                        pre_c = c\n                    continue\n                no_repeat_blank_label.append(c)\n                pre_c = c\n            preb_labels.append(no_repeat_blank_label)\n        for i, label in enumerate(preb_labels):\n            # show image and its predict label\n            if args.show:\n                show(imgs[i], label, targets[i])\n            if len(label) != len(targets[i]):\n                Tn_1 += 1\n                continue\n            if (np.asarray(targets[i]) == np.asarray(label)).all():\n                Tp += 1\n            else:\n                Tn_2 += 1\n    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n    print(""[Info] Test Accuracy: {} [{}:{}:{}:{}]"".format(Acc, Tp, Tn_1, Tn_2, (Tp+Tn_1+Tn_2)))\n    t2 = time.time()\n    print(""[Info] Test Speed: {}s 1/{}]"".format((t2 - t1) / len(datasets), len(datasets)))\n\ndef show(img, label, target):\n    img = np.transpose(img, (1, 2, 0))\n    img *= 128.\n    img += 127.5\n    img = img.astype(np.uint8)\n\n    lb = """"\n    for i in label:\n        lb += CHARS[i]\n    tg = """"\n    for j in target.tolist():\n        tg += CHARS[int(j)]\n\n    flag = ""F""\n    if lb == tg:\n        flag = ""T""\n    # img = cv2.putText(img, lb, (0,16), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.6, (0, 0, 255), 1)\n    img = cv2ImgAddText(img, lb, (0, 0))\n    cv2.imshow(""test"", img)\n    print(""target: "", tg, "" ### {} ### "".format(flag), ""predict: "", lb)\n    cv2.waitKey()\n    cv2.destroyAllWindows()\n\ndef cv2ImgAddText(img, text, pos, textColor=(255, 0, 0), textSize=12):\n    if (isinstance(img, np.ndarray)):  # detect opencv format or not\n        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    draw = ImageDraw.Draw(img)\n    fontText = ImageFont.truetype(""data/NotoSansCJK-Regular.ttc"", textSize, encoding=""utf-8"")\n    draw.text(pos, text, textColor, font=fontText)\n\n    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)\n\n\nif __name__ == ""__main__"":\n    test()\n'"
train_LPRNet.py,11,"b'# -*- coding: utf-8 -*-\n# /usr/bin/env/python3\n\n\'\'\'\nPytorch implementation for LPRNet.\nAuthor: aiboy.wei@outlook.com .\n\'\'\'\n\nfrom data.load_data import CHARS, CHARS_DICT, LPRDataLoader\nfrom model.LPRNet import build_lprnet\n# import torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.utils.data import *\nfrom torch import optim\nimport torch.nn as nn\nimport numpy as np\nimport argparse\nimport torch\nimport time\nimport os\n\ndef sparse_tuple_for_ctc(T_length, lengths):\n    input_lengths = []\n    target_lengths = []\n\n    for ch in lengths:\n        input_lengths.append(T_length)\n        target_lengths.append(ch)\n\n    return tuple(input_lengths), tuple(target_lengths)\n\ndef adjust_learning_rate(optimizer, cur_epoch, base_lr, lr_schedule):\n    """"""\n    Sets the learning rate\n    """"""\n    lr = 0\n    for i, e in enumerate(lr_schedule):\n        if cur_epoch < e:\n            lr = base_lr * (0.1 ** i)\n            break\n    if lr == 0:\n        lr = base_lr\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n    return lr\n\ndef get_parser():\n    parser = argparse.ArgumentParser(description=\'parameters to train net\')\n    parser.add_argument(\'--max_epoch\', default=15, help=\'epoch to train the network\')\n    parser.add_argument(\'--img_size\', default=[94, 24], help=\'the image size\')\n    parser.add_argument(\'--train_img_dirs\', default=""~/workspace/trainMixLPR"", help=\'the train images path\')\n    parser.add_argument(\'--test_img_dirs\', default=""~/workspace/testMixLPR"", help=\'the test images path\')\n    parser.add_argument(\'--dropout_rate\', default=0.5, help=\'dropout rate.\')\n    parser.add_argument(\'--learning_rate\', default=0.1, help=\'base value of learning rate.\')\n    parser.add_argument(\'--lpr_max_len\', default=8, help=\'license plate number max length.\')\n    parser.add_argument(\'--train_batch_size\', default=128, help=\'training batch size.\')\n    parser.add_argument(\'--test_batch_size\', default=120, help=\'testing batch size.\')\n    parser.add_argument(\'--phase_train\', default=True, type=bool, help=\'train or test phase flag.\')\n    parser.add_argument(\'--num_workers\', default=8, type=int, help=\'Number of workers used in dataloading\')\n    parser.add_argument(\'--cuda\', default=True, type=bool, help=\'Use cuda to train model\')\n    parser.add_argument(\'--resume_epoch\', default=0, type=int, help=\'resume iter for retraining\')\n    parser.add_argument(\'--save_interval\', default=2000, type=int, help=\'interval for save model state dict\')\n    parser.add_argument(\'--test_interval\', default=2000, type=int, help=\'interval for evaluate\')\n    parser.add_argument(\'--momentum\', default=0.9, type=float, help=\'momentum\')\n    parser.add_argument(\'--weight_decay\', default=2e-5, type=float, help=\'Weight decay for SGD\')\n    parser.add_argument(\'--lr_schedule\', default=[4, 8, 12, 14, 16], help=\'schedule for learning rate.\')\n    parser.add_argument(\'--save_folder\', default=\'./weights/\', help=\'Location to save checkpoint models\')\n    # parser.add_argument(\'--pretrained_model\', default=\'./weights/Final_LPRNet_model.pth\', help=\'pretrained base model\')\n    parser.add_argument(\'--pretrained_model\', default=\'\', help=\'pretrained base model\')\n\n    args = parser.parse_args()\n\n    return args\n\ndef collate_fn(batch):\n    imgs = []\n    labels = []\n    lengths = []\n    for _, sample in enumerate(batch):\n        img, label, length = sample\n        imgs.append(torch.from_numpy(img))\n        labels.extend(label)\n        lengths.append(length)\n    labels = np.asarray(labels).flatten().astype(np.int)\n\n    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n\ndef train():\n    args = get_parser()\n\n    T_length = 18 # args.lpr_max_len\n    epoch = 0 + args.resume_epoch\n    loss_val = 0\n\n    if not os.path.exists(args.save_folder):\n        os.mkdir(args.save_folder)\n\n    lprnet = build_lprnet(lpr_max_len=args.lpr_max_len, phase=args.phase_train, class_num=len(CHARS), dropout_rate=args.dropout_rate)\n    device = torch.device(""cuda:0"" if args.cuda else ""cpu"")\n    lprnet.to(device)\n    print(""Successful to build network!"")\n\n    # load pretrained model\n    if args.pretrained_model:\n        lprnet.load_state_dict(torch.load(args.pretrained_model))\n        print(""load pretrained model successful!"")\n    else:\n        def xavier(param):\n            nn.init.xavier_uniform(param)\n\n        def weights_init(m):\n            for key in m.state_dict():\n                if key.split(\'.\')[-1] == \'weight\':\n                    if \'conv\' in key:\n                        nn.init.kaiming_normal_(m.state_dict()[key], mode=\'fan_out\')\n                    if \'bn\' in key:\n                        m.state_dict()[key][...] = xavier(1)\n                elif key.split(\'.\')[-1] == \'bias\':\n                    m.state_dict()[key][...] = 0.01\n\n        lprnet.backbone.apply(weights_init)\n        lprnet.container.apply(weights_init)\n        print(""initial net weights successful!"")\n\n    # define optimizer\n    # optimizer = optim.SGD(lprnet.parameters(), lr=args.learning_rate,\n    #                       momentum=args.momentum, weight_decay=args.weight_decay)\n    optimizer = optim.RMSprop(lprnet.parameters(), lr=args.learning_rate, alpha = 0.9, eps=1e-08,\n                         momentum=args.momentum, weight_decay=args.weight_decay)\n    train_img_dirs = os.path.expanduser(args.train_img_dirs)\n    test_img_dirs = os.path.expanduser(args.test_img_dirs)\n    train_dataset = LPRDataLoader(train_img_dirs.split(\',\'), args.img_size, args.lpr_max_len)\n    test_dataset = LPRDataLoader(test_img_dirs.split(\',\'), args.img_size, args.lpr_max_len)\n\n    epoch_size = len(train_dataset) // args.train_batch_size\n    max_iter = args.max_epoch * epoch_size\n\n    ctc_loss = nn.CTCLoss(blank=len(CHARS)-1, reduction=\'mean\') # reduction: \'none\' | \'mean\' | \'sum\'\n\n    if args.resume_epoch > 0:\n        start_iter = args.resume_epoch * epoch_size\n    else:\n        start_iter = 0\n\n    for iteration in range(start_iter, max_iter):\n        if iteration % epoch_size == 0:\n            # create batch iterator\n            batch_iterator = iter(DataLoader(train_dataset, args.train_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n            loss_val = 0\n            epoch += 1\n\n        if iteration !=0 and iteration % args.save_interval == 0:\n            torch.save(lprnet.state_dict(), args.save_folder + \'LPRNet_\' + \'_iteration_\' + repr(iteration) + \'.pth\')\n\n        if (iteration + 1) % args.test_interval == 0:\n            Greedy_Decode_Eval(lprnet, test_dataset, args)\n            # lprnet.train() # should be switch to train mode\n\n        start_time = time.time()\n        # load train data\n        images, labels, lengths = next(batch_iterator)\n        # labels = np.array([el.numpy() for el in labels]).T\n        # print(labels)\n        # get ctc parameters\n        input_lengths, target_lengths = sparse_tuple_for_ctc(T_length, lengths)\n        # update lr\n        lr = adjust_learning_rate(optimizer, epoch, args.learning_rate, args.lr_schedule)\n\n        if args.cuda:\n            images = Variable(images, requires_grad=False).cuda()\n            labels = Variable(labels, requires_grad=False).cuda()\n        else:\n            images = Variable(images, requires_grad=False)\n            labels = Variable(labels, requires_grad=False)\n\n        # forward\n        logits = lprnet(images)\n        log_probs = logits.permute(2, 0, 1) # for ctc loss: T x N x C\n        # print(labels.shape)\n        log_probs = log_probs.log_softmax(2).requires_grad_()\n        # log_probs = log_probs.detach().requires_grad_()\n        # print(log_probs.shape)\n        # backprop\n        optimizer.zero_grad()\n        loss = ctc_loss(log_probs, labels, input_lengths=input_lengths, target_lengths=target_lengths)\n        if loss.item() == np.inf:\n            continue\n        loss.backward()\n        optimizer.step()\n        loss_val += loss.item()\n        end_time = time.time()\n        if iteration % 20 == 0:\n            print(\'Epoch:\' + repr(epoch) + \' || epochiter: \' + repr(iteration % epoch_size) + \'/\' + repr(epoch_size)\n                  + \'|| Totel iter \' + repr(iteration) + \' || Loss: %.4f||\' % (loss.item()) +\n                  \'Batch time: %.4f sec. ||\' % (end_time - start_time) + \'LR: %.8f\' % (lr))\n    # final test\n    print(""Final test Accuracy:"")\n    Greedy_Decode_Eval(lprnet, test_dataset, args)\n\n    # save final parameters\n    torch.save(lprnet.state_dict(), args.save_folder + \'Final_LPRNet_model.pth\')\n\ndef Greedy_Decode_Eval(Net, datasets, args):\n    # TestNet = Net.eval()\n    epoch_size = len(datasets) // args.test_batch_size\n    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n\n    Tp = 0\n    Tn_1 = 0\n    Tn_2 = 0\n    t1 = time.time()\n    for i in range(epoch_size):\n        # load train data\n        images, labels, lengths = next(batch_iterator)\n        start = 0\n        targets = []\n        for length in lengths:\n            label = labels[start:start+length]\n            targets.append(label)\n            start += length\n        targets = np.array([el.numpy() for el in targets])\n\n        if args.cuda:\n            images = Variable(images.cuda())\n        else:\n            images = Variable(images)\n\n        # forward\n        prebs = Net(images)\n        # greedy decode\n        prebs = prebs.cpu().detach().numpy()\n        preb_labels = list()\n        for i in range(prebs.shape[0]):\n            preb = prebs[i, :, :]\n            preb_label = list()\n            for j in range(preb.shape[1]):\n                preb_label.append(np.argmax(preb[:, j], axis=0))\n            no_repeat_blank_label = list()\n            pre_c = preb_label[0]\n            if pre_c != len(CHARS) - 1:\n                no_repeat_blank_label.append(pre_c)\n            for c in preb_label: # dropout repeate label and blank label\n                if (pre_c == c) or (c == len(CHARS) - 1):\n                    if c == len(CHARS) - 1:\n                        pre_c = c\n                    continue\n                no_repeat_blank_label.append(c)\n                pre_c = c\n            preb_labels.append(no_repeat_blank_label)\n        for i, label in enumerate(preb_labels):\n            if len(label) != len(targets[i]):\n                Tn_1 += 1\n                continue\n            if (np.asarray(targets[i]) == np.asarray(label)).all():\n                Tp += 1\n            else:\n                Tn_2 += 1\n\n    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n    print(""[Info] Test Accuracy: {} [{}:{}:{}:{}]"".format(Acc, Tp, Tn_1, Tn_2, (Tp+Tn_1+Tn_2)))\n    t2 = time.time()\n    print(""[Info] Test Speed: {}s 1/{}]"".format((t2 - t1) / len(datasets), len(datasets)))\n\n\nif __name__ == ""__main__"":\n    train()\n'"
data/__init__.py,0,b'from .load_data import *'
data/load_data.py,1,"b'from torch.utils.data import *\nfrom imutils import paths\nimport numpy as np\nimport random\nimport cv2\nimport os\n\nCHARS = [\'\xe4\xba\xac\', \'\xe6\xb2\xaa\', \'\xe6\xb4\xa5\', \'\xe6\xb8\x9d\', \'\xe5\x86\x80\', \'\xe6\x99\x8b\', \'\xe8\x92\x99\', \'\xe8\xbe\xbd\', \'\xe5\x90\x89\', \'\xe9\xbb\x91\',\n         \'\xe8\x8b\x8f\', \'\xe6\xb5\x99\', \'\xe7\x9a\x96\', \'\xe9\x97\xbd\', \'\xe8\xb5\xa3\', \'\xe9\xb2\x81\', \'\xe8\xb1\xab\', \'\xe9\x84\x82\', \'\xe6\xb9\x98\', \'\xe7\xb2\xa4\',\n         \'\xe6\xa1\x82\', \'\xe7\x90\xbc\', \'\xe5\xb7\x9d\', \'\xe8\xb4\xb5\', \'\xe4\xba\x91\', \'\xe8\x97\x8f\', \'\xe9\x99\x95\', \'\xe7\x94\x98\', \'\xe9\x9d\x92\', \'\xe5\xae\x81\',\n         \'\xe6\x96\xb0\',\n         \'0\', \'1\', \'2\', \'3\', \'4\', \'5\', \'6\', \'7\', \'8\', \'9\',\n         \'A\', \'B\', \'C\', \'D\', \'E\', \'F\', \'G\', \'H\', \'J\', \'K\',\n         \'L\', \'M\', \'N\', \'P\', \'Q\', \'R\', \'S\', \'T\', \'U\', \'V\',\n         \'W\', \'X\', \'Y\', \'Z\', \'I\', \'O\', \'-\'\n         ]\n\nCHARS_DICT = {char:i for i, char in enumerate(CHARS)}\n\nclass LPRDataLoader(Dataset):\n    def __init__(self, img_dir, imgSize, lpr_max_len, PreprocFun=None):\n        self.img_dir = img_dir\n        self.img_paths = []\n        for i in range(len(img_dir)):\n            self.img_paths += [el for el in paths.list_images(img_dir[i])]\n        random.shuffle(self.img_paths)\n        self.img_size = imgSize\n        self.lpr_max_len = lpr_max_len\n        if PreprocFun is not None:\n            self.PreprocFun = PreprocFun\n        else:\n            self.PreprocFun = self.transform\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, index):\n        filename = self.img_paths[index]\n        Image = cv2.imread(filename)\n        height, width, _ = Image.shape\n        if height != self.img_size[1] or width != self.img_size[0]:\n            Image = cv2.resize(Image, self.img_size)\n        Image = self.PreprocFun(Image)\n\n        basename = os.path.basename(filename)\n        imgname, suffix = os.path.splitext(basename)\n        imgname = imgname.split(""-"")[0].split(""_"")[0]\n        label = list()\n        for c in imgname:\n            # one_hot_base = np.zeros(len(CHARS))\n            # one_hot_base[CHARS_DICT[c]] = 1\n            label.append(CHARS_DICT[c])\n\n        if len(label) == 8:\n            if self.check(label) == False:\n                print(imgname)\n                assert 0, ""Error label ^~^!!!""\n\n        return Image, label, len(label)\n\n    def transform(self, img):\n        img = img.astype(\'float32\')\n        img -= 127.5\n        img *= 0.0078125\n        img = np.transpose(img, (2, 0, 1))\n\n        return img\n\n    def check(self, label):\n        if label[2] != CHARS_DICT[\'D\'] and label[2] != CHARS_DICT[\'F\'] \\\n                and label[-1] != CHARS_DICT[\'D\'] and label[-1] != CHARS_DICT[\'F\']:\n            print(""Error label, Please check!"")\n            return False\n        else:\n            return True\n'"
model/LPRNet.py,6,"b'import torch.nn as nn\nimport torch\n\nclass small_basic_block(nn.Module):\n    def __init__(self, ch_in, ch_out):\n        super(small_basic_block, self).__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)),\n            nn.ReLU(),\n            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)),\n            nn.ReLU(),\n            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),\n        )\n    def forward(self, x):\n        return self.block(x)\n\nclass LPRNet(nn.Module):\n    def __init__(self, lpr_max_len, phase, class_num, dropout_rate):\n        super(LPRNet, self).__init__()\n        self.phase = phase\n        self.lpr_max_len = lpr_max_len\n        self.class_num = class_num\n        self.backbone = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1), # 0\n            nn.BatchNorm2d(num_features=64),\n            nn.ReLU(),  # 2\n            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1)),\n            small_basic_block(ch_in=64, ch_out=128),    # *** 4 ***\n            nn.BatchNorm2d(num_features=128),\n            nn.ReLU(),  # 6\n            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2)),\n            small_basic_block(ch_in=64, ch_out=256),   # 8\n            nn.BatchNorm2d(num_features=256),\n            nn.ReLU(),  # 10\n            small_basic_block(ch_in=256, ch_out=256),   # *** 11 ***\n            nn.BatchNorm2d(num_features=256),   # 12\n            nn.ReLU(),\n            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2)),  # 14\n            nn.Dropout(dropout_rate),\n            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 4), stride=1),  # 16\n            nn.BatchNorm2d(num_features=256),\n            nn.ReLU(),  # 18\n            nn.Dropout(dropout_rate),\n            nn.Conv2d(in_channels=256, out_channels=class_num, kernel_size=(13, 1), stride=1), # 20\n            nn.BatchNorm2d(num_features=class_num),\n            nn.ReLU(),  # *** 22 ***\n        )\n        self.container = nn.Sequential(\n            nn.Conv2d(in_channels=448+self.class_num, out_channels=self.class_num, kernel_size=(1, 1), stride=(1, 1)),\n            # nn.BatchNorm2d(num_features=self.class_num),\n            # nn.ReLU(),\n            # nn.Conv2d(in_channels=self.class_num, out_channels=self.lpr_max_len+1, kernel_size=3, stride=2),\n            # nn.ReLU(),\n        )\n\n    def forward(self, x):\n        keep_features = list()\n        for i, layer in enumerate(self.backbone.children()):\n            x = layer(x)\n            if i in [2, 6, 13, 22]: # [2, 4, 8, 11, 22]\n                keep_features.append(x)\n\n        global_context = list()\n        for i, f in enumerate(keep_features):\n            if i in [0, 1]:\n                f = nn.AvgPool2d(kernel_size=5, stride=5)(f)\n            if i in [2]:\n                f = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))(f)\n            f_pow = torch.pow(f, 2)\n            f_mean = torch.mean(f_pow)\n            f = torch.div(f, f_mean)\n            global_context.append(f)\n\n        x = torch.cat(global_context, 1)\n        x = self.container(x)\n        logits = torch.mean(x, dim=2)\n\n        return logits\n\ndef build_lprnet(lpr_max_len=8, phase=False, class_num=66, dropout_rate=0.5):\n\n    Net = LPRNet(lpr_max_len, phase, class_num, dropout_rate)\n\n    if phase == ""train"":\n        return Net.train()\n    else:\n        return Net.eval()\n'"
model/__init__.py,0,b'from .LPRNet import *'
