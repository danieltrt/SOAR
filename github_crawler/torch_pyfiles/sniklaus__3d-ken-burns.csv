file_path,api_count,code
autozoom.py,3,"b""#!/usr/bin/env python\n\nimport torch\nimport torchvision\n\nimport base64\nimport cupy\nimport cv2\nimport flask\nimport getopt\nimport gevent\nimport gevent.pywsgi\nimport glob\nimport h5py\nimport io\nimport math\nimport moviepy\nimport moviepy.editor\nimport numpy\nimport os\nimport random\nimport re\nimport scipy\nimport scipy.io\nimport shutil\nimport sys\nimport tempfile\nimport time\nimport urllib\nimport zipfile\n\n##########################################################\n\nassert(int(str('').join(torch.__version__.split('.')[0:2])) >= 12) # requires at least pytorch version 1.2.0\n\ntorch.set_grad_enabled(False) # make sure to not compute gradients for computational performance\n\ntorch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance\n\n##########################################################\n\nobjCommon = {}\n\nexec(open('./common.py', 'r').read())\n\nexec(open('./models/disparity-estimation.py', 'r').read())\nexec(open('./models/disparity-adjustment.py', 'r').read())\nexec(open('./models/disparity-refinement.py', 'r').read())\nexec(open('./models/pointcloud-inpainting.py', 'r').read())\n\n##########################################################\n\narguments_strIn = './images/doublestrike.jpg'\narguments_strOut = './autozoom.mp4'\n\nfor strOption, strArgument in getopt.getopt(sys.argv[1:], '', [ strParameter[2:] + '=' for strParameter in sys.argv[1::2] ])[0]:\n\tif strOption == '--in' and strArgument != '': arguments_strIn = strArgument # path to the input image\n\tif strOption == '--out' and strArgument != '': arguments_strOut = strArgument # path to where the output should be stored\n# end\n\n##########################################################\n\nif __name__ == '__main__':\n\tnpyImage = cv2.imread(filename=arguments_strIn, flags=cv2.IMREAD_COLOR)\n\n\tintWidth = npyImage.shape[1]\n\tintHeight = npyImage.shape[0]\n\n\tfltRatio = float(intWidth) / float(intHeight)\n\n\tintWidth = min(int(1024 * fltRatio), 1024)\n\tintHeight = min(int(1024 / fltRatio), 1024)\n\n\tnpyImage = cv2.resize(src=npyImage, dsize=(intWidth, intHeight), fx=0.0, fy=0.0, interpolation=cv2.INTER_AREA)\n\n\tprocess_load(npyImage, {})\n\n\tobjFrom = {\n\t\t'fltCenterU': intWidth / 2.0,\n\t\t'fltCenterV': intHeight / 2.0,\n\t\t'intCropWidth': int(math.floor(0.97 * intWidth)),\n\t\t'intCropHeight': int(math.floor(0.97 * intHeight))\n\t}\n\n\tobjTo = process_autozoom({\n\t\t'fltShift': 100.0,\n\t\t'fltZoom': 1.25,\n\t\t'objFrom': objFrom\n\t})\n\n\tnpyResult = process_kenburns({\n\t\t'fltSteps': numpy.linspace(0.0, 1.0, 75).tolist(),\n\t\t'objFrom': objFrom,\n\t\t'objTo': objTo,\n\t\t'boolInpaint': True\n\t})\n\n\tmoviepy.editor.ImageSequenceClip(sequence=[ npyFrame[:, :, ::-1] for npyFrame in npyResult + list(reversed(npyResult))[1:] ], fps=25).write_videofile(arguments_strOut)\n# end"""
benchmark.py,6,"b""#!/usr/bin/env python\n\nimport torch\nimport torchvision\n\nimport base64\nimport cupy\nimport cv2\nimport flask\nimport getopt\nimport gevent\nimport gevent.pywsgi\nimport glob\nimport h5py\nimport io\nimport math\nimport moviepy\nimport moviepy.editor\nimport numpy\nimport os\nimport random\nimport re\nimport scipy\nimport scipy.io\nimport shutil\nimport sys\nimport tempfile\nimport time\nimport urllib\nimport zipfile\n\n##########################################################\n\nassert(int(str('').join(torch.__version__.split('.')[0:2])) >= 12) # requires at least pytorch version 1.2.0\n\ntorch.set_grad_enabled(False) # make sure to not compute gradients for computational performance\n\ntorch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance\n\n##########################################################\n\nobjCommon = {}\n\nexec(open('./common.py', 'r').read())\n\nexec(open('./models/disparity-estimation.py', 'r').read())\nexec(open('./models/disparity-adjustment.py', 'r').read())\nexec(open('./models/disparity-refinement.py', 'r').read())\nexec(open('./models/pointcloud-inpainting.py', 'r').read())\n\n##########################################################\n\nprint('large parts of this benchmark were adapted from Tobias Koch')\nprint('this implementation first downloads the official evaluation scripts')\nprint('the depth boundary error is currently different from the paper')\nprint('this is due to the official evaluation scripts being outdated')\n\n##########################################################\n\nabs_rel = [ numpy.nan ] * 1000\nsq_rel = [ numpy.nan ] * 1000\nrms  = [ numpy.nan ] * 1000\nlog10 = [ numpy.nan ] * 1000\nthr1 = [ numpy.nan ] * 1000\nthr2 = [ numpy.nan ] * 1000\nthr3 = [ numpy.nan ] * 1000\ndde_0 = [ numpy.nan ] * 1000\ndde_m = [ numpy.nan ] * 1000\ndde_p = [ numpy.nan ] * 1000\ndbe_acc = [ numpy.nan ] * 1000\ndbe_com = [ numpy.nan ] * 1000\npe_fla = []\npe_ori = []\n\n##########################################################\n\nif os.path.isfile('./benchmark-ibims-scripts.zip') == False:\n\turllib.request.urlretrieve('ftp://m1455541:m1455541@dataserv.ub.tum.de/evaluation_scripts.zip', './benchmark-ibims-scripts.zip')\n# end\n\nobjZip = zipfile.ZipFile('./benchmark-ibims-scripts.zip', 'r')\n\nstrScript = objZip.read('evaluation_scripts/evaluate_ibims_error_metrics.py').decode('utf-8')\nstrScript = strScript.replace('# exclude masked invalid and missing measurements', 'idx = gt!=0')\nstrScript = strScript.replace('gt=gt[gt!=0]', 'gt=gt[idx]')\nstrScript = strScript.replace('pred=pred[pred!=0]', 'pred=pred[idx]')\n\nexec(strScript)\n\nobjZip.close()\n\n##########################################################\n\nif os.path.isfile('./benchmark-ibims-data.zip') == False:\n\turllib.request.urlretrieve('ftp://m1455541:m1455541@dataserv.ub.tum.de/ibims1_core_mat.zip', './benchmark-ibims-data.zip')\n# end\n\nobjZip = zipfile.ZipFile('./benchmark-ibims-data.zip', 'r')\n\nfor intMat, strMat in enumerate([ strFile for strFile in objZip.namelist() if strFile.endswith('.mat') ]):\n\tprint(intMat, strMat)\n\n\tobjMat = scipy.io.loadmat(io.BytesIO(objZip.read(strMat)))['data']\n\n\ttenImage = torch.FloatTensor(numpy.ascontiguousarray(objMat['rgb'][0][0][:, :, ::-1].transpose(2, 0, 1)[None, :, :, :].astype(numpy.float32) * (1.0 / 255.0))).cuda()\n\ttenDisparity = disparity_estimation(tenImage)\n\ttenDisparity = disparity_refinement(torch.nn.functional.interpolate(input=tenImage, size=(tenDisparity.shape[2] * 4, tenDisparity.shape[3] * 4), mode='bilinear', align_corners=False), tenDisparity)\n\ttenDisparity = torch.nn.functional.interpolate(input=tenDisparity, size=(tenImage.shape[2], tenImage.shape[3]), mode='bilinear', align_corners=False) * (max(tenImage.shape[2], tenImage.shape[3]) / 256.0)\n\ttenDepth = 1.0 / tenDisparity\n\n\tvalid = objMat['mask_transp'][0][0] * objMat['mask_invalid'][0][0] * (objMat['depth'][0][0] != 0.0)\n\n\tpred = tenDepth[0, 0, :, :].cpu().numpy()\n\tnpyLstsqa = numpy.stack([pred[valid == 1.0].flatten(), numpy.full([int((valid == 1.0).sum().item())], 1.0, numpy.float32)], 1)\n\tnpyLstsqb = objMat['depth'][0][0][valid == 1.0].flatten()\n\tnpyScalebias = numpy.linalg.lstsq(npyLstsqa, npyLstsqb, None)[0]\n\tpred = (pred * npyScalebias[0]) + npyScalebias[1]\n\n\tabs_rel[intMat], sq_rel[intMat], rms[intMat], log10[intMat], thr1[intMat], thr2[intMat], thr3[intMat] = compute_global_errors((objMat['depth'][0][0] * valid).flatten(), (pred * valid).flatten())\n\tdde_0[intMat], dde_m[intMat], dde_p[intMat] = compute_directed_depth_error((objMat['depth'][0][0] * valid).flatten(), (pred * valid).flatten(), 3.0)\n\tdbe_acc[intMat], dbe_com[intMat] = compute_depth_boundary_error(objMat['edges'][0][0], pred)\n\n\tif objMat['mask_wall_paras'][0][0].size > 0:\n\t\tpe_fla_wall, pe_ori_wall = compute_planarity_error(objMat['depth'][0][0] * valid, pred * valid, objMat['mask_wall_paras'][0][0], objMat['mask_wall'][0][0] * valid, objMat['calib'][0][0])\n\t\tpe_fla.extend(pe_fla_wall.tolist())\n\t\tpe_ori.extend(pe_ori_wall.tolist())\n\t# end\n\n\tif objMat['mask_table_paras'][0][0].size > 0:\n\t\tpe_fla_table, pe_ori_table = compute_planarity_error(objMat['depth'][0][0] * valid, pred * valid, objMat['mask_table_paras'][0][0], objMat['mask_table'][0][0] * valid, objMat['calib'][0][0])\n\t\tpe_fla.extend(pe_fla_table.tolist())\n\t\tpe_ori.extend(pe_ori_table.tolist())\n\t# end\n\n\tif objMat['mask_floor_paras'][0][0].size > 0:\n\t\tpe_fla_floor, pe_ori_floor = compute_planarity_error(objMat['depth'][0][0] * valid, pred * valid, objMat['mask_floor_paras'][0][0], objMat['mask_floor'][0][0] * valid, objMat['calib'][0][0])\n\t\tpe_fla.extend(pe_fla_floor.tolist())\n\t\tpe_ori.extend(pe_ori_floor.tolist())\n\t# end\n# end\n\nobjZip.close()\n\n##########################################################\n\nprint('abs_rel = ', numpy.nanmean(abs_rel))\nprint('sq_rel  = ', numpy.nanmean(sq_rel))\nprint('rms     = ', numpy.nanmean(rms))\nprint('log10   = ', numpy.nanmean(log10))\nprint('thr1    = ', numpy.nanmean(thr1))\nprint('thr2    = ', numpy.nanmean(thr2))\nprint('thr3    = ', numpy.nanmean(thr3))\nprint('dde_0   = ', numpy.nanmean(dde_0))\nprint('dde_m   = ', numpy.nanmean(dde_m))\nprint('dde_p   = ', numpy.nanmean(dde_p))\nprint('dbe_acc = ', numpy.nanmean(dbe_acc))\nprint('dbe_com = ', numpy.nanmean(dbe_com))\nprint('pe_fla  = ', numpy.nanmean(pe_fla))\nprint('pe_ori  = ', numpy.nanmean(pe_ori))"""
common.py,15,"b'def process_load(npyImage, objSettings):\n\tobjCommon[\'fltFocal\'] = 1024 / 2.0\n\tobjCommon[\'fltBaseline\'] = 40.0\n\tobjCommon[\'intWidth\'] = npyImage.shape[1]\n\tobjCommon[\'intHeight\'] = npyImage.shape[0]\n\n\ttenImage = torch.FloatTensor(numpy.ascontiguousarray(npyImage.transpose(2, 0, 1)[None, :, :, :].astype(numpy.float32) * (1.0 / 255.0))).cuda()\n\ttenDisparity = disparity_estimation(tenImage)\n\ttenDisparity = disparity_adjustment(tenImage, tenDisparity)\n\ttenDisparity = disparity_refinement(tenImage, tenDisparity)\n\ttenDisparity = tenDisparity / tenDisparity.max() * objCommon[\'fltBaseline\']\n\ttenDepth = (objCommon[\'fltFocal\'] * objCommon[\'fltBaseline\']) / (tenDisparity + 0.0000001)\n\ttenValid = (spatial_filter(tenDisparity / tenDisparity.max(), \'laplacian\').abs() < 0.03).float()\n\ttenPoints = depth_to_points(tenDepth * tenValid, objCommon[\'fltFocal\'])\n\ttenUnaltered = depth_to_points(tenDepth, objCommon[\'fltFocal\'])\n\n\tobjCommon[\'fltDispmin\'] = tenDisparity.min().item()\n\tobjCommon[\'fltDispmax\'] = tenDisparity.max().item()\n\tobjCommon[\'objDepthrange\'] = cv2.minMaxLoc(src=tenDepth[0, 0, 128:-128, 128:-128].detach().cpu().numpy(), mask=None)\n\tobjCommon[\'tenRawImage\'] = tenImage\n\tobjCommon[\'tenRawDisparity\'] = tenDisparity\n\tobjCommon[\'tenRawDepth\'] = tenDepth\n\tobjCommon[\'tenRawPoints\'] = tenPoints.view(1, 3, -1)\n\tobjCommon[\'tenRawUnaltered\'] = tenUnaltered.view(1, 3, -1)\n\n\tobjCommon[\'tenInpaImage\'] = objCommon[\'tenRawImage\'].view(1, 3, -1)\n\tobjCommon[\'tenInpaDisparity\'] = objCommon[\'tenRawDisparity\'].view(1, 1, -1)\n\tobjCommon[\'tenInpaDepth\'] = objCommon[\'tenRawDepth\'].view(1, 1, -1)\n\tobjCommon[\'tenInpaPoints\'] = objCommon[\'tenRawPoints\'].view(1, 3, -1)\n# end\n\ndef process_inpaint(tenShift):\n\tobjInpainted = pointcloud_inpainting(objCommon[\'tenRawImage\'], objCommon[\'tenRawDisparity\'], tenShift)\n\n\tobjInpainted[\'tenDepth\'] = (objCommon[\'fltFocal\'] * objCommon[\'fltBaseline\']) / (objInpainted[\'tenDisparity\'] + 0.0000001)\n\tobjInpainted[\'tenValid\'] = (spatial_filter(objInpainted[\'tenDisparity\'] / objInpainted[\'tenDisparity\'].max(), \'laplacian\').abs() < 0.03).float()\n\tobjInpainted[\'tenPoints\'] = depth_to_points(objInpainted[\'tenDepth\'] * objInpainted[\'tenValid\'], objCommon[\'fltFocal\'])\n\tobjInpainted[\'tenPoints\'] = objInpainted[\'tenPoints\'].view(1, 3, -1)\n\tobjInpainted[\'tenPoints\'] = objInpainted[\'tenPoints\'] - tenShift\n\n\ttenMask = (objInpainted[\'tenExisting\'] == 0.0).view(1, 1, -1)\n\n\tobjCommon[\'tenInpaImage\'] = torch.cat([ objCommon[\'tenInpaImage\'], objInpainted[\'tenImage\'].view(1, 3, -1)[tenMask.expand(-1, 3, -1)].view(1, 3, -1) ], 2)\n\tobjCommon[\'tenInpaDisparity\'] = torch.cat([ objCommon[\'tenInpaDisparity\'], objInpainted[\'tenDisparity\'].view(1, 1, -1)[tenMask.expand(-1, 1, -1)].view(1, 1, -1) ], 2)\n\tobjCommon[\'tenInpaDepth\'] = torch.cat([ objCommon[\'tenInpaDepth\'], objInpainted[\'tenDepth\'].view(1, 1, -1)[tenMask.expand(-1, 1, -1)].view(1, 1, -1) ], 2)\n\tobjCommon[\'tenInpaPoints\'] = torch.cat([ objCommon[\'tenInpaPoints\'], objInpainted[\'tenPoints\'].view(1, 3, -1)[tenMask.expand(-1, 3, -1)].view(1, 3, -1) ], 2)\n# end\n\ndef process_shift(objSettings):\n\tfltClosestDepth = objCommon[\'objDepthrange\'][0] + (objSettings[\'fltDepthTo\'] - objSettings[\'fltDepthFrom\'])\n\tfltClosestFromU = objCommon[\'objDepthrange\'][2][0]\n\tfltClosestFromV = objCommon[\'objDepthrange\'][2][1]\n\tfltClosestToU = fltClosestFromU + objSettings[\'fltShiftU\']\n\tfltClosestToV = fltClosestFromV + objSettings[\'fltShiftV\']\n\tfltClosestFromX = ((fltClosestFromU - (objCommon[\'intWidth\'] / 2.0)) * fltClosestDepth) / objCommon[\'fltFocal\']\n\tfltClosestFromY = ((fltClosestFromV - (objCommon[\'intHeight\'] / 2.0)) * fltClosestDepth) / objCommon[\'fltFocal\']\n\tfltClosestToX = ((fltClosestToU - (objCommon[\'intWidth\'] / 2.0)) * fltClosestDepth) / objCommon[\'fltFocal\']\n\tfltClosestToY = ((fltClosestToV - (objCommon[\'intHeight\'] / 2.0)) * fltClosestDepth) / objCommon[\'fltFocal\']\n\n\tfltShiftX = fltClosestFromX - fltClosestToX\n\tfltShiftY = fltClosestFromY - fltClosestToY\n\tfltShiftZ = objSettings[\'fltDepthTo\'] - objSettings[\'fltDepthFrom\']\n\n\ttenShift = torch.FloatTensor([ fltShiftX, fltShiftY, fltShiftZ ]).view(1, 3, 1).cuda()\n\n\ttenPoints = objSettings[\'tenPoints\'].clone()\n\n\ttenPoints[:, 0:1, :] *= tenPoints[:, 2:3, :] / (objSettings[\'tenPoints\'][:, 2:3, :] + 0.0000001)\n\ttenPoints[:, 1:2, :] *= tenPoints[:, 2:3, :] / (objSettings[\'tenPoints\'][:, 2:3, :] + 0.0000001)\n\n\ttenPoints += tenShift\n\n\treturn tenPoints, tenShift\n# end\n\ndef process_autozoom(objSettings):\n\tnpyShiftU = numpy.linspace(-objSettings[\'fltShift\'], objSettings[\'fltShift\'], 16)[None, :].repeat(16, 0)\n\tnpyShiftV = numpy.linspace(-objSettings[\'fltShift\'], objSettings[\'fltShift\'], 16)[:, None].repeat(16, 1)\n\tfltCropWidth = objSettings[\'objFrom\'][\'intCropWidth\'] / objSettings[\'fltZoom\']\n\tfltCropHeight = objSettings[\'objFrom\'][\'intCropHeight\'] / objSettings[\'fltZoom\']\n\n\tfltDepthFrom = objCommon[\'objDepthrange\'][0]\n\tfltDepthTo = objCommon[\'objDepthrange\'][0] * (fltCropWidth / objSettings[\'objFrom\'][\'intCropWidth\'])\n\n\tfltBest = 0.0\n\tfltBestU = None\n\tfltBestV = None\n\n\tfor intU in range(16):\n\t\tfor intV in range(16):\n\t\t\tfltShiftU = npyShiftU[intU, intV].item()\n\t\t\tfltShiftV = npyShiftV[intU, intV].item()\n\n\t\t\tif objSettings[\'objFrom\'][\'fltCenterU\'] + fltShiftU < fltCropWidth / 2.0:\n\t\t\t\tcontinue\n\n\t\t\telif objSettings[\'objFrom\'][\'fltCenterU\'] + fltShiftU > objCommon[\'intWidth\'] - (fltCropWidth / 2.0):\n\t\t\t\tcontinue\n\n\t\t\telif objSettings[\'objFrom\'][\'fltCenterV\'] + fltShiftV < fltCropHeight / 2.0:\n\t\t\t\tcontinue\n\n\t\t\telif objSettings[\'objFrom\'][\'fltCenterV\'] + fltShiftV > objCommon[\'intHeight\'] - (fltCropHeight / 2.0):\n\t\t\t\tcontinue\n\n\t\t\t# end\n\n\t\t\ttenPoints = process_shift({\n\t\t\t\t\'tenPoints\': objCommon[\'tenRawPoints\'],\n\t\t\t\t\'fltShiftU\': fltShiftU,\n\t\t\t\t\'fltShiftV\': fltShiftV,\n\t\t\t\t\'fltDepthFrom\': fltDepthFrom,\n\t\t\t\t\'fltDepthTo\': fltDepthTo\n\t\t\t})[0]\n\n\t\t\ttenRender, tenExisting = render_pointcloud(tenPoints, objCommon[\'tenRawImage\'].view(1, 3, -1), objCommon[\'intWidth\'], objCommon[\'intHeight\'], objCommon[\'fltFocal\'], objCommon[\'fltBaseline\'])\n\n\t\t\tif fltBest < (tenExisting > 0.0).float().sum().item():\n\t\t\t\tfltBest = (tenExisting > 0.0).float().sum().item()\n\t\t\t\tfltBestU = fltShiftU\n\t\t\t\tfltBestV = fltShiftV\n\t\t\t# end\n\t\t# end\n\t# end\n\n\treturn {\n\t\t\'fltCenterU\': objSettings[\'objFrom\'][\'fltCenterU\'] + fltBestU,\n\t\t\'fltCenterV\': objSettings[\'objFrom\'][\'fltCenterV\'] + fltBestV,\n\t\t\'intCropWidth\': int(round(objSettings[\'objFrom\'][\'intCropWidth\'] / objSettings[\'fltZoom\'])),\n\t\t\'intCropHeight\': int(round(objSettings[\'objFrom\'][\'intCropHeight\'] / objSettings[\'fltZoom\']))\n\t}\n# end\n\ndef process_kenburns(objSettings):\n\tnpyOutputs = []\n\n\tif \'boolInpaint\' not in objSettings or objSettings[\'boolInpaint\'] == True:\n\t\tobjCommon[\'tenInpaImage\'] = objCommon[\'tenRawImage\'].view(1, 3, -1)\n\t\tobjCommon[\'tenInpaDisparity\'] = objCommon[\'tenRawDisparity\'].view(1, 1, -1)\n\t\tobjCommon[\'tenInpaDepth\'] = objCommon[\'tenRawDepth\'].view(1, 1, -1)\n\t\tobjCommon[\'tenInpaPoints\'] = objCommon[\'tenRawPoints\'].view(1, 3, -1)\n\n\t\tfor fltStep in [ 0.0, 1.0 ]:\n\t\t\tfltFrom = 1.0 - fltStep\n\t\t\tfltTo = 1.0 - fltFrom\n\n\t\t\tfltShiftU = ((fltFrom * objSettings[\'objFrom\'][\'fltCenterU\']) + (fltTo * objSettings[\'objTo\'][\'fltCenterU\'])) - (objCommon[\'intWidth\'] / 2.0)\n\t\t\tfltShiftV = ((fltFrom * objSettings[\'objFrom\'][\'fltCenterV\']) + (fltTo * objSettings[\'objTo\'][\'fltCenterV\'])) - (objCommon[\'intHeight\'] / 2.0)\n\t\t\tfltCropWidth = (fltFrom * objSettings[\'objFrom\'][\'intCropWidth\']) + (fltTo * objSettings[\'objTo\'][\'intCropWidth\'])\n\t\t\tfltCropHeight = (fltFrom * objSettings[\'objFrom\'][\'intCropHeight\']) + (fltTo * objSettings[\'objTo\'][\'intCropHeight\'])\n\n\t\t\tfltDepthFrom = objCommon[\'objDepthrange\'][0]\n\t\t\tfltDepthTo = objCommon[\'objDepthrange\'][0] * (fltCropWidth / max(objSettings[\'objFrom\'][\'intCropWidth\'], objSettings[\'objTo\'][\'intCropWidth\']))\n\n\t\t\ttenShift = process_shift({\n\t\t\t\t\'tenPoints\': objCommon[\'tenInpaPoints\'],\n\t\t\t\t\'fltShiftU\': fltShiftU,\n\t\t\t\t\'fltShiftV\': fltShiftV,\n\t\t\t\t\'fltDepthFrom\': fltDepthFrom,\n\t\t\t\t\'fltDepthTo\': fltDepthTo\n\t\t\t})[1]\n\n\t\t\tprocess_inpaint(1.1 * tenShift)\n\t\t# end\n\t# end\n\n\tfor fltStep in objSettings[\'fltSteps\']:\n\t\tfltFrom = 1.0 - fltStep\n\t\tfltTo = 1.0 - fltFrom\n\n\t\tfltShiftU = ((fltFrom * objSettings[\'objFrom\'][\'fltCenterU\']) + (fltTo * objSettings[\'objTo\'][\'fltCenterU\'])) - (objCommon[\'intWidth\'] / 2.0)\n\t\tfltShiftV = ((fltFrom * objSettings[\'objFrom\'][\'fltCenterV\']) + (fltTo * objSettings[\'objTo\'][\'fltCenterV\'])) - (objCommon[\'intHeight\'] / 2.0)\n\t\tfltCropWidth = (fltFrom * objSettings[\'objFrom\'][\'intCropWidth\']) + (fltTo * objSettings[\'objTo\'][\'intCropWidth\'])\n\t\tfltCropHeight = (fltFrom * objSettings[\'objFrom\'][\'intCropHeight\']) + (fltTo * objSettings[\'objTo\'][\'intCropHeight\'])\n\n\t\tfltDepthFrom = objCommon[\'objDepthrange\'][0]\n\t\tfltDepthTo = objCommon[\'objDepthrange\'][0] * (fltCropWidth / max(objSettings[\'objFrom\'][\'intCropWidth\'], objSettings[\'objTo\'][\'intCropWidth\']))\n\n\t\ttenPoints = process_shift({\n\t\t\t\'tenPoints\': objCommon[\'tenInpaPoints\'],\n\t\t\t\'fltShiftU\': fltShiftU,\n\t\t\t\'fltShiftV\': fltShiftV,\n\t\t\t\'fltDepthFrom\': fltDepthFrom,\n\t\t\t\'fltDepthTo\': fltDepthTo\n\t\t})[0]\n\n\t\ttenRender, tenExisting = render_pointcloud(tenPoints, torch.cat([ objCommon[\'tenInpaImage\'], objCommon[\'tenInpaDepth\'] ], 1).view(1, 4, -1), objCommon[\'intWidth\'], objCommon[\'intHeight\'], objCommon[\'fltFocal\'], objCommon[\'fltBaseline\'])\n\n\t\ttenRender = fill_disocclusion(tenRender, tenRender[:, 3:4, :, :] * (tenExisting > 0.0).float())\n\n\t\tnpyOutput = (tenRender[0, 0:3, :, :].detach().cpu().numpy().transpose(1, 2, 0) * 255.0).clip(0.0, 255.0).astype(numpy.uint8)\n\t\tnpyOutput = cv2.getRectSubPix(image=npyOutput, patchSize=(max(objSettings[\'objFrom\'][\'intCropWidth\'], objSettings[\'objTo\'][\'intCropWidth\']), max(objSettings[\'objFrom\'][\'intCropHeight\'], objSettings[\'objTo\'][\'intCropHeight\'])), center=(objCommon[\'intWidth\'] / 2.0, objCommon[\'intHeight\'] / 2.0))\n\t\tnpyOutput = cv2.resize(src=npyOutput, dsize=(objCommon[\'intWidth\'], objCommon[\'intHeight\']), fx=0.0, fy=0.0, interpolation=cv2.INTER_LINEAR)\n\n\t\tnpyOutputs.append(npyOutput)\n\t# end\n\n\treturn npyOutputs\n# end\n\n##########################################################\n\ndef preprocess_kernel(strKernel, objVariables):\n\twith open(\'./common.cuda\', \'r\') as objFile:\n\t\tstrKernel = objFile.read() + strKernel\n\t# end\n\n\tfor strVariable in objVariables:\n\t\tobjValue = objVariables[strVariable]\n\n\t\tif type(objValue) == int:\n\t\t\tstrKernel = strKernel.replace(\'{{\' + strVariable + \'}}\', str(objValue))\n\n\t\telif type(objValue) == float:\n\t\t\tstrKernel = strKernel.replace(\'{{\' + strVariable + \'}}\', str(objValue))\n\n\t\telif type(objValue) == str:\n\t\t\tstrKernel = strKernel.replace(\'{{\' + strVariable + \'}}\', objValue)\n\n\t\t# end\n\t# end\n\n\twhile True:\n\t\tobjMatch = re.search(\'(SIZE_)([0-4])(\\()([^\\)]*)(\\))\', strKernel)\n\n\t\tif objMatch is None:\n\t\t\tbreak\n\t\t# end\n\n\t\tintArg = int(objMatch.group(2))\n\n\t\tstrTensor = objMatch.group(4)\n\t\tintSizes = objVariables[strTensor].size()\n\n\t\tstrKernel = strKernel.replace(objMatch.group(), str(intSizes[intArg]))\n\t# end\n\n\twhile True:\n\t\tobjMatch = re.search(\'(STRIDE_)([0-4])(\\()([^\\)]*)(\\))\', strKernel)\n\n\t\tif objMatch is None:\n\t\t\tbreak\n\t\t# end\n\n\t\tintArg = int(objMatch.group(2))\n\n\t\tstrTensor = objMatch.group(4)\n\t\tintStrides = objVariables[strTensor].stride()\n\n\t\tstrKernel = strKernel.replace(objMatch.group(), str(intStrides[intArg]))\n\t# end\n\n\twhile True:\n\t\tobjMatch = re.search(\'(OFFSET_)([0-4])(\\()([^\\)]+)(\\))\', strKernel)\n\n\t\tif objMatch is None:\n\t\t\tbreak\n\t\t# end\n\n\t\tintArgs = int(objMatch.group(2))\n\t\tstrArgs = objMatch.group(4).split(\',\')\n\n\t\tstrTensor = strArgs[0]\n\t\tintStrides = objVariables[strTensor].stride()\n\t\tstrIndex = [ \'((\' + strArgs[intArg + 1].replace(\'{\', \'(\').replace(\'}\', \')\').strip() + \')*\' + str(intStrides[intArg]) + \')\' for intArg in range(intArgs) ]\n\n\t\tstrKernel = strKernel.replace(objMatch.group(0), \'(\' + str.join(\'+\', strIndex) + \')\')\n\t# end\n\n\twhile True:\n\t\tobjMatch = re.search(\'(VALUE_)([0-4])(\\()([^\\)]+)(\\))\', strKernel)\n\n\t\tif objMatch is None:\n\t\t\tbreak\n\t\t# end\n\n\t\tintArgs = int(objMatch.group(2))\n\t\tstrArgs = objMatch.group(4).split(\',\')\n\n\t\tstrTensor = strArgs[0]\n\t\tintStrides = objVariables[strTensor].stride()\n\t\tstrIndex = [ \'((\' + strArgs[intArg + 1].replace(\'{\', \'(\').replace(\'}\', \')\').strip() + \')*\' + str(intStrides[intArg]) + \')\' for intArg in range(intArgs) ]\n\n\t\tstrKernel = strKernel.replace(objMatch.group(0), strTensor + \'[\' + str.join(\'+\', strIndex) + \']\')\n\t# end\n\n\treturn strKernel\n# end\n\n@cupy.util.memoize(for_each_device=True)\ndef launch_kernel(strFunction, strKernel):\n\tif \'CUDA_HOME\' not in os.environ:\n\t\tos.environ[\'CUDA_HOME\'] = sorted(glob.glob(\'/usr/lib/cuda*\') + glob.glob(\'/usr/local/cuda*\'))[-1]\n\t# end\n\n\treturn cupy.cuda.compile_with_cache(strKernel, tuple([ \'-I \' + os.environ[\'CUDA_HOME\'], \'-I \' + os.environ[\'CUDA_HOME\'] + \'/include\' ])).get_function(strFunction)\n# end\n\ndef depth_to_points(tenDepth, fltFocal):\n\ttenHorizontal = torch.linspace((-0.5 * tenDepth.shape[3]) + 0.5, (0.5 * tenDepth.shape[3]) - 0.5, tenDepth.shape[3]).view(1, 1, 1, tenDepth.shape[3]).expand(tenDepth.shape[0], -1, tenDepth.shape[2], -1)\n\ttenHorizontal = tenHorizontal * (1.0 / fltFocal)\n\ttenHorizontal = tenHorizontal.type_as(tenDepth)\n\n\ttenVertical = torch.linspace((-0.5 * tenDepth.shape[2]) + 0.5, (0.5 * tenDepth.shape[2]) - 0.5, tenDepth.shape[2]).view(1, 1, tenDepth.shape[2], 1).expand(tenDepth.shape[0], -1, -1, tenDepth.shape[3])\n\ttenVertical = tenVertical * (1.0 / fltFocal)\n\ttenVertical = tenVertical.type_as(tenDepth)\n\n\treturn torch.cat([ tenDepth * tenHorizontal, tenDepth * tenVertical, tenDepth ], 1)\n# end\n\ndef spatial_filter(tenInput, strType):\n\ttenOutput = None\n\n\tif strType == \'laplacian\':\n\t\ttenLaplacian = tenInput.new_zeros(tenInput.shape[1], tenInput.shape[1], 3, 3)\n\n\t\tfor intKernel in range(tenInput.shape[1]):\n\t\t\ttenLaplacian[intKernel, intKernel, 0, 1] = -1.0\n\t\t\ttenLaplacian[intKernel, intKernel, 0, 2] = -1.0\n\t\t\ttenLaplacian[intKernel, intKernel, 1, 1] = 4.0\n\t\t\ttenLaplacian[intKernel, intKernel, 1, 0] = -1.0\n\t\t\ttenLaplacian[intKernel, intKernel, 2, 0] = -1.0\n\t\t# end\n\n\t\ttenOutput = torch.nn.functional.pad(input=tenInput, pad=[ 1, 1, 1, 1 ], mode=\'replicate\')\n\t\ttenOutput = torch.nn.functional.conv2d(input=tenOutput, weight=tenLaplacian)\n\n\telif strType == \'median-3\':\n\t\ttenOutput = torch.nn.functional.pad(input=tenInput, pad=[ 1, 1, 1, 1 ], mode=\'reflect\')\n\t\ttenOutput = tenOutput.unfold(2, 3, 1).unfold(3, 3, 1)\n\t\ttenOutput = tenOutput.contiguous().view(tenOutput.shape[0], tenOutput.shape[1], tenOutput.shape[2], tenOutput.shape[3], 3 * 3)\n\t\ttenOutput = tenOutput.median(-1, False)[0]\n\n\telif strType == \'median-5\':\n\t\ttenOutput = torch.nn.functional.pad(input=tenInput, pad=[ 2, 2, 2, 2 ], mode=\'reflect\')\n\t\ttenOutput = tenOutput.unfold(2, 5, 1).unfold(3, 5, 1)\n\t\ttenOutput = tenOutput.contiguous().view(tenOutput.shape[0], tenOutput.shape[1], tenOutput.shape[2], tenOutput.shape[3], 5 * 5)\n\t\ttenOutput = tenOutput.median(-1, False)[0]\n\n\t# end\n\n\treturn tenOutput\n# end\n\ndef render_pointcloud(tenInput, tenData, intWidth, intHeight, fltFocal, fltBaseline):\n\ttenData = torch.cat([ tenData, tenData.new_ones([ tenData.shape[0], 1, tenData.shape[2] ]) ], 1)\n\n\ttenZee = tenInput.new_zeros([ tenData.shape[0], 1, intHeight, intWidth ]).fill_(1000000.0)\n\ttenOutput = tenInput.new_zeros([ tenData.shape[0], tenData.shape[1], intHeight, intWidth ])\n\n\tn = tenInput.shape[0] * tenInput.shape[2]\n\tlaunch_kernel(\'kernel_pointrender_updateZee\', preprocess_kernel(\'\'\'\n\t\textern ""C"" __global__ void kernel_pointrender_updateZee(\n\t\t\tconst int n,\n\t\t\tconst float* input,\n\t\t\tconst float* data,\n\t\t\tconst float* zee\n\t\t) { for (int intIndex = (blockIdx.x * blockDim.x) + threadIdx.x; intIndex < n; intIndex += blockDim.x * gridDim.x) {\n\t\t\tconst int intSample = ( intIndex / SIZE_2(input) ) % SIZE_0(input);\n\t\t\tconst int intPoint  = ( intIndex                 ) % SIZE_2(input);\n\n\t\t\tassert(SIZE_1(input) == 3);\n\t\t\tassert(SIZE_1(zee) == 1);\n\n\t\t\tfloat3 fltPlanePoint = make_float3(0.0, 0.0, {{fltFocal}});\n\t\t\tfloat3 fltPlaneNormal = make_float3(0.0, 0.0, 1.0);\n\n\t\t\tfloat3 fltLinePoint = make_float3(VALUE_3(input, intSample, 0, intPoint), VALUE_3(input, intSample, 1, intPoint), VALUE_3(input, intSample, 2, intPoint));\n\t\t\tfloat3 fltLineVector = make_float3(0.0, 0.0, 0.0) - fltLinePoint;\n\n\t\t\tif (fltLinePoint.z < 0.001) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfloat fltNumerator = dot(fltPlanePoint - fltLinePoint, fltPlaneNormal);\n\t\t\tfloat fltDenominator = dot(fltLineVector, fltPlaneNormal);\n\t\t\tfloat fltDistance = fltNumerator / fltDenominator;\n\n\t\t\tif (fabs(fltDenominator) < 0.001) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfloat3 fltIntersection = fltLinePoint + (fltDistance * fltLineVector); // https://en.wikipedia.org/wiki/Line%E2%80%93plane_intersection\n\n\t\t\tfloat fltOutputX = fltIntersection.x + (0.5 * SIZE_3(zee)) - 0.5;\n\t\t\tfloat fltOutputY = fltIntersection.y + (0.5 * SIZE_2(zee)) - 0.5;\n\n\t\t\tfloat fltError = 1000000.0 - (({{fltFocal}} * {{fltBaseline}}) / (fltLinePoint.z + 0.0000001));\n\n\t\t\tint intNorthwestX = (int) (floor(fltOutputX));\n\t\t\tint intNorthwestY = (int) (floor(fltOutputY));\n\t\t\tint intNortheastX = intNorthwestX + 1;\n\t\t\tint intNortheastY = intNorthwestY;\n\t\t\tint intSouthwestX = intNorthwestX;\n\t\t\tint intSouthwestY = intNorthwestY + 1;\n\t\t\tint intSoutheastX = intNorthwestX + 1;\n\t\t\tint intSoutheastY = intNorthwestY + 1;\n\n\t\t\tfloat fltNorthwest = (intSoutheastX - fltOutputX)    * (intSoutheastY - fltOutputY);\n\t\t\tfloat fltNortheast = (fltOutputX    - intSouthwestX) * (intSouthwestY - fltOutputY);\n\t\t\tfloat fltSouthwest = (intNortheastX - fltOutputX)    * (fltOutputY    - intNortheastY);\n\t\t\tfloat fltSoutheast = (fltOutputX    - intNorthwestX) * (fltOutputY    - intNorthwestY);\n\n\t\t\tif ((fltNorthwest >= fltNortheast) & (fltNorthwest >= fltSouthwest) & (fltNorthwest >= fltSoutheast)) {\n\t\t\t\tif ((intNorthwestX >= 0) & (intNorthwestX < SIZE_3(zee)) & (intNorthwestY >= 0) & (intNorthwestY < SIZE_2(zee))) {\n\t\t\t\t\tatomicMin(&zee[OFFSET_4(zee, intSample, 0, intNorthwestY, intNorthwestX)], fltError);\n\t\t\t\t}\n\n\t\t\t} else if ((fltNortheast >= fltNorthwest) & (fltNortheast >= fltSouthwest) & (fltNortheast >= fltSoutheast)) {\n\t\t\t\tif ((intNortheastX >= 0) & (intNortheastX < SIZE_3(zee)) & (intNortheastY >= 0) & (intNortheastY < SIZE_2(zee))) {\n\t\t\t\t\tatomicMin(&zee[OFFSET_4(zee, intSample, 0, intNortheastY, intNortheastX)], fltError);\n\t\t\t\t}\n\n\t\t\t} else if ((fltSouthwest >= fltNorthwest) & (fltSouthwest >= fltNortheast) & (fltSouthwest >= fltSoutheast)) {\n\t\t\t\tif ((intSouthwestX >= 0) & (intSouthwestX < SIZE_3(zee)) & (intSouthwestY >= 0) & (intSouthwestY < SIZE_2(zee))) {\n\t\t\t\t\tatomicMin(&zee[OFFSET_4(zee, intSample, 0, intSouthwestY, intSouthwestX)], fltError);\n\t\t\t\t}\n\n\t\t\t} else if ((fltSoutheast >= fltNorthwest) & (fltSoutheast >= fltNortheast) & (fltSoutheast >= fltSouthwest)) {\n\t\t\t\tif ((intSoutheastX >= 0) & (intSoutheastX < SIZE_3(zee)) & (intSoutheastY >= 0) & (intSoutheastY < SIZE_2(zee))) {\n\t\t\t\t\tatomicMin(&zee[OFFSET_4(zee, intSample, 0, intSoutheastY, intSoutheastX)], fltError);\n\t\t\t\t}\n\n\t\t\t}\n\t\t} }\n\t\'\'\', {\n\t\t\'intWidth\': intWidth,\n\t\t\'intHeight\': intHeight,\n\t\t\'fltFocal\': fltFocal,\n\t\t\'fltBaseline\': fltBaseline,\n\t\t\'input\': tenInput,\n\t\t\'data\': tenData,\n\t\t\'zee\': tenZee\n\t}))(\n\t\tgrid=tuple([ int((n + 512 - 1) / 512), 1, 1 ]),\n\t\tblock=tuple([ 512, 1, 1 ]),\n\t\targs=[ n, tenInput.data_ptr(), tenData.data_ptr(), tenZee.data_ptr() ]\n\t)\n\n\tn = tenZee.nelement()\n\tlaunch_kernel(\'kernel_pointrender_updateDegrid\', preprocess_kernel(\'\'\'\n\t\textern ""C"" __global__ void kernel_pointrender_updateDegrid(\n\t\t\tconst int n,\n\t\t\tconst float* input,\n\t\t\tconst float* data,\n\t\t\tfloat* zee\n\t\t) { for (int intIndex = (blockIdx.x * blockDim.x) + threadIdx.x; intIndex < n; intIndex += blockDim.x * gridDim.x) {\n\t\t\tconst int intN = ( intIndex / SIZE_3(zee) / SIZE_2(zee) / SIZE_1(zee) ) % SIZE_0(zee);\n\t\t\tconst int intC = ( intIndex / SIZE_3(zee) / SIZE_2(zee)               ) % SIZE_1(zee);\n\t\t\tconst int intY = ( intIndex / SIZE_3(zee)                             ) % SIZE_2(zee);\n\t\t\tconst int intX = ( intIndex                                           ) % SIZE_3(zee);\n\n\t\t\tassert(SIZE_1(input) == 3);\n\t\t\tassert(SIZE_1(zee) == 1);\n\n\t\t\tint intCount = 0;\n\t\t\tfloat fltSum = 0.0;\n\n\t\t\tint intOpposingX[] = {  1,  0,  1,  1 };\n\t\t\tint intOpposingY[] = {  0,  1,  1, -1 };\n\n\t\t\tfor (int intOpposing = 0; intOpposing < 4; intOpposing += 1) {\n\t\t\t\tint intOneX = intX + intOpposingX[intOpposing];\n\t\t\t\tint intOneY = intY + intOpposingY[intOpposing];\n\t\t\t\tint intTwoX = intX - intOpposingX[intOpposing];\n\t\t\t\tint intTwoY = intY - intOpposingY[intOpposing];\n\n\t\t\t\tif ((intOneX < 0) | (intOneX >= SIZE_3(zee)) | (intOneY < 0) | (intOneY >= SIZE_2(zee))) {\n\t\t\t\t\tcontinue;\n\n\t\t\t\t} else if ((intTwoX < 0) | (intTwoX >= SIZE_3(zee)) | (intTwoY < 0) | (intTwoY >= SIZE_2(zee))) {\n\t\t\t\t\tcontinue;\n\n\t\t\t\t}\n\n\t\t\t\tif (VALUE_4(zee, intN, intC, intY, intX) >= VALUE_4(zee, intN, intC, intOneY, intOneX) + 1.0) {\n\t\t\t\t\tif (VALUE_4(zee, intN, intC, intY, intX) >= VALUE_4(zee, intN, intC, intTwoY, intTwoX) + 1.0) {\n\t\t\t\t\t\tintCount += 2;\n\t\t\t\t\t\tfltSum += VALUE_4(zee, intN, intC, intOneY, intOneX);\n\t\t\t\t\t\tfltSum += VALUE_4(zee, intN, intC, intTwoY, intTwoX);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (intCount > 0) {\n\t\t\t\tzee[OFFSET_4(zee, intN, intC, intY, intX)] = min(VALUE_4(zee, intN, intC, intY, intX), fltSum / intCount);\n\t\t\t}\n\t\t} }\n\t\'\'\', {\n\t\t\'intWidth\': intWidth,\n\t\t\'intHeight\': intHeight,\n\t\t\'fltFocal\': fltFocal,\n\t\t\'fltBaseline\': fltBaseline,\n\t\t\'input\': tenInput,\n\t\t\'data\': tenData,\n\t\t\'zee\': tenZee\n\t}))(\n\t\tgrid=tuple([ int((n + 512 - 1) / 512), 1, 1 ]),\n\t\tblock=tuple([ 512, 1, 1 ]),\n\t\targs=[ n, tenInput.data_ptr(), tenData.data_ptr(), tenZee.data_ptr() ]\n\t)\n\n\tn = tenInput.shape[0] * tenInput.shape[2]\n\tlaunch_kernel(\'kernel_pointrender_updateOutput\', preprocess_kernel(\'\'\'\n\t\textern ""C"" __global__ void kernel_pointrender_updateOutput(\n\t\t\tconst int n,\n\t\t\tconst float* input,\n\t\t\tconst float* data,\n\t\t\tconst float* zee,\n\t\t\tfloat* output\n\t\t) { for (int intIndex = (blockIdx.x * blockDim.x) + threadIdx.x; intIndex < n; intIndex += blockDim.x * gridDim.x) {\n\t\t\tconst int intSample = ( intIndex / SIZE_2(input) ) % SIZE_0(input);\n\t\t\tconst int intPoint  = ( intIndex                 ) % SIZE_2(input);\n\n\t\t\tassert(SIZE_1(input) == 3);\n\t\t\tassert(SIZE_1(zee) == 1);\n\n\t\t\tfloat3 fltPlanePoint = make_float3(0.0, 0.0, {{fltFocal}});\n\t\t\tfloat3 fltPlaneNormal = make_float3(0.0, 0.0, 1.0);\n\n\t\t\tfloat3 fltLinePoint = make_float3(VALUE_3(input, intSample, 0, intPoint), VALUE_3(input, intSample, 1, intPoint), VALUE_3(input, intSample, 2, intPoint));\n\t\t\tfloat3 fltLineVector = make_float3(0.0, 0.0, 0.0) - fltLinePoint;\n\n\t\t\tif (fltLinePoint.z < 0.001) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfloat fltNumerator = dot(fltPlanePoint - fltLinePoint, fltPlaneNormal);\n\t\t\tfloat fltDenominator = dot(fltLineVector, fltPlaneNormal);\n\t\t\tfloat fltDistance = fltNumerator / fltDenominator;\n\n\t\t\tif (fabs(fltDenominator) < 0.001) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfloat3 fltIntersection = fltLinePoint + (fltDistance * fltLineVector); // https://en.wikipedia.org/wiki/Line%E2%80%93plane_intersection\n\n\t\t\tfloat fltOutputX = fltIntersection.x + (0.5 * SIZE_3(output)) - 0.5;\n\t\t\tfloat fltOutputY = fltIntersection.y + (0.5 * SIZE_2(output)) - 0.5;\n\n\t\t\tfloat fltError = 1000000.0 - (({{fltFocal}} * {{fltBaseline}}) / (fltLinePoint.z + 0.0000001));\n\n\t\t\tint intNorthwestX = (int) (floor(fltOutputX));\n\t\t\tint intNorthwestY = (int) (floor(fltOutputY));\n\t\t\tint intNortheastX = intNorthwestX + 1;\n\t\t\tint intNortheastY = intNorthwestY;\n\t\t\tint intSouthwestX = intNorthwestX;\n\t\t\tint intSouthwestY = intNorthwestY + 1;\n\t\t\tint intSoutheastX = intNorthwestX + 1;\n\t\t\tint intSoutheastY = intNorthwestY + 1;\n\n\t\t\tfloat fltNorthwest = (intSoutheastX - fltOutputX)    * (intSoutheastY - fltOutputY);\n\t\t\tfloat fltNortheast = (fltOutputX    - intSouthwestX) * (intSouthwestY - fltOutputY);\n\t\t\tfloat fltSouthwest = (intNortheastX - fltOutputX)    * (fltOutputY    - intNortheastY);\n\t\t\tfloat fltSoutheast = (fltOutputX    - intNorthwestX) * (fltOutputY    - intNorthwestY);\n\n\t\t\tif ((intNorthwestX >= 0) & (intNorthwestX < SIZE_3(output)) & (intNorthwestY >= 0) & (intNorthwestY < SIZE_2(output))) {\n\t\t\t\tif (fltError <= VALUE_4(zee, intSample, 0, intNorthwestY, intNorthwestX) + 1.0) {\n\t\t\t\t\tfor (int intData = 0; intData < SIZE_1(data); intData += 1) {\n\t\t\t\t\t\tatomicAdd(&output[OFFSET_4(output, intSample, intData, intNorthwestY, intNorthwestX)], VALUE_3(data, intSample, intData, intPoint) * fltNorthwest);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ((intNortheastX >= 0) & (intNortheastX < SIZE_3(output)) & (intNortheastY >= 0) & (intNortheastY < SIZE_2(output))) {\n\t\t\t\tif (fltError <= VALUE_4(zee, intSample, 0, intNortheastY, intNortheastX) + 1.0) {\n\t\t\t\t\tfor (int intData = 0; intData < SIZE_1(data); intData += 1) {\n\t\t\t\t\t\tatomicAdd(&output[OFFSET_4(output, intSample, intData, intNortheastY, intNortheastX)], VALUE_3(data, intSample, intData, intPoint) * fltNortheast);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ((intSouthwestX >= 0) & (intSouthwestX < SIZE_3(output)) & (intSouthwestY >= 0) & (intSouthwestY < SIZE_2(output))) {\n\t\t\t\tif (fltError <= VALUE_4(zee, intSample, 0, intSouthwestY, intSouthwestX) + 1.0) {\n\t\t\t\t\tfor (int intData = 0; intData < SIZE_1(data); intData += 1) {\n\t\t\t\t\t\tatomicAdd(&output[OFFSET_4(output, intSample, intData, intSouthwestY, intSouthwestX)], VALUE_3(data, intSample, intData, intPoint) * fltSouthwest);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ((intSoutheastX >= 0) & (intSoutheastX < SIZE_3(output)) & (intSoutheastY >= 0) & (intSoutheastY < SIZE_2(output))) {\n\t\t\t\tif (fltError <= VALUE_4(zee, intSample, 0, intSoutheastY, intSoutheastX) + 1.0) {\n\t\t\t\t\tfor (int intData = 0; intData < SIZE_1(data); intData += 1) {\n\t\t\t\t\t\tatomicAdd(&output[OFFSET_4(output, intSample, intData, intSoutheastY, intSoutheastX)], VALUE_3(data, intSample, intData, intPoint) * fltSoutheast);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} }\n\t\'\'\', {\n\t\t\'intWidth\': intWidth,\n\t\t\'intHeight\': intHeight,\n\t\t\'fltFocal\': fltFocal,\n\t\t\'fltBaseline\': fltBaseline,\n\t\t\'input\': tenInput,\n\t\t\'data\': tenData,\n\t\t\'zee\': tenZee,\n\t\t\'output\': tenOutput\n\t}))(\n\t\tgrid=tuple([ int((n + 512 - 1) / 512), 1, 1 ]),\n\t\tblock=tuple([ 512, 1, 1 ]),\n\t\targs=[ n, tenInput.data_ptr(), tenData.data_ptr(), tenZee.data_ptr(), tenOutput.data_ptr() ]\n\t)\n\n\treturn tenOutput[:, :-1, :, :] / (tenOutput[:, -1:, :, :] + 0.0000001), tenOutput[:, -1:, :, :].detach().clone()\n# end\n\ndef fill_disocclusion(tenInput, tenDepth):\n\ttenOutput = tenInput.clone()\n\n\tn = tenInput.shape[0] * tenInput.shape[2] * tenInput.shape[3]\n\tlaunch_kernel(\'kernel_discfill_updateOutput\', preprocess_kernel(\'\'\'\n\t\textern ""C"" __global__ void kernel_discfill_updateOutput(\n\t\t\tconst int n,\n\t\t\tconst float* input,\n\t\t\tconst float* depth,\n\t\t\tfloat* output\n\t\t) { for (int intIndex = (blockIdx.x * blockDim.x) + threadIdx.x; intIndex < n; intIndex += blockDim.x * gridDim.x) {\n\t\t\tconst int intSample = ( intIndex / SIZE_3(input) / SIZE_2(input) ) % SIZE_0(input);\n\t\t\tconst int intY      = ( intIndex / SIZE_3(input)                 ) % SIZE_2(input);\n\t\t\tconst int intX      = ( intIndex                                 ) % SIZE_3(input);\n\n\t\t\tassert(SIZE_1(depth) == 1);\n\n\t\t\tif (VALUE_4(depth, intSample, 0, intY, intX) > 0.0) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfloat fltShortest = 1000000.0;\n\n\t\t\tint intFillX = -1;\n\t\t\tint intFillY = -1;\n\n\t\t\tfloat fltDirectionX[] = { -1, 0, 1, 1,    -1, 1, 2,  2,    -2, -1, 1, 2, 3, 3,  3,  3 };\n\t\t\tfloat fltDirectionY[] = {  1, 1, 1, 0,     2, 2, 1, -1,     3,  3, 3, 3, 2, 1, -1, -2 };\n\n\t\t\tfor (int intDirection = 0; intDirection < 16; intDirection += 1) {\n\t\t\t\tfloat fltNormalize = sqrt((fltDirectionX[intDirection] * fltDirectionX[intDirection]) + (fltDirectionY[intDirection] * fltDirectionY[intDirection]));\n\n\t\t\t\tfltDirectionX[intDirection] /= fltNormalize;\n\t\t\t\tfltDirectionY[intDirection] /= fltNormalize;\n\t\t\t}\n\n\t\t\tfor (int intDirection = 0; intDirection < 16; intDirection += 1) {\n\t\t\t\tfloat fltFromX = intX; int intFromX = 0;\n\t\t\t\tfloat fltFromY = intY; int intFromY = 0;\n\n\t\t\t\tfloat fltToX = intX; int intToX = 0;\n\t\t\t\tfloat fltToY = intY; int intToY = 0;\n\n\t\t\t\tdo {\n\t\t\t\t\tfltFromX -= fltDirectionX[intDirection]; intFromX = (int) (round(fltFromX));\n\t\t\t\t\tfltFromY -= fltDirectionY[intDirection]; intFromY = (int) (round(fltFromY));\n\n\t\t\t\t\tif ((intFromX < 0) | (intFromX >= SIZE_3(input))) { break; }\n\t\t\t\t\tif ((intFromY < 0) | (intFromY >= SIZE_2(input))) { break; }\n\t\t\t\t\tif (VALUE_4(depth, intSample, 0, intFromY, intFromX) > 0.0) { break; }\n\t\t\t\t} while (true);\n\t\t\t\tif ((intFromX < 0) | (intFromX >= SIZE_3(input))) { continue; }\n\t\t\t\tif ((intFromY < 0) | (intFromY >= SIZE_2(input))) { continue; }\n\n\t\t\t\tdo {\n\t\t\t\t\tfltToX += fltDirectionX[intDirection]; intToX = (int) (round(fltToX));\n\t\t\t\t\tfltToY += fltDirectionY[intDirection]; intToY = (int) (round(fltToY));\n\n\t\t\t\t\tif ((intToX < 0) | (intToX >= SIZE_3(input))) { break; }\n\t\t\t\t\tif ((intToY < 0) | (intToY >= SIZE_2(input))) { break; }\n\t\t\t\t\tif (VALUE_4(depth, intSample, 0, intToY, intToX) > 0.0) { break; }\n\t\t\t\t} while (true);\n\t\t\t\tif ((intToX < 0) | (intToX >= SIZE_3(input))) { continue; }\n\t\t\t\tif ((intToY < 0) | (intToY >= SIZE_2(input))) { continue; }\n\n\t\t\t\tfloat fltDistance = sqrt(powf(intToX - intFromX, 2) + powf(intToY - intFromY, 2));\n\n\t\t\t\tif (fltShortest > fltDistance) {\n\t\t\t\t\tintFillX = intFromX;\n\t\t\t\t\tintFillY = intFromY;\n\n\t\t\t\t\tif (VALUE_4(depth, intSample, 0, intFromY, intFromX) < VALUE_4(depth, intSample, 0, intToY, intToX)) {\n\t\t\t\t\t\tintFillX = intToX;\n\t\t\t\t\t\tintFillY = intToY;\n\t\t\t\t\t}\n\n\t\t\t\t\tfltShortest = fltDistance;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (intFillX == -1) {\n\t\t\t\treturn;\n\n\t\t\t} else if (intFillY == -1) {\n\t\t\t\treturn;\n\n\t\t\t}\n\n\t\t\tfor (int intDepth = 0; intDepth < SIZE_1(input); intDepth += 1) {\n\t\t\t\toutput[OFFSET_4(output, intSample, intDepth, intY, intX)] = VALUE_4(input, intSample, intDepth, intFillY, intFillX);\n\t\t\t}\n\t\t} }\n\t\'\'\', {\n\t\t\'input\': tenInput,\n\t\t\'depth\': tenDepth,\n\t\t\'output\': tenOutput\n\t}))(\n\t\tgrid=tuple([ int((n + 512 - 1) / 512), 1, 1 ]),\n\t\tblock=tuple([ 512, 1, 1 ]),\n\t\targs=[ n, tenInput.data_ptr(), tenDepth.data_ptr(), tenOutput.data_ptr() ]\n\t)\n\n\treturn tenOutput\n# end'"
depthestim.py,6,"b""#!/usr/bin/env python\n\nimport torch\nimport torchvision\n\nimport base64\nimport cupy\nimport cv2\nimport flask\nimport getopt\nimport gevent\nimport gevent.pywsgi\nimport glob\nimport h5py\nimport io\nimport math\nimport moviepy\nimport moviepy.editor\nimport numpy\nimport os\nimport random\nimport re\nimport scipy\nimport scipy.io\nimport shutil\nimport sys\nimport tempfile\nimport time\nimport urllib\nimport zipfile\n\n##########################################################\n\nassert(int(str('').join(torch.__version__.split('.')[0:2])) >= 12) # requires at least pytorch version 1.2.0\n\ntorch.set_grad_enabled(False) # make sure to not compute gradients for computational performance\n\ntorch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance\n\n##########################################################\n\nobjCommon = {}\n\nexec(open('./common.py', 'r').read())\n\nexec(open('./models/disparity-estimation.py', 'r').read())\nexec(open('./models/disparity-adjustment.py', 'r').read())\nexec(open('./models/disparity-refinement.py', 'r').read())\nexec(open('./models/pointcloud-inpainting.py', 'r').read())\n\n##########################################################\n\narguments_strIn = './images/doublestrike.jpg'\narguments_strOut = './depthestim.npy'\n\nfor strOption, strArgument in getopt.getopt(sys.argv[1:], '', [ strParameter[2:] + '=' for strParameter in sys.argv[1::2] ])[0]:\n\tif strOption == '--in' and strArgument != '': arguments_strIn = strArgument # path to the input image\n\tif strOption == '--out' and strArgument != '': arguments_strOut = strArgument # path to where the output should be stored\n# end\n\n##########################################################\n\nif __name__ == '__main__':\n\tnpyImage = cv2.imread(filename=arguments_strIn, flags=cv2.IMREAD_COLOR)\n\n\tfltFocal = max(npyImage.shape[0], npyImage.shape[1]) / 2.0\n\tfltBaseline = 40.0\n\n\ttenImage = torch.FloatTensor(numpy.ascontiguousarray(npyImage.transpose(2, 0, 1)[None, :, :, :].astype(numpy.float32) * (1.0 / 255.0))).cuda()\n\ttenDisparity = disparity_estimation(tenImage)\n\ttenDisparity = disparity_refinement(torch.nn.functional.interpolate(input=tenImage, size=(tenDisparity.shape[2] * 4, tenDisparity.shape[3] * 4), mode='bilinear', align_corners=False), tenDisparity)\n\ttenDisparity = torch.nn.functional.interpolate(input=tenDisparity, size=(tenImage.shape[2], tenImage.shape[3]), mode='bilinear', align_corners=False) * (max(tenImage.shape[2], tenImage.shape[3]) / 256.0)\n\ttenDepth = (fltFocal * fltBaseline) / (tenDisparity + 0.0000001)\n\n\tnpyDisparity = tenDisparity[0, 0, :, :].cpu().numpy()\n\tnpyDepth = tenDepth[0, 0, :, :].cpu().numpy()\n\n\tcv2.imwrite(filename=arguments_strOut.replace('.npy', '.png'), img=(npyDisparity / fltBaseline * 255.0).clip(0.0, 255.0).astype(numpy.uint8))\n\n\tnumpy.save(arguments_strOut, npyDepth)\n# end"""
interface.py,4,"b""#!/usr/bin/env python\n\nimport torch\nimport torchvision\n\nimport base64\nimport cupy\nimport cv2\nimport flask\nimport getopt\nimport gevent\nimport gevent.pywsgi\nimport glob\nimport h5py\nimport io\nimport math\nimport moviepy\nimport moviepy.editor\nimport numpy\nimport os\nimport random\nimport re\nimport scipy\nimport scipy.io\nimport shutil\nimport sys\nimport tempfile\nimport time\nimport urllib\nimport zipfile\n\n##########################################################\n\nassert(int(str('').join(torch.__version__.split('.')[0:2])) >= 12) # requires at least pytorch version 1.2.0\n\ntorch.set_grad_enabled(False) # make sure to not compute gradients for computational performance\n\ntorch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance\n\n##########################################################\n\nobjCommon = {}\n\nexec(open('./common.py', 'r').read())\n\nexec(open('./models/disparity-estimation.py', 'r').read())\nexec(open('./models/disparity-adjustment.py', 'r').read())\nexec(open('./models/disparity-refinement.py', 'r').read())\nexec(open('./models/pointcloud-inpainting.py', 'r').read())\n\n##########################################################\n\nobjPlayback = {\n\t'strImage': None,\n\t'npyImage': None,\n\t'strMode': 'automatic',\n\t'intTime': 0,\n\t'fltTime': numpy.linspace(0.0, 1.0, 75).tolist() + list(reversed(numpy.linspace(0.0, 1.0, 75).tolist())),\n\t'strCache': {},\n\t'objFrom': {\n\t\t'fltCenterU': 512.0,\n\t\t'fltCenterV': 384.0,\n\t\t'intCropWidth': 1024,\n\t\t'intCropHeight': 768\n\t},\n\t'objTo': {\n\t\t'fltCenterU': 512.0,\n\t\t'fltCenterV': 384.0,\n\t\t'intCropWidth': 1024,\n\t\t'intCropHeight': 768\n\t}\n}\n\nobjFlask = flask.Flask(import_name=__name__, static_url_path='', static_folder=os.path.abspath('./'))\n\n@objFlask.route(rule='/', methods=[ 'GET' ])\ndef index():\n\treturn objFlask.send_static_file('interface.html')\n# end\n\n@objFlask.route(rule='/load_image', methods=[ 'POST' ])\ndef load_image():\n\tobjPlayback['strImage'] = flask.request.form['strFile']\n\tobjPlayback['npyImage'] = numpy.ascontiguousarray(cv2.imdecode(buf=numpy.fromstring(base64.b64decode(flask.request.form['strData'].split(';base64,')[1]), numpy.uint8), flags=-1)[:, :, 0:3])\n\tobjPlayback['strCache'] = {}\n\n\tprocess_load(objPlayback['npyImage'], {})\n\n\tfor fltX, fltY in [ (100.0, 0.0), (-100.0, 0.0), (0.0, 100.0), (0.0, -100.0) ]:\n\t\tprocess_inpaint(torch.FloatTensor([ fltX, fltY, 0.0 ]).view(1, 3, 1).cuda())\n\t# end\n\n\treturn ''\n# end\n\n@objFlask.route(rule='/autozoom', methods=[ 'POST' ])\ndef autozoom():\n\tobjPlayback['objFrom'] = {\n\t\t'fltCenterU': 512.0,\n\t\t'fltCenterV': 384.0,\n\t\t'intCropWidth': 1000,\n\t\t'intCropHeight': 750\n\t}\n\n\tobjPlayback['objTo'] = process_autozoom({\n\t\t'fltShift': 100.0,\n\t\t'fltZoom': 1.25,\n\t\t'objFrom': objPlayback['objFrom']\n\t})\n\n\treturn flask.jsonify({\n\t\t'objFrom': objPlayback['objFrom'],\n\t\t'objTo': objPlayback['objTo']\n\t})\n# end\n\n@objFlask.route(rule='/update_mode', methods=[ 'POST' ])\ndef update_mode():\n\tobjPlayback['strMode'] = flask.request.form['strMode']\n\n\treturn ''\n# end\n\n@objFlask.route(rule='/update_from', methods=[ 'POST' ])\ndef update_from():\n\tobjPlayback['intTime'] = objPlayback['fltTime'].index(0.0)\n\tobjPlayback['strCache'] = {}\n\tobjPlayback['objFrom']['fltCenterU'] = float(flask.request.form['fltCenterU'])\n\tobjPlayback['objFrom']['fltCenterV'] = float(flask.request.form['fltCenterV'])\n\tobjPlayback['objFrom']['intCropWidth'] = int(flask.request.form['intCropWidth'])\n\tobjPlayback['objFrom']['intCropHeight'] = int(flask.request.form['intCropHeight'])\n\n\treturn ''\n# end\n\n@objFlask.route(rule='/update_to', methods=[ 'POST' ])\ndef update_to():\n\tobjPlayback['intTime'] = objPlayback['fltTime'].index(1.0)\n\tobjPlayback['strCache'] = {}\n\tobjPlayback['objTo']['fltCenterU'] = float(flask.request.form['fltCenterU'])\n\tobjPlayback['objTo']['fltCenterV'] = float(flask.request.form['fltCenterV'])\n\tobjPlayback['objTo']['intCropWidth'] = int(flask.request.form['intCropWidth'])\n\tobjPlayback['objTo']['intCropHeight'] = int(flask.request.form['intCropHeight'])\n\n\treturn ''\n# end\n\n@objFlask.route(rule='/get_live', methods=[ 'GET' ])\ndef get_live():\n\tdef generator():\n\t\tfltFramelimiter = 0.0\n\n\t\twhile True:\n\t\t\tfor intYield in range(100): gevent.sleep(0.0)\n\n\t\t\tgevent.sleep(max(0.0, (1.0 / 25.0) - (time.time() - fltFramelimiter))); fltFramelimiter = time.time()\n\n\t\t\tif objPlayback['strImage'] is None:\n\t\t\t\tyield b'--frame\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n' + cv2.imencode(ext='.jpg', img=numpy.ones([ 768, 1024, 3 ], numpy.uint8) * 29, params=[ cv2.IMWRITE_JPEG_QUALITY, 80 ])[1].tobytes() + b'\\r\\n'; continue\n\t\t\t# end\n\n\t\t\tif objPlayback['intTime'] > len(objPlayback['fltTime']) - 1:\n\t\t\t\tobjPlayback['intTime'] = 0\n\t\t\t# end\n\n\t\t\tintTime = objPlayback['intTime']\n\t\t\tfltTime = objPlayback['fltTime'][intTime]\n\n\t\t\tif objPlayback['strMode'] == 'automatic':\n\t\t\t\tobjPlayback['intTime'] += 1\n\t\t\t# end\n\n\t\t\tif str(fltTime) not in objPlayback['strCache']:\n\t\t\t\tnpyKenburns = process_kenburns({\n\t\t\t\t\t'fltSteps': [ fltTime ],\n\t\t\t\t\t'objFrom': objPlayback['objFrom'],\n\t\t\t\t\t'objTo': objPlayback['objTo'],\n\t\t\t\t\t'boolInpaint': False\n\t\t\t\t})[0]\n\n\t\t\t\tobjPlayback['strCache'][str(fltTime)] = b'--frame\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n' + cv2.imencode(ext='.jpg', img=npyKenburns, params=[ cv2.IMWRITE_JPEG_QUALITY, 80 ])[1].tobytes() + b'\\r\\n'\n\t\t\t# end\n\n\t\t\tyield objPlayback['strCache'][str(fltTime)]\n\t\t# end\n\t# end\n\n\treturn flask.Response(response=generator(), mimetype='multipart/x-mixed-replace; boundary=frame')\n# end\n\n@objFlask.route(rule='/get_result', methods=[ 'GET' ])\ndef get_result():\n\tstrTempdir = tempfile.gettempdir() + '/kenburns-' + str(os.getpid()) + '-' + str.join('', [ random.choice('abcdefghijklmnopqrstuvwxyz0123456789') for intCount in range(20) ])\n\n\tos.makedirs(strTempdir + '/')\n\n\tnpyKenburns = process_kenburns({\n\t\t'fltSteps': numpy.linspace(0.0, 1.0, 75).tolist(),\n\t\t'objFrom': objPlayback['objFrom'],\n\t\t'objTo': objPlayback['objTo'],\n\t\t'boolInpaint': True\n\t})\n\n\tmoviepy.editor.ImageSequenceClip(sequence=[ npyFrame[:, :, ::-1] for npyFrame in npyKenburns + list(reversed(npyKenburns))[1:] ], fps=25).write_videofile(strTempdir + '/kenburns.mp4')\n\n\tobjKenburns = io.BytesIO(open(strTempdir + '/kenburns.mp4', 'rb').read())\n\n\tshutil.rmtree(strTempdir + '/')\n\n\treturn flask.send_file(filename_or_fp=objKenburns, mimetype='video/mp4', as_attachment=True, attachment_filename='kenburns.mp4', cache_timeout=-1)\n# end\n\ngevent.pywsgi.WSGIServer(listener=('0.0.0.0', 8080), application=objFlask).serve_forever()"""
models/disparity-adjustment.py,4,"b""moduleMaskrcnn = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True).cuda().eval()\n\ndef disparity_adjustment(tenImage, tenDisparity):\n\tassert(tenImage.shape[0] == 1)\n\tassert(tenDisparity.shape[0] == 1)\n\n\tboolUsed = {}\n\ttenMasks = []\n\n\tobjPredictions = moduleMaskrcnn([ tenImage[ 0, [ 2, 0, 1 ], :, : ] ])[0]\n\n\tfor intMask in range(objPredictions['masks'].shape[0]):\n\t\tif intMask in boolUsed:\n\t\t\tcontinue\n\n\t\telif objPredictions['scores'][intMask].item() < 0.7:\n\t\t\tcontinue\n\n\t\telif objPredictions['labels'][intMask].item() not in [ 1, 3, 6, 7, 8, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25 ]:\n\t\t\tcontinue\n\n\t\t# end\n\n\t\tboolUsed[intMask] = True\n\t\ttenMask = (objPredictions['masks'][(intMask + 0):(intMask + 1), :, :, :] > 0.5).float()\n\n\t\tif tenMask.sum().item() < 64:\n\t\t\tcontinue\n\t\t# end\n\n\t\tfor intMerge in range(objPredictions['masks'].shape[0]):\n\t\t\tif intMerge in boolUsed:\n\t\t\t\tcontinue\n\n\t\t\telif objPredictions['scores'][intMerge].item() < 0.7:\n\t\t\t\tcontinue\n\n\t\t\telif objPredictions['labels'][intMerge].item() not in [ 2, 4, 27, 28, 31, 32, 33 ]:\n\t\t\t\tcontinue\n\n\t\t\t# end\n\n\t\t\ttenMerge = (objPredictions['masks'][(intMerge + 0):(intMerge + 1), :, :, :] > 0.5).float()\n\n\t\t\tif ((tenMask + tenMerge) > 1.0).sum().item() < 0.03 * tenMerge.sum().item():\n\t\t\t\tcontinue\n\t\t\t# end\n\n\t\t\tboolUsed[intMerge] = True\n\t\t\ttenMask = (tenMask + tenMerge).clamp(0.0, 1.0)\n\t\t# end\n\n\t\ttenMasks.append(tenMask)\n\t# end\n\n\ttenAdjusted = torch.nn.functional.interpolate(input=tenDisparity, size=(tenImage.shape[2], tenImage.shape[3]), mode='bilinear', align_corners=False)\n\n\tfor tenAdjust in tenMasks:\n\t\ttenPlane = tenAdjusted * tenAdjust\n\n\t\ttenPlane = torch.nn.functional.max_pool2d(input=tenPlane.neg(), kernel_size=3, stride=1, padding=1).neg()\n\t\ttenPlane = torch.nn.functional.max_pool2d(input=tenPlane.neg(), kernel_size=3, stride=1, padding=1).neg()\n\n\t\tintLeft = (tenPlane.sum(2, True) > 0.0).flatten().nonzero()[0].item()\n\t\tintTop = (tenPlane.sum(3, True) > 0.0).flatten().nonzero()[0].item()\n\t\tintRight = (tenPlane.sum(2, True) > 0.0).flatten().nonzero()[-1].item()\n\t\tintBottom = (tenPlane.sum(3, True) > 0.0).flatten().nonzero()[-1].item()\n\n\t\ttenAdjusted = ((1.0 - tenAdjust) * tenAdjusted) + (tenAdjust * tenPlane[:, :, int(round(intTop + (0.97 * (intBottom - intTop)))):, :].max())\n\t# end\n\n\treturn torch.nn.functional.interpolate(input=tenAdjusted, size=(tenDisparity.shape[2], tenDisparity.shape[3]), mode='bilinear', align_corners=False)\n# end"""
models/disparity-estimation.py,40,"b""class Basic(torch.nn.Module):\n\tdef __init__(self, strType, intChannels):\n\t\tsuper(Basic, self).__init__()\n\n\t\tif strType == 'relu-conv-relu-conv':\n\t\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t\t)\n\n\t\telif strType == 'conv-relu-conv':\n\t\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t\t)\n\n\t\t# end\n\n\t\tif intChannels[0] == intChannels[2]:\n\t\t\tself.moduleShortcut = None\n\n\t\telif intChannels[0] != intChannels[2]:\n\t\t\tself.moduleShortcut = torch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[2], kernel_size=1, stride=1, padding=0)\n\n\t\t# end\n\t# end\n\n\tdef forward(self, tenInput):\n\t\tif self.moduleShortcut is None:\n\t\t\treturn self.moduleMain(tenInput) + tenInput\n\n\t\telif self.moduleShortcut is not None:\n\t\t\treturn self.moduleMain(tenInput) + self.moduleShortcut(tenInput)\n\n\t\t# end\n\t# end\n# end\n\nclass Downsample(torch.nn.Module):\n\tdef __init__(self, intChannels):\n\t\tsuper(Downsample, self).__init__()\n\n\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=2, padding=1),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t)\n\t# end\n\n\tdef forward(self, tenInput):\n\t\treturn self.moduleMain(tenInput)\n\t# end\n# end\n\nclass Upsample(torch.nn.Module):\n\tdef __init__(self, intChannels):\n\t\tsuper(Upsample, self).__init__()\n\n\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\ttorch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t)\n\t# end\n\n\tdef forward(self, tenInput):\n\t\treturn self.moduleMain(tenInput)\n\t# end\n# end\n\nclass Semantics(torch.nn.Module):\n\tdef __init__(self):\n\t\tsuper(Semantics, self).__init__()\n\n\t\tmoduleVgg = torchvision.models.vgg19_bn(pretrained=True).features.eval()\n\n\t\tself.moduleVgg = torch.nn.Sequential(\n\t\t\tmoduleVgg[0:3],\n\t\t\tmoduleVgg[3:6],\n\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n\t\t\tmoduleVgg[7:10],\n\t\t\tmoduleVgg[10:13],\n\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n\t\t\tmoduleVgg[14:17],\n\t\t\tmoduleVgg[17:20],\n\t\t\tmoduleVgg[20:23],\n\t\t\tmoduleVgg[23:26],\n\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True),\n\t\t\tmoduleVgg[27:30],\n\t\t\tmoduleVgg[30:33],\n\t\t\tmoduleVgg[33:36],\n\t\t\tmoduleVgg[36:39],\n\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)\n\t\t)\n\t# end\n\n\tdef forward(self, tenInput):\n\t\ttenPreprocessed = tenInput[:, [ 2, 1, 0 ], :, :]\n\n\t\ttenPreprocessed[:, 0, :, :] = (tenPreprocessed[:, 0, :, :] - 0.485) / 0.229\n\t\ttenPreprocessed[:, 1, :, :] = (tenPreprocessed[:, 1, :, :] - 0.456) / 0.224\n\t\ttenPreprocessed[:, 2, :, :] = (tenPreprocessed[:, 2, :, :] - 0.406) / 0.225\n\n\t\treturn self.moduleVgg(tenPreprocessed)\n\t# end\n# end\n\nclass Disparity(torch.nn.Module):\n\tdef __init__(self):\n\t\tsuper(Disparity, self).__init__()\n\n\t\tself.moduleImage = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7, stride=2, padding=3)\n\t\tself.moduleSemantics = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n\n\t\tfor intRow, intFeatures in [ (0, 32), (1, 48), (2, 64), (3, 512), (4, 512), (5, 512) ]:\n\t\t\tself.add_module(str(intRow) + 'x0' + ' - ' + str(intRow) + 'x1', Basic('relu-conv-relu-conv', [ intFeatures, intFeatures, intFeatures ]))\n\t\t\tself.add_module(str(intRow) + 'x1' + ' - ' + str(intRow) + 'x2', Basic('relu-conv-relu-conv', [ intFeatures, intFeatures, intFeatures ]))\n\t\t\tself.add_module(str(intRow) + 'x2' + ' - ' + str(intRow) + 'x3', Basic('relu-conv-relu-conv', [ intFeatures, intFeatures, intFeatures ]))\n\t\t# end\n\n\t\tfor intCol in [ 0, 1 ]:\n\t\t\tself.add_module('0x' + str(intCol) + ' - ' + '1x' + str(intCol), Downsample([ 32, 48, 48 ]))\n\t\t\tself.add_module('1x' + str(intCol) + ' - ' + '2x' + str(intCol), Downsample([ 48, 64, 64 ]))\n\t\t\tself.add_module('2x' + str(intCol) + ' - ' + '3x' + str(intCol), Downsample([ 64, 512, 512 ]))\n\t\t\tself.add_module('3x' + str(intCol) + ' - ' + '4x' + str(intCol), Downsample([ 512, 512, 512 ]))\n\t\t\tself.add_module('4x' + str(intCol) + ' - ' + '5x' + str(intCol), Downsample([ 512, 512, 512 ]))\n\t\t# end\n\n\t\tfor intCol in [ 2, 3 ]:\n\t\t\tself.add_module('5x' + str(intCol) + ' - ' + '4x' + str(intCol), Upsample([ 512, 512, 512 ]))\n\t\t\tself.add_module('4x' + str(intCol) + ' - ' + '3x' + str(intCol), Upsample([ 512, 512, 512 ]))\n\t\t\tself.add_module('3x' + str(intCol) + ' - ' + '2x' + str(intCol), Upsample([ 512, 64, 64 ]))\n\t\t\tself.add_module('2x' + str(intCol) + ' - ' + '1x' + str(intCol), Upsample([ 64, 48, 48 ]))\n\t\t\tself.add_module('1x' + str(intCol) + ' - ' + '0x' + str(intCol), Upsample([ 48, 32, 32 ]))\n\t\t# end\n\n\t\tself.moduleDisparity = Basic('conv-relu-conv', [ 32, 32, 1 ])\n\t# end\n\n\tdef forward(self, tenImage, tenSemantics):\n\t\ttenColumn = [ None, None, None, None, None, None ]\n\n\t\ttenColumn[0] = self.moduleImage(tenImage)\n\t\ttenColumn[1] = self._modules['0x0 - 1x0'](tenColumn[0])\n\t\ttenColumn[2] = self._modules['1x0 - 2x0'](tenColumn[1])\n\t\ttenColumn[3] = self._modules['2x0 - 3x0'](tenColumn[2]) + self.moduleSemantics(tenSemantics)\n\t\ttenColumn[4] = self._modules['3x0 - 4x0'](tenColumn[3])\n\t\ttenColumn[5] = self._modules['4x0 - 5x0'](tenColumn[4])\n\n\t\tintColumn = 1\n\t\tfor intRow in range(len(tenColumn)):\n\t\t\ttenColumn[intRow] = self._modules[str(intRow) + 'x' + str(intColumn - 1) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow])\n\t\t\tif intRow != 0:\n\t\t\t\ttenColumn[intRow] += self._modules[str(intRow - 1) + 'x' + str(intColumn) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow - 1])\n\t\t\t# end\n\t\t# end\n\n\t\tintColumn = 2\n\t\tfor intRow in range(len(tenColumn) -1, -1, -1):\n\t\t\ttenColumn[intRow] = self._modules[str(intRow) + 'x' + str(intColumn - 1) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow])\n\t\t\tif intRow != len(tenColumn) - 1:\n\t\t\t\ttenUp = self._modules[str(intRow + 1) + 'x' + str(intColumn) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow + 1])\n\n\t\t\t\tif tenUp.shape[2] != tenColumn[intRow].shape[2]: tenUp = torch.nn.functional.pad(input=tenUp, pad=[ 0, 0, 0, -1 ], mode='constant', value=0.0)\n\t\t\t\tif tenUp.shape[3] != tenColumn[intRow].shape[3]: tenUp = torch.nn.functional.pad(input=tenUp, pad=[ 0, -1, 0, 0 ], mode='constant', value=0.0)\n\n\t\t\t\ttenColumn[intRow] += tenUp\n\t\t\t# end\n\t\t# end\n\n\t\tintColumn = 3\n\t\tfor intRow in range(len(tenColumn) -1, -1, -1):\n\t\t\ttenColumn[intRow] = self._modules[str(intRow) + 'x' + str(intColumn - 1) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow])\n\t\t\tif intRow != len(tenColumn) - 1:\n\t\t\t\ttenUp = self._modules[str(intRow + 1) + 'x' + str(intColumn) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow + 1])\n\n\t\t\t\tif tenUp.shape[2] != tenColumn[intRow].shape[2]: tenUp = torch.nn.functional.pad(input=tenUp, pad=[ 0, 0, 0, -1 ], mode='constant', value=0.0)\n\t\t\t\tif tenUp.shape[3] != tenColumn[intRow].shape[3]: tenUp = torch.nn.functional.pad(input=tenUp, pad=[ 0, -1, 0, 0 ], mode='constant', value=0.0)\n\n\t\t\t\ttenColumn[intRow] += tenUp\n\t\t\t# end\n\t\t# end\n\n\t\treturn torch.nn.functional.threshold(input=self.moduleDisparity(tenColumn[0]), threshold=0.0, value=0.0)\n\t# end\n# end\n\nmoduleSemantics = Semantics().cuda().eval()\nmoduleDisparity = Disparity().cuda().eval(); moduleDisparity.load_state_dict(torch.load('./models/disparity-estimation.pytorch'))\n\ndef disparity_estimation(tenImage):\n\tintWidth = tenImage.shape[3]\n\tintHeight = tenImage.shape[2]\n\n\tfltRatio = float(intWidth) / float(intHeight)\n\n\tintWidth = min(int(512 * fltRatio), 512)\n\tintHeight = min(int(512 / fltRatio), 512)\n\n\ttenImage = torch.nn.functional.interpolate(input=tenImage, size=(intHeight, intWidth), mode='bilinear', align_corners=False)\n\n\treturn moduleDisparity(tenImage, moduleSemantics(tenImage))\n# end"""
models/disparity-refinement.py,33,"b""class Basic(torch.nn.Module):\n\tdef __init__(self, strType, intChannels):\n\t\tsuper(Basic, self).__init__()\n\n\t\tif strType == 'relu-conv-relu-conv':\n\t\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t\t)\n\n\t\telif strType == 'conv-relu-conv':\n\t\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t\t)\n\n\t\t# end\n\n\t\tif intChannels[0] == intChannels[2]:\n\t\t\tself.moduleShortcut = None\n\n\t\telif intChannels[0] != intChannels[2]:\n\t\t\tself.moduleShortcut = torch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[2], kernel_size=1, stride=1, padding=0)\n\n\t\t# end\n\t# end\n\n\tdef forward(self, tenInput):\n\t\tif self.moduleShortcut is None:\n\t\t\treturn self.moduleMain(tenInput) + tenInput\n\n\t\telif self.moduleShortcut is not None:\n\t\t\treturn self.moduleMain(tenInput) + self.moduleShortcut(tenInput)\n\n\t\t# end\n\t# end\n# end\n\nclass Downsample(torch.nn.Module):\n\tdef __init__(self, intChannels):\n\t\tsuper(Downsample, self).__init__()\n\n\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=2, padding=1),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t)\n\t# end\n\n\tdef forward(self, tenInput):\n\t\treturn self.moduleMain(tenInput)\n\t# end\n# end\n\nclass Upsample(torch.nn.Module):\n\tdef __init__(self, intChannels):\n\t\tsuper(Upsample, self).__init__()\n\n\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\ttorch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t)\n\t# end\n\n\tdef forward(self, tenInput):\n\t\treturn self.moduleMain(tenInput)\n\t# end\n# end\n\nclass Refine(torch.nn.Module):\n\tdef __init__(self):\n\t\tsuper(Refine, self).__init__()\n\n\t\tself.moduleImageOne = Basic('conv-relu-conv', [ 3, 24, 24 ])\n\t\tself.moduleImageTwo = Downsample([ 24, 48, 48 ])\n\t\tself.moduleImageThr = Downsample([ 48, 96, 96 ])\n\n\t\tself.moduleDisparityOne = Basic('conv-relu-conv', [ 1, 96, 96 ])\n\t\tself.moduleDisparityTwo = Upsample([ 192, 96, 96 ])\n\t\tself.moduleDisparityThr = Upsample([ 144, 48, 48 ])\n\t\tself.moduleDisparityFou = Basic('conv-relu-conv', [ 72, 24, 24 ])\n\n\t\tself.moduleRefine = Basic('conv-relu-conv', [ 24, 24, 1 ])\n\t# end\n\n\tdef forward(self, tenImage, tenDisparity):\n\t\ttenMean = [ tenImage.view(tenImage.shape[0], -1).mean(1, True).view(tenImage.shape[0], 1, 1, 1), tenDisparity.view(tenDisparity.shape[0], -1).mean(1, True).view(tenDisparity.shape[0], 1, 1, 1) ]\n\t\ttenStd = [ tenImage.view(tenImage.shape[0], -1).std(1, True).view(tenImage.shape[0], 1, 1, 1), tenDisparity.view(tenDisparity.shape[0], -1).std(1, True).view(tenDisparity.shape[0], 1, 1, 1) ]\n\n\t\ttenImage = tenImage.clone()\n\t\ttenImage -= tenMean[0]\n\t\ttenImage /= tenStd[0] + 0.0000001\n\n\t\ttenDisparity = tenDisparity.clone()\n\t\ttenDisparity -= tenMean[1]\n\t\ttenDisparity /= tenStd[1] + 0.0000001\n\n\t\ttenImageOne = self.moduleImageOne(tenImage)\n\t\ttenImageTwo = self.moduleImageTwo(tenImageOne)\n\t\ttenImageThr = self.moduleImageThr(tenImageTwo)\n\n\t\ttenUpsample = self.moduleDisparityOne(tenDisparity)\n\t\tif tenUpsample.shape != tenImageThr.shape: tenUpsample = torch.nn.functional.interpolate(input=tenUpsample, size=(tenImageThr.shape[2], tenImageThr.shape[3]), mode='bilinear', align_corners=False) # not ideal\n\t\ttenUpsample = self.moduleDisparityTwo(torch.cat([ tenImageThr, tenUpsample ], 1)); tenImageThr = None\n\t\tif tenUpsample.shape != tenImageTwo.shape: tenUpsample = torch.nn.functional.interpolate(input=tenUpsample, size=(tenImageTwo.shape[2], tenImageTwo.shape[3]), mode='bilinear', align_corners=False) # not ideal\n\t\ttenUpsample = self.moduleDisparityThr(torch.cat([ tenImageTwo, tenUpsample ], 1)); tenImageTwo = None\n\t\tif tenUpsample.shape != tenImageOne.shape: tenUpsample = torch.nn.functional.interpolate(input=tenUpsample, size=(tenImageOne.shape[2], tenImageOne.shape[3]), mode='bilinear', align_corners=False) # not ideal\n\t\ttenUpsample = self.moduleDisparityFou(torch.cat([ tenImageOne, tenUpsample ], 1)); tenImageOne = None\n\n\t\ttenRefine = self.moduleRefine(tenUpsample)\n\t\ttenRefine *= tenStd[1] + 0.0000001\n\t\ttenRefine += tenMean[1]\n\n\t\treturn torch.nn.functional.threshold(input=tenRefine, threshold=0.0, value=0.0)\n\t# end\n# end\n\nmoduleRefine = Refine().cuda().eval(); moduleRefine.load_state_dict(torch.load('./models/disparity-refinement.pytorch'))\n\ndef disparity_refinement(tenImage, tenDisparity):\n\treturn moduleRefine(tenImage, tenDisparity)\n# end"""
models/pointcloud-inpainting.py,39,"b""class Basic(torch.nn.Module):\n\tdef __init__(self, strType, intChannels):\n\t\tsuper(Basic, self).__init__()\n\n\t\tif strType == 'relu-conv-relu-conv':\n\t\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t\t)\n\n\t\telif strType == 'conv-relu-conv':\n\t\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t\t)\n\n\t\t# end\n\n\t\tif intChannels[0] == intChannels[2]:\n\t\t\tself.moduleShortcut = None\n\n\t\telif intChannels[0] != intChannels[2]:\n\t\t\tself.moduleShortcut = torch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[2], kernel_size=1, stride=1, padding=0)\n\n\t\t# end\n\t# end\n\n\tdef forward(self, tenInput):\n\t\tif self.moduleShortcut is None:\n\t\t\treturn self.moduleMain(tenInput) + tenInput\n\n\t\telif self.moduleShortcut is not None:\n\t\t\treturn self.moduleMain(tenInput) + self.moduleShortcut(tenInput)\n\n\t\t# end\n\t# end\n# end\n\nclass Downsample(torch.nn.Module):\n\tdef __init__(self, intChannels):\n\t\tsuper(Downsample, self).__init__()\n\n\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=2, padding=1),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t)\n\t# end\n\n\tdef forward(self, tenInput):\n\t\treturn self.moduleMain(tenInput)\n\t# end\n# end\n\nclass Upsample(torch.nn.Module):\n\tdef __init__(self, intChannels):\n\t\tsuper(Upsample, self).__init__()\n\n\t\tself.moduleMain = torch.nn.Sequential(\n\t\t\ttorch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[0], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[0], out_channels=intChannels[1], kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.PReLU(num_parameters=intChannels[1], init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=intChannels[1], out_channels=intChannels[2], kernel_size=3, stride=1, padding=1)\n\t\t)\n\t# end\n\n\tdef forward(self, tenInput):\n\t\treturn self.moduleMain(tenInput)\n\t# end\n# end\n\nclass Inpaint(torch.nn.Module):\n\tdef __init__(self):\n\t\tsuper(Inpaint, self).__init__()\n\n\t\tself.moduleContext = torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d(in_channels=4, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True),\n\t\t\ttorch.nn.PReLU(num_parameters=64, init=0.25),\n\t\t\ttorch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True),\n\t\t\ttorch.nn.PReLU(num_parameters=64, init=0.25)\n\t\t)\n\n\t\tself.moduleInput = Basic('conv-relu-conv', [ 3 + 1 + 64 + 1, 32, 32 ])\n\n\t\tfor intRow, intFeatures in [ (0, 32), (1, 64), (2, 128), (3, 256) ]:\n\t\t\tself.add_module(str(intRow) + 'x0' + ' - ' + str(intRow) + 'x1', Basic('relu-conv-relu-conv', [ intFeatures, intFeatures, intFeatures ]))\n\t\t\tself.add_module(str(intRow) + 'x1' + ' - ' + str(intRow) + 'x2', Basic('relu-conv-relu-conv', [ intFeatures, intFeatures, intFeatures ]))\n\t\t\tself.add_module(str(intRow) + 'x2' + ' - ' + str(intRow) + 'x3', Basic('relu-conv-relu-conv', [ intFeatures, intFeatures, intFeatures ]))\n\t\t# end\n\n\t\tfor intCol in [ 0, 1 ]:\n\t\t\tself.add_module('0x' + str(intCol) + ' - ' + '1x' + str(intCol), Downsample([ 32, 64, 64 ]))\n\t\t\tself.add_module('1x' + str(intCol) + ' - ' + '2x' + str(intCol), Downsample([ 64, 128, 128 ]))\n\t\t\tself.add_module('2x' + str(intCol) + ' - ' + '3x' + str(intCol), Downsample([ 128, 256, 256 ]))\n\t\t# end\n\n\t\tfor intCol in [ 2, 3 ]:\n\t\t\tself.add_module('3x' + str(intCol) + ' - ' + '2x' + str(intCol), Upsample([ 256, 128, 128 ]))\n\t\t\tself.add_module('2x' + str(intCol) + ' - ' + '1x' + str(intCol), Upsample([ 128, 64, 64 ]))\n\t\t\tself.add_module('1x' + str(intCol) + ' - ' + '0x' + str(intCol), Upsample([ 64, 32, 32 ]))\n\t\t# end\n\n\t\tself.moduleImage = Basic('conv-relu-conv', [ 32, 32, 3 ])\n\t\tself.moduleDisparity = Basic('conv-relu-conv', [ 32, 32, 1 ])\n\t# end\n\n\tdef forward(self, tenImage, tenDisparity, tenShift):\n\t\ttenDepth = (objCommon['fltFocal'] * objCommon['fltBaseline']) / (tenDisparity + 0.0000001)\n\t\ttenValid = (spatial_filter(tenDisparity / tenDisparity.max(), 'laplacian').abs() < 0.03).float()\n\t\ttenPoints = depth_to_points(tenDepth * tenValid, objCommon['fltFocal'])\n\t\ttenPoints = tenPoints.view(1, 3, -1)\n\n\t\ttenMean = [ tenImage.view(tenImage.shape[0], -1).mean(1, True).view(tenImage.shape[0], 1, 1, 1), tenDisparity.view(tenDisparity.shape[0], -1).mean(1, True).view(tenDisparity.shape[0], 1, 1, 1) ]\n\t\ttenStd = [ tenImage.view(tenImage.shape[0], -1).std(1, True).view(tenImage.shape[0], 1, 1, 1), tenDisparity.view(tenDisparity.shape[0], -1).std(1, True).view(tenDisparity.shape[0], 1, 1, 1) ]\n\n\t\ttenImage = tenImage.clone()\n\t\ttenImage -= tenMean[0]\n\t\ttenImage /= tenStd[0] + 0.0000001\n\n\t\ttenDisparity = tenDisparity.clone()\n\t\ttenDisparity -= tenMean[1]\n\t\ttenDisparity /= tenStd[1] + 0.0000001\n\n\t\ttenContext = self.moduleContext(torch.cat([ tenImage, tenDisparity ], 1))\n\n\t\ttenRender, tenExisting = render_pointcloud(tenPoints + tenShift, torch.cat([ tenImage, tenDisparity, tenContext ], 1).view(1, 68, -1), objCommon['intWidth'], objCommon['intHeight'], objCommon['fltFocal'], objCommon['fltBaseline'])\n\n\t\ttenExisting = (tenExisting > 0.0).float()\n\t\ttenExisting = tenExisting * spatial_filter(tenExisting, 'median-5')\n\t\ttenRender = tenRender * tenExisting.clone().detach()\n\n\t\ttenColumn = [ None, None, None, None ]\n\n\t\ttenColumn[0] = self.moduleInput(torch.cat([ tenRender, tenExisting ], 1))\n\t\ttenColumn[1] = self._modules['0x0 - 1x0'](tenColumn[0])\n\t\ttenColumn[2] = self._modules['1x0 - 2x0'](tenColumn[1])\n\t\ttenColumn[3] = self._modules['2x0 - 3x0'](tenColumn[2])\n\n\t\tintColumn = 1\n\t\tfor intRow in range(len(tenColumn)):\n\t\t\ttenColumn[intRow] = self._modules[str(intRow) + 'x' + str(intColumn - 1) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow])\n\t\t\tif intRow != 0:\n\t\t\t\ttenColumn[intRow] += self._modules[str(intRow - 1) + 'x' + str(intColumn) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow - 1])\n\t\t\t# end\n\t\t# end\n\n\t\tintColumn = 2\n\t\tfor intRow in range(len(tenColumn) -1, -1, -1):\n\t\t\ttenColumn[intRow] = self._modules[str(intRow) + 'x' + str(intColumn - 1) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow])\n\t\t\tif intRow != len(tenColumn) - 1:\n\t\t\t\ttenUp = self._modules[str(intRow + 1) + 'x' + str(intColumn) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow + 1])\n\n\t\t\t\tif tenUp.shape[2] != tenColumn[intRow].shape[2]: tenUp = torch.nn.functional.pad(input=tenUp, pad=[ 0, 0, 0, -1 ], mode='constant', value=0.0)\n\t\t\t\tif tenUp.shape[3] != tenColumn[intRow].shape[3]: tenUp = torch.nn.functional.pad(input=tenUp, pad=[ 0, -1, 0, 0 ], mode='constant', value=0.0)\n\n\t\t\t\ttenColumn[intRow] += tenUp\n\t\t\t# end\n\t\t# end\n\n\t\tintColumn = 3\n\t\tfor intRow in range(len(tenColumn) -1, -1, -1):\n\t\t\ttenColumn[intRow] = self._modules[str(intRow) + 'x' + str(intColumn - 1) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow])\n\t\t\tif intRow != len(tenColumn) - 1:\n\t\t\t\ttenUp = self._modules[str(intRow + 1) + 'x' + str(intColumn) + ' - ' + str(intRow) + 'x' + str(intColumn)](tenColumn[intRow + 1])\n\n\t\t\t\tif tenUp.shape[2] != tenColumn[intRow].shape[2]: tenUp = torch.nn.functional.pad(input=tenUp, pad=[ 0, 0, 0, -1 ], mode='constant', value=0.0)\n\t\t\t\tif tenUp.shape[3] != tenColumn[intRow].shape[3]: tenUp = torch.nn.functional.pad(input=tenUp, pad=[ 0, -1, 0, 0 ], mode='constant', value=0.0)\n\n\t\t\t\ttenColumn[intRow] += tenUp\n\t\t\t# end\n\t\t# end\n\n\t\ttenImage = self.moduleImage(tenColumn[0])\n\t\ttenImage *= tenStd[0] + 0.0000001\n\t\ttenImage += tenMean[0]\n\n\t\ttenDisparity = self.moduleDisparity(tenColumn[0])\n\t\ttenDisparity *= tenStd[1] + 0.0000001\n\t\ttenDisparity += tenMean[1]\n\n\t\treturn {\n\t\t\t'tenExisting': tenExisting,\n\t\t\t'tenImage': tenImage.clamp(0.0, 1.0) if self.training == False else tenImage,\n\t\t\t'tenDisparity': torch.nn.functional.threshold(input=tenDisparity, threshold=0.0, value=0.0)\n\t\t}\n\t# end\n# end\n\nmoduleInpaint = Inpaint().cuda().eval(); moduleInpaint.load_state_dict(torch.load('./models/pointcloud-inpainting.pytorch'))\n\ndef pointcloud_inpainting(tenImage, tenDisparity, tenShift):\n\treturn moduleInpaint(tenImage, tenDisparity, tenShift)\n# end"""
