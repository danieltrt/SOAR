file_path,api_count,code
run.py,56,"b""#!/usr/bin/env python\n\nimport torch\n\nimport getopt\nimport math\nimport numpy\nimport os\nimport PIL\nimport PIL.Image\nimport sys\n\n##########################################################\n\nassert(int(str('').join(torch.__version__.split('.')[0:2])) >= 13) # requires at least pytorch version 1.3.0\n\ntorch.set_grad_enabled(False) # make sure to not compute gradients for computational performance\n\ntorch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance\n\n##########################################################\n\narguments_strModel = 'bsds500'\narguments_strIn = './images/sample.png'\narguments_strOut = './out.png'\n\nfor strOption, strArgument in getopt.getopt(sys.argv[1:], '', [ strParameter[2:] + '=' for strParameter in sys.argv[1::2] ])[0]:\n\tif strOption == '--model' and strArgument != '': arguments_strModel = strArgument # which model to use\n\tif strOption == '--in' and strArgument != '': arguments_strIn = strArgument # path to the input image\n\tif strOption == '--out' and strArgument != '': arguments_strOut = strArgument # path to where the output should be stored\n# end\n\n##########################################################\n\nclass Network(torch.nn.Module):\n\tdef __init__(self):\n\t\tsuper(Network, self).__init__()\n\n\t\tself.netVggOne = torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False),\n\t\t\ttorch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False)\n\t\t)\n\n\t\tself.netVggTwo = torch.nn.Sequential(\n\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2),\n\t\t\ttorch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False),\n\t\t\ttorch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False)\n\t\t)\n\n\t\tself.netVggThr = torch.nn.Sequential(\n\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2),\n\t\t\ttorch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False),\n\t\t\ttorch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False),\n\t\t\ttorch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False)\n\t\t)\n\n\t\tself.netVggFou = torch.nn.Sequential(\n\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2),\n\t\t\ttorch.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False),\n\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False),\n\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False)\n\t\t)\n\n\t\tself.netVggFiv = torch.nn.Sequential(\n\t\t\ttorch.nn.MaxPool2d(kernel_size=2, stride=2),\n\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False),\n\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False),\n\t\t\ttorch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n\t\t\ttorch.nn.ReLU(inplace=False)\n\t\t)\n\n\t\tself.netScoreOne = torch.nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0)\n\t\tself.netScoreTwo = torch.nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0)\n\t\tself.netScoreThr = torch.nn.Conv2d(in_channels=256, out_channels=1, kernel_size=1, stride=1, padding=0)\n\t\tself.netScoreFou = torch.nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0)\n\t\tself.netScoreFiv = torch.nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1, stride=1, padding=0)\n\n\t\tself.netCombine = torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d(in_channels=5, out_channels=1, kernel_size=1, stride=1, padding=0),\n\t\t\ttorch.nn.Sigmoid()\n\t\t)\n\n\t\tself.load_state_dict({ strKey.replace('module', 'net'): tenWeight for strKey, tenWeight in torch.load(__file__.replace('run.py', 'network-' + arguments_strModel + '.pytorch')).items() })\n\t# end\n\n\tdef forward(self, tenInput):\n\t\ttenBlue = (tenInput[:, 0:1, :, :] * 255.0) - 104.00698793\n\t\ttenGreen = (tenInput[:, 1:2, :, :] * 255.0) - 116.66876762\n\t\ttenRed = (tenInput[:, 2:3, :, :] * 255.0) - 122.67891434\n\n\t\ttenInput = torch.cat([ tenBlue, tenGreen, tenRed ], 1)\n\n\t\ttenVggOne = self.netVggOne(tenInput)\n\t\ttenVggTwo = self.netVggTwo(tenVggOne)\n\t\ttenVggThr = self.netVggThr(tenVggTwo)\n\t\ttenVggFou = self.netVggFou(tenVggThr)\n\t\ttenVggFiv = self.netVggFiv(tenVggFou)\n\n\t\ttenScoreOne = self.netScoreOne(tenVggOne)\n\t\ttenScoreTwo = self.netScoreTwo(tenVggTwo)\n\t\ttenScoreThr = self.netScoreThr(tenVggThr)\n\t\ttenScoreFou = self.netScoreFou(tenVggFou)\n\t\ttenScoreFiv = self.netScoreFiv(tenVggFiv)\n\n\t\ttenScoreOne = torch.nn.functional.interpolate(input=tenScoreOne, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n\t\ttenScoreTwo = torch.nn.functional.interpolate(input=tenScoreTwo, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n\t\ttenScoreThr = torch.nn.functional.interpolate(input=tenScoreThr, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n\t\ttenScoreFou = torch.nn.functional.interpolate(input=tenScoreFou, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n\t\ttenScoreFiv = torch.nn.functional.interpolate(input=tenScoreFiv, size=(tenInput.shape[2], tenInput.shape[3]), mode='bilinear', align_corners=False)\n\n\t\treturn self.netCombine(torch.cat([ tenScoreOne, tenScoreTwo, tenScoreThr, tenScoreFou, tenScoreFiv ], 1))\n\t# end\n# end\n\nnetNetwork = None\n\n##########################################################\n\ndef estimate(tenInput):\n\tglobal netNetwork\n\n\tif netNetwork is None:\n\t\tnetNetwork = Network().cuda().eval()\n\t# end\n\n\tintWidth = tenInput.shape[2]\n\tintHeight = tenInput.shape[1]\n\n\tassert(intWidth == 480) # remember that there is no guarantee for correctness, comment this line out if you acknowledge this and want to continue\n\tassert(intHeight == 320) # remember that there is no guarantee for correctness, comment this line out if you acknowledge this and want to continue\n\n\treturn netNetwork(tenInput.cuda().view(1, 3, intHeight, intWidth))[0, :, :, :].cpu()\n# end\n\n##########################################################\n\nif __name__ == '__main__':\n\ttenInput = torch.FloatTensor(numpy.ascontiguousarray(numpy.array(PIL.Image.open(arguments_strIn))[:, :, ::-1].transpose(2, 0, 1).astype(numpy.float32) * (1.0 / 255.0)))\n\n\ttenOutput = estimate(tenInput)\n\n\tPIL.Image.fromarray((tenOutput.clamp(0.0, 1.0).numpy().transpose(1, 2, 0)[:, :, 0] * 255.0).astype(numpy.uint8)).save(arguments_strOut)\n# end"""
comparison/comparison.py,1,"b""#!/usr/bin/env python\n\nimport math\nimport moviepy\nimport moviepy.editor\nimport numpy\nimport PIL\nimport PIL.Image\nimport PIL.ImageFont\nimport PIL.ImageDraw\n\nintX = 32\nintY = 320 - 64\n\nobjImages = [ {\n\t'strFile': '../images/sample.png',\n\t'strText': 'input'\n}, {\n\t'strFile': 'official - caffe.png',\n\t'strText': 'official - Caffe'\n}, {\n\t'strFile': 'this - pytorch.png',\n\t'strText': 'this - PyTorch'\n} ]\n\nnpyImages = []\n\nfor objImage in objImages:\n\tobjOutput = PIL.Image.open(objImage['strFile']).convert('RGB')\n\n\tfor intU in [ intShift - 10 for intShift in range(20) ]:\n\t\tfor intV in [ intShift - 10 for intShift in range(20) ]:\n\t\t\tif math.sqrt(math.pow(intU, 2.0) + math.pow(intV, 2.0)) <= 5.0:\n\t\t\t\tPIL.ImageDraw.Draw(objOutput).text((intX + intU, intY + intV), objImage['strText'], (255, 255, 255), PIL.ImageFont.truetype('freefont/FreeSerifBold.ttf', 32))\n\t\t\t# end\n\t\t# end\n\t# end\n\n\tPIL.ImageDraw.Draw(objOutput).text((intX, intY), objImage['strText'], (0, 0, 0), PIL.ImageFont.truetype('freefont/FreeSerifBold.ttf', 32))\n\n\tnpyImages.append(numpy.array(objOutput))\n# end\n\nmoviepy.editor.ImageSequenceClip(sequence=npyImages, fps=1).write_gif(filename='comparison.gif', program='ImageMagick', opt='optimizeplus')"""
