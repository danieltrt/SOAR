file_path,api_count,code
config.py,0,"b""#data\r\ndataroot='./data'  #./data/train/img      ./data/train/gt\r\ntest_img_path='./data/test/img'\r\nresult = './result'\r\n\r\nlr = 0.0001\r\ngpu_ids = [0]\r\ngpu = 1\r\ninit_type = 'xavier'\r\n\r\nresume = False\r\ncheckpoint = ''# should be file\r\ntrain_batch_size_per_gpu  = 14\r\nnum_workers = 1\r\n\r\nprint_freq = 1\r\neval_iteration = 50\r\nsave_iteration = 50\r\nmax_epochs = 1000000\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"""
data_util.py,0,"b'\'\'\'\nthis file is modified from keras implemention of data process multi-threading,\nsee https://github.com/fchollet/keras/blob/master/keras/utils/data_utils.py\n\'\'\'\nimport time\nimport numpy as np\nimport threading\nimport multiprocessing\ntry:\n    import queue\nexcept ImportError:\n    import Queue as queue\n\n\nclass GeneratorEnqueuer():\n    """"""Builds a queue out of a data generator.\n\n    Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n\n    # Arguments\n        generator: a generator function which endlessly yields data\n        use_multiprocessing: use multiprocessing if True, otherwise threading\n        wait_time: time to sleep in-between calls to `put()`\n        random_seed: Initial seed for workers,\n            will be incremented by one for each workers.\n    """"""\n\n    def __init__(self, generator,\n                 use_multiprocessing=False,\n                 wait_time=0.05,\n                 random_seed=None):\n        self.wait_time = wait_time\n        self._generator = generator\n        self._use_multiprocessing = use_multiprocessing\n        self._threads = []\n        self._stop_event = None\n        self.queue = None\n        self.random_seed = random_seed\n\n    def start(self, workers=1, max_queue_size=10):\n        """"""Kicks off threads which add data from the generator into the queue.\n\n        # Arguments\n            workers: number of worker threads\n            max_queue_size: queue size\n                (when full, threads could block on `put()`)\n        """"""\n\n        def data_generator_task():\n            while not self._stop_event.is_set():\n                try:\n                    if self._use_multiprocessing or self.queue.qsize() < max_queue_size:\n                        generator_output = next(self._generator)\n                        self.queue.put(generator_output)\n                    else:\n                        time.sleep(self.wait_time)\n                except Exception:\n                    self._stop_event.set()\n                    raise\n\n        try:\n            if self._use_multiprocessing:\n                self.queue = multiprocessing.Queue(maxsize=max_queue_size)\n                self._stop_event = multiprocessing.Event()\n            else:\n                self.queue = queue.Queue()\n                self._stop_event = threading.Event()\n\n            for _ in range(workers):\n                if self._use_multiprocessing:\n                    # Reset random seed else all children processes\n                    # share the same seed\n                    np.random.seed(self.random_seed)\n                    thread = multiprocessing.Process(target=data_generator_task)\n                    thread.daemon = True\n                    if self.random_seed is not None:\n                        self.random_seed += 1\n                else:\n                    thread = threading.Thread(target=data_generator_task)\n                self._threads.append(thread)\n                thread.start()\n        except:\n            self.stop()\n            raise\n\n    def is_running(self):\n        return self._stop_event is not None and not self._stop_event.is_set()\n\n    def stop(self, timeout=None):\n        """"""Stops running threads and wait for them to exit, if necessary.\n\n        Should be called by the same thread which called `start()`.\n\n        # Arguments\n            timeout: maximum time to wait on `thread.join()`.\n        """"""\n        if self.is_running():\n            self._stop_event.set()\n\n        for thread in self._threads:\n            if thread.is_alive():\n                if self._use_multiprocessing:\n                    thread.terminate()\n                else:\n                    thread.join(timeout)\n\n        if self._use_multiprocessing:\n            if self.queue is not None:\n                self.queue.close()\n\n        self._threads = []\n        self._stop_event = None\n        self.queue = None\n\n    def get(self):\n        """"""Creates a generator to extract data from the queue.\n\n        Skip the data if it is `None`.\n\n        # Returns\n            A generator\n        """"""\n        while self.is_running():\n            if not self.queue.empty():\n                inputs = self.queue.get()\n                if inputs is not None:\n                    yield inputs\n            else:\n                time.sleep(self.wait_time)'"
data_utils.py,9,"b'import os\nimport math\nimport random\nimport torch\nimport torchvision.transforms as transforms\nfrom torch.utils import data\nimport glob as gb\nimport numpy as np\nimport cv2\nimport csv\nimport sys\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as Patches\nfrom shapely.geometry import Polygon\nfrom PIL import Image\nimport warnings\nfrom geo_map_cython_lib import gen_geo_map\n\n\n\n\ndef get_images(root):\n    \'\'\'\n    get images\'s path and name\n    return:\n    files -- a list of img path\n    name  -- a list of img name\n    \'\'\'\n    assert os.path.isdir(root) == True, \'get_img get a wrong path:{} to imgs\'.format(root)\n    \n    files = []\n    for ext in [\'jpg\', \'png\', \'jpeg\', \'JPG\']: \n        files.extend(gb.glob(os.path.join(root, \'*.{}\'.format(ext))))\n    name = []\n    for i in range(len(files)):\n        name.append(files[i].split(\'/\')[-1])\n    \n    # check\n    for i in range(len(files)):\n        assert os.path.basename(files[i]) == name[i], \'img path cant corresponding to img name\'\n    print(\'EAST <==> Prepare <==> Total:{} imgs for train\'.format(len(files)))\n    \n    files = sorted(files)\n    name = sorted(name)\n    return files, name\n\n\ndef load_annoataion(p):\n    \'\'\'\n    load annotation from the text file\n\n    Note:\n    modified\n    1. top left vertice\n    2. clockwise\n\n    :param p:\n    :return:\n    \'\'\'\n    text_polys = []\n    text_tags = []\n    if not os.path.exists(p):\n        return np.array(text_polys, dtype=np.float32)\n    with open(p, \'r\') as f:\n        reader = csv.reader(f)\n        for line in reader: \n            label = line[-1]# strip BOM. \\ufeff for python3,  \\xef\\xbb\\bf for python2 \n            line = [i.strip(\'\\ufeff\').strip(\'\\xef\\xbb\\xbf\') for i in line] \n            x1, y1, x2, y2, x3, y3, x4, y4 = list(map(int, line[:8])) \n            text_polys.append([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n            if label == \'*\' or label == \'###\':\n                text_tags.append(True)\n            else:\n                text_tags.append(False)\n        \n    return np.array(text_polys, dtype=np.float32), np.array(text_tags, dtype=np.bool)\n    #return text_polys, text_tags\n\ndef polygon_area(poly):\n    \'\'\'\n    compute area of a polygon\n    :param poly:\n    :return:\n    \'\'\'\n    poly_ = np.array(poly)\n    assert poly_.shape == (4,2), \'poly shape should be 4,2\'\n    edge = [\n        (poly[1][0] - poly[0][0]) * (poly[1][1] + poly[0][1]),\n        (poly[2][0] - poly[1][0]) * (poly[2][1] + poly[1][1]),\n        (poly[3][0] - poly[2][0]) * (poly[3][1] + poly[2][1]),\n        (poly[0][0] - poly[3][0]) * (poly[0][1] + poly[3][1])\n    ]\n    return np.sum(edge)/2.\n\ndef calculate_distance(c1, c2):\n    return math.sqrt(math.pow(c1[0]-c2[0], 2) + math.pow(c1[1]-c2[1], 2))\n\ndef choose_best_begin_point(pre_result):\n    """"""\n    find top-left vertice and resort\n    """"""\n    final_result = []\n    for coordinate in pre_result:\n        x1 = coordinate[0][0]\n        y1 = coordinate[0][1]\n        x2 = coordinate[1][0]\n        y2 = coordinate[1][1]\n        x3 = coordinate[2][0]\n        y3 = coordinate[2][1]\n        x4 = coordinate[3][0]\n        y4 = coordinate[3][1]\n        xmin = min(x1, x2, x3, x4)\n        ymin = min(y1, y2, y3, y4)\n        xmax = max(x1, x2, x3, x4)\n        ymax = max(y1, y2, y3, y4)\n        combinate = [[[x1, y1], [x2, y2], [x3, y3], [x4, y4]],\n                     [[x2, y2], [x3, y3], [x4, y4], [x1, y1]], \n                     [[x3, y3], [x4, y4], [x1, y1], [x2, y2]], \n                     [[x4, y4], [x1, y1], [x2, y2], [x3, y3]]]\n        dst_coordinate = [[xmin, ymin], [xmax, ymin], [xmax, ymax], [xmin, ymax]]\n        force = 100000000.0\n        force_flag = 0\n        for i in range(4):\n            temp_force = calculate_distance(combinate[i][0], dst_coordinate[0]) + calculate_distance(combinate[i][1], dst_coordinate[1]) + calculate_distance(combinate[i][2], dst_coordinate[2]) + calculate_distance(combinate[i][3], dst_coordinate[3])\n            if temp_force < force:\n                force = temp_force\n                force_flag = i\n        #if force_flag != 0:\n        #    print(""choose one direction!"")\n        final_result.append(combinate[force_flag])\n        \n    return final_result\n\n\ndef check_and_validate_polys(polys, tags, xxx_todo_changeme):\n    \'\'\'\n    check so that the text poly is in the same direction,\n    and also filter some invalid polygons\n    :param polys:\n    :param tags:\n    :return:\n    \'\'\'\n\n    (h, w) = xxx_todo_changeme\n    if polys.shape[0] == 0:\n        return polys\n    polys[:, :, 0] = np.clip(polys[:, :, 0], 0, w-1)\n    polys[:, :, 1] = np.clip(polys[:, :, 1], 0, h-1)\n\n    validated_polys = []\n    validated_tags = []\n\n    # find top-left and clockwise\n    polys = choose_best_begin_point(polys)\n\n    for poly, tag in zip(polys, tags):\n        p_area = polygon_area(poly)\n        if abs(p_area) < 1:\n            # print poly\n            #print(\'invalid poly\')\n            continue\n        if p_area > 0:\n            #print(\'poly in wrong direction\')\n            poly = poly[(0, 3, 2, 1), :]\n        validated_polys.append(poly)\n        validated_tags.append(tag)\n    return np.array(validated_polys), np.array(validated_tags)\n\ndef crop_area(im, polys, tags, crop_background=False, max_tries=5000, vis = False, img_name = None):\n    \'\'\'\n    make random crop from the input image\n    :param im:\n    :param polys:\n    :param tags:\n    :param crop_background:\n    :param max_tries:\n    :return:\n    \'\'\'\n    h, w, _ = im.shape\n    pad_h = h//10\n    pad_w = w//10\n    h_array = np.zeros((h + pad_h*2), dtype=np.int32)\n    w_array = np.zeros((w + pad_w*2), dtype=np.int32)\n    \n    if polys.shape[0] == 0:\n        return im, [], []\n\n    for poly in polys:\n        poly = np.round(poly, decimals=0).astype(np.int32)\n        minx = np.min(poly[:, 0])\n        maxx = np.max(poly[:, 0])\n        w_array[minx+pad_w:maxx+pad_w] = 1\n        miny = np.min(poly[:, 1])\n        maxy = np.max(poly[:, 1])\n        h_array[miny+pad_h:maxy+pad_h] = 1\n\n    # ensure the cropped area not across a text\n    h_axis = np.where(h_array == 0)[0]\n    w_axis = np.where(w_array == 0)[0]\n    \n    if len(h_axis) == 0 or len(w_axis) == 0:\n        return im, polys, tags\n    \n    for i in range(max_tries):\n        #print(\'we have try {} times\'.format(i))\n        xx = np.random.choice(w_axis, size=2)\n        xmin = np.min(xx) - pad_w\n        xmax = np.max(xx) - pad_w\n        xmin = np.clip(xmin, 0, w-1)\n        xmax = np.clip(xmax, 0, w-1)\n        yy = np.random.choice(h_axis, size=2)\n        ymin = np.min(yy) - pad_h\n        ymax = np.max(yy) - pad_h\n        ymin = np.clip(ymin, 0, h-1)\n        ymax = np.clip(ymax, 0, h-1)\n        # if xmax - xmin < FLAGS.min_crop_side_ratio*w or ymax - ymin < FLAGS.min_crop_side_ratio*h:\n        if xmax - xmin < 0.1*w or ymax - ymin < 0.1*h:\n            # area too small\n            continue\n        if polys.shape[0] != 0:\n            poly_axis_in_area = (polys[:, :, 0] >= xmin) & (polys[:, :, 0] <= xmax) \\\n                                & (polys[:, :, 1] >= ymin) & (polys[:, :, 1] <= ymax)\n            selected_polys = np.where(np.sum(poly_axis_in_area, axis=1) == 4)[0]\n        else:\n            selected_polys = []\n\n        if len(selected_polys) == 0:\n            # no text in this area\n            if crop_background == True:\n                im = im[ymin:ymax+1, xmin:xmax+1, :]\n                polys = []\n                tags = []\n\n                return im, polys, tags\n            else:\n                continue\n        else:\n            if crop_background == False:\n                im = im[ymin:ymax+1, xmin:xmax+1, :]\n                polys = polys.tolist()\n                polys = [polys[i] for i in selected_polys]\n                polys = np.array(polys)\n                polys[:, :, 0] -= xmin #ndarray\n                polys[:, :, 1] -= ymin\n                polys = polys.astype(np.int32)\n                polys = polys.tolist()\n\n                tags  = tags.tolist()\n                tags  = [tags[i]  for i in selected_polys]\n                return im, polys, tags\n            else:\n                continue\n    return im, polys, tags\n\n\n\n""""""\ndef crop_area(im, polys, tags, crop_background=False, max_tries=50, vis = True, img_name = None):\n    \'\'\'\n    make random crop from the input image\n    :param im:\n    :param polys:\n    :param tags:\n    :param crop_background:\n    :param max_tries:\n    :return:\n    \'\'\'\n    print(\'goggogoogo\')\n    h, w, _ = im.shape\n    pad_h = h//10\n    pad_w = w//10\n    h_array = np.zeros((h + pad_h*2), dtype=np.int32)\n    w_array = np.zeros((w + pad_w*2), dtype=np.int32)\n    for poly in polys:\n        poly = np.round(poly, decimals=0).astype(np.int32)\n        minx = np.min(poly[:, 0])\n        maxx = np.max(poly[:, 0])\n        w_array[minx+pad_w:maxx+pad_w] = 1\n        miny = np.min(poly[:, 1])\n        maxy = np.max(poly[:, 1])\n        h_array[miny+pad_h:maxy+pad_h] = 1\n    # ensure the cropped area not across a text\n    h_axis = np.where(h_array == 0)[0]\n    w_axis = np.where(w_array == 0)[0]\n    print(\'aaaaaaaaa\')\n    if len(h_axis) == 0 or len(w_axis) == 0:\n        return im, polys, tags\n    \n    print(\'bbbbbbbbb\')\n    for i in range(max_tries):\n        print(\'we have try {} times\'.format(i))\n        xx = np.random.choice(w_axis, size=2)\n        xmin = np.min(xx) - pad_w\n        xmax = np.max(xx) - pad_w\n        xmin = np.clip(xmin, 0, w-1)\n        xmax = np.clip(xmax, 0, w-1)\n        yy = np.random.choice(h_axis, size=2)\n        ymin = np.min(yy) - pad_h\n        ymax = np.max(yy) - pad_h\n        ymin = np.clip(ymin, 0, h-1)\n        ymax = np.clip(ymax, 0, h-1)\n        # if xmax - xmin < FLAGS.min_crop_side_ratio*w or ymax - ymin < FLAGS.min_crop_side_ratio*h:\n        if xmax - xmin < 0.1*w or ymax - ymin < 0.1*h:\n            # area too small\n            continue\n        if polys.shape[0] != 0:\n            poly_axis_in_area = (polys[:, :, 0] >= xmin) & (polys[:, :, 0] <= xmax) \\\n                                & (polys[:, :, 1] >= ymin) & (polys[:, :, 1] <= ymax)\n            selected_polys = np.where(np.sum(poly_axis_in_area, axis=1) == 4)[0]\n        else:\n            selected_polys = []\n        if len(selected_polys) == 0:\n            # no text in this area\n            if crop_background:\n                im = im[ymin:ymax+1, xmin:xmax+1, :]\n                polys = polys[selected_polys]\n                tags = tags[selected_polys]\n                if vis == True:\n                    path = os.path.join(os.path.abspath(\'./\'), \'tmp/vis_for_crop\', \'{}-bg.jpg\'.format(img_name))\n                    cv2.imwrite(path, im)\n                    print(\'save a bg\')\n                return im, polys, tags\n            else:\n                continue\n        im = im[ymin:ymax+1, xmin:xmax+1, :]\n        polys = polys[selected_polys]\n        tags = tags[selected_polys]\n        polys[:, :, 0] -= xmin\n        polys[:, :, 1] -= ymin\n\n        print(\'crop front\')\n        if vis == True:\n            #print(\'TEST for visualization about crop img\')\n            for ids, poly in enumerate(polys):\n                print(\'img h:{} w:{} poly id:{} {}\'.format(im.shape[0], im.shape[1], ids, poly))\n                x = [poly.astype(np.int32).reshape((-1, 1, 2))]\n                cv2.polylines(im[:, :, ::-1], x, True, color=(255, 255, 0), thickness=3)\n                print(x)\n            path = os.path.join(os.path.abspath(\'./\'), \'tmp/vis_for_crop\', \'{}-fg.jpg\'.format(img_name))\n            cv2.imwrite(path, im)\n            print(\'save a fg\')\n        return im, polys, tags\n\n    return im, polys, tags\n""""""\n\ndef shrink_poly(poly, r):\n    \'\'\'\n    fit a poly inside the origin poly, maybe bugs here...\n    used for generate the score map\n    :param poly: the text poly\n    :param r: r in the paper\n    :return: the shrinked poly\n    \'\'\'\n    # shrink ratio\n    R = 0.3\n    # find the longer pair\n    if np.linalg.norm(poly[0] - poly[1]) + np.linalg.norm(poly[2] - poly[3]) > \\\n                    np.linalg.norm(poly[0] - poly[3]) + np.linalg.norm(poly[1] - poly[2]):\n        # first move (p0, p1), (p2, p3), then (p0, p3), (p1, p2)\n        ## p0, p1\n        theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n        poly[0][0] += R * r[0] * np.cos(theta)\n        poly[0][1] += R * r[0] * np.sin(theta)\n        poly[1][0] -= R * r[1] * np.cos(theta)\n        poly[1][1] -= R * r[1] * np.sin(theta)\n        ## p2, p3\n        theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n        poly[3][0] += R * r[3] * np.cos(theta)\n        poly[3][1] += R * r[3] * np.sin(theta)\n        poly[2][0] -= R * r[2] * np.cos(theta)\n        poly[2][1] -= R * r[2] * np.sin(theta)\n        ## p0, p3\n        theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n        poly[0][0] += R * r[0] * np.sin(theta)\n        poly[0][1] += R * r[0] * np.cos(theta)\n        poly[3][0] -= R * r[3] * np.sin(theta)\n        poly[3][1] -= R * r[3] * np.cos(theta)\n        ## p1, p2\n        theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n        poly[1][0] += R * r[1] * np.sin(theta)\n        poly[1][1] += R * r[1] * np.cos(theta)\n        poly[2][0] -= R * r[2] * np.sin(theta)\n        poly[2][1] -= R * r[2] * np.cos(theta)\n    else:\n        ## p0, p3\n        # print poly\n        theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n        poly[0][0] += R * r[0] * np.sin(theta)\n        poly[0][1] += R * r[0] * np.cos(theta)\n        poly[3][0] -= R * r[3] * np.sin(theta)\n        poly[3][1] -= R * r[3] * np.cos(theta)\n        ## p1, p2\n        theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n        poly[1][0] += R * r[1] * np.sin(theta)\n        poly[1][1] += R * r[1] * np.cos(theta)\n        poly[2][0] -= R * r[2] * np.sin(theta)\n        poly[2][1] -= R * r[2] * np.cos(theta)\n        ## p0, p1\n        theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n        poly[0][0] += R * r[0] * np.cos(theta)\n        poly[0][1] += R * r[0] * np.sin(theta)\n        poly[1][0] -= R * r[1] * np.cos(theta)\n        poly[1][1] -= R * r[1] * np.sin(theta)\n        ## p2, p3\n        theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n        poly[3][0] += R * r[3] * np.cos(theta)\n        poly[3][1] += R * r[3] * np.sin(theta)\n        poly[2][0] -= R * r[2] * np.cos(theta)\n        poly[2][1] -= R * r[2] * np.sin(theta)\n    return poly\n\n\ndef point_dist_to_line(p1, p2, p3):\n    # compute the distance from p3 to p1-p2\n    distance = 0\n    try:\n        eps = 1e-5\n        distance = np.linalg.norm(np.cross(p2 - p1, p1 - p3)) /(np.linalg.norm(p2 - p1)+eps)\n    \n    except:\n        print(\'point dist to line raise Exception\')\n    \n    return distance\n\n\ndef fit_line(p1, p2):\n    # fit a line ax+by+c = 0\n    if p1[0] == p1[1]:\n        return [1., 0., -p1[0]]\n    else:\n        [k, b] = np.polyfit(p1, p2, deg=1)\n        return [k, -1., b]\n\n\ndef line_cross_point(line1, line2):\n    # line1 0= ax+by+c, compute the cross point of line1 and line2\n    if line1[0] != 0 and line1[0] == line2[0]:\n        print(\'Cross point does not exist\')\n        return None\n    if line1[0] == 0 and line2[0] == 0:\n        print(\'Cross point does not exist\')\n        return None\n    if line1[1] == 0:\n        x = -line1[2]\n        y = line2[0] * x + line2[2]\n    elif line2[1] == 0:\n        x = -line2[2]\n        y = line1[0] * x + line1[2]\n    else:\n        k1, _, b1 = line1\n        k2, _, b2 = line2\n        x = -(b1-b2)/(k1-k2)\n        y = k1*x + b1\n    return np.array([x, y], dtype=np.float32)\n\n\ndef line_verticle(line, point):\n    # get the verticle line from line across point\n    if line[1] == 0:\n        verticle = [0, -1, point[1]]\n    else:\n        if line[0] == 0:\n            verticle = [1, 0, -point[0]]\n        else:\n            verticle = [-1./line[0], -1, point[1] - (-1/line[0] * point[0])]\n    return verticle\n\n\ndef rectangle_from_parallelogram(poly):\n    \'\'\'\n    fit a rectangle from a parallelogram\n    :param poly:\n    :return:\n    \'\'\'\n    p0, p1, p2, p3 = poly\n    angle_p0 = np.arccos(np.dot(p1-p0, p3-p0)/(np.linalg.norm(p0-p1) * np.linalg.norm(p3-p0)))\n    if angle_p0 < 0.5 * np.pi:\n        if np.linalg.norm(p0 - p1) > np.linalg.norm(p0-p3):\n            # p0 and p2\n            ## p0\n            p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n            p2p3_verticle = line_verticle(p2p3, p0)\n\n            new_p3 = line_cross_point(p2p3, p2p3_verticle)\n            ## p2\n            p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n            p0p1_verticle = line_verticle(p0p1, p2)\n\n            new_p1 = line_cross_point(p0p1, p0p1_verticle)\n            return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n        else:\n            p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n            p1p2_verticle = line_verticle(p1p2, p0)\n\n            new_p1 = line_cross_point(p1p2, p1p2_verticle)\n            p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n            p0p3_verticle = line_verticle(p0p3, p2)\n\n            new_p3 = line_cross_point(p0p3, p0p3_verticle)\n            return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n    else:\n        if np.linalg.norm(p0-p1) > np.linalg.norm(p0-p3):\n            # p1 and p3\n            ## p1\n            p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n            p2p3_verticle = line_verticle(p2p3, p1)\n\n            new_p2 = line_cross_point(p2p3, p2p3_verticle)\n            ## p3\n            p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n            p0p1_verticle = line_verticle(p0p1, p3)\n\n            new_p0 = line_cross_point(p0p1, p0p1_verticle)\n            return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n        else:\n            p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n            p0p3_verticle = line_verticle(p0p3, p1)\n\n            new_p0 = line_cross_point(p0p3, p0p3_verticle)\n            p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n            p1p2_verticle = line_verticle(p1p2, p3)\n\n            new_p2 = line_cross_point(p1p2, p1p2_verticle)\n            return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n\n\ndef sort_rectangle(poly):\n    # sort the four coordinates of the polygon, points in poly should be sorted clockwise\n    # First find the lowest point\n    p_lowest = np.argmax(poly[:, 1])\n    if np.count_nonzero(poly[:, 1] == poly[p_lowest, 1]) == 2:\n        # \xe5\xba\x95\xe8\xbe\xb9\xe5\xb9\xb3\xe8\xa1\x8c\xe4\xba\x8eX\xe8\xbd\xb4, \xe9\x82\xa3\xe4\xb9\x88p0\xe4\xb8\xba\xe5\xb7\xa6\xe4\xb8\x8a\xe8\xa7\x92\n        p0_index = np.argmin(np.sum(poly, axis=1))\n        p1_index = (p0_index + 1) % 4\n        p2_index = (p0_index + 2) % 4\n        p3_index = (p0_index + 3) % 4\n        return poly[[p0_index, p1_index, p2_index, p3_index]], 0.\n    else:\n        # \xe6\x89\xbe\xe5\x88\xb0\xe6\x9c\x80\xe4\xbd\x8e\xe7\x82\xb9\xe5\x8f\xb3\xe8\xbe\xb9\xe7\x9a\x84\xe7\x82\xb9\n        p_lowest_right = (p_lowest - 1) % 4\n        p_lowest_left = (p_lowest + 1) % 4\n        angle = np.arctan(-(poly[p_lowest][1] - poly[p_lowest_right][1])/(poly[p_lowest][0] - poly[p_lowest_right][0]))\n        # assert angle > 0\n        if angle <= 0:\n            print(angle, poly[p_lowest], poly[p_lowest_right])\n        if angle/np.pi * 180 > 45:\n            # \xe8\xbf\x99\xe4\xb8\xaa\xe7\x82\xb9\xe4\xb8\xbap2\n            p2_index = p_lowest\n            p1_index = (p2_index - 1) % 4\n            p0_index = (p2_index - 2) % 4\n            p3_index = (p2_index + 1) % 4\n            return poly[[p0_index, p1_index, p2_index, p3_index]], -(np.pi/2 - angle)\n        else:\n            # \xe8\xbf\x99\xe4\xb8\xaa\xe7\x82\xb9\xe4\xb8\xbap3\n            p3_index = p_lowest\n            p0_index = (p3_index + 1) % 4\n            p1_index = (p3_index + 2) % 4\n            p2_index = (p3_index + 3) % 4\n            return poly[[p0_index, p1_index, p2_index, p3_index]], angle\n\n\ndef restore_rectangle_rbox(origin, geometry):\n    d = geometry[:, :4]\n    angle = geometry[:, 4]\n    # for angle > 0\n    origin_0 = origin[angle >= 0]\n    d_0 = d[angle >= 0]\n    angle_0 = angle[angle >= 0]\n    if origin_0.shape[0] > 0:\n        p = np.array([np.zeros(d_0.shape[0]), -d_0[:, 0] - d_0[:, 2],\n                      d_0[:, 1] + d_0[:, 3], -d_0[:, 0] - d_0[:, 2],\n                      d_0[:, 1] + d_0[:, 3], np.zeros(d_0.shape[0]),\n                      np.zeros(d_0.shape[0]), np.zeros(d_0.shape[0]),\n                      d_0[:, 3], -d_0[:, 2]])\n        p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n\n        rotate_matrix_x = np.array([np.cos(angle_0), np.sin(angle_0)]).transpose((1, 0))\n        rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n\n        rotate_matrix_y = np.array([-np.sin(angle_0), np.cos(angle_0)]).transpose((1, 0))\n        rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n\n        p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n        p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n\n        p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n\n        p3_in_origin = origin_0 - p_rotate[:, 4, :]\n        new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n        new_p1 = p_rotate[:, 1, :] + p3_in_origin\n        new_p2 = p_rotate[:, 2, :] + p3_in_origin\n        new_p3 = p_rotate[:, 3, :] + p3_in_origin\n\n        new_p_0 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n                                  new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n    else:\n        new_p_0 = np.zeros((0, 4, 2))\n    # for angle < 0\n    origin_1 = origin[angle < 0]\n    d_1 = d[angle < 0]\n    angle_1 = angle[angle < 0]\n    if origin_1.shape[0] > 0:\n        p = np.array([-d_1[:, 1] - d_1[:, 3], -d_1[:, 0] - d_1[:, 2],\n                      np.zeros(d_1.shape[0]), -d_1[:, 0] - d_1[:, 2],\n                      np.zeros(d_1.shape[0]), np.zeros(d_1.shape[0]),\n                      -d_1[:, 1] - d_1[:, 3], np.zeros(d_1.shape[0]),\n                      -d_1[:, 1], -d_1[:, 2]])\n        p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n\n        rotate_matrix_x = np.array([np.cos(-angle_1), -np.sin(-angle_1)]).transpose((1, 0))\n        rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n\n        rotate_matrix_y = np.array([np.sin(-angle_1), np.cos(-angle_1)]).transpose((1, 0))\n        rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n\n        p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n        p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n\n        p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n\n        p3_in_origin = origin_1 - p_rotate[:, 4, :]\n        new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n        new_p1 = p_rotate[:, 1, :] + p3_in_origin\n        new_p2 = p_rotate[:, 2, :] + p3_in_origin\n        new_p3 = p_rotate[:, 3, :] + p3_in_origin\n\n        new_p_1 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n                                  new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n    else:\n        new_p_1 = np.zeros((0, 4, 2))\n    return np.concatenate([new_p_0, new_p_1])\n\n\ndef restore_rectangle(origin, geometry):\n    return restore_rectangle_rbox(origin, geometry)\n\n\ndef generate_rbox(im_size, polys, tags):\n    """"""\n    score map is (128, 128, 1) with shrinked poly\n    poly mask is (128, 128, 1) with differnt colors\n\n\n    geo map is  (128, 128, 5) with\n    """"""\n    h, w = im_size\n    poly_mask = np.zeros((h, w), dtype=np.uint8)\n    score_map = np.zeros((h, w), dtype=np.uint8)\n    geo_map = np.zeros((h, w, 5), dtype=np.float32)\n    # mask used during traning, to ignore some hard areas\n    training_mask = np.ones((h, w), dtype=np.uint8)\n    for poly_idx, poly_tag in enumerate(zip(polys, tags)):\n        poly = poly_tag[0]\n        tag = poly_tag[1]\n        poly = np.array(poly)\n        tag  = np.array(tag)\n        r = [None, None, None, None]\n        for i in range(4):\n            r[i] = min(np.linalg.norm(poly[i] - poly[(i + 1) % 4]),\n                       np.linalg.norm(poly[i] - poly[(i - 1) % 4]))\n        # score map\n        shrinked_poly = shrink_poly(poly.copy(), r).astype(np.int32)[np.newaxis, :, :]\n        cv2.fillPoly(score_map, shrinked_poly, 1)\n\n        # use different color to draw poly mask\n        cv2.fillPoly(poly_mask, shrinked_poly, poly_idx + 1)\n        # if the poly is too small, then ignore it during training\n        poly_h = min(np.linalg.norm(poly[0] - poly[3]), np.linalg.norm(poly[1] - poly[2]))\n        poly_w = min(np.linalg.norm(poly[0] - poly[1]), np.linalg.norm(poly[2] - poly[3]))\n        # if min(poly_h, poly_w) < FLAGS.min_text_size:\n        if min(poly_h, poly_w) < 10:\n            cv2.fillPoly(training_mask, poly.astype(np.int32)[np.newaxis, :, :], 0)\n        if tag:\n            cv2.fillPoly(training_mask, poly.astype(np.int32)[np.newaxis, :, :], 0)\n\n        xy_in_poly = np.argwhere(poly_mask == (poly_idx + 1))\n        # if geometry == \'RBOX\':\n        # \xe5\xaf\xb9\xe4\xbb\xbb\xe6\x84\x8f\xe4\xb8\xa4\xe4\xb8\xaa\xe9\xa1\xb6\xe7\x82\xb9\xe7\x9a\x84\xe7\xbb\x84\xe5\x90\x88\xe7\x94\x9f\xe6\x88\x90\xe4\xb8\x80\xe4\xb8\xaa\xe5\xb9\xb3\xe8\xa1\x8c\xe5\x9b\x9b\xe8\xbe\xb9\xe5\xbd\xa2\n        fitted_parallelograms = []\n        for i in range(4):\n            p0 = poly[i]\n            p1 = poly[(i + 1) % 4]\n            p2 = poly[(i + 2) % 4]\n            p3 = poly[(i + 3) % 4]\n\n            #fit_line ([x1, x2], [y1, y2]) return k, -1, b just a line\n            edge = fit_line([p0[0], p1[0]], [p0[1], p1[1]])             #p0, p1\n            backward_edge = fit_line([p0[0], p3[0]], [p0[1], p3[1]])    #p0, p3\n            forward_edge = fit_line([p1[0], p2[0]], [p1[1], p2[1]])     #p1, p2\n\n            #select shorter line\n            if point_dist_to_line(p0, p1, p2) > point_dist_to_line(p0, p1, p3):\n                # \xe5\xb9\xb3\xe8\xa1\x8c\xe7\xba\xbf\xe7\xbb\x8f\xe8\xbf\x87p2\n                if edge[1] == 0:#verticle\n                    edge_opposite = [1, 0, -p2[0]]\n                else:\n                    edge_opposite = [edge[0], -1, p2[1] - edge[0] * p2[0]]\n            else:\n                # \xe7\xbb\x8f\xe8\xbf\x87p3\n                if edge[1] == 0:\n                    edge_opposite = [1, 0, -p3[0]]\n                else:\n                    edge_opposite = [edge[0], -1, p3[1] - edge[0] * p3[0]]\n            # move forward edge\n            new_p0 = p0\n            new_p1 = p1\n            new_p2 = p2\n            new_p3 = p3\n            new_p2 = line_cross_point(forward_edge, edge_opposite)\n            if point_dist_to_line(p1, new_p2, p0) > point_dist_to_line(p1, new_p2, p3):\n                # across p0\n                if forward_edge[1] == 0:\n                    forward_opposite = [1, 0, -p0[0]]\n                else:\n                    forward_opposite = [forward_edge[0], -1, p0[1] - forward_edge[0] * p0[0]]\n            else:\n                # across p3\n                if forward_edge[1] == 0:\n                    forward_opposite = [1, 0, -p3[0]]\n                else:\n                    forward_opposite = [forward_edge[0], -1, p3[1] - forward_edge[0] * p3[0]]\n            new_p0 = line_cross_point(forward_opposite, edge)\n            new_p3 = line_cross_point(forward_opposite, edge_opposite)\n            fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n            # or move backward edge\n            new_p0 = p0\n            new_p1 = p1\n            new_p2 = p2\n            new_p3 = p3\n            new_p3 = line_cross_point(backward_edge, edge_opposite)\n            if point_dist_to_line(p0, p3, p1) > point_dist_to_line(p0, p3, p2):\n                # across p1\n                if backward_edge[1] == 0:\n                    backward_opposite = [1, 0, -p1[0]]\n                else:\n                    backward_opposite = [backward_edge[0], -1, p1[1] - backward_edge[0] * p1[0]]\n            else:\n                # across p2\n                if backward_edge[1] == 0:\n                    backward_opposite = [1, 0, -p2[0]]\n                else:\n                    backward_opposite = [backward_edge[0], -1, p2[1] - backward_edge[0] * p2[0]]\n            new_p1 = line_cross_point(backward_opposite, edge)\n            new_p2 = line_cross_point(backward_opposite, edge_opposite)\n            fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n\n        areas = [Polygon(t).area for t in fitted_parallelograms]\n        parallelogram = np.array(fitted_parallelograms[np.argmin(areas)][:-1], dtype=np.float32)\n        # sort thie polygon\n        parallelogram_coord_sum = np.sum(parallelogram, axis=1)\n        min_coord_idx = np.argmin(parallelogram_coord_sum)\n        parallelogram = parallelogram[[min_coord_idx, (min_coord_idx + 1) % 4, (min_coord_idx + 2) % 4, (min_coord_idx + 3) % 4]]\n\n        rectange = rectangle_from_parallelogram(parallelogram)\n        rectange, rotate_angle = sort_rectangle(rectange)\n        #print(\'parallel {} rectangle {}\'.format(parallelogram, rectange))\n        p0_rect, p1_rect, p2_rect, p3_rect = rectange\n        # this is one area of many\n        """"""\n        for y, x in xy_in_poly:\n            point = np.array([x, y], dtype=np.float32)\n            # top\n            geo_map[y, x, 0] = point_dist_to_line(p0_rect, p1_rect, point)\n            # right\n            geo_map[y, x, 1] = point_dist_to_line(p1_rect, p2_rect, point)\n            # down\n            geo_map[y, x, 2] = point_dist_to_line(p2_rect, p3_rect, point)\n            # left\n            geo_map[y, x, 3] = point_dist_to_line(p3_rect, p0_rect, point)\n            # angle\n            geo_map[y, x, 4] = rotate_angle\n        """"""\n        gen_geo_map.gen_geo_map(geo_map, xy_in_poly, rectange, rotate_angle)\n\n    ###sum up\n    # score_map , in shrinked poly is 1\n    # geo_map, corresponding to score map\n    # training map is less than geo_map\n\n    return score_map, geo_map, training_mask\n\ndef image_label(txt_root, \n                image_list, img_name,\n                txt_list, txt_name,\n                index,\n                input_size = 512, \n                random_scale = np.array([0.5, 1, 2.0, 3.0]),\n                background_ratio = 3./8):\n    \'\'\'\n    get image\'s corresponding matrix and ground truth\n    return\n    images [512, 512, 3]\n    score  [128, 128, 1]\n    geo    [128, 128, 5]\n    mask   [128, 128, 1]\n    \'\'\'\n\n    try:\n        im_fn = image_list[index]\n        txt_fn = txt_list[index]\n\n        im = cv2.imread(im_fn)\n        # print im_fn\n        h, w, _ = im.shape\n        #txt_fn = im_fn.replace(os.path.basename(im_fn).split(\'.\')[1], \'txt\')\n        if not os.path.exists(txt_fn):\n            sys.exit(\'text file {} does not exists\'.format(txt_fn))\n\n        text_polys, text_tags = load_annoataion(txt_fn)\n\n        text_polys, text_tags = check_and_validate_polys(text_polys, text_tags, (h, w))\n        # if text_polys.shape[0] == 0:\n        #     continue\n        # random scale this image\n        rd_scale = np.random.choice(random_scale)\n\n        im = cv2.resize(im, dsize=None, fx=rd_scale, fy=rd_scale)\n        text_polys *= rd_scale\n        ###########################for exception to return #############################\n        h, w, _ = im.shape\n\n        # pad the image to the training input size or the longer side of image\n        new_h, new_w, _ = im.shape\n        max_h_w_i = np.max([new_h, new_w, input_size])\n        im_padded = np.zeros((max_h_w_i, max_h_w_i, 3), dtype=np.uint8)\n        im_padded[:new_h, :new_w, :] = im.copy()\n        im = im_padded\n        # resize the image to input size\n        new_h, new_w, _ = im.shape\n        resize_h = input_size\n        resize_w = input_size\n        im = cv2.resize(im, dsize=(resize_w, resize_h))\n        resize_ratio_3_x = resize_w/float(new_w)\n        resize_ratio_3_y = resize_h/float(new_h)\n        #print(text_polys.type.name)\n\n        for i in range(len(text_polys)):\n            for j in range(4):\n                text_polys[i][j][0] *= resize_ratio_3_x\n                text_polys[i][j][1] *= resize_ratio_3_y\n\n        #text_polys[:, :, 0] *= resize_ratio_3_x\n        #ext_polys[:, :, 1] *= resize_ratio_3_y\n        new_h, new_w, _ = im.shape\n        ########################################################################\n\n        # print rd_scale\n        # random crop a area from image\n        #if np.random.rand() < background_ratio:\n        #tmp = False\n        if np.random.rand() < background_ratio:\n            # crop background\n            im, text_polys, text_tags = crop_area(im, text_polys, text_tags, crop_background=True)\n            assert len(text_polys) == 0, \'crop area should have no text_polys\'\n            #if text_polys.shape[0] > 0:\n            #    print(\'cannot find background\')\n            #    return None, None, None, None \n            \n            # pad and resize image\n            new_h, new_w, _ = im.shape\n            max_h_w_i = np.max([new_h, new_w, input_size])\n            im_padded = np.zeros((max_h_w_i, max_h_w_i, 3), dtype=np.uint8)\n            im_padded[:new_h, :new_w, :] = im.copy()\n            im = cv2.resize(im_padded, dsize=(input_size, input_size))\n            score_map = np.zeros((input_size, input_size), dtype=np.uint8)\n            geo_map_channels = 5 \n            geo_map = np.zeros((input_size, input_size, geo_map_channels), dtype=np.float32)\n            training_mask = np.ones((input_size, input_size), dtype=np.uint8)\n        else:\n            im, text_polys, text_tags = crop_area(im, text_polys, text_tags, crop_background=False)\n            #assert len(text_polys) > 0, \'crop area should have some text_polys\'\n            if len(text_polys) == 0: #for some reason , gt contain no polys, have to return black\n                score_map = np.zeros((input_size, input_size), dtype=np.uint8)\n                geo_map_channels = 5 \n                geo_map = np.zeros((input_size, input_size, geo_map_channels), dtype=np.float32)\n                training_mask = np.ones((input_size, input_size), dtype=np.uint8)\n                images = im[:, :, ::-1].astype(np.float32)\n                score_maps = score_map[::4, ::4, np.newaxis].astype(np.float32)\n                geo_maps = geo_map[::4, ::4, :].astype(np.float32)\n                training_masks = training_mask[::4, ::4, np.newaxis].astype(np.float32)\n                return images, score_maps, geo_maps, training_masks\n            #if text_polys.shape[0] == 0:\n            #    print(\'cannot find frontground\')\n            #    return None, None, None, None\n            h, w, _ = im.shape\n\n            # pad the image to the training input size or the longer side of image\n            new_h, new_w, _ = im.shape\n            max_h_w_i = np.max([new_h, new_w, input_size])\n            im_padded = np.zeros((max_h_w_i, max_h_w_i, 3), dtype=np.uint8)\n            im_padded[:new_h, :new_w, :] = im.copy()\n            im = im_padded\n            # resize the image to input size\n            new_h, new_w, _ = im.shape\n            resize_h = input_size\n            resize_w = input_size\n            im = cv2.resize(im, dsize=(resize_w, resize_h))\n            resize_ratio_3_x = resize_w/float(new_w)\n            resize_ratio_3_y = resize_h/float(new_h)\n            #print(text_polys.type.name)\n\n            for i in range(len(text_polys)):\n                for j in range(4):\n                    text_polys[i][j][0] *= resize_ratio_3_x\n                    text_polys[i][j][1] *= resize_ratio_3_y\n\n            #text_polys[:, :, 0] *= resize_ratio_3_x\n            #ext_polys[:, :, 1] *= resize_ratio_3_y\n            new_h, new_w, _ = im.shape\n            #print(\'done3\')\n            score_map, geo_map, training_mask = generate_rbox((new_h, new_w), text_polys, text_tags)\n            #print(\'done4\')\n    \n    except Exception as e:\n        print(\'Exception continue\')\n        return None, None,None,None\n\n    images = im[:, :, ::-1].astype(np.float32)\n    score_maps = score_map[::4, ::4, np.newaxis].astype(np.float32)\n    geo_maps = geo_map[::4, ::4, :].astype(np.float32)\n    training_masks = training_mask[::4, ::4, np.newaxis].astype(np.float32)\n\n    return images, score_maps, geo_maps, training_masks\n\n \ndef transform_for_train(img):\n    """"""\n    args \n    img -- \n    """"""\n    h, w, c = img.shape\n    assert h == 512, \'img should be 512\'\n    assert w == 512, \'img should be 512\'\n    assert c == 3  , \'img should be 3 channels\'\n    # cv2 trans to pil\n    image = Image.fromarray(np.uint8(img))\n\n    transform_list = []\n    \n    transform_list.append(transforms.ColorJitter(0.5, 0.5, 0.5, 0.25))\n\n    transform_list.append(transforms.ToTensor())\n    \n    transform_list.append(transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)))\n\n    transform = transforms.Compose(transform_list)\n\n    transforms.Compose(transform_list)\n    return transform(image)\n\nclass custom_dset(data.Dataset):\n    def __init__(self, img_root, txt_root, vis = False):\n        \n        self.img_path_list, self.img_name_list = get_images(img_root)\n        \n        self.txt_root = txt_root\n        \n        self.vis = vis\n\n        self._txt_name_list = [txt_name for txt_name in os.listdir(txt_root)]\n\n        self._txt_path_list = [os.path.join(txt_root, txt_name) for txt_name in os.listdir(txt_root)]\n        \n        self.txt_name_list = sorted(self._txt_name_list)\n        \n        self.txt_path_list = sorted(self._txt_path_list)\n\n\n        # check img_path_list, img_name_list, txt_root\n        for i in range(len(self.img_path_list)):\n            img_id = []\n            img_id.append(os.path.basename(self.img_path_list[i]).strip(\'.jpg\'))\n            img_id.append(os.path.basename(self.txt_path_list[i]).strip(\'.txt\'))\n            img_id.append(self.img_name_list[i].strip(\'.jpg\'))\n            img_id.append(self.txt_name_list[i].strip(\'.txt\'))\n            if (img_id[0] == img_id[1])&(img_id[2] == img_id[3])&(img_id[0] == img_id[2]):\n                continue\n            else:\n                print(img_id[0])\n                print(img_id[1])\n                print(img_id[2])\n                print(img_id[3])\n                sys.exit(\'img list and txt list is not matched\')\n\n\n    def __getitem__(self, index):\n        #transform = transform_for_train()\n        status = True\n        while status:\n            img, score_map, geo_map, training_mask = image_label(self.txt_root,\n            \n                self.img_path_list, self.img_name_list,\n            \n                self.txt_path_list, self.txt_name_list,\n            \n                index, input_size = 512,\n            \n                random_scale = np.array([0.5, 1.0, 2.0, 3.0]), background_ratio = 3./8)\n        \n            if not img is None:#512,512,3 ndarray should transform to 3,512,512\n\n\n                status = False\n                \n                #img = transform_for_train(img)\n                img = img.transpose(2, 0, 1)\n                #print(img.shape)\n                #print(type(img))\n\n                return img, score_map, geo_map, training_mask\n\n            else:\n\n                index = np.random.random_integers(0, self.__len__())\n                print(\'Exception in getitem, and choose another index:{}\'.format(index))\n\n\n\n        \n        #    sys.exit(\'some image cant find approprite crop\')\n        #img = transform_for_train(img)\n        #if img == None:\n        #   return None, None, None, None\n\n        \n\n    def __len__(self):\n        return len(self.img_path_list)\n\ndef collate_fn(batch):\n    img, score_map, geo_map, training_mask = zip(*batch)#tuple\n    bs = len(score_map)\n    images = []\n    score_maps = []\n    geo_maps = []\n    training_masks = []\n    for i in range(bs):\n        if img[i] is not None:\n            a = torch.from_numpy(img[i])\n            #a = img[i]\n            images.append(a)\n           \n            b = torch.from_numpy(score_map[i])\n            b = b.permute(2, 0, 1)\n            score_maps.append(b)\n            \n            c = torch.from_numpy(geo_map[i])\n            c = c.permute(2, 0, 1)\n            geo_maps.append(c)\n            \n            d = torch.from_numpy(training_mask[i])\n            d = d.permute(2, 0, 1)\n            training_masks.append(d)\n    \n    images = torch.stack(images, 0)\n    score_maps = torch.stack(score_maps, 0)\n    geo_maps = torch.stack(geo_maps, 0)\n    training_masks = torch.stack(training_masks, 0)\n\n    return images, score_maps, geo_maps, training_masks\n## img = bs * 512 * 512 *3\n## score_map = bs* 128 * 128 * 1\n## geo_map = bs * 128 * 128 * 5\n## training_mask = bs * 128 * 128 * 1\n'"
eval.py,2,"b'import cv2\nimport time\nimport math\nimport os\nimport numpy as np\nfrom PIL import Image\nimport locality_aware_nms as nms_locality\nimport lanms\nimport shutil\nimport torch\nimport model\nfrom data_utils import restore_rectangle, polygon_area\nfrom torch.autograd import Variable\nimport config as cfg\nimport sys\nfrom torchvision import transforms\nimport model\ntest_data_path = cfg.test_img_path\n\n\ndef rotate(box_List,image):\n    #xuan zhuan tu pian\n\n    n=len(box_List)\n    c=0;\n    angle=0\n    for i in range(n):\n        box=box_List[i]\n        y1 = min(box[0][1], box[1][1], box[2][1], box[3][1])\n        y2 = max(box[0][1], box[1][1], box[2][1], box[3][1])\n        x1 = min(box[0][0], box[1][0], box[2][0], box[3][0])\n        x2 = max(box[0][0], box[1][0], box[2][0], box[3][0])\n        for j in range(4):\n            if(box[j][1]==y2):\n                k1=j\n        for j in range(4):\n            if(box[j][0]==x2 and j!=k1):\n                k2=j\n        c=(box[k1][0]-box[k2][0])*1.0/(box[k1][1]-box[k2][1])\n        if(c<0):\n            c=-c\n        if(c>1):\n            c=1.0/c\n        angle=math.atan(c)+angle\n    angle=angle/n\n    (h, w) = image.shape[:2]\n    center = (w / 2, h / 2)\n    scale=1\n    M = cv2.getRotationMatrix2D(center,angle, scale)\n    image_new = cv2.warpAffine(image, M, (w, h))\n    return image_new\n\ndef get_images_for_test():\n    \'\'\'\n    find image files in test data path\n    :return: list of files found\n    \'\'\'\n    files = []\n    exts = [\'jpg\', \'png\', \'jpeg\', \'JPG\']\n    for parent, dirnames, filenames in os.walk(test_data_path):\n        for filename in filenames:\n            for ext in exts:\n                if filename.endswith(ext):\n                    files.append(os.path.join(parent, filename))\n                    break\n    \n    # print(\'Find {} images\'.format(len(files)))\n    return files\n\ndef resize_image(im, max_side_len=2400):\n    \'\'\'\n    resize image to a size multiple of 32 which is required by the network\n    :param im: the resized image\n    :param max_side_len: limit of max image size to avoid out of memory in gpu\n    :return: the resized image and the resize ratio\n    \'\'\'\n    h, w, _ = im.shape\n\n    resize_w = w\n    resize_h = h\n\n    # limit the max side\n    """"""\n    if max(resize_h, resize_w) > max_side_len:\n        ratio = float(max_side_len) / resize_h if resize_h > resize_w else float(max_side_len) / resize_w\n    else:\n        ratio = 1.\n\n    resize_h = int(resize_h * ratio)\n    resize_w = int(resize_w * ratio)\n    """"""\n\n    resize_h = resize_h if resize_h % 32 == 0 else (resize_h // 32 - 1) * 32\n    resize_w = resize_w if resize_w % 32 == 0 else (resize_w // 32 - 1) * 32\n    #resize_h, resize_w = 512, 512\n    im = cv2.resize(im, (int(resize_w), int(resize_h)))\n\n    ratio_h = resize_h / float(h)\n    ratio_w = resize_w / float(w)\n\n    return im, (ratio_h, ratio_w)\n\ndef detect(score_map, geo_map, timer, score_map_thresh=1e-5, box_thresh=1e-8, nms_thres=0.1):\n    \'\'\'\n    restore text boxes from score map and geo map\n    :param score_map:\n    :param geo_map:\n    :param timer:\n    :param score_map_thresh: threshhold for score map\n    :param box_thresh: threshhold for boxes\n    :param nms_thres: threshold for nms\n    :return:\n    \'\'\'\n    if len(score_map.shape) == 4:\n        score_map = score_map[0, :, :, 0]\n        geo_map = geo_map[0, :, :, ]\n    # filter the score map\n    xy_text = np.argwhere(score_map > score_map_thresh)\n    # sort the text boxes via the y axis\n    xy_text = xy_text[np.argsort(xy_text[:, 0])]\n    # restore\n    start = time.time()\n    text_box_restored = restore_rectangle(xy_text[:, ::-1]*4, geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2\n    #print(\'{} text boxes before nms\'.format(text_box_restored.shape[0]))\n    boxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32)\n    boxes[:, :8] = text_box_restored.reshape((-1, 8))\n    boxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]]\n    timer[\'restore\'] = time.time() - start\n    # nms part\n    start = time.time()\n    # boxes = nms_locality.nms_locality(boxes.astype(np.float64), nms_thres)\n    boxes = lanms.merge_quadrangle_n9(boxes.astype(\'float32\'), nms_thres)\n    timer[\'nms\'] = time.time() - start\n    if boxes.shape[0] == 0:\n        return None, timer\n\n    # here we filter some low score boxes by the average score map, this is different from the orginal paper\n    for i, box in enumerate(boxes):\n        mask = np.zeros_like(score_map, dtype=np.uint8)\n        cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32) // 4, 1)\n        boxes[i, 8] = cv2.mean(score_map, mask)[0]\n    boxes = boxes[boxes[:, 8] > box_thresh]\n    return boxes, timer\n\ndef sort_poly(p):\n    min_axis = np.argmin(np.sum(p, axis=1))\n    p = p[[min_axis, (min_axis+1)%4, (min_axis+2)%4, (min_axis+3)%4]]\n    if abs(p[0, 0] - p[1, 0]) > abs(p[0, 1] - p[1, 1]):\n        return p\n    else:\n        return p[[0, 3, 2, 1]]\n\ndef change_box(box_List):\n    n=len(box_List)\n    for i in range(n):\n        box=box_List[i]\n        y1 = min(box[0][1], box[1][1], box[2][1], box[3][1])\n        y2 = max(box[0][1], box[1][1], box[2][1], box[3][1])\n        x1 = min(box[0][0], box[1][0], box[2][0], box[3][0])\n        x2 = max(box[0][0], box[1][0], box[2][0], box[3][0])\n        box[0][1]=y1\n        box[0][0]=x1\n        box[1][1]=y1\n        box[1][0]=x2\n        box[3][1]=y2\n        box[3][0]=x1\n        box[2][1]=y2\n        box[2][0]=x2\n        box_List[i]=box\n    return box_List\n\ndef save_box(box_List,image,img_path):\n    n=len(box_List)\n    box_final = []\n    for i in range(n):\n        box=box_List[i]\n        y1_0 = int(min(box[0][1], box[1][1], box[2][1], box[3][1]))\n        y2_0 = int(max(box[0][1], box[1][1], box[2][1], box[3][1]))\n        x1_0 = int(min(box[0][0], box[1][0], box[2][0], box[3][0]))\n        x2_0 = int(max(box[0][0], box[1][0], box[2][0], box[3][0]))\n        y1 = max(int(y1_0 - 0.1 * (y2_0 - y1_0)), 0)\n        y2 = min(int(y2_0 + 0.1 * (y2_0 - y1_0)), image.shape[0] - 1)\n        x1 = max(int(x1_0 - 0.25 * (x2_0 - x1_0)), 0)\n        x2 = min(int(x2_0 + 0.25 * (x2_0 - x1_0)), image.shape[1] - 1)\n        image_new=image[y1:y2,x1:x2]\n\n        # # \xe5\x9b\xbe\xe5\x83\x8f\xe5\xa4\x84\xe7\x90\x86\n        gray_2 = image_new[:,:,0]\n        gradX = cv2.Sobel(gray_2, ddepth = cv2.CV_32F, dx = 1, dy = 0, ksize = -1)\n        gradY = cv2.Sobel(gray_2, ddepth = cv2.CV_32F, dx = 0, dy = 1, ksize = -1)\n        blurred = cv2.blur(gradX, (2, 2))\n        (_, thresh) = cv2.threshold(blurred, 160, 255, cv2.THRESH_BINARY)\n        # closed = cv2.erode(thresh, None, iterations = 1)\n        # closed = cv2.dilate(closed, None, iterations = 1)\n        closed = thresh\n        x_plus = []\n        x_left = 1\n        x_right = closed.shape[1]\n        for jj in range(0, closed.shape[1]):\n            plus = 0\n            for ii in range(0, closed.shape[0]):\n                plus = plus + closed[ii][jj]\n            x_plus.append(plus)\n\n        for jj in range(0, int(closed.shape[1] * 0.5 - 1)):\n            if(x_plus[jj] > 0.4 * max(x_plus)):\n                x_left = max(jj - 5, 0)\n                break\n        for ii in range(closed.shape[1] - 1, int(closed.shape[1] * 0.5 + 1), -1):\n            if(x_plus[ii] > 0.4 * max(x_plus)):\n                x_right = min(ii + 5, closed.shape[1] - 1)\n                break\n\n        image_new = image_new[:, x_left:x_right]\n        cv2.imwrite(""."" + img_path.split(""."")[1]+\'_\'+str(i)+"".jpg"", image_new)\n        box[0][1]=y1\n        box[0][0]=x1 + x_left\n        box[1][1]=y1\n        box[1][0]=x1 + x_right\n        box[3][1]=y2\n        box[3][0]=x1 + x_left\n        box[2][1]=y2\n        box[2][0]=x1 + x_right\n        box_List[i]=box\n    return box_List\n\ndef transform_for_test():\n    """"""\n    CV2 => PI => tensor\n    """"""\n    #image = Image.fromarray(np.uint8(img))\n\n    transform_list = []\n    \n    transform_list.append(transforms.ToTensor())\n    \n    transform_list.append(transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)))\n\n    transform = transforms.Compose(transform_list)\n\n    return transform\n\n\ndef predict(model, criterion, epoch):\n    # prepare ooutput directory\n    print(\'EAST <==> TEST <==> Create Res_file and Img_with_box <==> Begin\')\n    result_root = os.path.abspath(cfg.result)\n    if not os.path.exists(result_root):\n        os.mkdir(result_root)\n\n    output_dir_txt = os.path.join(result_root, \'epoch_\'+str(epoch)+\'_gt\')\n    output_dir_pic = os.path.join(result_root, \'epoch_\'+str(epoch)+\'_img_with_box\')\n\n    try:\n        shutil.rmtree(output_dir_txt)\n    except:\n        print(\'Dir {} is not exists, make it\'.format(output_dir_txt))\n        \n    try:\n        shutil.rmtree(output_dir_pic)\n    except:\n        print(\'Dir {} is not exists, make it\'.format(output_dir_pic))\n\n    try:\n        os.mkdir(output_dir_txt)\n        os.mkdir(output_dir_pic)\n\n    except OSError as e:\n        if e.errno != 17:\n            raise\n\n    print(\'EAST <==> TEST <==> Create Res_file and Img_with_box Directory \')\n\n    model = model.eval()\n    im_fn_list = get_images_for_test()\n    start = time.time()\n\n    for idx, im_fn in enumerate(im_fn_list):    \n        print(\'EAST <==> TEST <==> idx:{} <==> Begin\'.format(idx))\n        im = cv2.imread(im_fn)[:, :, ::-1]\n\n\n        #transform = transform_for_test()\n\n\n        start_time = time.time()\n        im_resized, (ratio_h, ratio_w) = resize_image(im)\n        im_resized = im_resized.astype(np.float32)\n        #image = Image.fromarray(np.uint8(im_resized))\n\n        #im_resized = transform(image) \n        im_resized = im_resized.transpose(2, 0, 1)\n        im_resized = torch.from_numpy(im_resized)\n        im_resized = im_resized.cuda()\n        im_resized = im_resized.unsqueeze(0)\n        #im_resized = im_resized.permute(0, 3, 1, 2)\n\n        timer = {\'net\': 0, \'restore\': 0, \'nms\': 0}\n        start = time.time()\n        \n        score, geometry = model(im_resized)\n\n        timer[\'net\'] = time.time() - start\n        print(\'EAST <==> TEST <==> idx:{} <==> model  :{:.2f}ms\'.format(idx, timer[\'net\']*1000))\n\n        score = score.permute(0, 2, 3, 1)\n        geometry = geometry.permute(0, 2, 3, 1)\n        score = score.data.cpu().numpy()\n        geometry = geometry.data.cpu().numpy()\n\n        boxes, timer = detect(score_map=score, geo_map=geometry, timer=timer)\n        print(\'EAST <==> TEST <==> idx:{} <==> restore:{:.2f}ms\'.format(idx, timer[\'restore\']*1000))\n        print(\'EAST <==> TEST <==> idx:{} <==> nms    :{:.2f}ms\'.format(idx, timer[\'nms\']*1000))\n\n\n        print(\'EAST <==> TEST <==> Record and Save <==> id:{} <==> Begin\'.format(idx))\n        if boxes is not None:\n            boxes = boxes[:, :8].reshape((-1, 4, 2))\n            boxes[:, :, 0] /= ratio_w\n            boxes[:, :, 1] /= ratio_h\n\n        if boxes is not None:\n            res_file = os.path.join(output_dir_txt, \'res_img_{}.txt\'.format(os.path.basename(im_fn).split(\'_\')[-1].strip(\'.jpg\')))\n            with open(res_file, \'w\') as f:\n                for box in boxes:\n                    box = sort_poly(box.astype(np.int32))\n\n                    if np.linalg.norm(box[0] - box[1]) < 5 or np.linalg.norm(box[3] - box[0]) < 5:\n                        #print(\'wrong direction\')\n                        continue\n                    \n                    if box[0, 0] < 0 or box[0, 1] < 0 or box[1,0] < 0 or box[1,1] < 0 or box[2,0]<0 or box[2,1]<0 or box[3,0] < 0 or box[3,1]<0:\n                        continue\n                        \n                    poly = np.array([[box[0, 0], box[0, 1]], [box[1, 0], box[1, 1]], [box[2, 0], box[2, 1]], [box[3, 0], box[3, 1]]])\n                    \n                    p_area = polygon_area(poly)\n                    if p_area > 0:\n                        poly = poly[(0, 3, 2, 1), :]\n\n                    f.write(\'{},{},{},{},{},{},{},{}\\r\\n\'.format(poly[0, 0], poly[0, 1], poly[1, 0], poly[1, 1], poly[2, 0], poly[2, 1], poly[3, 0], poly[3, 1],))\n                    cv2.polylines(im[:, :, ::-1], [box.astype(np.int32).reshape((-1, 1, 2))], True, color=(255, 255, 0), thickness=1)\n        \n        save_img_path = os.path.join(output_dir_pic, os.path.basename(im_fn))\n        cv2.imwrite(save_img_path, im[:, :, ::-1])\n        print(\'EAST <==> TEST <==> Save txt   at:{} <==> Done\'.format(res_file))\n        print(\'EAST <==> TEST <==> Save image at:{} <==> Done\'.format(save_img_path))\n\n        print(\'EAST <==> TEST <==> Record and Save <==> ids:{} <==> Done\'.format(idx))\n    return  output_dir_txt\n\nif __name__ == ""__main__"":\n    predict()\n'"
hmean.py,0,"b""import os\nimport shutil\nfrom pyicdartools import TL_iou, rrc_evaluation_funcs\ndef compute_hmean(submit_file_path):\n\tprint('EAST <==> Evaluation <==> Compute Hmean <==> Begin')\n\n\tbasename = os.path.basename(submit_file_path)\n\tassert basename == 'submit.zip', 'There is no submit.zip'\n\n\tdirname  = os.path.dirname(submit_file_path)\n\tgt_file_path  = os.path.join(dirname, 'gt.zip')\n\tassert os.path.isfile(gt_file_path), 'There is no gt.zip'\n\n\tlog_file_path = os.path.join(dirname, 'log_epoch_hmean.txt')\n\tif not os.path.isfile(log_file_path):\n\t\tos.mknod(log_file_path)\n\n\tresult_dir_path = os.path.join(dirname, 'result')\n\ttry:\n\t\tshutil.rmtree(result_dir_path)\n\texcept:\n\t\tpass\n\tos.mkdir(result_dir_path)\n\t\n\tresDict = rrc_evaluation_funcs.main_evaluation({'g': gt_file_path,'s': submit_file_path,'o':result_dir_path},TL_iou.default_evaluation_params, TL_iou.validate_data, TL_iou.evaluate_method)\n\n\tprint(resDict)\n\trecall    = resDict['method']['recall']\n\n\tprecision = resDict['method']['precision']\n\n\thmean     = resDict['method']['hmean']\n\n\tprint('EAST <==> Evaluation <==> Precision:{:.2f} Recall:{:.2f} Hmean{:.2f} <==> Done'.format(precision, recall, hmean))\n\n\twith open(log_file_path, 'a') as f:\n\t\tf.write('EAST <==> Evaluation <==> Precision:{:.2f} Recall:{:.2f} Hmean{:.2f} <==> Done\\n'.format(precision, recall, hmean))\n\n\treturn hmean\n\nif __name__ == '__main__':\n\tsubmit_file_path = '/home/djsong/update/result/submit.zip'\n\thmean = compute_hmean(submit_file_path)"""
locality_aware_nms.py,0,"b""import numpy as np\nfrom shapely.geometry import Polygon\n\n\ndef intersection(g, p):\n    g = Polygon(g[:8].reshape((4, 2)))\n    p = Polygon(p[:8].reshape((4, 2)))\n    if not g.is_valid or not p.is_valid:\n        return 0\n    inter = Polygon(g).intersection(Polygon(p)).area\n    union = g.area + p.area - inter\n    if union == 0:\n        return 0\n    else:\n        return inter/union\n\n\ndef weighted_merge(g, p):\n    g[:8] = (g[8] * g[:8] + p[8] * p[:8])/(g[8] + p[8])\n    g[8] = (g[8] + p[8])\n    return g\n\n\ndef standard_nms(S, thres):\n    order = np.argsort(S[:, 8])[::-1]\n    keep = []\n    while order.size > 0:\n        i = order[0]\n        keep.append(i)\n        ovr = np.array([intersection(S[i], S[t]) for t in order[1:]])\n\n        inds = np.where(ovr <= thres)[0]\n        order = order[inds+1]\n\n    return S[keep]\n\n\ndef nms_locality(polys, thres=0.3):\n    '''\n    locality aware nms of EAST\n    :param polys: a N*9 numpy array. first 8 coordinates, then prob\n    :return: boxes after nms\n    '''\n    S = []\n    p = None\n    for g in polys:\n        if p is not None and intersection(g, p) > thres:\n            p = weighted_merge(g, p)\n        else:\n            if p is not None:\n                S.append(p)\n            p = g\n    if p is not None:\n        S.append(p)\n\n    if len(S) == 0:\n        return np.array([])\n    return standard_nms(np.array(S), thres)\n\n\nif __name__ == '__main__':\n    # 343,350,448,135,474,143,369,359\n    print(Polygon(np.array([[343, 350], [448, 135],\n                            [474, 143], [369, 359]])).area)\n"""
loss.py,11,"b""import torch\nfrom torch.autograd import Variable\n\n\n### \xe6\xad\xa4\xe5\xa4\x84\xe9\xbb\x98\xe8\xae\xa4\xe7\x9c\x9f\xe5\xae\x9e\xe5\x80\xbc\xe5\x92\x8c\xe9\xa2\x84\xe6\xb5\x8b\xe5\x80\xbc\xe7\x9a\x84\xe6\xa0\xbc\xe5\xbc\x8f\xe5\x9d\x87\xe4\xb8\xba bs * W * H * channels\nimport torch\nimport torch.nn as nn\n\ndef dice_coefficient(y_true_cls, y_pred_cls,\n                     training_mask):\n    '''\n    dice loss\n    :param y_true_cls:\n    :param y_pred_cls:\n    :param training_mask:\n    :return:\n    '''\n    eps = 1e-5\n    intersection =torch.sum(y_true_cls * y_pred_cls * training_mask)\n    union = torch.sum(y_true_cls * training_mask) + torch.sum(y_pred_cls * training_mask) + eps\n    loss = 1. - (2 * intersection / union)\n\n    return loss\n\nclass LossFunc(nn.Module):\n    def __init__(self):\n        super(LossFunc, self).__init__()\n        return \n    \n    def forward(self, y_true_cls, y_pred_cls, y_true_geo, y_pred_geo, training_mask):\n        classification_loss = dice_coefficient(y_true_cls, y_pred_cls, training_mask)\n        # scale classification loss to match the iou loss part\n        classification_loss *= 0.01\n\n        # d1 -> top, d2->right, d3->bottom, d4->left\n    #     d1_gt, d2_gt, d3_gt, d4_gt, theta_gt = tf.split(value=y_true_geo, num_or_size_splits=5, axis=3)\n        d1_gt, d2_gt, d3_gt, d4_gt, theta_gt = torch.split(y_true_geo, 1, 1)\n    #     d1_pred, d2_pred, d3_pred, d4_pred, theta_pred = tf.split(value=y_pred_geo, num_or_size_splits=5, axis=3)\n        d1_pred, d2_pred, d3_pred, d4_pred, theta_pred = torch.split(y_pred_geo, 1, 1)\n        area_gt = (d1_gt + d3_gt) * (d2_gt + d4_gt)\n        area_pred = (d1_pred + d3_pred) * (d2_pred + d4_pred)\n        w_union = torch.min(d2_gt, d2_pred) + torch.min(d4_gt, d4_pred)\n        h_union = torch.min(d1_gt, d1_pred) + torch.min(d3_gt, d3_pred)\n        area_intersect = w_union * h_union\n        area_union = area_gt + area_pred - area_intersect\n        L_AABB = -torch.log((area_intersect + 1.0)/(area_union + 1.0))\n        L_theta = 1 - torch.cos(theta_pred - theta_gt)\n        L_g = L_AABB + 20 * L_theta\n\n        return torch.mean(L_g * y_true_cls * training_mask) + classification_loss\n\n"""
main.py,7,"b'import torch\nfrom torch.autograd import Variable\nimport os\nfrom torch import nn\nfrom torch.optim import lr_scheduler\nfrom torch.nn.utils.rnn import pack_padded_sequence\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom model import East\nfrom loss import *\nfrom data_utils import custom_dset, collate_fn\nimport time\nfrom tensorboardX import SummaryWriter\nimport config as cfg\nfrom utils.init import *\nfrom utils.util import *\nfrom utils.save import *\nfrom utils.myzip import *\nimport torch.backends.cudnn as cudnn\nfrom eval import predict\nfrom hmean import compute_hmean\nimport zipfile\nimport glob\nimport warnings\nimport numpy as np\n\n\n\ndef train(train_loader, model, criterion, scheduler, optimizer, epoch):\n    start = time.time()\n    losses = AverageMeter()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    end = time.time()\n    model.train()\n    \n    for i, (img, score_map, geo_map, training_mask) in enumerate(train_loader):\n        data_time.update(time.time() - end)\n\n        if cfg.gpu is not None:\n            img, score_map, geo_map, training_mask = img.cuda(), score_map.cuda(), geo_map.cuda(), training_mask.cuda()\n\n        f_score, f_geometry = model(img)\n        loss1 = criterion(score_map, f_score, geo_map, f_geometry, training_mask)\n        losses.update(loss1.item(), img.size(0))\n\n        # backward\n        scheduler.step()\n        optimizer.zero_grad()\n        loss1.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % cfg.print_freq == 0:\n            print(\'EAST <==> TRAIN <==> Epoch: [{0}][{1}/{2}] Loss {loss.val:.4f} Avg Loss {loss.avg:.4f})\\n\'.format(epoch, i, len(train_loader), loss=losses))\n\n        save_loss_info(losses, epoch, i, train_loader)\n\n\ndef main():\n    hmean = .0\n    is_best = False\n\n    warnings.simplefilter(\'ignore\', np.RankWarning)\n    # Prepare for dataset\n    print(\'EAST <==> Prepare <==> DataLoader <==> Begin\')\n    train_root_path = os.path.abspath(os.path.join(\'./dataset/\', \'train\'))\n    train_img = os.path.join(train_root_path, \'img\')\n    train_gt  = os.path.join(train_root_path, \'gt\')\n\n    trainset = custom_dset(train_img, train_gt)\n    train_loader = DataLoader(trainset, batch_size=cfg.train_batch_size_per_gpu*cfg.gpu,\n        shuffle=True, collate_fn=collate_fn, num_workers=cfg.num_workers)\n    print(\'EAST <==> Prepare <==> Batch_size:{} <==> Begin\'.format(cfg.train_batch_size_per_gpu*cfg.gpu))\n    print(\'EAST <==> Prepare <==> DataLoader <==> Done\') \n    \n\n    # test datalodaer\n    """"""\n    for i in range(100000):\n        for j, (a,b,c,d) in enumerate(train_loader):\n            print(i, j,\'/\',len(train_loader))\n    """"""\n\n    # Model\n    print(\'EAST <==> Prepare <==> Network <==> Begin\')\n    model = East()\n    model = nn.DataParallel(model, device_ids=cfg.gpu_ids)\n    model = model.cuda()\n    init_weights(model, init_type=cfg.init_type)\n    cudnn.benchmark = True\n    \n    criterion = LossFunc()\n    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n    scheduler = lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.94)\n    \n    # init or resume\n    if cfg.resume and  os.path.isfile(cfg.checkpoint):\n        weightpath = os.path.abspath(cfg.checkpoint)\n        print(""EAST <==> Prepare <==> Loading checkpoint \'{}\' <==> Begin"".format(weightpath))\n        checkpoint = torch.load(weightpath)\n        start_epoch = checkpoint[\'epoch\']\n        model.load_state_dict(checkpoint[\'state_dict\'])\n        optimizer.load_state_dict(checkpoint[\'optimizer\'])\n        print(""EAST <==> Prepare <==> Loading checkpoint \'{}\' <==> Done"".format(weightpath))\n    else:\n        start_epoch = 0\n    print(\'EAST <==> Prepare <==> Network <==> Done\')\n\n    for epoch in range(start_epoch, cfg.max_epochs):\n\n        train(train_loader, model, criterion, scheduler, optimizer, epoch)\n\n        if epoch % cfg.eval_iteration == 0:\n\n            # create res_file and img_with_box\n            output_txt_dir_path = predict(model, criterion, epoch)\n\n            # Zip file\n            submit_path = MyZip(output_txt_dir_path, epoch)\n\n            # submit and compute Hmean\n            hmean_ = compute_hmean(submit_path)\n\n            if hmean_ > hmean:\n                is_best = True\n\n            state = {\n                    \'epoch\'      : epoch,\n                    \'state_dict\' : model.state_dict(),\n                    \'optimizer\'  : optimizer.state_dict(),\n                    \'is_best\'    : is_best,\n                    }\n            save_checkpoint(state, epoch)\n\n\n\nif __name__ == ""__main__"":\n    main()\n'"
model.py,12,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torch\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        f = []\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        f.append(x)\n        x = self.layer2(x)\n        f.append(x)\n        x = self.layer3(x)\n        f.append(x)\n        x = self.layer4(x)\n        f.append(x)\n        # x = self.avgpool(x)\n        # x = x.view(x.size(0), -1)\n        # x = self.fc(x)\n        \'\'\'\n        f\xe4\xb8\xad\xe7\x9a\x84\xe6\xaf\x8f\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xe7\x9a\x84size\xe5\x88\x86\xe5\x88\xab\xe6\x98\xaf bs 256 w/4 h/4\xef\xbc\x8c bs 512 w/8 h/8\xef\xbc\x8c \n        bs 1024 w/16 h/16\xef\xbc\x8c bs 2048 w/32 h/32\n        \'\'\'\n        return x, f\n\n\ndef resnet50(pretrained=True, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        \n        #model.load_state_dict(torch.load(""./resnet50-19c8e357.pth""))\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef mean_image_subtraction(images, means=[123.68, 116.78, 103.94]):\n    \'\'\'\n    image normalization\n    :param images: bs * w * h * channel \n    :param means:\n    :return:\n    \'\'\'\n    num_channels = images.data.shape[1]\n    if len(means) != num_channels:\n      raise ValueError(\'len(means) must match the number of channels\')\n    for i in range(num_channels):\n        images.data[:,i,:,:] -= means[i]\n\n    return images\n\n\nclass East(nn.Module):\n    def __init__(self):\n        super(East, self).__init__()\n        self.resnet = resnet50(True)\n        self.conv1 = nn.Conv2d(3072, 128, 1)\n        self.bn1 = nn.BatchNorm2d(128)\n        self.relu1 = nn.ReLU()\n\n        self.conv2 = nn.Conv2d(128, 128, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.relu2 = nn.ReLU()\n\n        self.conv3 = nn.Conv2d(640, 64, 1)\n        self.bn3 = nn.BatchNorm2d(64)\n        self.relu3 = nn.ReLU()\n\n        self.conv4 = nn.Conv2d(64, 64, 3 ,padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.relu4 = nn.ReLU()\n\n        self.conv5 = nn.Conv2d(320, 64, 1)\n        self.bn5 = nn.BatchNorm2d(64)\n        self.relu5 = nn.ReLU()\n\n        self.conv6 = nn.Conv2d(64, 32, 3, padding=1)\n        self.bn6 = nn.BatchNorm2d(32)\n        self.relu6 = nn.ReLU()\n\n        self.conv7 = nn.Conv2d(32, 32, 3, padding=1)\n        self.bn7 = nn.BatchNorm2d(32)\n        self.relu7 = nn.ReLU()\n\n        self.conv8 = nn.Conv2d(32, 1, 1)\n        self.sigmoid1 = nn.Sigmoid()\n        self.conv9 = nn.Conv2d(32, 4, 1)\n        self.sigmoid2 = nn.Sigmoid()\n        self.conv10 = nn.Conv2d(32, 1, 1)\n        self.sigmoid3 = nn.Sigmoid()\n        self.unpool1 = nn.Upsample(scale_factor=2, mode=\'bilinear\')\n        self.unpool2 = nn.Upsample(scale_factor=2, mode=\'bilinear\')\n        self.unpool3 = nn.Upsample(scale_factor=2, mode=\'bilinear\')\n    \n    def forward(self,images):\n        images = mean_image_subtraction(images)\n        _, f = self.resnet(images)\n        h = f[3]  # bs 2048 w/32 h/32\n        g = (self.unpool1(h)) #bs 2048 w/16 h/16\n        c = self.conv1(torch.cat((g, f[2]), 1))\n        c = self.bn1(c)\n        c = self.relu1(c)\n        \n        h = self.conv2(c)  # bs 128 w/16 h/16\n        h = self.bn2(h)\n        h = self.relu2(h)\n        g = self.unpool2(h) # bs 128 w/8 h/8\n        c = self.conv3(torch.cat((g, f[1]), 1))\n        c = self.bn3(c)\n        c = self.relu3(c)\n\n        h = self.conv4(c)  # bs 64 w/8 h/8\n        h = self.bn4(h)\n        h = self.relu4(h)\n        g = self.unpool3(h) # bs 64 w/4 h/4\n        c = self.conv5(torch.cat((g, f[0]), 1))\n        c = self.bn5(c)\n        c = self.relu5(c)\n        \n        h = self.conv6(c) # bs 32 w/4 h/4\n        h = self.bn6(h)\n        h = self.relu6(h)\n        g = self.conv7(h) # bs 32 w/4 h/4\n        g = self.bn7(g)\n        g = self.relu7(g)\n        \n        F_score = self.conv8(g) #  bs 1 w/4 h/4\n        F_score = self.sigmoid1(F_score)\n        geo_map = self.conv9(g)\n        geo_map = self.sigmoid2(geo_map) * 512\n        angle_map = self.conv10(g)\n        angle_map = self.sigmoid3(angle_map)\n        angle_map = (angle_map - 0.5) * math.pi / 2\n\n        F_geometry = torch.cat((geo_map, angle_map), 1) # bs 5 w/4 w/4\n        return F_score, F_geometry\n'"
geo_map_cython_lib/setup.py,0,"b""from distutils.core import setup\nfrom distutils.extension import Extension\nfrom Cython.Build import cythonize\nimport numpy\n\nextensions = [\n  Extension('gen_geo_map', ['gen_geo_map.pyx'],\n            include_dirs = [numpy.get_include()]\n  ),\n]\n\nsetup(\n    ext_modules = cythonize(extensions),\n)"""
lanms/__init__.py,0,"b""import subprocess\nimport os\nimport numpy as np\n\nBASE_DIR = os.path.dirname(os.path.realpath(__file__))\n\nif subprocess.call(['make', '-C', BASE_DIR]) != 0:  # return value\n    raise RuntimeError('Cannot compile lanms: {}'.format(BASE_DIR))\n\n\ndef merge_quadrangle_n9(polys, thres=0.3, precision=10000):\n    from .adaptor import merge_quadrangle_n9 as nms_impl\n    if len(polys) == 0:\n        return np.array([], dtype='float32')\n    p = polys.copy()\n    p[:,:8] *= precision\n    ret = np.array(nms_impl(p, thres), dtype='float32')\n    ret[:,:8] /= precision\n    return ret\n\n"""
lanms/__main__.py,0,"b""import numpy as np\n\n\nfrom . import merge_quadrangle_n9\n\nif __name__ == '__main__':\n    # unit square with confidence 1\n    q = np.array([0, 0, 0, 1, 1, 1, 1, 0, 1], dtype='float32')\n\n    print(merge_quadrangle_n9(np.array([q, q + 0.1, q + 2])))\n"""
pyicdartools/TL_iou.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport sys\nsys.path.append(\'.\')\nfrom collections import namedtuple\nfrom pyicdartools import rrc_evaluation_funcs\nimport importlib\nfrom shapely.geometry import Polygon as plg\nimport numpy as np\n\ndef evaluation_imports():\n    """"""\n    evaluation_imports: Dictionary ( key = module name , value = alias  )  with python modules used in the evaluation.\n    """"""\n    return {\n            \'Polygon\':\'plg\',\n            \'numpy\':\'np\'\n            }\n\ndef default_evaluation_params():\n    """"""\n    default_evaluation_params: Default parameters to use for the validation and evaluation.\n    """"""\n    return {\n                \'IOU_CONSTRAINT\' : 0.5,\n                \'AREA_PRECISION_CONSTRAINT\' : 0.5,\n                \'GT_SAMPLE_NAME_2_ID\':\'gt_img_([0-9]+).txt\',\n                \'DET_SAMPLE_NAME_2_ID\':\'res_img_([0-9]+).txt\',\n                \'LTRB\':False, #LTRB:2points(left,top,right,bottom) or 4 points(x1,y1,x2,y2,x3,y3,x4,y4)\n                \'CRLF\':False, # Lines are delimited by Windows CRLF format\n                \'CONFIDENCES\':False, #Detections must include confidence value. AP will be calculated\n                \'PER_SAMPLE_RESULTS\':True #Generate per sample results and produce data for visualization\n            }\n\ndef validate_data(gtFilePath, submFilePath,evaluationParams):\n    """"""\n    Method validate_data: validates that all files in the results folder are correct (have the correct name contents).\n                            Validates also that there are no missing files in the folder.\n                            If some error detected, the method raises the error\n    """"""\n    gt = rrc_evaluation_funcs.load_zip_file(gtFilePath,evaluationParams[\'GT_SAMPLE_NAME_2_ID\'])\n\n    subm = rrc_evaluation_funcs.load_zip_file(submFilePath,evaluationParams[\'DET_SAMPLE_NAME_2_ID\'],True)\n\n    #Validate format of GroundTruth\n    for k in gt:\n        rrc_evaluation_funcs.validate_lines_in_file(k,gt[k],evaluationParams[\'CRLF\'],evaluationParams[\'LTRB\'],True)\n\n    #Validate format of results\n    for k in subm:\n        if (k in gt) == False :\n            raise Exception(""The sample %s not present in GT"" %k)\n\n        rrc_evaluation_funcs.validate_lines_in_file(k,subm[k],evaluationParams[\'CRLF\'],evaluationParams[\'LTRB\'],False,evaluationParams[\'CONFIDENCES\'])\n\n\ndef evaluate_method(gtFilePath, submFilePath, evaluationParams):\n    """"""\n    Method evaluate_method: evaluate method and returns the results\n        Results. Dictionary with the following values:\n        - method (required)  Global method metrics. Ex: { \'Precision\':0.8,\'Recall\':0.9 }\n        - samples (optional) Per sample metrics. Ex: {\'sample1\' : { \'Precision\':0.8,\'Recall\':0.9 } , \'sample2\' : { \'Precision\':0.8,\'Recall\':0.9 }\n    """"""\n    """"""\n    for module,alias in evaluation_imports().items():\n        globals()[alias] = importlib.import_module(module)\n    """"""\n    def polygon_from_points(points):\n        """"""\n        Returns a Polygon object to use with the Polygon2 class from a list of 8 points: x1,y1,x2,y2,x3,y3,x4,y4\n        """"""\n        resBoxes=np.empty([1,8],dtype=\'int32\')\n        resBoxes[0,0]=int(points[0])\n        resBoxes[0,4]=int(points[1])\n        resBoxes[0,1]=int(points[2])\n        resBoxes[0,5]=int(points[3])\n        resBoxes[0,2]=int(points[4])\n        resBoxes[0,6]=int(points[5])\n        resBoxes[0,3]=int(points[6])\n        resBoxes[0,7]=int(points[7])\n        pointMat = resBoxes[0].reshape([2,4]).T\n        return plg( pointMat)\n\n    def rectangle_to_polygon(rect):\n        resBoxes=np.empty([1,8],dtype=\'int32\')\n        resBoxes[0,0]=int(rect.xmin)\n        resBoxes[0,4]=int(rect.ymax)\n        resBoxes[0,1]=int(rect.xmin)\n        resBoxes[0,5]=int(rect.ymin)\n        resBoxes[0,2]=int(rect.xmax)\n        resBoxes[0,6]=int(rect.ymin)\n        resBoxes[0,3]=int(rect.xmax)\n        resBoxes[0,7]=int(rect.ymax)\n\n        pointMat = resBoxes[0].reshape([2,4]).T\n\n        return plg( pointMat)\n\n    def rectangle_to_points(rect):\n        points = [int(rect.xmin), int(rect.ymax), int(rect.xmax), int(rect.ymax), int(rect.xmax), int(rect.ymin), int(rect.xmin), int(rect.ymin)]\n        return points\n\n    def get_union(pD,pG):\n        areaA = pD.area;\n        areaB = pG.area;\n        return areaA + areaB - get_intersection(pD, pG);\n\n    def get_intersection_over_union(pD,pG):\n        try:\n            return get_intersection(pD, pG) / get_union(pD, pG);\n        except:\n            return 0\n\n    def get_intersection(pD,pG):\n        pInt = pD & pG\n        try:\n            if len(pInt) == 0:\n                return 0\n        except:\n            return pInt.area\n\n    def compute_ap(confList, matchList,numGtCare):\n        correct = 0\n        AP = 0\n        if len(confList)>0:\n            confList = np.array(confList)\n            matchList = np.array(matchList)\n            sorted_ind = np.argsort(-confList)\n            confList = confList[sorted_ind]\n            matchList = matchList[sorted_ind]\n            for n in range(len(confList)):\n                match = matchList[n]\n                if match:\n                    correct += 1\n                    AP += float(correct)/(n + 1)\n\n            if numGtCare>0:\n                AP /= numGtCare\n\n        return AP\n\n    perSampleMetrics = {}\n\n    matchedSum = 0\n\n    Rectangle = namedtuple(\'Rectangle\', \'xmin ymin xmax ymax\')\n\n    gt = rrc_evaluation_funcs.load_zip_file(gtFilePath,evaluationParams[\'GT_SAMPLE_NAME_2_ID\'])\n    subm = rrc_evaluation_funcs.load_zip_file(submFilePath,evaluationParams[\'DET_SAMPLE_NAME_2_ID\'],True)\n\n    numGlobalCareGt = 0;\n    numGlobalCareDet = 0;\n\n    arrGlobalConfidences = [];\n    arrGlobalMatches = [];\n\n    for ids, resFile in enumerate(gt):\n\n        gtFile = rrc_evaluation_funcs.decode_utf8(gt[resFile])\n        recall = 0\n        precision = 0\n        hmean = 0\n\n        detMatched = 0\n\n        iouMat = np.empty([1,1])\n\n        gtPols = []\n        detPols = []\n\n        gtPolPoints = []\n        detPolPoints = []\n\n        #Array of Ground Truth Polygons\' keys marked as don\'t Care\n        gtDontCarePolsNum = []\n        #Array of Detected Polygons\' matched with a don\'t Care GT\n        detDontCarePolsNum = []\n\n        pairs = []\n        detMatchedNums = []\n\n        arrSampleConfidences = [];\n        arrSampleMatch = [];\n        sampleAP = 0;\n\n        evaluationLog = """"\n\n        pointsList,_,transcriptionsList = rrc_evaluation_funcs.get_tl_line_values_from_file_contents(gtFile,evaluationParams[\'CRLF\'],evaluationParams[\'LTRB\'],True,False)\n        for n in range(len(pointsList)):\n            points = pointsList[n]\n            transcription = transcriptionsList[n]\n            dontCare = transcription == ""###""\n            if evaluationParams[\'LTRB\']:\n                gtRect = Rectangle(*points)\n                gtPol = rectangle_to_polygon(gtRect)\n            else:\n                gtPol = polygon_from_points(points)\n            gtPols.append(gtPol)\n            gtPolPoints.append(points)\n            if dontCare:\n                gtDontCarePolsNum.append( len(gtPols)-1 )\n\n        evaluationLog += ""GT polygons: "" + str(len(gtPols)) + ("" ("" + str(len(gtDontCarePolsNum)) + "" don\'t care)\\n"" if len(gtDontCarePolsNum)>0 else ""\\n"")\n\n        if resFile in subm:\n\n            detFile = rrc_evaluation_funcs.decode_utf8(subm[resFile])\n\n            pointsList,confidencesList,_ = rrc_evaluation_funcs.get_tl_line_values_from_file_contents(detFile,evaluationParams[\'CRLF\'],evaluationParams[\'LTRB\'],False,evaluationParams[\'CONFIDENCES\'])\n            for n in range(len(pointsList)):\n                points = pointsList[n]\n\n                if evaluationParams[\'LTRB\']:\n                    detRect = Rectangle(*points)\n                    detPol = rectangle_to_polygon(detRect)\n                else:\n                    detPol = polygon_from_points(points)\n                detPols.append(detPol)\n                detPolPoints.append(points)\n                if len(gtDontCarePolsNum)>0 :\n                    for dontCarePol in gtDontCarePolsNum:\n                        dontCarePol = gtPols[dontCarePol]\n                        intersected_area = get_intersection(dontCarePol,detPol)\n                        pdDimensions = detPol.area\n                        precision = 0 if pdDimensions == 0 else intersected_area / pdDimensions\n                        if (precision > evaluationParams[\'AREA_PRECISION_CONSTRAINT\'] ):\n                            detDontCarePolsNum.append( len(detPols)-1 )\n                            break\n\n            evaluationLog += ""DET polygons: "" + str(len(detPols)) + ("" ("" + str(len(detDontCarePolsNum)) + "" don\'t care)\\n"" if len(detDontCarePolsNum)>0 else ""\\n"")\n\n            if len(gtPols)>0 and len(detPols)>0:\n                #Calculate IoU and precision matrixs\n                outputShape=[len(gtPols),len(detPols)]\n                iouMat = np.empty(outputShape)\n                gtRectMat = np.zeros(len(gtPols),np.int8)\n                detRectMat = np.zeros(len(detPols),np.int8)\n                for gtNum in range(len(gtPols)):\n                    for detNum in range(len(detPols)):\n                        pG = gtPols[gtNum]\n                        pD = detPols[detNum]\n                        iouMat[gtNum,detNum] = get_intersection_over_union(pD,pG)\n\n                for gtNum in range(len(gtPols)):\n                    match = False;\n                    for detNum in range(len(detPols)):\n                        if gtRectMat[gtNum] == 0 and detRectMat[detNum] == 0 and gtNum not in gtDontCarePolsNum and detNum not in detDontCarePolsNum :\n                            if iouMat[gtNum,detNum]>evaluationParams[\'IOU_CONSTRAINT\']:\n                                gtRectMat[gtNum] = 1\n                                detRectMat[detNum] = 1\n                                detMatched += 1\n                                pairs.append({\'gt\':gtNum,\'det\':detNum})\n                                detMatchedNums.append(detNum)\n                                evaluationLog += ""Match GT #"" + str(gtNum) + "" with Det #"" + str(detNum) + ""\\n""\n                                match = True\n\n                if evaluationParams[\'CONFIDENCES\']:\n                    for detNum in range(len(detPols)):\n                        if detNum not in detDontCarePolsNum :\n                            #we exclude the don\'t care detections\n                            match = detNum in detMatchedNums\n\n                            arrSampleConfidences.append(confidencesList[detNum])\n                            arrSampleMatch.append(match)\n\n                            arrGlobalConfidences.append(confidencesList[detNum]);\n                            arrGlobalMatches.append(match);\n\n        numGtCare = (len(gtPols) - len(gtDontCarePolsNum))\n        numDetCare = (len(detPols) - len(detDontCarePolsNum))\n        if numGtCare == 0:\n            recall = float(1)\n            precision = float(0) if numDetCare >0 else float(1)\n            sampleAP = precision\n        else:\n            recall = float(detMatched) / numGtCare\n            precision = 0 if numDetCare==0 else float(detMatched) / numDetCare\n            if evaluationParams[\'CONFIDENCES\'] and evaluationParams[\'PER_SAMPLE_RESULTS\']:\n                sampleAP = compute_ap(arrSampleConfidences, arrSampleMatch, numGtCare )\n\n        hmean = 0 if (precision + recall)==0 else 2.0 * precision * recall / (precision + recall)\n        print(\'==\'*28)\n        print(\'ID:{:3d} P {:3d}% R {:3d}% Hmean {:3d}% Matched:{:2d} GT:{:2d} Det:{:2d}\'.format(ids+1, int(precision*100), int(recall*100), int(hmean*100),detMatched, numGtCare, numDetCare))\n        matchedSum += detMatched\n        numGlobalCareGt += numGtCare\n        numGlobalCareDet += numDetCare\n\n        if evaluationParams[\'PER_SAMPLE_RESULTS\']:\n            perSampleMetrics[resFile] = {\n                                            \'precision\':precision,\n                                            \'recall\':recall,\n                                            \'hmean\':hmean,\n                                            \'pairs\':pairs,\n                                            \'AP\':sampleAP,\n                                            \'iouMat\':[] if len(detPols)>100 else iouMat.tolist(),\n                                            \'gtPolPoints\':gtPolPoints,\n                                            \'detPolPoints\':detPolPoints,\n                                            \'gtDontCare\':gtDontCarePolsNum,\n                                            \'detDontCare\':detDontCarePolsNum,\n                                            \'evaluationParams\': evaluationParams,\n                                            \'evaluationLog\': evaluationLog\n                                        }\n\n    # Compute MAP and MAR\n    AP = 0\n    if evaluationParams[\'CONFIDENCES\']:\n        AP = compute_ap(arrGlobalConfidences, arrGlobalMatches, numGlobalCareGt)\n\n    methodRecall = 0 if numGlobalCareGt == 0 else float(matchedSum)/numGlobalCareGt\n    methodPrecision = 0 if numGlobalCareDet == 0 else float(matchedSum)/numGlobalCareDet\n    methodHmean = 0 if methodRecall + methodPrecision==0 else 2* methodRecall * methodPrecision / (methodRecall + methodPrecision)\n\n    methodMetrics = {\'precision\':methodPrecision, \'recall\':methodRecall,\'hmean\': methodHmean, \'AP\': AP  }\n\n    resDict = {\'calculated\':True,\'Message\':\'\',\'method\': methodMetrics,\'per_sample\': perSampleMetrics}\n\n\n    return resDict;\n\n\n\nif __name__==\'__main__\':\n    rrc_evaluation_funcs.main_evaluation(None,default_evaluation_params,validate_data,evaluate_method)\n'"
pyicdartools/__init__.py,0,b'#!/usr/bin/env python2\n#encoding: UTF-8\n'
pyicdartools/config.py,0,"b'#!/usr/bin/env python2\r\n#encoding: UTF-8\r\nimport json\r\n#Name of the script used for the evalution\r\nevaluation_script = \'TL_iou\'\r\n#Custom evalution params\r\nevaluation_params = json.loads(""""""{""IOU_CONSTRAINT"":0.5,""AREA_PRECISION_CONSTRAINT"":0.5,""GT_SAMPLE_NAME_2_ID"":""gt_img_([0-9]+).txt"",""DET_SAMPLE_NAME_2_ID"":""res_img_([0-9]+).txt"",""LTRB"":false,""CRLF"":false,""CONFIDENCES"":false}"""""")\r\n#Upload instructions\r\ninstructions = """"""<ul>\r\n\t<li>A single zip file is expected, containing a set of text files.</li>\r\n\t<li>No directory structure within the zip file is permitted, just the set of text files.</li>\r\n\t<li>The containing text files should be named as&nbsp;<strong><em>res_img_#.txt</em></strong>, where&nbsp;<em><strong>#</strong></em>&nbsp;is the number of the corresponding test-set image.</li>\r\n\t<li>Each text file should contain as many lines as text bounding boxes found. Each line should contain eight comma separated values only. The values should correspond to the coordinates of the four corners of the bounding quadrilateral of the word.</li>\r\n\t<li>New lines in the text files should be indicated with the windows CR/LF termination.</li>\r\n</ul>\r\n\r\n<p>The submitted zip file is automatically checked at the time of submission, and a submission log is presented to the user along with a confirmation of the submission. The checks performed are the following:</p>\r\n\r\n<ul>\r\n\t<li>That the file submitted is a valid zip file, it can be opened and the contents can be extracted.</li>\r\n\t<li>That the names of the text files contained are correct and the image numbers are within the bounds of the test set.</li>\r\n\t<li>That each text file contains eight comma separated values per line.</li>\r\n\t<li>That the coordinates passed are within the bounds of the image and that the coordinates are in clocwise order</li>\r\n</ul>\r\n\r\n<p>See here an example of the&nbsp;<a href=""http://rrc.cvc.uab.es/files/task1_ch4_sample.zip"">expected submission file</a></p>\r\n""""""\r\n#Extension of the GT file. gt.[extension]\r\ngt_ext = ""zip""\r\n#Acronym for the task. It\'s used to cache the Images\r\nacronym = ""IST-T1""\r\n#Title of the Task\r\ntitle = ""Incidental Scene Text - Task 1 Text Localization TEST DATASET (evaluation:IoU)""\r\n#Custom JavaScript for the visualiztion.\r\ncustomJS = \'visualization_TL_iou.js\'\r\n#Custom CSS for the visualiztion.\r\ncustomCSS = \'visualization_TL_iou.css\'\r\n#Parameters used to show the results of a method and the method\'s ranking\r\nmethod_params = json.loads(""""""{""recall"":{""long_name"":""Recall"",""type"":""double"",""order"":"""",""grafic"":""1"",""format"":""perc""},""precision"":{""long_name"":""Precision"",""type"":""double"",""order"":"""",""grafic"":""1"",""format"":""perc""},""hmean"":{""long_name"":""Hmean"",""type"":""double"",""order"":""desc"",""grafic"":""1"",""format"":""perc""}}"""""")\r\n#Parameters to show for each sample\r\nsample_params = json.loads(""""""{""recall"":{""long_name"":""Recall"",""type"":""double"",""order"":"""",""grafic"":"""",""format"":""perc""},""precision"":{""long_name"":""Precision"",""type"":""double"",""order"":"""",""grafic"":"""",""format"":""perc""},""hmean"":{""long_name"":""Hmean"",""type"":""double"",""order"":""desc"",""grafic"":"""",""format"":""perc""}}"""""")\r\n#Parameters to ask for for each submition\r\nsubmit_params = json.loads(""""""{}"""""")\r\n#Regular expression to get the Sample ID from the image name. ID must be the first capturing group.\r\nimage_name_to_id_str = \'img_([0-9]+).(jpg|gif|png)\'\r\n'"
pyicdartools/evaluation.py,0,"b'#!/usr/bin/env python2\r\n# -*- coding: utf-8 -*-\r\nimport sys\r\nimport os\r\n\r\nsys.path.append(\'./\')\r\nimport json\r\nimport StringIO\r\nimport zipfile\r\nimport re\r\nfrom datetime import datetime\r\nimport importlib\r\nimport sqlite3\r\nimport rrc_evaluation_funcs\r\nfrom config import *\r\nimport pickle\r\nimport cv2\r\nimport shapely\r\nfrom shapely.geometry import Polygon, MultiPoint\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport matplotlib.image as mpimg\r\nfrom collections import defaultdict\r\nimport operator\r\n\r\ntry:\r\n    from bottle import route, run, request, static_file, url, template, TEMPLATE_PATH, HTTPResponse, redirect\r\nexcept ImportError:\r\n    print """"""Required module not found: Bottle. Installation: pip install --user bottle""""""\r\n    sys.exit(-1)\r\n\r\ntry:\r\n    from PIL import Image\r\nexcept ImportError:\r\n    print """"""Required module not found: Pillow. Installation: pip install --user Pillow""""""\r\n    sys.exit(-1)\r\n\r\np = {\r\n    \'g\': os.path.dirname(os.path.abspath(__file__)) + ""/gt/gt."" + gt_ext,\r\n    # \'s\': \'/home/mhliao/research/oriented/TextBoxes_polygon/data/data_text/icdar15_rbox/icdar15_submit.zip\',\r\n    \'o\': os.path.dirname(os.path.abspath(__file__)) + ""/output"",\r\n    \'p\': evaluation_params\r\n}\r\n\r\nimg_dir = \'/home/mhliao/data/icdar15/test_images/\'\r\n\r\n\r\ndef list_from_str(st):\r\n    line = st.split(\',\')\r\n    new_line = [float(a) for a in line[0:8]] + [float(line[-1])]\r\n    return new_line\r\n\r\n\r\ndef polygon_from_list(line):\r\n    """"""\r\n    Create a shapely polygon object from gt or dt line.\r\n    """"""\r\n    # polygon_points = [float(o) for o in line.split(\',\')[:8]]\r\n    polygon_points = np.array(line).reshape(4, 2)\r\n    polygon = Polygon(polygon_points).convex_hull\r\n    return polygon\r\n\r\n\r\ndef polygon_iou(list1, list2):\r\n    """"""\r\n    Intersection over union between two shapely polygons.\r\n    """"""\r\n    polygon_points1 = np.array(list1).reshape(4, 2)\r\n    poly1 = Polygon(polygon_points1).convex_hull\r\n    polygon_points2 = np.array(list2).reshape(4, 2)\r\n    poly2 = Polygon(polygon_points2).convex_hull\r\n    union_poly = np.concatenate((polygon_points1, polygon_points2))\r\n    if not poly1.intersects(poly2):  # this test is fast and can accelerate calculation\r\n        iou = 0\r\n    else:\r\n        try:\r\n            inter_area = poly1.intersection(poly2).area\r\n            # union_area = poly1.area + poly2.area - inter_area\r\n            union_area = MultiPoint(union_poly).convex_hull.area\r\n            if union_area == 0:\r\n                return 0\r\n            iou = float(inter_area) / union_area\r\n        except shapely.geos.TopologicalError:\r\n            print(\'shapely.geos.TopologicalError occured, iou set to 0\')\r\n            iou = 0\r\n    return iou\r\n\r\n\r\ndef nms(boxes, overlap):\r\n    rec_scores = [b[-1] for b in boxes]\r\n    indices = sorted(range(len(rec_scores)), key=lambda k: -rec_scores[k])\r\n    box_num = len(boxes)\r\n    nms_flag = [True] * box_num\r\n    for i in range(box_num):\r\n        ii = indices[i]\r\n        if not nms_flag[ii]:\r\n            continue\r\n        for j in range(box_num):\r\n            jj = indices[j]\r\n            if j == i:\r\n                continue\r\n            if not nms_flag[jj]:\r\n                continue\r\n            box1 = boxes[ii]\r\n            box2 = boxes[jj]\r\n            box1_score = rec_scores[ii]\r\n            box2_score = rec_scores[jj]\r\n            # str1 = box1[9]\r\n            # str2 = box2[9]\r\n            # box_i = [box1[0], box1[1], box1[4], box1[5]]\r\n            # box_j = [box2[0], box2[1], box2[4], box2[5]]\r\n            poly1 = polygon_from_list(box1[0:8])\r\n            poly2 = polygon_from_list(box2[0:8])\r\n            iou = polygon_iou(box1[0:8], box2[0:8])\r\n            thresh = overlap\r\n\r\n            if iou > thresh:\r\n                if box1_score > box2_score:\r\n                    nms_flag[jj] = False\r\n                if box1_score == box2_score and poly1.area > poly2.area:\r\n                    nms_flag[jj] = False\r\n                if box1_score == box2_score and poly1.area <= poly2.area:\r\n                    nms_flag[ii] = False\r\n                    break\r\n            \'\'\'\r\n            if abs((box_i[3]-box_i[1])-(box_j[3]-box_j[1]))<((box_i[3]-box_i[1])+(box_j[3]-box_j[1]))/2:\r\n                if abs(box_i[3]-box_j[3])+abs(box_i[1]-box_j[1])<(max(box_i[3],box_j[3])-min(box_i[1],box_j[1]))/3:\r\n                    if box_i[0]<=box_j[0] and (box_i[2]+min(box_i[3]-box_i[1],box_j[3]-box_j[1])>=box_j[2]):\r\n                        nms_flag[jj] = False\r\n            \'\'\'\r\n    return nms_flag\r\n\r\n\r\ndef packing(save_dir, pack_dir, pack_name):\r\n    files = os.listdir(save_dir)\r\n    if not os.path.exists(pack_dir):\r\n        os.mkdir(pack_dir)\r\n    os.system(\'zip -r -j \' + os.path.join(pack_dir, pack_name + \'.zip\') + \' \' + save_dir + \'/*\')\r\n\r\ndef test_single(dt_dir, score_det, overlap, zip_dir, pack_dir, result_list, vis_path=\'\'):\r\n    print score_det, overlap\r\n    if not os.path.exists(zip_dir):\r\n        os.mkdir(zip_dir)\r\n    nms_dir = os.path.join(zip_dir, str(score_det) + \'_over\' + str(overlap))\r\n    if not os.path.exists(nms_dir):\r\n        os.mkdir(nms_dir)\r\n    for i in range(1, 501):\r\n        img = \'img_\' + str(i) + \'.jpg\'\r\n        print img\r\n        image = cv2.imread(os.path.join(img_dir, img))\r\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n        gt_img = \'gt_img_\' + str(i) + \'.txt\'\r\n        with open(os.path.join(\'./gt/gt\', gt_img)) as f:\r\n            ori_gt_lines = [o.decode(\'utf-8-sig\').encode(\'utf-8\') for o in f.readlines()]\r\n        ori_gt_coors = [g.strip().split(\',\')[0:8] for g in ori_gt_lines]\r\n        ori_gt_lines = [g.strip().split(\',\') for g in ori_gt_lines]\r\n        for ii, g in enumerate(ori_gt_coors):\r\n            x1 = int(g[0])\r\n            y1 = int(g[1])\r\n            x2 = int(g[2])\r\n            y2 = int(g[3])\r\n            x3 = int(g[4])\r\n            y3 = int(g[5])\r\n            x4 = int(g[6])\r\n            y4 = int(g[7])\r\n            ori_gt_coors[ii] = [x1, y1, x2, y2, x3, y3, x4, y4]\r\n        with open(os.path.join(dt_dir, \'res_img_\' + str(i) + \'.txt\'), \'r\') as f:\r\n            dt_lines = [a.strip() for a in f.readlines()]\r\n        dt_lines = [list_from_str(dt) for dt in dt_lines]\r\n        test_coors = []\r\n        for t in dt_lines:\r\n            if t[8] > score_det:\r\n                test_coors.append(t[0:8])\r\n\r\n        dt_lines = [dt for dt in dt_lines if dt[-1] > score_det]\r\n        nms_flag = nms(dt_lines, overlap)\r\n        boxes = []\r\n        for k in range(len(dt_lines)):\r\n            dt = dt_lines[k]\r\n            if nms_flag[k]:\r\n                if dt not in boxes:\r\n                    boxes.append(dt)\r\n\r\n        with open(os.path.join(nms_dir, \'res_img_\' + str(i) + \'.txt\'), \'w\') as f:\r\n            for g in boxes:\r\n                gt_coors = [int(b) for b in g[0:8]]\r\n                # gt_coor_strs = [str(a) for a in gt_coors]+ [g[-2]]\r\n                gt_coor_strs = [str(a) for a in gt_coors]\r\n                f.write(\',\'.join(gt_coor_strs) + \'\\r\\n\')\r\n\r\n        if vis_path:\r\n            if len(boxes) > 0:\r\n                hit_gts = []\r\n                bad_dts = []\r\n                hit_dts = []\r\n                max_iou = []\r\n                dictlist = [defaultdict(int) for x in range(len(ori_gt_lines))]\r\n                for index_dt in range(len(boxes)):\r\n                    ori_dt = boxes[index_dt][0:8]\r\n                    ious = []\r\n                    for index_gt in range(len(ori_gt_coors)):\r\n                        ori_gt = ori_gt_coors[index_gt]\r\n                        poly1 = polygon_from_list(ori_gt)\r\n                        poly2 = polygon_from_list(ori_dt)\r\n                        iou = polygon_iou(ori_gt, ori_dt)\r\n                        # print \'iou\',iou\r\n                        ious.append(iou)\r\n                    max_iou = max(ious)\r\n                    max_index = ious.index(max_iou)\r\n                    if max_iou > 0.5:\r\n                        dictlist[max_index][index_dt] = max_iou\r\n                dt_gt = defaultdict(int)\r\n                for index_gt_dts, gt_dts in enumerate(dictlist):\r\n                    if len(gt_dts) == 0:\r\n                        continue\r\n                    else:\r\n                        sorted_dts = sorted(gt_dts.items(), key=operator.itemgetter(1))\r\n                        dt_gt[sorted_dts[0][0]] = index_gt_dts\r\n\r\n                for index_dt, bb in enumerate(boxes):\r\n                    # matched gt and dt\r\n                    if index_dt in dt_gt.keys():\r\n                        index_gt = dt_gt[index_dt]\r\n                        hit_gts.append(ori_gt_lines[index_gt])\r\n                        hit_dts.append(bb)\r\n                        # print \'match gt,dt\',ori_gt_lines[index_gt],bb\r\n                bad_dts = [item for item in boxes if item not in hit_dts]\r\n                # miss_gts = list(set(ori_gt_lines)^set(hit_gts))\r\n                miss_gts = [item for item in ori_gt_lines if item not in hit_gts]\r\n                miss_gts = [gg for gg in miss_gts if \'#\' not in gg[-1]]\r\n\r\n                if not os.path.exists(vis_path):\r\n                    os.mkdir(vis_path)\r\n                plt.clf()\r\n\r\n                plt.imshow(image, aspect=\'normal\')\r\n                currentAxis = plt.gca()\r\n                for index in range(len(hit_dts)):\r\n                    res = hit_dts[index][0:8]\r\n                    res = [int(a) for a in res]\r\n                    res = np.array(res).reshape(4, 2)\r\n                    currentAxis.add_patch(plt.Polygon(res, fill=None, edgecolor=\'#00FF00\', linewidth=1))\r\n                    # rec_str = hit_dts[index][-2]\r\n                    axis_x = res[0][0] - 4\r\n                    axis_y = res[0][1] - 4\r\n                    # currentAxis.text(axis_x, axis_y, rec_str, color=\'#FFFF00\',fontsize=5,fontweight=\'bold\')\r\n                for index in range(len(bad_dts)):\r\n                    res = bad_dts[index][0:8]\r\n                    res = [int(a) for a in res]\r\n                    res = np.array(res).reshape(4, 2)\r\n                    currentAxis.add_patch(plt.Polygon(res, fill=None, edgecolor=\'r\', linewidth=1))\r\n                    # rec_str = bad_dts[index][-2]\r\n                    axis_x = res[0][0] - 10\r\n                    axis_y = res[0][1] - 10\r\n                    # currentAxis.text(axis_x, axis_y, rec_str, color=\'#FFFF00\',fontsize=12)\r\n                for index in range(len(miss_gts)):\r\n                    res = miss_gts[index][0:8]\r\n                    res = [int(a) for a in res]\r\n                    res = np.array(res).reshape(4, 2)\r\n                    currentAxis.add_patch(plt.Polygon(res, fill=None, linestyle=\'dashdot\', edgecolor=\'r\', linewidth=1))\r\n                    # rec_str = miss_gts[index][-2]\r\n                    axis_x = res[0][0]\r\n                    axis_y = res[0][1]\r\n                    # currentAxis.text(axis_x, axis_y, rec_str, color=\'#FFFF00\',fontsize=18)\r\n                plt.axis(\'off\')\r\n                plt.tick_params(axis=\'both\', left=\'off\', top=\'off\', right=\'off\', bottom=\'off\', labelleft=\'off\',\r\n                                labeltop=\'off\', labelright=\'off\', labelbottom=\'off\')\r\n                plt.savefig(os.path.join(vis_path, img), dpi=300, bbox_inches=\'tight\', pad_inches=0)\r\n                plt.close()\r\n    pack_name = str(score_det) + \'_over\' + str(overlap)\r\n\r\n    packing(nms_dir, pack_dir, pack_name)\r\n    submit_dir = os.path.join(pack_dir, pack_name + \'.zip\')\r\n\r\n    res = online_test(submit_dir, result_list)\r\n    res = [str(float(a)) for a in res]\r\n    res = [str(score_det), str(overlap)] + res\r\n    with open(result_list, \'a\') as f1:\r\n        f1.write(\',\'.join(res) + \'\\n\')\r\n\r\n\r\ndef test_all(dt_dir, zip_dir, pack_dir, result_list, pkl_file, vis_path=\'\'):\r\n    score_det_range = [0]\r\n    # score_rec_range = [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1]\r\n    score_rec_range = [0.05, 0.06]\r\n    overlap_range = [a / 100.0 for a in range(22, 27, 2)]\r\n    score_det = 0\r\n    for score_rec in score_rec_range:\r\n        for overlap in overlap_range:\r\n            if not os.path.exists(pkl_file):\r\n                tested_list = []\r\n                with open(pkl_file, \'wb\') as f:\r\n                    pickle.dump(tested_list, f)\r\n            else:\r\n                with open(pkl_file, \'rb\') as f:\r\n                    tested_list = pickle.load(f)\r\n                to_test = [score_det, score_rec, overlap]\r\n                to_test = [str(i) for i in to_test]\r\n                to_test = \',\'.join(to_test)\r\n                if to_test not in tested_list:\r\n                    test_single(dt_dir, score_det, score_rec, overlap, zip_dir, pack_dir, result_list, vis_path)\r\n                    tested_list.append(to_test)\r\n                    with open(pkl_file, \'wb\') as f:\r\n                        pickle.dump(tested_list, f)\r\n                else:\r\n                    continue\r\n\r\ndef online_test(submit_dir, result_list):\r\n    for k, _ in submit_params.iteritems():\r\n        p[\'p\'][k] = request.forms.get(k)\r\n    module = importlib.import_module(""config."" + evaluation_script)\r\n    # resDict = rrc_evaluation_funcs.main_evaluation(p,module.default_evaluation_params,module.validate_data,module.evaluate_method)\r\n    evalParams = module.default_evaluation_params()\r\n    print(evalParams)\r\n    if \'p\' in p.keys():\r\n        evalParams.update(p[\'p\'] if isinstance(p[\'p\'], dict) else json.loads(p[\'p\'][1:-1]))\r\n    module.validate_data(p[\'g\'], submit_dir, evalParams)\r\n    evalData = module.evaluate_method(p[\'g\'], submit_dir, evalParams)\r\n    resDict = {\'calculated\': True, \'Message\': \'\', \'method\': \'{}\', \'per_sample\': \'{}\'}\r\n    resDict.update(evalData)\r\n    # print(resDict[\'method\'])\r\n    precision = resDict[\'method\'][\'precision\']\r\n    recall = resDict[\'method\'][\'recall\']\r\n    fmeasure = resDict[\'method\'][\'hmean\']\r\n    print \'p,r,f\', precision, recall, fmeasure\r\n    return [precision, recall, fmeasure]\r\n\r\n\r\ndef visulization(img_dir, bbox_dir, visu_dir):\r\n    for root, dirs, files in os.walk(img_dir):\r\n        for file in files:\r\n            # print(file)\r\n            # if file!=\'img_75.jpg\':\r\n            #   continue\r\n            print(file)\r\n            image_name = file\r\n            img_path = os.path.join(img_dir, image_name)\r\n            img = cv2.imread(img_path)\r\n            plt.clf()\r\n            plt.imshow(img)\r\n            currentAxis = plt.gca()\r\n            bbox_name = \'res_\' + file[0:len(file) - 3] + \'txt\'\r\n            bbox_path = os.path.join(bbox_dir, bbox_name)\r\n            if os.path.isfile(bbox_path):\r\n                with open(bbox_path, \'r\') as f:\r\n                    count = 1\r\n                    for line in f.readlines():\r\n                        line = line.strip()\r\n                        x1 = line.split(\',\')[0]\r\n                        y1 = line.split(\',\')[1]\r\n                        x2 = line.split(\',\')[2]\r\n                        y2 = line.split(\',\')[3]\r\n                        x3 = line.split(\',\')[4]\r\n                        y3 = line.split(\',\')[5]\r\n                        x4 = line.split(\',\')[6]\r\n                        y4 = line.split(\',\')[7]\r\n                        rbox = np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\r\n                        color_rbox = \'r\'\r\n                        currentAxis.add_patch(plt.Polygon(rbox, fill=False, edgecolor=color_rbox, linewidth=1))\r\n                        # currentAxis.text(int(x1), int(y1), str(count), bbox={\'facecolor\':\'white\', \'alpha\':0.5})\r\n                        count = count + 1\r\n\r\n                plt.axis(\'off\')\r\n                plt.savefig(visu_dir + image_name, dpi=300)\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    dt_dir = \'/home/mhliao/research/oriented/TextBoxes_polygon/data/data_text/icdar15_polygon_multiscale0/\'\r\n    score_det = 0.6\r\n    overlap = 0.2\r\n    zip_dir = \'/home/mhliao/research/oriented/TextBoxes_polygon/data/data_text/detection_zip/\'\r\n    pack_dir = \'/home/mhliao/research/oriented/TextBoxes_polygon/data/data_text/detection_zip/\'\r\n    result_list = \'/home/mhliao/research/oriented/TextBoxes_polygon/data/data_text/detection_zip/result.txt\'\r\n    test_single(dt_dir, score_det, overlap, zip_dir, pack_dir, result_list, vis_path=\'./visu_result/\')\r\n\r\n'"
pyicdartools/rrc_evaluation_funcs.py,0,"b'#!/usr/bin/env python2\n#encoding: UTF-8\nimport json\nimport sys;sys.path.append(\'./\')\nimport zipfile\nimport re\nimport sys\nimport os\nimport codecs\nimport importlib\n""""""\n#from StringIO import StringIO\ntry:\n    from StringIO import StringIO\nexcept ImportError:\n    from io import StringIO\n""""""\ndef print_help():\n    sys.stdout.write(\'Usage: python %s.py -g=<gtFile> -s=<submFile> -o=<outputFolder> [-i=<gtImagesFile> -p=<jsonParams>]\' %sys.argv[0])\n    sys.exit(2)\n\n\ndef load_zip_file_keys(file,fileNameRegExp=\'\'):\n    """"""\n    Returns an array with the entries of the ZIP file that match with the regular expression.\n    The key\'s are the names or the file or the capturing group definied in the fileNameRegExp\n    """"""\n    try:\n        archive=zipfile.ZipFile(file, mode=\'r\', allowZip64=True)\n    except :\n        raise Exception(\'Error loading the ZIP archive.\')\n\n    pairs = []\n\n    for name in archive.namelist():\n        addFile = True\n        keyName = name\n        if fileNameRegExp!="""":\n            m = re.match(fileNameRegExp,name)\n            if m == None:\n                addFile = False\n            else:\n                if len(m.groups())>0:\n                    keyName = m.group(1)\n\n        if addFile:\n            pairs.append( keyName )\n\n    return pairs\n\n\ndef load_zip_file(file,fileNameRegExp=\'\',allEntries=False):\n    """"""\n    Returns an array with the contents (filtered by fileNameRegExp) of a ZIP file.\n    The key\'s are the names or the file or the capturing group definied in the fileNameRegExp\n    allEntries validates that all entries in the ZIP file pass the fileNameRegExp\n    """"""\n    try:\n        archive=zipfile.ZipFile(file, mode=\'r\', allowZip64=True)\n    except :\n        raise Exception(\'Error loading the ZIP archive\')\n\n    pairs = []\n\n    for name in archive.namelist():\n        addFile = True\n        keyName = name\n        if fileNameRegExp!="""":\n            m = re.match(fileNameRegExp,name)\n            if m == None:\n                addFile = False\n            else:\n                if len(m.groups())>0:\n                    keyName = m.group(1)\n\n        if addFile:\n            pairs.append( [ keyName , archive.read(name)] )\n        else:\n            if allEntries:\n                raise Exception(\'ZIP entry not valid: %s\' %name)\n\n    return dict(pairs)\n\ndef decode_utf8(raw):\n    """"""\n    Returns a Unicode object on success, or None on failure\n    """"""\n    try:\n        raw = codecs.decode(raw,\'utf-8\', \'replace\')\n        #extracts BOM if exists\n        raw = raw.encode(\'utf8\')\n        if raw.startswith(codecs.BOM_UTF8):\n            raw = raw.replace(codecs.BOM_UTF8, \'\', 1)\n        return raw.decode(\'utf-8\')\n    except:\n       return None\n\ndef validate_lines_in_file(fileName,file_contents,CRLF=True,LTRB=True,withTranscription=False,withConfidence=False,imWidth=0,imHeight=0):\n    """"""\n    This function validates that all lines of the file calling the Line validation function for each line\n    """"""\n    utf8File = decode_utf8(file_contents)\n    if (utf8File is None) :\n        raise Exception(""The file %s is not UTF-8"" %fileName)\n\n    lines = utf8File.split( ""\\r\\n"" if CRLF else ""\\n"" )\n    for line in lines:\n        line = line.replace(""\\r"","""").replace(""\\n"","""")\n        if(line != """"):\n            try:\n                validate_tl_line(line,LTRB,withTranscription,withConfidence,imWidth,imHeight)\n            except Exception as e:\n                raise Exception((""Line in sample not valid. Sample: %s Line: %s Error: %s"" %(fileName,line,str(e))).encode(\'utf-8\', \'replace\'))\n\n\n\ndef validate_tl_line(line,LTRB=True,withTranscription=True,withConfidence=True,imWidth=0,imHeight=0):\n    """"""\n    Validate the format of the line. If the line is not valid an exception will be raised.\n    If maxWidth and maxHeight are specified, all points must be inside the imgage bounds.\n    Posible values are:\n    LTRB=True: xmin,ymin,xmax,ymax[,confidence][,transcription]\n    LTRB=False: x1,y1,x2,y2,x3,y3,x4,y4[,confidence][,transcription]\n    """"""\n    get_tl_line_values(line,LTRB,withTranscription,withConfidence,imWidth,imHeight)\n\n\ndef get_tl_line_values(line,LTRB=True,withTranscription=False,withConfidence=False,imWidth=0,imHeight=0):\n    """"""\n    Validate the format of the line. If the line is not valid an exception will be raised.\n    If maxWidth and maxHeight are specified, all points must be inside the imgage bounds.\n    Posible values are:\n    LTRB=True: xmin,ymin,xmax,ymax[,confidence][,transcription]\n    LTRB=False: x1,y1,x2,y2,x3,y3,x4,y4[,confidence][,transcription]\n    Returns values from a textline. Points , [Confidences], [Transcriptions]\n    """"""\n    confidence = 0.0\n    transcription = """";\n    points = []\n\n    numPoints = 4;\n\n    if LTRB:\n\n        numPoints = 4;\n\n        if withTranscription and withConfidence:\n            m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*([0-9]+)\\s*,\\s*([0-9]+)\\s*,\\s*([0-1].?[0-9]*)\\s*,(.*)$\',line)\n            if m == None :\n                m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*([0-9]+)\\s*,\\s*([0-9]+)\\s*,\\s*([0-1].?[0-9]*)\\s*,(.*)$\',line)\n                raise Exception(""Format incorrect. Should be: xmin,ymin,xmax,ymax,confidence,transcription"")\n        elif withConfidence:\n            m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*([0-9]+)\\s*,\\s*([0-9]+)\\s*,\\s*([0-1].?[0-9]*)\\s*$\',line)\n            if m == None :\n                raise Exception(""Format incorrect. Should be: xmin,ymin,xmax,ymax,confidence"")\n        elif withTranscription:\n            m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*([0-9]+)\\s*,\\s*([0-9]+)\\s*,(.*)$\',line)\n            if m == None :\n                raise Exception(""Format incorrect. Should be: xmin,ymin,xmax,ymax,transcription"")\n        else:\n            m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*([0-9]+)\\s*,\\s*([0-9]+)\\s*,?\\s*$\',line)\n            if m == None :\n                raise Exception(""Format incorrect. Should be: xmin,ymin,xmax,ymax"")\n\n        xmin = int(m.group(1))\n        ymin = int(m.group(2))\n        xmax = int(m.group(3))\n        ymax = int(m.group(4))\n        if(xmax<xmin):\n                raise Exception(""Xmax value (%s) not valid (Xmax < Xmin)."" %(xmax))\n        if(ymax<ymin):\n                raise Exception(""Ymax value (%s)  not valid (Ymax < Ymin)."" %(ymax))\n\n        points = [ float(m.group(i)) for i in range(1, (numPoints+1) ) ]\n\n        if (imWidth>0 and imHeight>0):\n            validate_point_inside_bounds(xmin,ymin,imWidth,imHeight);\n            validate_point_inside_bounds(xmax,ymax,imWidth,imHeight);\n\n    else:\n\n        numPoints = 8;\n\n        if withTranscription and withConfidence:\n            m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*([0-1].?[0-9]*)\\s*,(.*)$\',line)\n            if m == None :\n                raise Exception(""Format incorrect. Should be: x1,y1,x2,y2,x3,y3,x4,y4,confidence,transcription"")\n        elif withConfidence:\n            m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*([0-1].?[0-9]*)\\s*$\',line)\n            if m == None :\n                raise Exception(""Format incorrect. Should be: x1,y1,x2,y2,x3,y3,x4,y4,confidence"")\n        elif withTranscription:\n            m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,(.*)$\',line)\n            if m == None :\n                raise Exception(""Format incorrect. Should be: x1,y1,x2,y2,x3,y3,x4,y4,transcription"")\n        else:\n            m = re.match(r\'^\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*,\\s*(-?[0-9]+)\\s*$\',line)\n            if m == None :\n                raise Exception(""Format incorrect. Should be: x1,y1,x2,y2,x3,y3,x4,y4"")\n\n        points = [ float(m.group(i)) for i in range(1, (numPoints+1) ) ]\n\n        validate_clockwise_points(points)\n\n        if (imWidth>0 and imHeight>0):\n            validate_point_inside_bounds(points[0],points[1],imWidth,imHeight);\n            validate_point_inside_bounds(points[2],points[3],imWidth,imHeight);\n            validate_point_inside_bounds(points[4],points[5],imWidth,imHeight);\n            validate_point_inside_bounds(points[6],points[7],imWidth,imHeight);\n\n\n    if withConfidence:\n        try:\n            confidence = float(m.group(numPoints+1))\n        except ValueError:\n            raise Exception(""Confidence value must be a float"")\n\n    if withTranscription:\n        posTranscription = numPoints + (2 if withConfidence else 1)\n        transcription = m.group(posTranscription)\n        m2 = re.match(r\'^\\s*\\""(.*)\\""\\s*$\',transcription)\n        if m2 != None : #Transcription with double quotes, we extract the value and replace escaped characters\n            transcription = m2.group(1).replace(""\\\\\\\\"", ""\\\\"").replace(""\\\\\\"""", ""\\"""")\n\n    return points,confidence,transcription\n\n\ndef validate_point_inside_bounds(x,y,imWidth,imHeight):\n    if(x<0 or x>imWidth):\n            raise Exception(""X value (%s) not valid. Image dimensions: (%s,%s)"" %(xmin,imWidth,imHeight))\n    if(y<0 or y>imHeight):\n            raise Exception(""Y value (%s)  not valid. Image dimensions: (%s,%s) Sample: %s Line:%s"" %(ymin,imWidth,imHeight))\n\ndef validate_clockwise_points(points):\n    """"""\n    Validates that the points that the 4 points that dlimite a polygon are in clockwise order.\n    """"""\n\n    if len(points) != 8:\n        raise Exception(""Points list not valid."" + str(len(points)))\n\n    point = [\n                [int(points[0]) , int(points[1])],\n                [int(points[2]) , int(points[3])],\n                [int(points[4]) , int(points[5])],\n                [int(points[6]) , int(points[7])]\n            ]\n    edge = [\n                ( point[1][0] - point[0][0])*( point[1][1] + point[0][1]),\n                ( point[2][0] - point[1][0])*( point[2][1] + point[1][1]),\n                ( point[3][0] - point[2][0])*( point[3][1] + point[2][1]),\n                ( point[0][0] - point[3][0])*( point[0][1] + point[3][1])\n    ]\n\n    summatory = edge[0] + edge[1] + edge[2] + edge[3];\n    if summatory>0:\n        raise Exception(""Points are not clockwise. The coordinates of bounding quadrilaterals have to be given in clockwise order. Regarding the correct interpretation of \'clockwise\' remember that the image coordinate system used is the standard one, with the image origin at the upper left, the X axis extending to the right and Y axis extending downwards."")\n\ndef get_tl_line_values_from_file_contents(content,CRLF=True,LTRB=True,withTranscription=False,withConfidence=False,imWidth=0,imHeight=0,sort_by_confidences=True):\n    """"""\n    Returns all points, confindences and transcriptions of a file in lists. Valid line formats:\n    xmin,ymin,xmax,ymax,[confidence],[transcription]\n    x1,y1,x2,y2,x3,y3,x4,y4,[confidence],[transcription]\n    """"""\n    pointsList = []\n    transcriptionsList = []\n    confidencesList = []\n\n    lines = content.split( ""\\r\\n"" if CRLF else ""\\n"" )\n    for line in lines:\n        line = line.replace(""\\r"","""").replace(""\\n"","""")\n        if(line != """") :\n            points, confidence, transcription = get_tl_line_values(line,LTRB,withTranscription,withConfidence,imWidth,imHeight);\n            pointsList.append(points)\n            transcriptionsList.append(transcription)\n            confidencesList.append(confidence)\n\n    if withConfidence and len(confidencesList)>0 and sort_by_confidences:\n        confidencesList, pointsList,transcriptionsList = (list(t) for t in zip(*sorted(zip(confidencesList, pointsList, transcriptionsList), reverse=True)))\n\n    return pointsList,confidencesList,transcriptionsList\n\ndef main_evaluation(p,default_evaluation_params_fn,validate_data_fn,evaluate_method_fn,show_result=True,per_sample=True):\n    """"""\n    This process validates a method, evaluates it and if it succed generates a ZIP file with a JSON entry for each sample.\n    Params:\n    p: Dictionary of parmeters with the GT/submission locations. If None is passed, the parameters send by the system are used.\n    default_evaluation_params_fn: points to a function that returns a dictionary with the default parameters used for the evaluation\n    validate_data_fn: points to a method that validates the corrct format of the submission\n    evaluate_method_fn: points to a function that evaluated the submission and return a Dictionary with the results\n    """"""\n    # check path\n    gt_path = p[\'g\']\n    submit_path = p[\'s\']\n    output = p[\'o\']\n    #print(\'gt\', gt_path)\n    #print(\'submit\', submit_path)\n    #print(\'output\', output)\n    if (p == None):\n        p = dict([s[1:].split(\'=\') for s in sys.argv[1:]])\n        if(len(sys.argv)<2):\n            print_help()\n\n    evalParams = default_evaluation_params_fn()\n    if \'p\' in p.keys():\n        evalParams.update( p[\'p\'] if isinstance(p[\'p\'], dict) else json.loads(p[\'p\'][1:-1]) )\n\n    resDict={\'calculated\':True,\'Message\':\'\',\'method\':\'{}\',\'per_sample\':\'{}\'}\n    try:\n        validate_data_fn(p[\'g\'], p[\'s\'], evalParams)\n        evalData = evaluate_method_fn(p[\'g\'], p[\'s\'], evalParams)\n        resDict.update(evalData)\n    except Exception as e:\n        resDict[\'Message\']= str(e)\n        resDict[\'calculated\']=False\n        #print(\'gt\',p[\'g\']) # addres of gt\n        #print(\'sub\',p[\'s\'])\n\n    if not os.path.exists(p[\'o\']):\n        os.makedirs(p[\'o\'])\n\n    resultsOutputname = p[\'o\'] + \'/results.zip\'\n    outZip = zipfile.ZipFile(resultsOutputname, mode=\'w\', allowZip64=True)\n\n    del resDict[\'per_sample\']\n    if \'output_items\' in resDict.keys():\n        del resDict[\'output_items\']\n\n    outZip.writestr(\'method.json\',json.dumps(resDict))\n\n    if not resDict[\'calculated\']:\n        if show_result:\n\n            sys.stderr.write(\'Error!\\n\'+ resDict[\'Message\']+\'\\n\\n\')\n        outZip.close()\n        return resDict\n\n    if per_sample == True:\n        for k,v in evalData[\'per_sample\'].items():\n            outZip.writestr( k + \'.json\',json.dumps(v))\n\n        if \'output_items\' in evalData.keys():\n            for k, v in evalData[\'output_items\'].iteritems():\n                outZip.writestr( k,v)\n\n    outZip.close()\n\n    if show_result:\n        sys.stdout.write(""Calculated!"")\n        sys.stdout.write(json.dumps(resDict[\'method\']))\n\n    return resDict\n\n\ndef main_validation(default_evaluation_params_fn,validate_data_fn):\n    """"""\n    This process validates a method\n    Params:\n    default_evaluation_params_fn: points to a function that returns a dictionary with the default parameters used for the evaluation\n    validate_data_fn: points to a method that validates the corrct format of the submission\n    """"""\n    try:\n        p = dict([s[1:].split(\'=\') for s in sys.argv[1:]])\n        evalParams = default_evaluation_params_fn()\n        if \'p\' in p.keys():\n            evalParams.update( p[\'p\'] if isinstance(p[\'p\'], dict) else json.loads(p[\'p\'][1:-1]) )\n\n        validate_data_fn(p[\'g\'], p[\'s\'], evalParams)\n        print(\'SUCCESS\')\n        sys.exit(0)\n    except Exception as e:\n        print(str(e))\n        sys.exit(101)'"
utils/init.py,1,"b'from torch.nn import init\r\ndef init_net(net, init_type=\'normal\'):\r\n    init_weights(net, init_type)\r\n    return net\r\n\r\ndef init_weights(net, init_type=\'normal\', gain=0.02):\r\n    def init_func(m):\r\n        # this will apply to each layer\r\n        classname = m.__class__.__name__\r\n        if hasattr(m, \'weight\') and (classname.find(\'conv\')!=-1 or classname.find(\'Linear\')!=-1):\r\n            if init_type==\'normal\':\r\n                init.normal_(m.weight.data, 0.0, gain)\r\n            elif init_type == \'xavier\':\r\n                init.xavier_normal_(m.weight.data, gain=gain)\r\n            elif init_type == \'kaiming\':\r\n                init.kaiming_normal_(m.weight.data, a=0, mode=\'fan_in\')#good for relu\r\n            elif init_type == \'orthogonal\':\r\n                init.orthogonal_(m.weight.data, gain=gain)\r\n            else:\r\n                raise NotImplementedError(\'initialization method [%s] is not implemented\' % init_type)\r\n            \r\n            if hasattr(m, \'bias\') and m.bias is not None:\r\n                init.constant_(m.bias.data, 0.0)\r\n        elif classname.find(\'BatchNorm2d\') != -1:\r\n            init.normal_(m.weight.data, 1.0, gain)\r\n            init.constant_(m.bias.data, 0.0)\r\n    print(""EAST <==> Prepare <==> Init Network\'{}\' <==> Begin"".format(init_type))\r\n\r\n    net.apply(init_func)'"
utils/myzip.py,0,"b""import os\nimport sys\ndef MyZip(out_txt_dir, epoch):\n\tprint('ZIP :get out_txt_dir {}'.format(out_txt_dir))\n\t#out_txt_dir : /home/djsong/update/result/epoch_0_gt\n\tassert os.path.isdir(out_txt_dir), 'Res_txt dir is not exit'\n\n\tprint('EAST <==> Evaluation <==> Into out_txt_dir:{} <==> Begin'.format(out_txt_dir))\n\ttry:\n\t\tos.chdir(out_txt_dir)\n\n\t\tos.system('zip -r submit-{}.zip ./*.txt'.format(epoch))\n\n\t\tos.system('cp submit-{}.zip ../submit.zip'.format(epoch))\n\n\t\tos.chdir('../../')\n\n\t\n\texcept:\n\t\tsys.exit('ZIP ERROR')\n\n\tprint('EAST <==> Evaluation <==> Into out_txt_dir:{} <==> Done'.format(out_txt_dir))\n\tworkspace = os.path.abspath('./result')\n\n\tsubmit_path = os.path.join(workspace, 'submit.zip')\n\n\treturn submit_path\n\n\n\n\n\n\n\n"""
utils/save.py,1,"b'import torch\r\nimport os\r\nimport shutil\r\nimport datetime\r\nfrom utils.util import *\r\n# this is for weight\r\ndef save_checkpoint(state, epoch, filename=\'checkpoint.pth.tar\'):\r\n    """"""[summary]\r\n\r\n    [description]\r\n\r\n    Arguments:\r\n        state {[type]} -- [description] a dict describe some params\r\n        is_best {bool} -- [description] a bool value\r\n\r\n    Keyword Arguments:\r\n        filename {str} -- [description] (default: {\'checkpoint.pth.tar\'})\r\n    """"""\r\n    print(\'EAST <==> Save weight - epoch {} <==> Begin\'.format(epoch))\r\n    root_dir = os.path.abspath(\'./\')\r\n    weight_dir = os.path.join(root_dir, \'weight\')\r\n\r\n    if not os.path.exists(weight_dir):\r\n        os.mkdir(weight_dir)\r\n\r\n    filename = \'epoch_\'+str(epoch)+\'_checkpoint.pth.tar\'\r\n    file_path = os.path.join(weight_dir, filename)\r\n    torch.save(state, file_path)\r\n\r\n    if state[\'is_best\']:\r\n        src = file_path\r\n        dst = os.path.join(weight_dir, \'best_model.pth.tar\')\r\n        shutil.copyfile(src, dst)\r\n    print(\'EAST <==> Save weight - epoch {} <==> Done\'.format(epoch))\r\n\r\ndef save_loss_info(losses, epoch, current_batch, loader, path=\'./log.txt\'):\r\n    default_path = os.path.abspath(path)\r\n\r\n    dir_path = os.path.dirname(default_path)\r\n\r\n    log_loss_path = os.path.join(dir_path, \'result\', \'log_loss.txt\')\r\n    \r\n    if not os.path.isfile(log_loss_path):\r\n        os.mknod(log_loss_path)\r\n\r\n    with open(path, \'a\') as f:\r\n        line = \'Epoch: [{0}][{1}/{2}]\\t Loss {loss.val:.4f} ({loss.avg:.4f})\\n\'.format(epoch,current_batch, len(loader), loss = losses)\r\n        f.write(line)\r\n\r\n\r\n\r\n\r\n\r\n'"
utils/util.py,0,"b'class AverageMeter(object):\r\n    """"""Computes and stores the average and current value""""""\r\n    def __init__(self):\r\n        self.reset()\r\n\r\n    def reset(self):\r\n        self.val = 0\r\n        self.avg = 0\r\n        self.sum = 0\r\n        self.count = 0\r\n\r\n    def update(self, val, n=1):\r\n        self.val = val\r\n        self.sum += val * n\r\n        self.count += n\r\n        self.avg = self.sum / self.count'"
