file_path,api_count,code
download_data.py,0,"b'""""""\nDownload all the data that is needed for the tutorial\nso we don\'t crash the conference network.\n\n""""""\nfrom pathlib import Path\n\nfrom torchvision import models\nfrom torchvision.datasets import MNIST, CIFAR10\n\nfrom notebooks import my_datasets\nfrom notebooks.utils import ptitle\n\n\nif __name__ == ""__main__"":\n    ROOT = Path(""data/raw"")\n    ROOT.mkdir(parents=True, exist_ok=True)\n\n    ptitle(""Downloading DogsCatsDataset"")\n    _ds = my_datasets.DogsCatsDataset(ROOT, ""train"", download=True)\n\n    print()\n    ptitle(""Downloading MNIST"")\n    _ds = MNIST(ROOT, train=True, download=True)\n    _ds = MNIST(ROOT, train=False, download=True)\n\n    print()\n    ptitle(""Downloading CIFAR10"")\n    _ds = CIFAR10(ROOT, train=True, download=True)\n    _ds = CIFAR10(ROOT, train=False, download=True)\n\n    print()\n    ptitle(""Downloading models"")\n    _model = models.resnet18(pretrained=True)\n    _model = models.squeezenet1_1(pretrained=True)\n'"
notebooks/my_datasets.py,0,"b'import os\nimport zipfile\n\nfrom torchvision.datasets.folder import ImageFolder, default_loader\nfrom torchvision.datasets.utils import download_url, check_integrity\n\n\n################################################################################\n# PyTorch\nclass DogsCatsDataset(ImageFolder):\n    """"""\n    The \'Dogs and Cats\' dataset from kaggle.\n\n    https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/\n\n    Args:\n        root: the location where to store the dataset\n        suffix: path to the train/valid/sample dataset. See folder structure.\n        transform (callable, optional): A function/transform that takes in\n            an PIL image and returns a transformed version.\n            E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that\n            takes in the target and transforms it.\n        loader: A function to load an image given its path.\n        download: if ``True``, download the data.\n\n\n    The folder structure of the dataset is as follows::\n\n        \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 dogscats\n            \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 sample\n            \xe2\x94\x82   \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 train\n            \xe2\x94\x82   \xe2\x94\x82   \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 cats\n            \xe2\x94\x82   \xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 dogs\n            \xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 valid\n            \xe2\x94\x82       \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 cats\n            \xe2\x94\x82       \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 dogs\n            \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 train\n            \xe2\x94\x82   \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 cats\n            \xe2\x94\x82   \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 dogs\n            \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 valid\n                \xe2\x94\x9c\xe2\x94\x80\xe2\x94\x80 cats\n                \xe2\x94\x94\xe2\x94\x80\xe2\x94\x80 dogs\n\n    """"""\n\n    url = ""http://files.fast.ai/data/dogscats.zip""\n    filename = ""dogscats.zip""\n    checksum = ""aef22ec7d472dd60e8ee79eecc19f131""\n\n    def __init__(\n        self,\n        root: str,\n        suffix: str,\n        transform=None,\n        target_transform=None,\n        loader=default_loader,\n        download=False,\n    ):\n        self.root = os.path.expanduser(root)\n\n        if download:\n            self._download()\n            self._extract()\n\n        if not self._check_integrity():\n            raise RuntimeError(\n                ""Dataset not found or corrupted. ""\n                ""You can use download=True to download it""\n            )\n\n        path = os.path.join(self.root, ""dogscats"", suffix)\n        print(f""Loading data from {path}."")\n        assert os.path.isdir(path), f""\'{suffix}\' is not valid.""\n\n        super().__init__(path, transform, target_transform, loader)\n\n    def _download(self):\n        if self._check_integrity():\n            print(""Dataset already downloaded and verified."")\n            return\n\n        root = self.root\n        print(""Downloading dataset... (this might take a while)"")\n        download_url(self.url, root, self.filename, self.checksum)\n\n    def _extract(self):\n        path_to_zip = os.path.join(self.root, self.filename)\n        with zipfile.ZipFile(path_to_zip, ""r"") as zip_ref:\n            zip_ref.extractall(self.root)\n\n    def _check_integrity(self):\n        path_to_zip = os.path.join(self.root, self.filename)\n        return check_integrity(path_to_zip, self.checksum)\n'"
notebooks/my_train_helper.py,0,b'def get_trainable(model_params):\n    return (p for p in model_params if p.requires_grad)\n\n\ndef get_frozen(model_params):\n    return (p for p in model_params if not p.requires_grad)\n\n\ndef all_trainable(model_params):\n    return all(p.requires_grad for p in model_params)\n\n\ndef all_frozen(model_params):\n    return all(not p.requires_grad for p in model_params)\n\n\ndef freeze_all(model_params):\n    for param in model_params:\n        param.requires_grad = False\n'
notebooks/utils.py,2,"b'import os\nimport zipfile\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision import models\nfrom torchvision.datasets.folder import ImageFolder, default_loader\nfrom torchvision.datasets.utils import download_url, check_integrity\nfrom my_datasets import DogsCatsDataset\n\n\n################################################################################\nDEVICE = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")\n\n\n################################################################################\n# Helpers\ndef attr(obj):\n    """"""\n    Return all public attributes of an object.\n    """"""\n    return [x for x in dir(obj) if not x.startswith(""_"")]\n\n\ndef ptitle(title):\n    print(""#"" * 80)\n    print(f""# {title}"")\n\n\n\n################################################################################\n# DOGS AND CATS DEMO\n\ndef get_model(n_classes=2):\n    model = models.resnet18(pretrained=True)\n    # Freeze all\n    for param in model.parameters():\n        param.requires_grad = False\n    model.fc = nn.Linear(512, n_classes)\n    model = model.to(DEVICE)\n    return model\n\n\ndef get_data():\n    _image_size = 224\n    _mean, _std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n    train_trans = transforms.Compose([\n        transforms.Resize(256),  # some images are pretty small\n        transforms.RandomCrop(_image_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(.3, .3, .3),\n        transforms.ToTensor(),\n        transforms.Normalize(_mean, _std),\n    ])\n    val_trans = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(_image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(_mean, _std),\n    ])\n\n    train_ds = DogsCatsDataset(""../data/raw"", ""sample/train"", transform=train_trans)\n    val_ds = DogsCatsDataset(""../data/raw"", ""sample/valid"", transform=val_trans)\n\n    batch_size = 2\n    train_dl = DataLoader(\n        train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=4,\n    )\n    val_dl = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=4,\n    )\n    return train_dl, val_dl\n'"
