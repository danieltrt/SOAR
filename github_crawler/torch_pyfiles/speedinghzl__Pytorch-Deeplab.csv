file_path,api_count,code
evaluate.py,5,"b'import argparse\nimport scipy\nfrom scipy import ndimage\nimport cv2\nimport numpy as np\nimport sys\n\nimport torch\nfrom torch.autograd import Variable\nimport torchvision.models as models\nimport torch.nn.functional as F\nfrom torch.utils import data\nfrom deeplab.model import Res_Deeplab\nfrom deeplab.datasets import VOCDataSet\nfrom collections import OrderedDict\nimport os\n\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nDATA_DIRECTORY = \'../../data/VOCdevkit/voc12\'\nDATA_LIST_PATH = \'./dataset/list/val.txt\'\nIGNORE_LABEL = 255\nNUM_CLASSES = 21\nNUM_STEPS = 1449 # Number of images in the validation set.\nRESTORE_FROM = \'./deeplab_resnet.ckpt\'\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLabLFOV Network"")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    parser.add_argument(""--gpu"", type=int, default=0,\n                        help=""choose gpu device."")\n    return parser.parse_args()\n\n\ndef get_iou(data_list, class_num, save_path=None):\n    from multiprocessing import Pool \n    from deeplab.metric import ConfusionMatrix\n\n    ConfM = ConfusionMatrix(class_num)\n    f = ConfM.generateM\n    pool = Pool() \n    m_list = pool.map(f, data_list)\n    pool.close() \n    pool.join() \n    \n    for m in m_list:\n        ConfM.addM(m)\n\n    aveJ, j_list, M = ConfM.jaccard()\n    print(\'meanIOU: \' + str(aveJ) + \'\\n\')\n    if save_path:\n        with open(save_path, \'w\') as f:\n            f.write(\'meanIOU: \' + str(aveJ) + \'\\n\')\n            f.write(str(j_list)+\'\\n\')\n            f.write(str(M)+\'\\n\')\n\ndef show_all(gt, pred):\n    import matplotlib.pyplot as plt\n    from matplotlib import colors\n    from mpl_toolkits.axes_grid1 import make_axes_locatable\n\n    fig, axes = plt.subplots(1, 2)\n    ax1, ax2 = axes\n\n    classes = np.array((\'background\',  # always index 0\n               \'aeroplane\', \'bicycle\', \'bird\', \'boat\',\n               \'bottle\', \'bus\', \'car\', \'cat\', \'chair\',\n                         \'cow\', \'diningtable\', \'dog\', \'horse\',\n                         \'motorbike\', \'person\', \'pottedplant\',\n                         \'sheep\', \'sofa\', \'train\', \'tvmonitor\'))\n    colormap = [(0,0,0),(0.5,0,0),(0,0.5,0),(0.5,0.5,0),(0,0,0.5),(0.5,0,0.5),(0,0.5,0.5), \n                    (0.5,0.5,0.5),(0.25,0,0),(0.75,0,0),(0.25,0.5,0),(0.75,0.5,0),(0.25,0,0.5), \n                    (0.75,0,0.5),(0.25,0.5,0.5),(0.75,0.5,0.5),(0,0.25,0),(0.5,0.25,0),(0,0.75,0), \n                    (0.5,0.75,0),(0,0.25,0.5)]\n    cmap = colors.ListedColormap(colormap)\n    bounds=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n    norm = colors.BoundaryNorm(bounds, cmap.N)\n\n    ax1.set_title(\'gt\')\n    ax1.imshow(gt, cmap=cmap, norm=norm)\n\n    ax2.set_title(\'pred\')\n    ax2.imshow(pred, cmap=cmap, norm=norm)\n\n    plt.show()\n\ndef main():\n    """"""Create the model and start the evaluation process.""""""\n    args = get_arguments()\n\n    gpu0 = args.gpu\n\n    model = Res_Deeplab(num_classes=args.num_classes)\n    \n    saved_state_dict = torch.load(args.restore_from)\n    model.load_state_dict(saved_state_dict)\n\n    model.eval()\n    model.cuda(gpu0)\n\n    testloader = data.DataLoader(VOCDataSet(args.data_dir, args.data_list, crop_size=(505, 505), mean=IMG_MEAN, scale=False, mirror=False), \n                                    batch_size=1, shuffle=False, pin_memory=True)\n\n    interp = nn.Upsample(size=(505, 505), mode=\'bilinear\', align_corners=True)\n    data_list = []\n\n    for index, batch in enumerate(testloader):\n        if index % 100 == 0:\n            print(\'%d processd\'%(index))\n        image, label, size, name = batch\n        size = size[0].numpy()\n        output = model(Variable(image, volatile=True).cuda(gpu0))\n        output = interp(output).cpu().data[0].numpy()\n\n        output = output[:,:size[0],:size[1]]\n        gt = np.asarray(label[0].numpy()[:size[0],:size[1]], dtype=np.int)\n        \n        output = output.transpose(1,2,0)\n        output = np.asarray(np.argmax(output, axis=2), dtype=np.int)\n\n        # show_all(gt, output)\n        data_list.append([gt.flatten(), output.flatten()])\n\n    get_iou(data_list, args.num_classes)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
evaluate_msc.py,6,"b'import argparse\nimport scipy\nfrom scipy import ndimage\nimport cv2\nimport numpy as np\nimport sys\n\nimport torch\nfrom torch.autograd import Variable\nimport torchvision.models as models\nimport torch.nn.functional as F\nfrom torch.utils import data\nfrom deeplab.model import Res_Deeplab\nfrom deeplab.datasets import VOCDataSet\nfrom collections import OrderedDict\nimport os\n\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nDATA_DIRECTORY = \'../data/VOCdevkit/voc12\'\nDATA_LIST_PATH = \'./dataset/list/val.txt\'\nIGNORE_LABEL = 255\nNUM_CLASSES = 21\nNUM_STEPS = 1449 # Number of images in the validation set.\nRESTORE_FROM = \'./deeplab_resnet.ckpt\'\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLabLFOV Network"")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    parser.add_argument(""--gpu"", type=int, default=0,\n                        help=""choose gpu device."")\n    return parser.parse_args()\n\n\ndef get_iou(data_list, class_num, save_path=None):\n    from multiprocessing import Pool \n    from deeplab.metric import ConfusionMatrix\n\n    ConfM = ConfusionMatrix(class_num)\n    f = ConfM.generateM\n    pool = Pool() \n    m_list = pool.map(f, data_list)\n    pool.close() \n    pool.join() \n    \n    for m in m_list:\n        ConfM.addM(m)\n\n    aveJ, j_list, M = ConfM.jaccard()\n    print(\'meanIOU: \' + str(aveJ) + \'\\n\')\n    if save_path:\n        with open(save_path, \'w\') as f:\n            f.write(\'meanIOU: \' + str(aveJ) + \'\\n\')\n            f.write(str(j_list)+\'\\n\')\n            f.write(str(M)+\'\\n\')\n\ndef show_all(gt, pred):\n    import matplotlib.pyplot as plt\n    from matplotlib import colors\n    from mpl_toolkits.axes_grid1 import make_axes_locatable\n\n    fig, axes = plt.subplots(1, 2)\n    ax1, ax2 = axes\n\n    classes = np.array((\'background\',  # always index 0\n               \'aeroplane\', \'bicycle\', \'bird\', \'boat\',\n               \'bottle\', \'bus\', \'car\', \'cat\', \'chair\',\n                         \'cow\', \'diningtable\', \'dog\', \'horse\',\n                         \'motorbike\', \'person\', \'pottedplant\',\n                         \'sheep\', \'sofa\', \'train\', \'tvmonitor\'))\n    colormap = [(0,0,0),(0.5,0,0),(0,0.5,0),(0.5,0.5,0),(0,0,0.5),(0.5,0,0.5),(0,0.5,0.5), \n                    (0.5,0.5,0.5),(0.25,0,0),(0.75,0,0),(0.25,0.5,0),(0.75,0.5,0),(0.25,0,0.5), \n                    (0.75,0,0.5),(0.25,0.5,0.5),(0.75,0.5,0.5),(0,0.25,0),(0.5,0.25,0),(0,0.75,0), \n                    (0.5,0.75,0),(0,0.25,0.5)]\n    cmap = colors.ListedColormap(colormap)\n    bounds=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n    norm = colors.BoundaryNorm(bounds, cmap.N)\n\n    ax1.set_title(\'gt\')\n    ax1.imshow(gt, cmap=cmap, norm=norm)\n\n    ax2.set_title(\'pred\')\n    ax2.imshow(pred, cmap=cmap, norm=norm)\n\n    plt.show()\n\ndef main():\n    """"""Create the model and start the evaluation process.""""""\n    args = get_arguments()\n\n    gpu0 = args.gpu\n\n    model = Res_Deeplab(num_classes=args.num_classes)\n    \n    saved_state_dict = torch.load(args.restore_from)\n    model.load_state_dict(saved_state_dict)\n\n    model.eval()\n    model.cuda(gpu0)\n\n    testloader = data.DataLoader(VOCDataSet(args.data_dir, args.data_list, crop_size=(505, 505), mean=IMG_MEAN, scale=False, mirror=False), \n                                    batch_size=1, shuffle=False, pin_memory=True)\n\n    interp = nn.Upsample(size=(505, 505), mode=\'bilinear\')\n    data_list = []\n\n    for index, batch in enumerate(testloader):\n        if index % 100 == 0:\n            print(\'%d processd\'%(index))\n        images, label, size, name = batch\n        images = Variable(images, volatile=True)\n        h, w, c = size[0].numpy()\n        images075 = nn.Upsample(size=(int(h*0.75), int(w*0.75)), mode=\'bilinear\')(images)\n        images05 = nn.Upsample(size=(int(h*0.5), int(w*0.5)), mode=\'bilinear\')(images)\n\n        out100 = model(images.cuda(args.gpu))\n        out075 = model(images075.cuda(args.gpu))\n        out05 = model(images05.cuda(args.gpu))\n        o_h, o_w = out100.size()[2:]\n        interpo1 = nn.Upsample(size=(o_h, o_w), mode=\'bilinear\')\n        out_max = torch.max(torch.stack([out100, interpo1(out075), interpo1(out05)]), dim=0)[0]\n\n        output = interp(out_max).cpu().data[0].numpy()\n\n        output = output[:,:h,:w]\n        output = output.transpose(1,2,0)\n        output = np.asarray(np.argmax(output, axis=2), dtype=np.int)\n\n        gt = np.asarray(label[0].numpy()[:h,:w], dtype=np.int)\n\n        # show_all(gt, output)\n        data_list.append([gt.flatten(), output.flatten()])\n\n    get_iou(data_list, args.num_classes)\n\n\nif __name__ == \'__main__\':\n    main()'"
train.py,9,"b'import argparse\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils import data\nimport numpy as np\nimport pickle\nimport cv2\nfrom torch.autograd import Variable\nimport torch.optim as optim\nimport scipy.misc\nimport torch.backends.cudnn as cudnn\nimport sys\nimport os\nimport os.path as osp\nfrom deeplab.model import Res_Deeplab\nfrom deeplab.loss import CrossEntropy2d\nfrom deeplab.datasets import VOCDataSet\nimport matplotlib.pyplot as plt\nimport random\nimport timeit\nstart = timeit.default_timer()\n\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nBATCH_SIZE = 10\nDATA_DIRECTORY = \'../../data/VOCdevkit/voc12\'\nDATA_LIST_PATH = \'./dataset/list/train_aug.txt\'\nIGNORE_LABEL = 255\nINPUT_SIZE = \'321,321\'\nLEARNING_RATE = 2.5e-4\nMOMENTUM = 0.9\nNUM_CLASSES = 21\nNUM_STEPS = 20000\nPOWER = 0.9\nRANDOM_SEED = 1234\nRESTORE_FROM = \'./dataset/MS_DeepLab_resnet_pretrained_COCO_init.pth\'\nSAVE_NUM_IMAGES = 2\nSAVE_PRED_EVERY = 1000\nSNAPSHOT_DIR = \'./snapshots/\'\nWEIGHT_DECAY = 0.0005\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLab-ResNet Network"")\n    parser.add_argument(""--batch-size"", type=int, default=BATCH_SIZE,\n                        help=""Number of images sent to the network in one step."")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--input-size"", type=str, default=INPUT_SIZE,\n                        help=""Comma-separated string with height and width of images."")\n    parser.add_argument(""--is-training"", action=""store_true"",\n                        help=""Whether to updates the running means and variances during the training."")\n    parser.add_argument(""--learning-rate"", type=float, default=LEARNING_RATE,\n                        help=""Base learning rate for training with polynomial decay."")\n    parser.add_argument(""--momentum"", type=float, default=MOMENTUM,\n                        help=""Momentum component of the optimiser."")\n    parser.add_argument(""--not-restore-last"", action=""store_true"",\n                        help=""Whether to not restore last (FC) layers."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--num-steps"", type=int, default=NUM_STEPS,\n                        help=""Number of training steps."")\n    parser.add_argument(""--power"", type=float, default=POWER,\n                        help=""Decay parameter to compute the learning rate."")\n    parser.add_argument(""--random-mirror"", action=""store_true"",\n                        help=""Whether to randomly mirror the inputs during the training."")\n    parser.add_argument(""--random-scale"", action=""store_true"",\n                        help=""Whether to randomly scale the inputs during the training."")\n    parser.add_argument(""--random-seed"", type=int, default=RANDOM_SEED,\n                        help=""Random seed to have reproducible results."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    parser.add_argument(""--save-num-images"", type=int, default=SAVE_NUM_IMAGES,\n                        help=""How many images to save."")\n    parser.add_argument(""--save-pred-every"", type=int, default=SAVE_PRED_EVERY,\n                        help=""Save summaries and checkpoint every often."")\n    parser.add_argument(""--snapshot-dir"", type=str, default=SNAPSHOT_DIR,\n                        help=""Where to save snapshots of the model."")\n    parser.add_argument(""--weight-decay"", type=float, default=WEIGHT_DECAY,\n                        help=""Regularisation parameter for L2-loss."")\n    parser.add_argument(""--gpu"", type=int, default=0,\n                        help=""choose gpu device."")\n    return parser.parse_args()\n\nargs = get_arguments()\n\ndef loss_calc(pred, label):\n    """"""\n    This function returns cross entropy loss for semantic segmentation\n    """"""\n    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n    label = Variable(label.long()).cuda()\n    criterion = torch.nn.CrossEntropyLoss(ignore_index=IGNORE_LABEL).cuda()\n    \n    return criterion(pred, label)\n\n\ndef lr_poly(base_lr, iter, max_iter, power):\n    return base_lr*((1-float(iter)/max_iter)**(power))\n\n\ndef get_1x_lr_params_NOscale(model):\n    """"""\n    This generator returns all the parameters of the net except for \n    the last classification layer. Note that for each batchnorm layer, \n    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return \n    any batchnorm parameter\n    """"""\n    b = []\n\n    b.append(model.conv1)\n    b.append(model.bn1)\n    b.append(model.layer1)\n    b.append(model.layer2)\n    b.append(model.layer3)\n    b.append(model.layer4)\n\n    \n    for i in range(len(b)):\n        for j in b[i].modules():\n            jj = 0\n            for k in j.parameters():\n                jj+=1\n                if k.requires_grad:\n                    yield k\n\ndef get_10x_lr_params(model):\n    """"""\n    This generator returns all the parameters for the last layer of the net,\n    which does the classification of pixel into classes\n    """"""\n    b = []\n    b.append(model.layer5.parameters())\n\n    for j in range(len(b)):\n        for i in b[j]:\n            yield i\n            \n            \ndef adjust_learning_rate(optimizer, i_iter):\n    """"""Sets the learning rate to the initial LR divided by 5 at 60th, 120th and 160th epochs""""""\n    lr = lr_poly(args.learning_rate, i_iter, args.num_steps, args.power)\n    optimizer.param_groups[0][\'lr\'] = lr\n    optimizer.param_groups[1][\'lr\'] = lr * 10\n\n\ndef main():\n    """"""Create the model and start the training.""""""\n    \n    os.environ[""CUDA_VISIBLE_DEVICES""]=str(args.gpu)\n    h, w = map(int, args.input_size.split(\',\'))\n    input_size = (h, w)\n\n    cudnn.enabled = True\n\n    # Create network.\n    model = Res_Deeplab(num_classes=args.num_classes)\n    # For a small batch size, it is better to keep \n    # the statistics of the BN layers (running means and variances)\n    # frozen, and to not update the values provided by the pre-trained model. \n    # If is_training=True, the statistics will be updated during the training.\n    # Note that is_training=False still updates BN parameters gamma (scale) and beta (offset)\n    # if they are presented in var_list of the optimiser definition.\n\n    saved_state_dict = torch.load(args.restore_from)\n    new_params = model.state_dict().copy()\n    for i in saved_state_dict:\n        #Scale.layer5.conv2d_list.3.weight\n        i_parts = i.split(\'.\')\n        # print i_parts\n        if not args.num_classes == 21 or not i_parts[1]==\'layer5\':\n            new_params[\'.\'.join(i_parts[1:])] = saved_state_dict[i]\n    model.load_state_dict(new_params)\n    #model.float()\n    #model.eval() # use_global_stats = True\n    model.train()\n    model.cuda()\n    \n    cudnn.benchmark = True\n\n    if not os.path.exists(args.snapshot_dir):\n        os.makedirs(args.snapshot_dir)\n\n\n    trainloader = data.DataLoader(VOCDataSet(args.data_dir, args.data_list, max_iters=args.num_steps*args.batch_size, crop_size=input_size, \n                    scale=args.random_scale, mirror=args.random_mirror, mean=IMG_MEAN), \n                    batch_size=args.batch_size, shuffle=True, num_workers=5, pin_memory=True)\n\n    optimizer = optim.SGD([{\'params\': get_1x_lr_params_NOscale(model), \'lr\': args.learning_rate }, \n                {\'params\': get_10x_lr_params(model), \'lr\': 10*args.learning_rate}], \n                lr=args.learning_rate, momentum=args.momentum,weight_decay=args.weight_decay)\n    optimizer.zero_grad()\n\n    interp = nn.Upsample(size=input_size, mode=\'bilinear\', align_corners=True)\n\n\n    for i_iter, batch in enumerate(trainloader):\n        images, labels, _, _ = batch\n        images = Variable(images).cuda()\n\n        optimizer.zero_grad()\n        adjust_learning_rate(optimizer, i_iter)\n        pred = interp(model(images))\n        loss = loss_calc(pred, labels)\n        loss.backward()\n        optimizer.step()\n\n        \n        print \'iter = \', i_iter, \'of\', args.num_steps,\'completed, loss = \', loss.data.cpu().numpy()\n\n        if i_iter >= args.num_steps-1:\n            print \'save model ...\'\n            torch.save(model.state_dict(),osp.join(args.snapshot_dir, \'VOC12_scenes_\'+str(args.num_steps)+\'.pth\'))\n            break\n\n        if i_iter % args.save_pred_every == 0 and i_iter!=0:\n            print \'taking snapshot ...\'\n            torch.save(model.state_dict(),osp.join(args.snapshot_dir, \'VOC12_scenes_\'+str(i_iter)+\'.pth\'))     \n\n    end = timeit.default_timer()\n    print end-start,\'seconds\'\n\nif __name__ == \'__main__\':\n    main()\n'"
train_msc.py,10,"b'import argparse\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils import data\nimport numpy as np\nimport pickle\nimport cv2\nfrom torch.autograd import Variable\nimport torch.optim as optim\nimport scipy.misc\nimport torch.backends.cudnn as cudnn\nimport sys\nimport os\nimport os.path as osp\nimport scipy.ndimage as nd\nfrom deeplab.model import Res_Deeplab\nfrom deeplab.loss import CrossEntropy2d\nfrom deeplab.datasets import VOCDataSet\nimport matplotlib.pyplot as plt\nimport random\nimport timeit\nstart = timeit.timeit()\n\nIMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n\nBATCH_SIZE = 1\nDATA_DIRECTORY = \'../data/VOCdevkit/voc12\'\nDATA_LIST_PATH = \'./dataset/list/train_aug.txt\'\nITER_SIZE = 10\nIGNORE_LABEL = 255\nINPUT_SIZE = \'321,321\'\nLEARNING_RATE = 2.5e-4\nMOMENTUM = 0.9\nNUM_CLASSES = 21\nNUM_STEPS = 20000\nPOWER = 0.9\nRANDOM_SEED = 1234\nRESTORE_FROM = \'./dataset/MS_DeepLab_resnet_pretrained_COCO_init.pth\'\nSAVE_NUM_IMAGES = 2\nSAVE_PRED_EVERY = 1000\nSNAPSHOT_DIR = \'./snapshots_msc/\'\nWEIGHT_DECAY = 0.0005\n\ndef get_arguments():\n    """"""Parse all the arguments provided from the CLI.\n    \n    Returns:\n      A list of parsed arguments.\n    """"""\n    parser = argparse.ArgumentParser(description=""DeepLab-ResNet Network"")\n    parser.add_argument(""--batch-size"", type=int, default=BATCH_SIZE,\n                        help=""Number of images sent to the network in one step."")\n    parser.add_argument(""--data-dir"", type=str, default=DATA_DIRECTORY,\n                        help=""Path to the directory containing the PASCAL VOC dataset."")\n    parser.add_argument(""--data-list"", type=str, default=DATA_LIST_PATH,\n                        help=""Path to the file listing the images in the dataset."")\n    parser.add_argument(""--ignore-label"", type=int, default=IGNORE_LABEL,\n                        help=""The index of the label to ignore during the training."")\n    parser.add_argument(""--input-size"", type=str, default=INPUT_SIZE,\n                        help=""Comma-separated string with height and width of images."")\n    parser.add_argument(""--iter-size"", type=int, default=ITER_SIZE,\n                        help=""Number of steps after which gradient update is applied."")\n    parser.add_argument(""--is-training"", action=""store_true"",\n                        help=""Whether to updates the running means and variances during the training."")\n    parser.add_argument(""--learning-rate"", type=float, default=LEARNING_RATE,\n                        help=""Base learning rate for training with polynomial decay."")\n    parser.add_argument(""--momentum"", type=float, default=MOMENTUM,\n                        help=""Momentum component of the optimiser."")\n    parser.add_argument(""--not-restore-last"", action=""store_true"",\n                        help=""Whether to not restore last (FC) layers."")\n    parser.add_argument(""--num-classes"", type=int, default=NUM_CLASSES,\n                        help=""Number of classes to predict (including background)."")\n    parser.add_argument(""--num-steps"", type=int, default=NUM_STEPS,\n                        help=""Number of training steps."")\n    parser.add_argument(""--power"", type=float, default=POWER,\n                        help=""Decay parameter to compute the learning rate."")\n    parser.add_argument(""--random-mirror"", action=""store_true"",\n                        help=""Whether to randomly mirror the inputs during the training."")\n    parser.add_argument(""--random-scale"", action=""store_true"",\n                        help=""Whether to randomly scale the inputs during the training."")\n    parser.add_argument(""--random-seed"", type=int, default=RANDOM_SEED,\n                        help=""Random seed to have reproducible results."")\n    parser.add_argument(""--restore-from"", type=str, default=RESTORE_FROM,\n                        help=""Where restore model parameters from."")\n    parser.add_argument(""--save-num-images"", type=int, default=SAVE_NUM_IMAGES,\n                        help=""How many images to save."")\n    parser.add_argument(""--save-pred-every"", type=int, default=SAVE_PRED_EVERY,\n                        help=""Save summaries and checkpoint every often."")\n    parser.add_argument(""--snapshot-dir"", type=str, default=SNAPSHOT_DIR,\n                        help=""Where to save snapshots of the model."")\n    parser.add_argument(""--weight-decay"", type=float, default=WEIGHT_DECAY,\n                        help=""Regularisation parameter for L2-loss."")\n    parser.add_argument(""--gpu"", type=int, default=0,\n                        help=""choose gpu device."")\n    return parser.parse_args()\n\nargs = get_arguments()\n\ndef loss_calc(pred, label, gpu):\n    """"""\n    This function returns cross entropy loss for semantic segmentation\n    """"""\n    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n    label = torch.from_numpy(label).long()\n    label = Variable(label).cuda(gpu)\n    m = nn.LogSoftmax()\n    criterion = CrossEntropy2d().cuda(gpu)\n    pred = m(pred)\n    \n    return criterion(pred, label)\n\n\ndef lr_poly(base_lr, iter, max_iter, power):\n    return base_lr*((1-float(iter)/max_iter)**(power))\n\n\ndef get_1x_lr_params_NOscale(model):\n    """"""\n    This generator returns all the parameters of the net except for \n    the last classification layer. Note that for each batchnorm layer, \n    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return \n    any batchnorm parameter\n    """"""\n    b = []\n\n    b.append(model.conv1)\n    b.append(model.bn1)\n    b.append(model.layer1)\n    b.append(model.layer2)\n    b.append(model.layer3)\n    b.append(model.layer4)\n\n    \n    for i in range(len(b)):\n        for j in b[i].modules():\n            jj = 0\n            for k in j.parameters():\n                jj+=1\n                if k.requires_grad:\n                    yield k\n\ndef get_10x_lr_params(model):\n    """"""\n    This generator returns all the parameters for the last layer of the net,\n    which does the classification of pixel into classes\n    """"""\n    b = []\n    b.append(model.layer5.parameters())\n\n    for j in range(len(b)):\n        for i in b[j]:\n            yield i\n            \n            \ndef adjust_learning_rate(optimizer, i_iter):\n    """"""Sets the learning rate to the initial LR divided by 5 at 60th, 120th and 160th epochs""""""\n    lr = lr_poly(args.learning_rate, i_iter, args.num_steps, args.power)\n    optimizer.param_groups[0][\'lr\'] = lr\n    optimizer.param_groups[1][\'lr\'] = lr * 10\n\n\ndef main():\n    """"""Create the model and start the training.""""""\n    \n    h, w = map(int, args.input_size.split(\',\'))\n    input_size = (h, w)\n\n    cudnn.enabled = True\n    gpu = args.gpu\n\n    # Create network.\n    model = Res_Deeplab(num_classes=args.num_classes)\n    # For a small batch size, it is better to keep \n    # the statistics of the BN layers (running means and variances)\n    # frozen, and to not update the values provided by the pre-trained model. \n    # If is_training=True, the statistics will be updated during the training.\n    # Note that is_training=False still updates BN parameters gamma (scale) and beta (offset)\n    # if they are presented in var_list of the optimiser definition.\n\n    saved_state_dict = torch.load(args.restore_from)\n    new_params = model.state_dict().copy()\n    for i in saved_state_dict:\n        #Scale.layer5.conv2d_list.3.weight\n        i_parts = i.split(\'.\')\n        # print i_parts\n        if not args.num_classes == 21 or not i_parts[1]==\'layer5\':\n            new_params[\'.\'.join(i_parts[1:])] = saved_state_dict[i]\n    model.load_state_dict(new_params)\n    #model.float()\n    #model.eval() # use_global_stats = True\n    model.train()\n    model.cuda(args.gpu)\n    \n    cudnn.benchmark = True\n\n    if not os.path.exists(args.snapshot_dir):\n        os.makedirs(args.snapshot_dir)\n\n\n    trainloader = data.DataLoader(VOCDataSet(args.data_dir, args.data_list, max_iters=args.num_steps*args.iter_size,\n                    crop_size=input_size, scale=args.random_scale, mirror=args.random_mirror, mean=IMG_MEAN), \n                    batch_size=args.batch_size, shuffle=True, num_workers=1, pin_memory=True)\n\n    optimizer = optim.SGD([{\'params\': get_1x_lr_params_NOscale(model), \'lr\': args.learning_rate }, \n                {\'params\': get_10x_lr_params(model), \'lr\': 10*args.learning_rate}], \n                lr=args.learning_rate, momentum=args.momentum,weight_decay=args.weight_decay)\n    optimizer.zero_grad()\n\n    b_loss = 0\n    for i_iter, batch in enumerate(trainloader):\n\n        images, labels, _, _ = batch\n        images, labels = Variable(images), labels.numpy()\n        h, w = images.size()[2:]\n        images075 = nn.Upsample(size=(int(h*0.75), int(w*0.75)), mode=\'bilinear\')(images)\n        images05 = nn.Upsample(size=(int(h*0.5), int(w*0.5)), mode=\'bilinear\')(images)\n\n        out = model(images.cuda(args.gpu))\n        out075 = model(images075.cuda(args.gpu))\n        out05 = model(images05.cuda(args.gpu))\n        o_h, o_w = out.size()[2:]\n        interpo1 = nn.Upsample(size=(o_h, o_w), mode=\'bilinear\')\n        interpo2 = nn.Upsample(size=(h, w), mode=\'bilinear\')\n        out_max = interpo2(torch.max(torch.stack([out, interpo1(out075), interpo1(out05)]), dim=0)[0])\n\n        loss = loss_calc(out_max, labels, args.gpu)\n        d1, d2 = float(labels.shape[1]), float(labels.shape[2])\n        loss100 = loss_calc(out, nd.zoom(labels, (1.0, out.size()[2]/d1, out.size()[3]/d2), order=0), args.gpu)\n        loss075 = loss_calc(out075, nd.zoom(labels, (1.0, out075.size()[2]/d1, out075.size()[3]/d2), order=0), args.gpu)\n        loss05 = loss_calc(out05, nd.zoom(labels, (1.0, out05.size()[2]/d1, out05.size()[3]/d2), order=0), args.gpu)\n        loss_all = (loss + loss100 + loss075 + loss05) / args.iter_size\n        loss_all.backward()\n        b_loss += loss_all.data.cpu().numpy()\n\n        b_iter = i_iter / args.iter_size\n\n        if b_iter >= args.num_steps-1:\n            print \'save model ...\'\n            optimizer.step()\n            torch.save(model.state_dict(),osp.join(args.snapshot_dir, \'VOC12_scenes_\'+str(args.num_steps)+\'.pth\'))\n            break\n\n        if i_iter % args.iter_size == 0 and i_iter != 0:\n            print \'iter = \', b_iter, \'of\', args.num_steps,\'completed, loss = \', b_loss\n            optimizer.step()\n            adjust_learning_rate(optimizer, b_iter)\n            optimizer.zero_grad()\n            b_loss = 0\n\n        if i_iter % (args.save_pred_every*args.iter_size) == 0 and b_iter!=0:\n            print \'taking snapshot ...\'\n            torch.save(model.state_dict(),osp.join(args.snapshot_dir, \'VOC12_scenes_\'+str(b_iter)+\'.pth\'))\n\n    end = timeit.timeit()\n    print end-start,\'seconds\'\n\nif __name__ == \'__main__\':\n    main()\n'"
deeplab/__init__.py,0,b'\n'
deeplab/datasets.py,1,"b'import os\nimport os.path as osp\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport collections\nimport torch\nimport torchvision\nimport cv2\nfrom torch.utils import data\n\n\nclass VOCDataSet(data.Dataset):\n    def __init__(self, root, list_path, max_iters=None, crop_size=(321, 321), mean=(128, 128, 128), scale=True, mirror=True, ignore_label=255):\n        self.root = root\n        self.list_path = list_path\n        self.crop_h, self.crop_w = crop_size\n        self.scale = scale\n        self.ignore_label = ignore_label\n        self.mean = mean\n        self.is_mirror = mirror\n        # self.mean_bgr = np.array([104.00698793, 116.66876762, 122.67891434])\n        self.img_ids = [i_id.strip() for i_id in open(list_path)]\n        if not max_iters==None:\n\t    self.img_ids = self.img_ids * int(np.ceil(float(max_iters) / len(self.img_ids)))\n        self.files = []\n        # for split in [""train"", ""trainval"", ""val""]:\n        for name in self.img_ids:\n            img_file = osp.join(self.root, ""JPEGImages/%s.jpg"" % name)\n            label_file = osp.join(self.root, ""SegmentationClassAug/%s.png"" % name)\n            self.files.append({\n                ""img"": img_file,\n                ""label"": label_file,\n                ""name"": name\n            })\n\n    def __len__(self):\n        return len(self.files)\n\n    def generate_scale_label(self, image, label):\n        f_scale = 0.5 + random.randint(0, 11) / 10.0\n        image = cv2.resize(image, None, fx=f_scale, fy=f_scale, interpolation = cv2.INTER_LINEAR)\n        label = cv2.resize(label, None, fx=f_scale, fy=f_scale, interpolation = cv2.INTER_NEAREST)\n        return image, label\n\n    def __getitem__(self, index):\n        datafiles = self.files[index]\n        image = cv2.imread(datafiles[""img""], cv2.IMREAD_COLOR)\n        label = cv2.imread(datafiles[""label""], cv2.IMREAD_GRAYSCALE)\n        size = image.shape\n        name = datafiles[""name""]\n        if self.scale:\n            image, label = self.generate_scale_label(image, label)\n        image = np.asarray(image, np.float32)\n        image -= self.mean\n        img_h, img_w = label.shape\n        pad_h = max(self.crop_h - img_h, 0)\n        pad_w = max(self.crop_w - img_w, 0)\n        if pad_h > 0 or pad_w > 0:\n            img_pad = cv2.copyMakeBorder(image, 0, pad_h, 0, \n                pad_w, cv2.BORDER_CONSTANT, \n                value=(0.0, 0.0, 0.0))\n            label_pad = cv2.copyMakeBorder(label, 0, pad_h, 0, \n                pad_w, cv2.BORDER_CONSTANT,\n                value=(self.ignore_label,))\n        else:\n            img_pad, label_pad = image, label\n\n        img_h, img_w = label_pad.shape\n        h_off = random.randint(0, img_h - self.crop_h)\n        w_off = random.randint(0, img_w - self.crop_w)\n        # roi = cv2.Rect(w_off, h_off, self.crop_w, self.crop_h);\n        image = np.asarray(img_pad[h_off : h_off+self.crop_h, w_off : w_off+self.crop_w], np.float32)\n        label = np.asarray(label_pad[h_off : h_off+self.crop_h, w_off : w_off+self.crop_w], np.float32)\n        #image = image[:, :, ::-1]  # change to BGR\n        image = image.transpose((2, 0, 1))\n        if self.is_mirror:\n            flip = np.random.choice(2) * 2 - 1\n            image = image[:, :, ::flip]\n            label = label[:, ::flip]\n\n        return image.copy(), label.copy(), np.array(size), name\n\n\nclass VOCDataTestSet(data.Dataset):\n    def __init__(self, root, list_path, crop_size=(505, 505), mean=(128, 128, 128)):\n        self.root = root\n        self.list_path = list_path\n        self.crop_h, self.crop_w = crop_size\n        self.mean = mean\n        # self.mean_bgr = np.array([104.00698793, 116.66876762, 122.67891434])\n        self.img_ids = [i_id.strip() for i_id in open(list_path)]\n        self.files = [] \n        # for split in [""train"", ""trainval"", ""val""]:\n        for name in self.img_ids:\n            img_file = osp.join(self.root, ""JPEGImages/%s.jpg"" % name)\n            self.files.append({\n                ""img"": img_file\n            })\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, index):\n        datafiles = self.files[index]\n        image = cv2.imread(datafiles[""img""], cv2.IMREAD_COLOR)\n        size = image.shape\n        name = osp.splitext(osp.basename(datafiles[""img""]))[0]\n        image = np.asarray(image, np.float32)\n        image -= self.mean\n        \n        img_h, img_w, _ = image.shape\n        pad_h = max(self.crop_h - img_h, 0)\n        pad_w = max(self.crop_w - img_w, 0)\n        if pad_h > 0 or pad_w > 0:\n            image = cv2.copyMakeBorder(image, 0, pad_h, 0, \n                pad_w, cv2.BORDER_CONSTANT, \n                value=(0.0, 0.0, 0.0))\n        image = image.transpose((2, 0, 1))\n        return image, name, size\n\n\nif __name__ == \'__main__\':\n    dst = VOCDataSet(""./data"", is_transform=True)\n    trainloader = data.DataLoader(dst, batch_size=4)\n    for i, data in enumerate(trainloader):\n        imgs, labels = data\n        if i == 0:\n            img = torchvision.utils.make_grid(imgs).numpy()\n            img = np.transpose(img, (1, 2, 0))\n            img = img[:, :, ::-1]\n            plt.imshow(img)\n            plt.show()\n'"
deeplab/loss.py,4,"b'import torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass CrossEntropy2d(nn.Module):\n\n    def __init__(self, size_average=True, ignore_label=255):\n        super(CrossEntropy2d, self).__init__()\n        self.size_average = size_average\n        self.ignore_label = ignore_label\n\n    def forward(self, predict, target, weight=None):\n        """"""\n            Args:\n                predict:(n, c, h, w)\n                target:(n, h, w)\n                weight (Tensor, optional): a manual rescaling weight given to each class.\n                                           If given, has to be a Tensor of size ""nclasses""\n        """"""\n        assert not target.requires_grad\n        assert predict.dim() == 4\n        assert target.dim() == 3\n        assert predict.size(0) == target.size(0), ""{0} vs {1} "".format(predict.size(0), target.size(0))\n        assert predict.size(2) == target.size(1), ""{0} vs {1} "".format(predict.size(2), target.size(1))\n        assert predict.size(3) == target.size(2), ""{0} vs {1} "".format(predict.size(3), target.size(3))\n        n, c, h, w = predict.size()\n        target_mask = (target >= 0) * (target != self.ignore_label)\n        target = target[target_mask]\n        if not target.data.dim():\n            return Variable(torch.zeros(1))\n        predict = predict.transpose(1, 2).transpose(2, 3).contiguous()\n        predict = predict[target_mask.view(n, h, w, 1).repeat(1, 1, 1, c)].view(-1, c)\n        loss = F.cross_entropy(predict, target, weight=weight, size_average=self.size_average)\n        return loss'"
deeplab/metric.py,0,"b""import os, sys\nimport numpy as np\n\nfrom multiprocessing import Pool \nimport copy_reg\nimport types\ndef _pickle_method(m):\n    if m.im_self is None:\n        return getattr, (m.im_class, m.im_func.func_name)\n    else:\n        return getattr, (m.im_self, m.im_func.func_name)\n\ncopy_reg.pickle(types.MethodType, _pickle_method)\n\nclass ConfusionMatrix(object):\n\n    def __init__(self, nclass, classes=None):\n        self.nclass = nclass\n        self.classes = classes\n        self.M = np.zeros((nclass, nclass))\n\n    def add(self, gt, pred):\n        assert(np.max(pred) <= self.nclass)\n        assert(len(gt) == len(pred))\n        for i in range(len(gt)):\n            if not gt[i] == 255:\n                self.M[gt[i], pred[i]] += 1.0\n\n    def addM(self, matrix):\n        assert(matrix.shape == self.M.shape)\n        self.M += matrix\n\n    def __str__(self):\n        pass\n\n    def recall(self):\n        recall = 0.0\n        for i in xrange(self.nclass):\n            recall += self.M[i, i] / np.sum(self.M[:, i])\n\n        return recall/self.nclass\n\n    def accuracy(self):\n        accuracy = 0.0\n        for i in xrange(self.nclass):\n            accuracy += self.M[i, i] / np.sum(self.M[i, :])\n\n        return accuracy/self.nclass\n\n    def jaccard(self):\n        jaccard = 0.0\n        jaccard_perclass = []\n        for i in xrange(self.nclass):\n            jaccard_perclass.append(self.M[i, i] / (np.sum(self.M[i, :]) + np.sum(self.M[:, i]) - self.M[i, i]))\n\n        return np.sum(jaccard_perclass)/len(jaccard_perclass), jaccard_perclass, self.M\n\n    def generateM(self, item):\n        gt, pred = item\n        m = np.zeros((self.nclass, self.nclass))\n        assert(len(gt) == len(pred))\n        for i in range(len(gt)):\n            if gt[i] < self.nclass: #and pred[i] < self.nclass:\n                m[gt[i], pred[i]] += 1.0\n        return m\n\n\nif __name__ == '__main__':\n    args = parse_args()\n\n    m_list = []\n    data_list = []\n    test_ids = [i.strip() for i in open(args.test_ids) if not i.strip() == '']\n    for index, img_id in enumerate(test_ids):\n        if index % 100 == 0:\n            print('%d processd'%(index))\n        pred_img_path = os.path.join(args.pred_dir, img_id+'.png')\n        gt_img_path = os.path.join(args.gt_dir, img_id+'.png')\n        pred = cv2.imread(pred_img_path, cv2.IMREAD_GRAYSCALE)\n        gt = cv2.imread(gt_img_path, cv2.IMREAD_GRAYSCALE)\n        # show_all(gt, pred)\n        data_list.append([gt.flatten(), pred.flatten()])\n\n    ConfM = ConfusionMatrix(args.class_num)\n    f = ConfM.generateM\n    pool = Pool() \n    m_list = pool.map(f, data_list)\n    pool.close() \n    pool.join() \n    \n    for m in m_list:\n        ConfM.addM(m)\n\n    aveJ, j_list, M = ConfM.jaccard()\n    with open(args.save_path, 'w') as f:\n        f.write('meanIOU: ' + str(aveJ) + '\\n')\n        f.write(str(j_list)+'\\n')\n        f.write(str(M)+'\\n')\n"""
deeplab/model.py,3,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nimport torch\nimport numpy as np\naffine_par = True\n\n\ndef outS(i):\n    i = int(i)\n    i = (i+1)/2\n    i = int(np.ceil((i+1)/2.0))\n    i = (i+1)/2\n    return i\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes, affine = affine_par)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes, affine = affine_par)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n        self.bn1 = nn.BatchNorm2d(planes,affine = affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n\n        padding = dilation\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, # change\n                               padding=padding, bias=False, dilation = dilation)\n        self.bn2 = nn.BatchNorm2d(planes,affine = affine_par)\n        for i in self.bn2.parameters():\n            i.requires_grad = False\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4, affine = affine_par)\n        for i in self.bn3.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass Classifier_Module(nn.Module):\n\n    def __init__(self, dilation_series, padding_series, num_classes):\n        super(Classifier_Module, self).__init__()\n        self.conv2d_list = nn.ModuleList()\n        for dilation, padding in zip(dilation_series, padding_series):\n            self.conv2d_list.append(nn.Conv2d(2048, num_classes, kernel_size=3, stride=1, padding=padding, dilation=dilation, bias = True))\n\n        for m in self.conv2d_list:\n            m.weight.data.normal_(0, 0.01)\n\n    def forward(self, x):\n        out = self.conv2d_list[0](x)\n        for i in range(len(self.conv2d_list)-1):\n            out += self.conv2d_list[i+1](x)\n        return out\n\nclass Residual_Covolution(nn.Module):\n    def __init__(self, icol, ocol, num_classes):\n        super(Residual_Covolution, self).__init__()\n        self.conv1 = nn.Conv2d(icol, ocol, kernel_size=3, stride=1, padding=12, dilation=12, bias=True)\n        self.conv2 = nn.Conv2d(ocol, num_classes, kernel_size=3, stride=1, padding=12, dilation=12, bias=True)\n        self.conv3 = nn.Conv2d(num_classes, ocol, kernel_size=1, stride=1, padding=0, dilation=1, bias=True)\n        self.conv4 = nn.Conv2d(ocol, icol, kernel_size=1, stride=1, padding=0, dilation=1, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        dow1 = self.conv1(x)\n        dow1 = self.relu(dow1)\n        seg = self.conv2(dow1)\n        inc1 = self.conv3(seg)\n        add1 = dow1 + self.relu(inc1)\n        inc2 = self.conv4(add1)\n        out = x + self.relu(inc2)\n        return out, seg\n\nclass Residual_Refinement_Module(nn.Module):\n\n    def __init__(self, num_classes):\n        super(Residual_Refinement_Module, self).__init__()\n        self.RC1 = Residual_Covolution(2048, 512, num_classes)\n        self.RC2 = Residual_Covolution(2048, 512, num_classes)\n\n    def forward(self, x):\n        x, seg1 = self.RC1(x)\n        _, seg2 = self.RC2(x)\n        return [seg1, seg1+seg2]\n\nclass ResNet_Refine(nn.Module):\n    def __init__(self, block, layers, num_classes):\n        self.inplanes = 64\n        super(ResNet_Refine, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64, affine = affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n        self.layer5 = Residual_Refinement_Module(num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, 0.01)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        #        for i in m.parameters():\n        #            i.requires_grad = False\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion or dilation == 2 or dilation == 4:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion,affine = affine_par))\n        for i in downsample._modules[\'1\'].parameters():\n            i.requires_grad = False\n        layers = []\n        layers.append(block(self.inplanes, planes, stride,dilation=dilation, downsample=downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, dilation=dilation))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n\n        return x     \n\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64, affine = affine_par)\n        for i in self.bn1.parameters():\n            i.requires_grad = False\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n        self.layer5 = self._make_pred_layer(Classifier_Module, [6,12,18,24],[6,12,18,24],num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, 0.01)\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        #        for i in m.parameters():\n        #            i.requires_grad = False\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion or dilation == 2 or dilation == 4:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion,affine = affine_par))\n        for i in downsample._modules[\'1\'].parameters():\n            i.requires_grad = False\n        layers = []\n        layers.append(block(self.inplanes, planes, stride,dilation=dilation, downsample=downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, dilation=dilation))\n\n        return nn.Sequential(*layers)\n    def _make_pred_layer(self,block, dilation_series, padding_series,num_classes):\n        return block(dilation_series,padding_series,num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n\n        return x\n\nclass MS_Deeplab(nn.Module):\n    def __init__(self,block,num_classes):\n        super(MS_Deeplab,self).__init__()\n        self.Scale = ResNet(block,[3, 4, 23, 3],num_classes)   #changed to fix #4 \n\n    def forward(self,x):\n        output = self.Scale(x) # for original scale\n        output_size = output.size()[2]\n        input_size = x.size()[2]\n\n        self.interp1 = nn.Upsample(size=(int(input_size*0.75)+1, int(input_size*0.75)+1), mode=\'bilinear\')\n        self.interp2 = nn.Upsample(size=(int(input_size*0.5)+1, int(input_size*0.5)+1), mode=\'bilinear\')\n        self.interp3 = nn.Upsample(size=(output_size, output_size), mode=\'bilinear\')\n\n        x75 = self.interp1(x)\n        output75 = self.interp3(self.Scale(x75)) # for 0.75x scale\n\n        x5 = self.interp2(x)\n        output5 = self.interp3(self.Scale(x5))\t# for 0.5x scale\n\n        out_max = torch.max(torch.max(output, output75), output5)\n        return [output, output75, output5, out_max]\n\ndef Res_Ms_Deeplab(num_classes=21):\n    model = MS_Deeplab(Bottleneck, num_classes)\n    return model\n\ndef Res_Deeplab(num_classes=21, is_refine=False):\n    if is_refine:\n        model = ResNet_Refine(Bottleneck,[3, 4, 23, 3], num_classes)\n    else:\n        model = ResNet(Bottleneck,[3, 4, 23, 3], num_classes)\n    return model\n\n'"
