file_path,api_count,code
args.py,0,"b'import argparse\n\nNONLINEARITIES = [""tanh"", ""relu"", ""softplus"", ""elu"", ""swish"", ""square"", ""identity""]\nSOLVERS = [""dopri5"", ""bdf"", ""rk4"", ""midpoint"", \'adams\', \'explicit_adams\', \'fixed_adams\']\nLAYERS = [""ignore"", ""concat"", ""concat_v2"", ""squash"", ""concatsquash"", ""scale"", ""concatscale""]\n\n\ndef add_args(parser):\n    # model architecture options\n    parser.add_argument(\'--input_dim\', type=int, default=3,\n                        help=\'Number of input dimensions (3 for 3D point clouds)\')\n    parser.add_argument(\'--dims\', type=str, default=\'256\')\n    parser.add_argument(\'--latent_dims\', type=str, default=\'256\')\n    parser.add_argument(""--num_blocks"", type=int, default=1,\n                        help=\'Number of stacked CNFs.\')\n    parser.add_argument(""--latent_num_blocks"", type=int, default=1,\n                        help=\'Number of stacked CNFs.\')\n    parser.add_argument(""--layer_type"", type=str, default=""concatsquash"", choices=LAYERS)\n    parser.add_argument(\'--time_length\', type=float, default=0.5)\n    parser.add_argument(\'--train_T\', type=eval, default=True, choices=[True, False])\n    parser.add_argument(""--nonlinearity"", type=str, default=""tanh"", choices=NONLINEARITIES)\n    parser.add_argument(\'--use_adjoint\', type=eval, default=True, choices=[True, False])\n    parser.add_argument(\'--solver\', type=str, default=\'dopri5\', choices=SOLVERS)\n    parser.add_argument(\'--atol\', type=float, default=1e-5)\n    parser.add_argument(\'--rtol\', type=float, default=1e-5)\n    parser.add_argument(\'--batch_norm\', type=eval, default=True, choices=[True, False])\n    parser.add_argument(\'--sync_bn\', type=eval, default=False, choices=[True, False])\n    parser.add_argument(\'--bn_lag\', type=float, default=0)\n\n    # training options\n    parser.add_argument(\'--use_latent_flow\', action=\'store_true\',\n                        help=\'Whether to use the latent flow to model the prior.\')\n    parser.add_argument(\'--use_deterministic_encoder\', action=\'store_true\',\n                        help=\'Whether to use a deterministic encoder.\')\n    parser.add_argument(\'--zdim\', type=int, default=128,\n                        help=\'Dimension of the shape code\')\n    parser.add_argument(\'--optimizer\', type=str, default=\'adam\',\n                        help=\'Optimizer to use\', choices=[\'adam\', \'adamax\', \'sgd\'])\n    parser.add_argument(\'--batch_size\', type=int, default=50,\n                        help=\'Batch size (of datasets) for training\')\n    parser.add_argument(\'--lr\', type=float, default=1e-3,\n                        help=\'Learning rate for the Adam optimizer.\')\n    parser.add_argument(\'--beta1\', type=float, default=0.9,\n                        help=\'Beta1 for Adam.\')\n    parser.add_argument(\'--beta2\', type=float, default=0.999,\n                        help=\'Beta2 for Adam.\')\n    parser.add_argument(\'--momentum\', type=float, default=0.9,\n                        help=\'Momentum for SGD\')\n    parser.add_argument(\'--weight_decay\', type=float, default=0.,\n                        help=\'Weight decay for the optimizer.\')\n    parser.add_argument(\'--epochs\', type=int, default=100,\n                        help=\'Number of epochs for training (default: 100)\')\n    parser.add_argument(\'--seed\', type=int, default=None,\n                        help=\'Seed for initializing training. \')\n    parser.add_argument(\'--recon_weight\', type=float, default=1.,\n                        help=\'Weight for the reconstruction loss.\')\n    parser.add_argument(\'--prior_weight\', type=float, default=1.,\n                        help=\'Weight for the prior loss.\')\n    parser.add_argument(\'--entropy_weight\', type=float, default=1.,\n                        help=\'Weight for the entropy loss.\')\n    parser.add_argument(\'--scheduler\', type=str, default=\'linear\',\n                        help=\'Type of learning rate schedule\')\n    parser.add_argument(\'--exp_decay\', type=float, default=1.,\n                        help=\'Learning rate schedule exponential decay rate\')\n    parser.add_argument(\'--exp_decay_freq\', type=int, default=1,\n                        help=\'Learning rate exponential decay frequency\')\n\n    # data options\n    parser.add_argument(\'--dataset_type\', type=str, default=""shapenet15k"",\n                        help=""Dataset types."", choices=[\'shapenet15k\', \'modelnet40_15k\', \'modelnet10_15k\'])\n    parser.add_argument(\'--cates\', type=str, nargs=\'+\', default=[""airplane""],\n                        help=""Categories to be trained (useful only if \'shapenet\' is selected)"")\n    parser.add_argument(\'--data_dir\', type=str, default=""data/ShapeNetCore.v2.PC15k"",\n                        help=""Path to the training data"")\n    parser.add_argument(\'--mn40_data_dir\', type=str, default=""data/ModelNet40.PC15k"",\n                        help=""Path to ModelNet40"")\n    parser.add_argument(\'--mn10_data_dir\', type=str, default=""data/ModelNet10.PC15k"",\n                        help=""Path to ModelNet10"")\n    parser.add_argument(\'--dataset_scale\', type=float, default=1.,\n                        help=\'Scale of the dataset (x,y,z * scale = real output, default=1).\')\n    parser.add_argument(\'--random_rotate\', action=\'store_true\',\n                        help=\'Whether to randomly rotate each shape.\')\n    parser.add_argument(\'--normalize_per_shape\', action=\'store_true\',\n                        help=\'Whether to perform normalization per shape.\')\n    parser.add_argument(\'--normalize_std_per_axis\', action=\'store_true\',\n                        help=\'Whether to perform normalization per axis.\')\n    parser.add_argument(""--tr_max_sample_points"", type=int, default=2048,\n                        help=\'Max number of sampled points (train)\')\n    parser.add_argument(""--te_max_sample_points"", type=int, default=2048,\n                        help=\'Max number of sampled points (test)\')\n    parser.add_argument(\'--num_workers\', type=int, default=4,\n                        help=\'Number of data loading threads\')\n\n    # logging and saving frequency\n    parser.add_argument(\'--log_name\', type=str, default=None, help=""Name for the log dir"")\n    parser.add_argument(\'--viz_freq\', type=int, default=10)\n    parser.add_argument(\'--val_freq\', type=int, default=10)\n    parser.add_argument(\'--log_freq\', type=int, default=10)\n    parser.add_argument(\'--save_freq\', type=int, default=10)\n\n    # validation options\n    parser.add_argument(\'--no_validation\', action=\'store_true\',\n                        help=\'Whether to disable validation altogether.\')\n    parser.add_argument(\'--save_val_results\', action=\'store_true\',\n                        help=\'Whether to save the validation results.\')\n    parser.add_argument(\'--eval_classification\', action=\'store_true\',\n                        help=\'Whether to evaluate classification accuracy on MN40 and MN10.\')\n    parser.add_argument(\'--no_eval_sampling\', action=\'store_true\',\n                        help=\'Whether to evaluate sampling.\')\n    parser.add_argument(\'--max_validate_shapes\', type=int, default=None,\n                        help=\'Max number of shapes used for validation pass.\')\n\n    # resuming\n    parser.add_argument(\'--resume_checkpoint\', type=str, default=None,\n                        help=\'Path to the checkpoint to be loaded.\')\n    parser.add_argument(\'--resume_optimizer\', action=\'store_true\',\n                        help=\'Whether to resume the optimizer when resumed training.\')\n    parser.add_argument(\'--resume_non_strict\', action=\'store_true\',\n                        help=\'Whether to resume in none-strict mode.\')\n    parser.add_argument(\'--resume_dataset_mean\', type=str, default=None,\n                        help=\'Path to the file storing the dataset mean.\')\n    parser.add_argument(\'--resume_dataset_std\', type=str, default=None,\n                        help=\'Path to the file storing the dataset std.\')\n\n    # distributed training\n    parser.add_argument(\'--world_size\', default=1, type=int,\n                        help=\'Number of distributed nodes.\')\n    parser.add_argument(\'--dist_url\', default=\'tcp://127.0.0.1:9991\', type=str,\n                        help=\'url used to set up distributed training\')\n    parser.add_argument(\'--dist_backend\', default=\'nccl\', type=str,\n                        help=\'distributed backend\')\n    parser.add_argument(\'--distributed\', action=\'store_true\',\n                        help=\'Use multi-processing distributed training to launch \'\n                             \'N processes per node, which has N GPUs. This is the \'\n                             \'fastest way to use PyTorch for either single node or \'\n                             \'multi node data parallel training\')\n    parser.add_argument(\'--rank\', default=0, type=int,\n                        help=\'node rank for distributed training\')\n    parser.add_argument(\'--gpu\', default=None, type=int,\n                        help=\'GPU id to use. None means using all available GPUs.\')\n\n    # Evaluation options\n    parser.add_argument(\'--evaluate_recon\', default=False, action=\'store_true\',\n                        help=\'Whether set to the evaluation for reconstruction.\')\n    parser.add_argument(\'--num_sample_shapes\', default=10, type=int,\n                        help=\'Number of shapes to be sampled (for demo.py).\')\n    parser.add_argument(\'--num_sample_points\', default=2048, type=int,\n                        help=\'Number of points (per-shape) to be sampled (for demo.py).\')\n\n    return parser\n\n\ndef get_parser():\n    # command line args\n    parser = argparse.ArgumentParser(description=\'Flow-based Point Cloud Generation Experiment\')\n    parser = add_args(parser)\n    return parser\n\n\ndef get_args():\n    parser = get_parser()\n    args = parser.parse_args()\n    return args\n'"
datasets.py,5,"b'import os\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom torch.utils import data\nimport random\n\n# taken from https://github.com/optas/latent_3d_points/blob/8e8f29f8124ed5fc59439e8551ba7ef7567c9a37/src/in_out.py\nsynsetid_to_cate = {\n    \'02691156\': \'airplane\', \'02773838\': \'bag\', \'02801938\': \'basket\',\n    \'02808440\': \'bathtub\', \'02818832\': \'bed\', \'02828884\': \'bench\',\n    \'02876657\': \'bottle\', \'02880940\': \'bowl\', \'02924116\': \'bus\',\n    \'02933112\': \'cabinet\', \'02747177\': \'can\', \'02942699\': \'camera\',\n    \'02954340\': \'cap\', \'02958343\': \'car\', \'03001627\': \'chair\',\n    \'03046257\': \'clock\', \'03207941\': \'dishwasher\', \'03211117\': \'monitor\',\n    \'04379243\': \'table\', \'04401088\': \'telephone\', \'02946921\': \'tin_can\',\n    \'04460130\': \'tower\', \'04468005\': \'train\', \'03085013\': \'keyboard\',\n    \'03261776\': \'earphone\', \'03325088\': \'faucet\', \'03337140\': \'file\',\n    \'03467517\': \'guitar\', \'03513137\': \'helmet\', \'03593526\': \'jar\',\n    \'03624134\': \'knife\', \'03636649\': \'lamp\', \'03642806\': \'laptop\',\n    \'03691459\': \'speaker\', \'03710193\': \'mailbox\', \'03759954\': \'microphone\',\n    \'03761084\': \'microwave\', \'03790512\': \'motorcycle\', \'03797390\': \'mug\',\n    \'03928116\': \'piano\', \'03938244\': \'pillow\', \'03948459\': \'pistol\',\n    \'03991062\': \'pot\', \'04004475\': \'printer\', \'04074963\': \'remote_control\',\n    \'04090263\': \'rifle\', \'04099429\': \'rocket\', \'04225987\': \'skateboard\',\n    \'04256520\': \'sofa\', \'04330267\': \'stove\', \'04530566\': \'vessel\',\n    \'04554684\': \'washer\', \'02992529\': \'cellphone\',\n    \'02843684\': \'birdhouse\', \'02871439\': \'bookshelf\',\n    # \'02858304\': \'boat\', no boat in our dataset, merged into vessels\n    # \'02834778\': \'bicycle\', not in our taxonomy\n}\ncate_to_synsetid = {v: k for k, v in synsetid_to_cate.items()}\n\n\nclass Uniform15KPC(Dataset):\n    def __init__(self, root_dir, subdirs, tr_sample_size=10000,\n                 te_sample_size=10000, split=\'train\', scale=1.,\n                 normalize_per_shape=False, random_subsample=False,\n                 normalize_std_per_axis=False,\n                 all_points_mean=None, all_points_std=None,\n                 input_dim=3):\n        self.root_dir = root_dir\n        self.split = split\n        self.in_tr_sample_size = tr_sample_size\n        self.in_te_sample_size = te_sample_size\n        self.subdirs = subdirs\n        self.scale = scale\n        self.random_subsample = random_subsample\n        self.input_dim = input_dim\n\n        self.all_cate_mids = []\n        self.cate_idx_lst = []\n        self.all_points = []\n        for cate_idx, subd in enumerate(self.subdirs):\n            # NOTE: [subd] here is synset id\n            sub_path = os.path.join(root_dir, subd, self.split)\n            if not os.path.isdir(sub_path):\n                print(""Directory missing : %s"" % sub_path)\n                continue\n\n            all_mids = []\n            for x in os.listdir(sub_path):\n                if not x.endswith(\'.npy\'):\n                    continue\n                all_mids.append(os.path.join(self.split, x[:-len(\'.npy\')]))\n\n            # NOTE: [mid] contains the split: i.e. ""train/<mid>"" or ""val/<mid>"" or ""test/<mid>""\n            for mid in all_mids:\n                # obj_fname = os.path.join(sub_path, x)\n                obj_fname = os.path.join(root_dir, subd, mid + "".npy"")\n                try:\n                    point_cloud = np.load(obj_fname)  # (15k, 3)\n                except:\n                    continue\n\n                assert point_cloud.shape[0] == 15000\n                self.all_points.append(point_cloud[np.newaxis, ...])\n                self.cate_idx_lst.append(cate_idx)\n                self.all_cate_mids.append((subd, mid))\n\n        # Shuffle the index deterministically (based on the number of examples)\n        self.shuffle_idx = list(range(len(self.all_points)))\n        random.Random(38383).shuffle(self.shuffle_idx)\n        self.cate_idx_lst = [self.cate_idx_lst[i] for i in self.shuffle_idx]\n        self.all_points = [self.all_points[i] for i in self.shuffle_idx]\n        self.all_cate_mids = [self.all_cate_mids[i] for i in self.shuffle_idx]\n\n        # Normalization\n        self.all_points = np.concatenate(self.all_points)  # (N, 15000, 3)\n        self.normalize_per_shape = normalize_per_shape\n        self.normalize_std_per_axis = normalize_std_per_axis\n        if all_points_mean is not None and all_points_std is not None:  # using loaded dataset stats\n            self.all_points_mean = all_points_mean\n            self.all_points_std = all_points_std\n        elif self.normalize_per_shape:  # per shape normalization\n            B, N = self.all_points.shape[:2]\n            self.all_points_mean = self.all_points.mean(axis=1).reshape(B, 1, input_dim)\n            if normalize_std_per_axis:\n                self.all_points_std = self.all_points.reshape(B, N, -1).std(axis=1).reshape(B, 1, input_dim)\n            else:\n                self.all_points_std = self.all_points.reshape(B, -1).std(axis=1).reshape(B, 1, 1)\n        else:  # normalize across the dataset\n            self.all_points_mean = self.all_points.reshape(-1, input_dim).mean(axis=0).reshape(1, 1, input_dim)\n            if normalize_std_per_axis:\n                self.all_points_std = self.all_points.reshape(-1, input_dim).std(axis=0).reshape(1, 1, input_dim)\n            else:\n                self.all_points_std = self.all_points.reshape(-1).std(axis=0).reshape(1, 1, 1)\n\n        self.all_points = (self.all_points - self.all_points_mean) / self.all_points_std\n        self.train_points = self.all_points[:, :10000]\n        self.test_points = self.all_points[:, 10000:]\n\n        self.tr_sample_size = min(10000, tr_sample_size)\n        self.te_sample_size = min(5000, te_sample_size)\n        print(""Total number of data:%d"" % len(self.train_points))\n        print(""Min number of points: (train)%d (test)%d""\n              % (self.tr_sample_size, self.te_sample_size))\n        assert self.scale == 1, ""Scale (!= 1) is deprecated""\n\n    def get_pc_stats(self, idx):\n        if self.normalize_per_shape:\n            m = self.all_points_mean[idx].reshape(1, self.input_dim)\n            s = self.all_points_std[idx].reshape(1, -1)\n            return m, s\n\n        return self.all_points_mean.reshape(1, -1), self.all_points_std.reshape(1, -1)\n\n    def renormalize(self, mean, std):\n        self.all_points = self.all_points * self.all_points_std + self.all_points_mean\n        self.all_points_mean = mean\n        self.all_points_std = std\n        self.all_points = (self.all_points - self.all_points_mean) / self.all_points_std\n        self.train_points = self.all_points[:, :10000]\n        self.test_points = self.all_points[:, 10000:]\n\n    def __len__(self):\n        return len(self.train_points)\n\n    def __getitem__(self, idx):\n        tr_out = self.train_points[idx]\n        if self.random_subsample:\n            tr_idxs = np.random.choice(tr_out.shape[0], self.tr_sample_size)\n        else:\n            tr_idxs = np.arange(self.tr_sample_size)\n        tr_out = torch.from_numpy(tr_out[tr_idxs, :]).float()\n\n        te_out = self.test_points[idx]\n        if self.random_subsample:\n            te_idxs = np.random.choice(te_out.shape[0], self.te_sample_size)\n        else:\n            te_idxs = np.arange(self.te_sample_size)\n        te_out = torch.from_numpy(te_out[te_idxs, :]).float()\n\n        m, s = self.get_pc_stats(idx)\n        cate_idx = self.cate_idx_lst[idx]\n        sid, mid = self.all_cate_mids[idx]\n\n        return {\n            \'idx\': idx,\n            \'train_points\': tr_out,\n            \'test_points\': te_out,\n            \'mean\': m, \'std\': s, \'cate_idx\': cate_idx,\n            \'sid\': sid, \'mid\': mid\n        }\n\n\nclass ModelNet40PointClouds(Uniform15KPC):\n    def __init__(self, root_dir=""data/ModelNet40.PC15k"",\n                 tr_sample_size=10000, te_sample_size=2048,\n                 split=\'train\', scale=1., normalize_per_shape=False,\n                 normalize_std_per_axis=False,\n                 random_subsample=False,\n                 all_points_mean=None, all_points_std=None):\n        self.root_dir = root_dir\n        self.split = split\n        assert self.split in [\'train\', \'test\']\n        self.sample_size = tr_sample_size\n        self.cates = []\n        for cate in os.listdir(root_dir):\n            if os.path.isdir(os.path.join(root_dir, cate)) \\\n                    and os.path.isdir(os.path.join(root_dir, cate, \'train\')) \\\n                    and os.path.isdir(os.path.join(root_dir, cate, \'test\')):\n                self.cates.append(cate)\n        assert len(self.cates) == 40, ""%s %s"" % (len(self.cates), self.cates)\n\n        # For non-aligned MN\n        # self.gravity_axis = 0\n        # self.display_axis_order = [0,1,2]\n\n        # Aligned MN has same axis-order as SN\n        self.gravity_axis = 1\n        self.display_axis_order = [0, 2, 1]\n\n        super(ModelNet40PointClouds, self).__init__(\n            root_dir, self.cates, tr_sample_size=tr_sample_size,\n            te_sample_size=te_sample_size, split=split, scale=scale,\n            normalize_per_shape=normalize_per_shape,\n            normalize_std_per_axis=normalize_std_per_axis,\n            random_subsample=random_subsample,\n            all_points_mean=all_points_mean, all_points_std=all_points_std,\n            input_dim=3)\n\n\nclass ModelNet10PointClouds(Uniform15KPC):\n    def __init__(self, root_dir=""data/ModelNet10.PC15k"",\n                 tr_sample_size=10000, te_sample_size=2048,\n                 split=\'train\', scale=1., normalize_per_shape=False,\n                 normalize_std_per_axis=False,\n                 random_subsample=False,\n                 all_points_mean=None, all_points_std=None):\n        self.root_dir = root_dir\n        self.split = split\n        assert self.split in [\'train\', \'test\']\n        self.cates = []\n        for cate in os.listdir(root_dir):\n            if os.path.isdir(os.path.join(root_dir, cate)) \\\n                    and os.path.isdir(os.path.join(root_dir, cate, \'train\')) \\\n                    and os.path.isdir(os.path.join(root_dir, cate, \'test\')):\n                self.cates.append(cate)\n        assert len(self.cates) == 10\n\n        # That\'s prealigned MN\n        # self.gravity_axis = 0\n        # self.display_axis_order = [0,1,2]\n\n        # Aligned MN has same axis-order as SN\n        self.gravity_axis = 1\n        self.display_axis_order = [0, 2, 1]\n\n        super(ModelNet10PointClouds, self).__init__(\n            root_dir, self.cates, tr_sample_size=tr_sample_size,\n            te_sample_size=te_sample_size, split=split, scale=scale,\n            normalize_per_shape=normalize_per_shape,\n            normalize_std_per_axis=normalize_std_per_axis,\n            random_subsample=random_subsample,\n            all_points_mean=all_points_mean, all_points_std=all_points_std,\n            input_dim=3)\n\n\nclass ShapeNet15kPointClouds(Uniform15KPC):\n    def __init__(self, root_dir=""data/ShapeNetCore.v2.PC15k"",\n                 categories=[\'airplane\'], tr_sample_size=10000, te_sample_size=2048,\n                 split=\'train\', scale=1., normalize_per_shape=False,\n                 normalize_std_per_axis=False,\n                 random_subsample=False,\n                 all_points_mean=None, all_points_std=None):\n        self.root_dir = root_dir\n        self.split = split\n        assert self.split in [\'train\', \'test\', \'val\']\n        self.tr_sample_size = tr_sample_size\n        self.te_sample_size = te_sample_size\n        self.cates = categories\n        if \'all\' in categories:\n            self.synset_ids = list(cate_to_synsetid.values())\n        else:\n            self.synset_ids = [cate_to_synsetid[c] for c in self.cates]\n\n        # assert \'v2\' in root_dir, ""Only supporting v2 right now.""\n        self.gravity_axis = 1\n        self.display_axis_order = [0, 2, 1]\n\n        super(ShapeNet15kPointClouds, self).__init__(\n            root_dir, self.synset_ids,\n            tr_sample_size=tr_sample_size,\n            te_sample_size=te_sample_size,\n            split=split, scale=scale,\n            normalize_per_shape=normalize_per_shape,\n            normalize_std_per_axis=normalize_std_per_axis,\n            random_subsample=random_subsample,\n            all_points_mean=all_points_mean, all_points_std=all_points_std,\n            input_dim=3)\n\n\ndef init_np_seed(worker_id):\n    seed = torch.initial_seed()\n    np.random.seed(seed % 4294967296)\n\n\ndef _get_MN40_datasets_(args, data_dir=None):\n    tr_dataset = ModelNet40PointClouds(\n        split=\'train\',\n        tr_sample_size=args.tr_max_sample_points,\n        te_sample_size=args.te_max_sample_points,\n        root_dir=(args.data_dir if data_dir is None else data_dir),\n        normalize_per_shape=args.normalize_per_shape,\n        normalize_std_per_axis=args.normalize_std_per_axis,\n        random_subsample=True)\n    te_dataset = ModelNet40PointClouds(\n        split=\'test\',\n        tr_sample_size=args.tr_max_sample_points,\n        te_sample_size=args.te_max_sample_points,\n        root_dir=(args.data_dir if data_dir is None else data_dir),\n        normalize_per_shape=args.normalize_per_shape,\n        normalize_std_per_axis=args.normalize_std_per_axis,\n        all_points_mean=tr_dataset.all_points_mean,\n        all_points_std=tr_dataset.all_points_std,\n    )\n\n    return tr_dataset, te_dataset\n\n\ndef _get_MN10_datasets_(args, data_dir=None):\n    tr_dataset = ModelNet10PointClouds(\n        split=\'train\',\n        tr_sample_size=args.tr_max_sample_points,\n        te_sample_size=args.te_max_sample_points,\n        root_dir=(args.data_dir if data_dir is None else data_dir),\n        normalize_per_shape=args.normalize_per_shape,\n        normalize_std_per_axis=args.normalize_std_per_axis,\n        random_subsample=True)\n    te_dataset = ModelNet10PointClouds(\n        split=\'test\',\n        tr_sample_size=args.tr_max_sample_points,\n        te_sample_size=args.te_max_sample_points,\n        root_dir=(args.data_dir if data_dir is None else data_dir),\n        normalize_per_shape=args.normalize_per_shape,\n        normalize_std_per_axis=args.normalize_std_per_axis,\n        all_points_mean=tr_dataset.all_points_mean,\n        all_points_std=tr_dataset.all_points_std,\n    )\n    return tr_dataset, te_dataset\n\n\ndef get_datasets(args):\n    if args.dataset_type == \'shapenet15k\':\n        tr_dataset = ShapeNet15kPointClouds(\n            categories=args.cates, split=\'train\',\n            tr_sample_size=args.tr_max_sample_points,\n            te_sample_size=args.te_max_sample_points,\n            scale=args.dataset_scale, root_dir=args.data_dir,\n            normalize_per_shape=args.normalize_per_shape,\n            normalize_std_per_axis=args.normalize_std_per_axis,\n            random_subsample=True)\n        te_dataset = ShapeNet15kPointClouds(\n            categories=args.cates, split=\'val\',\n            tr_sample_size=args.tr_max_sample_points,\n            te_sample_size=args.te_max_sample_points,\n            scale=args.dataset_scale, root_dir=args.data_dir,\n            normalize_per_shape=args.normalize_per_shape,\n            normalize_std_per_axis=args.normalize_std_per_axis,\n            all_points_mean=tr_dataset.all_points_mean,\n            all_points_std=tr_dataset.all_points_std,\n        )\n    elif args.dataset_type == \'modelnet40_15k\':\n        tr_dataset, te_dataset = _get_MN40_datasets_(args)\n    elif args.dataset_type == \'modelnet10_15k\':\n        tr_dataset, te_dataset = _get_MN10_datasets_(args)\n    else:\n        raise Exception(""Invalid dataset type:%s"" % args.dataset_type)\n\n    return tr_dataset, te_dataset\n\n\ndef get_clf_datasets(args):\n    return {\n        \'MN40\': _get_MN40_datasets_(args, data_dir=args.mn40_data_dir),\n        \'MN10\': _get_MN10_datasets_(args, data_dir=args.mn10_data_dir),\n    }\n\n\ndef get_data_loaders(args):\n    tr_dataset, te_dataset = get_datasets(args)\n    train_loader = data.DataLoader(\n        dataset=tr_dataset, batch_size=args.batch_size,\n        shuffle=True, num_workers=args.num_workers, drop_last=True,\n        worker_init_fn=init_np_seed)\n    train_unshuffle_loader = data.DataLoader(\n        dataset=tr_dataset, batch_size=args.batch_size,\n        shuffle=False, num_workers=args.num_workers, drop_last=True,\n        worker_init_fn=init_np_seed)\n    test_loader = data.DataLoader(\n        dataset=te_dataset, batch_size=args.batch_size,\n        shuffle=False, num_workers=args.num_workers, drop_last=False,\n        worker_init_fn=init_np_seed)\n\n    loaders = {\n        ""test_loader"": test_loader,\n        \'train_loader\': train_loader,\n        \'train_unshuffle_loader\': train_unshuffle_loader,\n    }\n    return loaders\n\n\nif __name__ == ""__main__"":\n    shape_ds = ShapeNet15kPointClouds(categories=[\'airplane\'], split=\'val\')\n    x_tr, x_te = next(iter(shape_ds))\n    print(x_tr.shape)\n    print(x_te.shape)\n\n'"
demo.py,6,"b'import open3d as o3d\nfrom datasets import get_datasets\nfrom args import get_args\nfrom models.networks import PointFlow\nimport os\nimport torch\nimport numpy as np\nimport torch.nn as nn\n\n\ndef main(args):\n    model = PointFlow(args)\n\n    def _transform_(m):\n        return nn.DataParallel(m)\n\n    model = model.cuda()\n    model.multi_gpu_wrapper(_transform_)\n\n    print(""Resume Path:%s"" % args.resume_checkpoint)\n    checkpoint = torch.load(args.resume_checkpoint)\n    model.load_state_dict(checkpoint)\n    model.eval()\n\n    _, te_dataset = get_datasets(args)\n    if args.resume_dataset_mean is not None and args.resume_dataset_std is not None:\n        mean = np.load(args.resume_dataset_mean)\n        std = np.load(args.resume_dataset_std)\n        te_dataset.renormalize(mean, std)\n    ds_mean = torch.from_numpy(te_dataset.all_points_mean).cuda()\n    ds_std = torch.from_numpy(te_dataset.all_points_std).cuda()\n\n    all_sample = []\n    with torch.no_grad():\n        for i in range(0, args.num_sample_shapes, args.batch_size):\n            B = len(range(i, min(i + args.batch_size, args.num_sample_shapes)))\n            N = args.num_sample_points\n            _, out_pc = model.sample(B, N)\n            out_pc = out_pc * ds_std + ds_mean\n            all_sample.append(out_pc)\n\n    sample_pcs = torch.cat(all_sample, dim=0).cpu().detach().numpy()\n    print(""Generation sample size:(%s, %s, %s)"" % sample_pcs.shape)\n\n    # Save the generative output\n    os.makedirs(""demo"", exist_ok=True)\n    np.save(os.path.join(""demo"", ""model_out_smp.npy""), sample_pcs)\n\n    # Visualize the demo\n    pcl = o3d.geometry.PointCloud()\n    for i in range(int(sample_pcs.shape[0])):\n        print(""Visualizing: %03d/%03d"" % (i, sample_pcs.shape[0]))\n        pts = sample_pcs[i].reshape(-1, 3)\n        pcl.points = o3d.utility.Vector3dVector(pts)\n        o3d.visualization.draw_geometries([pcl])\n\n\nif __name__ == \'__main__\':\n    args = get_args()\n    main(args)\n'"
test.py,8,"b'from datasets import get_datasets, synsetid_to_cate\nfrom args import get_args\nfrom pprint import pprint\nfrom metrics.evaluation_metrics import EMD_CD\nfrom metrics.evaluation_metrics import jsd_between_point_cloud_sets as JSD\nfrom metrics.evaluation_metrics import compute_all_metrics\nfrom collections import defaultdict\nfrom models.networks import PointFlow\nimport os\nimport torch\nimport numpy as np\nimport torch.nn as nn\n\n\ndef get_test_loader(args):\n    _, te_dataset = get_datasets(args)\n    if args.resume_dataset_mean is not None and args.resume_dataset_std is not None:\n        mean = np.load(args.resume_dataset_mean)\n        std = np.load(args.resume_dataset_std)\n        te_dataset.renormalize(mean, std)\n    loader = torch.utils.data.DataLoader(\n        dataset=te_dataset, batch_size=args.batch_size, shuffle=False,\n        num_workers=0, pin_memory=True, drop_last=False)\n    return loader\n\n\ndef evaluate_recon(model, args):\n    # TODO: make this memory efficient\n    if \'all\' in args.cates:\n        cates = list(synsetid_to_cate.values())\n    else:\n        cates = args.cates\n    all_results = {}\n    cate_to_len = {}\n    save_dir = os.path.dirname(args.resume_checkpoint)\n    for cate in cates:\n        args.cates = [cate]\n        loader = get_test_loader(args)\n\n        all_sample = []\n        all_ref = []\n        for data in loader:\n            idx_b, tr_pc, te_pc = data[\'idx\'], data[\'train_points\'], data[\'test_points\']\n            te_pc = te_pc.cuda() if args.gpu is None else te_pc.cuda(args.gpu)\n            tr_pc = tr_pc.cuda() if args.gpu is None else tr_pc.cuda(args.gpu)\n            B, N = te_pc.size(0), te_pc.size(1)\n            out_pc = model.reconstruct(tr_pc, num_points=N)\n            m, s = data[\'mean\'].float(), data[\'std\'].float()\n            m = m.cuda() if args.gpu is None else m.cuda(args.gpu)\n            s = s.cuda() if args.gpu is None else s.cuda(args.gpu)\n            out_pc = out_pc * s + m\n            te_pc = te_pc * s + m\n\n            all_sample.append(out_pc)\n            all_ref.append(te_pc)\n\n        sample_pcs = torch.cat(all_sample, dim=0)\n        ref_pcs = torch.cat(all_ref, dim=0)\n        cate_to_len[cate] = int(sample_pcs.size(0))\n        print(""Cate=%s Total Sample size:%s Ref size: %s""\n              % (cate, sample_pcs.size(), ref_pcs.size()))\n\n        # Save it\n        np.save(os.path.join(save_dir, ""%s_out_smp.npy"" % cate),\n                sample_pcs.cpu().detach().numpy())\n        np.save(os.path.join(save_dir, ""%s_out_ref.npy"" % cate),\n                ref_pcs.cpu().detach().numpy())\n\n        results = EMD_CD(sample_pcs, ref_pcs, args.batch_size, accelerated_cd=True)\n        results = {\n            k: (v.cpu().detach().item() if not isinstance(v, float) else v)\n            for k, v in results.items()}\n        pprint(results)\n        all_results[cate] = results\n\n    # Save final results\n    print(""=""*80)\n    print(""All category results:"")\n    print(""=""*80)\n    pprint(all_results)\n    save_path = os.path.join(save_dir, ""percate_results.npy"")\n    np.save(save_path, all_results)\n\n    # Compute weighted performance\n    ttl_r, ttl_cnt = defaultdict(lambda: 0.), defaultdict(lambda: 0.)\n    for catename, l in cate_to_len.items():\n        for k, v in all_results[catename].items():\n            ttl_r[k] += v * float(l)\n            ttl_cnt[k] += float(l)\n    ttl_res = {k: (float(ttl_r[k]) / float(ttl_cnt[k])) for k in ttl_r.keys()}\n    print(""=""*80)\n    print(""Averaged results:"")\n    pprint(ttl_res)\n    print(""=""*80)\n\n    save_path = os.path.join(save_dir, ""results.npy"")\n    np.save(save_path, all_results)\n\n\ndef evaluate_gen(model, args):\n    loader = get_test_loader(args)\n    all_sample = []\n    all_ref = []\n    for data in loader:\n        idx_b, te_pc = data[\'idx\'], data[\'test_points\']\n        te_pc = te_pc.cuda() if args.gpu is None else te_pc.cuda(args.gpu)\n        B, N = te_pc.size(0), te_pc.size(1)\n        _, out_pc = model.sample(B, N)\n\n        # denormalize\n        m, s = data[\'mean\'].float(), data[\'std\'].float()\n        m = m.cuda() if args.gpu is None else m.cuda(args.gpu)\n        s = s.cuda() if args.gpu is None else s.cuda(args.gpu)\n        out_pc = out_pc * s + m\n        te_pc = te_pc * s + m\n\n        all_sample.append(out_pc)\n        all_ref.append(te_pc)\n\n    sample_pcs = torch.cat(all_sample, dim=0)\n    ref_pcs = torch.cat(all_ref, dim=0)\n    print(""Generation sample size:%s reference size: %s""\n          % (sample_pcs.size(), ref_pcs.size()))\n\n    # Save the generative output\n    save_dir = os.path.dirname(args.resume_checkpoint)\n    np.save(os.path.join(save_dir, ""model_out_smp.npy""), sample_pcs.cpu().detach().numpy())\n    np.save(os.path.join(save_dir, ""model_out_ref.npy""), ref_pcs.cpu().detach().numpy())\n\n    # Compute metrics\n    results = compute_all_metrics(sample_pcs, ref_pcs, args.batch_size, accelerated_cd=True)\n    results = {k: (v.cpu().detach().item()\n                   if not isinstance(v, float) else v) for k, v in results.items()}\n    pprint(results)\n\n    sample_pcl_npy = sample_pcs.cpu().detach().numpy()\n    ref_pcl_npy = ref_pcs.cpu().detach().numpy()\n    jsd = JSD(sample_pcl_npy, ref_pcl_npy)\n    print(""JSD:%s"" % jsd)\n\n\ndef main(args):\n    model = PointFlow(args)\n\n    def _transform_(m):\n        return nn.DataParallel(m)\n\n    model = model.cuda()\n    model.multi_gpu_wrapper(_transform_)\n\n    print(""Resume Path:%s"" % args.resume_checkpoint)\n    checkpoint = torch.load(args.resume_checkpoint)\n    model.load_state_dict(checkpoint)\n    model.eval()\n\n    with torch.no_grad():\n        if args.evaluate_recon:\n            # Evaluate reconstruction\n            evaluate_recon(model, args)\n        else:\n            # Evaluate generation\n            evaluate_gen(model, args)\n\n\nif __name__ == \'__main__\':\n    args = get_args()\n    main(args)\n'"
train.py,14,"b'import sys\r\nimport os\r\nimport torch\r\nimport torch.distributed as dist\r\nimport torch.nn as nn\r\nimport warnings\r\nimport torch.distributed\r\nimport numpy as np\r\nimport random\r\nimport faulthandler\r\nimport torch.multiprocessing as mp\r\nimport time\r\nimport scipy.misc\r\nfrom models.networks import PointFlow\r\nfrom torch import optim\r\nfrom args import get_args\r\nfrom torch.backends import cudnn\r\nfrom utils import AverageValueMeter, set_random_seed, apply_random_rotation, save, resume, visualize_point_clouds\r\nfrom tensorboardX import SummaryWriter\r\nfrom datasets import get_datasets, init_np_seed\r\n\r\nfaulthandler.enable()\r\n\r\n\r\ndef main_worker(gpu, save_dir, ngpus_per_node, args):\r\n    # basic setup\r\n    cudnn.benchmark = True\r\n    args.gpu = gpu\r\n    if args.gpu is not None:\r\n        print(""Use GPU: {} for training"".format(args.gpu))\r\n\r\n    if args.distributed:\r\n        if args.dist_url == ""env://"" and args.rank == -1:\r\n            args.rank = int(os.environ[""RANK""])\r\n        if args.distributed:\r\n            args.rank = args.rank * ngpus_per_node + gpu\r\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\r\n                                world_size=args.world_size, rank=args.rank)\r\n\r\n    if args.log_name is not None:\r\n        log_dir = ""runs/%s"" % args.log_name\r\n    else:\r\n        log_dir = ""runs/time-%d"" % time.time()\r\n\r\n    if not args.distributed or (args.rank % ngpus_per_node == 0):\r\n        writer = SummaryWriter(logdir=log_dir)\r\n    else:\r\n        writer = None\r\n\r\n    if not args.use_latent_flow:  # auto-encoder only\r\n        args.prior_weight = 0\r\n        args.entropy_weight = 0\r\n\r\n    # multi-GPU setup\r\n    model = PointFlow(args)\r\n    if args.distributed:  # Multiple processes, single GPU per process\r\n        if args.gpu is not None:\r\n            def _transform_(m):\r\n                return nn.parallel.DistributedDataParallel(\r\n                    m, device_ids=[args.gpu], output_device=args.gpu, check_reduction=True)\r\n\r\n            torch.cuda.set_device(args.gpu)\r\n            model.cuda(args.gpu)\r\n            model.multi_gpu_wrapper(_transform_)\r\n            args.batch_size = int(args.batch_size / ngpus_per_node)\r\n            args.workers = 0\r\n        else:\r\n            assert 0, ""DistributedDataParallel constructor should always set the single device scope""\r\n    elif args.gpu is not None:  # Single process, single GPU per process\r\n        torch.cuda.set_device(args.gpu)\r\n        model = model.cuda(args.gpu)\r\n    else:  # Single process, multiple GPUs per process\r\n        def _transform_(m):\r\n            return nn.DataParallel(m)\r\n        model = model.cuda()\r\n        model.multi_gpu_wrapper(_transform_)\r\n\r\n    # resume checkpoints\r\n    start_epoch = 0\r\n    optimizer = model.make_optimizer(args)\r\n    if args.resume_checkpoint is None and os.path.exists(os.path.join(save_dir, \'checkpoint-latest.pt\')):\r\n        args.resume_checkpoint = os.path.join(save_dir, \'checkpoint-latest.pt\')  # use the latest checkpoint\r\n    if args.resume_checkpoint is not None:\r\n        if args.resume_optimizer:\r\n            model, optimizer, start_epoch = resume(\r\n                args.resume_checkpoint, model, optimizer, strict=(not args.resume_non_strict))\r\n        else:\r\n            model, _, start_epoch = resume(\r\n                args.resume_checkpoint, model, optimizer=None, strict=(not args.resume_non_strict))\r\n        print(\'Resumed from: \' + args.resume_checkpoint)\r\n\r\n    # initialize datasets and loaders\r\n    tr_dataset, te_dataset = get_datasets(args)\r\n    if args.distributed:\r\n        train_sampler = torch.utils.data.distributed.DistributedSampler(tr_dataset)\r\n    else:\r\n        train_sampler = None\r\n\r\n    train_loader = torch.utils.data.DataLoader(\r\n        dataset=tr_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\r\n        num_workers=0, pin_memory=True, sampler=train_sampler, drop_last=True,\r\n        worker_init_fn=init_np_seed)\r\n    test_loader = torch.utils.data.DataLoader(\r\n        dataset=te_dataset, batch_size=args.batch_size, shuffle=False,\r\n        num_workers=0, pin_memory=True, drop_last=False,\r\n        worker_init_fn=init_np_seed)\r\n\r\n    # save dataset statistics\r\n    if not args.distributed or (args.rank % ngpus_per_node == 0):\r\n        np.save(os.path.join(save_dir, ""train_set_mean.npy""), tr_dataset.all_points_mean)\r\n        np.save(os.path.join(save_dir, ""train_set_std.npy""), tr_dataset.all_points_std)\r\n        np.save(os.path.join(save_dir, ""train_set_idx.npy""), np.array(tr_dataset.shuffle_idx))\r\n        np.save(os.path.join(save_dir, ""val_set_mean.npy""), te_dataset.all_points_mean)\r\n        np.save(os.path.join(save_dir, ""val_set_std.npy""), te_dataset.all_points_std)\r\n        np.save(os.path.join(save_dir, ""val_set_idx.npy""), np.array(te_dataset.shuffle_idx))\r\n\r\n    # load classification dataset if needed\r\n    if args.eval_classification:\r\n        from datasets import get_clf_datasets\r\n\r\n        def _make_data_loader_(dataset):\r\n            return torch.utils.data.DataLoader(\r\n                dataset=dataset, batch_size=args.batch_size, shuffle=False,\r\n                num_workers=0, pin_memory=True, drop_last=False,\r\n                worker_init_fn=init_np_seed\r\n            )\r\n\r\n        clf_datasets = get_clf_datasets(args)\r\n        clf_loaders = {\r\n            k: [_make_data_loader_(ds) for ds in ds_lst] for k, ds_lst in clf_datasets.items()\r\n        }\r\n    else:\r\n        clf_loaders = None\r\n\r\n    # initialize the learning rate scheduler\r\n    if args.scheduler == \'exponential\':\r\n        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, args.exp_decay)\r\n    elif args.scheduler == \'step\':\r\n        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.epochs // 2, gamma=0.1)\r\n    elif args.scheduler == \'linear\':\r\n        def lambda_rule(ep):\r\n            lr_l = 1.0 - max(0, ep - 0.5 * args.epochs) / float(0.5 * args.epochs)\r\n            return lr_l\r\n        scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\r\n    else:\r\n        assert 0, ""args.schedulers should be either \'exponential\' or \'linear\'""\r\n\r\n    # main training loop\r\n    start_time = time.time()\r\n    entropy_avg_meter = AverageValueMeter()\r\n    latent_nats_avg_meter = AverageValueMeter()\r\n    point_nats_avg_meter = AverageValueMeter()\r\n    if args.distributed:\r\n        print(""[Rank %d] World size : %d"" % (args.rank, dist.get_world_size()))\r\n\r\n    print(""Start epoch: %d End epoch: %d"" % (start_epoch, args.epochs))\r\n    for epoch in range(start_epoch, args.epochs):\r\n        if args.distributed:\r\n            train_sampler.set_epoch(epoch)\r\n\r\n        # adjust the learning rate\r\n        if (epoch + 1) % args.exp_decay_freq == 0:\r\n            scheduler.step(epoch=epoch)\r\n            if writer is not None:\r\n                writer.add_scalar(\'lr/optimizer\', scheduler.get_lr()[0], epoch)\r\n\r\n        # train for one epoch\r\n        for bidx, data in enumerate(train_loader):\r\n            idx_batch, tr_batch, te_batch = data[\'idx\'], data[\'train_points\'], data[\'test_points\']\r\n            step = bidx + len(train_loader) * epoch\r\n            model.train()\r\n            if args.random_rotate:\r\n                tr_batch, _, _ = apply_random_rotation(\r\n                    tr_batch, rot_axis=train_loader.dataset.gravity_axis)\r\n            inputs = tr_batch.cuda(args.gpu, non_blocking=True)\r\n            out = model(inputs, optimizer, step, writer)\r\n            entropy, prior_nats, recon_nats = out[\'entropy\'], out[\'prior_nats\'], out[\'recon_nats\']\r\n            entropy_avg_meter.update(entropy)\r\n            point_nats_avg_meter.update(recon_nats)\r\n            latent_nats_avg_meter.update(prior_nats)\r\n            if step % args.log_freq == 0:\r\n                duration = time.time() - start_time\r\n                start_time = time.time()\r\n                print(""[Rank %d] Epoch %d Batch [%2d/%2d] Time [%3.2fs] Entropy %2.5f LatentNats %2.5f PointNats %2.5f""\r\n                      % (args.rank, epoch, bidx, len(train_loader), duration, entropy_avg_meter.avg,\r\n                         latent_nats_avg_meter.avg, point_nats_avg_meter.avg))\r\n\r\n        # evaluate on the validation set\r\n        if not args.no_validation and (epoch + 1) % args.val_freq == 0:\r\n            from utils import validate\r\n            validate(test_loader, model, epoch, writer, save_dir, args, clf_loaders=clf_loaders)\r\n\r\n        # save visualizations\r\n        if (epoch + 1) % args.viz_freq == 0:\r\n            # reconstructions\r\n            model.eval()\r\n            samples = model.reconstruct(inputs)\r\n            results = []\r\n            for idx in range(min(10, inputs.size(0))):\r\n                res = visualize_point_clouds(samples[idx], inputs[idx], idx,\r\n                                             pert_order=train_loader.dataset.display_axis_order)\r\n                results.append(res)\r\n            res = np.concatenate(results, axis=1)\r\n            scipy.misc.imsave(os.path.join(save_dir, \'images\', \'tr_vis_conditioned_epoch%d-gpu%s.png\' % (epoch, args.gpu)),\r\n                              res.transpose((1, 2, 0)))\r\n            if writer is not None:\r\n                writer.add_image(\'tr_vis/conditioned\', torch.as_tensor(res), epoch)\r\n\r\n            # samples\r\n            if args.use_latent_flow:\r\n                num_samples = min(10, inputs.size(0))\r\n                num_points = inputs.size(1)\r\n                _, samples = model.sample(num_samples, num_points)\r\n                results = []\r\n                for idx in range(num_samples):\r\n                    res = visualize_point_clouds(samples[idx], inputs[idx], idx,\r\n                                                 pert_order=train_loader.dataset.display_axis_order)\r\n                    results.append(res)\r\n                res = np.concatenate(results, axis=1)\r\n                scipy.misc.imsave(os.path.join(save_dir, \'images\', \'tr_vis_conditioned_epoch%d-gpu%s.png\' % (epoch, args.gpu)),\r\n                                  res.transpose((1, 2, 0)))\r\n                if writer is not None:\r\n                    writer.add_image(\'tr_vis/sampled\', torch.as_tensor(res), epoch)\r\n\r\n        # save checkpoints\r\n        if not args.distributed or (args.rank % ngpus_per_node == 0):\r\n            if (epoch + 1) % args.save_freq == 0:\r\n                save(model, optimizer, epoch + 1,\r\n                     os.path.join(save_dir, \'checkpoint-%d.pt\' % epoch))\r\n                save(model, optimizer, epoch + 1,\r\n                     os.path.join(save_dir, \'checkpoint-latest.pt\'))\r\n\r\n\r\ndef main():\r\n    # command line args\r\n    args = get_args()\r\n    save_dir = os.path.join(""checkpoints"", args.log_name)\r\n    if not os.path.exists(save_dir):\r\n        os.makedirs(save_dir)\r\n        os.makedirs(os.path.join(save_dir, \'images\'))\r\n\r\n    with open(os.path.join(save_dir, \'command.sh\'), \'w\') as f:\r\n        f.write(\'python -X faulthandler \' + \' \'.join(sys.argv))\r\n        f.write(\'\\n\')\r\n\r\n    if args.seed is None:\r\n        args.seed = random.randint(0, 1000000)\r\n    set_random_seed(args.seed)\r\n\r\n    if args.gpu is not None:\r\n        warnings.warn(\'You have chosen a specific GPU. This will completely \'\r\n                      \'disable data parallelism.\')\r\n\r\n    if args.dist_url == ""env://"" and args.world_size == -1:\r\n        args.world_size = int(os.environ[""WORLD_SIZE""])\r\n\r\n    if args.sync_bn:\r\n        assert args.distributed\r\n\r\n    print(""Arguments:"")\r\n    print(args)\r\n\r\n    ngpus_per_node = torch.cuda.device_count()\r\n    if args.distributed:\r\n        args.world_size = ngpus_per_node * args.world_size\r\n        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(save_dir, ngpus_per_node, args))\r\n    else:\r\n        main_worker(args.gpu, save_dir, ngpus_per_node, args)\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\r\n'"
utils.py,26,"b'from pprint import pprint\r\nfrom sklearn.svm import LinearSVC\r\nfrom math import log, pi\r\nimport os\r\nimport torch\r\nimport torch.distributed as dist\r\nimport random\r\nimport numpy as np\r\nimport matplotlib\r\nmatplotlib.use(\'Agg\')\r\nimport matplotlib.pyplot as plt\r\nfrom mpl_toolkits.mplot3d import Axes3D\r\n\r\n\r\nclass AverageValueMeter(object):\r\n    """"""Computes and stores the average and current value""""""\r\n\r\n    def __init__(self):\r\n        self.val = 0\r\n        self.avg = 0\r\n        self.sum = 0\r\n        self.count = 0.0\r\n\r\n    def reset(self):\r\n        self.val = 0\r\n        self.avg = 0\r\n        self.sum = 0\r\n        self.count = 0.0\r\n\r\n    def update(self, val, n=1):\r\n        self.val = val\r\n        self.sum += val * n\r\n        self.count += n\r\n        self.avg = self.sum / self.count\r\n\r\n\r\ndef gaussian_log_likelihood(x, mean, logvar, clip=True):\r\n    if clip:\r\n        logvar = torch.clamp(logvar, min=-4, max=3)\r\n    a = log(2 * pi)\r\n    b = logvar\r\n    c = (x - mean) ** 2 / torch.exp(logvar)\r\n    return -0.5 * torch.sum(a + b + c)\r\n\r\n\r\ndef bernoulli_log_likelihood(x, p, clip=True, eps=1e-6):\r\n    if clip:\r\n        p = torch.clamp(p, min=eps, max=1 - eps)\r\n    return torch.sum((x * torch.log(p)) + ((1 - x) * torch.log(1 - p)))\r\n\r\n\r\ndef kl_diagnormal_stdnormal(mean, logvar):\r\n    a = mean ** 2\r\n    b = torch.exp(logvar)\r\n    c = -1\r\n    d = -logvar\r\n    return 0.5 * torch.sum(a + b + c + d)\r\n\r\n\r\ndef kl_diagnormal_diagnormal(q_mean, q_logvar, p_mean, p_logvar):\r\n    # Ensure correct shapes since no numpy broadcasting yet\r\n    p_mean = p_mean.expand_as(q_mean)\r\n    p_logvar = p_logvar.expand_as(q_logvar)\r\n\r\n    a = p_logvar\r\n    b = - 1\r\n    c = - q_logvar\r\n    d = ((q_mean - p_mean) ** 2 + torch.exp(q_logvar)) / torch.exp(p_logvar)\r\n    return 0.5 * torch.sum(a + b + c + d)\r\n\r\n\r\n# Taken from https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/15\r\ndef truncated_normal(tensor, mean=0, std=1, trunc_std=2):\r\n    size = tensor.shape\r\n    tmp = tensor.new_empty(size + (4,)).normal_()\r\n    valid = (tmp < trunc_std) & (tmp > -trunc_std)\r\n    ind = valid.max(-1, keepdim=True)[1]\r\n    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\r\n    tensor.data.mul_(std).add_(mean)\r\n    return tensor\r\n\r\n\r\ndef reduce_tensor(tensor, world_size=None):\r\n    rt = tensor.clone()\r\n    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\r\n    if world_size is None:\r\n        world_size = dist.get_world_size()\r\n\r\n    rt /= world_size\r\n    return rt\r\n\r\n\r\ndef standard_normal_logprob(z):\r\n    dim = z.size(-1)\r\n    log_z = -0.5 * dim * log(2 * pi)\r\n    return log_z - z.pow(2) / 2\r\n\r\n\r\ndef set_random_seed(seed):\r\n    """"""set random seed""""""\r\n    random.seed(seed)\r\n    np.random.seed(seed)\r\n    torch.manual_seed(seed)\r\n    torch.cuda.manual_seed(seed)\r\n    torch.cuda.manual_seed_all(seed)\r\n\r\n\r\n# Visualization\r\ndef visualize_point_clouds(pts, gtr, idx, pert_order=[0, 1, 2]):\r\n    pts = pts.cpu().detach().numpy()[:, pert_order]\r\n    gtr = gtr.cpu().detach().numpy()[:, pert_order]\r\n\r\n    fig = plt.figure(figsize=(6, 3))\r\n    ax1 = fig.add_subplot(121, projection=\'3d\')\r\n    ax1.set_title(""Sample:%s"" % idx)\r\n    ax1.scatter(pts[:, 0], pts[:, 1], pts[:, 2], s=5)\r\n\r\n    ax2 = fig.add_subplot(122, projection=\'3d\')\r\n    ax2.set_title(""Ground Truth:%s"" % idx)\r\n    ax2.scatter(gtr[:, 0], gtr[:, 1], gtr[:, 2], s=5)\r\n\r\n    fig.canvas.draw()\r\n\r\n    # grab the pixel buffer and dump it into a numpy array\r\n    res = np.array(fig.canvas.renderer._renderer)\r\n    res = np.transpose(res, (2, 0, 1))\r\n\r\n    plt.close()\r\n    return res\r\n\r\n\r\n# Augmentation\r\ndef apply_random_rotation(pc, rot_axis=1):\r\n    B = pc.shape[0]\r\n\r\n    theta = np.random.rand(B) * 2 * np.pi\r\n    zeros = np.zeros(B)\r\n    ones = np.ones(B)\r\n    cos = np.cos(theta)\r\n    sin = np.sin(theta)\r\n\r\n    if rot_axis == 0:\r\n        rot = np.stack([\r\n            cos, -sin, zeros,\r\n            sin, cos, zeros,\r\n            zeros, zeros, ones\r\n        ]).T.reshape(B, 3, 3)\r\n    elif rot_axis == 1:\r\n        rot = np.stack([\r\n            cos, zeros, -sin,\r\n            zeros, ones, zeros,\r\n            sin, zeros, cos\r\n        ]).T.reshape(B, 3, 3)\r\n    elif rot_axis == 2:\r\n        rot = np.stack([\r\n            ones, zeros, zeros,\r\n            zeros, cos, -sin,\r\n            zeros, sin, cos\r\n        ]).T.reshape(B, 3, 3)\r\n    else:\r\n        raise Exception(""Invalid rotation axis"")\r\n    rot = torch.from_numpy(rot).to(pc)\r\n\r\n    # (B, N, 3) mul (B, 3, 3) -> (B, N, 3)\r\n    pc_rotated = torch.bmm(pc, rot)\r\n    return pc_rotated, rot, theta\r\n\r\n\r\ndef validate_classification(loaders, model, args):\r\n    train_loader, test_loader = loaders\r\n\r\n    def _make_iter_(loader):\r\n        iterator = iter(loader)\r\n        return iterator\r\n\r\n    tr_latent = []\r\n    tr_label = []\r\n    for data in _make_iter_(train_loader):\r\n        tr_pc = data[\'train_points\']\r\n        tr_pc = tr_pc.cuda() if args.gpu is None else tr_pc.cuda(args.gpu)\r\n        latent = model.encode(tr_pc)\r\n        label = data[\'cate_idx\']\r\n        tr_latent.append(latent.cpu().detach().numpy())\r\n        tr_label.append(label.cpu().detach().numpy())\r\n    tr_label = np.concatenate(tr_label)\r\n    tr_latent = np.concatenate(tr_latent)\r\n\r\n    te_latent = []\r\n    te_label = []\r\n    for data in _make_iter_(test_loader):\r\n        tr_pc = data[\'train_points\']\r\n        tr_pc = tr_pc.cuda() if args.gpu is None else tr_pc.cuda(args.gpu)\r\n        latent = model.encode(tr_pc)\r\n        label = data[\'cate_idx\']\r\n        te_latent.append(latent.cpu().detach().numpy())\r\n        te_label.append(label.cpu().detach().numpy())\r\n    te_label = np.concatenate(te_label)\r\n    te_latent = np.concatenate(te_latent)\r\n\r\n    clf = LinearSVC(random_state=0)\r\n    clf.fit(tr_latent, tr_label)\r\n    test_pred = clf.predict(te_latent)\r\n    test_gt = te_label.flatten()\r\n    acc = np.mean((test_pred == test_gt).astype(float)) * 100.\r\n    res = {\'acc\': acc}\r\n    print(""Acc:%s"" % acc)\r\n    return res\r\n\r\n\r\ndef validate_conditioned(loader, model, args, max_samples=None, save_dir=None):\r\n    from metrics.evaluation_metrics import EMD_CD\r\n    all_idx = []\r\n    all_sample = []\r\n    all_ref = []\r\n    ttl_samples = 0\r\n    iterator = iter(loader)\r\n\r\n    for data in iterator:\r\n        # idx_b, tr_pc, te_pc = data[:3]\r\n        idx_b, tr_pc, te_pc = data[\'idx\'], data[\'train_points\'], data[\'test_points\']\r\n        tr_pc = tr_pc.cuda() if args.gpu is None else tr_pc.cuda(args.gpu)\r\n        te_pc = te_pc.cuda() if args.gpu is None else te_pc.cuda(args.gpu)\r\n\r\n        if tr_pc.size(1) > te_pc.size(1):\r\n            tr_pc = tr_pc[:, :te_pc.size(1), :]\r\n        out_pc = model.reconstruct(tr_pc, num_points=te_pc.size(1))\r\n\r\n        # denormalize\r\n        m, s = data[\'mean\'].float(), data[\'std\'].float()\r\n        m = m.cuda() if args.gpu is None else m.cuda(args.gpu)\r\n        s = s.cuda() if args.gpu is None else s.cuda(args.gpu)\r\n        out_pc = out_pc * s + m\r\n        te_pc = te_pc * s + m\r\n\r\n        all_sample.append(out_pc)\r\n        all_ref.append(te_pc)\r\n        all_idx.append(idx_b)\r\n\r\n        ttl_samples += int(te_pc.size(0))\r\n        if max_samples is not None and ttl_samples >= max_samples:\r\n            break\r\n\r\n    # Compute MMD and CD\r\n    sample_pcs = torch.cat(all_sample, dim=0)\r\n    ref_pcs = torch.cat(all_ref, dim=0)\r\n    print(""[rank %s] Recon Sample size:%s Ref size: %s"" % (args.rank, sample_pcs.size(), ref_pcs.size()))\r\n\r\n    if save_dir is not None and args.save_val_results:\r\n        smp_pcs_save_name = os.path.join(save_dir, ""smp_recon_pcls_gpu%s.npy"" % args.gpu)\r\n        ref_pcs_save_name = os.path.join(save_dir, ""ref_recon_pcls_gpu%s.npy"" % args.gpu)\r\n        np.save(smp_pcs_save_name, sample_pcs.cpu().detach().numpy())\r\n        np.save(ref_pcs_save_name, ref_pcs.cpu().detach().numpy())\r\n        print(""Saving file:%s %s"" % (smp_pcs_save_name, ref_pcs_save_name))\r\n\r\n    res = EMD_CD(sample_pcs, ref_pcs, args.batch_size, accelerated_cd=True)\r\n    mmd_cd = res[\'MMD-CD\'] if \'MMD-CD\' in res else None\r\n    mmd_emd = res[\'MMD-EMD\'] if \'MMD-EMD\' in res else None\r\n\r\n    print(""MMD-CD  :%s"" % mmd_cd)\r\n    print(""MMD-EMD :%s"" % mmd_emd)\r\n\r\n    return res\r\n\r\n\r\ndef validate_sample(loader, model, args, max_samples=None, save_dir=None):\r\n    from metrics.evaluation_metrics import compute_all_metrics, jsd_between_point_cloud_sets as JSD\r\n    all_sample = []\r\n    all_ref = []\r\n    ttl_samples = 0\r\n\r\n    iterator = iter(loader)\r\n\r\n    for data in iterator:\r\n        idx_b, te_pc = data[\'idx\'], data[\'test_points\']\r\n        te_pc = te_pc.cuda() if args.gpu is None else te_pc.cuda(args.gpu)\r\n        _, out_pc = model.sample(te_pc.size(0), te_pc.size(1), gpu=args.gpu)\r\n\r\n        # denormalize\r\n        m, s = data[\'mean\'].float(), data[\'std\'].float()\r\n        m = m.cuda() if args.gpu is None else m.cuda(args.gpu)\r\n        s = s.cuda() if args.gpu is None else s.cuda(args.gpu)\r\n        out_pc = out_pc * s + m\r\n        te_pc = te_pc * s + m\r\n\r\n        all_sample.append(out_pc)\r\n        all_ref.append(te_pc)\r\n\r\n        ttl_samples += int(te_pc.size(0))\r\n        if max_samples is not None and ttl_samples >= max_samples:\r\n            break\r\n\r\n    sample_pcs = torch.cat(all_sample, dim=0)\r\n    ref_pcs = torch.cat(all_ref, dim=0)\r\n    print(""[rank %s] Generation Sample size:%s Ref size: %s""\r\n          % (args.rank, sample_pcs.size(), ref_pcs.size()))\r\n\r\n    if save_dir is not None and args.save_val_results:\r\n        smp_pcs_save_name = os.path.join(save_dir, ""smp_syn_pcls_gpu%s.npy"" % args.gpu)\r\n        ref_pcs_save_name = os.path.join(save_dir, ""ref_syn_pcls_gpu%s.npy"" % args.gpu)\r\n        np.save(smp_pcs_save_name, sample_pcs.cpu().detach().numpy())\r\n        np.save(ref_pcs_save_name, ref_pcs.cpu().detach().numpy())\r\n        print(""Saving file:%s %s"" % (smp_pcs_save_name, ref_pcs_save_name))\r\n\r\n    res = compute_all_metrics(sample_pcs, ref_pcs, args.batch_size, accelerated_cd=True)\r\n    pprint(res)\r\n\r\n    sample_pcs = sample_pcs.cpu().detach().numpy()\r\n    ref_pcs = ref_pcs.cpu().detach().numpy()\r\n    jsd = JSD(sample_pcs, ref_pcs)\r\n    jsd = torch.tensor(jsd).cuda() if args.gpu is None else torch.tensor(jsd).cuda(args.gpu)\r\n    res.update({""JSD"": jsd})\r\n    print(""JSD     :%s"" % jsd)\r\n    return res\r\n\r\n\r\ndef save(model, optimizer, epoch, path):\r\n    d = {\r\n        \'epoch\': epoch,\r\n        \'model\': model.state_dict(),\r\n        \'optimizer\': optimizer.state_dict()\r\n    }\r\n    torch.save(d, path)\r\n\r\n\r\ndef resume(path, model, optimizer=None, strict=True):\r\n    ckpt = torch.load(path)\r\n    model.load_state_dict(ckpt[\'model\'], strict=strict)\r\n    start_epoch = ckpt[\'epoch\']\r\n    if optimizer is not None:\r\n        optimizer.load_state_dict(ckpt[\'optimizer\'])\r\n    return model, optimizer, start_epoch\r\n\r\n\r\ndef validate(test_loader, model, epoch, writer, save_dir, args, clf_loaders=None):\r\n    model.eval()\r\n\r\n    # Make epoch wise save directory\r\n    if writer is not None and args.save_val_results:\r\n        save_dir = os.path.join(save_dir, \'epoch-%d\' % epoch)\r\n        if not os.path.isdir(save_dir):\r\n            os.makedirs(save_dir)\r\n    else:\r\n        save_dir = None\r\n\r\n    # classification\r\n    if args.eval_classification and clf_loaders is not None:\r\n        for clf_expr, loaders in clf_loaders.items():\r\n            with torch.no_grad():\r\n                clf_val_res = validate_classification(loaders, model, args)\r\n\r\n            for k, v in clf_val_res.items():\r\n                if writer is not None and v is not None:\r\n                    writer.add_scalar(\'val_%s/%s\' % (clf_expr, k), v, epoch)\r\n\r\n    # samples\r\n    if args.use_latent_flow:\r\n        with torch.no_grad():\r\n            val_sample_res = validate_sample(\r\n                test_loader, model, args, max_samples=args.max_validate_shapes,\r\n                save_dir=save_dir)\r\n\r\n        for k, v in val_sample_res.items():\r\n            if not isinstance(v, float):\r\n                v = v.cpu().detach().item()\r\n            if writer is not None and v is not None:\r\n                writer.add_scalar(\'val_sample/%s\' % k, v, epoch)\r\n\r\n    # reconstructions\r\n    with torch.no_grad():\r\n        val_res = validate_conditioned(\r\n            test_loader, model, args, max_samples=args.max_validate_shapes,\r\n            save_dir=save_dir)\r\n    for k, v in val_res.items():\r\n        if not isinstance(v, float):\r\n            v = v.cpu().detach().item()\r\n        if writer is not None and v is not None:\r\n            writer.add_scalar(\'val_conditioned/%s\' % k, v, epoch)\r\n\r\n'"
metrics/__init__.py,0,b''
metrics/evaluation_metrics.py,23,"b'import torch\nimport numpy as np\nimport warnings\nfrom scipy.stats import entropy\nfrom sklearn.neighbors import NearestNeighbors\nfrom numpy.linalg import norm\n\n# Import CUDA version of approximate EMD, from https://github.com/zekunhao1995/pcgan-pytorch/\nfrom .StructuralLosses.match_cost import match_cost\nfrom .StructuralLosses.nn_distance import nn_distance\n\n\n# # Import CUDA version of CD, borrowed from https://github.com/ThibaultGROUEIX/AtlasNet\n# try:\n#     from . chamfer_distance_ext.dist_chamfer import chamferDist\n#     CD = chamferDist()\n#     def distChamferCUDA(x,y):\n#         return CD(x,y,gpu)\n# except:\n\n\ndef distChamferCUDA(x, y):\n    return nn_distance(x, y)\n\n\ndef emd_approx(sample, ref):\n    B, N, N_ref = sample.size(0), sample.size(1), ref.size(1)\n    assert N == N_ref, ""Not sure what would EMD do in this case""\n    emd = match_cost(sample, ref)  # (B,)\n    emd_norm = emd / float(N)  # (B,)\n    return emd_norm\n\n\n# Borrow from https://github.com/ThibaultGROUEIX/AtlasNet\ndef distChamfer(a, b):\n    x, y = a, b\n    bs, num_points, points_dim = x.size()\n    xx = torch.bmm(x, x.transpose(2, 1))\n    yy = torch.bmm(y, y.transpose(2, 1))\n    zz = torch.bmm(x, y.transpose(2, 1))\n    diag_ind = torch.arange(0, num_points).to(a).long()\n    rx = xx[:, diag_ind, diag_ind].unsqueeze(1).expand_as(xx)\n    ry = yy[:, diag_ind, diag_ind].unsqueeze(1).expand_as(yy)\n    P = (rx.transpose(2, 1) + ry - 2 * zz)\n    return P.min(1)[0], P.min(2)[0]\n\n\ndef EMD_CD(sample_pcs, ref_pcs, batch_size, accelerated_cd=False, reduced=True):\n    N_sample = sample_pcs.shape[0]\n    N_ref = ref_pcs.shape[0]\n    assert N_sample == N_ref, ""REF:%d SMP:%d"" % (N_ref, N_sample)\n\n    cd_lst = []\n    emd_lst = []\n    iterator = range(0, N_sample, batch_size)\n\n    for b_start in iterator:\n        b_end = min(N_sample, b_start + batch_size)\n        sample_batch = sample_pcs[b_start:b_end]\n        ref_batch = ref_pcs[b_start:b_end]\n\n        if accelerated_cd:\n            dl, dr = distChamferCUDA(sample_batch, ref_batch)\n        else:\n            dl, dr = distChamfer(sample_batch, ref_batch)\n        cd_lst.append(dl.mean(dim=1) + dr.mean(dim=1))\n\n        emd_batch = emd_approx(sample_batch, ref_batch)\n        emd_lst.append(emd_batch)\n\n    if reduced:\n        cd = torch.cat(cd_lst).mean()\n        emd = torch.cat(emd_lst).mean()\n    else:\n        cd = torch.cat(cd_lst)\n        emd = torch.cat(emd_lst)\n\n    results = {\n        \'MMD-CD\': cd,\n        \'MMD-EMD\': emd,\n    }\n    return results\n\n\ndef _pairwise_EMD_CD_(sample_pcs, ref_pcs, batch_size, accelerated_cd=True):\n    N_sample = sample_pcs.shape[0]\n    N_ref = ref_pcs.shape[0]\n    all_cd = []\n    all_emd = []\n    iterator = range(N_sample)\n    for sample_b_start in iterator:\n        sample_batch = sample_pcs[sample_b_start]\n\n        cd_lst = []\n        emd_lst = []\n        for ref_b_start in range(0, N_ref, batch_size):\n            ref_b_end = min(N_ref, ref_b_start + batch_size)\n            ref_batch = ref_pcs[ref_b_start:ref_b_end]\n\n            batch_size_ref = ref_batch.size(0)\n            sample_batch_exp = sample_batch.view(1, -1, 3).expand(batch_size_ref, -1, -1)\n            sample_batch_exp = sample_batch_exp.contiguous()\n\n            if accelerated_cd:\n                dl, dr = distChamferCUDA(sample_batch_exp, ref_batch)\n            else:\n                dl, dr = distChamfer(sample_batch_exp, ref_batch)\n            cd_lst.append((dl.mean(dim=1) + dr.mean(dim=1)).view(1, -1))\n\n            emd_batch = emd_approx(sample_batch_exp, ref_batch)\n            emd_lst.append(emd_batch.view(1, -1))\n\n        cd_lst = torch.cat(cd_lst, dim=1)\n        emd_lst = torch.cat(emd_lst, dim=1)\n        all_cd.append(cd_lst)\n        all_emd.append(emd_lst)\n\n    all_cd = torch.cat(all_cd, dim=0)  # N_sample, N_ref\n    all_emd = torch.cat(all_emd, dim=0)  # N_sample, N_ref\n\n    return all_cd, all_emd\n\n\n# Adapted from https://github.com/xuqiantong/GAN-Metrics/blob/master/framework/metric.py\ndef knn(Mxx, Mxy, Myy, k, sqrt=False):\n    n0 = Mxx.size(0)\n    n1 = Myy.size(0)\n    label = torch.cat((torch.ones(n0), torch.zeros(n1))).to(Mxx)\n    M = torch.cat((torch.cat((Mxx, Mxy), 1), torch.cat((Mxy.transpose(0, 1), Myy), 1)), 0)\n    if sqrt:\n        M = M.abs().sqrt()\n    INFINITY = float(\'inf\')\n    val, idx = (M + torch.diag(INFINITY * torch.ones(n0 + n1).to(Mxx))).topk(k, 0, False)\n\n    count = torch.zeros(n0 + n1).to(Mxx)\n    for i in range(0, k):\n        count = count + label.index_select(0, idx[i])\n    pred = torch.ge(count, (float(k) / 2) * torch.ones(n0 + n1).to(Mxx)).float()\n\n    s = {\n        \'tp\': (pred * label).sum(),\n        \'fp\': (pred * (1 - label)).sum(),\n        \'fn\': ((1 - pred) * label).sum(),\n        \'tn\': ((1 - pred) * (1 - label)).sum(),\n    }\n\n    s.update({\n        \'precision\': s[\'tp\'] / (s[\'tp\'] + s[\'fp\'] + 1e-10),\n        \'recall\': s[\'tp\'] / (s[\'tp\'] + s[\'fn\'] + 1e-10),\n        \'acc_t\': s[\'tp\'] / (s[\'tp\'] + s[\'fn\'] + 1e-10),\n        \'acc_f\': s[\'tn\'] / (s[\'tn\'] + s[\'fp\'] + 1e-10),\n        \'acc\': torch.eq(label, pred).float().mean(),\n    })\n    return s\n\n\ndef lgan_mmd_cov(all_dist):\n    N_sample, N_ref = all_dist.size(0), all_dist.size(1)\n    min_val_fromsmp, min_idx = torch.min(all_dist, dim=1)\n    min_val, _ = torch.min(all_dist, dim=0)\n    mmd = min_val.mean()\n    mmd_smp = min_val_fromsmp.mean()\n    cov = float(min_idx.unique().view(-1).size(0)) / float(N_ref)\n    cov = torch.tensor(cov).to(all_dist)\n    return {\n        \'lgan_mmd\': mmd,\n        \'lgan_cov\': cov,\n        \'lgan_mmd_smp\': mmd_smp,\n    }\n\n\ndef compute_all_metrics(sample_pcs, ref_pcs, batch_size, accelerated_cd=False):\n    results = {}\n\n    M_rs_cd, M_rs_emd = _pairwise_EMD_CD_(ref_pcs, sample_pcs, batch_size, accelerated_cd=accelerated_cd)\n\n    res_cd = lgan_mmd_cov(M_rs_cd.t())\n    results.update({\n        ""%s-CD"" % k: v for k, v in res_cd.items()\n    })\n\n    res_emd = lgan_mmd_cov(M_rs_emd.t())\n    results.update({\n        ""%s-EMD"" % k: v for k, v in res_emd.items()\n    })\n\n    M_rr_cd, M_rr_emd = _pairwise_EMD_CD_(ref_pcs, ref_pcs, batch_size, accelerated_cd=accelerated_cd)\n    M_ss_cd, M_ss_emd = _pairwise_EMD_CD_(sample_pcs, sample_pcs, batch_size, accelerated_cd=accelerated_cd)\n\n    # 1-NN results\n    one_nn_cd_res = knn(M_rr_cd, M_rs_cd, M_ss_cd, 1, sqrt=False)\n    results.update({\n        ""1-NN-CD-%s"" % k: v for k, v in one_nn_cd_res.items() if \'acc\' in k\n    })\n    one_nn_emd_res = knn(M_rr_emd, M_rs_emd, M_ss_emd, 1, sqrt=False)\n    results.update({\n        ""1-NN-EMD-%s"" % k: v for k, v in one_nn_emd_res.items() if \'acc\' in k\n    })\n\n    return results\n\n\n#######################################################\n# JSD : from https://github.com/optas/latent_3d_points\n#######################################################\ndef unit_cube_grid_point_cloud(resolution, clip_sphere=False):\n    """"""Returns the center coordinates of each cell of a 3D grid with resolution^3 cells,\n    that is placed in the unit-cube.\n    If clip_sphere it True it drops the ""corner"" cells that lie outside the unit-sphere.\n    """"""\n    grid = np.ndarray((resolution, resolution, resolution, 3), np.float32)\n    spacing = 1.0 / float(resolution - 1)\n    for i in range(resolution):\n        for j in range(resolution):\n            for k in range(resolution):\n                grid[i, j, k, 0] = i * spacing - 0.5\n                grid[i, j, k, 1] = j * spacing - 0.5\n                grid[i, j, k, 2] = k * spacing - 0.5\n\n    if clip_sphere:\n        grid = grid.reshape(-1, 3)\n        grid = grid[norm(grid, axis=1) <= 0.5]\n\n    return grid, spacing\n\n\ndef jsd_between_point_cloud_sets(sample_pcs, ref_pcs, resolution=28):\n    """"""Computes the JSD between two sets of point-clouds, as introduced in the paper\n    ```Learning Representations And Generative Models For 3D Point Clouds```.\n    Args:\n        sample_pcs: (np.ndarray S1xR2x3) S1 point-clouds, each of R1 points.\n        ref_pcs: (np.ndarray S2xR2x3) S2 point-clouds, each of R2 points.\n        resolution: (int) grid-resolution. Affects granularity of measurements.\n    """"""\n    in_unit_sphere = True\n    sample_grid_var = entropy_of_occupancy_grid(sample_pcs, resolution, in_unit_sphere)[1]\n    ref_grid_var = entropy_of_occupancy_grid(ref_pcs, resolution, in_unit_sphere)[1]\n    return jensen_shannon_divergence(sample_grid_var, ref_grid_var)\n\n\ndef entropy_of_occupancy_grid(pclouds, grid_resolution, in_sphere=False, verbose=False):\n    """"""Given a collection of point-clouds, estimate the entropy of the random variables\n    corresponding to occupancy-grid activation patterns.\n    Inputs:\n        pclouds: (numpy array) #point-clouds x points per point-cloud x 3\n        grid_resolution (int) size of occupancy grid that will be used.\n    """"""\n    epsilon = 10e-4\n    bound = 0.5 + epsilon\n    if abs(np.max(pclouds)) > bound or abs(np.min(pclouds)) > bound:\n        if verbose:\n            warnings.warn(\'Point-clouds are not in unit cube.\')\n\n    if in_sphere and np.max(np.sqrt(np.sum(pclouds ** 2, axis=2))) > bound:\n        if verbose:\n            warnings.warn(\'Point-clouds are not in unit sphere.\')\n\n    grid_coordinates, _ = unit_cube_grid_point_cloud(grid_resolution, in_sphere)\n    grid_coordinates = grid_coordinates.reshape(-1, 3)\n    grid_counters = np.zeros(len(grid_coordinates))\n    grid_bernoulli_rvars = np.zeros(len(grid_coordinates))\n    nn = NearestNeighbors(n_neighbors=1).fit(grid_coordinates)\n\n    for pc in pclouds:\n        _, indices = nn.kneighbors(pc)\n        indices = np.squeeze(indices)\n        for i in indices:\n            grid_counters[i] += 1\n        indices = np.unique(indices)\n        for i in indices:\n            grid_bernoulli_rvars[i] += 1\n\n    acc_entropy = 0.0\n    n = float(len(pclouds))\n    for g in grid_bernoulli_rvars:\n        if g > 0:\n            p = float(g) / n\n            acc_entropy += entropy([p, 1.0 - p])\n\n    return acc_entropy / len(grid_counters), grid_counters\n\n\ndef jensen_shannon_divergence(P, Q):\n    if np.any(P < 0) or np.any(Q < 0):\n        raise ValueError(\'Negative values.\')\n    if len(P) != len(Q):\n        raise ValueError(\'Non equal size.\')\n\n    P_ = P / np.sum(P)  # Ensure probabilities.\n    Q_ = Q / np.sum(Q)\n\n    e1 = entropy(P_, base=2)\n    e2 = entropy(Q_, base=2)\n    e_sum = entropy((P_ + Q_) / 2.0, base=2)\n    res = e_sum - ((e1 + e2) / 2.0)\n\n    res2 = _jsdiv(P_, Q_)\n\n    if not np.allclose(res, res2, atol=10e-5, rtol=0):\n        warnings.warn(\'Numerical values of two JSD methods don\\\'t agree.\')\n\n    return res\n\n\ndef _jsdiv(P, Q):\n    """"""another way of computing JSD""""""\n\n    def _kldiv(A, B):\n        a = A.copy()\n        b = B.copy()\n        idx = np.logical_and(a > 0, b > 0)\n        a = a[idx]\n        b = b[idx]\n        return np.sum([v for v in a * np.log2(a / b)])\n\n    P_ = P / np.sum(P)\n    Q_ = Q / np.sum(Q)\n\n    M = 0.5 * (P_ + Q_)\n\n    return 0.5 * (_kldiv(P_, M) + _kldiv(Q_, M))\n\n\nif __name__ == ""__main__"":\n    B, N = 2, 10\n    x = torch.rand(B, N, 3)\n    y = torch.rand(B, N, 3)\n\n    distChamfer = distChamferCUDA()\n    min_l, min_r = distChamfer(x.cuda(), y.cuda())\n    print(min_l.shape)\n    print(min_r.shape)\n\n    l_dist = min_l.mean().cpu().detach().item()\n    r_dist = min_r.mean().cpu().detach().item()\n    print(l_dist, r_dist)\n'"
models/__init__.py,0,b''
models/cnf.py,7,"b'import torch\nimport torch.nn as nn\nfrom torchdiffeq import odeint_adjoint\nfrom torchdiffeq import odeint as odeint_normal\n\n__all__ = [""CNF"", ""SequentialFlow""]\n\n\nclass SequentialFlow(nn.Module):\n    """"""A generalized nn.Sequential container for normalizing flows.""""""\n\n    def __init__(self, layer_list):\n        super(SequentialFlow, self).__init__()\n        self.chain = nn.ModuleList(layer_list)\n\n    def forward(self, x, context, logpx=None, reverse=False, inds=None, integration_times=None):\n        if inds is None:\n            if reverse:\n                inds = range(len(self.chain) - 1, -1, -1)\n            else:\n                inds = range(len(self.chain))\n\n        if logpx is None:\n            for i in inds:\n                x = self.chain[i](x, context, logpx, integration_times, reverse)\n            return x\n        else:\n            for i in inds:\n                x, logpx = self.chain[i](x, context, logpx, integration_times, reverse)\n            return x, logpx\n\n\nclass CNF(nn.Module):\n    def __init__(self, odefunc, conditional=True, T=1.0, train_T=False, regularization_fns=None,\n                 solver=\'dopri5\', atol=1e-5, rtol=1e-5, use_adjoint=True):\n        super(CNF, self).__init__()\n        self.train_T = train_T\n        self.T = T\n        if train_T:\n            self.register_parameter(""sqrt_end_time"", nn.Parameter(torch.sqrt(torch.tensor(T))))\n\n        if regularization_fns is not None and len(regularization_fns) > 0:\n            raise NotImplementedError(""Regularization not supported"")\n        self.use_adjoint = use_adjoint\n        self.odefunc = odefunc\n        self.solver = solver\n        self.atol = atol\n        self.rtol = rtol\n        self.test_solver = solver\n        self.test_atol = atol\n        self.test_rtol = rtol\n        self.solver_options = {}\n        self.conditional = conditional\n\n    def forward(self, x, context=None, logpx=None, integration_times=None, reverse=False):\n        if logpx is None:\n            _logpx = torch.zeros(*x.shape[:-1], 1).to(x)\n        else:\n            _logpx = logpx\n\n        if self.conditional:\n            assert context is not None\n            states = (x, _logpx, context)\n            atol = [self.atol] * 3\n            rtol = [self.rtol] * 3\n        else:\n            states = (x, _logpx)\n            atol = [self.atol] * 2\n            rtol = [self.rtol] * 2\n\n        if integration_times is None:\n            if self.train_T:\n                integration_times = torch.stack(\n                    [torch.tensor(0.0).to(x), self.sqrt_end_time * self.sqrt_end_time]\n                ).to(x)\n            else:\n                integration_times = torch.tensor([0., self.T], requires_grad=False).to(x)\n\n        if reverse:\n            integration_times = _flip(integration_times, 0)\n\n        # Refresh the odefunc statistics.\n        self.odefunc.before_odeint()\n        odeint = odeint_adjoint if self.use_adjoint else odeint_normal\n        if self.training:\n            state_t = odeint(\n                self.odefunc,\n                states,\n                integration_times.to(x),\n                atol=atol,\n                rtol=rtol,\n                method=self.solver,\n                options=self.solver_options,\n            )\n        else:\n            state_t = odeint(\n                self.odefunc,\n                states,\n                integration_times.to(x),\n                atol=self.test_atol,\n                rtol=self.test_rtol,\n                method=self.test_solver,\n            )\n\n        if len(integration_times) == 2:\n            state_t = tuple(s[1] for s in state_t)\n\n        z_t, logpz_t = state_t[:2]\n\n        if logpx is not None:\n            return z_t, logpz_t\n        else:\n            return z_t\n\n    def num_evals(self):\n        return self.odefunc._num_evals.item()\n\n\ndef _flip(x, dim):\n    indices = [slice(None)] * x.dim()\n    indices[dim] = torch.arange(x.size(dim) - 1, -1, -1, dtype=torch.long, device=x.device)\n    return x[tuple(indices)]\n'"
models/diffeq_layers.py,4,"b""import torch\nimport torch.nn as nn\n\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Linear') != -1 or classname.find('Conv') != -1:\n        nn.init.constant_(m.weight, 0)\n        nn.init.normal_(m.bias, 0, 0.01)\n\n\nclass IgnoreLinear(nn.Module):\n    def __init__(self, dim_in, dim_out, dim_c):\n        super(IgnoreLinear, self).__init__()\n        self._layer = nn.Linear(dim_in, dim_out)\n\n    def forward(self, context, x):\n        return self._layer(x)\n\n\nclass ConcatLinear(nn.Module):\n    def __init__(self, dim_in, dim_out, dim_c):\n        super(ConcatLinear, self).__init__()\n        self._layer = nn.Linear(dim_in + 1 + dim_c, dim_out)\n\n    def forward(self, context, x, c):\n        if x.dim() == 3:\n            context = context.unsqueeze(1).expand(-1, x.size(1), -1)\n        x_context = torch.cat((x, context), dim=2)\n        return self._layer(x_context)\n\n\nclass ConcatLinear_v2(nn.Module):\n    def __init__(self, dim_in, dim_out, dim_c):\n        super(ConcatLinear_v2, self).__init__()\n        self._layer = nn.Linear(dim_in, dim_out)\n        self._hyper_bias = nn.Linear(1 + dim_c, dim_out, bias=False)\n\n    def forward(self, context, x):\n        bias = self._hyper_bias(context)\n        if x.dim() == 3:\n            bias = bias.unsqueeze(1)\n        return self._layer(x) + bias\n\n\nclass SquashLinear(nn.Module):\n    def __init__(self, dim_in, dim_out, dim_c):\n        super(SquashLinear, self).__init__()\n        self._layer = nn.Linear(dim_in, dim_out)\n        self._hyper = nn.Linear(1 + dim_c, dim_out)\n\n    def forward(self, context, x):\n        gate = torch.sigmoid(self._hyper(context))\n        if x.dim() == 3:\n            gate = gate.unsqueeze(1)\n        return self._layer(x) * gate\n\n\nclass ScaleLinear(nn.Module):\n    def __init__(self, dim_in, dim_out, dim_c):\n        super(ScaleLinear, self).__init__()\n        self._layer = nn.Linear(dim_in, dim_out)\n        self._hyper = nn.Linear(1 + dim_c, dim_out)\n\n    def forward(self, context, x):\n        gate = self._hyper(context)\n        if x.dim() == 3:\n            gate = gate.unsqueeze(1)\n        return self._layer(x) * gate\n\n\nclass ConcatSquashLinear(nn.Module):\n    def __init__(self, dim_in, dim_out, dim_c):\n        super(ConcatSquashLinear, self).__init__()\n        self._layer = nn.Linear(dim_in, dim_out)\n        self._hyper_bias = nn.Linear(1 + dim_c, dim_out, bias=False)\n        self._hyper_gate = nn.Linear(1 + dim_c, dim_out)\n\n    def forward(self, context, x):\n        gate = torch.sigmoid(self._hyper_gate(context))\n        bias = self._hyper_bias(context)\n        if x.dim() == 3:\n            gate = gate.unsqueeze(1)\n            bias = bias.unsqueeze(1)\n        ret = self._layer(x) * gate + bias\n        return ret\n\n\nclass ConcatScaleLinear(nn.Module):\n    def __init__(self, dim_in, dim_out, dim_c):\n        super(ConcatScaleLinear, self).__init__()\n        self._layer = nn.Linear(dim_in, dim_out)\n        self._hyper_bias = nn.Linear(1 + dim_c, dim_out, bias=False)\n        self._hyper_gate = nn.Linear(1 + dim_c, dim_out)\n\n    def forward(self, context, x):\n        gate = self._hyper_gate(context)\n        bias = self._hyper_bias(context)\n        if x.dim() == 3:\n            gate = gate.unsqueeze(1)\n            bias = bias.unsqueeze(1)\n        ret = self._layer(x) * gate + bias\n        return ret\n"""
models/flow.py,0,"b'from .odefunc import ODEfunc, ODEnet\nfrom .normalization import MovingBatchNorm1d\nfrom .cnf import CNF, SequentialFlow\n\n\ndef count_nfe(model):\n    class AccNumEvals(object):\n\n        def __init__(self):\n            self.num_evals = 0\n\n        def __call__(self, module):\n            if isinstance(module, CNF):\n                self.num_evals += module.num_evals()\n\n    accumulator = AccNumEvals()\n    model.apply(accumulator)\n    return accumulator.num_evals\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\ndef count_total_time(model):\n    class Accumulator(object):\n\n        def __init__(self):\n            self.total_time = 0\n\n        def __call__(self, module):\n            if isinstance(module, CNF):\n                self.total_time = self.total_time + module.sqrt_end_time * module.sqrt_end_time\n\n    accumulator = Accumulator()\n    model.apply(accumulator)\n    return accumulator.total_time\n\n\ndef build_model(args, input_dim, hidden_dims, context_dim, num_blocks, conditional):\n    def build_cnf():\n        diffeq = ODEnet(\n            hidden_dims=hidden_dims,\n            input_shape=(input_dim,),\n            context_dim=context_dim,\n            layer_type=args.layer_type,\n            nonlinearity=args.nonlinearity,\n        )\n        odefunc = ODEfunc(\n            diffeq=diffeq,\n        )\n        cnf = CNF(\n            odefunc=odefunc,\n            T=args.time_length,\n            train_T=args.train_T,\n            conditional=conditional,\n            solver=args.solver,\n            use_adjoint=args.use_adjoint,\n            atol=args.atol,\n            rtol=args.rtol,\n        )\n        return cnf\n\n    chain = [build_cnf() for _ in range(num_blocks)]\n    if args.batch_norm:\n        bn_layers = [MovingBatchNorm1d(input_dim, bn_lag=args.bn_lag, sync=args.sync_bn)\n                     for _ in range(num_blocks)]\n        bn_chain = [MovingBatchNorm1d(input_dim, bn_lag=args.bn_lag, sync=args.sync_bn)]\n        for a, b in zip(chain, bn_layers):\n            bn_chain.append(a)\n            bn_chain.append(b)\n        chain = bn_chain\n    model = SequentialFlow(chain)\n\n    return model\n\n\ndef get_point_cnf(args):\n    dims = tuple(map(int, args.dims.split(""-"")))\n    model = build_model(args, args.input_dim, dims, args.zdim, args.num_blocks, True).cuda()\n    print(""Number of trainable parameters of Point CNF: {}"".format(count_parameters(model)))\n    return model\n\n\ndef get_latent_cnf(args):\n    dims = tuple(map(int, args.latent_dims.split(""-"")))\n    model = build_model(args, args.zdim, dims, 0, args.latent_num_blocks, False).cuda()\n    print(""Number of trainable parameters of Latent CNF: {}"".format(count_parameters(model)))\n    return model\n'"
models/networks.py,10,"b'import torch\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch import nn\nfrom models.flow import get_point_cnf\nfrom models.flow import get_latent_cnf\nfrom utils import truncated_normal, reduce_tensor, standard_normal_logprob\n\n\nclass Encoder(nn.Module):\n    def __init__(self, zdim, input_dim=3, use_deterministic_encoder=False):\n        super(Encoder, self).__init__()\n        self.use_deterministic_encoder = use_deterministic_encoder\n        self.zdim = zdim\n        self.conv1 = nn.Conv1d(input_dim, 128, 1)\n        self.conv2 = nn.Conv1d(128, 128, 1)\n        self.conv3 = nn.Conv1d(128, 256, 1)\n        self.conv4 = nn.Conv1d(256, 512, 1)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.bn3 = nn.BatchNorm1d(256)\n        self.bn4 = nn.BatchNorm1d(512)\n\n        if self.use_deterministic_encoder:\n            self.fc1 = nn.Linear(512, 256)\n            self.fc2 = nn.Linear(256, 128)\n            self.fc_bn1 = nn.BatchNorm1d(256)\n            self.fc_bn2 = nn.BatchNorm1d(128)\n            self.fc3 = nn.Linear(128, zdim)\n        else:\n            # Mapping to [c], cmean\n            self.fc1_m = nn.Linear(512, 256)\n            self.fc2_m = nn.Linear(256, 128)\n            self.fc3_m = nn.Linear(128, zdim)\n            self.fc_bn1_m = nn.BatchNorm1d(256)\n            self.fc_bn2_m = nn.BatchNorm1d(128)\n\n            # Mapping to [c], cmean\n            self.fc1_v = nn.Linear(512, 256)\n            self.fc2_v = nn.Linear(256, 128)\n            self.fc3_v = nn.Linear(128, zdim)\n            self.fc_bn1_v = nn.BatchNorm1d(256)\n            self.fc_bn2_v = nn.BatchNorm1d(128)\n\n    def forward(self, x):\n        x = x.transpose(1, 2)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.bn4(self.conv4(x))\n        x = torch.max(x, 2, keepdim=True)[0]\n        x = x.view(-1, 512)\n\n        if self.use_deterministic_encoder:\n            ms = F.relu(self.fc_bn1(self.fc1(x)))\n            ms = F.relu(self.fc_bn2(self.fc2(ms)))\n            ms = self.fc3(ms)\n            m, v = ms, 0\n        else:\n            m = F.relu(self.fc_bn1_m(self.fc1_m(x)))\n            m = F.relu(self.fc_bn2_m(self.fc2_m(m)))\n            m = self.fc3_m(m)\n            v = F.relu(self.fc_bn1_v(self.fc1_v(x)))\n            v = F.relu(self.fc_bn2_v(self.fc2_v(v)))\n            v = self.fc3_v(v)\n\n        return m, v\n\n\n# Model\nclass PointFlow(nn.Module):\n    def __init__(self, args):\n        super(PointFlow, self).__init__()\n        self.input_dim = args.input_dim\n        self.zdim = args.zdim\n        self.use_latent_flow = args.use_latent_flow\n        self.use_deterministic_encoder = args.use_deterministic_encoder\n        self.prior_weight = args.prior_weight\n        self.recon_weight = args.recon_weight\n        self.entropy_weight = args.entropy_weight\n        self.distributed = args.distributed\n        self.truncate_std = None\n        self.encoder = Encoder(\n                zdim=args.zdim, input_dim=args.input_dim,\n                use_deterministic_encoder=args.use_deterministic_encoder)\n        self.point_cnf = get_point_cnf(args)\n        self.latent_cnf = get_latent_cnf(args) if args.use_latent_flow else nn.Sequential()\n\n    @staticmethod\n    def sample_gaussian(size, truncate_std=None, gpu=None):\n        y = torch.randn(*size).float()\n        y = y if gpu is None else y.cuda(gpu)\n        if truncate_std is not None:\n            truncated_normal(y, mean=0, std=1, trunc_std=truncate_std)\n        return y\n\n    @staticmethod\n    def reparameterize_gaussian(mean, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn(std.size()).to(mean)\n        return mean + std * eps\n\n    @staticmethod\n    def gaussian_entropy(logvar):\n        const = 0.5 * float(logvar.size(1)) * (1. + np.log(np.pi * 2))\n        ent = 0.5 * logvar.sum(dim=1, keepdim=False) + const\n        return ent\n\n    def multi_gpu_wrapper(self, f):\n        self.encoder = f(self.encoder)\n        self.point_cnf = f(self.point_cnf)\n        self.latent_cnf = f(self.latent_cnf)\n\n    def make_optimizer(self, args):\n        def _get_opt_(params):\n            if args.optimizer == \'adam\':\n                optimizer = optim.Adam(params, lr=args.lr, betas=(args.beta1, args.beta2),\n                                       weight_decay=args.weight_decay)\n            elif args.optimizer == \'sgd\':\n                optimizer = torch.optim.SGD(params, lr=args.lr, momentum=args.momentum)\n            else:\n                assert 0, ""args.optimizer should be either \'adam\' or \'sgd\'""\n            return optimizer\n        opt = _get_opt_(list(self.encoder.parameters()) + list(self.point_cnf.parameters())\n                        + list(list(self.latent_cnf.parameters())))\n        return opt\n\n    def forward(self, x, opt, step, writer=None):\n        opt.zero_grad()\n        batch_size = x.size(0)\n        num_points = x.size(1)\n        z_mu, z_sigma = self.encoder(x)\n        if self.use_deterministic_encoder:\n            z = z_mu + 0 * z_sigma\n        else:\n            z = self.reparameterize_gaussian(z_mu, z_sigma)\n\n        # Compute H[Q(z|X)]\n        if self.use_deterministic_encoder:\n            entropy = torch.zeros(batch_size).to(z)\n        else:\n            entropy = self.gaussian_entropy(z_sigma)\n\n        # Compute the prior probability P(z)\n        if self.use_latent_flow:\n            w, delta_log_pw = self.latent_cnf(z, None, torch.zeros(batch_size, 1).to(z))\n            log_pw = standard_normal_logprob(w).view(batch_size, -1).sum(1, keepdim=True)\n            delta_log_pw = delta_log_pw.view(batch_size, 1)\n            log_pz = log_pw - delta_log_pw\n        else:\n            log_pz = torch.zeros(batch_size, 1).to(z)\n\n        # Compute the reconstruction likelihood P(X|z)\n        z_new = z.view(*z.size())\n        z_new = z_new + (log_pz * 0.).mean()\n        y, delta_log_py = self.point_cnf(x, z_new, torch.zeros(batch_size, num_points, 1).to(x))\n        log_py = standard_normal_logprob(y).view(batch_size, -1).sum(1, keepdim=True)\n        delta_log_py = delta_log_py.view(batch_size, num_points, 1).sum(1)\n        log_px = log_py - delta_log_py\n\n        # Loss\n        entropy_loss = -entropy.mean() * self.entropy_weight\n        recon_loss = -log_px.mean() * self.recon_weight\n        prior_loss = -log_pz.mean() * self.prior_weight\n        loss = entropy_loss + prior_loss + recon_loss\n        loss.backward()\n        opt.step()\n\n        # LOGGING (after the training)\n        if self.distributed:\n            entropy_log = reduce_tensor(entropy.mean())\n            recon = reduce_tensor(-log_px.mean())\n            prior = reduce_tensor(-log_pz.mean())\n        else:\n            entropy_log = entropy.mean()\n            recon = -log_px.mean()\n            prior = -log_pz.mean()\n\n        recon_nats = recon / float(x.size(1) * x.size(2))\n        prior_nats = prior / float(self.zdim)\n\n        if writer is not None:\n            writer.add_scalar(\'train/entropy\', entropy_log, step)\n            writer.add_scalar(\'train/prior\', prior, step)\n            writer.add_scalar(\'train/prior(nats)\', prior_nats, step)\n            writer.add_scalar(\'train/recon\', recon, step)\n            writer.add_scalar(\'train/recon(nats)\', recon_nats, step)\n\n        return {\n            \'entropy\': entropy_log.cpu().detach().item()\n            if not isinstance(entropy_log, float) else entropy_log,\n            \'prior_nats\': prior_nats,\n            \'recon_nats\': recon_nats,\n        }\n\n    def encode(self, x):\n        z_mu, z_sigma = self.encoder(x)\n        if self.use_deterministic_encoder:\n            return z_mu\n        else:\n            return self.reparameterize_gaussian(z_mu, z_sigma)\n\n    def decode(self, z, num_points, truncate_std=None):\n        # transform points from the prior to a point cloud, conditioned on a shape code\n        y = self.sample_gaussian((z.size(0), num_points, self.input_dim), truncate_std)\n        x = self.point_cnf(y, z, reverse=True).view(*y.size())\n        return y, x\n\n    def sample(self, batch_size, num_points, truncate_std=None, truncate_std_latent=None, gpu=None):\n        assert self.use_latent_flow, ""Sampling requires `self.use_latent_flow` to be True.""\n        # Generate the shape code from the prior\n        w = self.sample_gaussian((batch_size, self.zdim), truncate_std_latent, gpu=gpu)\n        z = self.latent_cnf(w, None, reverse=True).view(*w.size())\n        # Sample points conditioned on the shape code\n        y = self.sample_gaussian((batch_size, num_points, self.input_dim), truncate_std, gpu=gpu)\n        x = self.point_cnf(y, z, reverse=True).view(*y.size())\n        return z, x\n\n    def reconstruct(self, x, num_points=None, truncate_std=None):\n        num_points = x.size(1) if num_points is None else num_points\n        z = self.encode(x)\n        _, x = self.decode(z, num_points, truncate_std)\n        return x\n'"
models/normalization.py,18,"b""import torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nfrom utils import reduce_tensor\n\n__all__ = ['MovingBatchNorm1d']\n\n\nclass MovingBatchNormNd(nn.Module):\n    def __init__(self, num_features, eps=1e-4, decay=0.1, bn_lag=0., affine=True, sync=False):\n        super(MovingBatchNormNd, self).__init__()\n        self.num_features = num_features\n        self.sync = sync\n        self.affine = affine\n        self.eps = eps\n        self.decay = decay\n        self.bn_lag = bn_lag\n        self.register_buffer('step', torch.zeros(1))\n        if self.affine:\n            self.weight = Parameter(torch.Tensor(num_features))\n            self.bias = Parameter(torch.Tensor(num_features))\n        else:\n            self.register_parameter('weight', None)\n            self.register_parameter('bias', None)\n        self.register_buffer('running_mean', torch.zeros(num_features))\n        self.register_buffer('running_var', torch.ones(num_features))\n        self.reset_parameters()\n\n    @property\n    def shape(self):\n        raise NotImplementedError\n\n    def reset_parameters(self):\n        self.running_mean.zero_()\n        self.running_var.fill_(1)\n        if self.affine:\n            self.weight.data.zero_()\n            self.bias.data.zero_()\n\n    def forward(self, x, c=None, logpx=None, reverse=False):\n        if reverse:\n            return self._reverse(x, logpx)\n        else:\n            return self._forward(x, logpx)\n\n    def _forward(self, x, logpx=None):\n        num_channels = x.size(-1)\n        used_mean = self.running_mean.clone().detach()\n        used_var = self.running_var.clone().detach()\n\n        if self.training:\n            # compute batch statistics\n            x_t = x.transpose(0, 1).reshape(num_channels, -1)\n            batch_mean = torch.mean(x_t, dim=1)\n\n            if self.sync:\n                batch_ex2 = torch.mean(x_t**2, dim=1)\n                batch_mean = reduce_tensor(batch_mean)\n                batch_ex2 = reduce_tensor(batch_ex2)\n                batch_var = batch_ex2 - batch_mean**2\n            else:\n                batch_var = torch.var(x_t, dim=1)\n\n            # moving average\n            if self.bn_lag > 0:\n                used_mean = batch_mean - (1 - self.bn_lag) * (batch_mean - used_mean.detach())\n                used_mean /= (1. - self.bn_lag**(self.step[0] + 1))\n                used_var = batch_var - (1 - self.bn_lag) * (batch_var - used_var.detach())\n                used_var /= (1. - self.bn_lag**(self.step[0] + 1))\n\n            # update running estimates\n            self.running_mean -= self.decay * (self.running_mean - batch_mean.data)\n            self.running_var -= self.decay * (self.running_var - batch_var.data)\n            self.step += 1\n\n        # perform normalization\n        used_mean = used_mean.view(*self.shape).expand_as(x)\n        used_var = used_var.view(*self.shape).expand_as(x)\n\n        y = (x - used_mean) * torch.exp(-0.5 * torch.log(used_var + self.eps))\n\n        if self.affine:\n            weight = self.weight.view(*self.shape).expand_as(x)\n            bias = self.bias.view(*self.shape).expand_as(x)\n            y = y * torch.exp(weight) + bias\n\n        if logpx is None:\n            return y\n        else:\n            return y, logpx - self._logdetgrad(x, used_var).sum(-1, keepdim=True)\n\n    def _reverse(self, y, logpy=None):\n        used_mean = self.running_mean\n        used_var = self.running_var\n\n        if self.affine:\n            weight = self.weight.view(*self.shape).expand_as(y)\n            bias = self.bias.view(*self.shape).expand_as(y)\n            y = (y - bias) * torch.exp(-weight)\n\n        used_mean = used_mean.view(*self.shape).expand_as(y)\n        used_var = used_var.view(*self.shape).expand_as(y)\n        x = y * torch.exp(0.5 * torch.log(used_var + self.eps)) + used_mean\n\n        if logpy is None:\n            return x\n        else:\n            return x, logpy + self._logdetgrad(x, used_var).sum(-1, keepdim=True)\n\n    def _logdetgrad(self, x, used_var):\n        logdetgrad = -0.5 * torch.log(used_var + self.eps)\n        if self.affine:\n            weight = self.weight.view(*self.shape).expand(*x.size())\n            logdetgrad += weight\n        return logdetgrad\n\n    def __repr__(self):\n        return (\n            '{name}({num_features}, eps={eps}, decay={decay}, bn_lag={bn_lag},'\n            ' affine={affine})'.format(name=self.__class__.__name__, **self.__dict__)\n        )\n\n\ndef stable_var(x, mean=None, dim=1):\n    if mean is None:\n        mean = x.mean(dim, keepdim=True)\n    mean = mean.view(-1, 1)\n    res = torch.pow(x - mean, 2)\n    max_sqr = torch.max(res, dim, keepdim=True)[0]\n    var = torch.mean(res / max_sqr, 1, keepdim=True) * max_sqr\n    var = var.view(-1)\n    # change nan to zero\n    var[var != var] = 0\n    return var\n\n\nclass MovingBatchNorm1d(MovingBatchNormNd):\n    @property\n    def shape(self):\n        return [1, -1]\n\n    def forward(self, x, context=None, logpx=None, integration_times=None, reverse=False):\n        ret = super(MovingBatchNorm1d, self).forward(\n                x, context, logpx=logpx, reverse=reverse)\n        return ret\n"""
models/odefunc.py,11,"b'import copy\nimport torch\nimport torch.nn as nn\nfrom . import diffeq_layers\n\n__all__ = [""ODEnet"", ""ODEfunc""]\n\n\ndef divergence_approx(f, y, e=None):\n    e_dzdx = torch.autograd.grad(f, y, e, create_graph=True)[0]\n    e_dzdx_e = e_dzdx.mul(e)\n\n    cnt = 0\n    while not e_dzdx_e.requires_grad and cnt < 10:\n        # print(""RequiresGrad:f=%s, y(rgrad)=%s, e_dzdx:%s, e:%s, e_dzdx_e:%s cnt=%d""\n        #       % (f.requires_grad, y.requires_grad, e_dzdx.requires_grad,\n        #          e.requires_grad, e_dzdx_e.requires_grad, cnt))\n        e_dzdx = torch.autograd.grad(f, y, e, create_graph=True)[0]\n        e_dzdx_e = e_dzdx * e\n        cnt += 1\n\n    approx_tr_dzdx = e_dzdx_e.sum(dim=-1)\n    assert approx_tr_dzdx.requires_grad, \\\n        ""(failed to add node to graph) f=%s %s, y(rgrad)=%s, e_dzdx:%s, e:%s, e_dzdx_e:%s cnt:%s"" \\\n        % (\n        f.size(), f.requires_grad, y.requires_grad, e_dzdx.requires_grad, e.requires_grad, e_dzdx_e.requires_grad, cnt)\n    return approx_tr_dzdx\n\n\nclass Swish(nn.Module):\n    def __init__(self):\n        super(Swish, self).__init__()\n        self.beta = nn.Parameter(torch.tensor(1.0))\n\n    def forward(self, x):\n        return x * torch.sigmoid(self.beta * x)\n\n\nclass Lambda(nn.Module):\n    def __init__(self, f):\n        super(Lambda, self).__init__()\n        self.f = f\n\n    def forward(self, x):\n        return self.f(x)\n\n\nNONLINEARITIES = {\n    ""tanh"": nn.Tanh(),\n    ""relu"": nn.ReLU(),\n    ""softplus"": nn.Softplus(),\n    ""elu"": nn.ELU(),\n    ""swish"": Swish(),\n    ""square"": Lambda(lambda x: x ** 2),\n    ""identity"": Lambda(lambda x: x),\n}\n\n\nclass ODEnet(nn.Module):\n    """"""\n    Helper class to make neural nets for use in continuous normalizing flows\n    """"""\n\n    def __init__(self, hidden_dims, input_shape, context_dim, layer_type=""concat"", nonlinearity=""softplus""):\n        super(ODEnet, self).__init__()\n        base_layer = {\n            ""ignore"": diffeq_layers.IgnoreLinear,\n            ""squash"": diffeq_layers.SquashLinear,\n            ""scale"": diffeq_layers.ScaleLinear,\n            ""concat"": diffeq_layers.ConcatLinear,\n            ""concat_v2"": diffeq_layers.ConcatLinear_v2,\n            ""concatsquash"": diffeq_layers.ConcatSquashLinear,\n            ""concatscale"": diffeq_layers.ConcatScaleLinear,\n        }[layer_type]\n\n        # build models and add them\n        layers = []\n        activation_fns = []\n        hidden_shape = input_shape\n\n        for dim_out in (hidden_dims + (input_shape[0],)):\n            layer_kwargs = {}\n            layer = base_layer(hidden_shape[0], dim_out, context_dim, **layer_kwargs)\n            layers.append(layer)\n            activation_fns.append(NONLINEARITIES[nonlinearity])\n\n            hidden_shape = list(copy.copy(hidden_shape))\n            hidden_shape[0] = dim_out\n\n        self.layers = nn.ModuleList(layers)\n        self.activation_fns = nn.ModuleList(activation_fns[:-1])\n\n    def forward(self, context, y):\n        dx = y\n        for l, layer in enumerate(self.layers):\n            dx = layer(context, dx)\n            # if not last layer, use nonlinearity\n            if l < len(self.layers) - 1:\n                dx = self.activation_fns[l](dx)\n        return dx\n\n\nclass ODEfunc(nn.Module):\n    def __init__(self, diffeq):\n        super(ODEfunc, self).__init__()\n        self.diffeq = diffeq\n        self.divergence_fn = divergence_approx\n        self.register_buffer(""_num_evals"", torch.tensor(0.))\n\n    def before_odeint(self, e=None):\n        self._e = e\n        self._num_evals.fill_(0)\n\n    def forward(self, t, states):\n        y = states[0]\n        t = torch.ones(y.size(0), 1).to(y) * t.clone().detach().requires_grad_(True).type_as(y)\n        self._num_evals += 1\n        for state in states:\n            state.requires_grad_(True)\n\n        # Sample and fix the noise.\n        if self._e is None:\n            self._e = torch.randn_like(y, requires_grad=True).to(y)\n\n        with torch.set_grad_enabled(True):\n            if len(states) == 3:  # conditional CNF\n                c = states[2]\n                tc = torch.cat([t, c.view(y.size(0), -1)], dim=1)\n                dy = self.diffeq(tc, y)\n                divergence = self.divergence_fn(dy, y, e=self._e).unsqueeze(-1)\n                return dy, -divergence, torch.zeros_like(c).requires_grad_(True)\n            elif len(states) == 2:  # unconditional CNF\n                dy = self.diffeq(t, y)\n                divergence = self.divergence_fn(dy, y, e=self._e).view(-1, 1)\n                return dy, -divergence\n            else:\n                assert 0, ""`len(states)` should be 2 or 3""\n'"
metrics/pytorch_structural_losses/__init__.py,0,"b'#import torch\n\n#from MakePytorchBackend import AddGPU, Foo, ApproxMatch\n\n#from Add import add_gpu, approx_match\n\n'"
metrics/pytorch_structural_losses/match_cost.py,1,"b'import torch\nfrom torch.autograd import Function\nfrom metrics.StructuralLosses.StructuralLossesBackend import ApproxMatch, MatchCost, MatchCostGrad\n\n# Inherit from Function\nclass MatchCostFunction(Function):\n    # Note that both forward and backward are @staticmethods\n    @staticmethod\n    # bias is an optional argument\n    def forward(ctx, seta, setb):\n        #print(""Match Cost Forward"")\n        ctx.save_for_backward(seta, setb)\n        \'\'\'\n        input:\n\t        set1 : batch_size * #dataset_points * 3\n\t        set2 : batch_size * #query_points * 3\n        returns:\n\t        match : batch_size * #query_points * #dataset_points\n        \'\'\'\n        match, temp = ApproxMatch(seta, setb)\n        ctx.match = match\n        cost = MatchCost(seta, setb, match)\n        return cost\n\n    """"""\n    grad_1,grad_2=approxmatch_module.match_cost_grad(xyz1,xyz2,match)\n\treturn [grad_1*tf.expand_dims(tf.expand_dims(grad_cost,1),2),grad_2*tf.expand_dims(tf.expand_dims(grad_cost,1),2),None]\n\t""""""\n    # This function has only a single output, so it gets only one gradient\n    @staticmethod\n    def backward(ctx, grad_output):\n        #print(""Match Cost Backward"")\n        # This is a pattern that is very convenient - at the top of backward\n        # unpack saved_tensors and initialize all gradients w.r.t. inputs to\n        # None. Thanks to the fact that additional trailing Nones are\n        # ignored, the return statement is simple even when the function has\n        # optional inputs.\n        seta, setb = ctx.saved_tensors\n        #grad_input = grad_weight = grad_bias = None\n        grada, gradb = MatchCostGrad(seta, setb, ctx.match)\n        grad_output_expand = grad_output.unsqueeze(1).unsqueeze(2)\n        return grada*grad_output_expand, gradb*grad_output_expand\n\nmatch_cost = MatchCostFunction.apply\n\n'"
metrics/pytorch_structural_losses/nn_distance.py,1,"b'import torch\nfrom torch.autograd import Function\n# from extensions.StructuralLosses.StructuralLossesBackend import NNDistance, NNDistanceGrad\nfrom metrics.StructuralLosses.StructuralLossesBackend import NNDistance, NNDistanceGrad\n\n# Inherit from Function\nclass NNDistanceFunction(Function):\n    # Note that both forward and backward are @staticmethods\n    @staticmethod\n    # bias is an optional argument\n    def forward(ctx, seta, setb):\n        #print(""Match Cost Forward"")\n        ctx.save_for_backward(seta, setb)\n        \'\'\'\n        input:\n\t        set1 : batch_size * #dataset_points * 3\n\t        set2 : batch_size * #query_points * 3\n        returns:\n\t        dist1, idx1, dist2, idx2\n        \'\'\'\n        dist1, idx1, dist2, idx2 = NNDistance(seta, setb)\n        ctx.idx1 = idx1\n        ctx.idx2 = idx2\n        return dist1, dist2\n\n    # This function has only a single output, so it gets only one gradient\n    @staticmethod\n    def backward(ctx, grad_dist1, grad_dist2):\n        #print(""Match Cost Backward"")\n        # This is a pattern that is very convenient - at the top of backward\n        # unpack saved_tensors and initialize all gradients w.r.t. inputs to\n        # None. Thanks to the fact that additional trailing Nones are\n        # ignored, the return statement is simple even when the function has\n        # optional inputs.\n        seta, setb = ctx.saved_tensors\n        idx1 = ctx.idx1\n        idx2 = ctx.idx2\n        grada, gradb = NNDistanceGrad(seta, setb, idx1, idx2, grad_dist1, grad_dist2)\n        return grada, gradb\n\nnn_distance = NNDistanceFunction.apply\n\n'"
metrics/pytorch_structural_losses/setup.py,1,"b""from setuptools import setup\nfrom torch.utils.cpp_extension import CUDAExtension, BuildExtension\n\n# Python interface\nsetup(\n    name='PyTorchStructuralLosses',\n    version='0.1.0',\n    install_requires=['torch'],\n    packages=['StructuralLosses'],\n    package_dir={'StructuralLosses': './'},\n    ext_modules=[\n        CUDAExtension(\n            name='StructuralLossesBackend',\n            include_dirs=['./'],\n            sources=[\n                'pybind/bind.cpp',\n            ],\n            libraries=['make_pytorch'],\n            library_dirs=['objs'],\n            # extra_compile_args=['-g']\n        )\n    ],\n    cmdclass={'build_ext': BuildExtension},\n    author='Christopher B. Choy',\n    author_email='chrischoy@ai.stanford.edu',\n    description='Tutorial for Pytorch C++ Extension with a Makefile',\n    keywords='Pytorch C++ Extension',\n    url='https://github.com/chrischoy/MakePytorchPlusPlus',\n    zip_safe=False,\n)\n"""
