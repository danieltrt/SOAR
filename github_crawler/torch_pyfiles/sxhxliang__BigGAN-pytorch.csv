file_path,api_count,code
CrossReplicaBN.py,9,"b'import torch\nfrom torch import nn \nfrom torch.nn.parameter import Parameter\nfrom torch.nn import functional as F\n\n# TODO for ScaledCrossReplicaBatchNorm2d\nclass _BatchNorm(nn.Module):\n    _version = 2\n\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True,\n                 track_running_stats=True):\n        super(_BatchNorm, self).__init__()\n        self.num_features = num_features\n        self.eps = eps\n        self.momentum = momentum\n        self.affine = affine\n        self.track_running_stats = track_running_stats\n        if self.affine:\n            self.weight = Parameter(torch.Tensor(num_features))\n            self.bias = Parameter(torch.Tensor(num_features))\n        else:\n            self.register_parameter(\'weight\', None)\n            self.register_parameter(\'bias\', None)\n        if self.track_running_stats:\n            self.register_buffer(\'running_mean\', torch.zeros(num_features))\n            self.register_buffer(\'running_var\', torch.ones(num_features))\n            self.register_buffer(\'num_batches_tracked\', torch.tensor(0, dtype=torch.long))\n        else:\n            self.register_parameter(\'running_mean\', None)\n            self.register_parameter(\'running_var\', None)\n            self.register_parameter(\'num_batches_tracked\', None)\n        self.reset_parameters()\n\n    def reset_running_stats(self):\n        if self.track_running_stats:\n            self.running_mean.zero_()\n            self.running_var.fill_(1)\n            self.num_batches_tracked.zero_()\n\n    def reset_parameters(self):\n        self.reset_running_stats()\n        if self.affine:\n            self.weight.data.uniform_()\n            self.bias.data.zero_()\n\n    def _check_input_dim(self, input):\n        raise NotImplementedError\n\n    def forward(self, input):\n        self._check_input_dim(input)\n\n        exponential_average_factor = 0.0\n\n        if self.training and self.track_running_stats:\n            self.num_batches_tracked += 1\n            if self.momentum is None:  # use cumulative moving average\n                exponential_average_factor = 1.0 / self.num_batches_tracked.item()\n            else:  # use exponential moving average\n                exponential_average_factor = self.momentum\n\n        return F.batch_norm(\n            input, self.running_mean, self.running_var, self.weight, self.bias,\n            self.training or not self.track_running_stats,\n            exponential_average_factor, self.eps)\n\n    def extra_repr(self):\n        return \'{num_features}, eps={eps}, momentum={momentum}, affine={affine}, \' \\\n               \'track_running_stats={track_running_stats}\'.format(**self.__dict__)\n\n    def _load_from_state_dict(self, state_dict, prefix, metadata, strict,\n                              missing_keys, unexpected_keys, error_msgs):\n        version = metadata.get(\'version\', None)\n\n        if (version is None or version < 2) and self.track_running_stats:\n            # at version 2: added num_batches_tracked buffer\n            #               this should have a default value of 0\n            num_batches_tracked_key = prefix + \'num_batches_tracked\'\n            if num_batches_tracked_key not in state_dict:\n                state_dict[num_batches_tracked_key] = torch.tensor(0, dtype=torch.long)\n\n        super(_BatchNorm, self)._load_from_state_dict(\n            state_dict, prefix, metadata, strict,\n            missing_keys, unexpected_keys, error_msgs)\n\n# TODO for ScaledCrossReplicaBatchNorm2d\nclass ScaledCrossReplicaBatchNorm2d(_BatchNorm):\n    r""""""Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs\n    with additional channel dimension) as described in the paper\n    `Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .\n\n    .. math::\n\n        y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n\n    The mean and standard-deviation are calculated per-dimension over\n    the mini-batches and :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\n    of size `C` (where `C` is the input size).\n\n    By default, during training this layer keeps running estimates of its\n    computed mean and variance, which are then used for normalization during\n    evaluation. The running estimates are kept with a default :attr:`momentum`\n    of 0.1.\n\n    If :attr:`track_running_stats` is set to ``False``, this layer then does not\n    keep running estimates, and batch statistics are instead used during\n    evaluation time as well.\n\n    .. note::\n        This :attr:`momentum` argument is different from one used in optimizer\n        classes and the conventional notion of momentum. Mathematically, the\n        update rule for running statistics here is\n        :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momemtum} \\times x_t`,\n        where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n        new observed value.\n\n    Because the Batch Normalization is done over the `C` dimension, computing statistics\n    on `(N, H, W)` slices, it\'s common terminology to call this Spatial Batch Normalization.\n\n    Args:\n        num_features: :math:`C` from an expected input of size\n            :math:`(N, C, H, W)`\n        eps: a value added to the denominator for numerical stability.\n            Default: 1e-5\n        momentum: the value used for the running_mean and running_var\n            computation. Can be set to ``None`` for cumulative moving average\n            (i.e. simple average). Default: 0.1\n        affine: a boolean value that when set to ``True``, this module has\n            learnable affine parameters. Default: ``True``\n        track_running_stats: a boolean value that when set to ``True``, this\n            module tracks the running mean and variance, and when set to ``False``,\n            this module does not track such statistics and always uses batch\n            statistics in both training and eval modes. Default: ``True``\n\n    Shape:\n        - Input: :math:`(N, C, H, W)`\n        - Output: :math:`(N, C, H, W)` (same shape as input)\n\n    Examples::\n\n        >>> # With Learnable Parameters\n        >>> m = nn.BatchNorm2d(100)\n        >>> # Without Learnable Parameters\n        >>> m = nn.BatchNorm2d(100, affine=False)\n        >>> input = torch.randn(20, 100, 35, 45)\n        >>> output = m(input)\n\n    .. _`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`:\n        https://arxiv.org/abs/1502.03167\n    """"""\n\n    def _check_input_dim(self, input):\n        if input.dim() != 4:\n            raise ValueError(\'expected 4D input (got {}D input)\'\n                             .format(input.dim()))'"
data_loader.py,1,"b""import torch\r\nimport torchvision.datasets as dsets\r\nfrom torchvision import transforms\r\n\r\n\r\nclass Data_Loader():\r\n    def __init__(self, train, dataset, image_path, image_size, batch_size, shuf=True):\r\n        self.dataset = dataset\r\n        self.path = image_path\r\n        self.imsize = image_size\r\n        self.batch = batch_size\r\n        self.shuf = shuf\r\n        self.train = train\r\n\r\n    def transform(self, resize, totensor, normalize, centercrop):\r\n        options = []\r\n        if centercrop:\r\n            options.append(transforms.CenterCrop(160))\r\n        if resize:\r\n            options.append(transforms.Resize((self.imsize,self.imsize)))\r\n        if totensor:\r\n            options.append(transforms.ToTensor())\r\n        if normalize:\r\n            options.append(transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\r\n        transform = transforms.Compose(options)\r\n        return transform\r\n\r\n    def load_lsun(self, classes=['church_outdoor_train','classroom_train']):\r\n        transforms = self.transform(True, True, True, False)\r\n        dataset = dsets.LSUN(self.path, classes=classes, transform=transforms)\r\n        return dataset\r\n    \r\n    def load_imagenet(self):\r\n        transforms = self.transform(True, True, True, True)\r\n        dataset = dsets.ImageFolder(self.path+'/imagenet', transform=transforms)\r\n        return dataset\r\n\r\n    def load_celeb(self):\r\n        transforms = self.transform(True, True, True, True)\r\n        dataset = dsets.ImageFolder(self.path+'/CelebA', transform=transforms)\r\n        return dataset\r\n\r\n    def load_off(self):\r\n        transforms = self.transform(True, True, True, False)\r\n        dataset = dsets.ImageFolder(self.path, transform=transforms)\r\n        return dataset\r\n\r\n    def loader(self):\r\n        if self.dataset == 'lsun':\r\n            dataset = self.load_lsun()\r\n        elif self.dataset == 'imagenet':\r\n            dataset = self.load_imagenet()\r\n        elif self.dataset == 'celeb':\r\n            dataset = self.load_celeb()\r\n        elif self.dataset == 'off':\r\n            dataset = self.load_off()\r\n\r\n        print('dataset',len(dataset))\r\n        loader = torch.utils.data.DataLoader(dataset=dataset,\r\n                                              batch_size=self.batch,\r\n                                              shuffle=self.shuf,\r\n                                              num_workers=2,\r\n                                              drop_last=True)\r\n        return loader\r\n\r\n"""
debug.py,3,"b'from model_resnet import *\nfrom demo import *\nfrom utils import *\n\ndim_z = 120\nvocab_size = 1000\n\n\nnum_samples = 12 #@param {type:""slider"", min:1, max:20, step:1}\ntruncation = 0.32 #@param {type:""slider"", min:0.02, max:1, step:0.02}\nnoise_seed = 0 #@param {type:""slider"", min:0, max:100, step:1}\ncategory = ""951""\n\n\nz = truncated_z_sample(num_samples, truncation, noise_seed)\ny = int(951)\n# print(z)\n\n\nfeed_dict = sample(z, y, truncation=truncation)\n# print(feed_dict[\'input_y\'].shape)\n\n\nmodel = Generator(code_dim=120, n_class=1000, chn=6, debug=True)\n# inputs = torch.from_numpy(feed_dict[\'input_z\']).float()\n# labels = torch.from_numpy(feed_dict[\'input_y\']).float()\n# out = model(inputs,labels)\n\n# print(out.size())\n# model.apply(weights_init)\n\n\nprint(\'0,1,2,3\'.split(\',\'))\n# torch.save(model.state_dict(),\'test_model.pth\')\n\n\n\n'"
demo.py,0,"b'\nfrom scipy.stats import truncnorm\nimport numpy as np\n\ndim_z = 120\nvocab_size = 1000\n\ndef truncated_z_sample(batch_size, truncation=1., seed=None):\n    state = None if seed is None else np.random.RandomState(seed)\n    values = truncnorm.rvs(-2, 2, size=(batch_size, dim_z), random_state=state)\n    return truncation * values\n\n\ndef one_hot(index, vocab_size=vocab_size):\n    index = np.asarray(index)\n    if len(index.shape) == 0:\n        index = np.asarray([index])\n    assert len(index.shape) == 1\n    num = index.shape[0]\n    output = np.zeros((num, vocab_size), dtype=np.float32)\n    output[np.arange(num), index] = 1\n    return output\n\n\ndef one_hot_if_needed(label, vocab_size=vocab_size):\n    label = np.asarray(label)\n    if len(label.shape) <= 1:\n        label = one_hot(label, vocab_size)\n    assert len(label.shape) == 2\n    return label\n\n\ndef sample(noise, label, truncation=1., batch_size=8, vocab_size=vocab_size):\n    noise = np.asarray(noise)\n    label = np.asarray(label)\n    num = noise.shape[0]\n    if len(label.shape) == 0:\n        label = np.asarray([label] * num)\n    if label.shape[0] != num:\n        raise ValueError(\'Got # noise samples ({}) != # label samples ({})\'\n                         .format(noise.shape[0], label.shape[0]))\n    label = one_hot_if_needed(label, vocab_size)\n    ims = []\n    for batch_start in range(0, num, batch_size):\n        s = slice(batch_start, min(num, batch_start + batch_size))\n        feed_dict = {\'input_z\': noise[s],\n                     \'input_y\': label[s], \'input_trunc\': truncation}\n    return feed_dict          \n    #     ims.append(sess.run(output, feed_dict=feed_dict))\n    # ims = np.concatenate(ims, axis=0)\n    # assert ims.shape[0] == num\n    # ims = np.clip(((ims + 1) / 2.0) * 256, 0, 255)\n    # ims = np.uint8(ims)\n    # return ims\n\n\ndef interpolate(A, B, num_interps):\n    alphas = np.linspace(0, 1, num_interps)\n    if A.shape != B.shape:\n        raise ValueError(\'A and B must have the same shape to interpolate.\')\n    return np.array([(1-a)*A + a*B for a in alphas])\n\n\ndef imgrid(imarray, cols=5, pad=1):\n    if imarray.dtype != np.uint8:\n        raise ValueError(\'imgrid input imarray must be uint8\')\n    pad = int(pad)\n    assert pad >= 0\n    cols = int(cols)\n    assert cols >= 1\n    N, H, W, C = imarray.shape\n    rows = int(np.ceil(N / float(cols)))\n    batch_pad = rows * cols - N\n    assert batch_pad >= 0\n    post_pad = [batch_pad, pad, pad, 0]\n    pad_arg = [[0, p] for p in post_pad]\n    imarray = np.pad(imarray, pad_arg, \'constant\', constant_values=255)\n    H += pad\n    W += pad\n    grid = (imarray\n            .reshape(rows, cols, H, W, C)\n            .transpose(0, 2, 1, 3, 4)\n            .reshape(rows*H, cols*W, C))\n    if pad:\n        grid = grid[:-pad, :-pad]\n    return grid\n\n\ndef imshow(a, format=\'png\', jpeg_fallback=True):\n    a = np.asarray(a, dtype=np.uint8)\n    str_file = cStringIO.StringIO()\n    PIL.Image.fromarray(a).save(str_file, format)\n    png_data = str_file.getvalue()\n    try:\n        disp = IPython.display.display(IPython.display.Image(png_data))\n    except IOError:\n        if jpeg_fallback and format != \'jpeg\':\n            print(\'Warning: image was too large to display in format ""{}""; \'\n                  \'trying jpeg instead.\').format(format)\n            return imshow(a, format=\'jpeg\')\n        else:\n            raise\n    return disp\n'"
main.py,1,"b""\r\nfrom parameter import *\r\nfrom trainer import Trainer\r\n# from tester import Tester\r\nfrom data_loader import Data_Loader\r\nfrom torch.backends import cudnn\r\nfrom utils import make_folder\r\n\r\nimport glob\r\nimport os\r\n\r\ndef main(config):\r\n    # For fast training\r\n    cudnn.benchmark = True\r\n\r\n\r\n    config.n_class = len(glob.glob(os.path.join(config.image_path, '*/')))\r\n    print('number class:', config.n_class)\r\n    # Data loader\r\n    data_loader = Data_Loader(config.train, config.dataset, config.image_path, config.imsize,\r\n                             config.batch_size, shuf=config.train)\r\n\r\n    # Create directories if not exist\r\n    make_folder(config.model_save_path, config.version)\r\n    make_folder(config.sample_path, config.version)\r\n    make_folder(config.log_path, config.version)\r\n    make_folder(config.attn_path, config.version)\r\n\r\n\r\n    print('config data_loader and build logs folder')\r\n\r\n    if config.train:\r\n        if config.model=='sagan':\r\n            trainer = Trainer(data_loader.loader(), config)\r\n        elif config.model == 'qgan':\r\n            trainer = qgan_trainer(data_loader.loader(), config)\r\n        trainer.train()\r\n    else:\r\n        tester = Tester(data_loader.loader(), config)\r\n        tester.test()\r\n\r\nif __name__ == '__main__':\r\n    config = get_parameters()\r\n    print(config)\r\n    main(config)"""
model_resnet.py,14,"b'import torch\r\n\r\nfrom torch import nn\r\nfrom torch.nn import init\r\nfrom torch.nn import functional as F\r\n\r\nimport functools\r\nfrom torch.autograd import Variable\r\nfrom CrossReplicaBN import ScaledCrossReplicaBatchNorm2d\r\nfrom spectral import SpectralNorm\r\n\r\n\r\nclass Spectral_Norm:\r\n    def __init__(self, name):\r\n        self.name = name\r\n\r\n    def compute_weight(self, module):\r\n        weight = getattr(module, self.name + \'_orig\')\r\n        u = getattr(module, self.name + \'_u\')\r\n        size = weight.size()\r\n        weight_mat = weight.contiguous().view(size[0], -1)\r\n        with torch.no_grad():\r\n            v = weight_mat.t() @ u\r\n            v = v / v.norm()\r\n            u = weight_mat @ v\r\n            u = u / u.norm()\r\n        sigma = u @ weight_mat @ v\r\n        weight_sn = weight / sigma\r\n        # weight_sn = weight_sn.view(*size)\r\n\r\n        return weight_sn, u\r\n\r\n    @staticmethod\r\n    def apply(module, name):\r\n        fn = Spectral_Norm(name)\r\n\r\n        weight = getattr(module, name)\r\n        del module._parameters[name]\r\n        module.register_parameter(name + \'_orig\', weight)\r\n        input_size = weight.size(0)\r\n        u = weight.new_empty(input_size).normal_()\r\n        module.register_buffer(name, weight)\r\n        module.register_buffer(name + \'_u\', u)\r\n\r\n        module.register_forward_pre_hook(fn)\r\n\r\n        return fn\r\n\r\n    def __call__(self, module, input):\r\n        weight_sn, u = self.compute_weight(module)\r\n        setattr(module, self.name, weight_sn)\r\n        setattr(module, self.name + \'_u\', u)\r\n\r\n\r\ndef spectral_norm(module, name=\'weight\'):\r\n    Spectral_Norm.apply(module, name)\r\n\r\n    return module\r\n\r\n\r\ndef spectral_init(module, gain=1):\r\n    init.xavier_uniform_(module.weight, gain)\r\n    if module.bias is not None:\r\n        module.bias.data.zero_()\r\n\r\n    return spectral_norm(module)\r\n\r\ndef init_linear(linear):\r\n    init.xavier_uniform_(linear.weight)\r\n    linear.bias.data.zero_()\r\n\r\n\r\ndef init_conv(conv, glu=True):\r\n    init.xavier_uniform_(conv.weight)\r\n    if conv.bias is not None:\r\n        conv.bias.data.zero_()\r\n\r\n\r\ndef leaky_relu(input):\r\n    return F.leaky_relu(input, negative_slope=0.2)\r\n\r\nclass SelfAttention(nn.Module):\r\n    """""" Self attention Layer""""""\r\n    def __init__(self,in_dim,activation=F.relu):\r\n        super(SelfAttention,self).__init__()\r\n        self.chanel_in = in_dim\r\n        self.activation = activation\r\n        \r\n        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\r\n        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\r\n        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\r\n        self.gamma = nn.Parameter(torch.zeros(1))\r\n\r\n        self.softmax  = nn.Softmax(dim=-1) #\r\n\r\n        init_conv(self.query_conv)\r\n        init_conv(self.key_conv)\r\n        init_conv(self.value_conv)\r\n        \r\n    def forward(self,x):\r\n        """"""\r\n            inputs :\r\n                x : input feature maps( B X C X W X H)\r\n            returns :\r\n                out : self attention value + input feature \r\n                attention: B X N X N (N is Width*Height)\r\n        """"""\r\n        m_batchsize,C,width ,height = x.size()\r\n        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\r\n        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\r\n        energy =  torch.bmm(proj_query,proj_key) # transpose check\r\n        attention = self.softmax(energy) # BX (N) X (N) \r\n        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\r\n\r\n        out = torch.bmm(proj_value,attention.permute(0,2,1) )\r\n        out = out.view(m_batchsize,C,width,height)\r\n        \r\n        out = self.gamma*out + x\r\n        return out\r\n\r\n\r\n\r\nclass ConditionalNorm(nn.Module):\r\n    def __init__(self, in_channel, n_condition=148):\r\n        super().__init__()\r\n\r\n        self.bn = nn.BatchNorm2d(in_channel, affine=False)\r\n\r\n        self.embed = nn.Linear(n_condition, in_channel* 2)\r\n        self.embed.weight.data[:, :in_channel] = 1\r\n        self.embed.weight.data[:, in_channel:] = 0\r\n\r\n    def forward(self, input, class_id):\r\n        out = self.bn(input)\r\n        # print(class_id.dtype)\r\n        # print(\'class_id\', class_id.size()) # torch.Size([4, 148])\r\n        # print(out.size()) #torch.Size([4, 128, 4, 4])\r\n        # class_id = torch.randn(4,1)\r\n        # print(self.embed)\r\n        embed = self.embed(class_id)\r\n        # print(\'embed\', embed.size())\r\n        gamma, beta = embed.chunk(2, 1)\r\n        gamma = gamma.unsqueeze(2).unsqueeze(3)\r\n        beta = beta.unsqueeze(2).unsqueeze(3)\r\n        # print(beta.size())\r\n        out = gamma * out + beta\r\n\r\n        return out\r\n\r\n\r\nclass GBlock(nn.Module):\r\n    def __init__(self, in_channel, out_channel, kernel_size=[3, 3],\r\n                 padding=1, stride=1, n_class=None, bn=True,\r\n                 activation=F.relu, upsample=True, downsample=False):\r\n        super().__init__()\r\n\r\n        gain = 2 ** 0.5\r\n\r\n        self.conv0 = SpectralNorm(nn.Conv2d(in_channel, out_channel,\r\n                                             kernel_size, stride, padding,\r\n                                             bias=True if bn else True))\r\n        self.conv1 = SpectralNorm(nn.Conv2d(out_channel, out_channel,\r\n                                             kernel_size, stride, padding,\r\n                                             bias=True if bn else True))\r\n\r\n        self.skip_proj = False\r\n        if in_channel != out_channel or upsample or downsample:\r\n            self.conv_sc = SpectralNorm(nn.Conv2d(in_channel, out_channel,\r\n                                                   1, 1, 0))\r\n            self.skip_proj = True\r\n\r\n        self.upsample = upsample\r\n        self.downsample = downsample\r\n        self.activation = activation\r\n        self.bn = bn\r\n        if bn:\r\n            self.HyperBN = ConditionalNorm(in_channel, 148)\r\n            self.HyperBN_1 = ConditionalNorm(out_channel, 148)\r\n\r\n    def forward(self, input, condition=None):\r\n        out = input\r\n\r\n        if self.bn:\r\n            # print(\'condition\',condition.size()) #condition torch.Size([4, 148])\r\n            out = self.HyperBN(out, condition)\r\n        out = self.activation(out)\r\n        if self.upsample:\r\n            # TODO different form papers\r\n            out = F.upsample(out, scale_factor=2)\r\n        out = self.conv0(out)\r\n        if self.bn:\r\n            out = self.HyperBN_1(out, condition)\r\n        out = self.activation(out)\r\n        out = self.conv1(out)\r\n\r\n        if self.downsample:\r\n            out = F.avg_pool2d(out, 2)\r\n\r\n        if self.skip_proj:\r\n            skip = input\r\n            if self.upsample:\r\n                # TODO different form papers\r\n                skip = F.upsample(skip, scale_factor=2)\r\n            skip = self.conv_sc(skip)\r\n            if self.downsample:\r\n                skip = F.avg_pool2d(skip, 2)\r\n\r\n        else:\r\n            skip = input\r\n\r\n        return out + skip\r\n\r\n\r\nclass Generator(nn.Module):\r\n    def __init__(self, code_dim=100, n_class=1000, chn=96, debug=False):\r\n        super().__init__()\r\n\r\n        self.linear = SpectralNorm(nn.Linear(n_class, 128, bias=False))\r\n        \r\n        if debug:\r\n            chn = 8\r\n\r\n        self.first_view = 16 * chn\r\n\r\n        self.G_linear = SpectralNorm(nn.Linear(20, 4 * 4 * 16 * chn))\r\n\r\n        self.conv = nn.ModuleList([GBlock(16*chn, 16*chn, n_class=n_class),\r\n                                GBlock(16*chn, 8*chn, n_class=n_class),\r\n                                GBlock(8*chn, 4*chn, n_class=n_class),\r\n                                GBlock(4*chn, 2*chn, n_class=n_class),\r\n                                SelfAttention(2*chn),\r\n                                GBlock(2*chn, 1*chn, n_class=n_class)])\r\n\r\n        # TODO impl ScaledCrossReplicaBatchNorm \r\n        self.ScaledCrossReplicaBN = ScaledCrossReplicaBatchNorm2d(1*chn)\r\n        self.colorize = SpectralNorm(nn.Conv2d(1*chn, 3, [3, 3], padding=1))\r\n\r\n    def forward(self, input, class_id):\r\n        codes = torch.split(input, 20, 1)\r\n        class_emb = self.linear(class_id)  # 128\r\n\r\n        out = self.G_linear(codes[0])\r\n        # out = out.view(-1, 1536, 4, 4)\r\n        out = out.view(-1, self.first_view, 4, 4)\r\n        ids = 1\r\n        for i, conv in enumerate(self.conv):\r\n            if isinstance(conv, GBlock):\r\n                \r\n                conv_code = codes[ids]\r\n                ids = ids+1\r\n                condition = torch.cat([conv_code, class_emb], 1)\r\n                # print(\'condition\',condition.size()) #torch.Size([4, 148])\r\n                out = conv(out, condition)\r\n\r\n            else:\r\n                out = conv(out)\r\n\r\n        out = self.ScaledCrossReplicaBN(out)\r\n        out = F.relu(out)\r\n        out = self.colorize(out)\r\n\r\n        return F.tanh(out)\r\n\r\n\r\nclass Discriminator(nn.Module):\r\n    def __init__(self, n_class=1000, chn=96, debug=False):\r\n        super().__init__()\r\n\r\n        def conv(in_channel, out_channel, downsample=True):\r\n            return GBlock(in_channel, out_channel,\r\n                          bn=False,\r\n                          upsample=False, downsample=downsample)\r\n\r\n        gain = 2 ** 0.5\r\n        \r\n\r\n        if debug:\r\n            chn = 8\r\n        self.debug = debug\r\n\r\n        self.pre_conv = nn.Sequential(SpectralNorm(nn.Conv2d(3, 1*chn, 3,padding=1),),\r\n                                      nn.ReLU(),\r\n                                      SpectralNorm(nn.Conv2d(1*chn, 1*chn, 3,padding=1),),\r\n                                      nn.AvgPool2d(2))\r\n        self.pre_skip = SpectralNorm(nn.Conv2d(3, 1*chn, 1))\r\n\r\n        self.conv = nn.Sequential(conv(1*chn, 1*chn, downsample=True),\r\n                                  SelfAttention(1*chn),\r\n                                  conv(1*chn, 2*chn, downsample=True),    \r\n                                  conv(2*chn, 4*chn, downsample=True),\r\n                                  conv(4*chn, 8*chn, downsample=True),\r\n                                  conv(8*chn, 16*chn, downsample=True),\r\n                                  conv(16*chn, 16*chn, downsample=False))\r\n\r\n        self.linear = SpectralNorm(nn.Linear(16*chn, 1))\r\n\r\n        self.embed = nn.Embedding(n_class, 16*chn)\r\n        self.embed.weight.data.uniform_(-0.1, 0.1)\r\n        self.embed = spectral_norm(self.embed)\r\n\r\n    def forward(self, input, class_id):\r\n        \r\n        out = self.pre_conv(input)\r\n        out = out + self.pre_skip(F.avg_pool2d(input, 2))\r\n        # print(out.size())\r\n        out = self.conv(out)\r\n        out = F.relu(out)\r\n        out = out.view(out.size(0), out.size(1), -1)\r\n        out = out.sum(2)\r\n        out_linear = self.linear(out).squeeze(1)\r\n        embed = self.embed(class_id)\r\n\r\n        prod = (out * embed).sum(1)\r\n\r\n        # if self.debug == debug:\r\n        #     print(\'class_id\',class_id.size())\r\n        #     print(\'out_linear\',out_linear.size())\r\n        #     print(\'embed\', embed.size())\r\n        #     print(\'prod\', prod.size())\r\n\r\n        return out_linear + prod\r\n'"
parameter.py,0,"b""import argparse\r\n\r\ndef str2bool(v):\r\n    return v.lower() in ('true')\r\n\r\ndef get_parameters():\r\n\r\n    parser = argparse.ArgumentParser()\r\n\r\n    # Model hyper-parameters\r\n    parser.add_argument('--model', type=str, default='sagan', choices=['sagan', 'qgan'])\r\n    parser.add_argument('--adv_loss', type=str, default='wgan-gp', choices=['wgan-gp', 'hinge'])\r\n    parser.add_argument('--imsize', type=int, default=128)\r\n    parser.add_argument('--g_num', type=int, default=5)\r\n    parser.add_argument('--chn', type=int, default=64)\r\n    parser.add_argument('--z_dim', type=int, default=120)\r\n    parser.add_argument('--g_conv_dim', type=int, default=64)\r\n    parser.add_argument('--d_conv_dim', type=int, default=64)\r\n    parser.add_argument('--lambda_gp', type=float, default=10)\r\n    parser.add_argument('--version', type=str, default='sagan_1')\r\n\r\n    # Training setting\r\n    parser.add_argument('--total_step', type=int, default=1000000, help='how many times to update the generator')\r\n    parser.add_argument('--d_iters', type=float, default=5)\r\n    parser.add_argument('--batch_size', type=int, default=64)\r\n    parser.add_argument('--num_workers', type=int, default=12)\r\n    parser.add_argument('--g_lr', type=float, default=0.0001)\r\n    parser.add_argument('--d_lr', type=float, default=0.0004)\r\n    parser.add_argument('--lr_decay', type=float, default=0.95)\r\n    parser.add_argument('--beta1', type=float, default=0.0)\r\n    parser.add_argument('--beta2', type=float, default=0.9)\r\n\r\n    # using pretrained\r\n    parser.add_argument('--pretrained_model', type=int, default=None)\r\n\r\n    # Misc\r\n    parser.add_argument('--train', type=str2bool, default=True)\r\n    parser.add_argument('--parallel', type=str2bool, default=False)\r\n    parser.add_argument('--gpus', type=str, default='0', help='gpuids eg: 0,1,2,3  --parallel True  ')\r\n    parser.add_argument('--dataset', type=str, default='lsun', choices=['lsun', 'celeb','off'])\r\n    parser.add_argument('--use_tensorboard', type=str2bool, default=False)\r\n\r\n    # Path\r\n    parser.add_argument('--image_path', type=str, default='./data')\r\n    parser.add_argument('--log_path', type=str, default='./logs')\r\n    parser.add_argument('--model_save_path', type=str, default='./models')\r\n    parser.add_argument('--sample_path', type=str, default='./samples')\r\n    parser.add_argument('--attn_path', type=str, default='./attn')\r\n\r\n    # Step size\r\n    parser.add_argument('--log_step', type=int, default=10)\r\n    parser.add_argument('--sample_step', type=int, default=100)\r\n    parser.add_argument('--model_save_step', type=float, default=1.0)\r\n\r\n\r\n    return parser.parse_args()\r\n"""
spectral.py,7,"b'import torch\r\nfrom torch.optim.optimizer import Optimizer, required\r\n\r\nfrom torch.autograd import Variable\r\nimport torch.nn.functional as F\r\nfrom torch import nn\r\nfrom torch import Tensor\r\nfrom torch.nn import Parameter\r\n\r\ndef l2normalize(v, eps=1e-12):\r\n    return v / (v.norm() + eps)\r\n\r\n\r\nclass SpectralNorm(nn.Module):\r\n    def __init__(self, module, name=\'weight\', power_iterations=1):\r\n        super(SpectralNorm, self).__init__()\r\n        self.module = module\r\n        self.name = name\r\n        self.power_iterations = power_iterations\r\n        if not self._made_params():\r\n            self._make_params()\r\n\r\n    def _update_u_v(self):\r\n        u = getattr(self.module, self.name + ""_u"")\r\n        v = getattr(self.module, self.name + ""_v"")\r\n        w = getattr(self.module, self.name + ""_bar"")\r\n\r\n        height = w.data.shape[0]\r\n        for _ in range(self.power_iterations):\r\n            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\r\n            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\r\n\r\n        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\r\n        sigma = u.dot(w.view(height, -1).mv(v))\r\n        setattr(self.module, self.name, w / sigma.expand_as(w))\r\n\r\n    def _made_params(self):\r\n        try:\r\n            u = getattr(self.module, self.name + ""_u"")\r\n            v = getattr(self.module, self.name + ""_v"")\r\n            w = getattr(self.module, self.name + ""_bar"")\r\n            return True\r\n        except AttributeError:\r\n            return False\r\n\r\n\r\n    def _make_params(self):\r\n        w = getattr(self.module, self.name)\r\n\r\n        height = w.data.shape[0]\r\n        width = w.view(height, -1).data.shape[1]\r\n\r\n        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\r\n        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\r\n        u.data = l2normalize(u.data)\r\n        v.data = l2normalize(v.data)\r\n        w_bar = Parameter(w.data)\r\n\r\n        del self.module._parameters[self.name]\r\n\r\n        self.module.register_parameter(self.name + ""_u"", u)\r\n        self.module.register_parameter(self.name + ""_v"", v)\r\n        self.module.register_parameter(self.name + ""_bar"", w_bar)\r\n\r\n\r\n    def forward(self, *args):\r\n        self._update_u_v()\r\n        return self.module.forward(*args)'"
trainer.py,24,"b'\r\nimport os\r\nimport time\r\nimport torch\r\nimport datetime\r\n\r\nimport torch.nn as nn\r\nfrom torch.autograd import Variable\r\nfrom torchvision.utils import save_image\r\n\r\nfrom model_resnet import Generator, Discriminator\r\nfrom utils import *\r\n\r\nclass Trainer(object):\r\n    def __init__(self, data_loader, config):\r\n\r\n        # Data loader\r\n        self.data_loader = data_loader\r\n\r\n        # exact model and loss\r\n        self.model = config.model\r\n        self.adv_loss = config.adv_loss\r\n\r\n        # Model hyper-parameters\r\n        self.imsize = config.imsize\r\n        self.g_num = config.g_num\r\n        self.z_dim = config.z_dim\r\n        self.g_conv_dim = config.g_conv_dim\r\n        self.d_conv_dim = config.d_conv_dim\r\n        self.parallel = config.parallel\r\n        self.gpus = config.gpus\r\n\r\n        self.lambda_gp = config.lambda_gp\r\n        self.total_step = config.total_step\r\n        self.d_iters = config.d_iters\r\n        self.batch_size = config.batch_size\r\n        self.num_workers = config.num_workers\r\n        self.g_lr = config.g_lr\r\n        self.d_lr = config.d_lr\r\n        self.lr_decay = config.lr_decay\r\n        self.beta1 = config.beta1\r\n        self.beta2 = config.beta2\r\n        self.pretrained_model = config.pretrained_model\r\n\r\n        self.dataset = config.dataset\r\n        self.use_tensorboard = config.use_tensorboard\r\n        self.image_path = config.image_path\r\n        self.log_path = config.log_path\r\n        self.model_save_path = config.model_save_path\r\n        self.sample_path = config.sample_path\r\n        self.log_step = config.log_step\r\n        self.sample_step = config.sample_step\r\n        self.model_save_step = config.model_save_step\r\n        self.version = config.version\r\n\r\n        self.n_class = config.n_class\r\n        self.chn = config.chn\r\n\r\n        # Path\r\n        self.log_path = os.path.join(config.log_path, self.version)\r\n        self.sample_path = os.path.join(config.sample_path, self.version)\r\n        self.model_save_path = os.path.join(config.model_save_path, self.version)\r\n\r\n        self.device = torch.device(\'cuda\' if torch.cuda.is_available() else \'cpu\')\r\n\r\n        print(\'build_model...\')\r\n        self.build_model()\r\n\r\n        if self.use_tensorboard:\r\n            self.build_tensorboard()\r\n\r\n        # Start with trained model\r\n        if self.pretrained_model:\r\n            print(\'load_pretrained_model...\')\r\n            self.load_pretrained_model()\r\n\r\n\r\n    def label_sampel(self):\r\n        label = torch.LongTensor(self.batch_size, 1).random_()%self.n_class\r\n        one_hot= torch.zeros(self.batch_size, self.n_class).scatter_(1, label, 1)\r\n        return label.squeeze(1).to(self.device), one_hot.to(self.device)       \r\n\r\n    def train(self):\r\n\r\n        # Data iterator\r\n        data_iter = iter(self.data_loader)\r\n        step_per_epoch = len(self.data_loader)\r\n        model_save_step = int(self.model_save_step * step_per_epoch)\r\n\r\n        # Fixed input for debugging\r\n        fixed_z = tensor2var(torch.randn(self.batch_size, self.z_dim))\r\n\r\n        # Start with trained model\r\n        if self.pretrained_model:\r\n            start = self.pretrained_model + 1\r\n        else:\r\n            start = 0\r\n\r\n        # Start time\r\n        print(\'Start   ======  training...\')\r\n        start_time = time.time()\r\n        for step in range(start, self.total_step):\r\n\r\n            # ================== Train D ================== #\r\n            self.D.train()\r\n            self.G.train()\r\n\r\n            try:\r\n                real_images, real_labels = next(data_iter)\r\n            except:\r\n                data_iter = iter(self.data_loader)\r\n                real_images, real_labels = next(data_iter)\r\n\r\n            # Compute loss with real images\r\n\r\n            real_labels = real_labels.to(self.device)\r\n            real_images = real_images.to(self.device)\r\n\r\n            d_out_real = self.D(real_images, real_labels)\r\n            if self.adv_loss == \'wgan-gp\':\r\n                d_loss_real = - torch.mean(d_out_real)\r\n            elif self.adv_loss == \'hinge\':\r\n                d_loss_real = torch.nn.ReLU()(1.0 - d_out_real).mean()\r\n\r\n            # apply Gumbel Softmax\r\n            z = torch.randn(self.batch_size, self.z_dim).to(self.device)\r\n\r\n            z_class, z_class_one_hot = self.label_sampel()\r\n \r\n            fake_images = self.G(z, z_class_one_hot)\r\n            d_out_fake = self.D(fake_images, z_class)\r\n\r\n            if self.adv_loss == \'wgan-gp\':\r\n                d_loss_fake = d_out_fake.mean()\r\n            elif self.adv_loss == \'hinge\':\r\n                d_loss_fake = torch.nn.ReLU()(1.0 + d_out_fake).mean()\r\n\r\n\r\n            # Backward + Optimize\r\n            d_loss = d_loss_real + d_loss_fake\r\n            self.reset_grad()\r\n            d_loss.backward()\r\n            self.d_optimizer.step()\r\n\r\n\r\n            if self.adv_loss == \'wgan-gp\':\r\n                # Compute gradient penalty\r\n                alpha = torch.rand(real_images.size(0), 1, 1, 1).to(self.device).expand_as(real_images)\r\n                interpolated = Variable(alpha * real_images.data + (1 - alpha) * fake_images.data, requires_grad=True)\r\n                out = self.D(interpolated)\r\n\r\n                grad = torch.autograd.grad(outputs=out,\r\n                                           inputs=interpolated,\r\n                                           grad_outputs=torch.ones(out.size()).to(self.device),\r\n                                           retain_graph=True,\r\n                                           create_graph=True,\r\n                                           only_inputs=True)[0]\r\n\r\n                grad = grad.view(grad.size(0), -1)\r\n                grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\r\n                d_loss_gp = torch.mean((grad_l2norm - 1) ** 2)\r\n\r\n                # Backward + Optimize\r\n                d_loss = self.lambda_gp * d_loss_gp\r\n\r\n                self.reset_grad()\r\n                d_loss.backward()\r\n                self.d_optimizer.step()\r\n\r\n            # ================== Train G and gumbel ================== #\r\n            # Create random noise\r\n            z = torch.randn(self.batch_size, self.z_dim).to(self.device)\r\n            z_class, z_class_one_hot = self.label_sampel()\r\n            \r\n            fake_images = self.G(z, z_class_one_hot)\r\n\r\n            # Compute loss with fake images\r\n            g_out_fake = self.D(fake_images, z_class)  # batch x n\r\n            if self.adv_loss == \'wgan-gp\':\r\n                g_loss_fake = - g_out_fake.mean()\r\n            elif self.adv_loss == \'hinge\':\r\n                g_loss_fake = - g_out_fake.mean()\r\n\r\n            self.reset_grad()\r\n            g_loss_fake.backward()\r\n            self.g_optimizer.step()\r\n\r\n\r\n            # Print out log info\r\n            if (step + 1) % self.log_step == 0:\r\n                elapsed = time.time() - start_time\r\n                elapsed = str(datetime.timedelta(seconds=elapsed))\r\n                print(""Elapsed [{}], G_step [{}/{}], D_step[{}/{}], d_out_real: {:.4f}, d_out_fake: {:.4f}, g_loss_fake: {:.4f}"".\r\n                      format(elapsed, step + 1, self.total_step, (step + 1),\r\n                             self.total_step , d_loss_real.item(), d_loss_fake.item(), g_loss_fake.item()))\r\n                \r\n                if self.use_tensorboard:\r\n                    self.writer.add_scalar(\'data/d_loss_real\', d_loss_real.item(),(step + 1))\r\n                    self.writer.add_scalar(\'data/d_loss_fake\', d_loss_fake.item(),(step + 1))\r\n                    self.writer.add_scalar(\'data/d_loss\', d_loss.item(), (step + 1))\r\n\r\n                    self.writer.add_scalar(\'data/g_loss_fake\', g_loss_fake.item(), (step + 1))\r\n\r\n\r\n            # Sample images\r\n            if (step + 1) % self.sample_step == 0:\r\n                print(\'Sample images {}_fake.png\'.format(step + 1))\r\n                fake_images= self.G(fixed_z, z_class_one_hot)\r\n                save_image(denorm(fake_images.data),\r\n                           os.path.join(self.sample_path, \'{}_fake.png\'.format(step + 1)))\r\n\r\n            if (step+1) % model_save_step==0:\r\n                torch.save(self.G.state_dict(),\r\n                           os.path.join(self.model_save_path, \'{}_G.pth\'.format(step + 1)))\r\n                torch.save(self.D.state_dict(),\r\n                           os.path.join(self.model_save_path, \'{}_D.pth\'.format(step + 1)))\r\n            \r\n            \r\n\r\n    def build_model(self):\r\n        # code_dim=100, n_class=1000\r\n        self.G = Generator(self.z_dim, self.n_class, chn=self.chn).to(self.device)\r\n        self.D = Discriminator(self.n_class, chn=self.chn).to(self.device)\r\n        if self.parallel:\r\n            print(\'use parallel...\')\r\n            print(\'gpuids \', self.gpus)\r\n            gpus = [int(i) for i in self.gpus.split(\',\')]\r\n    \r\n            self.G = nn.DataParallel(self.G, device_ids=gpus)\r\n            self.D = nn.DataParallel(self.D, device_ids=gpus)\r\n\r\n        # self.G.apply(weights_init)\r\n        # self.D.apply(weights_init)\r\n\r\n        # Loss and optimizer\r\n        # self.g_optimizer = torch.optim.Adam(self.G.parameters(), self.g_lr, [self.beta1, self.beta2])\r\n        self.g_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.G.parameters()), self.g_lr, [self.beta1, self.beta2])\r\n        self.d_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.D.parameters()), self.d_lr, [self.beta1, self.beta2])\r\n\r\n        self.c_loss = torch.nn.CrossEntropyLoss()\r\n        # print networks\r\n        print(self.G)\r\n        print(self.D)\r\n\r\n    def build_tensorboard(self):\r\n        from tensorboardX import SummaryWriter\r\n        # from logger import Logger\r\n        # self.logger = Logger(self.log_path)\r\n        \r\n        tf_logs_path = os.path.join(self.log_path, \'tf_logs\')\r\n        self.writer = SummaryWriter(log_dir=tf_logs_path)\r\n\r\n\r\n    def load_pretrained_model(self):\r\n        self.G.load_state_dict(torch.load(os.path.join(\r\n            self.model_save_path, \'{}_G.pth\'.format(self.pretrained_model))))\r\n        self.D.load_state_dict(torch.load(os.path.join(\r\n            self.model_save_path, \'{}_D.pth\'.format(self.pretrained_model))))\r\n        print(\'loaded trained models (step: {})..!\'.format(self.pretrained_model))\r\n\r\n    def reset_grad(self):\r\n        self.d_optimizer.zero_grad()\r\n        self.g_optimizer.zero_grad()\r\n\r\n    def save_sample(self, data_iter):\r\n        real_images, _ = next(data_iter)\r\n        save_image(denorm(real_images), os.path.join(self.sample_path, \'real.png\'))\r\n'"
utils.py,3,"b""import os\r\nimport torch\r\nfrom torch.autograd import Variable\r\nfrom torch.nn import init\r\n\r\ndef make_folder(path, version):\r\n        if not os.path.exists(os.path.join(path, version)):\r\n            os.makedirs(os.path.join(path, version))\r\n\r\n\r\ndef tensor2var(x, grad=False):\r\n    if torch.cuda.is_available():\r\n        x = x.cuda()\r\n    return Variable(x, requires_grad=grad)\r\n\r\ndef var2tensor(x):\r\n    return x.data.cpu()\r\n\r\ndef var2numpy(x):\r\n    return x.data.cpu().numpy()\r\n\r\ndef denorm(x):\r\n    out = (x + 1) / 2\r\n    return out.clamp_(0, 1)\r\n\r\ndef weights_init(m):\r\n    classname = m.__class__.__name__\r\n    # print(classname)\r\n    if classname.find('Conv2d') != -1:\r\n        init.xavier_normal_(m.weight.data)\r\n        init.constant_(m.bias.data, 0.0)\r\n    elif classname.find('Linear') != -1:\r\n        init.xavier_normal_(m.weight.data)\r\n        init.constant_(m.bias.data, 0.0)\r\n\r\n"""
