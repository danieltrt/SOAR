file_path,api_count,code
cifar.py,9,"b'""""""\n    PyTorch training code for\n    ""Paying More Attention to Attention: Improving the Performance of\n                Convolutional Neural Networks via Attention Transfer""\n    https://arxiv.org/abs/1612.03928\n    \n    This file includes:\n     * CIFAR ResNet and Wide ResNet training code which exactly reproduces\n       https://github.com/szagoruyko/wide-residual-networks\n     * Activation-based attention transfer\n     * Knowledge distillation implementation\n\n    2017 Sergey Zagoruyko\n""""""\n\nimport argparse\nimport os\nimport json\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nfrom torch.optim import SGD\nimport torchvision.transforms as T\nfrom torchvision import datasets\nimport torch.nn.functional as F\nimport torchnet as tnt\nfrom torchnet.engine import Engine\nfrom torch.utils.data import DataLoader\nimport torch.backends.cudnn as cudnn\nimport utils\n\ncudnn.benchmark = True\n\nparser = argparse.ArgumentParser(description=\'Wide Residual Networks\')\n# Model options\nparser.add_argument(\'--depth\', default=16, type=int)\nparser.add_argument(\'--width\', default=1, type=float)\nparser.add_argument(\'--dataset\', default=\'CIFAR10\', type=str)\nparser.add_argument(\'--dataroot\', default=\'.\', type=str)\nparser.add_argument(\'--dtype\', default=\'float\', type=str)\nparser.add_argument(\'--nthread\', default=4, type=int)\nparser.add_argument(\'--teacher_id\', default=\'\', type=str)\n\n# Training options\nparser.add_argument(\'--batch_size\', default=128, type=int)\nparser.add_argument(\'--lr\', default=0.1, type=float)\nparser.add_argument(\'--epochs\', default=200, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--weight_decay\', default=0.0005, type=float)\nparser.add_argument(\'--epoch_step\', default=\'[60,120,160]\', type=str,\n                    help=\'json list with epochs to drop lr on\')\nparser.add_argument(\'--lr_decay_ratio\', default=0.2, type=float)\nparser.add_argument(\'--resume\', default=\'\', type=str)\nparser.add_argument(\'--randomcrop_pad\', default=4, type=float)\nparser.add_argument(\'--temperature\', default=4, type=float)\nparser.add_argument(\'--alpha\', default=0, type=float)\nparser.add_argument(\'--beta\', default=0, type=float)\n\n# Device options\nparser.add_argument(\'--cuda\', action=\'store_true\')\nparser.add_argument(\'--save\', default=\'\', type=str,\n                    help=\'save parameters and logs in this folder\')\nparser.add_argument(\'--ngpu\', default=1, type=int,\n                    help=\'number of GPUs to use for training\')\nparser.add_argument(\'--gpu_id\', default=\'0\', type=str,\n                    help=\'id(s) for CUDA_VISIBLE_DEVICES\')\n\n\ndef create_dataset(opt, train):\n    transform = T.Compose([\n        T.ToTensor(),\n        T.Normalize(np.array([125.3, 123.0, 113.9]) / 255.0,\n                    np.array([63.0, 62.1, 66.7]) / 255.0),\n    ])\n    if train:\n        transform = T.Compose([\n            T.Pad(4, padding_mode=\'reflect\'),\n            T.RandomHorizontalFlip(),\n            T.RandomCrop(32),\n            transform\n        ])\n    return getattr(datasets, opt.dataset)(opt.dataroot, train=train, download=True, transform=transform)\n\n\ndef resnet(depth, width, num_classes):\n    assert (depth - 4) % 6 == 0, \'depth should be 6n+4\'\n    n = (depth - 4) // 6\n    widths = [int(v * width) for v in (16, 32, 64)]\n\n    def gen_block_params(ni, no):\n        return {\n            \'conv0\': utils.conv_params(ni, no, 3),\n            \'conv1\': utils.conv_params(no, no, 3),\n            \'bn0\': utils.bnparams(ni),\n            \'bn1\': utils.bnparams(no),\n            \'convdim\': utils.conv_params(ni, no, 1) if ni != no else None,\n        }\n\n    def gen_group_params(ni, no, count):\n        return {\'block%d\' % i: gen_block_params(ni if i == 0 else no, no)\n                for i in range(count)}\n\n    flat_params = utils.cast(utils.flatten({\n        \'conv0\': utils.conv_params(3, 16, 3),\n        \'group0\': gen_group_params(16, widths[0], n),\n        \'group1\': gen_group_params(widths[0], widths[1], n),\n        \'group2\': gen_group_params(widths[1], widths[2], n),\n        \'bn\': utils.bnparams(widths[2]),\n        \'fc\': utils.linear_params(widths[2], num_classes),\n    }))\n\n    utils.set_requires_grad_except_bn_(flat_params)\n\n    def block(x, params, base, mode, stride):\n        o1 = F.relu(utils.batch_norm(x, params, base + \'.bn0\', mode), inplace=True)\n        y = F.conv2d(o1, params[base + \'.conv0\'], stride=stride, padding=1)\n        o2 = F.relu(utils.batch_norm(y, params, base + \'.bn1\', mode), inplace=True)\n        z = F.conv2d(o2, params[base + \'.conv1\'], stride=1, padding=1)\n        if base + \'.convdim\' in params:\n            return z + F.conv2d(o1, params[base + \'.convdim\'], stride=stride)\n        else:\n            return z + x\n\n    def group(o, params, base, mode, stride):\n        for i in range(n):\n            o = block(o, params, f\'{base}.block{i}\', mode, stride if i == 0 else 1)\n        return o\n\n    def f(input, params, mode, base=\'\'):\n        x = F.conv2d(input, params[f\'{base}conv0\'], padding=1)\n        g0 = group(x, params, f\'{base}group0\', mode, 1)\n        g1 = group(g0, params, f\'{base}group1\', mode, 2)\n        g2 = group(g1, params, f\'{base}group2\', mode, 2)\n        o = F.relu(utils.batch_norm(g2, params, f\'{base}bn\', mode))\n        o = F.avg_pool2d(o, 8, 1, 0)\n        o = o.view(o.size(0), -1)\n        o = F.linear(o, params[f\'{base}fc.weight\'], params[f\'{base}fc.bias\'])\n        return o, (g0, g1, g2)\n\n    return f, flat_params\n\n\ndef main():\n    opt = parser.parse_args()\n    print(\'parsed options:\', vars(opt))\n    epoch_step = json.loads(opt.epoch_step)\n    num_classes = 10 if opt.dataset == \'CIFAR10\' else 100\n\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = opt.gpu_id\n\n    def create_iterator(mode):\n        return DataLoader(create_dataset(opt, mode), opt.batch_size, shuffle=mode,\n                          num_workers=opt.nthread, pin_memory=torch.cuda.is_available())\n\n    train_loader = create_iterator(True)\n    test_loader = create_iterator(False)\n\n    # deal with student first\n    f_s, params_s = resnet(opt.depth, opt.width, num_classes)\n\n    # deal with teacher\n    if opt.teacher_id:\n        with open(os.path.join(\'logs\', opt.teacher_id, \'log.txt\'), \'r\') as ff:\n            line = ff.readline()\n            r = line.find(\'json_stats\')\n            info = json.loads(line[r + 12:])\n        f_t = resnet(info[\'depth\'], info[\'width\'], num_classes)[0]\n        model_data = torch.load(os.path.join(\'logs\', opt.teacher_id, \'model.pt7\'))\n        params_t = model_data[\'params\']\n\n        # merge teacher and student params\n        params = {\'student.\' + k: v for k, v in params_s.items()}\n        for k, v in params_t.items():\n            params[\'teacher.\' + k] = v.detach().requires_grad_(False)\n\n        def f(inputs, params, mode):\n            y_s, g_s = f_s(inputs, params, mode, \'student.\')\n            with torch.no_grad():\n                y_t, g_t = f_t(inputs, params, False, \'teacher.\')\n            return y_s, y_t, [utils.at_loss(x, y) for x, y in zip(g_s, g_t)]\n    else:\n        f, params = f_s, params_s\n\n    def create_optimizer(opt, lr):\n        print(\'creating optimizer with lr = \', lr)\n        return SGD((v for v in params.values() if v.requires_grad), lr,\n                   momentum=0.9, weight_decay=opt.weight_decay)\n\n    optimizer = create_optimizer(opt, opt.lr)\n\n    epoch = 0\n    if opt.resume != \'\':\n        state_dict = torch.load(opt.resume)\n        epoch = state_dict[\'epoch\']\n        params_tensors = state_dict[\'params\']\n        for k, v in params.items():\n            v.data.copy_(params_tensors[k])\n        optimizer.load_state_dict(state_dict[\'optimizer\'])\n\n    print(\'\\nParameters:\')\n    utils.print_tensor_dict(params)\n\n    n_parameters = sum(p.numel() for p in list(params_s.values()))\n    print(\'\\nTotal number of parameters:\', n_parameters)\n\n    meter_loss = tnt.meter.AverageValueMeter()\n    classacc = tnt.meter.ClassErrorMeter(accuracy=True)\n    timer_train = tnt.meter.TimeMeter(\'s\')\n    timer_test = tnt.meter.TimeMeter(\'s\')\n    meters_at = [tnt.meter.AverageValueMeter() for i in range(3)]\n\n    if not os.path.exists(opt.save):\n        os.mkdir(opt.save)\n\n    def h(sample):\n        inputs = utils.cast(sample[0], opt.dtype).detach()\n        targets = utils.cast(sample[1], \'long\')\n        if opt.teacher_id != \'\':\n            y_s, y_t, loss_groups = utils.data_parallel(f, inputs, params, sample[2], range(opt.ngpu))\n            loss_groups = [v.sum() for v in loss_groups]\n            [m.add(v.item()) for m, v in zip(meters_at, loss_groups)]\n            return utils.distillation(y_s, y_t, targets, opt.temperature, opt.alpha) \\\n                   + opt.beta * sum(loss_groups), y_s\n        else:\n            y = utils.data_parallel(f, inputs, params, sample[2], range(opt.ngpu))[0]\n            return F.cross_entropy(y, targets), y\n\n    def log(t, state):\n        torch.save(dict(params={k: v.data for k, v in params.items()},\n                        optimizer=state[\'optimizer\'].state_dict(),\n                        epoch=t[\'epoch\']),\n                   os.path.join(opt.save, \'model.pt7\'))\n        z = vars(opt).copy(); z.update(t)\n        logname = os.path.join(opt.save, \'log.txt\')\n        with open(logname, \'a\') as f:\n            f.write(\'json_stats: \' + json.dumps(z) + \'\\n\')\n        print(z)\n\n    def on_sample(state):\n        state[\'sample\'].append(state[\'train\'])\n\n    def on_forward(state):\n        classacc.add(state[\'output\'].data, state[\'sample\'][1])\n        meter_loss.add(state[\'loss\'].item())\n\n    def on_start(state):\n        state[\'epoch\'] = epoch\n\n    def on_start_epoch(state):\n        classacc.reset()\n        meter_loss.reset()\n        timer_train.reset()\n        [meter.reset() for meter in meters_at]\n        state[\'iterator\'] = tqdm(train_loader)\n\n        epoch = state[\'epoch\'] + 1\n        if epoch in epoch_step:\n            lr = state[\'optimizer\'].param_groups[0][\'lr\']\n            state[\'optimizer\'] = create_optimizer(opt, lr * opt.lr_decay_ratio)\n\n    def on_end_epoch(state):\n        train_loss = meter_loss.mean\n        train_acc = classacc.value()\n        train_time = timer_train.value()\n        meter_loss.reset()\n        classacc.reset()\n        timer_test.reset()\n\n        engine.test(h, test_loader)\n\n        test_acc = classacc.value()[0]\n        print(log({\n            ""train_loss"": train_loss,\n            ""train_acc"": train_acc[0],\n            ""test_loss"": meter_loss.mean,\n            ""test_acc"": test_acc,\n            ""epoch"": state[\'epoch\'],\n            ""num_classes"": num_classes,\n            ""n_parameters"": n_parameters,\n            ""train_time"": train_time,\n            ""test_time"": timer_test.value(),\n            ""at_losses"": [m.value() for m in meters_at],\n           }, state))\n        print(\'==> id: %s (%d/%d), test_acc: \\33[91m%.2f\\033[0m\' % \\\n                       (opt.save, state[\'epoch\'], opt.epochs, test_acc))\n\n    engine = Engine()\n    engine.hooks[\'on_sample\'] = on_sample\n    engine.hooks[\'on_forward\'] = on_forward\n    engine.hooks[\'on_start_epoch\'] = on_start_epoch\n    engine.hooks[\'on_end_epoch\'] = on_end_epoch\n    engine.hooks[\'on_start\'] = on_start\n    engine.train(h, train_loader, opt.epochs, optimizer)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
imagenet.py,8,"b'""""""\n    PyTorch training code for\n    ""Paying More Attention to Attention: Improving the Performance of\n                Convolutional Neural Networks via Attention Transfer""\n    https://arxiv.org/abs/1612.03928\n    \n    This file includes:\n     * ImageNet ResNet training code that follows\n       https://github.com/facebook/fb.resnet.torch\n     * Activation-based attention transfer on ImageNet\n\n    2017 Sergey Zagoruyko\n""""""\n\nimport argparse\nimport os\nimport re\nimport json\nimport numpy as np\nfrom torch.optim import SGD\nfrom tqdm import tqdm\nimport torch\nimport torchnet as tnt\nfrom torchnet.engine import Engine\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as T\nfrom torch.backends import cudnn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport utils\nfrom collections import OrderedDict\n\ncudnn.benchmark = True\n\nparser = argparse.ArgumentParser(description=\'Wide Residual Networks\')\n# Model options\nparser.add_argument(\'--dtype\', default=\'float\', type=str)\nparser.add_argument(\'--depth\', default=18, type=int)\nparser.add_argument(\'--width\', default=1, type=float)\nparser.add_argument(\'--imagenetpath\', default=\'/home/zagoruys/ILSVRC2012\', type=str)\nparser.add_argument(\'--nthread\', default=4, type=int)\nparser.add_argument(\'--teacher_params\', default=\'\', type=str)\n\n# Training options\nparser.add_argument(\'--batch_size\', default=256, type=int)\nparser.add_argument(\'--lr\', default=0.1, type=float)\nparser.add_argument(\'--epochs\', default=100, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--weight_decay\', default=1e-4, type=float)\nparser.add_argument(\'--epoch_step\', default=\'[30,60,90]\', type=str,\n                    help=\'json list with epochs to drop lr on\')\nparser.add_argument(\'--lr_decay_ratio\', default=0.1, type=float)\nparser.add_argument(\'--resume\', default=\'\', type=str)\nparser.add_argument(\'--temperature\', default=4, type=float)\nparser.add_argument(\'--alpha\', default=0, type=float)\nparser.add_argument(\'--beta\', default=0, type=float)\n\n\n# Device options\nparser.add_argument(\'--cuda\', action=\'store_true\')\nparser.add_argument(\'--save\', default=\'\', type=str,\n                    help=\'save parameters and logs in this folder\')\nparser.add_argument(\'--ngpu\', default=1, type=int,\n                    help=\'number of GPUs to use for training\')\nparser.add_argument(\'--gpu_id\', default=\'0\', type=str,\n                    help=\'id(s) for CUDA_VISIBLE_DEVICES\')\n\n\ndef get_iterator(imagenetpath, batch_size, nthread, mode):\n    imagenetpath = os.path.expanduser(imagenetpath)\n\n    normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\n    print(""| setting up data loader..."")\n    if mode:\n        traindir = os.path.join(imagenetpath, \'train\')\n        ds = ImageFolder(traindir, T.Compose([\n            T.RandomResizedCrop(224),\n            T.RandomHorizontalFlip(),\n            T.ToTensor(),\n            normalize,\n        ]))\n    else:\n        valdir = os.path.join(imagenetpath, \'val\')\n        ds = ImageFolder(valdir, T.Compose([\n            T.Resize(256),\n            T.CenterCrop(224),\n            T.ToTensor(),\n            normalize,\n        ]))\n\n    return DataLoader(ds, batch_size=batch_size, shuffle=mode,\n                      num_workers=nthread, pin_memory=True)\n\n\ndef define_teacher(params_file):\n    """""" Defines student resnet\n        \n        Network size is determined from parameters, assuming\n        pre-activation basic-block resnet (ResNet-18 or ResNet-34)\n    """"""\n    params = torch.load(params_file)\n\n    params = {k: p.cuda() for k, p in params.items()}\n\n    blocks = [sum([re.match(\'group%d.block\\d+.conv0.weight\'%j, k) is not None\n                   for k in list(params.keys())]) for j in range(4)]\n\n    def conv2d(input, params, base, stride=1, pad=0):\n        return F.conv2d(input, params[base + \'.weight\'], params[base + \'.bias\'], stride, pad)\n\n    def group(input, params, base, stride, n):\n        o = input\n        for i in range(0,n):\n            b_base = \'%s.block%d.conv\' % (base, i)\n            x = o\n            o = conv2d(x, params, b_base + \'0\', pad=1, stride=stride if i == 0 else 1)\n            o = F.relu(o, inplace=True)\n            o = conv2d(o, params, b_base + \'1\', pad=1)\n            if i == 0 and stride != 1:\n                o += F.conv2d(x, params[b_base + \'_dim.weight\'], stride=stride)\n            else:\n                o += x\n            o = F.relu(o, inplace=True)\n        return o\n\n    def f(inputs, params, pr=\'\'):\n        o = conv2d(inputs, params, pr+\'conv0\', 2, 3)\n        o = F.relu(o, inplace=True)\n        o = F.max_pool2d(o, 3, 2, 1)\n        o_g0 = group(o, params, pr+\'group0\', 1, blocks[0])\n        o_g1 = group(o_g0, params, pr+\'group1\', 2, blocks[1])\n        o_g2 = group(o_g1, params, pr+\'group2\', 2, blocks[2])\n        o_g3 = group(o_g2, params, pr+\'group3\', 2, blocks[3])\n        o = F.avg_pool2d(o_g3, 7, 1, 0)\n        o = o.view(o.size(0), -1)\n        o = F.linear(o, params[pr+\'fc.weight\'], params[pr+\'fc.bias\'])\n        return o, (o_g0, o_g1, o_g2, o_g3)\n\n    return f, params\n\n\ndef define_student(depth, width):\n    definitions = {18: [2,2,2,2],\n                   34: [3,4,6,5]}\n    assert depth in list(definitions.keys())\n    widths = [int(w * width) for w in (64, 128, 256, 512)]\n    blocks = definitions[depth]\n\n    def gen_block_params(ni, no):\n        return {\'conv0\': utils.conv_params(ni, no, 3),\n                \'conv1\': utils.conv_params(no, no, 3),\n                \'bn0\': utils.bnparams(no),\n                \'bn1\': utils.bnparams(no),\n                \'convdim\': utils.conv_params(ni, no, 1) if ni != no else None,\n                }\n\n    def gen_group_params(ni, no, count):\n        return {\'block%d\'%i: gen_block_params(ni if i==0 else no, no)\n                for i in range(count)}\n\n    flat_params = OrderedDict(utils.flatten({\n        \'conv0\': utils.conv_params(3, 64, 7),\n        \'bn0\': utils.bnparams(64),\n        \'group0\': gen_group_params(64, widths[0], blocks[0]),\n        \'group1\': gen_group_params(widths[0], widths[1], blocks[1]),\n        \'group2\': gen_group_params(widths[1], widths[2], blocks[2]),\n        \'group3\': gen_group_params(widths[2], widths[3], blocks[3]),\n        \'fc\': utils.linear_params(widths[3], 1000),\n    }))\n\n    utils.set_requires_grad_except_bn_(flat_params)\n\n    def block(x, params, base, mode, stride):\n        y = F.conv2d(x, params[base+\'.conv0\'], stride=stride, padding=1)\n        o1 = F.relu(utils.batch_norm(y, params, base+\'.bn0\', mode), inplace=True)\n        z = F.conv2d(o1, params[base+\'.conv1\'], stride=1, padding=1)\n        o2 = utils.batch_norm(z, params, base+\'.bn1\', mode)\n        if base + \'.convdim\' in params:\n            return F.relu(o2 + F.conv2d(x, params[base+\'.convdim\'], stride=stride), inplace=True)\n        else:\n            return F.relu(o2 + x, inplace=True)\n\n    def group(o, params, base, mode, stride, n):\n        for i in range(n):\n            o = block(o, params, \'%s.block%d\' % (base, i), mode, stride if i == 0 else 1)\n        return o\n\n    def f(input, params, mode, pr=\'\'):\n        o = F.conv2d(input, params[pr+\'conv0\'], stride=2, padding=3)\n        o = F.relu(utils.batch_norm(o, params, pr+\'bn0\', mode), inplace=True)\n        o = F.max_pool2d(o, 3, 2, 1)\n        g0 = group(o, params, pr+\'group0\', mode, 1, blocks[0])\n        g1 = group(g0, params, pr+\'group1\', mode, 2, blocks[1])\n        g2 = group(g1, params, pr+\'group2\', mode, 2, blocks[2])\n        g3 = group(g2, params, pr+\'group3\', mode, 2, blocks[3])\n        o = F.avg_pool2d(g3, 7)\n        o = o.view(o.size(0), -1)\n        o = F.linear(o, params[pr+\'fc.weight\'], params[pr+\'fc.bias\'])\n        return o, [g0, g1, g2, g3]\n\n    return f, flat_params\n\n\ndef main():\n    opt = parser.parse_args()\n    epoch_step = json.loads(opt.epoch_step)\n    print(\'parsed options:\', vars(opt))\n\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = opt.gpu_id\n\n    epoch_step = json.loads(opt.epoch_step)\n\n    if not os.path.exists(opt.save):\n        os.mkdir(opt.save)\n\n    f_s, params_s = define_student(opt.depth, opt.width)\n    f_t, params_t = define_teacher(opt.teacher_params)\n    params = {\'student.\'+k: v for k, v in params_s.items()}\n    params.update({\'teacher.\'+k: v for k, v in params_t.items()})\n\n    params = OrderedDict((k, p.cuda().detach().requires_grad_(p.requires_grad)) for k, p in params.items())\n\n    optimizable = [v for v in params.values() if v.requires_grad]\n    def create_optimizer(opt, lr):\n        print(\'creating optimizer with lr = \', lr)\n        return SGD(optimizable, lr, momentum=0.9, weight_decay=opt.weight_decay)\n\n    optimizer = create_optimizer(opt, opt.lr)\n\n    iter_train = get_iterator(opt.imagenetpath, opt.batch_size, opt.nthread, True)\n    iter_test = get_iterator(opt.imagenetpath, opt.batch_size, opt.nthread, False)\n\n    epoch = 0\n    if opt.resume != \'\':\n        state_dict = torch.load(opt.resume)\n        epoch = state_dict[\'epoch\']\n        params_tensors = state_dict[\'params\']\n        for k, v in params.items():\n            v.data.copy_(params_tensors[k])\n        optimizer.load_state_dict(state_dict[\'optimizer\'])\n\n    print(\'\\nParameters:\')\n    utils.print_tensor_dict(params)\n\n\n    n_parameters = sum(p.numel() for p in optimizable)\n    print(\'\\nTotal number of parameters:\', n_parameters)\n\n    meter_loss = tnt.meter.AverageValueMeter()\n    classacc = tnt.meter.ClassErrorMeter(topk=[1, 5], accuracy=True)\n    timer_train = tnt.meter.TimeMeter(\'s\')\n    timer_test = tnt.meter.TimeMeter(\'s\')\n    meters_at = [tnt.meter.AverageValueMeter() for i in range(4)]\n\n    def f(inputs, params, mode):\n        y_s, g_s = f_s(inputs, params, mode, \'student.\')\n        with torch.no_grad():\n            y_t, g_t = f_t(inputs, params, \'teacher.\')\n        return y_s, y_t, [utils.at_loss(x, y) for x, y in zip(g_s, g_t)]\n\n    def h(sample):\n        inputs, targets, mode = sample\n        inputs = inputs.cuda().detach()\n        targets = targets.cuda().long().detach()\n        y_s, y_t, loss_groups = utils.data_parallel(f, inputs, params, mode, range(opt.ngpu))\n        loss_groups = [v.sum() for v in loss_groups]\n        [m.add(v.item()) for m,v in zip(meters_at, loss_groups)]\n        return utils.distillation(y_s, y_t, targets, opt.temperature, opt.alpha) \\\n                + opt.beta * sum(loss_groups), y_s\n\n    def log(t, state):\n        torch.save(dict(params={k: v.data for k, v in params.items()},\n                        optimizer=state[\'optimizer\'].state_dict(),\n                        epoch=t[\'epoch\']),\n                   os.path.join(opt.save, \'model.pt7\'))\n        z = vars(opt).copy(); z.update(t)\n        logname = os.path.join(opt.save, \'log.txt\')\n        with open(logname, \'a\') as f:\n            f.write(\'json_stats: \' + json.dumps(z) + \'\\n\')\n        print(z)\n\n    def on_sample(state):\n        state[\'sample\'].append(state[\'train\'])\n\n    def on_forward(state):\n        classacc.add(state[\'output\'].data, state[\'sample\'][1])\n        loss = state[\'loss\'].item()\n        meter_loss.add(loss)\n        if state[\'train\']:\n            state[\'iterator\'].set_postfix(loss=loss)\n\n    def on_start(state):\n        state[\'epoch\'] = epoch\n\n    def on_start_epoch(state):\n        classacc.reset()\n        meter_loss.reset()\n        timer_train.reset()\n        [meter.reset() for meter in meters_at]\n        state[\'iterator\'] = tqdm(iter_train, dynamic_ncols=True)\n\n        epoch = state[\'epoch\'] + 1\n        if epoch in epoch_step:\n            lr = state[\'optimizer\'].param_groups[0][\'lr\']\n            state[\'optimizer\'] = create_optimizer(opt, lr * opt.lr_decay_ratio)\n\n    def on_end_epoch(state):\n        train_loss = meter_loss.value()\n        train_acc = classacc.value()\n        train_time = timer_train.value()\n        meter_loss.reset()\n        classacc.reset()\n        timer_test.reset()\n\n        engine.test(h, iter_test)\n\n        print(log({\n            ""train_loss"": train_loss[0],\n            ""train_acc"": train_acc,\n            ""test_loss"": meter_loss.value()[0],\n            ""test_acc"": classacc.value(),\n            ""epoch"": state[\'epoch\'],\n            ""n_parameters"": n_parameters,\n            ""train_time"": train_time,\n            ""test_time"": timer_test.value(),\n            ""at_losses"": [m.value() for m in meters_at],\n           }, state))\n\n    engine = Engine()\n    engine.hooks[\'on_sample\'] = on_sample\n    engine.hooks[\'on_forward\'] = on_forward\n    engine.hooks[\'on_start_epoch\'] = on_start_epoch\n    engine.hooks[\'on_end_epoch\'] = on_end_epoch\n    engine.hooks[\'on_start\'] = on_start\n    engine.train(h, iter_train, opt.epochs, optimizer)\n\n\nif __name__ == \'__main__\':\n    main()\n'"
utils.py,12,"b""from nested_dict import nested_dict\nfrom functools import partial\nimport torch\nfrom torch.nn.init import kaiming_normal_\nfrom torch.nn.parallel._functions import Broadcast\nfrom torch.nn.parallel import scatter, parallel_apply, gather\nimport torch.nn.functional as F\n\n\ndef distillation(y, teacher_scores, labels, T, alpha):\n    p = F.log_softmax(y/T, dim=1)\n    q = F.softmax(teacher_scores/T, dim=1)\n    l_kl = F.kl_div(p, q, size_average=False) * (T**2) / y.shape[0]\n    l_ce = F.cross_entropy(y, labels)\n    return l_kl * alpha + l_ce * (1. - alpha)\n\n\ndef at(x):\n    return F.normalize(x.pow(2).mean(1).view(x.size(0), -1))\n\n\ndef at_loss(x, y):\n    return (at(x) - at(y)).pow(2).mean()\n\n\ndef cast(params, dtype='float'):\n    if isinstance(params, dict):\n        return {k: cast(v, dtype) for k,v in params.items()}\n    else:\n        return getattr(params.cuda() if torch.cuda.is_available() else params, dtype)()\n\n\ndef conv_params(ni, no, k=1):\n    return kaiming_normal_(torch.Tensor(no, ni, k, k))\n\n\ndef linear_params(ni, no):\n    return {'weight': kaiming_normal_(torch.Tensor(no, ni)), 'bias': torch.zeros(no)}\n\n\ndef bnparams(n):\n    return {'weight': torch.rand(n),\n            'bias': torch.zeros(n),\n            'running_mean': torch.zeros(n),\n            'running_var': torch.ones(n)}\n\n\ndef data_parallel(f, input, params, mode, device_ids, output_device=None):\n    device_ids = list(device_ids)\n    if output_device is None:\n        output_device = device_ids[0]\n\n    if len(device_ids) == 1:\n        return f(input, params, mode)\n\n    params_all = Broadcast.apply(device_ids, *params.values())\n    params_replicas = [{k: params_all[i + j*len(params)] for i, k in enumerate(params.keys())}\n                       for j in range(len(device_ids))]\n\n    replicas = [partial(f, params=p, mode=mode)\n                for p in params_replicas]\n    inputs = scatter([input], device_ids)\n    outputs = parallel_apply(replicas, inputs)\n    return gather(outputs, output_device)\n\n\ndef flatten(params):\n    return {'.'.join(k): v for k, v in nested_dict(params).items_flat() if v is not None}\n\n\ndef batch_norm(x, params, base, mode):\n    return F.batch_norm(x, weight=params[base + '.weight'],\n                        bias=params[base + '.bias'],\n                        running_mean=params[base + '.running_mean'],\n                        running_var=params[base + '.running_var'],\n                        training=mode)\n\n\ndef print_tensor_dict(params):\n    kmax = max(len(key) for key in params.keys())\n    for i, (key, v) in enumerate(params.items()):\n        print(str(i).ljust(5), key.ljust(kmax + 3), str(tuple(v.shape)).ljust(23), torch.typename(v), v.requires_grad)\n\n\ndef set_requires_grad_except_bn_(params):\n    for k, v in params.items():\n        if not k.endswith('running_mean') and not k.endswith('running_var'):\n            v.requires_grad = True\n"""
