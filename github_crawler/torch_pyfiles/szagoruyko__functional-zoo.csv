file_path,api_count,code
imagenet-validation.py,6,"b'# dependencies\nimport re\nimport os\nimport argparse\nimport torch\nfrom tqdm import tqdm\nimport cv2\nimport hickle as hkl\nimport numpy as np\nimport torch.utils.data\nimport torchnet as tnt\nfrom torchvision import cvtransforms\nimport torchvision.datasets as datasets\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\n# input arguments\nparser = argparse.ArgumentParser(description = \'PyTorch ImageNet validation\')\nparser.add_argument(\'--imagenetpath\', metavar=\'PATH\', required=True,\n                    help=\'path to dataset\')\nparser.add_argument(\'--numthreads\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading threads (default: 4)\')\nparser.add_argument(\'--model\', metavar=\'PATH\', required=True,\n                    help=\'path to model\')\n\n\ndef define_model(params):\n    blocks = [sum([re.match(\'group%d.block\\d+.conv0.weight\'%j, k) is not None\n                   for k in params.keys()]) for j in range(4)]\n\n    def conv2d(input, params, base, stride=1, padding=0):\n        return F.conv2d(input, params[base + \'.weight\'], params[base + \'.bias\'], stride, padding)\n\n    def group(input, params, base, stride, n):\n        o = input\n        for i in range(0,n):\n            b_base = (\'%s.block%d.conv\') % (base, i)\n            x = o\n            o = conv2d(x, params, b_base + \'0\', padding=1, stride=i==0 and stride or 1)\n            o = F.relu(o)\n            o = conv2d(o, params, b_base + \'1\', padding=1)\n            if i == 0 and stride != 1:\n                o += conv2d(x, params, b_base + \'_dim\', stride=stride)\n            else:\n                o += x\n            o = F.relu(o)\n        return o\n\n    def f(input, params):\n        o = F.conv2d(input, params[\'conv0.weight\'], params[\'conv0.bias\'], 2, 3)\n        o = F.relu(o)\n        o = F.max_pool2d(o, 3, 2, 1)\n        o_g0 = group(o, params, \'group0\', 1, blocks[0])\n        o_g1 = group(o_g0, params, \'group1\', 2, blocks[1])\n        o_g2 = group(o_g1, params, \'group2\', 2, blocks[2])\n        o_g3 = group(o_g2, params, \'group3\', 2, blocks[3])\n        o = F.avg_pool2d(o_g3, 7)\n        o = o.view(o.size(0), -1)\n        o = F.linear(o, params[\'fc.weight\'], params[\'fc.bias\'])\n        return o\n    return f\n\n\ndef main():\n\n    # parse input arguments\n    args = parser.parse_args()\n\n    def cvload(path):\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        return img\n\n    # set up data loader\n    print(""| setting up data loader..."")\n    valdir = os.path.join(args.imagenetpath, \'val\')\n    ds = datasets.ImageFolder(valdir, tnt.transform.compose([\n            cvtransforms.Scale(256),\n            cvtransforms.CenterCrop(224),\n            lambda x: x.astype(np.float32) / 255.0,\n            cvtransforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                   std=[0.229, 0.224, 0.225]),\n            lambda x: x.transpose(2,0,1).astype(np.float32),\n            torch.from_numpy,\n            ]), loader = cvload)\n    train_loader = torch.utils.data.DataLoader(ds,\n        batch_size=256, shuffle=False,\n        num_workers=args.numthreads, pin_memory=False)\n\n    params = hkl.load(args.model)\n    params = {k: Variable(torch.from_numpy(v).cuda()) for k,v in params.iteritems()}\n\n    f = define_model(params)\n\n    class_err = tnt.meter.ClassErrorMeter(topk=[1,5], accuracy=True)\n\n    for sample in tqdm(train_loader):\n        inputs = Variable(sample[0].cuda(), volatile=True)\n        targets = sample[1]\n        class_err.add(f(inputs, params).data, targets)\n\n    print \'Validation top1/top5 accuracy:\'\n    print class_err.value()\n\nif __name__ == \'__main__\':\n    main()\n'"
visualize.py,1,b'from graphviz import Digraph\nimport torch\nfrom torch.autograd import Variable\n\n\n# make_dot was moved to https://github.com/szagoruyko/pytorchviz\nfrom torchviz import make_dot\n'
