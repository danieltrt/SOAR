file_path,api_count,code
test.py,10,"b'""""""\n/*****************************************************************************/\n\nTest for BatchNorm2dSync with multi-gpu\n\n/*****************************************************************************/\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nsys.path.append(""./"")\nfrom modules import nn as NN\n\ntorch.backends.cudnn.deterministic = True\n\n\ndef init_weight(model):\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n            m.weight.data.normal_(0, np.sqrt(2. / n))\n        elif isinstance(m, NN.BatchNorm2d) or isinstance(m, nn.BatchNorm2d):\n            m.weight.data.fill_(1)\n            m.bias.data.zero_()\n        elif isinstance(m, nn.Linear):\n            m.bias.data.zero_()\n\nnum_gpu = torch.cuda.device_count()\nprint(""num_gpu={}"".format(num_gpu))\nif num_gpu < 2:\n    print(""No multi-gpu found. NN.BatchNorm2d will act as normal nn.BatchNorm2d"")\n\nm1 = nn.Sequential(\n    nn.Conv2d(3, 3, 1, 1, bias=False),\n    nn.BatchNorm2d(3),\n    nn.ReLU(inplace=True),\n    nn.Conv2d(3, 3, 1, 1, bias=False),\n    nn.BatchNorm2d(3),\n).cuda()\ntorch.manual_seed(123)\ninit_weight(m1)\nm2 = nn.Sequential(\n    nn.Conv2d(3, 3, 1, 1, bias=False),\n    NN.BatchNorm2d(3),\n    nn.ReLU(inplace=True),\n    nn.Conv2d(3, 3, 1, 1, bias=False),\n    NN.BatchNorm2d(3),\n).cuda()\ntorch.manual_seed(123)\ninit_weight(m2)\nm2 = nn.DataParallel(m2, device_ids=range(num_gpu))\no1 = torch.optim.SGD(m1.parameters(), 1e-3)\no2 = torch.optim.SGD(m2.parameters(), 1e-3)\ny = torch.ones(num_gpu).float().cuda()\ntorch.manual_seed(123)\nfor _ in range(100):\n    x = torch.rand(num_gpu, 3, 2, 2).cuda()\n    o1.zero_grad()\n    z1 = m1(x)\n    l1 = F.mse_loss(z1.mean(-1).mean(-1).mean(-1), y)\n    l1.backward()\n    o1.step()\n    o2.zero_grad()\n    z2 = m2(x)\n    l2 = F.mse_loss(z2.mean(-1).mean(-1).mean(-1), y)\n    l2.backward()\n    o2.step()\n    print(m2.module[1].bias.grad - m1[1].bias.grad)\n    print(m2.module[1].weight.grad - m1[1].weight.grad)\n    print(m2.module[-1].bias.grad - m1[-1].bias.grad)\n    print(m2.module[-1].weight.grad - m1[-1].weight.grad)\nm2 = m2.module\nprint(""==============================="")\nprint(""m1(nn.BatchNorm2d) running_mean"",\n      m1[1].running_mean, m1[-1].running_mean)\nprint(""m2(NN.BatchNorm2d) running_mean"",\n      m2[1].running_mean, m2[-1].running_mean)\nprint(""m1(nn.BatchNorm2d) running_var"", m1[1].running_var, m1[-1].running_var)\nprint(""m2(NN.BatchNorm2d) running_var"", m2[1].running_var, m2[-1].running_var)\nprint(""m1(nn.BatchNorm2d) weight"", m1[1].weight, m1[-1].weight)\nprint(""m2(NN.BatchNorm2d) weight"", m2[1].weight, m2[-1].weight)\nprint(""m1(nn.BatchNorm2d) bias"", m1[1].bias, m1[-1].bias)\nprint(""m2(NN.BatchNorm2d) bias"", m2[1].bias, m2[-1].bias)\n'"
modules/__init__.py,0,b''
modules/functional/__init__.py,0,b'from .syncbn import batchnorm2d_sync\n'
modules/functional/_csrc.py,3,"b'""""""\n/*****************************************************************************/\n\nExtension module loader\n\ncode referenced from : https://github.com/facebookresearch/maskrcnn-benchmark\n\n/*****************************************************************************/\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport glob\nimport os.path\n\nimport torch\n\ntry:\n    from torch.utils.cpp_extension import load\n    from torch.utils.cpp_extension import CUDA_HOME\nexcept ImportError:\n    raise ImportError(\n        ""The cpp layer extensions requires PyTorch 0.4 or higher"")\n\n\ndef _load_C_extensions():\n    this_dir = os.path.dirname(os.path.abspath(__file__))\n    this_dir = os.path.join(this_dir, ""csrc"")\n\n    main_file = glob.glob(os.path.join(this_dir, ""*.cpp""))\n    sources_cpu = glob.glob(os.path.join(this_dir, ""cpu"", ""*.cpp""))\n    sources_cuda = glob.glob(os.path.join(this_dir, ""cuda"", ""*.cu""))\n\n    sources = main_file + sources_cpu\n\n    extra_cflags = []\n    extra_cuda_cflags = []\n    if torch.cuda.is_available() and CUDA_HOME is not None:\n        sources.extend(sources_cuda)\n        extra_cflags = [""-O3"", ""-DWITH_CUDA""]\n        extra_cuda_cflags = [""--expt-extended-lambda""]\n    sources = [os.path.join(this_dir, s) for s in sources]\n    extra_include_paths = [this_dir]\n    return load(\n        name=""ext_lib"",\n        sources=sources,\n        extra_cflags=extra_cflags,\n        extra_include_paths=extra_include_paths,\n        extra_cuda_cflags=extra_cuda_cflags,\n    )\n\n\n_backend = _load_C_extensions()\n'"
modules/functional/syncbn.py,3,"b'""""""\n/*****************************************************************************/\n\nBatchNorm2dSync with multi-gpu\n\ncode referenced from : https://github.com/mapillary/inplace_abn\n\n/*****************************************************************************/\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport torch.cuda.comm as comm\nfrom torch.autograd import Function\nfrom torch.autograd.function import once_differentiable\nfrom ._csrc import _backend\n\n\ndef _count_samples(x):\n    count = 1\n    for i, s in enumerate(x.size()):\n        if i != 1:\n            count *= s\n    return count\n\n\nclass BatchNorm2dSyncFunc(Function):\n\n    @staticmethod\n    def forward(ctx, x, weight, bias, running_mean, running_var,\n                extra, compute_stats=True, momentum=0.1, eps=1e-05):\n        def _parse_extra(ctx, extra):\n            ctx.is_master = extra[""is_master""]\n            if ctx.is_master:\n                ctx.master_queue = extra[""master_queue""]\n                ctx.worker_queues = extra[""worker_queues""]\n                ctx.worker_ids = extra[""worker_ids""]\n            else:\n                ctx.master_queue = extra[""master_queue""]\n                ctx.worker_queue = extra[""worker_queue""]\n        # Save context\n        if extra is not None:\n            _parse_extra(ctx, extra)\n        ctx.compute_stats = compute_stats\n        ctx.momentum = momentum\n        ctx.eps = eps\n        ctx.affine = weight is not None and bias is not None\n        if ctx.compute_stats:\n            N = _count_samples(x) * (ctx.master_queue.maxsize + 1)\n            assert N > 1\n            # 1. compute sum(x) and sum(x^2)\n            xsum, xsqsum = _backend.syncbn_sum_sqsum(x.detach())\n            if ctx.is_master:\n                xsums, xsqsums = [xsum], [xsqsum]\n                # master : gatther all sum(x) and sum(x^2) from slaves\n                for _ in range(ctx.master_queue.maxsize):\n                    xsum_w, xsqsum_w = ctx.master_queue.get()\n                    ctx.master_queue.task_done()\n                    xsums.append(xsum_w)\n                    xsqsums.append(xsqsum_w)\n                xsum = comm.reduce_add(xsums)\n                xsqsum = comm.reduce_add(xsqsums)\n                mean = xsum / N\n                sumvar = xsqsum - xsum * mean\n                var = sumvar / N\n                uvar = sumvar / (N - 1)\n                # master : broadcast global mean, variance to all slaves\n                tensors = comm.broadcast_coalesced(\n                    (mean, uvar, var), [mean.get_device()] + ctx.worker_ids)\n                for ts, queue in zip(tensors[1:], ctx.worker_queues):\n                    queue.put(ts)\n            else:\n                # slave : send sum(x) and sum(x^2) to master\n                ctx.master_queue.put((xsum, xsqsum))\n                # slave : get global mean and variance\n                mean, uvar, var = ctx.worker_queue.get()\n                ctx.worker_queue.task_done()\n\n            # Update running stats\n            running_mean.mul_((1 - ctx.momentum)).add_(ctx.momentum * mean)\n            running_var.mul_((1 - ctx.momentum)).add_(ctx.momentum * uvar)\n            ctx.N = N\n            ctx.save_for_backward(x, weight, bias, mean, var)\n        else:\n            mean, var = running_mean, running_var\n\n        # do batch norm forward\n        z = _backend.syncbn_forward(x, weight, bias, mean, var,\n                                    ctx.affine, ctx.eps)\n        return z\n\n    @staticmethod\n    @once_differentiable\n    def backward(ctx, dz):\n        x, weight, bias, mean, var = ctx.saved_tensors\n        dz = dz.contiguous()\n\n        # 1. compute \\sum(\\frac{dJ}{dy_i}) and \\sum(\\frac{dJ}{dy_i}*\\hat{x_i})\n        sum_dz, sum_dz_xhat = _backend.syncbn_backward_xhat(\n            dz, x, mean, var, ctx.eps)\n        if ctx.is_master:\n            sum_dzs, sum_dz_xhats = [sum_dz], [sum_dz_xhat]\n            # master : gatther from slaves\n            for _ in range(ctx.master_queue.maxsize):\n                sum_dz_w, sum_dz_xhat_w = ctx.master_queue.get()\n                ctx.master_queue.task_done()\n                sum_dzs.append(sum_dz_w)\n                sum_dz_xhats.append(sum_dz_xhat_w)\n            # master : compute global stats\n            sum_dz = comm.reduce_add(sum_dzs)\n            sum_dz_xhat = comm.reduce_add(sum_dz_xhats)\n            sum_dz /= ctx.N\n            sum_dz_xhat /= ctx.N\n            # master : broadcast global stats\n            tensors = comm.broadcast_coalesced(\n                (sum_dz, sum_dz_xhat), [mean.get_device()] + ctx.worker_ids)\n            for ts, queue in zip(tensors[1:], ctx.worker_queues):\n                queue.put(ts)\n        else:\n            # slave : send to master\n            ctx.master_queue.put((sum_dz, sum_dz_xhat))\n            # slave : get global stats\n            sum_dz, sum_dz_xhat = ctx.worker_queue.get()\n            ctx.worker_queue.task_done()\n\n        # do batch norm backward\n        dx, dweight, dbias = _backend.syncbn_backward(\n            dz, x, weight, bias, mean, var, sum_dz, sum_dz_xhat,\n            ctx.affine, ctx.eps)\n\n        return dx, dweight, dbias, \\\n            None, None, None, None, None, None\n\nbatchnorm2d_sync = BatchNorm2dSyncFunc.apply\n\n__all__ = [""batchnorm2d_sync""]\n'"
modules/nn/__init__.py,0,b'from .syncbn import *\n'
modules/nn/syncbn.py,8,"b'""""""\n/*****************************************************************************/\n\nBatchNorm2dSync with multi-gpu\n\n/*****************************************************************************/\n""""""\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\ntry:\n    # python 3\n    from queue import Queue\nexcept ImportError:\n    # python 2\n    from Queue import Queue\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.nn.parameter import Parameter\nfrom modules.functional import batchnorm2d_sync\n\n\nclass _BatchNorm(nn.Module):\n    """"""\n    Customized BatchNorm from nn.BatchNorm\n    >> added freeze attribute to enable bn freeze.\n    """"""\n\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True,\n                 track_running_stats=True):\n        super(_BatchNorm, self).__init__()\n        self.num_features = num_features\n        self.eps = eps\n        self.momentum = momentum\n        self.affine = affine\n        self.track_running_stats = track_running_stats\n        self.freezed = False\n        if self.affine:\n            self.weight = Parameter(torch.Tensor(num_features))\n            self.bias = Parameter(torch.Tensor(num_features))\n        else:\n            self.register_parameter(\'weight\', None)\n            self.register_parameter(\'bias\', None)\n        if self.track_running_stats:\n            self.register_buffer(\'running_mean\', torch.zeros(num_features))\n            self.register_buffer(\'running_var\', torch.ones(num_features))\n        else:\n            self.register_parameter(\'running_mean\', None)\n            self.register_parameter(\'running_var\', None)\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        if self.track_running_stats:\n            self.running_mean.zero_()\n            self.running_var.fill_(1)\n        if self.affine:\n            self.weight.data.uniform_()\n            self.bias.data.zero_()\n\n    def _check_input_dim(self, input):\n        return NotImplemented\n\n    def forward(self, input):\n        self._check_input_dim(input)\n\n        compute_stats = not self.freezed and \\\n            self.training and self.track_running_stats\n\n        ret = F.batch_norm(input, self.running_mean, self.running_var,\n                           self.weight, self.bias, compute_stats,\n                           self.momentum, self.eps)\n        return ret\n\n    def extra_repr(self):\n        return \'{num_features}, eps={eps}, momentum={momentum}, \'\\\n               \'affine={affine}, \' \\\n               \'track_running_stats={track_running_stats}\'.format(\n                   **self.__dict__)\n\n\nclass BatchNorm2dNoSync(_BatchNorm):\n    """"""\n    Equivalent to nn.BatchNorm2d\n    """"""\n\n    def _check_input_dim(self, input):\n        if input.dim() != 4:\n            raise ValueError(\'expected 4D input (got {}D input)\'\n                             .format(input.dim()))\n\n\nclass BatchNorm2dSync(BatchNorm2dNoSync):\n    """"""\n    BatchNorm2d with automatic multi-GPU Sync\n    """"""\n\n    def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True,\n                 track_running_stats=True):\n        super(BatchNorm2dSync, self).__init__(\n            num_features, eps=eps, momentum=momentum, affine=affine,\n            track_running_stats=track_running_stats)\n        self.sync_enabled = True\n        self.devices = list(range(torch.cuda.device_count()))\n        if len(self.devices) > 1:\n            # Initialize queues\n            self.worker_ids = self.devices[1:]\n            self.master_queue = Queue(len(self.worker_ids))\n            self.worker_queues = [Queue(1) for _ in self.worker_ids]\n\n    def forward(self, x):\n        compute_stats = not self.freezed and \\\n            self.training and self.track_running_stats\n        if self.sync_enabled and compute_stats and len(self.devices) > 1:\n            if x.get_device() == self.devices[0]:\n                # Master mode\n                extra = {\n                    ""is_master"": True,\n                    ""master_queue"": self.master_queue,\n                    ""worker_queues"": self.worker_queues,\n                    ""worker_ids"": self.worker_ids\n                }\n            else:\n                # Worker mode\n                extra = {\n                    ""is_master"": False,\n                    ""master_queue"": self.master_queue,\n                    ""worker_queue"": self.worker_queues[\n                        self.worker_ids.index(x.get_device())]\n                }\n            return batchnorm2d_sync(x, self.weight, self.bias,\n                                    self.running_mean, self.running_var,\n                                    extra, compute_stats, self.momentum,\n                                    self.eps)\n        return super(BatchNorm2dSync, self).forward(x)\n\n    def __repr__(self):\n        """"""repr""""""\n        rep = \'{name}({num_features}, eps={eps}, momentum={momentum},\' \\\n            \'affine={affine}, \' \\\n            \'track_running_stats={track_running_stats},\' \\\n            \'devices={devices})\'\n        return rep.format(name=self.__class__.__name__, **self.__dict__)\n\n#BatchNorm2d = BatchNorm2dNoSync\nBatchNorm2d = BatchNorm2dSync\n'"
