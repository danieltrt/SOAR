file_path,api_count,code
denseNet_localization.py,12,"b'import numpy as np\nfrom os import listdir\nimport skimage.transform\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import functional as F\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torch.optim as optim\nfrom torch.autograd import Function\nfrom torchvision import models\nfrom torchvision import utils\nimport cv2\nimport sys\nimport os\nimport pickle\nfrom collections import defaultdict\nfrom collections import OrderedDict\n\nimport skimage\nfrom skimage.io import *\nfrom skimage.transform import *\n\nimport scipy\nimport scipy.ndimage as ndimage\nimport scipy.ndimage.filters as filters\nfrom scipy.ndimage import binary_dilation\nimport matplotlib.patches as patches\n\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = ""0""\n\ntest_txt_path = sys.argv[1]\nimg_folder_path = sys.argv[2]\n\nwith open(test_txt_path, ""r"") as f:\n    test_list = [i.strip() for i in f.readlines()]\n\nprint(""number of test examples:"",len(test_list))\n\ntest_X = []\nprint(""load and transform image"")\nfor i in range(len(test_list)):\n    image_path = os.path.join(img_folder_path, test_list[i])\n    img = scipy.misc.imread(image_path)\n    if img.shape != (1024,1024):\n        img = img[:,:,0]\n    img_resized = skimage.transform.resize(img,(256,256))\n    test_X.append((np.array(img_resized)).reshape(256,256,1))\n    if i % 100==0:\n        print(i)\ntest_X = np.array(test_X)\n\n# model archi\n# construct model\nclass DenseNet121(nn.Module):\n\t""""""Model modified.\n\tThe architecture of our model is the same as standard DenseNet121\n\texcept the classifier layer which has an additional sigmoid function.\n\t""""""\n\tdef __init__(self, out_size):\n\t\tsuper(DenseNet121, self).__init__()\n\t\tself.densenet121 = torchvision.models.densenet121(pretrained=True)\n\t\tnum_ftrs = self.densenet121.classifier.in_features\n\t\tself.densenet121.classifier = nn.Sequential(\n\t\t    nn.Linear(num_ftrs, out_size),\n\t\t    nn.Sigmoid()\n\t\t)\n\n\tdef forward(self, x):\n\t\tx = self.densenet121(x)\n\t\treturn x\n\nmodel = DenseNet121(8).cuda()\nmodel = torch.nn.DataParallel(model)\nmodel.load_state_dict(torch.load(""model/DenseNet121_aug4_pretrain_WeightBelow1_1_0.829766922537.pkl""))\nprint(""model loaded"")\n\n\n\n# build test dataset\nclass ChestXrayDataSet_plot(Dataset):\n\tdef __init__(self, input_X = test_X, transform=None):\n\t\tself.X = np.uint8(test_X*255)\n\t\tself.transform = transform\n\n\tdef __getitem__(self, index):\n\t\t""""""\n\t\tArgs:\n\t\t    index: the index of item \n\t\tReturns:\n\t\t    image \n\t\t""""""\n\t\tcurrent_X = np.tile(self.X[index],3)\n\t\timage = self.transform(current_X)\n\t\treturn image\n\tdef __len__(self):\n\t\treturn len(self.X)\n\ntest_dataset = ChestXrayDataSet_plot(input_X = test_X,transform=transforms.Compose([\n                                        transforms.ToPILImage(),\n                                        transforms.CenterCrop(224),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                        ]))\n\nthresholds = np.load(""thresholds.npy"")\nprint(""activate threshold"",thresholds)\n\nprint(""generate heatmap .........."")\n# ======= Grad CAM Function =========\nclass PropagationBase(object):\n\n    def __init__(self, model, cuda=False):\n        self.model = model\n        self.model.eval()\n        if cuda:\n            self.model.cuda()\n        self.cuda = cuda\n        self.all_fmaps = OrderedDict()\n        self.all_grads = OrderedDict()\n        self._set_hook_func()\n        self.image = None\n\n    def _set_hook_func(self):\n        raise NotImplementedError\n\n    def _encode_one_hot(self, idx):\n        one_hot = torch.FloatTensor(1, self.preds.size()[-1]).zero_()\n        one_hot[0][idx] = 1.0\n        return one_hot.cuda() if self.cuda else one_hot\n\n    def forward(self, image):\n        self.image = image\n        self.preds = self.model.forward(self.image)\n#         self.probs = F.softmax(self.preds)[0]\n#         self.prob, self.idx = self.preds[0].data.sort(0, True)\n        return self.preds.cpu().data.numpy()\n\n    def backward(self, idx):\n        self.model.zero_grad()\n        one_hot = self._encode_one_hot(idx)\n        self.preds.backward(gradient=one_hot, retain_graph=True)\n\n\nclass GradCAM(PropagationBase):\n\n    def _set_hook_func(self):\n\n        def func_f(module, input, output):\n            self.all_fmaps[id(module)] = output.data.cpu()\n\n        def func_b(module, grad_in, grad_out):\n            self.all_grads[id(module)] = grad_out[0].cpu()\n\n        for module in self.model.named_modules():\n            module[1].register_forward_hook(func_f)\n            module[1].register_backward_hook(func_b)\n\n    def _find(self, outputs, target_layer):\n        for key, value in outputs.items():\n            for module in self.model.named_modules():\n                if id(module[1]) == key:\n                    if module[0] == target_layer:\n                        return value\n        raise ValueError(\'Invalid layer name: {}\'.format(target_layer))\n\n    def _normalize(self, grads):\n        l2_norm = torch.sqrt(torch.mean(torch.pow(grads, 2))) + 1e-5\n        return grads / l2_norm.data[0]\n\n    def _compute_grad_weights(self, grads):\n        grads = self._normalize(grads)\n        self.map_size = grads.size()[2:]\n        return nn.AvgPool2d(self.map_size)(grads)\n\n    def generate(self, target_layer):\n        fmaps = self._find(self.all_fmaps, target_layer)\n        grads = self._find(self.all_grads, target_layer)\n        weights = self._compute_grad_weights(grads)\n        gcam = torch.FloatTensor(self.map_size).zero_()\n        for fmap, weight in zip(fmaps[0], weights[0]):\n            gcam += fmap * weight.data\n        \n        gcam = F.relu(Variable(gcam))\n\n        gcam = gcam.data.cpu().numpy()\n        gcam -= gcam.min()\n        gcam /= gcam.max()\n        gcam = cv2.resize(gcam, (self.image.size(3), self.image.size(2)))\n\n        return gcam\n\n    def save(self, filename, gcam, raw_image):\n        gcam = cv2.applyColorMap(np.uint8(gcam * 255.0), cv2.COLORMAP_JET)\n        gcam = gcam.astype(np.float) + raw_image.astype(np.float)\n        gcam = gcam / gcam.max() * 255.0\n        cv2.imwrite(filename, np.uint8(gcam))\n\n\n\n\n# ======== Create heatmap ===========\n\nheatmap_output = []\nimage_id = []\noutput_class = []\n\ngcam = GradCAM(model=model, cuda=True)\nfor index in range(len(test_dataset)):\n    input_img = Variable((test_dataset[index]).unsqueeze(0).cuda(), requires_grad=True)\n    probs = gcam.forward(input_img)\n\n    activate_classes = np.where((probs > thresholds)[0]==True)[0] # get the activated class\n    for activate_class in activate_classes:\n        gcam.backward(idx=activate_class)\n        output = gcam.generate(target_layer=""module.densenet121.features.denseblock4.denselayer16.conv.2"")\n        #### this output is heatmap ####\n        if np.sum(np.isnan(output)) > 0:\n            print(""fxxx nan"")\n        heatmap_output.append(output)\n        image_id.append(index)\n        output_class.append(activate_class)\n    print(""test "",str(index),"" finished"")\n\nprint(""heatmap output done"")\nprint(""total number of heatmap: "",len(heatmap_output))\n\n# ======= Plot bounding box =========\nimg_width, img_height = 224, 224\nimg_width_exp, img_height_exp = 1024, 1024\n\ncrop_del = 16\nrescale_factor = 4\n\nclass_index = [\'Atelectasis\', \'Cardiomegaly\', \'Effusion\', \'Infiltration\', \'Mass\', \'Nodule\', \'Pneumonia\', \'Pneumothorax\']\navg_size = np.array([[411.8, 512.5, 219.0, 139.1], [348.5, 392.3, 479.8, 381.1],\n                     [396.5, 415.8, 221.6, 318.0], [394.5, 389.1, 294.0, 297.4],\n                     [434.3, 366.7, 168.7, 189.8], [502.4, 458.7, 71.9, 70.4],\n                     [378.7, 416.7, 276.5, 304.5], [369.3, 209.4, 198.9, 246.0]])\n\n\nprediction_dict = {}\nfor i in range(len(test_list)):\n    prediction_dict[i] = []\n\nfor img_id, k, npy in zip(image_id, output_class, heatmap_output):\n    \n    data = npy\n    img_fname = test_list[img_id]\n\n    # output avgerge\n    prediction_sent = \'%s %.1f %.1f %.1f %.1f\' % (class_index[k], avg_size[k][0], avg_size[k][1], avg_size[k][2], avg_size[k][3])\n    prediction_dict[img_id].append(prediction_sent)\n\n    if np.isnan(data).any():\n        continue\n\n    w_k, h_k = (avg_size[k][2:4] * (256 / 1024)).astype(np.int)\n    \n    # Find local maxima\n    neighborhood_size = 100\n    threshold = .1\n    \n    data_max = filters.maximum_filter(data, neighborhood_size)\n    maxima = (data == data_max)\n    data_min = filters.minimum_filter(data, neighborhood_size)\n    diff = ((data_max - data_min) > threshold)\n    maxima[diff == 0] = 0\n    for _ in range(5):\n        maxima = binary_dilation(maxima)\n    \n    labeled, num_objects = ndimage.label(maxima)\n    slices = ndimage.find_objects(labeled)\n    xy = np.array(ndimage.center_of_mass(data, labeled, range(1, num_objects+1)))\n        \n    for pt in xy:\n        if data[int(pt[0]), int(pt[1])] > np.max(data)*.9:\n            upper = int(max(pt[0]-(h_k/2), 0.))\n            left = int(max(pt[1]-(w_k/2), 0.))\n\n            right = int(min(left+w_k, img_width))\n            lower = int(min(upper+h_k, img_height))\n            \n            prediction_sent = \'%s %.1f %.1f %.1f %.1f\' % (class_index[k], (left+crop_del)*rescale_factor, \\\n                                                                          (upper+crop_del)*rescale_factor, \\\n                                                                          (right-left)*rescale_factor, \\\n                                                                          (lower-upper)*rescale_factor)\n            \n            prediction_dict[img_id].append(prediction_sent)\n\nwith open(""bounding_box.txt"",""w"") as f:\n\tfor i in range(len(prediction_dict)):\n\t\tfname = test_list[i]\n\t\tprediction = prediction_dict[i]\n\n\t\tprint(os.path.join(img_folder_path, fname), len(prediction))\n\t\tf.write(\'%s %d\\n\' % (os.path.join(img_folder_path, fname), len(prediction)))\n\n\t\tfor p in prediction:\n\t\t\tprint(p)\n\t\t\tf.write(p+""\\n"")'"
find_bbox_size.py,0,"b""# Find the size of bounding boxes\r\n# Usage: python3 find_bbox_size.py <train_heatmap> <valid_heatmap>\r\n\r\n# <{train,valid}_heatmap> contains .npy files named 'heatmap_<id>_<class>.npy'\r\n# describing the heatmap of positive cases predicted by our model\r\n# files in <valid_heatmap> will only be used to calculate IOU scores\r\n#\r\n# <id> is the order of each validation image (in valid.txt)\r\n# <class> is the disease class in alphabetical order (0-7)\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport sys, os\r\n\r\nimport scipy\r\nimport scipy.ndimage as ndimage\r\nimport scipy.ndimage.filters as filters\r\nfrom scipy.ndimage import binary_dilation\r\n\r\nfrom iou import validate_total_score\r\n\r\nCROP_DEL, RESCALE_FACTOR = 16., 4.\r\nclass_names = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax']\r\n\r\n# heuristic threshold: all started from 1.00, tuned by 0.05 each time to find better threshold value\r\nintensity_th = [1., 1., 1., 1., 1., 1., 1., 1.]\r\ndelta_th = .05\r\n\r\nprev_default_box = None\r\n\r\nfor target_th in range(8):\r\n    # consider each class independent\r\n    max_iou_score = .0\r\n    \r\n    for _ in range(10):\r\n        intensity_th[target_th] -= delta_th\r\n    \r\n        x_sum = np.zeros(8)\r\n        y_sum = np.zeros(8)\r\n        w_sum = np.zeros(8)\r\n        h_sum = np.zeros(8)\r\n        class_count = np.zeros(8)\r\n        \r\n        npy_list = os.listdir(sys.argv[1])\r\n        \r\n        for npy_name in npy_list:\r\n            if not npy_name.endswith('.npy'):\r\n                continue\r\n        \r\n            data = np.load(os.path.join(sys.argv[1], npy_name))\r\n        \r\n            img_id = int(npy_name.split('.')[0].split('_')[1])\r\n            k = int(npy_name.split('.')[0].split('_')[2])\r\n        \r\n            if np.isnan(data).any():\r\n                continue\r\n            \r\n            # Find local maxima\r\n            neighborhood_size = 100\r\n            threshold = .1\r\n            \r\n            data_max = filters.maximum_filter(data, neighborhood_size)\r\n            maxima = (data == data_max)\r\n            data_min = filters.minimum_filter(data, neighborhood_size)\r\n            diff = ((data_max - data_min) > threshold)\r\n            maxima[diff == 0] = 0\r\n            for _ in range(5):\r\n                maxima = binary_dilation(maxima)\r\n            \r\n            labeled, num_objects = ndimage.label(maxima)\r\n            slices = ndimage.find_objects(labeled)\r\n            xy = np.array(ndimage.center_of_mass(data, labeled, range(1, num_objects+1)))\r\n            \r\n            thresholded_data = (data > np.max(data)*intensity_th[k]).astype(np.int)\r\n        \r\n            for point in xy:\r\n                centroid_x = int(point[0])\r\n                centroid_y = int(point[1])\r\n                \r\n                if data[centroid_x, centroid_y] > np.max(data)*.9:\r\n                    # find box boundaries\r\n                    left, right, upper, lower = centroid_x, centroid_x, centroid_y, centroid_y\r\n                    \r\n                    while left > 0 and thresholded_data[max(0,left), centroid_y] == 1:\r\n                        left -= 1\r\n                    while right < 224 and thresholded_data[min(224,right), centroid_y] == 1:\r\n                        right += 1\r\n                    while upper > 0 and thresholded_data[centroid_x, max(0,upper)] == 1:\r\n                        upper -= 1\r\n                    while lower < 224 and thresholded_data[centroid_x, min(224,lower)] == 1:\r\n                        lower += 1\r\n                    \r\n                    x_sum[k] += left\r\n                    y_sum[k] += upper\r\n                    w_sum[k] += right - left\r\n                    h_sum[k] += lower - upper\r\n                    class_count[k] += 1\r\n                    \r\n        # output stats\r\n        x_avg = (x_sum / class_count + CROP_DEL) * RESCALE_FACTOR\r\n        y_avg = (y_sum / class_count + CROP_DEL) * RESCALE_FACTOR\r\n        w_avg = w_sum / class_count * RESCALE_FACTOR\r\n        h_avg = h_sum / class_count * RESCALE_FACTOR\r\n        \r\n        default_box = []\r\n        for k in range(8):\r\n            #print('[%.1f, %.1f, %.1f, %.1f]'%(x_avg[k], y_avg[k], w_avg[k], h_avg[k]))\r\n            default_box.append([x_avg[k], y_avg[k], w_avg[k], h_avg[k]])\r\n        \r\n        iou_score = validate_total_score(np.array(default_box), valid_dir=sys.argv[2])\r\n        prev_default_box = default_box\r\n        print(iou_score)\r\n        \r\n        if iou_score >= max_iou_score:\r\n            max_iou_score = iou_score\r\n        else:\r\n            intensity_th[target_th] += delta_th\r\n            print('class %d stops at th = %f' % (target_th, intensity_th[target_th]))\r\n            break\r\n\r\nprint(intensity_th)\r\nprint(prev_default_box)"""
iou.py,0,"b""import numpy as np\nimport pandas as pd\n\nimport collections\nimport os\n\nimport scipy.ndimage as ndimage\nfrom scipy.ndimage import binary_dilation, filters\n\nBBOX_LIST_FNAME = 'BBox_List_2017.csv'\nVALID_FNAME = 'valid.txt'\nCROP_DEL, RESCALE_FACTOR = 16., 4.\n\n# class-id mapping\nclass_list = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax']\n\ndef IOU(xywh1, xywh2):\n    x1, y1, w1, h1 = xywh1\n    x2, y2, w2, h2 = xywh2\n\n    dx = min(x1+w1, x2+w2) - max(x1, x2)\n    dy = min(y1+h1, y2+h2) - max(y1, y2)\n    intersection = dx * dy if (dx >=0 and dy >= 0) else 0.\n    \n    union = w1 * h1 + w2 * h2 - intersection\n    return (intersection / union)\n\ndef preprocess_bbox_df(mismatch_id=-1):\n    # filename-id mapping\n    with open('valid.txt', 'r') as f:\n        valid_list = f.readlines()\n        valid_list = [s.strip('\\n') for s in valid_list]\n\n    df = pd.read_csv(BBOX_LIST_FNAME)\n    \n    # map file/class name to id\n    df['Image Index'] = df['Image Index'].apply(lambda x: valid_list.index(x) if x in valid_list else mismatch_id)\n    #df['Finding Label'] = df['Finding Label'].apply(lambda x: class_list.index(x))\n    \n    return df\n\ndef validate_score(predicted_xywh, bbox_df, img_id, class_name):\n    match_row = bbox_df[(bbox_df['Image Index'] == img_id) & (bbox_df['Finding Label'] == class_name)]\n    try:\n        assert(len(match_row)<=1)\n    except:\n        print('error with query:', match_row)\n    \n    # IOU = 0.0 for mismatch cases\n    if match_row.empty:\n        return 0.\n    \n    ground_truth_xywh = tuple(match_row.iloc[0,2:6])\n    \n    return IOU(predicted_xywh, ground_truth_xywh)\n\ndef validate_total_score(default_box, valid_dir='valid_heatmap'):\n    npy_list = os.listdir(valid_dir)\n    with open('valid.txt', 'r') as f:\n        fname_list = f.readlines()\n        fname_list = [s.strip('\\n') for s in fname_list]\n\n    prediction_dict = {}\n    for i in range(440):\n        prediction_dict[i] = []\n\n    for npy_name in npy_list:\n        if not npy_name.endswith('.npy'):\n            continue\n            \n        data = np.load(os.path.join(valid_dir, npy_name))\n        img_id = int(npy_name.split('.')[0].split('_')[1])\n        k = int(npy_name.split('.')[0].split('_')[2])\n            \n        # predict default_box\n        prediction_sent = (class_list[k], default_box[k][0], default_box[k][1], default_box[k][2], default_box[k][3])\n        prediction_dict[img_id].append(prediction_sent)\n\n        if np.isnan(data).any():\n            continue\n        \n        img_width, img_height = 224, 224\n        w_k, h_k = (default_box[k][2:] * (1 / RESCALE_FACTOR)).astype(np.int)    \n    \n        # Find local maxima\n        neighborhood_size = 100\n        threshold = .1\n        \n        data_max = filters.maximum_filter(data, neighborhood_size)\n        maxima = (data == data_max)\n        data_min = filters.minimum_filter(data, neighborhood_size)\n        diff = ((data_max - data_min) > threshold)\n        maxima[diff == 0] = 0\n        for _ in range(5):\n            maxima = binary_dilation(maxima)\n        \n        labeled, num_objects = ndimage.label(maxima)\n        slices = ndimage.find_objects(labeled)\n        xy = np.array(ndimage.center_of_mass(data, labeled, range(1, num_objects+1)))\n        \n        for pt in xy:\n            if data[int(pt[0]), int(pt[1])] > np.max(data)*.9:\n                upper = int(max(pt[0]-(h_k/2), 0.))\n                left = int(max(pt[1]-(w_k/2), 0.))\n                \n                right = int(min(left+w_k, img_width))\n                lower = int(min(upper+h_k, img_height))\n                \n                if lower == img_height and not k in [1]:\n                    # avoid bbox touching bottom\n                    continue\n                elif k in [5]:\n                    # avoid predicting low acc classes\n                    continue\n                else:\n                    prediction_sent = (class_list[k], (left+CROP_DEL)*RESCALE_FACTOR, (upper+CROP_DEL)*RESCALE_FACTOR,\n                                       (right-left)*RESCALE_FACTOR, (lower-upper)*RESCALE_FACTOR)\n                \n                prediction_dict[img_id].append(prediction_sent)\n    \n    # calculate IOU score\n    bbox_df = preprocess_bbox_df()\n    \n    iou_sum = 0.\n    iou25_count, iou50_count = 0, 0\n    box_count = 0\n\n    for img_id in range(len(prediction_dict)):\n        for pred in prediction_dict[img_id][:10]:\n            iou = validate_score(pred[1:], bbox_df, img_id, pred[0])\n                                 \n            iou_sum += iou\n            iou25_count += 1 if iou > .25 else 0\n            iou50_count += 1 if iou > .50 else 0\n            box_count = box_count + 1\n        \n    iou_avg = iou_sum / box_count\n    iou25_avg = iou25_count / box_count\n    iou50_avg = iou50_count / box_count\n    iou_score = (iou25_avg + iou50_avg) / 2\n\n    #print('total box_count =', box_count)\n    #print('average IOU =', iou_avg)\n    #print('average score at T(0.25) =', iou25_avg)\n    #print('average score at T(0.50) =', iou50_avg)\n    \n    return iou_score\n\nif __name__ == '__main__':\n    print(IOU((3., 3., 2., 2.), (1., 1., 3., 2.5)))\n"""
preprocessing.py,0,"b'import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport imageio\nfrom os import listdir\nimport skimage.transform\nimport pickle\nimport sys, os\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nimage_folder_path = sys.argv[1] # folder contain all images\ndata_entry_path = sys.argv[2] \nbbox_list_path = sys.argv[3]\ntrain_txt_path = sys.argv[4]\nvalid_txt_path = sys.argv[5]\ndata_path = sys.argv[6] # ouput folder for preprocessed data\n\ndef get_labels(pic_id):\n    labels = meta_data.loc[meta_data[""Image Index""]==pic_id,""Finding Labels""]\n    return labels.tolist()[0].split(""|"")\n\n# load data\nmeta_data = pd.read_csv(data_entry_path)\nbbox_list = pd.read_csv(bbox_list_path)\nwith open(train_txt_path, ""r"") as f:\n    train_list = [ i.strip() for i in f.readlines()]\nwith open(valid_txt_path, ""r"") as f:\n    valid_list = [ i.strip() for i in f.readlines()]\nlabel_eight = list(np.unique(bbox_list[""Finding Label""])) + [""No Finding""]\n\n\n# transform training images\nprint(""training example:"",len(train_list))\nprint(""take care of your RAM here !!!"")\ntrain_X = []\nfor i in range(len(train_list)):\n    image_path = os.path.join(image_folder_path,train_list[i])\n    img = imageio.imread(image_path)\n    if img.shape != (1024,1024): # there some image with shape (1024,1024,4) in training set\n        img = img[:,:,0]\n    img_resized = skimage.transform.resize(img,(256,256)) # or use img[::4] here\n    train_X.append((np.array(img_resized)/255).reshape(256,256,1))\n    if i % 3000==0:\n        print(i)\n\n\ntrain_X = np.array(train_X)\nnp.save(os.path.join(data_path,""train_X_small.npy""), train_X)\n\n# transform validation images\nprint(""validation example:"",len(valid_list))\nvalid_X = []\nfor i in range(len(valid_list)):\n    image_path = os.path.join(image_folder_path,valid_list[i])\n    img = imageio.imread(image_path)\n    if img.shape != (1024,1024):\n        img = img[:,:,0]\n    img_resized = skimage.transform.resize(img,(256,256))\n#     if img.shape != (1024,1024):\n#             train_X.append(img[:,:,0])\n#     else:\n    valid_X.append((np.array(img_resized)/255).reshape(256,256,1))\n    if i % 3000==0:\n        print(i)\n\nvalid_X = np.array(valid_X)\nnp.save(os.path.join(data_path,""valid_X_small.npy""), valid_X)\n\n\n# process label\nprint(""label preprocessing"")\n\ntrain_y = []\nfor train_id in train_list:\n    train_y.append(get_labels(train_id))\nvalid_y = []\nfor valid_id in valid_list:\n    valid_y.append(get_labels(valid_id))\n\n\nencoder = MultiLabelBinarizer()\nencoder.fit(train_y+valid_y)\ntrain_y_onehot = encoder.transform(train_y)\nvalid_y_onehot = encoder.transform(valid_y)\ntrain_y_onehot = np.delete(train_y_onehot, [2,3,5,6,7,10,12],1) # delete out 8 and ""No Finding"" column\nvalid_y_onehot = np.delete(valid_y_onehot, [2,3,5,6,7,10,12],1) # delete out 8 and ""No Finding"" column\n\nwith open(data_path + ""/train_y_onehot.pkl"",""wb"") as f:\n    pickle.dump(train_y_onehot, f)\nwith open(data_path + ""/valid_y_onehot.pkl"",""wb"") as f:\n    pickle.dump(valid_y_onehot, f)\nwith open(data_path + ""/label_encoder.pkl"",""wb"") as f:\n    pickle.dump(encoder, f)\n'"
train.py,17,"b'import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport os, sys\nimport pickle\nfrom collections import defaultdict\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport numpy as np\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom sklearn.metrics import roc_auc_score\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nos.environ[\'CUDA_VISIBLE_DEVICES\'] = ""0""\n\ndef compute_AUCs(gt, pred):\n\t\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    for i in range(N_CLASSES):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs\n\n\n# ====== prepare dataset ======\nclass ChestXrayDataSet(Dataset):\n    def __init__(self, train_or_valid = ""train"", transform=None):\n\n        data_path = sys.argv[1]\n        self.train_or_valid = train_or_valid\n        if train_or_valid == ""train"":\n            self.X = np.uint8(np.load(data_path + ""train_X_small.npy"")*255*255)\n            with open(data_path + ""train_y_onehot.pkl"", ""rb"") as f:\n                self.y = pickle.load(f)\n            sub_bool = (self.y.sum(axis=1)!=0)\n            self.y = self.y[sub_bool,:]\n            self.X = self.X[sub_bool,:]\n        else:\n            self.X = np.uint8(np.load(data_path + ""valid_X_small.npy"")*255*255)\n            with open(data_path + ""valid_y_onehot.pkl"", ""rb"") as f:\n                self.y = pickle.load(f)\n        \n        self.label_weight_pos = (len(self.y)-self.y.sum(axis=0))/len(self.y)\n        self.label_weight_neg = (self.y.sum(axis=0))/len(self.y)\n#         self.label_weight_pos = len(self.y)/self.y.sum(axis=0)\n#         self.label_weight_neg = len(self.y)/(len(self.y)-self.y.sum(axis=0))\n        self.transform = transform\n\n    def __getitem__(self, index):\n        """"""\n        Args:\n            index: the index of item \n        Returns:\n            image and its labels\n        """"""\n        current_X = np.tile(self.X[index],3) \n        label = self.y[index]\n        label_inverse = 1- label\n        weight = np.add((label_inverse * self.label_weight_neg),(label * self.label_weight_pos))\n        if self.transform is not None:\n            image = self.transform(current_X)\n        return image, torch.from_numpy(label).type(torch.FloatTensor), torch.from_numpy(weight).type(torch.FloatTensor)\n    def __len__(self):\n        return len(self.y)\n\n# construct model\nclass DenseNet121(nn.Module):\n    """"""Model modified.\n    The architecture of our model is the same as standard DenseNet121\n    except the classifier layer which has an additional sigmoid function.\n    """"""\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(\n            nn.Linear(num_ftrs, out_size),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x\n\n\n\n\n\nif __name__ == \'__main__\':\n\n\t# prepare training set\n\ttrain_dataset = ChestXrayDataSet(train_or_valid=""train"",\n                                    transform=transforms.Compose([\n                                        transforms.ToPILImage(),\n                                        transforms.RandomCrop(224),\n                                        transforms.RandomHorizontalFlip(),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n                                        ]))\n\taugment_img = []\n\taugment_label = []\n\taugment_weight = []\n\tfor i in range(4):\n\t\tfor j in range(len(train_dataset)):\n\t\t\tsingle_img, single_label, single_weight = train_dataset[j]\n\t\t\taugment_img.append(single_img)\n\t\t\taugment_label.append(single_label)\n\t\t\taugment_weight.append(single_weight)\n\t\t\tif j % 1000==0:\n\t\t\t\tprint(j)\n\n\t# shuffe data\n\tperm_index = torch.randperm(len(augment_label))\n\taugment_img = torch.stack(augment_img)[perm_index]\n\taugment_label = torch.stack(augment_label)[perm_index]\n\taugment_weight = torch.stack(augment_weight)[perm_index]\n\n\t# prepare validation set\n\tvalid_dataset = ChestXrayDataSet(train_or_valid=""valid"",\n\t\t\t\t\ttransform=transforms.Compose([\n\t\t\t\t\t\t\ttransforms.ToPILImage(),\n\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n\t\t\t\t\t\t\ttransforms.ToTensor(),\n\t\t\t\t\t\t\ttransforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n\t\t\t\t\t\t\t]))\n\n\tvalid_loader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=False, num_workers=16)\n\t# ====== start trianing =======\n\n\tcudnn.benchmark = True\n\tN_CLASSES = 8\n\tBATCH_SIZE = 64\n\n\t# initialize and load the model\n\tmodel = DenseNet121(N_CLASSES).cuda()\n\tmodel = torch.nn.DataParallel(model).cuda()\n\n\toptimizer = optim.Adam(model.parameters(),lr=0.0002, betas=(0.9, 0.999))\n\ttotal_length = len(augment_img)\n\tfor epoch in range(10):  # loop over the dataset multiple times\n\t\tprint(""Epoch:"",epoch)\n\t\trunning_loss = 0.0\n\n\t\t# shuffle\n\t\tperm_index = torch.randperm(len(augment_label))\n\t\taugment_img = augment_img[perm_index]\n\t\taugment_label = augment_label[perm_index]\n\t\taugment_weight = augment_weight[perm_index]\n\n\t\tfor index in range(0, total_length , BATCH_SIZE):\n\t\t\tif index+BATCH_SIZE > total_length:\n\t\t\t\tbreak\n\t\t\t# zero the parameter gradients\n\t\t\toptimizer.zero_grad()\n\t\t\tinputs_sub = augment_img[index:index+BATCH_SIZE]\n\t\t\tlabels_sub = augment_label[index:index+BATCH_SIZE]\n\t\t\tweights_sub = augment_weight[index:index+BATCH_SIZE]\n\t\t\tinputs_sub, labels_sub = Variable(inputs_sub.cuda()), Variable(labels_sub.cuda())\n\t\t\tweights_sub = Variable(weights_sub.cuda())\n\n\t\t\t# forward + backward + optimize\n\t\t\toutputs = model(inputs_sub)\n\t\t\tcriterion = nn.BCELoss()\n\t\t\tloss = criterion(outputs, labels_sub)\n\t\t\tloss.backward()\n\t\t\toptimizer.step()\n\t\t\trunning_loss += loss.data[0]\n\n\n\t\t# ======== validation ======== \n\t\t# switch to evaluate mode\n\t\tmodel.eval()\n\n\n\t\t# initialize the ground truth and output tensor\n\t\tgt = torch.FloatTensor()\n\t\tgt = gt.cuda()\n\t\tpred = torch.FloatTensor()\n\t\tpred = pred.cuda()\n\n\n\t\tfor i, (inp, target, weight) in enumerate(valid_loader):\n\t\t\ttarget = target.cuda()\n\t\t\tgt = torch.cat((gt, target), 0)\n\t\t\t#     bs, n_crops, c, h, w = inp.size()\n\t\t\tinput_var = Variable(inp.view(-1, 3, 224, 224).cuda(), volatile=True)\n\t\t\toutput = model(input_var)\n\t\t\t#     output_mean = output.view(bs, n_crops, -1).mean(1)\n\t\t\tpred = torch.cat((pred, output.data), 0)\n\n\t\tCLASS_NAMES = [\'Atelectasis\', \'Cardiomegaly\',\'Effusion\', \'Infiltration\',\n\t\t\t\t\t\t\'Mass\',\'Nodule\', \'Pneumonia\', \'Pneumothorax\']\n\n\t\tAUROCs = compute_AUCs(gt, pred)\n\t\tAUROC_avg = np.array(AUROCs).mean()\n\t\tprint(\'The average AUROC is {AUROC_avg:.3f}\'.format(AUROC_avg=AUROC_avg))\n\t\tfor i in range(N_CLASSES):\n\t\t    print(\'The AUROC of {} is {}\'.format(CLASS_NAMES[i], AUROCs[i]))\n\n\t\tmodel.train()\n\t\t# print statistics\n\t\tprint(\'[%d] loss: %.3f\' % (epoch + 1, running_loss / 715 ))\n\t\ttorch.save(model.state_dict(),\'DenseNet121_aug4_pretrain_noWeight_\'+str(epoch+1)+\'_\'+str(AUROC_avg)+\'.pkl\')\n\n\tprint(\'Finished Training\')'"
