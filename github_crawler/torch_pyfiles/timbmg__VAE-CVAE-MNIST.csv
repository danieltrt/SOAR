file_path,api_count,code
models.py,6,"b'import torch\nimport torch.nn as nn\n\nfrom utils import idx2onehot\n\n\nclass VAE(nn.Module):\n\n    def __init__(self, encoder_layer_sizes, latent_size, decoder_layer_sizes,\n                 conditional=False, num_labels=0):\n\n        super().__init__()\n\n        if conditional:\n            assert num_labels > 0\n\n        assert type(encoder_layer_sizes) == list\n        assert type(latent_size) == int\n        assert type(decoder_layer_sizes) == list\n\n        self.latent_size = latent_size\n\n        self.encoder = Encoder(\n            encoder_layer_sizes, latent_size, conditional, num_labels)\n        self.decoder = Decoder(\n            decoder_layer_sizes, latent_size, conditional, num_labels)\n\n    def forward(self, x, c=None):\n\n        if x.dim() > 2:\n            x = x.view(-1, 28*28)\n\n        batch_size = x.size(0)\n\n        means, log_var = self.encoder(x, c)\n\n        std = torch.exp(0.5 * log_var)\n        eps = torch.randn([batch_size, self.latent_size])\n        z = eps * std + means\n\n        recon_x = self.decoder(z, c)\n\n        return recon_x, means, log_var, z\n\n    def inference(self, n=1, c=None):\n\n        batch_size = n\n        z = torch.randn([batch_size, self.latent_size])\n\n        recon_x = self.decoder(z, c)\n\n        return recon_x\n\n\nclass Encoder(nn.Module):\n\n    def __init__(self, layer_sizes, latent_size, conditional, num_labels):\n\n        super().__init__()\n\n        self.conditional = conditional\n        if self.conditional:\n            layer_sizes[0] += num_labels\n\n        self.MLP = nn.Sequential()\n\n        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n            self.MLP.add_module(\n                name=""L{:d}"".format(i), module=nn.Linear(in_size, out_size))\n            self.MLP.add_module(name=""A{:d}"".format(i), module=nn.ReLU())\n\n        self.linear_means = nn.Linear(layer_sizes[-1], latent_size)\n        self.linear_log_var = nn.Linear(layer_sizes[-1], latent_size)\n\n    def forward(self, x, c=None):\n\n        if self.conditional:\n            c = idx2onehot(c, n=10)\n            x = torch.cat((x, c), dim=-1)\n\n        x = self.MLP(x)\n\n        means = self.linear_means(x)\n        log_vars = self.linear_log_var(x)\n\n        return means, log_vars\n\n\nclass Decoder(nn.Module):\n\n    def __init__(self, layer_sizes, latent_size, conditional, num_labels):\n\n        super().__init__()\n\n        self.MLP = nn.Sequential()\n\n        self.conditional = conditional\n        if self.conditional:\n            input_size = latent_size + num_labels\n        else:\n            input_size = latent_size\n\n        for i, (in_size, out_size) in enumerate(zip([input_size]+layer_sizes[:-1], layer_sizes)):\n            self.MLP.add_module(\n                name=""L{:d}"".format(i), module=nn.Linear(in_size, out_size))\n            if i+1 < len(layer_sizes):\n                self.MLP.add_module(name=""A{:d}"".format(i), module=nn.ReLU())\n            else:\n                self.MLP.add_module(name=""sigmoid"", module=nn.Sigmoid())\n\n    def forward(self, z, c):\n\n        if self.conditional:\n            c = idx2onehot(c, n=10)\n            z = torch.cat((z, c), dim=-1)\n\n        x = self.MLP(z)\n\n        return x\n'"
train.py,9,"b'import os\nimport time\nimport torch\nimport argparse\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader\nfrom collections import defaultdict\n\nfrom models import VAE\n\n\ndef main(args):\n\n    torch.manual_seed(args.seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(args.seed)\n\n    device = torch.device(\'cuda\' if torch.cuda.is_available() else \'cpu\')\n\n    ts = time.time()\n\n    dataset = MNIST(\n        root=\'data\', train=True, transform=transforms.ToTensor(),\n        download=True)\n    data_loader = DataLoader(\n        dataset=dataset, batch_size=args.batch_size, shuffle=True)\n\n    def loss_fn(recon_x, x, mean, log_var):\n        BCE = torch.nn.functional.binary_cross_entropy(\n            recon_x.view(-1, 28*28), x.view(-1, 28*28), reduction=\'sum\')\n        KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n\n        return (BCE + KLD) / x.size(0)\n\n    vae = VAE(\n        encoder_layer_sizes=args.encoder_layer_sizes,\n        latent_size=args.latent_size,\n        decoder_layer_sizes=args.decoder_layer_sizes,\n        conditional=args.conditional,\n        num_labels=10 if args.conditional else 0).to(device)\n\n    optimizer = torch.optim.Adam(vae.parameters(), lr=args.learning_rate)\n\n    logs = defaultdict(list)\n\n    for epoch in range(args.epochs):\n\n        tracker_epoch = defaultdict(lambda: defaultdict(dict))\n\n        for iteration, (x, y) in enumerate(data_loader):\n\n            x, y = x.to(device), y.to(device)\n\n            if args.conditional:\n                recon_x, mean, log_var, z = vae(x, y)\n            else:\n                recon_x, mean, log_var, z = vae(x)\n\n            for i, yi in enumerate(y):\n                id = len(tracker_epoch)\n                tracker_epoch[id][\'x\'] = z[i, 0].item()\n                tracker_epoch[id][\'y\'] = z[i, 1].item()\n                tracker_epoch[id][\'label\'] = yi.item()\n\n            loss = loss_fn(recon_x, x, mean, log_var)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            logs[\'loss\'].append(loss.item())\n\n            if iteration % args.print_every == 0 or iteration == len(data_loader)-1:\n                print(""Epoch {:02d}/{:02d} Batch {:04d}/{:d}, Loss {:9.4f}"".format(\n                    epoch, args.epochs, iteration, len(data_loader)-1, loss.item()))\n\n                if args.conditional:\n                    c = torch.arange(0, 10).long().unsqueeze(1)\n                    x = vae.inference(n=c.size(0), c=c)\n                else:\n                    x = vae.inference(n=10)\n\n                plt.figure()\n                plt.figure(figsize=(5, 10))\n                for p in range(10):\n                    plt.subplot(5, 2, p+1)\n                    if args.conditional:\n                        plt.text(\n                            0, 0, ""c={:d}"".format(c[p].item()), color=\'black\',\n                            backgroundcolor=\'white\', fontsize=8)\n                    plt.imshow(x[p].view(28, 28).data.numpy())\n                    plt.axis(\'off\')\n\n                if not os.path.exists(os.path.join(args.fig_root, str(ts))):\n                    if not(os.path.exists(os.path.join(args.fig_root))):\n                        os.mkdir(os.path.join(args.fig_root))\n                    os.mkdir(os.path.join(args.fig_root, str(ts)))\n\n                plt.savefig(\n                    os.path.join(args.fig_root, str(ts),\n                                 ""E{:d}I{:d}.png"".format(epoch, iteration)),\n                    dpi=300)\n                plt.clf()\n                plt.close(\'all\')\n\n        df = pd.DataFrame.from_dict(tracker_epoch, orient=\'index\')\n        g = sns.lmplot(\n            x=\'x\', y=\'y\', hue=\'label\', data=df.groupby(\'label\').head(100),\n            fit_reg=False, legend=True)\n        g.savefig(os.path.join(\n            args.fig_root, str(ts), ""E{:d}-Dist.png"".format(epoch)),\n            dpi=300)\n\n\nif __name__ == \'__main__\':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(""--seed"", type=int, default=0)\n    parser.add_argument(""--epochs"", type=int, default=10)\n    parser.add_argument(""--batch_size"", type=int, default=64)\n    parser.add_argument(""--learning_rate"", type=float, default=0.001)\n    parser.add_argument(""--encoder_layer_sizes"", type=list, default=[784, 256])\n    parser.add_argument(""--decoder_layer_sizes"", type=list, default=[256, 784])\n    parser.add_argument(""--latent_size"", type=int, default=2)\n    parser.add_argument(""--print_every"", type=int, default=100)\n    parser.add_argument(""--fig_root"", type=str, default=\'figs\')\n    parser.add_argument(""--conditional"", action=\'store_true\')\n\n    args = parser.parse_args()\n\n    main(args)\n'"
utils.py,2,"b'import torch\n\n\ndef idx2onehot(idx, n):\n\n    assert torch.max(idx).item() < n\n    if idx.dim() == 1:\n        idx = idx.unsqueeze(1)\n\n    onehot = torch.zeros(idx.size(0), n)\n    onehot.scatter_(1, idx, 1)\n\n    return onehot\n'"
