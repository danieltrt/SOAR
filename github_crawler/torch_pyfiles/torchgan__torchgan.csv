file_path,api_count,code
setup.py,0,"b'#!/usr/bin/env python\nimport io\nimport os\nimport re\nimport shutil\nimport sys\n\nfrom pkg_resources import DistributionNotFound, get_distribution\nfrom setuptools import find_packages, setup\n\n\ndef read(*names, **kwargs):\n    with io.open(\n        os.path.join(os.path.dirname(__file__), *names),\n        encoding=kwargs.get(""encoding"", ""utf8""),\n    ) as fp:\n        return fp.read()\n\n\ndef get_dist(pkgname):\n    try:\n        return get_distribution(pkgname)\n    except DistributionNotFound:\n        return None\n\n\ndef find_version(*file_paths):\n    version_file = read(*file_paths)\n    version_match = re.search(r""^__version__ = [\'\\""]([^\'\\""]*)[\'\\""]"", version_file, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(""Unable to find version string."")\n\n\nPATH_ROOT = os.path.dirname(__file__)\nVERSION = find_version(""torchgan"", ""__init__.py"")\n\n\ndef load_requirements(path_dir=PATH_ROOT, comment_char=\'#\'):\n    with open(os.path.join(path_dir, \'requirements.txt\'), \'r\') as file:\n        lines = [ln.strip() for ln in file.readlines()]\n    reqs = []\n    for ln in lines:\n        # filer all comments\n        if comment_char in ln:\n            ln = ln[:ln.index(comment_char)]\n        if ln:  # if requirement is not empty\n            reqs.append(ln)\n    return reqs\n\nsetup(\n    # Metadata\n    name=""torchgan"",\n    version=VERSION,\n    author=""Avik Pal & Aniket Das"",\n    author_email=""avikpal@cse.iitk.ac.in"",\n    url=""https://github.com/torchgan/torchgan"",\n    description=""Research Framework for easy and efficient training of GANs based on Pytorch"",\n    license=""MIT"",\n    # Package info\n    packages=find_packages(exclude=(""test"",)),\n    zip_safe=True,\n    install_requires=load_requirements(PATH_ROOT),\n    long_description=open(\'README.md\', encoding=\'utf-8\').read(),\n    long_description_content_type=\'text/markdown\',\n    include_package_data=True,\n    keywords=[\'deep learning\', \'pytorch\', \'GAN\', \'AI\'],\n    python_requires=\'>=3.6\',\n    classifiers=[\n        \'Environment :: Console\',\n        \'Natural Language :: English\',\n        # How mature is this project? Common values are\n        #   3 - Alpha, 4 - Beta, 5 - Production/Stable\n        \'Development Status :: 4 - Beta\',\n        # Indicate who your project is intended for\n        \'Intended Audience :: Developers\',\n        \'Topic :: Scientific/Engineering :: Artificial Intelligence\',\n        \'Topic :: Scientific/Engineering :: Image Recognition\',\n        \'Topic :: Scientific/Engineering :: Deep Learning\',\n        # Pick your license as you wish\n        \'License :: OSI Approved :: MIT License\',\n        \'Operating System :: OS Independent\',\n        # Specify the Python versions you support here. In particular, ensure\n        # that you indicate whether you support Python 2, Python 3 or both.\n        \'Programming Language :: Python :: 3\',\n        \'Programming Language :: Python :: 3.6\',\n        \'Programming Language :: Python :: 3.7\',\n    ],\n)\n'"
tests/__init__.py,0,b'# Needed to collect coverage data\n'
torchgan/__init__.py,0,"b'from torchgan import layers, logging, losses, metrics, models, trainer\n\n__version__ = ""v0.0.4""\n\nname = ""torchgan""\n'"
torchgan/utils.py,4,"b'from pkgutil import iter_modules\n\nimport torch\n\n\ndef reduce(x, reduction=None):\n    r""""""Applies reduction on a torch.Tensor.\n\n    Args:\n        x (torch.Tensor): The tensor on which reduction is to be applied.\n        reduction (str, optional): The reduction to be applied. If ``mean`` the  mean value of the\n            Tensor is returned. If ``sum`` the elements of the Tensor will be summed. If none of the\n            above then the Tensor is returning without any change.\n\n    Returns:\n        As per the above ``reduction`` convention.\n    """"""\n    if reduction == ""mean"":\n        return torch.mean(x)\n    elif reduction == ""sum"":\n        return torch.sum(x)\n    else:\n        return x\n\n\ndef getenv_defaults(module_name):\n    r""""""Determines if a particular package is installed in the system.\n\n    Args:\n        module_name (str): The name of the package to be found.\n\n    Returns:\n        1 if package is installed else 0\n    """"""\n    return int(module_name in (name for loader, name, ispkg in iter_modules()))\n'"
docs/source/conf.py,1,"b'#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# torchgan documentation build configuration file, created by\n# sphinx-quickstart on Sat Oct  6 13:31:50 2018.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\nimport os\nimport sys\nimport time\n\nimport sphinx_rtd_theme\n\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), ""../.."")))\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#\n# needs_sphinx = \'1.0\'\n\n# Mock Imports\nautodoc_mock_imports = [""torch"", ""pillow"", ""torchvision"", ""tensorboardX"", ""visdom""]\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named \'sphinx.ext.*\') or your custom\n# ones.\nextensions = [\n    ""sphinx.ext.autodoc"",\n    ""sphinx.ext.doctest"",\n    ""sphinx.ext.intersphinx"",\n    ""sphinx.ext.coverage"",\n    ""sphinx.ext.mathjax"",\n    ""sphinx.ext.ifconfig"",\n    ""sphinx.ext.viewcode"",\n    ""sphinx.ext.githubpages"",\n    ""sphinx.ext.napoleon"",\n    # \'sphinx_gallery.gen_gallery\'\n]\n\n# Napoleon settings\nnapoleon_google_docstring = True\nnapoleon_numpy_docstring = True\nnapoleon_include_init_with_doc = False\nnapoleon_include_private_with_doc = False\nnapoleon_include_special_with_doc = True\nnapoleon_use_admonition_for_examples = False\nnapoleon_use_admonition_for_notes = False\nnapoleon_use_admonition_for_references = False\nnapoleon_use_ivar = False\nnapoleon_use_param = True\nnapoleon_use_rtype = True\n\n# # Sphinx Gallery configuration\n# sphinx_gallery_conf = {\n#     # path to your examples scripts\n#     \'examples_dirs\': \'tutorial\',\n#     # path where to save gallery generated examples\n#     \'gallery_dirs\': \'tutorials\',\n# \t# which examples to execute\n# \t\'filename_pattern\': \'/tutorial_\',\n# \t# intersphinx\n# \t\'reference_url\': {\n#          # The module you locally document uses None\n#         \'torchgan\': None,\n#     },\n# \t# binder\n# \t\'binder\': {\n# \t    # Required keys\n# \t    \'org\': \'torchgan\',\n# \t    \'repo\': \'torchgan\',\n# \t    \'url\': \'https://mybinder.org\',  # Any URL of a binder server. Must be full URL (e.g. https://mybinder.org).\n# \t    \'branch\': \'master\',  # Can be any branch, tag, or commit hash. Use a branch that hosts your docs.\n# \t    \'dependencies\': \'requirements.txt\',\n# \t    \'use_jupyter_lab\': True # Whether Binder links should start Jupyter Lab instead of the Jupyter Notebook interface.\n# \t},\n# \t\'show_memory\': True,\n# \t\'thumbnail_size\': (300, 300),\n# }\n#\n# # generate autosummary even if no references\n# autosummary_generate = True\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [""_templates""]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n#\nsource_suffix = ["".rst"", "".md""]\n\n# The master toctree document.\nmaster_doc = ""index""\n\n# General information about the project.\nproject = u""torchgan""\n\ncopyright = u""2018-{}, Avik Pal & Aniket Das"".format(time.strftime(""%Y""))\nauthor = ""Avik Pal & Aniket Das""\n\n# The version info for the project you\'re documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n# The short X.Y version.\nversion = ""v0.0.4""\n# The full version, including alpha/beta/rc tags.\nrelease = ""v0.0.4""\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set ""language"" from the command line for these cases.\nlanguage = None\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This patterns also effect to html_static_path and html_extra_path\nexclude_patterns = []\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = ""sphinx""\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = False\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\nhtml_theme = ""sphinx_rtd_theme""\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#\nhtml_theme_options = {\n    ""canonical_url"": """",\n    ""analytics_id"": """",\n    ""logo_only"": False,\n    ""display_version"": True,\n    ""prev_next_buttons_location"": ""bottom"",\n    ""style_external_links"": True,\n    # Toc options\n    ""collapse_navigation"": False,\n    ""sticky_navigation"": False,\n    ""navigation_depth"": 4,\n    ""includehidden"": True,\n    ""titles_only"": False,\n}\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named ""default.css"" will overwrite the builtin ""default.css"".\nhtml_static_path = [""_static""]\n\n# Custom sidebar templates, must be a dictionary that maps document names\n# to template names.\n#\n# This is required for the alabaster theme\n# refs: http://alabaster.readthedocs.io/en/latest/installation.html#sidebars\n# html_sidebars = {\n#    \'**\': [\'searchbox.html\', \'globaltoc_custom.html\'],\n#    \'using/windows\': [\'searchbox.html\', \'windowssidebar.html\'],\n# }\n\n\n# -- Options for HTMLHelp output ------------------------------------------\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = ""torchgandoc""\n\n# on_rtd is whether we are on readthedocs.org\non_rtd = os.environ.get(""READTHEDOCS"", None) == ""True""\n\nif not on_rtd:  # only import and set the theme if we\'re building docs locally\n    import sphinx_rtd_theme\n\n    html_theme = ""sphinx_rtd_theme""\n    html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\n    def setup(app):\n        # app.add_javascript(""custom.js"")\n        app.add_stylesheet(""theme_overrides.css"")\n\n\nelse:\n    # Override default css to get a larger width for ReadTheDoc build\n    html_context = {\n        ""css_files"": [\n            ""https://media.readthedocs.org/css/sphinx_rtd_theme.css"",\n            ""https://media.readthedocs.org/css/readthedocs-doc-embed.css"",\n            ""_static/theme_overrides.css"",\n        ]\n    }\n\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size (\'letterpaper\' or \'a4paper\').\n    #\n    # \'papersize\': \'letterpaper\',\n    # The font size (\'10pt\', \'11pt\' or \'12pt\').\n    #\n    # \'pointsize\': \'10pt\',\n    # Additional stuff for the LaTeX preamble.\n    #\n    # \'preamble\': \'\',\n    # Latex figure (float) alignment\n    #\n    # \'figure_align\': \'htbp\',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (\n        master_doc,\n        ""torchgan.tex"",\n        ""torchgan Documentation"",\n        ""Avik Pal and Aniket Das"",\n        ""manual"",\n    )\n]\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, ""torchgan"", ""torchgan Documentation"", [author], 1)]\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        ""torchgan"",\n        ""torchgan Documentation"",\n        author,\n        ""torchgan"",\n        ""One line description of project."",\n        ""Miscellaneous"",\n    )\n]\n\n\n# -- Options for Epub output ----------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\nepub_author = author\nepub_publisher = author\nepub_copyright = copyright\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n#\n# epub_identifier = \'\'\n\n# A unique identification for the text.\n#\n# epub_uid = \'\'\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [""search.html""]\n\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {\n    ""python"": (""https://docs.python.org/3/"", None),\n    ""numpy"": (""https://docs.scipy.org/doc/numpy/"", None),\n    ""pytorch"": (""https://pytorch.org/docs/stable"", None),\n}\n'"
tests/torchgan/__init__.py,0,b'# Needed to collect coverage data\n'
tests/torchgan/test_layers.py,12,"b'import os\nimport sys\nimport unittest\n\nimport torch\nfrom torchgan.layers import *\n\nsys.path.append(os.path.join(os.path.dirname(__file__), ""../..""))\n\n\nclass TestLayers(unittest.TestCase):\n    def match_layer_outputs(self, layer, input, output_shape):\n        z = layer(input)\n\n        self.assertEqual(z.shape, output_shape)\n\n    def test_residual_block2d(self):\n        input = torch.rand(16, 3, 10, 10)\n\n        layer = ResidualBlock2d([3, 16, 32, 3], [3, 3, 1], paddings=[1, 1, 0])\n\n        self.match_layer_outputs(layer, input, (16, 3, 10, 10))\n\n        layer = ResidualBlock2d(\n            [3, 16, 32, 1],\n            [3, 3, 1],\n            paddings=[1, 1, 0],\n            shortcut=torch.nn.Conv2d(3, 1, 3, padding=1),\n        )\n\n        self.match_layer_outputs(layer, input, (16, 1, 10, 10))\n\n        layer = ResidualBlock2d([3, 16, 3], [1, 1])\n\n        self.match_layer_outputs(layer, input, (16, 3, 10, 10))\n\n    def test_transposed_residula_block2d(self):\n        input = torch.rand(16, 3, 10, 10)\n\n        layer = ResidualBlockTranspose2d([3, 16, 32, 3], [3, 3, 1], paddings=[1, 1, 0])\n\n        self.match_layer_outputs(layer, input, (16, 3, 10, 10))\n\n        layer = ResidualBlockTranspose2d(\n            [3, 16, 32, 1],\n            [3, 3, 1],\n            paddings=[1, 1, 0],\n            shortcut=torch.nn.Conv2d(3, 1, 3, padding=1),\n        )\n\n        self.match_layer_outputs(layer, input, (16, 1, 10, 10))\n\n        layer = ResidualBlockTranspose2d([3, 16, 3], [1, 1])\n\n        self.match_layer_outputs(layer, input, (16, 3, 10, 10))\n\n    def test_basic_block2d(self):\n        input = torch.rand(16, 3, 10, 10)\n\n        layer = BasicBlock2d(3, 13, 3, 1, 1)\n\n        self.match_layer_outputs(layer, input, (16, 16, 10, 10))\n\n        layer = BasicBlock2d(3, 13, 3, 1, 1, batchnorm=False)\n\n        self.match_layer_outputs(layer, input, (16, 16, 10, 10))\n\n    def test_bottleneck_block2d(self):\n        input = torch.rand(16, 3, 10, 10)\n\n        layer = BottleneckBlock2d(3, 13, 3, 1, 1)\n\n        self.match_layer_outputs(layer, input, (16, 16, 10, 10))\n\n        layer = BottleneckBlock2d(3, 13, 3, 1, 1, batchnorm=False)\n\n        self.match_layer_outputs(layer, input, (16, 16, 10, 10))\n\n    def test_transition_block2d(self):\n        input = torch.rand(16, 3, 10, 10)\n\n        layer = TransitionBlock2d(3, 16, 3, 1, 1)\n\n        self.match_layer_outputs(layer, input, (16, 16, 10, 10))\n\n        layer = TransitionBlock2d(3, 16, 3, 1, 1, batchnorm=False)\n\n        self.match_layer_outputs(layer, input, (16, 16, 10, 10))\n\n    def test_transition_block_transpose2d(self):\n        input = torch.rand(16, 3, 10, 10)\n\n        layer = TransitionBlockTranspose2d(3, 16, 3, 1, 1)\n\n        self.match_layer_outputs(layer, input, (16, 16, 10, 10))\n\n        layer = TransitionBlockTranspose2d(3, 16, 3, 1, 1, batchnorm=False)\n\n        self.match_layer_outputs(layer, input, (16, 16, 10, 10))\n\n    def test_dense_block2d(self):\n        input = torch.rand(16, 3, 10, 10)\n\n        layer = DenseBlock2d(5, 3, 16, BottleneckBlock2d, 3, padding=1)\n\n        self.match_layer_outputs(layer, input, (16, 83, 10, 10))\n\n    def test_self_attention2d(self):\n        input = torch.rand(16, 88, 10, 10)\n\n        layer = SelfAttention2d(88)\n\n        self.match_layer_outputs(layer, input, (16, 88, 10, 10))\n\n    def test_spectral_norm2d(self):\n        input = torch.rand(16, 3, 10, 10)\n\n        layer = SpectralNorm2d(\n            torch.nn.Conv2d(3, 10, 3, padding=1), power_iterations=10\n        )\n\n        self.match_layer_outputs(layer, input, (16, 10, 10, 10))\n'"
tests/torchgan/test_losses.py,9,"b'import os\nimport sys\nimport unittest\n\nimport torch\nimport torch.distributions as ds\nfrom torchgan.losses import *\n\nsys.path.append(os.path.join(os.path.dirname(__file__), ""../..""))\n\n\nclass TestLosses(unittest.TestCase):\n    def match_losses(\n        self,\n        l_g,\n        l_d,\n        dx,\n        dgz,\n        gen_loss_mean,\n        gen_loss_sum,\n        gen_loss_none,\n        d_loss_mean,\n        d_loss_sum,\n        d_loss_none,\n    ):\n        D_X = torch.Tensor(dx).view(-1, 1)\n        D_GZ = torch.Tensor(dgz).view(-1, 1)\n\n        self.assertAlmostEqual(d_loss_mean, l_d(D_X, D_GZ).item(), places=5)\n        l_d.reduction = ""sum""\n        self.assertAlmostEqual(d_loss_sum, l_d(D_X, D_GZ).item(), places=5)\n        l_d.reduction = ""none""\n        loss_none = l_d(D_X, D_GZ).view(-1, 1)\n        for i in range(4):\n            self.assertAlmostEqual(d_loss_none[i], loss_none[i].item(), places=5)\n\n        self.assertAlmostEqual(gen_loss_mean, l_g(D_GZ).item(), places=5)\n        l_g.reduction = ""sum""\n        self.assertAlmostEqual(gen_loss_sum, l_g(D_GZ).item(), places=5)\n        l_g.reduction = ""none""\n        loss_none = l_g(D_GZ).view(-1, 1)\n        for i in range(4):\n            self.assertAlmostEqual(gen_loss_none[i], loss_none[i].item(), places=5)\n\n    def test_wasserstein_loss(self):\n        dx = [1.3, 2.9, 8.4, 6.3]\n        dgz = [4.8, 1.2, -3.5, 5.9]\n\n        gen_loss_mean = -2.1\n        gen_loss_sum = -8.4\n        gen_loss_none = [-4.8, -1.2, 3.5, -5.9]\n\n        d_loss_mean = -2.625\n        d_loss_sum = -10.5\n        d_loss_none = [3.5000002, -1.7, -11.9, -0.4000001]\n\n        w_g = WassersteinGeneratorLoss()\n        w_d = WassersteinDiscriminatorLoss()\n        self.match_losses(\n            w_g,\n            w_d,\n            dx,\n            dgz,\n            gen_loss_mean,\n            gen_loss_sum,\n            gen_loss_none,\n            d_loss_mean,\n            d_loss_sum,\n            d_loss_none,\n        )\n\n    def test_lsgan_loss(self):\n        dx = [1.3, 2.9, 8.4, 6.3]\n        dgz = [4.8, 1.2, -3.5, 5.9]\n\n        gen_loss_mean = 7.3425007\n        gen_loss_sum = 29.370003\n        gen_loss_none = [7.2200007, 0.02000001, 10.125, 12.005]\n\n        d_loss_mean = 19.76125\n        d_loss_sum = 79.045\n        d_loss_none = [11.565001, 2.525, 33.504997, 31.45]\n\n        l_g = LeastSquaresGeneratorLoss()\n        l_d = LeastSquaresDiscriminatorLoss()\n        self.match_losses(\n            l_g,\n            l_d,\n            dx,\n            dgz,\n            gen_loss_mean,\n            gen_loss_sum,\n            gen_loss_none,\n            d_loss_mean,\n            d_loss_sum,\n            d_loss_none,\n        )\n\n    def test_minimax_loss(self):\n        dx = [1.3, 2.9, 8.4, 6.3]\n        dgz = [4.8, 1.2, -3.5, 5.9]\n\n        factor = -torch.log(torch.sigmoid(torch.ones(1))).item()\n\n        gen_loss_mean = -3.3642528 + factor\n        gen_loss_sum = -13.457011 + 4 * factor\n        gen_loss_none = [\n            -5.1214576 + factor,\n            -1.7765441 + factor,\n            -0.3430121 + factor,\n            -6.215997 + factor,\n        ]\n\n        d_loss_mean = 3.1251488\n        d_loss_sum = 12.500595\n        d_loss_none = [5.0492043, 1.5168452, 0.02997526, 5.90457]\n\n        l_g = MinimaxGeneratorLoss(nonsaturating=False)\n        l_d = MinimaxDiscriminatorLoss()\n        self.match_losses(\n            l_g,\n            l_d,\n            dx,\n            dgz,\n            gen_loss_mean,\n            gen_loss_sum,\n            gen_loss_none,\n            d_loss_mean,\n            d_loss_sum,\n            d_loss_none,\n        )\n\n    def test_minimax_nonsaturating_loss(self):\n        dx = [1.3, 2.9, 8.4, 6.3]\n        dgz = [4.8, 1.2, -3.5, 5.9]\n\n        gen_loss_mean = 0.9509911\n        gen_loss_sum = 3.8039644\n        gen_loss_none = [8.1960661e-03, 2.6328245e-01, 3.5297503e00, 2.7356991e-03]\n\n        d_loss_mean = 3.1251488\n        d_loss_sum = 12.500595\n        d_loss_none = [5.0492043, 1.5168452, 0.02997526, 5.90457]\n\n        l_g = MinimaxGeneratorLoss(nonsaturating=True)\n        l_d = MinimaxDiscriminatorLoss()\n        self.match_losses(\n            l_g,\n            l_d,\n            dx,\n            dgz,\n            gen_loss_mean,\n            gen_loss_sum,\n            gen_loss_none,\n            d_loss_mean,\n            d_loss_sum,\n            d_loss_none,\n        )\n\n    def test_mutual_info_penalty(self):\n        real_loss_mean = 2.600133\n        real_loss_sum = 5.200266\n        real_losses = [0.7086121, 4.491654]\n        mean = torch.Tensor([[1.3, 4.6, 7.1], [0.2, 11.4, 1.0]])\n        std = torch.Tensor([[1.0, 0.5, 3.1], [0.2, 3.5, 4.9]])\n        logits = torch.Tensor([[0.5, 0.5], [0.75, 0.25]])\n\n        c_dis = torch.Tensor([[0, 1], [1, 0]])\n        c_cont = torch.Tensor([[1.4, 4.0, 5.0], [-1.0, 7.0, 2.0]])\n\n        q_cont = ds.Normal(loc=mean, scale=std)\n        q_cat = ds.Categorical(logits=logits)\n\n        mutualinfo = MutualInformationPenalty()\n        loss_mean = mutualinfo(c_dis, c_cont, q_cat, q_cont)\n        self.assertAlmostEqual(loss_mean.item(), real_loss_mean, 5)\n\n        mutualinfo.reduction = ""sum""\n        loss_sum = mutualinfo(c_dis, c_cont, q_cat, q_cont)\n        self.assertAlmostEqual(loss_sum.item(), real_loss_sum, 5)\n\n        mutualinfo.reduction = ""none""\n        loss = mutualinfo(c_dis, c_cont, q_cat, q_cont)\n        for i in range(2):\n            self.assertAlmostEqual(loss[i].item(), real_losses[i], 5)\n'"
tests/torchgan/test_metrics.py,1,"b'import os\nimport sys\nimport unittest\n\nimport torch\nfrom torchgan.metrics import *\n\nsys.path.append(os.path.join(os.path.dirname(__file__), ""../..""))\n\n\nclass TestMetrics(unittest.TestCase):\n    def test_inception_score(self):\n        inception_score = ClassifierScore()\n        x = torch.Tensor([[1.0, 2.0, 3.0], [-1.0, 5.0, 3.1]])\n        self.assertAlmostEqual(inception_score.calculate_score(x).item(), 1.24357, 4)\n'"
tests/torchgan/test_models.py,36,"b'import os\nimport sys\nimport unittest\n\nimport torch\nimport torch.distributions as distributions\nfrom torchgan.models import *\n\nsys.path.append(os.path.join(os.path.dirname(__file__), ""../..""))\n\n\nclass TestModels(unittest.TestCase):\n    def test_dcgan_generator(self):\n        encodings = [50, 100]\n        channels = [3, 4]\n        out_size = [32, 256]\n        step = [64, 128]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ReLU()]\n        last_nonlinearity = [None, torch.nn.LeakyReLU()]\n        for i in range(2):\n            gen = DCGANGenerator(\n                encodings[i],\n                out_size[i],\n                channels[i],\n                step[i],\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            z = torch.rand(10, encodings[i])\n            x = gen(z)\n            assert x.shape == (10, channels[i], out_size[i], out_size[i])\n\n    def test_dcgan_discriminator(self):\n        channels = [3, 4]\n        step = [64, 128]\n        in_size = [32, 64]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ReLU()]\n        last_nonlinearity = [None, torch.nn.LeakyReLU()]\n        for i in range(2):\n            dis = DCGANDiscriminator(\n                in_size[i],\n                channels[i],\n                step[i],\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            x = torch.rand(10, channels[i], in_size[i], in_size[i])\n            loss = dis(x)\n            assert loss.shape == (10,)\n\n    def test_conditional_gan_generator(self):\n        encodings = [50, 100]\n        channels = [3, 4]\n        out_size = [32, 64]\n        classes = [5, 10]\n        step = [64, 128]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ELU(0.5)]\n        last_nonlinearity = [None, torch.nn.RReLU(0.25)]\n        for i in range(2):\n            ch = step[i]\n            x = torch.randn(10, encodings[i])\n            gen = ConditionalGANGenerator(\n                classes[i],\n                encodings[i],\n                out_size[i],\n                channels[i],\n                ch,\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            labels = torch.randint(0, classes[i], (10,))\n            y = gen(x, labels)\n            assert y.shape == (10, channels[i], out_size[i], out_size[i])\n\n    def test_conditional_gan_discriminator(self):\n        channels = [3, 4]\n        in_size = [32, 64]\n        classes = [5, 10]\n        step = [64, 128]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ELU(0.5)]\n        last_nonlinearity = [None, torch.nn.RReLU(0.25)]\n        for i in range(2):\n            ch = step[i]\n            x = torch.randn(10, channels[i], in_size[i], in_size[i])\n            gen = ConditionalGANDiscriminator(\n                classes[i],\n                in_size[i],\n                channels[i],\n                ch,\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            labels = torch.randint(0, classes[i], (10,))\n            y = gen(x, labels)\n            assert y.shape == (10,)\n\n    def test_acgan_generator(self):\n        encodings = [50, 100]\n        channels = [3, 4]\n        out_size = [32, 64]\n        classes = [5, 10]\n        step = [64, 128]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ELU(0.5)]\n        last_nonlinearity = [None, torch.nn.RReLU(0.25)]\n        for i in range(2):\n            ch = step[i]\n            x = torch.randn(10, encodings[i])\n            gen = ACGANGenerator(\n                classes[i],\n                encodings[i],\n                out_size[i],\n                channels[i],\n                ch,\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            labels = torch.randint(0, classes[i], (10,))\n            y = gen(x, labels)\n            assert y.shape == (10, channels[i], out_size[i], out_size[i])\n\n    def test_acgan_discriminator(self):\n        channels = [3, 4]\n        in_size = [32, 64]\n        classes = [5, 10]\n        step = [64, 128]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ELU(0.5)]\n        last_nonlinearity = [None, torch.nn.RReLU(0.25)]\n        for i in range(2):\n            ch = step[i]\n            x = torch.randn(10, channels[i], in_size[i], in_size[i])\n            gen = ACGANDiscriminator(\n                classes[i],\n                in_size[i],\n                channels[i],\n                ch,\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            dx, cx = gen(x, mode=""combine"")\n            assert dx.shape == (10,)\n            assert cx.shape == (10, classes[i])\n\n    def test_infogan_generator(self):\n        encodings = [50, 100]\n        channels = [3, 4]\n        out_size = [32, 64]\n        step = [64, 128]\n        dim_cont = [10, 20]\n        dim_dis = [30, 40]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ELU(0.5)]\n        last_nonlinearity = [None, torch.nn.RReLU(0.25)]\n        for i in range(2):\n            ch = step[i]\n            x = torch.randn(10, encodings[i])\n            cont = torch.rand(10, dim_cont[i])\n            dis = torch.zeros(10, dim_dis[i])\n            gen = InfoGANGenerator(\n                dim_cont[i],\n                dim_dis[i],\n                encodings[i],\n                out_size[i],\n                channels[i],\n                ch,\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            y = gen(x, cont, dis)\n            assert y.shape == (10, channels[i], out_size[i], out_size[i])\n\n    def test_infogan_discriminator(self):\n        channels = [3, 4]\n        in_size = [32, 64]\n        dim_cont = [10, 20]\n        dim_dis = [30, 40]\n        step = [64, 128]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ELU(0.5)]\n        last_nonlinearity = [None, torch.nn.RReLU(0.25)]\n        for i in range(2):\n            x = torch.randn(10, channels[i], in_size[i], in_size[i])\n            D = InfoGANDiscriminator(\n                dim_dis[i],\n                dim_cont[i],\n                in_size[i],\n                channels[i],\n                step[i],\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            y, dist_dis, dist_cont = D(x, True)\n            assert y.shape == (10, 1, 1, 1)\n            assert isinstance(dist_dis, distributions.OneHotCategorical)\n            assert isinstance(dist_cont, distributions.Normal)\n            assert dist_dis.sample().shape == (10, dim_dis[i])\n            assert dist_cont.sample().shape == (10, dim_cont[i])\n\n    def test_autoencoding_generator(self):\n        encodings = [50, 100]\n        channels = [3, 4]\n        out_size = [32, 64]\n        step = [64, 128]\n        scale = [2, 2]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ReLU()]\n        last_nonlinearity = [None, torch.nn.LeakyReLU()]\n        for i in range(2):\n            gen = AutoEncodingGenerator(\n                encodings[i],\n                out_size[i],\n                channels[i],\n                step[i],\n                scale[i],\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            z = torch.rand(10, encodings[i])\n            x = gen(z)\n            assert x.shape == (10, channels[i], out_size[i], out_size[i])\n\n    def test_autoencoding_discriminator(self):\n        channels = [3, 4]\n        encodings = [50, 100]\n        in_size = [32, 64]\n        step = [64, 128]\n        scale = [2, 2]\n        batchnorm = [True, False]\n        nonlinearities = [None, torch.nn.ReLU()]\n        last_nonlinearity = [None, torch.nn.LeakyReLU()]\n        for i in range(2):\n            dis = AutoEncodingDiscriminator(\n                in_size[i],\n                channels[i],\n                encodings[i],\n                step[i],\n                scale[i],\n                batchnorm[i],\n                nonlinearities[i],\n                last_nonlinearity[i],\n            )\n            x = torch.rand(10, channels[i], in_size[i], in_size[i])\n            loss = dis(x)\n            assert loss.shape == (10,)\n'"
tests/torchgan/test_trainer.py,5,"b'import os\nimport sys\nimport unittest\n\nimport torch\nimport torch.utils.data as data\nimport torchvision\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.optim import Adam\nfrom torchgan import *\nfrom torchgan.losses import *\nfrom torchgan.metrics import *\nfrom torchgan.models import *\nfrom torchgan.trainer import Trainer\n\nsys.path.append(os.path.join(os.path.dirname(__file__), ""../..""))\n\n\ndef mnist_dataloader():\n    train_dataset = dsets.MNIST(\n        root=""./mnist"",\n        train=True,\n        transform=transforms.Compose(\n            [\n                transforms.Pad((2, 2)),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=(0.5,), std=(0.5,)),\n            ]\n        ),\n        download=True,\n    )\n    train_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n    return train_loader\n\n\nclass TestTrainer(unittest.TestCase):\n    def test_trainer_dcgan(self):\n        network_params = {\n            ""generator"": {\n                ""name"": DCGANGenerator,\n                ""args"": {""out_channels"": 1, ""step_channels"": 4},\n                ""optimizer"": {\n                    ""name"": Adam,\n                    ""args"": {""lr"": 0.0002, ""betas"": (0.5, 0.999)},\n                },\n            },\n            ""discriminator"": {\n                ""name"": DCGANDiscriminator,\n                ""args"": {""in_channels"": 1, ""step_channels"": 4},\n                ""optimizer"": {\n                    ""name"": Adam,\n                    ""args"": {""lr"": 0.0002, ""betas"": (0.5, 0.999)},\n                },\n            },\n        }\n        losses_list = [MinimaxGeneratorLoss(), MinimaxDiscriminatorLoss()]\n        trainer = Trainer(\n            network_params,\n            losses_list,\n            sample_size=1,\n            epochs=1,\n            device=torch.device(""cpu""),\n        )\n        trainer(mnist_dataloader())\n\n    def test_trainer_cgan(self):\n        network_params = {\n            ""generator"": {\n                ""name"": ConditionalGANGenerator,\n                ""args"": {""num_classes"": 10, ""out_channels"": 1, ""step_channels"": 4},\n                ""optimizer"": {\n                    ""name"": Adam,\n                    ""args"": {""lr"": 0.0002, ""betas"": (0.5, 0.999)},\n                },\n            },\n            ""discriminator"": {\n                ""name"": ConditionalGANDiscriminator,\n                ""args"": {""num_classes"": 10, ""in_channels"": 1, ""step_channels"": 4},\n                ""optimizer"": {\n                    ""name"": Adam,\n                    ""args"": {""lr"": 0.0002, ""betas"": (0.5, 0.999)},\n                },\n            },\n        }\n        losses_list = [MinimaxGeneratorLoss(), MinimaxDiscriminatorLoss()]\n        trainer = Trainer(\n            network_params,\n            losses_list,\n            sample_size=1,\n            epochs=1,\n            device=torch.device(""cpu""),\n        )\n        trainer(mnist_dataloader())\n\n    def test_trainer_acgan(self):\n        network_params = {\n            ""generator"": {\n                ""name"": ACGANGenerator,\n                ""args"": {""num_classes"": 10, ""out_channels"": 1, ""step_channels"": 4},\n                ""optimizer"": {\n                    ""name"": Adam,\n                    ""args"": {""lr"": 0.0002, ""betas"": (0.5, 0.999)},\n                },\n            },\n            ""discriminator"": {\n                ""name"": ACGANDiscriminator,\n                ""args"": {""num_classes"": 10, ""in_channels"": 1, ""step_channels"": 4},\n                ""optimizer"": {\n                    ""name"": Adam,\n                    ""args"": {""lr"": 0.0002, ""betas"": (0.5, 0.999)},\n                },\n            },\n        }\n        losses_list = [\n            MinimaxGeneratorLoss(),\n            MinimaxDiscriminatorLoss(),\n            AuxiliaryClassifierGeneratorLoss(),\n            AuxiliaryClassifierDiscriminatorLoss(),\n        ]\n        trainer = Trainer(\n            network_params,\n            losses_list,\n            sample_size=1,\n            epochs=1,\n            device=torch.device(""cpu""),\n        )\n        trainer(mnist_dataloader())\n'"
torchgan/layers/__init__.py,0,b'from .denseblock import *\nfrom .minibatchdiscrimination import *\nfrom .residual import *\nfrom .selfattention import *\nfrom .spectralnorm import *\nfrom .virtualbatchnorm import *\n'
torchgan/layers/denseblock.py,19,"b'import torch\nimport torch.nn as nn\n\n__all__ = [\n    ""BasicBlock2d"",\n    ""BottleneckBlock2d"",\n    ""TransitionBlock2d"",\n    ""TransitionBlockTranspose2d"",\n    ""DenseBlock2d"",\n]\n\n\nclass BasicBlock2d(nn.Module):\n    r""""""Basic Block Module as described in `""Densely Connected Convolutional Networks by Huang et.\n    al."" <https://arxiv.org/abs/1608.06993>`_\n\n    The output is computed by ``concatenating`` the ``input`` tensor to the ``output`` tensor (of the\n    internal model) along the ``channel`` dimension.\n\n    The internal model is simply a sequence of a ``Conv2d`` layer and a ``BatchNorm2d`` layer, if\n    activated.\n\n    Args:\n        in_channels (int): The channel dimension of the input tensor.\n        out_channels (int): The channel dimension of the output tensor.\n        kernel (int, tuple): Size of the Convolutional Kernel.\n        stride (int, tuple, optional): Stride of the Convolutional Kernel.\n        padding (int, tuple, optional): Padding to be applied on the input tensor.\n        batchnorm (bool, optional): If ``True``, batch normalization shall be performed.\n        nonlinearity (torch.nn.Module, optional): Activation to be applied. Defaults to\n                                                  ``torch.nn.LeakyReLU``.\n    """"""\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel,\n        stride=1,\n        padding=0,\n        batchnorm=True,\n        nonlinearity=None,\n    ):\n        super(BasicBlock2d, self).__init__()\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        if batchnorm is True:\n            self.model = nn.Sequential(\n                nn.BatchNorm2d(in_channels),\n                nl,\n                nn.Conv2d(\n                    in_channels, out_channels, kernel, stride, padding, bias=False\n                ),\n            )\n        else:\n            self.model = nn.Sequential(\n                nl,\n                nn.Conv2d(\n                    in_channels, out_channels, kernel, stride, padding, bias=True\n                ),\n            )\n\n    def forward(self, x):\n        r""""""Computes the output of the basic dense block\n\n        Args:\n            x (torch.Tensor): The input tensor having channel dimension same as ``in_channels``.\n\n        Returns:\n            4D Tensor by concatenating the input to the output of the internal model.\n        """"""\n        return torch.cat([x, self.model(x)], 1)\n\n\nclass BottleneckBlock2d(nn.Module):\n    r""""""Bottleneck Block Module as described in `""Densely Connected Convolutional Networks by Huang\n    et. al."" <https://arxiv.org/abs/1608.06993>`_\n\n    The output is computed by ``concatenating`` the ``input`` tensor to the ``output`` tensor (of the\n    internal model) along the ``channel`` dimension.\n\n    The internal model is simply a sequence of 2 ``Conv2d`` layers and 2 ``BatchNorm2d`` layers, if\n    activated. This Module is much more computationally efficient than the ``BasicBlock2d``, and hence\n    is more recommended.\n\n    Args:\n        in_channels (int): The channel dimension of the input tensor.\n        out_channels (int): The channel dimension of the output tensor.\n        kernel (int, tuple): Size of the Convolutional Kernel.\n        stride (int, tuple, optional): Stride of the Convolutional Kernel.\n        padding (int, tuple, optional): Padding to be applied on the input tensor.\n        bottleneck_channels (int, optional): The channels in the intermediate convolutional\n                                             layer. A higher value will make learning of\n                                             more complex functions possible. Defaults to\n                                             ``4 * in_channels``.\n        batchnorm (bool, optional): If ``True``, batch normalization shall be performed.\n        nonlinearity (torch.nn.Module, optional): Activation to be applied. Defaults to\n                                                  ``torch.nn.LeakyReLU``.\n    """"""\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel,\n        stride=1,\n        padding=0,\n        bottleneck_channels=None,\n        batchnorm=True,\n        nonlinearity=None,\n    ):\n        super(BottleneckBlock2d, self).__init__()\n        bottleneck_channels = (\n            4 * in_channels if bottleneck_channels is None else bottleneck_channels\n        )\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        if batchnorm is True:\n            self.model = nn.Sequential(\n                nn.BatchNorm2d(in_channels),\n                nl,\n                nn.Conv2d(in_channels, bottleneck_channels, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(bottleneck_channels),\n                nl,\n                nn.Conv2d(\n                    bottleneck_channels,\n                    out_channels,\n                    kernel,\n                    stride,\n                    padding,\n                    bias=False,\n                ),\n            )\n        else:\n            self.model = nn.Sequential(\n                nl,\n                nn.Conv2d(in_channels, bottleneck_channels, 1, 1, 0, bias=True),\n                nl,\n                nn.Conv2d(\n                    bottleneck_channels,\n                    out_channels,\n                    kernel,\n                    stride,\n                    padding,\n                    bias=True,\n                ),\n            )\n\n    def forward(self, x):\n        r""""""Computes the output of the bottleneck dense block\n\n        Args:\n            x (torch.Tensor): The input tensor having channel dimension same as ``in_channels``.\n\n        Returns:\n            4D Tensor by concatenating the input to the output of the internal model.\n        """"""\n        return torch.cat([x, self.model(x)], 1)\n\n\nclass TransitionBlock2d(nn.Module):\n    r""""""Transition Block Module as described in `""Densely Connected Convolutional Networks by Huang\n    et. al."" <https://arxiv.org/abs/1608.06993>`_\n\n    This is a simple ``Sequential`` model of a ``Conv2d`` layer and a ``BatchNorm2d`` layer, if\n    activated.\n\n    Args:\n        in_channels (int): The channel dimension of the input tensor.\n        out_channels (int): The channel dimension of the output tensor.\n        kernel (int, tuple): Size of the Convolutional Kernel.\n        stride (int, tuple, optional): Stride of the Convolutional Kernel.\n        padding (int, tuple, optional): Padding to be applied on the input tensor.\n        batchnorm (bool, optional): If ``True``, batch normalization shall be performed.\n        nonlinearity (torch.nn.Module, optional): Activation to be applied. Defaults to\n                                                  ``torch.nn.LeakyReLU``.\n    """"""\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel,\n        stride=1,\n        padding=0,\n        batchnorm=True,\n        nonlinearity=None,\n    ):\n        super(TransitionBlock2d, self).__init__()\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        if batchnorm is True:\n            self.model = nn.Sequential(\n                nn.BatchNorm2d(in_channels),\n                nl,\n                nn.Conv2d(\n                    in_channels, out_channels, kernel, stride, padding, bias=False\n                ),\n            )\n        else:\n            self.model = nn.Sequential(\n                nl,\n                nn.Conv2d(\n                    in_channels, out_channels, kernel, stride, padding, bias=True\n                ),\n            )\n\n    def forward(self, x):\n        r""""""Computes the output of the transition block\n\n        Args:\n            x (torch.Tensor): The input tensor having channel dimension same as ``in_channels``.\n\n        Returns:\n            4D Tensor by applying the ``model`` on ``x``.\n        """"""\n        return self.model(x)\n\n\nclass TransitionBlockTranspose2d(nn.Module):\n    r""""""Transition Block Transpose Module is constructed by simply reversing the effect of\n    Transition Block Module. We replace the ``Conv2d`` layers by ``ConvTranspose2d`` layers.\n\n    Args:\n        in_channels (int): The channel dimension of the input tensor.\n        out_channels (int): The channel dimension of the output tensor.\n        kernel (int, tuple): Size of the Convolutional Kernel.\n        stride (int, tuple, optional): Stride of the Convolutional Kernel.\n        padding (int, tuple, optional): Padding to be applied on the input tensor.\n        batchnorm (bool, optional): If ``True``, batch normalization shall be performed.\n        nonlinearity (torch.nn.Module, optional): Activation to be applied. Defaults to\n                                                  ``torch.nn.LeakyReLU``.\n    """"""\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel,\n        stride=1,\n        padding=0,\n        batchnorm=True,\n        nonlinearity=None,\n    ):\n        super(TransitionBlockTranspose2d, self).__init__()\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        if batchnorm is True:\n            self.model = nn.Sequential(\n                nn.BatchNorm2d(in_channels),\n                nl,\n                nn.ConvTranspose2d(\n                    in_channels, out_channels, kernel, stride, padding, bias=False\n                ),\n            )\n        else:\n            self.model = nn.Sequential(\n                nl,\n                nn.ConvTranspose2d(\n                    in_channels, out_channels, kernel, stride, padding, bias=True\n                ),\n            )\n\n    def forward(self, x):\n        r""""""Computes the output of the transition block transpose\n\n        Args:\n            x (torch.Tensor): The input tensor having channel dimension same as ``in_channels``.\n\n        Returns:\n            4D Tensor by applying the ``model`` on ``x``.\n        """"""\n        return self.model(x)\n\n\nclass DenseBlock2d(nn.Module):\n    r""""""Dense Block Module as described in `""Densely Connected Convolutional Networks by Huang\n    et. al."" <https://arxiv.org/abs/1608.06993>`_\n\n    Args:\n        depth (int): The total number of ``blocks`` that will be present.\n        in_channels (int): The channel dimension of the input tensor.\n        growth_rate (int): The rate at which the channel dimension increases. The output of\n                           the module has a channel dimension of size ``in_channels +\n                           depth * growth_rate``.\n        block (torch.nn.Module): Should be once of the Densenet Blocks. Forms the building block\n                                 for the Dense Block.\n        kernel (int, tuple): Size of the Convolutional Kernel.\n        stride (int, tuple, optional): Stride of the Convolutional Kernel.\n        padding (int, tuple, optional): Padding to be applied on the input tensor.\n        batchnorm (bool, optional): If ``True``, batch normalization shall be performed.\n        nonlinearity (torch.nn.Module, optional): Activation to be applied. Defaults to\n                                                  ``torch.nn.LeakyReLU``.\n    """"""\n\n    def __init__(\n        self,\n        depth,\n        in_channels,\n        growth_rate,\n        block,\n        kernel,\n        stride=1,\n        padding=0,\n        batchnorm=True,\n        nonlinearity=None,\n    ):\n        super(DenseBlock2d, self).__init__()\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        model = []\n        for i in range(depth):\n            # FIXME(Aniket1998): There is no way to pass an option for bottleneck channels\n            model.append(\n                block(\n                    in_channels + i * growth_rate,\n                    growth_rate,\n                    kernel,\n                    stride,\n                    padding,\n                    batchnorm=batchnorm,\n                    nonlinearity=nl,\n                )\n            )\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        r""""""Computes the output of the transition block transpose\n\n        Args:\n            x (torch.Tensor): The input tensor having channel dimension same as ``in_channels``.\n\n        Returns:\n            4D Tensor by applying the ``model`` on ``x``.\n        """"""\n        return self.model(x)\n'"
torchgan/layers/minibatchdiscrimination.py,6,"b'import torch\nimport torch.nn as nn\n\n__all__ = [""MinibatchDiscrimination1d""]\n\n# The original paper by Salimans et. al. discusses only 1D minibatch discrimination\nclass MinibatchDiscrimination1d(nn.Module):\n    r""""""1D Minibatch Discrimination Module as proposed in the paper `""Improved Techniques for\n    Training GANs by Salimans et. al."" <https://arxiv.org/abs/1805.08318>`_\n\n    Allows the Discriminator to easily detect mode collapse by augmenting the activations to the succeeding\n    layer with side information that allows it to determine the \'closeness\' of the minibatch examples\n    with each other\n\n    .. math :: M_i = T * f(x_{i})\n    .. math :: c_b(x_{i}, x_{j}) = \\exp(-||M_{i, b} - M_{j, b}||_1) \\in \\mathbb{R}.\n    .. math :: o(x_{i})_b &= \\sum_{j=1}^{n} c_b(x_{i},x_{j}) \\in \\mathbb{R} \\\\\n    .. math :: o(x_{i}) &= \\Big[ o(x_{i})_1, o(x_{i})_2, \\dots, o(x_{i})_B \\Big] \\in \\mathbb{R}^B \\\\\n    .. math :: o(X) \\in \\mathbb{R}^{n \\times B}\n\n    This is followed by concatenating :math:`o(x_{i})` and :math:`f(x_{i})`\n\n    where\n\n    - :math:`f(x_{i}) \\in \\mathbb{R}^A` : Activations from an intermediate layer\n    - :math:`f(x_{i}) \\in \\mathbb{R}^A` : Parameter Tensor for generating minibatch discrimination matrix\n\n\n    Args:\n        in_features (int): Features input corresponding to dimension :math:`A`\n        out_features (int): Number of output features that are to be concatenated corresponding to dimension :math:`B`\n        intermediate_features (int): Intermediate number of features corresponding to dimension :math:`C`\n\n    Returns:\n        A Tensor of size :math:`(N, in_features + out_features)` where :math:`N` is the batch size\n    """"""\n\n    def __init__(self, in_features, out_features, intermediate_features=16):\n        super(MinibatchDiscrimination1d, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.intermediate_features = intermediate_features\n\n        self.T = nn.Parameter(\n            torch.Tensor(in_features, out_features, intermediate_features)\n        )\n        nn.init.normal_(self.T)\n\n    def forward(self, x):\n        r""""""Computes the output of the Minibatch Discrimination Layer\n\n        Args:\n            x (torch.Tensor): A Torch Tensor of dimensions :math: `(N, infeatures)`\n\n        Returns:\n            3D Torch Tensor of size :math: `(N,infeatures + outfeatures)` after applying Minibatch Discrimination\n        """"""\n        M = torch.mm(x, self.T.view(self.in_features, -1))\n        M = M.view(-1, self.out_features, self.intermediate_features).unsqueeze(0)\n        M_t = M.permute(1, 0, 2, 3)\n        # Broadcasting reduces the matrix subtraction to the form desired in the paper\n        out = torch.sum(torch.exp(-(torch.abs(M - M_t).sum(3))), dim=0) - 1\n        return torch.cat([x, out], 1)\n'"
torchgan/layers/residual.py,9,"b'import torch.nn as nn\n\n__all__ = [""ResidualBlock2d"", ""ResidualBlockTranspose2d""]\n\n\nclass ResidualBlock2d(nn.Module):\n    r""""""Residual Block Module as described in `""Deep Residual Learning for Image Recognition\n    by He et. al."" <https://arxiv.org/abs/1512.03385>`_\n\n    The output of the residual block is computed in the following manner:\n\n    .. math:: output = activation(layers(x) + shortcut(x))\n\n    where\n\n    - :math:`x` : Input to the Module\n    - :math:`layers` : The feed forward network\n    - :math:`shortcut` : The function to be applied along the skip connection\n    - :math:`activation` : The activation function applied at the end of the residual block\n\n    Args:\n        filters (list): A list of the filter sizes. For ex, if the input has a channel\n            dimension of 16, and you want 3 convolution layers and the final output to have a\n            channel dimension of 16, then the list would be [16, 32, 64, 16].\n        kernels (list): A list of the kernel sizes. Each kernel size can be an integer or a\n            tuple, similar to Pytorch convention. The length of the ``kernels`` list must be\n            1 less than the ``filters`` list.\n        strides (list, optional): A list of the strides for each convolution layer.\n        paddings (list, optional): A list of the padding in each convolution layer.\n        nonlinearity (torch.nn.Module, optional): The activation to be used after every convolution\n            layer.\n        batchnorm (bool, optional): If set to ``False``, batch normalization is not used after\n            every convolution layer.\n        shortcut (torch.nn.Module, optional): The function to be applied on the input along the\n            skip connection.\n        last_nonlinearity (torch.nn.Module, optional): The activation to be applied at the end of\n            the residual block.\n    """"""\n\n    def __init__(\n        self,\n        filters,\n        kernels,\n        strides=None,\n        paddings=None,\n        nonlinearity=None,\n        batchnorm=True,\n        shortcut=None,\n        last_nonlinearity=None,\n    ):\n        super(ResidualBlock2d, self).__init__()\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        if strides is None:\n            strides = [1 for _ in range(len(kernels))]\n        if paddings is None:\n            paddings = [0 for _ in range(len(kernels))]\n        assert (\n            len(filters) == len(kernels) + 1\n            and len(filters) == len(strides) + 1\n            and len(filters) == len(paddings) + 1\n        )\n        layers = []\n        for i in range(1, len(filters)):\n            layers.append(\n                nn.Conv2d(\n                    filters[i - 1],\n                    filters[i],\n                    kernels[i - 1],\n                    strides[i - 1],\n                    paddings[i - 1],\n                )\n            )\n            if batchnorm:\n                layers.append(nn.BatchNorm2d(filters[i]))\n            if i != len(filters):  # Last layer does not get an activation\n                layers.append(nl)\n        self.layers = nn.Sequential(*layers)\n        self.shortcut = shortcut\n        self.last_nonlinearity = last_nonlinearity\n\n    def forward(self, x):\n        r""""""Computes the output of the residual block\n\n        Args:\n            x (torch.Tensor): A 4D Torch Tensor which is the input to the Residual Block.\n\n        Returns:\n            4D Torch Tensor after applying the desired functions as specified while creating the\n            object.\n        """"""\n        out = self.layers(x)\n        if self.shortcut is not None:\n            out += self.shortcut(x)\n        else:\n            out += x\n        return out if self.last_nonlinearity is None else self.last_nonlinearity(out)\n\n\nclass ResidualBlockTranspose2d(nn.Module):\n    r""""""A customized version of Residual Block having Conv Transpose layers instead of Conv layers.\n\n    The output of this block is computed in the following manner:\n\n    .. math:: output = activation(layers(x) + shortcut(x))\n\n    where\n\n    - :math:`x` : Input to the Module\n    - :math:`layers` : The feed forward network\n    - :math:`shortcut` : The function to be applied along the skip connection\n    - :math:`activation` : The activation function applied at the end of the residual block\n\n    Args:\n        filters (list): A list of the filter sizes. For ex, if the input has a channel\n            dimension of 16, and you want 3 transposed convolution layers and the final output\n            to have a channel dimension of 16, then the list would be [16, 32, 64, 16].\n        kernels (list): A list of the kernel sizes. Each kernel size can be an integer or a\n            tuple, similar to Pytorch convention. The length of the ``kernels`` list must be\n            1 less than the ``filters`` list.\n        strides (list, optional): A list of the strides for each convolution layer.\n        paddings (list, optional): A list of the padding in each convolution layer.\n        nonlinearity (torch.nn.Module, optional): The activation to be used after every convolution\n            layer.\n        batchnorm (bool, optional): If set to ``False``, batch normalization is not used after\n            every convolution layer.\n        shortcut (torch.nn.Module, optional): The function to be applied on the input along the\n            skip connection.\n        last_nonlinearity (torch.nn.Module, optional): The activation to be applied at the end of\n            the residual block.\n    """"""\n\n    def __init__(\n        self,\n        filters,\n        kernels,\n        strides=None,\n        paddings=None,\n        nonlinearity=None,\n        batchnorm=True,\n        shortcut=None,\n        last_nonlinearity=None,\n    ):\n        super(ResidualBlockTranspose2d, self).__init__()\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        if strides is None:\n            strides = [1 for _ in range(len(kernels))]\n        if paddings is None:\n            paddings = [0 for _ in range(len(kernels))]\n        assert (\n            len(filters) == len(kernels) + 1\n            and len(filters) == len(strides) + 1\n            and len(filters) == len(paddings) + 1\n        )\n        layers = []\n        for i in range(1, len(filters)):\n            layers.append(\n                nn.ConvTranspose2d(\n                    filters[i - 1],\n                    filters[i],\n                    kernels[i - 1],\n                    strides[i - 1],\n                    paddings[i - 1],\n                )\n            )\n            if batchnorm:\n                layers.append(nn.BatchNorm2d(filters[i]))\n            if i != len(filters):  # Last layer does not get an activation\n                layers.append(nl)\n        self.layers = nn.Sequential(*layers)\n        self.shortcut = shortcut\n        self.last_nonlinearity = last_nonlinearity\n\n    def forward(self, x):\n        r""""""Computes the output of the residual block\n\n        Args:\n            x (torch.Tensor): A 4D Torch Tensor which is the input to the Transposed Residual Block.\n\n        Returns:\n            4D Torch Tensor after applying the desired functions as specified while creating the\n            object.\n        """"""\n        out = self.layers(x)\n        if self.shortcut is not None:\n            out += self.shortcut(x)\n        else:\n            out += x\n        return out if self.last_nonlinearity is None else self.last_nonlinearity(out)\n'"
torchgan/layers/selfattention.py,6,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n__all__ = [""SelfAttention2d""]\n\n\nclass SelfAttention2d(nn.Module):\n    r""""""Self Attention Module as proposed in the paper `""Self-Attention Generative Adversarial\n    Networks by Han Zhang et. al."" <https://arxiv.org/abs/1805.08318>`_\n\n    .. math:: attention = softmax((query(x))^T * key(x))\n    .. math:: output = \\gamma * value(x) * attention + x\n\n    where\n\n    - :math:`query` : 2D Convolution Operation\n    - :math:`key` : 2D Convolution Operation\n    - :math:`value` : 2D Convolution Operation\n    - :math:`x` : Input\n\n    Args:\n        input_dims (int): The input channel dimension in the input ``x``.\n        output_dims (int, optional): The output channel dimension. If ``None`` the output\n            channel value is computed as ``input_dims // 8``. So if the ``input_dims`` is **less\n            than 8** then the layer will give an error.\n        return_attn (bool, optional): Set it to ``True`` if you want the attention values to be\n            returned.\n    """"""\n\n    def __init__(self, input_dims, output_dims=None, return_attn=False):\n        output_dims = input_dims // 8 if output_dims is None else output_dims\n        if output_dims == 0:\n            raise Exception(\n                ""The output dims corresponding to the input dims is 0. Increase the input\\\n                            dims to 8 or more. Else specify output_dims""\n            )\n        super(SelfAttention2d, self).__init__()\n        self.query = nn.Conv2d(input_dims, output_dims, 1)\n        self.key = nn.Conv2d(input_dims, output_dims, 1)\n        self.value = nn.Conv2d(input_dims, input_dims, 1)\n        self.gamma = nn.Parameter(torch.zeros(1))\n        self.return_attn = return_attn\n\n    def forward(self, x):\n        r""""""Computes the output of the Self Attention Layer\n\n        Args:\n            x (torch.Tensor): A 4D Tensor with the channel dimension same as ``input_dims``.\n\n        Returns:\n            A tuple of the ``output`` and the ``attention`` if ``return_attn`` is set to ``True``\n            else just the ``output`` tensor.\n        """"""\n        dims = (x.size(0), -1, x.size(2) * x.size(3))\n        out_query = self.query(x).view(dims)\n        out_key = self.key(x).view(dims).permute(0, 2, 1)\n        attn = F.softmax(torch.bmm(out_key, out_query), dim=-1)\n        out_value = self.value(x).view(dims)\n        out_value = torch.bmm(out_value, attn).view(x.size())\n        out = self.gamma * out_value + x\n        if self.return_attn:\n            return out, attn\n        return out\n'"
torchgan/layers/spectralnorm.py,8,"b'import torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\n\n__all__ = [""SpectralNorm2d""]\n\n# NOTE(avik-pal): This code has been adapted from\n#                 https://github.com/heykeetae/Self-Attention-GAN/blob/master/spectral.py\nclass SpectralNorm2d(nn.Module):\n    r""""""2D Spectral Norm Module as described in `""Spectral Normalization\n    for Generative Adversarial Networks by Miyato et. al."" <https://arxiv.org/abs/1802.05957>`_\n    The spectral norm is computed using ``power iterations``.\n\n    Computation Steps:\n\n    .. math:: v_{t + 1} = \\frac{W^T W v_t}{||W^T W v_t||} = \\frac{(W^T W)^t v}{||(W^T W)^t v||}\n    .. math:: u_{t + 1} = W v_t\n    .. math:: v_{t + 1} = W^T u_{t + 1}\n    .. math:: Norm(W) = ||W v|| = u^T W v\n    .. math:: Output = \\frac{W}{Norm(W)} = \\frac{W}{u^T W v}\n\n    Args:\n        module (torch.nn.Module): The Module on which the Spectral Normalization needs to be\n            applied.\n        name (str, optional): The attribute of the ``module`` on which normalization needs to\n            be performed.\n        power_iterations (int, optional): Total number of iterations for the norm to converge.\n            ``1`` is usually enough given the weights vary quite gradually.\n\n    Example:\n        .. code:: python\n\n            >>> layer = SpectralNorm2d(Conv2d(3, 16, 1))\n            >>> x = torch.rand(1, 3, 10, 10)\n            >>> layer(x)\n    """"""\n\n    def __init__(self, module, name=""weight"", power_iterations=1):\n        super(SpectralNorm2d, self).__init__()\n        self.module = module\n        self.name = name\n        self.power_iterations = power_iterations\n        w = getattr(self.module, self.name)\n        height = w.data.shape[0]\n        width = w.view(height, -1).data.shape[1]\n        self.u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n        self.v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n        self.u.data = self._l2normalize(self.u.data)\n        self.v.data = self._l2normalize(self.v.data)\n        self.w_bar = Parameter(w.data)\n        del self.module._parameters[self.name]\n\n    def _l2normalize(self, x, eps=1e-12):\n        r""""""Function to calculate the ``L2 Normalized`` form of a Tensor\n\n        Args:\n            x (torch.Tensor): Tensor which needs to be normalized.\n            eps (float, optional): A small value needed to avoid infinite values.\n\n        Returns:\n            Normalized form of the tensor ``x``.\n        """"""\n        return x / (torch.norm(x) + eps)\n\n    def forward(self, *args):\n        r""""""Computes the output of the ``module`` and appies spectral normalization to the\n        ``name`` attribute of the ``module``.\n\n        Returns:\n            The output of the ``module``.\n        """"""\n        height = self.w_bar.data.shape[0]\n        for _ in range(self.power_iterations):\n            self.v.data = self._l2normalize(\n                torch.mv(torch.t(self.w_bar.view(height, -1)), self.u)\n            )\n            self.u.data = self._l2normalize(\n                torch.mv(self.w_bar.view(height, -1), self.v)\n            )\n        sigma = self.u.dot(self.w_bar.view(height, -1).mv(self.v))\n        setattr(self.module, self.name, self.w_bar / sigma.expand_as(self.w_bar))\n        return self.module.forward(*args)\n'"
torchgan/layers/virtualbatchnorm.py,12,"b'import torch\nimport torch.nn as nn\n\n__all__ = [""VirtualBatchNorm""]\n\n\nclass VirtualBatchNorm(nn.Module):\n    r""""""Virtual Batch Normalization Module as proposed in the paper\n    `""Improved Techniques for Training GANs by Salimans et. al."" <https://arxiv.org/abs/1805.08318>`_\n\n    Performs Normalizes the features of a batch based on the statistics collected on a reference\n    batch of samples that are chosen once and fixed from the start, as opposed to regular\n    batch normalization that uses the statistics of the batch being normalized\n\n    Virtual Batch Normalization requires that the size of the batch being normalized is at least\n    a multiple of (and ideally equal to) the size of the reference batch. Keep this in mind while\n    choosing the batch size in ```torch.utils.data.DataLoader``` or use ```drop_last=True```\n\n    .. math:: y = \\frac{x - \\mathrm{E}[x_{ref}]}{\\sqrt{\\mathrm{Var}[x_{ref}] + \\epsilon}} * \\gamma + \\beta\n\n    where\n\n    - :math:`x` : Batch Being Normalized\n    - :math:`x_{ref}` : Reference Batch\n\n    Args:\n        in_features (int): Size of the input dimension to be normalized\n        eps (float, optional): Value to be added to variance for numerical stability while normalizing\n    """"""\n\n    def __init__(self, in_features, eps=1e-5):\n        super(VirtualBatchNorm, self).__init__()\n        self.in_features = in_features\n        self.scale = nn.Parameter(torch.ones(in_features))\n        self.bias = nn.Parameter(torch.zeros(in_features))\n        self.ref_mu = None\n        self.ref_var = None\n        self.eps = eps\n\n    def _batch_stats(self, x):\n        r""""""Computes the statistics of the batch ``x``.\n\n        Args:\n            x (torch.Tensor): Tensor whose statistics need to be computed.\n\n        Returns:\n            A tuple of the mean and variance of the batch ``x``.\n        """"""\n        mu = torch.mean(x, dim=0, keepdim=True)\n        var = torch.var(x, dim=0, keepdim=True)\n        return mu, var\n\n    def _normalize(self, x, mu, var):\n        r""""""Normalizes the tensor ``x`` using the statistics ``mu`` and ``var``.\n\n        Args:\n            x (torch.Tensor): The Tensor to be normalized.\n            mu (torch.Tensor): Mean using which the Tensor is to be normalized.\n            var (torch.Tensor): Variance used in the normalization of ``x``.\n\n        Returns:\n            Normalized Tensor ``x``.\n        """"""\n        std = torch.sqrt(self.eps + var)\n        x = (x - mu) / std\n        sizes = list(x.size())\n        for dim, i in enumerate(x.size()):\n            if dim != 1:\n                sizes[dim] = 1\n        scale = self.scale.view(*sizes)\n        bias = self.bias.view(*sizes)\n        return x * scale + bias\n\n    def forward(self, x):\n        r""""""Computes the output of the Virtual Batch Normalization\n\n        Args:\n            x (torch.Tensor): A Torch Tensor of dimension at least 2 which is to be Normalized\n\n        Returns:\n            Torch Tensor of the same dimension after normalizing with respect to the statistics of the reference batch\n        """"""\n        assert x.size(1) == self.in_features\n        if self.ref_mu is None or self.ref_var is None:\n            self.ref_mu, self.ref_var = self._batch_stats(x)\n            self.ref_mu = self.ref_mu.clone().detach()\n            self.ref_var = self.ref_var.clone().detach()\n            out = self._normalize(x, self.ref_mu, self.ref_var)\n        else:\n            out = self._normalize(x, self.ref_mu, self.ref_var)\n            self.ref_mu = None\n            self.ref_var = None\n        return out\n'"
torchgan/logging/__init__.py,0,b'from .logger import *\nfrom .visualize import *\n'
torchgan/logging/backends.py,0,"b'import os\nimport subprocess\n\nfrom ..utils import getenv_defaults\n\n# Backends available for Visualization\n\n# Tensorboard\nTENSORBOARD_LOGGING = int(\n    os.getenv(""TENSORBOARD_LOGGING"", getenv_defaults(""tensorboardX""))\n)\nif TENSORBOARD_LOGGING == 1 and getenv_defaults(""tensorboardX"") == 0:\n    raise Exception(\n        ""TensorboardX is not installed. Install it or set TENSORBOARD_LOGGING to 0""\n    )\n\n# Console\nCONSOLE_LOGGING = int(os.getenv(""CONSOLE_LOGGING"", 1))\n\n# Visdom\nVISDOM_LOGGING = int(os.getenv(""VISDOM_LOGGING"", getenv_defaults(""visdom"")))\nif VISDOM_LOGGING == 1:\n    if getenv_defaults(""visdom"") == 0:\n        raise Exception(\n            ""Visdom is not installed. Install it or set VISDOM_LOGGING to 0""\n        )\n'"
torchgan/logging/logger.py,1,"b'from .backends import *\nfrom .visualize import *\n\nif TENSORBOARD_LOGGING == 1:\n    from tensorboardX import SummaryWriter\nif VISDOM_LOGGING == 1:\n    import visdom\n\n__all__ = [""Logger""]\n\n\nclass Logger(object):\n    r""""""Base Logger class. It controls the executions of all the Visualizers and is deeply\n    integrated with the functioning of the Trainer.\n\n    .. note::\n        The ``Logger`` has been designed to be controlled internally by the ``Trainer``. It is\n        recommended that the user does not attempt to use it externally in any form.\n\n    .. warning::\n        This ``Logger`` is meant to work on the standard Visualizers available. Work is being\n        done to support custom Visualizers in a clean way. But currently it is not possible to\n        do so.\n\n    Args:\n        trainer (torchgan.trainer.Trainer): The base trainer used for training.\n        losses_list (list): A list of the Loss Functions that need to be minimized. For a list of\n            pre-defined losses look at :mod:`torchgan.losses`. All losses in the list must be a\n            subclass of atleast ``GeneratorLoss`` or ``DiscriminatorLoss``.\n        metrics_list (list, optional): List of Metric Functions that need to be logged. For a list of\n            pre-defined metrics look at :mod:`torchgan.metrics`. All losses in the list must be a\n            subclass of ``EvaluationMetric``.\n        visdom_port (int, optional): Port to log using ``visdom``. A deafult server is started\n            at port ``8097``. So manually a new server has to be started if the post is changed.\n            This is ignored if ``VISDOM_LOGGING`` is ``0``.\n        log_dir (str, optional): Directory where TensorboardX should store the logs. This is\n            ignored if ``TENSORBOARD_LOGGING`` is ``0``.\n        writer (tensorboardX.SummaryWriter, optonal): Send a `SummaryWriter` if you\n            don\'t want to start a new SummaryWriter.\n        test_noise (torch.Tensor, optional): If provided then it will be used as the noise for image\n            sampling.\n        nrow (int, optional): Number of rows in which the image is to be stored.\n    """"""\n\n    def __init__(\n        self,\n        trainer,\n        losses_list,\n        metrics_list=None,\n        visdom_port=8097,\n        log_dir=None,\n        writer=None,\n        nrow=8,\n        test_noise=None,\n    ):\n        if TENSORBOARD_LOGGING == 1:\n            self.writer = SummaryWriter(log_dir) if writer is None else writer\n        else:\n            self.writer = None\n        self.logger_end_epoch = []\n        self.logger_mid_epoch = []\n        self.logger_end_epoch.append(\n            ImageVisualize(\n                trainer, writer=self.writer, test_noise=test_noise, nrow=nrow\n            )\n        )\n        self.logger_mid_epoch.append(\n            GradientVisualize(trainer.model_names, writer=self.writer)\n        )\n        if metrics_list is not None:\n            self.logger_end_epoch.append(\n                MetricVisualize(metrics_list, writer=self.writer)\n            )\n        self.logger_mid_epoch.append(LossVisualize(losses_list, writer=self.writer))\n\n    def get_loss_viz(self):\n        r""""""Get the LossVisualize object.\n        """"""\n        return self.logger_mid_epoch[1]\n\n    def get_metric_viz(self):\n        r""""""Get the MetricVisualize object.\n        """"""\n        return self.logger_end_epoch[1]\n\n    def get_grad_viz(self):\n        r""""""Get the GradientVisualize object.\n        """"""\n        return self.logger_mid_epoch[0]\n\n    def register(self, visualize, *args, mid_epoch=True, **kwargs):\n        r""""""Register a new ``Visualize`` object with the Logger.\n\n        Args:\n            visualize (torchgan.logging.Visualize): Class name of the visualizer.\n            mid_epoch (bool, optional): Set it to ``False`` if it is to be executed once the epoch is\n                over. Otherwise it is executed after every call to the ``train_iter``.\n        """"""\n        if mid_epoch:\n            self.logger_mid_epoch.append(visualize(*args, writer=self.writer, **kwargs))\n        else:\n            self.logger_end_epoch.append(visualize(*args, writer=self.writer, **kwargs))\n\n    def close(self):\n        r""""""Turns off the tensorboard ``SummaryWriter`` if it were created.\n        """"""\n        if self.writer is not None:\n            self.writer.close()\n\n    def run_mid_epoch(self, trainer, *args):\n        r""""""Runs the Visualizers after every call to the ``train_iter``.\n\n        Args:\n            trainer (torchgan.trainer.Trainer): The base trainer used for training.\n        """"""\n        for logger in self.logger_mid_epoch:\n            if (\n                type(logger).__name__ == ""LossVisualize""\n                or type(logger).__name__ == ""GradientVisualize""\n            ):\n                logger(trainer, lock_console=True)\n            else:\n                logger(*args, lock_console=True)\n\n    def run_end_epoch(self, trainer, epoch, time_duration, *args):\n        r""""""Runs the Visualizers at the end of one epoch.\n\n        Args:\n            trainer (torchgan.trainer.Trainer): The base trainer used for training.\n            epoch (int): The epoch number which was completed.\n        """"""\n        print(""Epoch {} Summary"".format(epoch + 1))\n        print(""Epoch time duration : {}"".format(time_duration))\n        for logger in self.logger_mid_epoch:\n            if type(logger).__name__ == ""LossVisualize"":\n                logger(trainer)\n            elif type(logger).__name__ == ""GradientVisualize"":\n                logger.report_end_epoch()\n            else:\n                logger(*args)\n        for logger in self.logger_end_epoch:\n            if type(logger).__name__ == ""ImageVisualize"":\n                logger(trainer)\n            elif type(logger).__name__ == ""MetricVisualize"":\n                logger()\n            else:\n                logger(*args)\n        print()\n'"
torchgan/logging/visualize.py,4,"b'import torch\nimport torchvision\n\nfrom ..models.model import Discriminator, Generator\nfrom .backends import *\n\nif TENSORBOARD_LOGGING == 1:\n    from tensorboardX import SummaryWriter\nif VISDOM_LOGGING == 1:\n    import visdom\n\n__all__ = [\n    ""Visualize"",\n    ""LossVisualize"",\n    ""MetricVisualize"",\n    ""GradientVisualize"",\n    ""ImageVisualize"",\n]\n\n\nclass Visualize(object):\n    r""""""Base class for all Visualizations.\n\n    Args:\n        visualize_list (list, optional): List of the functions needed for visualization.\n        visdom_port (int, optional): Port to log using ``visdom``. The visdom server needs to be\n            manually started at this port else an error will be thrown and the code will crash.\n            This is ignored if ``VISDOM_LOGGING`` is ``0``.\n        log_dir (str, optional): Directory where TensorboardX should store the logs. This is\n            ignored if ``TENSORBOARD_LOGGING`` is ``0``.\n        writer (tensorboardX.SummaryWriter, optonal): Send a `SummaryWriter` if you\n            don\'t want to start a new SummaryWriter.\n    """"""\n\n    def __init__(self, visualize_list, visdom_port=8097, log_dir=None, writer=None):\n        self.logs = {}\n        for item in visualize_list:\n            name = type(item).__name__\n            self.logs[name] = []\n        self.step = 1\n        if TENSORBOARD_LOGGING == 1:\n            self._build_tensorboard(log_dir, writer)\n        if VISDOM_LOGGING == 1:\n            self._build_visdom(visdom_port)\n\n    def _build_tensorboard(self, log_dir, writer):\n        r""""""Starts the tensorboard logging utilities.\n\n        Args:\n            log_dir (str, optional): Directory where TensorboardX should store the logs.\n            writer (tensorboardX.SummaryWriter, optonal): Send a `SummaryWriter` if you\n                don\'t want to start a new SummaryWriter.\n        """"""\n        self.writer = SummaryWriter(log_dir) if writer is None else writer\n\n    def _build_visdom(self, port):\n        r""""""Starts the visdom logging utilities.\n\n        Args:\n            port (int, optional): Port to log using ``visdom``. A deafult server is started at port\n                ``8097``. So manually a new server has to be started if the post is changed.\n        """"""\n        self.vis = visdom.Visdom(port=port)\n\n    def step_update(self):\n        r""""""Helper function which updates the step at the end of\n        one print iteration.\n        """"""\n        self.step += 1\n\n    def log_tensorboard(self):\n        r""""""Tensorboard logging function. Needs to be defined in the subclass\n\n        :raises NotImplementedError:\n        """"""\n        raise NotImplementedError\n\n    def log_console(self):\n        r""""""Console logging function. Needs to be defined in the subclass\n\n        :raises NotImplementedError:\n        """"""\n        raise NotImplementedError\n\n    def log_visdom(self):\n        r""""""Visdom logging function. Needs to be defined in the subclass\n\n        :raises NotImplementedError:\n        """"""\n        raise NotImplementedError\n\n    def __call__(\n        self,\n        *args,\n        lock_console=False,\n        lock_tensorboard=False,\n        lock_visdom=False,\n        **kwargs\n    ):\n        if not lock_console and CONSOLE_LOGGING == 1:\n            self.log_console(*args, **kwargs)\n        if not lock_tensorboard and TENSORBOARD_LOGGING == 1:\n            self.log_tensorboard(*args, **kwargs)\n        if not lock_visdom and VISDOM_LOGGING == 1:\n            self.log_visdom(*args, **kwargs)\n        self.step_update()\n\n\nclass LossVisualize(Visualize):\n    r""""""This class provides the Visualizations for Generator and Discriminator Losses.\n\n    Args:\n        visualize_list (list, optional): List of the functions needed for visualization.\n        visdom_port (int, optional): Port to log using ``visdom``. The visdom server needs to be\n            manually started at this port else an error will be thrown and the code will crash.\n            This is ignored if ``VISDOM_LOGGING`` is ``0``.\n        log_dir (str, optional): Directory where TensorboardX should store the logs. This is\n            ignored if ``TENSORBOARD_LOGGING`` is ``0``.\n        writer (tensorboardX.SummaryWriter, optonal): Send a `SummaryWriter` if you\n            don\'t want to start a new SummaryWriter.\n    """"""\n\n    def log_tensorboard(self, running_losses):\n        r""""""Tensorboard logging function. This function logs the following:\n\n        - ``Running Discriminator Loss``\n        - ``Running Generator Loss``\n        - ``Running Losses``\n        - Loss Values of the individual Losses.\n\n        Args:\n            running_losses (dict): A dict with 2 items namely, ``Running Discriminator Loss``,\n                and ``Running Generator Loss``.\n        """"""\n        self.writer.add_scalar(\n            ""Running Discriminator Loss"",\n            running_losses[""Running Discriminator Loss""],\n            self.step,\n        )\n        self.writer.add_scalar(\n            ""Running Generator Loss"",\n            running_losses[""Running Generator Loss""],\n            self.step,\n        )\n        self.writer.add_scalars(""Running Losses"", running_losses, self.step)\n        for name, value in self.logs.items():\n            val = value[-1]\n            if type(val) is tuple:\n                self.writer.add_scalar(\n                    ""Losses/{}-Generator"".format(name), val[0], self.step\n                )\n                self.writer.add_scalar(\n                    ""Losses/{}-Discriminator"".format(name), val[1], self.step\n                )\n            else:\n                self.writer.add_scalar(""Losses/{}"".format(name), val, self.step)\n\n    def log_console(self, running_losses):\n        r""""""Console logging function. This function logs the mean ``generator`` and ``discriminator``\n        losses.\n\n        Args:\n            running_losses (dict): A dict with 2 items namely, ``Running Discriminator Loss``,\n                and ``Running Generator Loss``.\n        """"""\n        for name, val in running_losses.items():\n            print(""Mean {} : {}"".format(name, val))\n\n    def log_visdom(self, running_losses):\n        r""""""Visdom logging function. This function logs the following:\n\n        - ``Running Discriminator Loss``\n        - ``Running Generator Loss``\n        - ``Running Losses``\n        - Loss Values of the individual Losses.\n\n        Args:\n            running_losses (dict): A dict with 2 items namely, ``Running Discriminator Loss``,\n                and ``Running Generator Loss``.\n        """"""\n        self.vis.line(\n            [running_losses[""Running Discriminator Loss""]],\n            [self.step],\n            win=""Running Discriminator Loss"",\n            update=""append"",\n            opts=dict(\n                title=""Running Discriminator Loss"",\n                xlabel=""Time Step"",\n                ylabel=""Running Loss"",\n            ),\n        )\n        self.vis.line(\n            [running_losses[""Running Generator Loss""]],\n            [self.step],\n            win=""Running Generator Loss"",\n            update=""append"",\n            opts=dict(\n                title=""Running Generator Loss"",\n                xlabel=""Time Step"",\n                ylabel=""Running Loss"",\n            ),\n        )\n        self.vis.line(\n            [\n                [\n                    running_losses[""Running Discriminator Loss""],\n                    running_losses[""Running Generator Loss""],\n                ]\n            ],\n            [self.step],\n            win=""Running Losses"",\n            update=""append"",\n            opts=dict(\n                title=""Running Losses"",\n                xlabel=""Time Step"",\n                ylabel=""Running Loss"",\n                legend=[""Discriminator"", ""Generator""],\n            ),\n        )\n        for name, value in self.logs.items():\n            val = value[-1]\n            if type(val) is tuple:\n                name1 = ""{}-Generator"".format(name)\n                name2 = ""{}-Discriminator"".format(name)\n                self.vis.line(\n                    [val[0]],\n                    [self.step],\n                    win=name1,\n                    update=""append"",\n                    opts=dict(title=name1, xlabel=""Time Step"", ylabel=""Loss Value""),\n                )\n                self.vis.line(\n                    [val[1]],\n                    [self.step],\n                    win=name2,\n                    update=""append"",\n                    opts=dict(title=name2, xlabel=""Time Step"", ylabel=""Loss Value""),\n                )\n            else:\n                self.vis.line(\n                    [val],\n                    [self.step],\n                    win=name,\n                    update=""append"",\n                    opts=dict(title=name, xlabel=""Time Step"", ylabel=""Loss Value""),\n                )\n\n    def __call__(self, trainer, **kwargs):\n        running_generator_loss = (\n            trainer.loss_information[""generator_losses""]\n            / trainer.loss_information[""generator_iters""]\n        )\n        running_discriminator_loss = (\n            trainer.loss_information[""discriminator_losses""]\n            / trainer.loss_information[""discriminator_iters""]\n        )\n        running_losses = {\n            ""Running Discriminator Loss"": running_discriminator_loss,\n            ""Running Generator Loss"": running_generator_loss,\n        }\n        super(LossVisualize, self).__call__(running_losses, **kwargs)\n\n\nclass MetricVisualize(Visualize):\n    r""""""This class provides the Visualizations for Metrics.\n\n    Args:\n        visualize_list (list, optional): List of the functions needed for visualization.\n        visdom_port (int, optional): Port to log using ``visdom``. The visdom server needs to be\n            manually started at this port else an error will be thrown and the code will crash.\n            This is ignored if ``VISDOM_LOGGING`` is ``0``.\n        log_dir (str, optional): Directory where TensorboardX should store the logs. This is\n            ignored if ``TENSORBOARD_LOGGING`` is ``0``.\n        writer (tensorboardX.SummaryWriter, optonal): Send a `SummaryWriter` if you\n            don\'t want to start a new SummaryWriter.\n    """"""\n\n    def log_tensorboard(self):\n        r""""""Tensorboard logging function. This function logs the values of the individual metrics.\n        """"""\n        for name, value in self.logs.items():\n            self.writer.add_scalar(""Metrics/{}"".format(name), value[-1], self.step)\n\n    def log_console(self):\n        r""""""Console logging function. This function logs the mean metrics.\n        """"""\n        for name, val in self.logs.items():\n            print(""{} : {}"".format(name, val[-1]))\n\n    def log_visdom(self):\n        r""""""Visdom logging function. This function logs the values of the individual metrics.\n        """"""\n        for name, value in self.logs.items():\n            self.vis.line(\n                [value[-1]],\n                [self.step],\n                win=name,\n                update=""append"",\n                opts=dict(title=name, xlabel=""Time Step"", ylabel=""Metric Value""),\n            )\n\n\nclass GradientVisualize(Visualize):\n    r""""""This class provides the Visualizations for the Gradients.\n\n    Args:\n        visualize_list (list, optional): List of the functions needed for visualization.\n        visdom_port (int, optional): Port to log using ``visdom``. The visdom server needs to be\n            manually started at this port else an error will be thrown and the code will crash.\n            This is ignored if ``VISDOM_LOGGING`` is ``0``.\n        log_dir (str, optional): Directory where TensorboardX should store the logs. This is\n            ignored if ``TENSORBOARD_LOGGING`` is ``0``.\n        writer (tensorboardX.SummaryWriter, optonal): Send a `SummaryWriter` if you\n            don\'t want to start a new SummaryWriter.\n    """"""\n\n    def __init__(self, visualize_list, visdom_port=8097, log_dir=None, writer=None):\n        if visualize_list is None or len(visualize_list) == 0:\n            raise Exception(""Gradient Visualizer requires list of model names"")\n        self.logs = {}\n        for item in visualize_list:\n            self.logs[item] = [0.0]\n        self.step = 1\n        if TENSORBOARD_LOGGING == 1:\n            self._build_tensorboard(log_dir, writer)\n        if VISDOM_LOGGING == 1:\n            self._build_visdom(visdom_port)\n\n    def log_tensorboard(self, name):\n        r""""""Tensorboard logging function. This function logs the values of the individual gradients.\n\n        Args:\n            name (str): Name of the model whose gradients are to be logged.\n        """"""\n        self.writer.add_scalar(\n            ""Gradients/{}"".format(name),\n            self.logs[name][len(self.logs[name]) - 1],\n            self.step,\n        )\n\n    def log_console(self, name):\n        r""""""Console logging function. This function logs the mean gradients.\n\n        Args:\n            name (str): Name of the model whose gradients are to be logged.\n        """"""\n        print(\n            ""{} Gradients : {}"".format(name, self.logs[name][len(self.logs[name]) - 1])\n        )\n\n    def log_visdom(self, name):\n        r""""""Visdom logging function. This function logs the values of the individual gradients.\n\n        Args:\n            name (str): Name of the model whose gradients are to be logged.\n        """"""\n        self.vis.line(\n            [self.logs[name][len(self.logs[name]) - 1]],\n            [self.step],\n            win=name,\n            update=""append"",\n            opts=dict(title=name, xlabel=""Time Step"", ylabel=""Gradient""),\n        )\n\n    def update_grads(self, name, model, eps=1e-5):\n        r""""""Updates the gradient logs.\n\n        Args:\n            name (str): Name of the model.\n            model (torch.nn.Module): Either a ``torchgan.models.Generator`` or a\n                ``torchgan.models.Discriminator`` or their subclass.\n            eps (float, optional): Tolerance value.\n        """"""\n        gradsum = 0.0\n        for p in model.parameters():\n            if p.grad is not None:\n                gradsum += torch.sum(p.grad ** 2).clone().item()\n        if gradsum > eps:\n            self.logs[name][len(self.logs[name]) - 1] += gradsum\n            model.zero_grad()\n\n    def report_end_epoch(self):\n        r""""""Prints to the console at the end of the epoch.\n        """"""\n        if CONSOLE_LOGGING == 1:\n            for key, val in self.logs.items():\n                print(""{} Mean Gradients : {}"".format(key, sum(val) / len(val)))\n\n    def __call__(self, trainer, **kwargs):\n        for name in trainer.model_names:\n            super(GradientVisualize, self).__call__(name, **kwargs)\n            self.logs[name].append(0.0)\n\n\nclass ImageVisualize(Visualize):\n    r""""""This class provides the Logging for the Images.\n\n    Args:\n        trainer (torchgan.trainer.Trainer): The base trainer used for training.\n        visdom_port (int, optional): Port to log using ``visdom``. The visdom server needs to be\n            manually started at this port else an error will be thrown and the code will crash.\n            This is ignored if ``VISDOM_LOGGING`` is ``0``.\n        log_dir (str, optional): Directory where TensorboardX should store the logs. This is\n            ignored if ``TENSORBOARD_LOGGING`` is ``0``.\n        writer (tensorboardX.SummaryWriter, optonal): Send a `SummaryWriter` if you\n            don\'t want to start a new SummaryWriter.\n        test_noise (torch.Tensor, optional): If provided then it will be used as the noise for image\n            sampling.\n        nrow (int, optional): Number of rows in which the image is to be stored.\n    """"""\n\n    def __init__(\n        self,\n        trainer,\n        visdom_port=8097,\n        log_dir=None,\n        writer=None,\n        test_noise=None,\n        nrow=8,\n    ):\n        super(ImageVisualize, self).__init__(\n            [], visdom_port=visdom_port, log_dir=log_dir, writer=writer\n        )\n        self.test_noise = []\n        for model in trainer.model_names:\n            if isinstance(getattr(trainer, model), Generator):\n                self.test_noise.append(\n                    getattr(trainer, model).sampler(trainer.sample_size, trainer.device)\n                    if test_noise is None\n                    else test_noise\n                )\n        self.step = 1\n        self.nrow = nrow\n\n    def log_tensorboard(self, trainer, image, model):\n        r""""""Logs a generated image in tensorboard at the end of an epoch.\n\n        Args:\n            trainer (torchgan.trainer.Trainer): The base trainer used for training.\n            image (Image): The generated image.\n            model (str): The name of the model which generated the ``image``.\n        """"""\n        self.writer.add_image(""Generated Samples/{}"".format(model), image, self.step)\n\n    def log_console(self, trainer, image, model):\n        r""""""Saves a generated image at the end of an epoch. The path where the image is\n        being stored is controlled by the ``trainer``.\n\n        Args:\n            trainer (torchgan.trainer.Trainer): The base trainer used for training.\n            image (Image): The generated image.\n            model (str): The name of the model which generated the ``image``.\n        """"""\n        save_path = ""{}/epoch{}_{}.png"".format(trainer.recon, self.step, model)\n        print(""Generating and Saving Images to {}"".format(save_path))\n        torchvision.utils.save_image(image, save_path)\n\n    def log_visdom(self, trainer, image, model):\n        r""""""Logs a generated image in visdom at the end of an epoch.\n\n        Args:\n            trainer (torchgan.trainer.Trainer): The base trainer used for training.\n            image (Image): The generated image.\n            model (str): The name of the model which generated the ``image``.\n        """"""\n        self.vis.image(image, opts=dict(caption=""Generated Samples/{}"".format(model)))\n\n    def __call__(self, trainer, **kwargs):\n        pos = 0\n        for model in trainer.model_names:\n            if isinstance(getattr(trainer, model), Generator):\n                generator = getattr(trainer, model)\n                with torch.no_grad():\n                    image = generator(*self.test_noise[pos])\n                    image = torchvision.utils.make_grid(\n                        image, nrow=self.nrow, normalize=True, range=(-1, 1)\n                    )\n                    super(ImageVisualize, self).__call__(\n                        trainer, image, model, **kwargs\n                    )\n                self.step -= 1\n                pos = pos + 1\n        self.step += 1 if pos > 0 else 0\n'"
torchgan/losses/__init__.py,0,b'from .auxclassifier import *\nfrom .boundaryequilibrium import *\nfrom .draganpenalty import *\nfrom .energybased import *\nfrom .featurematching import *\nfrom .functional import *\nfrom .historical import *\nfrom .leastsquares import *\nfrom .loss import *\nfrom .minimax import *\nfrom .mutualinfo import *\nfrom .wasserstein import *\n'
torchgan/losses/auxclassifier.py,14,"b'import torch\n\nfrom .functional import auxiliary_classification_loss\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [""AuxiliaryClassifierGeneratorLoss"", ""AuxiliaryClassifierDiscriminatorLoss""]\n\n\nclass AuxiliaryClassifierGeneratorLoss(GeneratorLoss):\n    r""""""Auxiliary Classifier GAN (ACGAN) loss based on a from\n    `""Conditional Image Synthesis With Auxiliary Classifier GANs\n    by Odena et. al. "" <https://arxiv.org/abs/1610.09585>`_ paper\n\n    Args:\n       reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def forward(self, logits, labels):\n        return auxiliary_classification_loss(logits, labels, self.reduction)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_generator,\n        device,\n        batch_size,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used by the Auxiliary Classifier generator loss.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows (label_g and label_d both could be either real labels or generated labels):\n\n        1. :math:`fake = generator(noise, label_g)`\n        2. :math:`value_1 = classifier(fake, label_g)`\n        3. :math:`value_2 = classifier(real, label_d)`\n        4. :math:`loss = loss\\_function(value_1, label_g) + loss\\_function(value_2, label_d)`\n        5. Backpropagate by computing :math:`\\nabla loss`\n        6. Run a step of the optimizer for discriminator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized. For ACGAN, it must require\n                                                   labels for training\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_discriminator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``discriminator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            batch_size (int): Batch Size of the data infered from the ``DataLoader`` by the ``Trainer``.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                generator,\n                discriminator,\n                optimizer_generator,\n                device,\n                batch_size,\n                labels,\n            )\n        if generator.label_type == ""required"" and labels is None:\n            raise Exception(""GAN model requires label for training"")\n        noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n        optimizer_generator.zero_grad()\n        if generator.label_type == ""none"":\n            raise Exception(""Incorrect Model: ACGAN generator must require labels"")\n        if generator.label_type == ""required"":\n            fake = generator(noise, labels)\n        elif generator.label_type == ""generated"":\n            label_gen = torch.randint(\n                0, generator.num_classes, (batch_size,), device=device\n            )\n            fake = generator(noise, label_gen)\n        cgz = discriminator(fake, mode=""classifier"")\n        if generator.label_type == ""required"":\n            loss = self.forward(cgz, labels)\n        else:\n            label_gen = label_gen.type(torch.LongTensor).to(device)\n            loss = self.forward(cgz, label_gen)\n        loss.backward()\n        optimizer_generator.step()\n        return loss.item()\n\n\nclass AuxiliaryClassifierDiscriminatorLoss(DiscriminatorLoss):\n    r""""""Auxiliary Classifier GAN (ACGAN) loss based on a from\n    `""Conditional Image Synthesis With Auxiliary Classifier GANs\n    by Odena et. al. "" <https://arxiv.org/abs/1610.09585>`_ paper\n\n    Args:\n       reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n       override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def forward(self, logits, labels):\n        return auxiliary_classification_loss(logits, labels, self.reduction)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_discriminator,\n        real_inputs,\n        device,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used by the Auxiliary Classifier discriminator loss.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows (label_g and label_d both could be either real labels or generated labels):\n\n        1. :math:`fake = generator(noise, label_g)`\n        2. :math:`value_1 = classifier(fake, label_g)`\n        3. :math:`value_2 = classifier(real, label_d)`\n        4. :math:`loss = loss\\_function(value_1, label_g) + loss\\_function(value_2, label_d)`\n        5. Backpropagate by computing :math:`\\nabla loss`\n        6. Run a step of the optimizer for discriminator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized. For ACGAN, it must require labels\n                                                   for training\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_discriminator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``discriminator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            batch_size (int): Batch Size of the data infered from the ``DataLoader`` by the ``Trainer``.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                device,\n                labels,\n            )\n        if labels is None:\n            raise Exception(""ACGAN Discriminator requires labels for training"")\n        if generator.label_type == ""none"":\n            raise Exception(\n                ""Incorrect Model: ACGAN generator must require labels for training""\n            )\n        batch_size = real_inputs.size(0)\n        noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n        optimizer_discriminator.zero_grad()\n        cx = discriminator(real_inputs, mode=""classifier"")\n        if generator.label_type == ""required"":\n            fake = generator(noise, labels)\n        elif generator.label_type == ""generated"":\n            label_gen = torch.randint(\n                0, generator.num_classes, (batch_size,), device=device\n            )\n            fake = generator(noise, label_gen)\n        cgz = discriminator(fake, mode=""classifier"")\n        if generator.label_type == ""required"":\n            loss = self.forward(cgz, labels) + self.forward(cx, labels)\n        else:\n            label_gen = label_gen.type(torch.LongTensor).to(device)\n            loss = self.forward(cgz, label_gen) + self.forward(cx, labels)\n        loss.backward()\n        optimizer_discriminator.step()\n        return loss.item()\n'"
torchgan/losses/boundaryequilibrium.py,9,"b'import torch\n\nfrom .functional import (\n    boundary_equilibrium_discriminator_loss,\n    boundary_equilibrium_generator_loss,\n)\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [""BoundaryEquilibriumGeneratorLoss"", ""BoundaryEquilibriumDiscriminatorLoss""]\n\n\nclass BoundaryEquilibriumGeneratorLoss(GeneratorLoss):\n    r""""""Boundary Equilibrium GAN generator loss from\n    `""BEGAN : Boundary Equilibrium Generative Adversarial Networks\n    by Berthelot et. al."" <https://arxiv.org/abs/1703.10717>`_ paper\n\n    The loss can be described as\n\n    .. math:: L(G) = D(G(z))\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Discriminator\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n    """"""\n\n    def forward(self, dgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return boundary_equilibrium_generator_loss(dgz, self.reduction)\n\n\nclass BoundaryEquilibriumDiscriminatorLoss(DiscriminatorLoss):\n    r""""""Boundary Equilibrium GAN discriminator loss from\n    `""BEGAN : Boundary Equilibrium Generative Adversarial Networks\n    by Berthelot et. al."" <https://arxiv.org/abs/1703.10717>`_ paper\n\n    The loss can be described as\n\n    .. math:: L(D) = D(x) - k_t \\times D(G(z))\n\n    .. math:: k_{t+1} = k_t + \\lambda \\times (\\gamma \\times D(x) - D(G(z)))\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Discriminator\n    - :math:`k_t` : Running average of the balance point of G and D\n    - :math:`\\lambda` : Learning rate of the running average\n    - :math:`\\gamma` : Goal bias hyperparameter\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): Function to be used in place ofthe default ``train_ops``\n        init_k (float, optional): Initial value of the balance point ``k``.\n        lambd (float, optional): Learning rate of the running average.\n        gamma (float, optional): Goal bias hyperparameter.\n    """"""\n\n    def __init__(\n        self,\n        reduction=""mean"",\n        override_train_ops=None,\n        init_k=0.0,\n        lambd=0.001,\n        gamma=0.75,\n    ):\n        super(BoundaryEquilibriumDiscriminatorLoss, self).__init__(\n            reduction, override_train_ops\n        )\n        self.reduction = reduction\n        self.override_train_ops = override_train_ops\n        self.k = init_k\n        self.lambd = lambd\n        self.gamma = gamma\n        # TODO(Aniket1998): Integrate this with the metrics API in a later release\n        self.convergence_metric = None\n\n    def forward(self, dx, dgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dx (torch.Tensor) : Output of the Discriminator with real data. It must have the\n                                dimensions (N, \\*) where \\* means any number of additional\n                                dimensions.\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            A tuple of 3 loss values, namely the ``total loss``, ``loss due to real data`` and ``loss\n            due to fake data``.\n        """"""\n        return boundary_equilibrium_discriminator_loss(dx, dgz, self.k, self.reduction)\n\n    def set_k(self, k=0.0):\n        r""""""Change the default value of k\n\n        Args:\n            k (float, optional) : New value to be set.\n        """"""\n        self.k = k\n\n    def update_k(self, loss_real, loss_fake):\n        r""""""Update the running mean of k for each forward pass.\n\n        The update takes place as\n\n        .. math:: k_{t+1} = k_t + \\lambda \\times (\\gamma \\times D(x) - D(G(z)))\n\n        Args:\n            loss_real (float): :math:`D(x)`\n            loss_fake (float): :math:`D(G(z))`\n        """"""\n        diff = self.gamma * loss_real - loss_fake\n        self.k += self.lambd * diff\n        # TODO(Aniket1998): Develop this into a proper TorchGAN convergence metric\n        self.convergence_metric = loss_real + abs(diff)\n        self.k = max(min(self.k, 1.0), 0.0)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_discriminator,\n        real_inputs,\n        device,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used by boundary equilibrium loss.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows:\n\n        1. :math:`fake = generator(noise)`\n        2. :math:`value_1 = discriminator(fake)`\n        3. :math:`value_2 = discriminator(real)`\n        4. :math:`loss = loss\\_function(value_1, value_2)`\n        5. Backpropagate by computing :math:`\\nabla loss`\n        6. Run a step of the optimizer for discriminator\n        7. Update the value of :math: `k`.\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_discriminator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``discriminator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                self,\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                device,\n                labels,\n            )\n        else:\n            if labels is None and (\n                generator.label_type == ""required""\n                or discriminator.label_type == ""required""\n            ):\n                raise Exception(""GAN model requires labels for training"")\n            batch_size = real_inputs.size(0)\n            noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n            if generator.label_type == ""generated"":\n                label_gen = torch.randint(\n                    0, generator.num_classes, (batch_size,), device=device\n                )\n            optimizer_discriminator.zero_grad()\n            if discriminator.label_type == ""none"":\n                dx = discriminator(real_inputs)\n            elif discriminator.label_type == ""required"":\n                dx = discriminator(real_inputs, labels)\n            else:\n                dx = discriminator(real_inputs, label_gen)\n            if generator.label_type == ""none"":\n                fake = generator(noise)\n            elif generator.label_type == ""required"":\n                fake = generator(noise, labels)\n            else:\n                fake = generator(noise, label_gen)\n            if discriminator.label_type == ""none"":\n                dgz = discriminator(fake.detach())\n            else:\n                if generator.label_type == ""generated"":\n                    dgz = discriminator(fake.detach(), label_gen)\n                else:\n                    dgz = discriminator(fake.detach(), labels)\n            loss_total, loss_real, loss_fake = self.forward(dx, dgz)\n            loss_total.backward()\n            optimizer_discriminator.step()\n            self.update_k(loss_real.item(), loss_fake.item())\n            return loss_total.item()\n'"
torchgan/losses/draganpenalty.py,9,"b'import torch\n\nfrom .functional import dragan_gradient_penalty\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [""DraganGradientPenalty""]\n\n\nclass DraganGradientPenalty(DiscriminatorLoss):\n    r""""""Gradient Penalty for the DRAGAN discriminator from `""On Convergence and Stability of GANs\n    by Kodali et. al."" <https://arxiv.org/abs/1705.07215>`_ paper\n\n    The gradient penalty is calculated as:\n\n    .. math:: \\lambda \\times (||grad(D(x))||_2 - k)^2\n\n    The gradient being taken with respect to x\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Disrciminator\n    - :math:`\\lambda` : Scaling hyperparameter\n    - :math:`x` : Interpolation term for the gradient penalty\n    - :math:`k` : Constant\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        lambd (float,optional) : Hyperparameter :math:`\\lambda` for scaling the gradient penalty.\n        k (float, optional) : Constant.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n    """"""\n\n    def __init__(self, reduction=""mean"", lambd=10.0, k=1.0, override_train_ops=None):\n        super(DraganGradientPenalty, self).__init__(reduction)\n        self.lambd = lambd\n        self.override_train_ops = override_train_ops\n        self.k = k\n\n    def forward(self, interpolate, d_interpolate):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            interpolate (torch.Tensor) : It must have the dimensions (N, \\*) where\n                                         \\* means any number of additional dimensions.\n            d_interpolate (torch.Tensor) : Output of the ``discriminator`` with ``interpolate``\n                                           as the input. It must have the dimensions (N, \\*)\n                                           where \\* means any number of additional dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return dragan_gradient_penalty(\n            interpolate, d_interpolate, self.k, self.reduction\n        )\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_discriminator,\n        real_inputs,\n        device,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used by the DRAGAN Gradient Penalty.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows:\n\n        1. :math:`interpolate = real + \\frac{1}{2} \\times (1 - \\alpha) \\times std(real) \\times \\beta`\n        2. :math:`d\\_interpolate = discriminator(interpolate)`\n        3. :math:`loss = loss\\_function(interpolate, d\\_interpolate)`\n        4. Backpropagate by computing :math:`\\nabla loss`\n        5. Run a step of the optimizer for discriminator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_discriminator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``discriminator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                self,\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                labels,\n            )\n        else:\n            # NOTE(avik-pal): We don\'t need the gradients for alpha and beta. It\'s there\n            #                 to prevent an error while calling autograd.grad\n            alpha = torch.rand(\n                size=real_inputs.shape, device=device, requires_grad=True\n            )\n            beta = torch.rand(size=real_inputs.shape, device=device, requires_grad=True)\n            optimizer_discriminator.zero_grad()\n            interpolate = real_inputs + (1 - alpha) * 0.5 * real_inputs.std() * beta\n            if generator.label_type == ""generated"":\n                label_gen = torch.randint(\n                    0, generator.num_classes, (real_inputs.size(0),), device=device\n                )\n            if discriminator.label_type == ""none"":\n                d_interpolate = discriminator(interpolate)\n            else:\n                if generator.label_type == ""generated"":\n                    d_interpolate = discriminator(interpolate, label_gen)\n                else:\n                    d_interpolate = discriminator(interpolate, labels)\n            loss = self.forward(interpolate, d_interpolate)\n            weighted_loss = self.lambd * loss\n            weighted_loss.backward()\n            optimizer_discriminator.step()\n            return loss.item()\n'"
torchgan/losses/energybased.py,16,"b'import torch\n\nfrom ..models import AutoEncodingDiscriminator\nfrom .functional import (\n    energy_based_discriminator_loss,\n    energy_based_generator_loss,\n    energy_based_pulling_away_term,\n)\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [\n    ""EnergyBasedGeneratorLoss"",\n    ""EnergyBasedDiscriminatorLoss"",\n    ""EnergyBasedPullingAwayTerm"",\n]\n\n\nclass EnergyBasedGeneratorLoss(GeneratorLoss):\n    r""""""Energy Based GAN generator loss from `""Energy Based Generative Adversarial Network\n    by Zhao et. al."" <https://arxiv.org/abs/1609.03126>`_ paper.\n\n    The loss can be described as:\n\n    .. math:: L(G) = D(G(z))\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Discriminator\n    - :math:`z` : A sample from the noise prior\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def forward(self, dgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dgz (torch.Tensor): Output of the Discriminator with generated data. It must have the\n                                dimensions (N, \\*) where \\* means any number of additional\n                                dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return energy_based_generator_loss(dgz, self.reduction)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_generator,\n        device,\n        batch_size,\n        labels=None,\n    ):\n        r""""""This function sets the ``embeddings`` attribute of the ``AutoEncodingDiscriminator`` to\n        ``False`` and calls the ``train_ops`` of the ``GeneratorLoss``. After the call the\n        attribute is again set to ``True``.\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_generator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``generator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            batch_size (int): Batch Size of the data infered from the ``DataLoader`` by the ``Trainer``.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                generator,\n                discriminator,\n                optimizer_generator,\n                device,\n                batch_size,\n                labels,\n            )\n        else:\n            if isinstance(discriminator, AutoEncodingDiscriminator):\n                setattr(discriminator, ""embeddings"", False)\n            loss = super(EnergyBasedGeneratorLoss, self).train_ops(\n                generator,\n                discriminator,\n                optimizer_generator,\n                device,\n                batch_size,\n                labels,\n            )\n            if isinstance(discriminator, AutoEncodingDiscriminator):\n                setattr(discriminator, ""embeddings"", True)\n            return loss\n\n\nclass EnergyBasedPullingAwayTerm(GeneratorLoss):\n    r""""""Energy Based Pulling Away Term from `""Energy Based Generative Adversarial Network\n    by Zhao et. al."" <https://arxiv.org/abs/1609.03126>`_ paper.\n\n    The loss can be described as:\n\n    .. math:: f_{PT}(S) = \\frac{1}{N(N-1)}\\sum_i\\sum_{j \\neq i}\\bigg(\\frac{S_i^T S_j}{||S_i||\\ ||S_j||}\\bigg)^2\n\n    where\n\n    - :math:`S` : The feature output from the encoder for generated images\n    - :math:`N` : Batch Size of the Input\n\n    Args:\n        pt_ratio (float, optional): The weight given to the pulling away term.\n        override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def __init__(self, pt_ratio=0.1, override_train_ops=None):\n        super(EnergyBasedPullingAwayTerm, self).__init__(""mean"", override_train_ops)\n        self.pt_ratio = pt_ratio\n\n    def forward(self, dgz, d_hid):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n            d_hid (torch.Tensor): The embeddings generated by the discriminator.\n\n        Returns:\n            scalar.\n        """"""\n        return self.pt_ratio * energy_based_pulling_away_term(d_hid)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_generator,\n        device,\n        batch_size,\n        labels=None,\n    ):\n        r""""""This function extracts the hidden embeddings of the discriminator network. The furthur\n        computation is same as the standard train_ops.\n\n        .. note::\n            For the loss to work properly, the discriminator must be a ``AutoEncodingDiscriminator``\n            and it must have a ``embeddings`` attribute which should be set to ``True``. Also the\n            generator ``label_type`` must be ``none``. As a result of these constraints it advisable\n            not to use custom models with this loss. This will be improved in future.\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_generator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``generator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            batch_size (int): Batch Size of the data infered from the ``DataLoader`` by the ``Trainer``.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                generator,\n                discriminator,\n                optimizer_generator,\n                device,\n                batch_size,\n                labels,\n            )\n        else:\n            if not isinstance(discriminator, AutoEncodingDiscriminator):\n                raise Exception(\n                    ""EBGAN PT requires the Discriminator to be a AutoEncoder""\n                )\n            if not generator.label_type == ""none"":\n                raise Exception(""EBGAN PT supports models which donot require labels"")\n            if not discriminator.embeddings:\n                raise Exception(""EBGAN PT requires the embeddings for loss computation"")\n            noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n            optimizer_generator.zero_grad()\n            fake = generator(noise)\n            d_hid, dgz = discriminator(fake)\n            loss = self.forward(dgz, d_hid)\n            loss.backward()\n            optimizer_generator.step()\n            return loss.item()\n\n\nclass EnergyBasedDiscriminatorLoss(DiscriminatorLoss):\n    r""""""Energy Based GAN generator loss from `""Energy Based Generative Adversarial Network\n    by Zhao et. al."" <https://arxiv.org/abs/1609.03126>`_ paper\n\n    The loss can be described as:\n\n    .. math:: L(D) = D(x) + max(0, m - D(G(z)))\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Discriminator\n    - :math:`m` : Margin Hyperparameter\n    - :math:`z` : A sample from the noise prior\n\n    .. note::\n        The convergence of EBGAN is highly sensitive to hyperparameters. The ``margin``\n        hyperparameter as per the paper was taken as follows:\n\n        +----------------------+--------+\n        | Dataset              | Margin |\n        +======================+========+\n        | MNIST                | 10.0   |\n        +----------------------+--------+\n        | LSUN                 | 80.0   |\n        +----------------------+--------+\n        | CELEB A              | 20.0   |\n        +----------------------+--------+\n        | Imagenet (128 x 128) | 40.0   |\n        +----------------------+--------+\n        | Imagenet (256 x 256) | 80.0   |\n        +----------------------+--------+\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        margin (float, optional): The margin hyperparameter.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n    """"""\n\n    def __init__(self, reduction=""mean"", margin=80.0, override_train_ops=None):\n        super(EnergyBasedDiscriminatorLoss, self).__init__(\n            reduction, override_train_ops\n        )\n        self.margin = margin\n\n    def forward(self, dx, dgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dx (torch.Tensor): Output of the Discriminator with real data. It must have the\n                               dimensions (N, \\*) where \\* means any number of additional\n                               dimensions.\n            dgz (torch.Tensor): Output of the Discriminator with generated data. It must have the\n                                dimensions (N, \\*) where \\* means any number of additional\n                                dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return energy_based_discriminator_loss(dx, dgz, self.margin, self.reduction)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_discriminator,\n        real_inputs,\n        device,\n        batch_size,\n        labels=None,\n    ):\n        r""""""This function sets the ``embeddings`` attribute of the ``AutoEncodingDiscriminator`` to\n        ``False`` and calls the ``train_ops`` of the ``DiscriminatorLoss``. After the call the\n        attribute is again set to ``True``.\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_discriminator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``discriminator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            batch_size (int): Batch Size of the data infered from the ``DataLoader`` by the ``Trainer``.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                self,\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                device,\n                labels,\n            )\n        else:\n            if isinstance(discriminator, AutoEncodingDiscriminator):\n                setattr(discriminator, ""embeddings"", False)\n            loss = super(EnergyBasedDiscriminatorLoss, self).train_ops(\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                device,\n                labels,\n            )\n            if isinstance(discriminator, AutoEncodingDiscriminator):\n                setattr(discriminator, ""embeddings"", True)\n            return loss\n'"
torchgan/losses/featurematching.py,9,"b'import torch\nimport torch.nn.functional as F\n\nfrom ..utils import reduce\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [""FeatureMatchingGeneratorLoss""]\n\n\nclass FeatureMatchingGeneratorLoss(GeneratorLoss):\n    r""""""Feature Matching Generator loss from\n    `""Improved Training of GANs by Salimans et. al."" <https://arxiv.org/abs/1606.03498>`_ paper\n\n    The loss can be described as:\n\n    .. math:: L(G) = ||f(x)-f(G(z))||_2\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`f` : An intermediate activation from the discriminator\n    - :math:`z` : A sample from the noise prior\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n    """"""\n\n    def forward(self, fx, fgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dx (torch.Tensor) : Output of the Discriminator with real data. It must have the\n                                dimensions (N, \\*) where \\* means any number of additional\n                                dimensions.\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return F.mse_loss(fgz, fx, reduction=self.reduction)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_generator,\n        real_inputs,\n        device,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used for feature matching.\n\n        The ``standard optimization algorithm`` for the ``generator`` defined in this train_ops\n        is as follows:\n\n        1. :math:`fake = generator(noise)`\n        2. :math:`value_1 = discriminator(fake)` where :math:`value_1` is an activation of an intermediate\n                                                 discriminator layer\n        3. :math:`value_2 = discriminator(real)` where :math:`value_2` is an activation of the same intermediate\n                                                 discriminator layer\n        4. :math:`loss = loss\\_function(value_1, value_2)`\n        5. Backpropagate by computing :math:`\\nabla loss`\n        6. Run a step of the optimizer for generator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_generator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``generator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                generator, discriminator, optimizer_generator, device, labels\n            )\n        else:\n            if labels is None and generator.label_type == ""required"":\n                raise Exception(""GAN model requires labels for training"")\n            batch_size = real_inputs.size(0)\n            noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n            optimizer_generator.zero_grad()\n            if generator.label_type == ""generated"":\n                label_gen = torch.randint(\n                    0, generator.num_classes, (batch_size,), device=device\n                )\n            if generator.label_type == ""none"":\n                fake = generator(noise)\n            elif generator.label_type == ""required"":\n                fake = generator(noise, labels)\n            elif generator.label_type == ""generated"":\n                fake = generator(noise, label_gen)\n\n            if discriminator.label_type == ""none"":\n                fx = discriminator(real_inputs, feature_matching=True)\n                fgz = discriminator(fake, feature_matching=True)\n            else:\n                if discriminator.label_type == ""generated"":\n                    fx = discriminator(real_inputs, label_gen, feature_matching=True)\n                else:\n                    fx = discriminator(real_inputs, labels, feature_matching=True)\n                if generator.label_type == ""generated"":\n                    fgz = discriminator(fake, label_gen, feature_matching=True)\n                else:\n                    fgz = discriminator(fake, labels, feature_matching=True)\n            loss = self.forward(fx, fgz)\n            loss.backward()\n            optimizer_generator.step()\n            return loss.item()\n'"
torchgan/losses/functional.py,12,"b'import torch\nimport torch.autograd as autograd\nimport torch.nn.functional as F\n\nfrom ..utils import reduce\n\n__all__ = [\n    ""minimax_generator_loss"",\n    ""minimax_discriminator_loss"",\n    ""least_squares_generator_loss"",\n    ""least_squares_discriminator_loss"",\n    ""mutual_information_penalty"",\n    ""wasserstein_generator_loss"",\n    ""wasserstein_discriminator_loss"",\n    ""wasserstein_gradient_penalty"",\n    ""dragan_gradient_penalty"",\n    ""auxiliary_classification_loss"",\n    ""energy_based_generator_loss"",\n    ""energy_based_discriminator_loss"",\n    ""energy_based_pulling_away_term"",\n    ""boundary_equilibrium_generator_loss"",\n    ""boundary_equilibrium_discriminator_loss"",\n]\n\n# Minimax Losses\n\n\ndef minimax_generator_loss(dgz, nonsaturating=True, reduction=""mean""):\n    if nonsaturating:\n        target = torch.ones_like(dgz)\n        return F.binary_cross_entropy_with_logits(dgz, target, reduction=reduction)\n    else:\n        target = torch.zeros_like(dgz)\n        return -1.0 * F.binary_cross_entropy_with_logits(\n            dgz, target, reduction=reduction\n        )\n\n\ndef minimax_discriminator_loss(dx, dgz, label_smoothing=0.0, reduction=""mean""):\n    target_ones = torch.ones_like(dgz) * (1.0 - label_smoothing)\n    target_zeros = torch.zeros_like(dx)\n    loss = F.binary_cross_entropy_with_logits(dx, target_ones, reduction=reduction)\n    loss += F.binary_cross_entropy_with_logits(dgz, target_zeros, reduction=reduction)\n    return loss\n\n\n# Least Squared Losses\n\n\ndef least_squares_generator_loss(dgz, c=1.0, reduction=""mean""):\n    return 0.5 * reduce((dgz - c) ** 2, reduction)\n\n\ndef least_squares_discriminator_loss(dx, dgz, a=0.0, b=1.0, reduction=""mean""):\n    return 0.5 * (reduce((dx - b) ** 2, reduction) + reduce((dgz - a) ** 2, reduction))\n\n\n# Mutual Information Penalty\n\n\ndef mutual_information_penalty(c_dis, c_cont, dist_dis, dist_cont, reduction=""mean""):\n    log_probs = torch.Tensor(\n        [\n            torch.mean(dist.log_prob(c))\n            for dist, c in zip((dist_dis, dist_cont), (c_dis, c_cont))\n        ]\n    )\n    return reduce(-1.0 * log_probs, reduction)\n\n\n# Wasserstein Losses\n\n\ndef wasserstein_generator_loss(fgz, reduction=""mean""):\n    return reduce(-1.0 * fgz, reduction)\n\n\ndef wasserstein_discriminator_loss(fx, fgz, reduction=""mean""):\n    return reduce(fgz - fx, reduction)\n\n\ndef wasserstein_gradient_penalty(interpolate, d_interpolate, reduction=""mean""):\n    grad_outputs = torch.ones_like(d_interpolate)\n    gradients = autograd.grad(\n        outputs=d_interpolate,\n        inputs=interpolate,\n        grad_outputs=grad_outputs,\n        create_graph=True,\n        retain_graph=True,\n        only_inputs=True,\n    )[0]\n\n    gradient_penalty = (gradients.norm(2) - 1) ** 2\n    return reduce(gradient_penalty, reduction)\n\n\n# Dragan Penalty\n\n\ndef dragan_gradient_penalty(interpolate, d_interpolate, k=1.0, reduction=""mean""):\n    grad_outputs = torch.ones_like(d_interpolate)\n    gradients = autograd.grad(\n        outputs=d_interpolate,\n        inputs=interpolate,\n        grad_outputs=grad_outputs,\n        create_graph=True,\n        retain_graph=True,\n        only_inputs=True,\n        allow_unused=True,\n    )[0]\n\n    gradient_penalty = (gradients.norm(2) - k) ** 2\n    return reduce(gradient_penalty, reduction)\n\n\n# Auxiliary Classifier Loss\n\n\ndef auxiliary_classification_loss(logits, labels, reduction=""mean""):\n    return F.cross_entropy(logits, labels, reduction=reduction)\n\n\n# Energy Based Losses\n\n\ndef energy_based_generator_loss(dgz, reduction=""mean""):\n    return reduce(dgz, reduction)\n\n\ndef energy_based_discriminator_loss(dx, dgz, margin, reduction=""mean""):\n    return reduce(dx + F.relu(-dgz + margin), reduction)\n\n\ndef energy_based_pulling_away_term(d_hid):\n    d_hid_normalized = F.normalize(d_hid, p=2, dim=0)\n    n = d_hid_normalized.size(0)\n    d_hid_normalized = d_hid_normalized.view(n, -1)\n    similarity = torch.matmul(d_hid_normalized, d_hid_normalized.transpose(1, 0))\n    loss_pt = torch.sum(similarity ** 2) / (n * (n - 1))\n    return loss_pt\n\n\n# Boundary Equilibrium Losses\n\n\ndef boundary_equilibrium_generator_loss(dgz, reduction=""mean""):\n    return reduce(dgz, reduction)\n\n\ndef boundary_equilibrium_discriminator_loss(dx, dgz, k, reduction=""mean""):\n    # NOTE(avik-pal): This is a bit peculiar compared to the other losses as it must return 3 values.\n    loss_real = reduce(dx, reduction)\n    loss_fake = reduce(dgz, reduction)\n    loss_total = loss_real - k * loss_fake\n    return loss_total, loss_real, loss_fake\n'"
torchgan/losses/historical.py,4,"b'import torch\n\nfrom ..utils import reduce\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [""HistoricalAverageGeneratorLoss"", ""HistoricalAverageDiscriminatorLoss""]\n\n\nclass HistoricalAverageGeneratorLoss(GeneratorLoss):\n    r""""""Historical Average Generator Loss from\n    `""Improved Techniques for Training GANs\n    by Salimans et. al."" <https://arxiv.org/pdf/1606.03498.pdf>`_ paper\n\n    The loss can be described as\n\n    .. math:: || \\vtheta - \\frac{1}{t} \\sum_{i=1}^t \\vtheta[i] ||^2\n\n    where\n\n    - :math:`G` : Generator\n    - :math: `\\vtheta[i]` : Generator Parameters at Past Timestep :math: `i`\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n        lambd (float, optional): Hyperparameter lambda for scaling the Historical Average Penalty\n    """"""\n\n    def __init__(\n        self, reduction=""elementwise_mean"", override_train_ops=None, lambd=1.0\n    ):\n        super(HistoricalAverageGeneratorLoss, self).__init__(\n            reduction, override_train_ops\n        )\n        self.timesteps = 0\n        self.sum_parameters = []\n        self.lambd = lambd\n\n    r""""""Defines the standard ``train_ops`` used by historical averaging loss.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows:\n\n        1. Compute the loss :math: `|| \\vtheta - \\frac{1}{t} \\sum_{i=1}^t \\vtheta[i] ||^2`\n        2. Backpropagate by computing :math:`\\nabla loss`\n        3. Run a step of the optimizer for discriminator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            optimizer_generator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``generator``.\n\n        Returns:\n            Scalar value of the loss.\n    """"""\n\n    def train_ops(self, generator, optimizer_generator):\n        if self.override_train_ops is not None:\n            return self.override_train_ops(self, generator, optimizer_generator)\n        else:\n            if self.timesteps == 0:\n                for p in generator.parameters():\n                    param = p.data.clone()\n                    self.sum_parameters.append(param)\n                self.timesteps += 1\n                return 0.0\n            else:\n                optimizer_generator.zero_grad()\n                loss = 0.0\n                for i, p in enumerate(generator.parameters()):\n                    loss += torch.sum(\n                        (p - (self.sum_parameters[i].data / self.timesteps)) ** 2\n                    )\n                    self.sum_parameters[i] += p.data.clone()\n                self.timesteps += 1\n                loss *= self.lambd\n                loss.backward()\n                optimizer_generator.step()\n                return loss.item()\n\n\nclass HistoricalAverageDiscriminatorLoss(DiscriminatorLoss):\n    r""""""Historical Average Discriminator Loss from\n    `""Improved Techniques for Training GANs\n    by Salimans et. al."" <https://arxiv.org/pdf/1606.03498.pdf>`_ paper\n\n    The loss can be described as\n\n    .. math:: || \\vtheta - \\frac{1}{t} \\sum_{i=1}^t \\vtheta[i] ||^2\n\n    where\n\n    - :math:`G` : Discriminator\n    - :math: `\\vtheta[i]` : Discriminator Parameters at Past Timestep :math: `i`\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n        lambd (float, optional): Hyperparameter lambda for scaling the Historical Average Penalty\n    """"""\n\n    def __init__(\n        self, reduction=""elementwise_mean"", override_train_ops=None, lambd=1.0\n    ):\n        super(HistoricalAverageDiscriminatorLoss, self).__init__(\n            reduction, override_train_ops\n        )\n        self.timesteps = 0\n        self.sum_parameters = []\n        self.lambd = lambd\n\n    r""""""Defines the standard ``train_ops`` used by historical averaging loss.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows:\n\n        1. Compute the loss :math: `|| \\vtheta - \\frac{1}{t} \\sum_{i=1}^t \\vtheta[i] ||^2`\n        2. Backpropagate by computing :math:`\\nabla loss`\n        3. Run a step of the optimizer for discriminator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            optimizer_generator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``generator``.\n\n        Returns:\n            Scalar value of the loss.\n    """"""\n\n    def train_ops(self, discriminator, optimizer_discriminator):\n        if self.override_train_ops is not None:\n            return self.override_train_ops(self, discriminator, optimizer_discriminator)\n        else:\n            if self.timesteps == 0:\n                for p in discriminator.parameters():\n                    param = p.data.clone()\n                    self.sum_parameters.append(param)\n                self.timesteps += 1\n                return 0.0\n            else:\n                optimizer_discriminator.zero_grad()\n                loss = 0.0\n                for i, p in enumerate(discriminator.parameters()):\n                    loss += torch.sum(\n                        (p - (self.sum_parameters[i].data / self.timesteps)) ** 2\n                    )\n                    self.sum_parameters[i] += p.data.clone()\n                self.timesteps += 1\n                loss *= self.lambd\n                loss.backward()\n                optimizer_discriminator.step()\n                return loss.item()\n'"
torchgan/losses/leastsquares.py,3,"b'import torch\n\nfrom .functional import least_squares_discriminator_loss, least_squares_generator_loss\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [""LeastSquaresGeneratorLoss"", ""LeastSquaresDiscriminatorLoss""]\n\n\nclass LeastSquaresGeneratorLoss(GeneratorLoss):\n    r""""""Least Squares GAN generator loss from `""Least Squares Generative Adversarial Networks\n    by Mao et. al."" <https://arxiv.org/abs/1611.04076>`_ paper\n\n    The loss can be described as\n\n    .. math:: L(G) = \\frac{(D(G(z)) - c)^2}{2}\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Disrciminator\n    - :math:`c` : target generator label\n    - :math:`z` : A sample from the noise prior\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        c (float, optional): Target generator label.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n    """"""\n\n    def __init__(self, reduction=""mean"", c=1.0, override_train_ops=None):\n        super(LeastSquaresGeneratorLoss, self).__init__(reduction, override_train_ops)\n        self.c = c\n\n    def forward(self, dgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return least_squares_generator_loss(dgz, self.c, self.reduction)\n\n\nclass LeastSquaresDiscriminatorLoss(DiscriminatorLoss):\n    r""""""Least Squares GAN discriminator loss from `""Least Squares Generative Adversarial Networks\n    by Mao et. al."" <https://arxiv.org/abs/1611.04076>`_ paper.\n\n    The loss can be described as:\n\n    .. math:: L(D) = \\frac{(D(x) - b)^2 + (D(G(z)) - a)^2}{2}\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Disrciminator\n    - :math:`a` : Target discriminator label for generated image\n    - :math:`b` : Target discriminator label for real image\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        a (float, optional): Target discriminator label for generated image.\n        b (float, optional): Target discriminator label for real image.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n    """"""\n\n    def __init__(self, reduction=""mean"", a=0.0, b=1.0, override_train_ops=None):\n        super(LeastSquaresDiscriminatorLoss, self).__init__(\n            reduction, override_train_ops\n        )\n        self.a = a\n        self.b = b\n\n    def forward(self, dx, dgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dx (torch.Tensor) : Output of the Discriminator with real data. It must have the\n                                dimensions (N, \\*) where \\* means any number of additional\n                                dimensions.\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return least_squares_discriminator_loss(dx, dgz, self.a, self.b, self.reduction)\n'"
torchgan/losses/loss.py,12,"b'import torch\nimport torch.nn as nn\n\n__all__ = [""GeneratorLoss"", ""DiscriminatorLoss""]\n\n\nclass GeneratorLoss(nn.Module):\n    r""""""Base class for all generator losses.\n\n    .. note:: All Losses meant to be minimized for optimizing the Generator must subclass this.\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n    """"""\n\n    def __init__(self, reduction=""mean"", override_train_ops=None):\n        super(GeneratorLoss, self).__init__()\n        self.reduction = reduction\n        self.override_train_ops = override_train_ops\n        self.arg_map = {}\n\n    def set_arg_map(self, value):\n        r""""""Updates the ``arg_map`` for passing a different value to the ``train_ops``.\n\n        Args:\n            value (dict): A mapping of the ``argument name`` in the method signature and the\n                variable name in the ``Trainer`` it corresponds to.\n\n        .. note::\n            If the ``train_ops`` signature is\n            ``train_ops(self, gen, disc, optimizer_generator, device, batch_size, labels=None)``\n            then we need to map ``gen`` to ``generator`` and ``disc`` to ``discriminator``.\n            In this case we make the following function call\n            ``loss.set_arg_map({""gen"": ""generator"", ""disc"": ""discriminator""})``.\n        """"""\n        self.arg_map.update(value)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_generator,\n        device,\n        batch_size,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used by most losses. Losses which have a different\n        training procedure can either ``subclass`` it **(recommended approach)** or make use of\n        ``override_train_ops`` argument.\n\n        The ``standard optimization algorithm`` for the ``generator`` defined in this train_ops\n        is as follows:\n\n        1. :math:`fake = generator(noise)`\n        2. :math:`value = discriminator(fake)`\n        3. :math:`loss = loss\\_function(value)`\n        4. Backpropagate by computing :math:`\\nabla loss`\n        5. Run a step of the optimizer for generator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_generator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``generator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            batch_size (int): Batch Size of the data infered from the ``DataLoader`` by the ``Trainer``.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                generator,\n                discriminator,\n                optimizer_generator,\n                device,\n                batch_size,\n                labels,\n            )\n        else:\n            if labels is None and generator.label_type == ""required"":\n                raise Exception(""GAN model requires labels for training"")\n            noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n            optimizer_generator.zero_grad()\n            if generator.label_type == ""generated"":\n                label_gen = torch.randint(\n                    0, generator.num_classes, (batch_size,), device=device\n                )\n            if generator.label_type == ""none"":\n                fake = generator(noise)\n            elif generator.label_type == ""required"":\n                fake = generator(noise, labels)\n            elif generator.label_type == ""generated"":\n                fake = generator(noise, label_gen)\n            if discriminator.label_type == ""none"":\n                dgz = discriminator(fake)\n            else:\n                if generator.label_type == ""generated"":\n                    dgz = discriminator(fake, label_gen)\n                else:\n                    dgz = discriminator(fake, labels)\n            loss = self.forward(dgz)\n            loss.backward()\n            optimizer_generator.step()\n            # NOTE(avik-pal): This will error if reduction is is \'none\'\n            return loss.item()\n\n\nclass DiscriminatorLoss(nn.Module):\n    r""""""Base class for all discriminator losses.\n\n    .. note:: All Losses meant to be minimized for optimizing the Discriminator must subclass this.\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n    """"""\n\n    def __init__(self, reduction=""mean"", override_train_ops=None):\n        super(DiscriminatorLoss, self).__init__()\n        self.reduction = reduction\n        self.override_train_ops = override_train_ops\n        self.arg_map = {}\n\n    def set_arg_map(self, value):\n        r""""""Updates the ``arg_map`` for passing a different value to the ``train_ops``.\n\n        Args:\n            value (dict): A mapping of the ``argument name`` in the method signature and the\n                variable name in the ``Trainer`` it corresponds to.\n\n        .. note::\n            If the ``train_ops`` signature is\n            ``train_ops(self, gen, disc, optimizer_discriminator, device, batch_size, labels=None)``\n            then we need to map ``gen`` to ``generator`` and ``disc`` to ``discriminator``.\n            In this case we make the following function call\n            ``loss.set_arg_map({""gen"": ""generator"", ""disc"": ""discriminator""})``.\n        """"""\n        self.arg_map.update(value)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_discriminator,\n        real_inputs,\n        device,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used by most losses. Losses which have a different\n        training procedure can either ``subclass`` it **(recommended approach)** or make use of\n        ``override_train_ops`` argument.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows:\n\n        1. :math:`fake = generator(noise)`\n        2. :math:`value_1 = discriminator(fake)`\n        3. :math:`value_2 = discriminator(real)`\n        4. :math:`loss = loss\\_function(value_1, value_2)`\n        5. Backpropagate by computing :math:`\\nabla loss`\n        6. Run a step of the optimizer for discriminator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_discriminator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``discriminator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            batch_size (int): Batch Size of the data infered from the ``DataLoader`` by the ``Trainer``.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                self,\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                device,\n                labels,\n            )\n        else:\n            if labels is None and (\n                generator.label_type == ""required""\n                or discriminator.label_type == ""required""\n            ):\n                raise Exception(""GAN model requires labels for training"")\n            batch_size = real_inputs.size(0)\n            noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n            if generator.label_type == ""generated"":\n                label_gen = torch.randint(\n                    0, generator.num_classes, (batch_size,), device=device\n                )\n            optimizer_discriminator.zero_grad()\n            if discriminator.label_type == ""none"":\n                dx = discriminator(real_inputs)\n            elif discriminator.label_type == ""required"":\n                dx = discriminator(real_inputs, labels)\n            else:\n                dx = discriminator(real_inputs, label_gen)\n            if generator.label_type == ""none"":\n                fake = generator(noise)\n            elif generator.label_type == ""required"":\n                fake = generator(noise, labels)\n            else:\n                fake = generator(noise, label_gen)\n            if discriminator.label_type == ""none"":\n                dgz = discriminator(fake.detach())\n            else:\n                if generator.label_type == ""generated"":\n                    dgz = discriminator(fake.detach(), label_gen)\n                else:\n                    dgz = discriminator(fake.detach(), labels)\n            loss = self.forward(dx, dgz)\n            loss.backward()\n            optimizer_discriminator.step()\n            # NOTE(avik-pal): This will error if reduction is is \'none\'\n            return loss.item()\n'"
torchgan/losses/minimax.py,3,"b'import torch\n\nfrom .functional import minimax_discriminator_loss, minimax_generator_loss\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [""MinimaxGeneratorLoss"", ""MinimaxDiscriminatorLoss""]\n\n\nclass MinimaxGeneratorLoss(GeneratorLoss):\n    r""""""Minimax game generator loss from the original GAN paper `""Generative Adversarial Networks\n    by Goodfellow et. al."" <https://arxiv.org/abs/1406.2661>`_\n\n    The loss can be described as:\n\n    .. math:: L(G) = log(1 - D(G(z)))\n\n    The nonsaturating heuristic is also supported:\n\n    .. math:: L(G) = -log(D(G(z)))\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Discriminator\n    - :math:`z` : A sample from the noise prior\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the outputs are averaged over batch size.\n            If ``sum`` the elements of the output are summed.\n        override_train_ops (function, optional): Function to be used in place of the default ``train_ops``\n        nonsaturating(bool, optional): Specifies whether to use the nonsaturating heuristic\n            loss for the generator.\n    """"""\n\n    def __init__(self, reduction=""mean"", nonsaturating=True, override_train_ops=None):\n        super(MinimaxGeneratorLoss, self).__init__(reduction, override_train_ops)\n        self.nonsaturating = nonsaturating\n\n    def forward(self, dgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return minimax_generator_loss(dgz, self.nonsaturating, self.reduction)\n\n\nclass MinimaxDiscriminatorLoss(DiscriminatorLoss):\n    r""""""Minimax game discriminator loss from the original GAN paper `""Generative Adversarial Networks\n    by Goodfellow et. al."" <https://arxiv.org/abs/1406.2661>`_\n\n    The loss can be described as:\n\n    .. math:: L(D) = -[log(D(x)) + log(1 - D(G(z)))]\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Discriminator\n    - :math:`x` : A sample from the data distribution\n    - :math:`z` : A sample from the noise prior\n\n    Args:\n        label_smoothing (float, optional): The factor by which the labels (1 in this case) needs\n            to be smoothened. For example, label_smoothing = 0.2 changes the value of the real\n            labels to 0.8.\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the mean of the output.\n            If ``sum`` the elements of the output will be summed.\n        override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def __init__(self, label_smoothing=0.0, reduction=""mean"", override_train_ops=None):\n        super(MinimaxDiscriminatorLoss, self).__init__(reduction, override_train_ops)\n        self.label_smoothing = label_smoothing\n\n    def forward(self, dx, dgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dx (torch.Tensor) : Output of the Discriminator with real data. It must have the\n                                dimensions (N, \\*) where \\* means any number of additional\n                                dimensions.\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return minimax_discriminator_loss(\n            dx, dgz, label_smoothing=self.label_smoothing, reduction=self.reduction\n        )\n'"
torchgan/losses/mutualinfo.py,3,"b'import torch\n\nfrom .functional import mutual_information_penalty\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [""MutualInformationPenalty""]\n\n\nclass MutualInformationPenalty(GeneratorLoss, DiscriminatorLoss):\n    r""""""Mutual Information Penalty as defined in\n    `""InfoGAN : Interpretable Representation Learning by Information Maximising Generative Adversarial Nets\n    by Chen et. al."" <https://arxiv.org/abs/1606.03657>`_ paper\n\n    The loss is the variational lower bound of the mutual information between\n    the latent codes and the generator distribution and is defined as\n\n    .. math:: L(G,Q) = log(Q|x)\n\n    where\n\n    - :math:`x` is drawn from the generator distribution G(z,c)\n    - :math:`c` drawn from the latent code prior :math:`P(c)`\n\n    Args:\n        lambd (float, optional): The scaling factor for the loss.\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the mean of the output.\n            If ``sum`` the elements of the output will be summed.\n        override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def __init__(self, lambd=1.0, reduction=""mean"", override_train_ops=None):\n        super(MutualInformationPenalty, self).__init__(reduction, override_train_ops)\n        self.lambd = lambd\n\n    def forward(self, c_dis, c_cont, dist_dis, dist_cont):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            c_dis (int): The discrete latent code sampled from the prior.\n            c_cont (int): The continuous latent code sampled from the prior.\n            dist_dis (torch.distributions.Distribution): The auxilliary distribution :math:`Q(c|x)` over the\n                discrete latent code output by the discriminator.\n            dist_cont (torch.distributions.Distribution): The auxilliary distribution :math:`Q(c|x)` over the\n                continuous latent code output by the discriminator.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return mutual_information_penalty(\n            c_dis, c_cont, dist_dis, dist_cont, reduction=self.reduction\n        )\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_generator,\n        optimizer_discriminator,\n        dis_code,\n        cont_code,\n        device,\n        batch_size,\n    ):\n        if self.override_train_ops is not None:\n            self.override_train_ops(\n                generator,\n                discriminator,\n                optimizer_generator,\n                optimizer_discriminator,\n                dis_code,\n                cont_code,\n                device,\n                batch_size,\n            )\n        else:\n            noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n            optimizer_discriminator.zero_grad()\n            optimizer_generator.zero_grad()\n            fake = generator(noise, dis_code, cont_code)\n            _, dist_dis, dist_cont = discriminator(fake, True)\n            loss = self.forward(dis_code, cont_code, dist_dis, dist_cont)\n            weighted_loss = self.lambd * loss\n            weighted_loss.backward()\n            optimizer_discriminator.step()\n            optimizer_generator.step()\n            return weighted_loss.item()\n'"
torchgan/losses/wasserstein.py,16,"b'import torch\n\nfrom .functional import (\n    wasserstein_discriminator_loss,\n    wasserstein_generator_loss,\n    wasserstein_gradient_penalty,\n)\nfrom .loss import DiscriminatorLoss, GeneratorLoss\n\n__all__ = [\n    ""WassersteinGeneratorLoss"",\n    ""WassersteinDiscriminatorLoss"",\n    ""WassersteinGradientPenalty"",\n]\n\n\nclass WassersteinGeneratorLoss(GeneratorLoss):\n    r""""""Wasserstein GAN generator loss from\n    `""Wasserstein GAN by Arjovsky et. al."" <https://arxiv.org/abs/1701.07875>`_ paper\n\n    The loss can be described as:\n\n    .. math:: L(G) = -f(G(z))\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`f` : Critic/Discriminator\n    - :math:`z` : A sample from the noise prior\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the mean of the output.\n            If ``sum`` the elements of the output will be summed.\n        override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def forward(self, fgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            dgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return wasserstein_generator_loss(fgz, self.reduction)\n\n\nclass WassersteinDiscriminatorLoss(DiscriminatorLoss):\n    r""""""Wasserstein GAN generator loss from\n    `""Wasserstein GAN by Arjovsky et. al."" <https://arxiv.org/abs/1701.07875>`_ paper\n\n    The loss can be described as:\n\n    .. math:: L(D) = f(G(z)) - f(x)\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`f` : Critic/Discriminator\n    - :math:`x` : A sample from the data distribution\n    - :math:`z` : A sample from the noise prior\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the mean of the output.\n            If ``sum`` the elements of the output will be summed.\n        clip (tuple, optional): Tuple that specifies the maximum and minimum parameter\n            clamping to be applied, as per the original version of the Wasserstein loss\n            without Gradient Penalty.\n        override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def __init__(self, reduction=""mean"", clip=None, override_train_ops=None):\n        super(WassersteinDiscriminatorLoss, self).__init__(\n            reduction, override_train_ops\n        )\n        if (isinstance(clip, tuple) or isinstance(clip, list)) and len(clip) > 1:\n            self.clip = clip\n        else:\n            self.clip = None\n\n    def forward(self, fx, fgz):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            fx (torch.Tensor) : Output of the Discriminator with real data. It must have the\n                                dimensions (N, \\*) where \\* means any number of additional\n                                dimensions.\n            fgz (torch.Tensor) : Output of the Discriminator with generated data. It must have the\n                                 dimensions (N, \\*) where \\* means any number of additional\n                                 dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        return wasserstein_discriminator_loss(fx, fgz, self.reduction)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_discriminator,\n        real_inputs,\n        device,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used by wasserstein discriminator loss.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows:\n\n        1. Clamp the discriminator parameters to satisfy :math:`lipschitz\\ condition`\n        2. :math:`fake = generator(noise)`\n        3. :math:`value_1 = discriminator(fake)`\n        4. :math:`value_2 = discriminator(real)`\n        5. :math:`loss = loss\\_function(value_1, value_2)`\n        6. Backpropagate by computing :math:`\\nabla loss`\n        7. Run a step of the optimizer for discriminator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_discriminator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``discriminator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                device,\n                labels,\n            )\n        else:\n            if self.clip is not None:\n                for p in discriminator.parameters():\n                    p.data.clamp_(self.clip[0], self.clip[1])\n            return super(WassersteinDiscriminatorLoss, self).train_ops(\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                device,\n                labels,\n            )\n\n\nclass WassersteinGradientPenalty(DiscriminatorLoss):\n    r""""""Gradient Penalty for the Improved Wasserstein GAN discriminator from\n    `""Improved Training of Wasserstein GANs\n    by Gulrajani et. al."" <https://arxiv.org/abs/1704.00028>`_ paper\n\n    The gradient penalty is calculated as:\n\n    .. math: \\lambda \\times (||\\nabla(D(x))||_2 - 1)^2\n\n    The gradient being taken with respect to x\n\n    where\n\n    - :math:`G` : Generator\n    - :math:`D` : Disrciminator/Critic\n    - :math:`\\lambda` : Scaling hyperparameter\n    - :math:`x` : Interpolation term for the gradient penalty\n\n    Args:\n        reduction (str, optional): Specifies the reduction to apply to the output.\n            If ``none`` no reduction will be applied. If ``mean`` the mean of the output.\n            If ``sum`` the elements of the output will be summed.\n        lambd (float,optional): Hyperparameter lambda for scaling the gradient penalty.\n        override_train_ops (function, optional): A function is passed to this argument,\n            if the default ``train_ops`` is not to be used.\n    """"""\n\n    def __init__(self, reduction=""mean"", lambd=10.0, override_train_ops=None):\n        super(WassersteinGradientPenalty, self).__init__(reduction, override_train_ops)\n        self.lambd = lambd\n        self.override_train_ops = override_train_ops\n\n    def forward(self, interpolate, d_interpolate):\n        r""""""Computes the loss for the given input.\n\n        Args:\n            interpolate (torch.Tensor) : It must have the dimensions (N, \\*) where\n                                         \\* means any number of additional dimensions.\n            d_interpolate (torch.Tensor) : Output of the ``discriminator`` with ``interpolate``\n                                           as the input. It must have the dimensions (N, \\*)\n                                           where \\* means any number of additional dimensions.\n\n        Returns:\n            scalar if reduction is applied else Tensor with dimensions (N, \\*).\n        """"""\n        # TODO(Aniket1998): Check for performance bottlenecks\n        # If found, write the backprop yourself instead of\n        # relying on autograd\n        return wasserstein_gradient_penalty(interpolate, d_interpolate, self.reduction)\n\n    def train_ops(\n        self,\n        generator,\n        discriminator,\n        optimizer_discriminator,\n        real_inputs,\n        device,\n        labels=None,\n    ):\n        r""""""Defines the standard ``train_ops`` used by the Wasserstein Gradient Penalty.\n\n        The ``standard optimization algorithm`` for the ``discriminator`` defined in this train_ops\n        is as follows:\n\n        1. :math:`fake = generator(noise)`\n        2. :math:`interpolate = \\epsilon \\times real + (1 - \\epsilon) \\times fake`\n        3. :math:`d\\_interpolate = discriminator(interpolate)`\n        4. :math:`loss = \\lambda loss\\_function(interpolate, d\\_interpolate)`\n        5. Backpropagate by computing :math:`\\nabla loss`\n        6. Run a step of the optimizer for discriminator\n\n        Args:\n            generator (torchgan.models.Generator): The model to be optimized.\n            discriminator (torchgan.models.Discriminator): The discriminator which judges the\n                performance of the generator.\n            optimizer_discriminator (torch.optim.Optimizer): Optimizer which updates the ``parameters``\n                of the ``discriminator``.\n            real_inputs (torch.Tensor): The real data to be fed to the ``discriminator``.\n            device (torch.device): Device on which the ``generator`` and ``discriminator`` is present.\n            batch_size (int): Batch Size of the data infered from the ``DataLoader`` by the ``Trainer``.\n            labels (torch.Tensor, optional): Labels for the data.\n\n        Returns:\n            Scalar value of the loss.\n        """"""\n        if self.override_train_ops is not None:\n            return self.override_train_ops(\n                self,\n                generator,\n                discriminator,\n                optimizer_discriminator,\n                real_inputs,\n                labels,\n            )\n        else:\n            if labels is None and (\n                generator.label_type == ""required""\n                or discriminator.label_type == ""required""\n            ):\n                raise Exception(""GAN model requires labels for training"")\n            batch_size = real_inputs.size(0)\n            noise = torch.randn(batch_size, generator.encoding_dims, device=device)\n            if generator.label_type == ""generated"":\n                label_gen = torch.randint(\n                    0, generator.num_classes, (batch_size,), device=device\n                )\n            optimizer_discriminator.zero_grad()\n            if generator.label_type == ""none"":\n                fake = generator(noise)\n            elif generator.label_type == ""required"":\n                fake = generator(noise, labels)\n            else:\n                fake = generator(noise, label_gen)\n            eps = torch.rand(1).item()\n            interpolate = eps * real_inputs + (1 - eps) * fake\n            if discriminator.label_type == ""none"":\n                d_interpolate = discriminator(interpolate)\n            else:\n                if generator.label_type == ""generated"":\n                    d_interpolate = discriminator(interpolate, label_gen)\n                else:\n                    d_interpolate = discriminator(interpolate, labels)\n            loss = self.forward(interpolate, d_interpolate)\n            weighted_loss = self.lambd * loss\n            weighted_loss.backward()\n            optimizer_discriminator.step()\n            return loss.item()\n'"
torchgan/metrics/__init__.py,0,b'from .classifierscore import *\nfrom .metric import *\n'
torchgan/metrics/classifierscore.py,9,"b'import torch\nimport torch.nn.functional as F\nimport torchvision\n\nfrom ..utils import reduce\nfrom .metric import EvaluationMetric\n\n__all__ = [""ClassifierScore""]\n\n\nclass ClassifierScore(EvaluationMetric):\n    r""""""\n    Computes the Classifier Score of a Model. Also popularly known as the Inception Score.\n    The ``classifier`` can be any model. It also supports models outside of torchvision models.\n    For more details on how to use custom trained models look up the tutorials.\n\n    Args:\n        classifier (torch.nn.Module, optional) : The model to be used as a base to compute the classifier\n            score. If ``None`` is passed the pretrained ``torchvision.models.inception_v3`` is used.\n\n            .. note ::\n                Ensure that the classifier is on the same ``device`` as the Trainer to avoid sudden\n                crash.\n        transform (torchvision.transforms, optional) : Transformations applied to the image before feeding\n            it to the classifier. Look up the documentation of the torchvision models for this transforms.\n        sample_size (int): Batch Size for calculation of Classifier Score.\n    """"""\n\n    def __init__(self, classifier=None, transform=None, sample_size=1):\n        super(ClassifierScore, self).__init__()\n        self.classifier = (\n            torchvision.models.inception_v3(True) if classifier is None else classifier\n        )\n        self.classifier.eval()\n        self.transform = transform\n        self.sample_size = sample_size\n\n    def preprocess(self, x):\n        r""""""\n        Preprocessor for the Classifier Score. It transforms the image as per the transform requirements\n        and feeds it to the classifier.\n\n        Args:\n            x (torch.Tensor) : Image in tensor format\n\n        Returns:\n            The output from the classifier.\n        """"""\n        x = x if self.transform is None else self.transform(x)\n        return self.classifier(x)\n\n    def calculate_score(self, x):\n        r""""""\n        Computes the Inception Score for the Input.\n\n        Args:\n            x (torch.Tensor) : Image in tensor format\n\n        Returns:\n            The Inception Score.\n        """"""\n        p = F.softmax(x, dim=1)\n        q = torch.mean(p, dim=0)\n        kl = torch.sum(p * (F.log_softmax(x, dim=1) - torch.log(q)), dim=1)\n        return torch.exp(reduce(kl, ""mean"")).data\n\n    def metric_ops(self, generator, device):\n        r""""""Defines the set of operations necessary to compute the ClassifierScore.\n\n        Args:\n            generator (torchgan.models.Generator): The generator which needs to be evaluated.\n            device (torch.device): Device on which the generator is present.\n\n        Returns:\n            The Classifier Score (scalar quantity)\n        """"""\n        noise = torch.randn(self.sample_size, generator.encoding_dims, device=device)\n        img = generator(noise).detach()\n        score = self.__call__(img)\n        return score\n'"
torchgan/metrics/metric.py,0,"b'__all__ = [""EvaluationMetric""]\n\n\nclass EvaluationMetric(object):\n    r""""""\n    Base class for all Evaluation Metrics\n    """"""\n\n    def __init__(self):\n        self.arg_map = {}\n\n    def set_arg_map(self, value):\n        r""""""Updates the ``arg_map`` for passing a different value to the ``metric_ops``.\n\n        Args:\n            value (dict): A mapping of the ``argument name`` in the method signature and the\n                variable name in the ``Trainer`` it corresponds to.\n\n        .. note::\n            If the ``metric_ops`` signature is\n            ``metric_ops(self, gen, disc)``\n            then we need to map ``gen`` to ``generator`` and ``disc`` to ``discriminator``.\n            In this case we make the following function call\n            ``metric.set_arg_map({""gen"": ""generator"", ""disc"": ""discriminator""})``.\n        """"""\n        self.arg_map.update(value)\n\n    def preprocess(self, x):\n        r""""""\n        Subclasses must override this function and provide their own preprocessing\n        pipeline.\n\n        :raises NotImplementedError: If the subclass doesn\'t override this function.\n        """"""\n        raise NotImplementedError\n\n    def calculate_score(self, x):\n        r""""""\n        Subclasses must override this function and provide their own score calculation.\n\n        :raises NotImplementedError: If the subclass doesn\'t override this function.\n        """"""\n        raise NotImplementedError\n\n    def metric_ops(self, generator, discriminator, **kwargs):\n        r""""""\n        Subclasses must override this function and provide their own metric evaluation ops.\n\n        :raises NotImplementedError: If the subclass doesn\'t override this function.\n        """"""\n        raise NotImplementedError\n\n    def __call__(self, x):\n        return self.calculate_score(self.preprocess(x))\n'"
torchgan/models/__init__.py,0,b'from .acgan import *\nfrom .autoencoding import *\nfrom .conditional import *\nfrom .dcgan import *\nfrom .infogan import *\nfrom .model import *\n'
torchgan/models/acgan.py,15,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom .dcgan import DCGANDiscriminator, DCGANGenerator\n\n__all__ = [""ACGANGenerator"", ""ACGANDiscriminator""]\n\n\nclass ACGANGenerator(DCGANGenerator):\n    r""""""Auxiliary Classifier GAN (ACGAN) generator based on a DCGAN model from\n    `""Conditional Image Synthesis With Auxiliary Classifier GANs\n    by Odena et. al. "" <https://arxiv.org/abs/1610.09585>`_ paper\n\n    Args:\n        num_classes (int): Total classes present in the dataset.\n        encoding_dims (int, optional): Dimension of the encoding vector sampled from the noise prior.\n        out_size (int, optional): Height and width of the input image to be generated. Must be at\n            least 16 and should be an exact power of 2.\n        out_channels (int, optional): Number of channels in the output Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n    """"""\n\n    def __init__(\n        self,\n        num_classes,\n        encoding_dims=100,\n        out_size=32,\n        out_channels=3,\n        step_channels=64,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n    ):\n        super(ACGANGenerator, self).__init__(\n            encoding_dims,\n            out_size,\n            out_channels,\n            step_channels,\n            batchnorm,\n            nonlinearity,\n            last_nonlinearity,\n            label_type=""generated"",\n        )\n        self.encoding_dims = encoding_dims\n        self.num_classes = num_classes\n        self.label_embeddings = nn.Embedding(self.num_classes, self.encoding_dims)\n\n    def forward(self, z, y):\n        r""""""Calculates the output tensor on passing the encoding ``z`` through the Generator.\n\n        Args:\n            z (torch.Tensor): A 2D torch tensor of the encoding sampled from a probability\n                distribution.\n            y (torch.Tensor): The labels corresponding to the encoding ``z``.\n\n        Returns:\n            A 4D torch.Tensor of the generated Images conditioned on ``y``.\n        """"""\n        y_emb = self.label_embeddings(y.type(torch.LongTensor).to(y.device))\n        return super(ACGANGenerator, self).forward(torch.mul(y_emb, z))\n\n    def sampler(self, sample_size, device):\n        return [\n            torch.randn(sample_size, self.encoding_dims, device=device),\n            torch.randint(0, self.num_classes, (sample_size,), device=device),\n        ]\n\n\nclass ACGANDiscriminator(DCGANDiscriminator):\n    r""""""Auxiliary Classifier GAN (ACGAN) discriminator based on a DCGAN model from\n    `""Conditional Image Synthesis With Auxiliary Classifier GANs\n    by Odena et. al. "" <https://arxiv.org/abs/1610.09585>`_ paper\n\n    Args:\n        num_classes (int): Total classes present in the dataset.\n        in_size (int, optional): Height and width of the input image to be evaluated. Must be at\n            least 16 and should be an exact power of 2.\n        in_channels (int, optional): Number of channels in the input Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n    """"""\n\n    def __init__(\n        self,\n        num_classes,\n        in_size=32,\n        in_channels=3,\n        step_channels=64,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n    ):\n        super(ACGANDiscriminator, self).__init__(\n            in_size,\n            in_channels,\n            step_channels,\n            batchnorm,\n            nonlinearity,\n            last_nonlinearity,\n            label_type=""none"",\n        )\n        last_nl = nn.LeakyReLU(0.2) if last_nonlinearity is None else last_nonlinearity\n        self.input_dims = in_channels\n        self.num_classes = num_classes\n        d = self.n * 2 ** (in_size.bit_length() - 4)\n        self.aux = nn.Sequential(\n            nn.Conv2d(d, self.num_classes, 4, 1, 0, bias=False), last_nl\n        )\n\n    def forward(self, x, mode=""discriminator"", feature_matching=False):\n        r""""""Calculates the output tensor on passing the image ``x`` through the Discriminator.\n\n        Args:\n            x (torch.Tensor): A 4D torch tensor of the image.\n            mode (str, optional): Option to choose the mode of the ACGANDiscriminator. Setting it to\n                \'discriminator\' gives the probability of the image being fake/real, \'classifier\' allows\n                it to make a prediction about the class of the image and anything else leads to\n                returning both the values.\n            feature_matching (bool, optional): Returns the activation from a predefined intermediate\n                layer.\n\n        Returns:\n            A 1D torch.Tensor of the probability of each image being real.\n        """"""\n        x = self.model(x)\n        if feature_matching is True:\n            return x\n        if mode == ""discriminator"":\n            dx = self.disc(x)\n            return dx.view(dx.size(0))\n        elif mode == ""classifier"":\n            cx = self.aux(x)\n            return cx.view(cx.size(0), cx.size(1))\n        else:\n            dx = self.disc(x)\n            cx = self.aux(x)\n            return dx.view(dx.size(0)), cx.view(cx.size(0), cx.size(1))\n'"
torchgan/models/autoencoding.py,12,"b'from math import ceil, log\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom .model import Discriminator, Generator\n\n__all__ = [""AutoEncodingGenerator"", ""AutoEncodingDiscriminator""]\n\n\nclass AutoEncodingGenerator(Generator):\n    r""""""Autoencoding Generator for Boundary Equilibrium GAN (BEGAN) from\n    `""BEGAN : Boundary Equilibrium Generative Adversarial Networks\n    by Berthelot et. al."" <https://arxiv.org/abs/1703.10717>`_ paper\n\n    Args:\n        encoding_dims (int, optional): Dimension of the encoding vector sampled from the noise prior.\n        out_size (int, optional): Height and width of the input image to be generated. Must be at\n            least 16 and should be an exact power of 2.\n        out_channels (int, optional): Number of channels in the output Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        scale_factor (int, optional): The scale factor is used to infer properties of the model like\n            ``upsample_pad``, ``upsample_filters``, ``upsample_stride`` and ``upsample_output_pad``.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n        label_type (str, optional): The type of labels expected by the Generator. The available\n            choices are \'none\' if no label is needed, \'required\' if the original labels are\n            needed and \'generated\' if labels are to be sampled from a distribution.\n    """"""\n\n    def __init__(\n        self,\n        encoding_dims=100,\n        out_size=32,\n        out_channels=3,\n        step_channels=64,\n        scale_factor=2,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n        label_type=""none"",\n    ):\n        super(AutoEncodingGenerator, self).__init__(encoding_dims, label_type)\n        if out_size < (scale_factor ** 4) or ceil(log(out_size, scale_factor)) != log(\n            out_size, scale_factor\n        ):\n            raise Exception(\n                ""Target image size must be at least {} and a perfect power of {}"".format(\n                    scale_factor ** 4, scale_factor\n                )\n            )\n        num_repeats = int(log(out_size, scale_factor)) - 3\n        same_filters = scale_factor + 1\n        same_pad = scale_factor // 2\n        if scale_factor == 2:\n            upsample_filters = 3\n            upsample_stride = 2\n            upsample_pad = 1\n            upsample_output_pad = 1\n        else:\n            upsample_filters = scale_factor\n            upsample_stride = scale_factor\n            upsample_pad = 0\n            upsample_output_pad = 0\n        self.ch = out_channels\n        self.n = step_channels\n        use_bias = not batchnorm\n        nl = nn.ELU() if nonlinearity is None else nonlinearity\n        last_nl = nn.Tanh() if last_nonlinearity is None else last_nonlinearity\n        init_dim = scale_factor ** 3\n        self.init_dim = init_dim\n\n        if batchnorm is True:\n            self.fc = nn.Sequential(\n                nn.Linear(self.encoding_dims, (init_dim ** 2) * self.n),\n                nn.BatchNorm1d((init_dim ** 2) * self.n),\n                nl,\n            )\n            initial_unit = nn.Sequential(\n                nn.Conv2d(self.n, self.n, same_filters, 1, same_pad, bias=use_bias),\n                nn.BatchNorm2d(self.n),\n                nl,\n                nn.Conv2d(self.n, self.n, same_filters, 1, same_pad, bias=use_bias),\n                nn.BatchNorm2d(self.n),\n                nl,\n            )\n            upsample_unit = nn.Sequential(\n                nn.ConvTranspose2d(\n                    self.n,\n                    self.n,\n                    upsample_filters,\n                    upsample_stride,\n                    upsample_pad,\n                    upsample_output_pad,\n                    bias=use_bias,\n                ),\n                nn.BatchNorm2d(self.n),\n                nl,\n                nn.Conv2d(self.n, self.n, same_filters, 1, same_pad, bias=use_bias),\n                nn.BatchNorm2d(self.n),\n                nl,\n            )\n        else:\n            self.fc = nn.Sequential(\n                nn.Linear(self.encoding_dims, (init_dim ** 2) * self.n), nl\n            )\n            initial_unit = nn.Sequential(\n                nn.Conv2d(self.n, self.n, same_filters, 1, same_pad, bias=use_bias),\n                nl,\n                nn.Conv2d(self.n, self.n, same_filters, 1, same_pad, bias=use_bias),\n                nl,\n            )\n            upsample_unit = nn.Sequential(\n                nn.ConvTranspose2d(\n                    self.n,\n                    self.n,\n                    upsample_filters,\n                    upsample_stride,\n                    upsample_pad,\n                    upsample_output_pad,\n                    bias=use_bias,\n                ),\n                nl,\n                nn.Conv2d(self.n, self.n, same_filters, 1, same_pad, bias=use_bias),\n                nl,\n            )\n\n        last_unit = nn.Sequential(\n            nn.Conv2d(self.n, self.ch, same_filters, 1, same_pad, bias=True), last_nl\n        )\n        model = [initial_unit]\n        for i in range(num_repeats):\n            model.append(upsample_unit)\n            out_size = out_size // scale_factor\n        model.append(last_unit)\n        self.model = nn.Sequential(*model)\n        self._weight_initializer()\n\n    def forward(self, z):\n        r""""""Calculates the output tensor on passing the encoding ``z`` through the Generator.\n\n        Args:\n            z (torch.Tensor): A 2D torch tensor of the encoding sampled from a probability\n                distribution.\n\n        Returns:\n            A 4D torch.Tensor of the generated image.\n        """"""\n        x = self.fc(z)\n        x = x.view(-1, self.n, self.init_dim, self.init_dim)\n        return self.model(x)\n\n\nclass AutoEncodingDiscriminator(Discriminator):\n    r""""""Autoencoding Generator for Boundary Equilibrium GAN (BEGAN) from\n    `""BEGAN : Boundary Equilibrium Generative Adversarial Networks\n    by Berthelot et. al."" <https://arxiv.org/abs/1703.10717>`_ paper\n\n    Args:\n        in_size (int, optional): Height and width of the input image to be evaluated. Must be at\n            least 16 and should be an exact power of 2.\n        in_channels (int, optional): Number of channels in the input Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        scale_factor (int, optional): The scale factor is used to infer properties of the model like\n            ``downsample_pad``, ``downsample_filters`` and ``downsample_stride``.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n        energy (bool, optional) : If set to True returns the energy instead of the decoder output.\n        embeddings (bool, optional) : If set to True the embeddings will be returned.\n        label_type (str, optional): The type of labels expected by the Generator. The available\n            choices are \'none\' if no label is needed, \'required\' if the original labels are\n            needed and \'generated\' if labels are to be sampled from a distribution.\n    """"""\n\n    def __init__(\n        self,\n        in_size=32,\n        in_channels=3,\n        encoding_dims=100,\n        step_channels=64,\n        scale_factor=2,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n        energy=True,\n        embeddings=False,\n        label_type=""none"",\n    ):\n        super(AutoEncodingDiscriminator, self).__init__(in_channels, label_type)\n        if in_size < (scale_factor ** 4) or ceil(log(in_size, scale_factor)) != log(\n            in_size, scale_factor\n        ):\n            raise Exception(\n                ""Input image size must be at least {} and a perfect power of {}"".format(\n                    scale_factor ** 4, scale_factor\n                )\n            )\n        num_repeats = int(log(in_size, scale_factor)) - 3\n        same_filters = scale_factor + 1\n        same_pad = scale_factor // 2\n        if scale_factor == 2:\n            downsample_filters = 3\n            downsample_stride = 2\n            downsample_pad = 1\n        else:\n            downsample_filters = scale_factor\n            downsample_stride = scale_factor\n            downsample_pad = 0\n        self.n = step_channels\n        nl = nn.ELU() if nonlinearity is None else nonlinearity\n        last_nl = nn.ELU() if last_nonlinearity is None else last_nonlinearity\n        use_bias = not batchnorm\n        init_dim = scale_factor ** 3\n        self.init_dim = init_dim\n        model = []\n        model.append(\n            nn.Sequential(\n                nn.Conv2d(\n                    self.input_dims, self.n, same_filters, 1, same_pad, bias=True\n                ),\n                nl,\n            )\n        )\n        if batchnorm is True:\n            for i in range(1, num_repeats + 1):\n                model.append(\n                    nn.Sequential(\n                        nn.Conv2d(\n                            self.n * i,\n                            self.n * i,\n                            same_filters,\n                            1,\n                            same_pad,\n                            bias=use_bias,\n                        ),\n                        nn.BatchNorm2d(self.n * i),\n                        nl,\n                        nn.Conv2d(\n                            self.n * i,\n                            self.n * (i + 1),\n                            downsample_filters,\n                            downsample_stride,\n                            downsample_pad,\n                            bias=use_bias,\n                        ),\n                        nn.BatchNorm2d(self.n * (i + 1)),\n                        nl,\n                    )\n                )\n            model.append(\n                nn.Sequential(\n                    nn.Conv2d(\n                        self.n * (num_repeats + 1),\n                        self.n * (num_repeats + 1),\n                        same_filters,\n                        1,\n                        same_pad,\n                        bias=use_bias,\n                    ),\n                    nn.BatchNorm2d(self.n * (num_repeats + 1)),\n                    nl,\n                    nn.Conv2d(\n                        self.n * (num_repeats + 1),\n                        self.n * (num_repeats + 1),\n                        same_filters,\n                        1,\n                        same_pad,\n                        bias=use_bias,\n                    ),\n                    nn.BatchNorm2d(self.n * (num_repeats + 1)),\n                    nl,\n                )\n            )\n            self.fc = nn.Sequential(\n                nn.Linear((init_dim ** 2) * (num_repeats + 1) * self.n, encoding_dims),\n                nn.BatchNorm1d(encoding_dims),\n                last_nl,\n            )\n        else:\n            for i in range(1, num_repeats + 1):\n                model.append(\n                    nn.Sequential(\n                        nn.Conv2d(self.n * i, self.n * i, 3, 1, 1, bias=use_bias),\n                        nl,\n                        nn.Conv2d(\n                            self.n * i,\n                            self.n * (i + 1),\n                            downsample_filters,\n                            downsample_stride,\n                            downsample_pad,\n                            bias=use_bias,\n                        ),\n                        nl,\n                    )\n                )\n            model.append(\n                nn.Sequential(\n                    nn.Conv2d(\n                        self.n * (num_repeats + 1),\n                        self.n * (num_repeats + 1),\n                        3,\n                        1,\n                        1,\n                        bias=use_bias,\n                    ),\n                    nl,\n                    nn.Conv2d(\n                        self.n * (num_repeats + 1),\n                        self.n * (num_repeats + 1),\n                        3,\n                        1,\n                        1,\n                        bias=use_bias,\n                    ),\n                    nl,\n                )\n            )\n            self.fc = nn.Sequential(\n                nn.Linear((init_dim ** 2) * (num_repeats + 1) * self.n, encoding_dims),\n                last_nl,\n            )\n        self.encoder = nn.Sequential(*model)\n        self.decoder = AutoEncodingGenerator(\n            encoding_dims,\n            in_size,\n            in_channels,\n            step_channels,\n            scale_factor,\n            batchnorm,\n            nonlinearity,\n            last_nonlinearity,\n        )\n        self.energy = energy\n        self.embeddings = embeddings\n        self._weight_initializer()\n\n    def forward(self, x, feature_matching=False):\n        r""""""Calculates the output tensor on passing the image ``x`` through the Discriminator.\n\n        Args:\n            x (torch.Tensor): A 4D torch tensor of the image.\n            feature_matching (bool, optional): Returns the activation from a predefined intermediate\n                layer.\n\n        Returns:\n            A 1D torch.Tensor of the energy value of each image.\n        """"""\n        x1 = self.encoder(x)\n        x2 = x1.view(-1, (self.init_dim ** 2) * x1.size(1))\n        x2 = self.fc(x2)\n        if feature_matching is True:\n            return x2\n        x2 = self.decoder(x2)\n        if self.energy:\n            x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n            x2 = x2.view(-1, x2.size(1) * x2.size(2) * x2.size(3))\n            if self.embeddings:\n                return x1, torch.mean((x - x2) ** 2, 1)\n            else:\n                return torch.mean((x - x2) ** 2, 1)\n        else:\n            if self.embeddings:\n                return x1, x2\n            else:\n                return x2\n'"
torchgan/models/conditional.py,18,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom .dcgan import DCGANDiscriminator, DCGANGenerator\n\n__all__ = [""ConditionalGANGenerator"", ""ConditionalGANDiscriminator""]\n\n\nclass ConditionalGANGenerator(DCGANGenerator):\n    r""""""Conditional GAN (CGAN) generator based on a DCGAN model from\n    `""Conditional Generative Adversarial Nets\n    by Mirza et. al. "" <https://arxiv.org/abs/1411.1784>`_ paper\n\n    Args:\n        num_classes (int): Total classes present in the dataset.\n        encoding_dims (int, optional): Dimension of the encoding vector sampled from the noise prior.\n        out_size (int, optional): Height and width of the input image to be generated. Must be at\n            least 16 and should be an exact power of 2.\n        out_channels (int, optional): Number of channels in the output Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n    """"""\n\n    def __init__(\n        self,\n        num_classes,\n        encoding_dims=100,\n        out_size=32,\n        out_channels=3,\n        step_channels=64,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n    ):\n        super(ConditionalGANGenerator, self).__init__(\n            encoding_dims + num_classes,\n            out_size,\n            out_channels,\n            step_channels,\n            batchnorm,\n            nonlinearity,\n            last_nonlinearity,\n            label_type=""generated"",\n        )\n        self.encoding_dims = encoding_dims\n        self.num_classes = num_classes\n        self.label_embeddings = nn.Embedding(self.num_classes, self.num_classes)\n\n    def forward(self, z, y):\n        r""""""Calculates the output tensor on passing the encoding ``z`` through the Generator.\n\n        Args:\n            z (torch.Tensor): A 2D torch tensor of the encoding sampled from a probability\n                distribution.\n            y (torch.Tensor): The labels corresponding to the encoding ``z``.\n\n        Returns:\n            A 4D torch.Tensor of the generated Images conditioned on ``y``.\n        """"""\n        y_emb = self.label_embeddings(y.type(torch.LongTensor).to(y.device))\n        return super(ConditionalGANGenerator, self).forward(\n            torch.cat((z, y_emb), dim=1)\n        )\n\n    def sampler(self, sample_size, device):\n        return [\n            torch.randn(sample_size, self.encoding_dims, device=device),\n            torch.randint(0, self.num_classes, (sample_size,), device=device),\n        ]\n\n\nclass ConditionalGANDiscriminator(DCGANDiscriminator):\n    r""""""Condititional GAN (CGAN) discriminator based on a DCGAN model from\n    `""Conditional Generative Adversarial Nets\n    by Mirza et. al. "" <https://arxiv.org/abs/1411.1784>`_ paper\n\n    Args:\n        num_classes (int): Total classes present in the dataset.\n        in_size (int, optional): Height and width of the input image to be evaluated. Must be at\n            least 16 and should be an exact power of 2.\n        in_channels (int, optional): Number of channels in the input Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n    """"""\n\n    def __init__(\n        self,\n        num_classes,\n        in_size=32,\n        in_channels=3,\n        step_channels=64,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n    ):\n        super(ConditionalGANDiscriminator, self).__init__(\n            in_size,\n            in_channels + num_classes,\n            step_channels,\n            batchnorm,\n            nonlinearity,\n            last_nonlinearity,\n            label_type=""required"",\n        )\n        self.input_dims = in_channels\n        self.num_classes = num_classes\n        self.label_embeddings = nn.Embedding(self.num_classes, self.num_classes)\n\n    def forward(self, x, y, feature_matching=False):\n        r""""""Calculates the output tensor on passing the image ``x`` through the Discriminator.\n\n        Args:\n            x (torch.Tensor): A 4D torch tensor of the image.\n            y (torch.Tensor): Labels corresponding to the images ``x``.\n            feature_matching (bool, optional): Returns the activation from a predefined intermediate\n                layer.\n\n        Returns:\n            A 1D torch.Tensor of the probability of each image being real.\n        """"""\n        # TODO(Aniket1998): If directly expanding the embeddings gives poor results,\n        # try layers of transposed convolution over the embeddings\n        y_emb = self.label_embeddings(y.type(torch.LongTensor).to(y.device))\n        y_emb = (\n            y_emb.unsqueeze(2)\n            .unsqueeze(3)\n            .expand(-1, y_emb.size(1), x.size(2), x.size(3))\n        )\n        return super(ConditionalGANDiscriminator, self).forward(\n            torch.cat((x, y_emb), dim=1), feature_matching=False\n        )\n'"
torchgan/models/dcgan.py,10,"b'from math import ceil, log2\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom .model import Discriminator, Generator\n\n__all__ = [""DCGANGenerator"", ""DCGANDiscriminator""]\n\n\nclass DCGANGenerator(Generator):\n    r""""""Deep Convolutional GAN (DCGAN) generator from\n    `""Unsupervised Representation Learning With Deep Convolutional Generative Aversarial Networks\n    by Radford et. al. "" <https://arxiv.org/abs/1511.06434>`_ paper\n\n    Args:\n        encoding_dims (int, optional): Dimension of the encoding vector sampled from the noise prior.\n        out_size (int, optional): Height and width of the input image to be generated. Must be at\n            least 16 and should be an exact power of 2.\n        out_channels (int, optional): Number of channels in the output Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n        label_type (str, optional): The type of labels expected by the Generator. The available\n            choices are \'none\' if no label is needed, \'required\' if the original labels are\n            needed and \'generated\' if labels are to be sampled from a distribution.\n    """"""\n\n    def __init__(\n        self,\n        encoding_dims=100,\n        out_size=32,\n        out_channels=3,\n        step_channels=64,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n        label_type=""none"",\n    ):\n        super(DCGANGenerator, self).__init__(encoding_dims, label_type)\n        if out_size < 16 or ceil(log2(out_size)) != log2(out_size):\n            raise Exception(\n                ""Target Image Size must be at least 16*16 and an exact power of 2""\n            )\n        num_repeats = out_size.bit_length() - 4\n        self.ch = out_channels\n        self.n = step_channels\n        use_bias = not batchnorm\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        last_nl = nn.Tanh() if last_nonlinearity is None else last_nonlinearity\n        model = []\n        d = int(self.n * (2 ** num_repeats))\n        if batchnorm is True:\n            model.append(\n                nn.Sequential(\n                    nn.ConvTranspose2d(self.encoding_dims, d, 4, 1, 0, bias=use_bias),\n                    nn.BatchNorm2d(d),\n                    nl,\n                )\n            )\n            for i in range(num_repeats):\n                model.append(\n                    nn.Sequential(\n                        nn.ConvTranspose2d(d, d // 2, 4, 2, 1, bias=use_bias),\n                        nn.BatchNorm2d(d // 2),\n                        nl,\n                    )\n                )\n                d = d // 2\n        else:\n            model.append(\n                nn.Sequential(\n                    nn.ConvTranspose2d(self.encoding_dims, d, 4, 1, 0, bias=use_bias),\n                    nl,\n                )\n            )\n            for i in range(num_repeats):\n                model.append(\n                    nn.Sequential(\n                        nn.ConvTranspose2d(d, d // 2, 4, 2, 1, bias=use_bias), nl\n                    )\n                )\n                d = d // 2\n\n        model.append(\n            nn.Sequential(nn.ConvTranspose2d(d, self.ch, 4, 2, 1, bias=True), last_nl)\n        )\n        self.model = nn.Sequential(*model)\n        self._weight_initializer()\n\n    def forward(self, x, feature_matching=False):\n        r""""""Calculates the output tensor on passing the encoding ``x`` through the Generator.\n\n        Args:\n            x (torch.Tensor): A 2D torch tensor of the encoding sampled from a probability\n                distribution.\n            feature_matching (bool, optional): Returns the activation from a predefined intermediate\n                layer.\n\n        Returns:\n            A 4D torch.Tensor of the generated image.\n        """"""\n        x = x.view(-1, x.size(1), 1, 1)\n        return self.model(x)\n\n\nclass DCGANDiscriminator(Discriminator):\n    r""""""Deep Convolutional GAN (DCGAN) discriminator from\n    `""Unsupervised Representation Learning With Deep Convolutional Generative Aversarial Networks\n    by Radford et. al. "" <https://arxiv.org/abs/1511.06434>`_ paper\n\n    Args:\n        in_size (int, optional): Height and width of the input image to be evaluated. Must be at\n            least 16 and should be an exact power of 2.\n        in_channels (int, optional): Number of channels in the input Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n        label_type (str, optional): The type of labels expected by the Generator. The available\n            choices are \'none\' if no label is needed, \'required\' if the original labels are\n            needed and \'generated\' if labels are to be sampled from a distribution.\n    """"""\n\n    def __init__(\n        self,\n        in_size=32,\n        in_channels=3,\n        step_channels=64,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n        label_type=""none"",\n    ):\n        super(DCGANDiscriminator, self).__init__(in_channels, label_type)\n        if in_size < 16 or ceil(log2(in_size)) != log2(in_size):\n            raise Exception(\n                ""Input Image Size must be at least 16*16 and an exact power of 2""\n            )\n        num_repeats = in_size.bit_length() - 4\n        self.n = step_channels\n        use_bias = not batchnorm\n        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n        last_nl = nn.LeakyReLU(0.2) if last_nonlinearity is None else last_nonlinearity\n        d = self.n\n        model = [nn.Sequential(nn.Conv2d(self.input_dims, d, 4, 2, 1, bias=True), nl)]\n        if batchnorm is True:\n            for i in range(num_repeats):\n                model.append(\n                    nn.Sequential(\n                        nn.Conv2d(d, d * 2, 4, 2, 1, bias=use_bias),\n                        nn.BatchNorm2d(d * 2),\n                        nl,\n                    )\n                )\n                d *= 2\n        else:\n            for i in range(num_repeats):\n                model.append(\n                    nn.Sequential(nn.Conv2d(d, d * 2, 4, 2, 1, bias=use_bias), nl)\n                )\n                d *= 2\n        self.disc = nn.Sequential(nn.Conv2d(d, 1, 4, 1, 0, bias=use_bias), last_nl)\n        self.model = nn.Sequential(*model)\n        self._weight_initializer()\n\n    def forward(self, x, feature_matching=False):\n        r""""""Calculates the output tensor on passing the image ``x`` through the Discriminator.\n\n        Args:\n            x (torch.Tensor): A 4D torch tensor of the image.\n            feature_matching (bool, optional): Returns the activation from a predefined intermediate\n                layer.\n\n        Returns:\n            A 1D torch.Tensor of the probability of each image being real.\n        """"""\n        x = self.model(x)\n        if feature_matching is True:\n            return x\n        else:\n            x = self.disc(x)\n            return x.view(x.size(0))\n'"
torchgan/models/infogan.py,14,"b'import torch\nimport torch.distributions as distributions\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom .dcgan import DCGANDiscriminator, DCGANGenerator\n\n__all__ = [""InfoGANGenerator"", ""InfoGANDiscriminator""]\n\n\nclass InfoGANGenerator(DCGANGenerator):\n    r""""""Generator for InfoGAN based on the Deep Convolutional GAN (DCGAN) architecture, from\n    `""InfoGAN : Interpretable Representation Learning With Information Maximizing Generative Aversarial Nets\n    by Chen et. al. "" <https://arxiv.org/abs/1606.03657>`_ paper\n\n    Args:\n        dim_dis (int): Dimension of the discrete latent code sampled from the prior.\n        dim_cont (int): Dimension of the continuous latent code sampled from the prior.\n        encoding_dims (int, optional): Dimension of the encoding vector sampled from the noise prior.\n        out_size (int, optional): Height and width of the input image to be generated. Must be at\n            least 16 and should be an exact power of 2.\n        out_channels (int, optional): Number of channels in the output Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n\n    Example:\n        >>> import torchgan.models as models\n        >>> G = models.InfoGANGenerator(10, 30)\n        >>> z = torch.randn(10, 100)\n        >>> c_cont = torch.randn(10, 10)\n        >>> c_dis = torch.randn(10, 30)\n        >>> x = G(z, c_cont, c_dis)\n    """"""\n\n    def __init__(\n        self,\n        dim_dis,\n        dim_cont,\n        encoding_dims=100,\n        out_size=32,\n        out_channels=3,\n        step_channels=64,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n    ):\n        super(InfoGANGenerator, self).__init__(\n            encoding_dims + dim_dis + dim_cont,\n            out_size,\n            out_channels,\n            step_channels,\n            batchnorm,\n            nonlinearity,\n            last_nonlinearity,\n        )\n        self.encoding_dims = encoding_dims\n        self.dim_cont = dim_cont\n        self.dim_dis = dim_dis\n\n    def forward(self, z, c_dis=None, c_cont=None):\n        z_cat = (\n            torch.cat([z, c_dis, c_cont], dim=1)\n            if c_dis is not None and c_cont is not None\n            else z\n        )\n        return super(InfoGANGenerator, self).forward(z_cat)\n\n\nclass InfoGANDiscriminator(DCGANDiscriminator):\n    r""""""Discriminator for InfoGAN based on the Deep Convolutional GAN (DCGAN) architecture, from\n    `""InfoGAN : Interpretable Representation Learning With Information Maximizing Generative Aversarial Nets\n    by Chen et. al. "" <https://arxiv.org/abs/1606.03657>`_ paper\n\n    The approximate conditional probability distribution over the latent code Q(c|x) is chosen to be a factored\n    Gaussian for the continuous latent code and a Categorical distribution for the discrete latent code\n\n    Args:\n        dim_dis (int): Dimension of the discrete latent code sampled from the prior.\n        dim_cont (int): Dimension of the continuous latent code sampled from the prior.\n        encoding_dims (int, optional): Dimension of the encoding vector sampled from the noise prior.\n        in_size (int, optional): Height and width of the input image to be evaluated. Must be at\n            least 16 and should be an exact power of 2.\n        in_channels (int, optional): Number of channels in the input Tensor.\n        step_channels (int, optional): Number of channels in multiples of which the DCGAN steps up\n            the convolutional features. The step up is done as dim :math:`z \\rightarrow d \\rightarrow\n            2 \\times d \\rightarrow 4 \\times d \\rightarrow 8 \\times d` where :math:`d` = step_channels.\n        batchnorm (bool, optional): If True, use batch normalization in the convolutional layers of\n            the generator.\n        nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the intermediate\n            convolutional layers. Defaults to ``LeakyReLU(0.2)`` when None is passed.\n        last_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the final\n            convolutional layer. Defaults to ``Tanh()`` when None is passed.\n        latent_nonlinearity (torch.nn.Module, optional): Nonlinearity to be used in the ``dist_conv``.\n            Defaults to ``LeakyReLU(0.2)`` when None is passed.\n    Example:\n        >>> import torchgan.models as models\n        >>> D = models.InfoGANDiscriminator(10, 30)\n        >>> x = torch.randn(10, 3, 32, 32)\n        >>> score, q_categorical, q_gaussian = D(x, return_latents=True)\n    """"""\n\n    def __init__(\n        self,\n        dim_dis,\n        dim_cont,\n        in_size=32,\n        in_channels=3,\n        step_channels=64,\n        batchnorm=True,\n        nonlinearity=None,\n        last_nonlinearity=None,\n        latent_nonlinearity=None,\n    ):\n        self.dim_cont = dim_cont\n        self.dim_dis = dim_dis\n        super(InfoGANDiscriminator, self).__init__(\n            in_size,\n            in_channels,\n            step_channels,\n            batchnorm,\n            nonlinearity,\n            last_nonlinearity,\n        )\n\n        self.latent_nl = (\n            nn.LeakyReLU(0.2) if latent_nonlinearity is None else latent_nonlinearity\n        )\n        d = self.n * 2 ** (in_size.bit_length() - 4)\n        if batchnorm is True:\n            self.dist_conv = nn.Sequential(\n                nn.Conv2d(d, d, 4, 1, 0, bias=not batchnorm),\n                nn.BatchNorm2d(d),\n                self.latent_nl,\n            )\n        else:\n            self.dist_conv = nn.Sequential(\n                nn.Conv2d(d, d, 4, 1, 0, bias=not batchnorm), self.latent_nl\n            )\n\n        self.dis_categorical = nn.Linear(d, self.dim_dis)\n\n        self.cont_mean = nn.Linear(d, self.dim_cont)\n        self.cont_logvar = nn.Linear(d, self.dim_cont)\n\n    def forward(self, x, return_latents=False, feature_matching=False):\n        x = self.model(x)\n        if feature_matching is True:\n            return x\n        critic_score = self.disc(x)\n        x = self.dist_conv(x).view(-1, x.size(1))\n        dist_dis = distributions.OneHotCategorical(logits=self.dis_categorical(x))\n        dist_cont = distributions.Normal(\n            loc=self.cont_mean(x), scale=torch.exp(0.5 * self.cont_logvar(x))\n        )\n        return (\n            critic_score,\n            dist_dis,\n            dist_cont if return_latents is True else critic_score,\n        )\n'"
torchgan/models/model.py,3,"b'import torch\nimport torch.nn as nn\n\n__all__ = [""Generator"", ""Discriminator""]\n\n\nclass Generator(nn.Module):\n    r""""""Base class for all Generator models. All Generator models must subclass this.\n\n    Args:\n        encoding_dims (int): Dimensions of the sample from the noise prior.\n        label_type (str, optional): The type of labels expected by the Generator. The available\n            choices are \'none\' if no label is needed, \'required\' if the original labels are\n            needed and \'generated\' if labels are to be sampled from a distribution.\n    """"""\n    # FIXME(Aniket1998): If a user is overriding the default initializer, he must also\n    # override the constructor. Find an efficient workaround by fixing the initialization mechanism\n    def __init__(self, encoding_dims, label_type=""none""):\n        super(Generator, self).__init__()\n        self.encoding_dims = encoding_dims\n        self.label_type = label_type\n\n    # TODO(Aniket1998): Think of better dictionary lookup based approaches to initialization\n    # That allows easy and customizable weight initialization without overriding\n    def _weight_initializer(self):\n        r""""""Default weight initializer for all generator models.\n        Models that require custom weight initialization can override this method\n        """"""\n        for m in self.modules():\n            if isinstance(m, nn.ConvTranspose2d):\n                nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1.0)\n                nn.init.constant_(m.bias, 0.0)\n\n    def sampler(self, sample_size, device):\n        r""""""Function to allow sampling data at inference time. Models requiring\n        input in any other format must override it in the subclass.\n\n        Args:\n            sample_size (int): The number of images to be generated\n            device (torch.device): The device on which the data must be generated\n\n        Returns:\n            A list of the items required as input\n        """"""\n        return [torch.randn(sample_size, self.encoding_dims, device=device)]\n\n\nclass Discriminator(nn.Module):\n    r""""""Base class for all Discriminator models. All Discriminator models must subclass this.\n\n    Args:\n        input_dims (int): Dimensions of the input.\n        label_type (str, optional): The type of labels expected by the Discriminator. The available\n            choices are \'none\' if no label is needed, \'required\' if the original labels are\n            needed and \'generated\' if labels are to be sampled from a distribution.\n    """"""\n\n    def __init__(self, input_dims, label_type=""none""):\n        super(Discriminator, self).__init__()\n        self.input_dims = input_dims\n        self.label_type = label_type\n\n    # TODO(Aniket1998): Think of better dictionary lookup based approaches to initialization\n    # That allows easy and customizable weight initialization without overriding\n    def _weight_initializer(self):\n        r""""""Default weight initializer for all disciminator models.\n        Models that require custom weight initialization can override this method\n        """"""\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1.0)\n                nn.init.constant_(m.bias, 0.0)\n'"
torchgan/trainer/__init__.py,0,b'from .base_trainer import *\nfrom .parallel_trainer import *\nfrom .trainer import *\n'
torchgan/trainer/base_trainer.py,7,"b'import os\nimport time\nfrom inspect import _empty, signature\nfrom warnings import warn\n\nimport torch\nimport torchvision\n\nfrom ..logging.logger import Logger\nfrom ..losses.loss import DiscriminatorLoss, GeneratorLoss\nfrom ..models.model import Discriminator, Generator\n\n__all__ = [""BaseTrainer""]\n\n\nclass BaseTrainer(object):\n    r""""""Base Trainer for TorchGANs.\n\n    .. warning::\n        This trainer is meant to form the base for all other Trainers. This is not meant for direct usage.\n\n    Features provided by this Base Trainer are:\n\n    - Loss and Metrics Logging via the ``Logger`` class.\n    - Generating Image Samples.\n    - Saving models at the end of every epoch and loading of previously saved models.\n    - Highly flexible and allows changing hyperparameters by simply adjusting the arguments.\n\n    Most of the functionalities provided by the Trainer are flexible enough and can be customized by\n    simply passing different arguments. You can train anything from a simple DCGAN to complex CycleGANs\n    without ever having to subclass this ``Trainer``.\n\n    Args:\n        losses_list (list): A list of the Loss Functions that need to be minimized. For a list of\n            pre-defined losses look at :mod:`torchgan.losses`. All losses in the list must be a\n            subclass of atleast ``GeneratorLoss`` or ``DiscriminatorLoss``.\n        metrics_list (list, optional): List of Metric Functions that need to be logged. For a list of\n            pre-defined metrics look at :mod:`torchgan.metrics`. All losses in the list must be a\n            subclass of ``EvaluationMetric``.\n        device (torch.device, optional): Device in which the operation is to be carried out. If you\n            are using a CPU machine make sure that you change it for proper functioning.\n        ncritic (int, optional): Setting it to a value will make the discriminator train that many\n            times more than the generator. If it is set to a negative value the generator will be\n            trained that many times more than the discriminator.\n        sample_size (int, optional): Total number of images to be generated at the end of an epoch\n            for logging purposes.\n        epochs (int, optional): Total number of epochs for which the models are to be trained.\n        checkpoints (str, optional): Path where the models are to be saved. The naming convention is\n            if checkpoints is ``./model/gan`` then models are saved as ``./model/gan0.model`` and so on.\n        retain_checkpoints (int, optional): Total number of checkpoints that should be retained. For\n            example, if the value is set to 3, we save at most 3 models and start rewriting the models\n            after that.\n        recon (str, optional): Directory where the sampled images are saved. Make sure the directory\n            exists from beforehand.\n        log_dir (str, optional): The directory for logging tensorboard. It is ignored if\n            TENSORBOARD_LOGGING is 0.\n        test_noise (torch.Tensor, optional): If provided then it will be used as the noise for image\n            sampling.\n        nrow (int, optional): Number of rows in which the image is to be stored.\n\n    Any other argument that you need to store in the object can be simply passed via keyword arguments.\n    """"""\n\n    def __init__(\n        self,\n        losses_list,\n        metrics_list=None,\n        device=torch.device(""cuda:0""),\n        ncritic=1,\n        epochs=5,\n        sample_size=8,\n        checkpoints=""./model/gan"",\n        retain_checkpoints=5,\n        recon=""./images"",\n        log_dir=None,\n        test_noise=None,\n        nrow=8,\n        **kwargs,\n    ):\n        self.device = device\n        self.losses = {}\n        for loss in losses_list:\n            self.losses[type(loss).__name__] = loss\n\n        if metrics_list is None:\n            self.metrics = None\n        else:\n            self.metrics = {}\n            for metric in metrics_list:\n                self.metrics[type(metric).__name__] = metric\n\n        self.sample_size = sample_size\n        self.epochs = epochs\n        self.checkpoints = checkpoints\n        self.retain_checkpoints = retain_checkpoints\n        self.recon = recon\n\n        # Not needed but we need to store this to avoid errors. Also makes life simpler\n        self.noise = None\n        self.real_inputs = None\n        self.labels = None\n        self.batch_size = 1\n\n        self.loss_information = {\n            ""generator_losses"": 0.0,\n            ""discriminator_losses"": 0.0,\n            ""generator_iters"": 0,\n            ""discriminator_iters"": 0,\n        }\n\n        assert ncritic != 0\n        if ncritic > 0:\n            self.ncritic = ncritic\n            self.ngen = 1\n        else:\n            self.ncritic = 1\n            self.ngen = abs(ncritic)\n\n        self.start_epoch = 0\n        self.last_retained_checkpoint = 0\n        for key, val in kwargs.items():\n            if key in self.__dict__:\n                warn(\n                    ""Overiding the default value of {} from {} to {}"".format(\n                        key, getattr(self, key), val\n                    )\n                )\n            setattr(self, key, val)\n\n        os.makedirs(self.checkpoints.rsplit(""/"", 1)[0], exist_ok=True)\n        os.makedirs(self.recon, exist_ok=True)\n\n    def save_model(self, epoch, save_items=None):\n        r""""""Function saves the model and some necessary information along with it. List of items\n        stored for future reference:\n\n        - Epoch\n        - Model States\n        - Optimizer States\n        - Loss Information\n        - Loss Objects\n        - Metric Objects\n        - Loss Logs\n\n        The save location is printed when this function is called.\n\n        Args:\n            epoch (int, optional): Epoch Number at which the model is being saved\n            save_items (str, list, optional): Pass the variable name of any other item you want to save.\n                The item must be present in the `__dict__` else training will come to an abrupt end.\n        """"""\n        if self.last_retained_checkpoint == self.retain_checkpoints:\n            self.last_retained_checkpoint = 0\n        save_path = self.checkpoints + str(self.last_retained_checkpoint) + "".model""\n        self.last_retained_checkpoint += 1\n        print(""Saving Model at \'{}\'"".format(save_path))\n        model = {\n            ""epoch"": epoch + 1,\n            ""loss_information"": self.loss_information,\n            ""loss_objects"": self.losses,\n            ""metric_objects"": self.metrics,\n            ""loss_logs"": (self.logger.get_loss_viz()).logs,\n        }\n        for save_item in self.model_names + self.optimizer_names:\n            model.update({save_item: (getattr(self, save_item)).state_dict()})\n        if save_items is not None:\n            if type(save_items) is list:\n                for itms in save_items:\n                    model.update({itms: getattr(self, itms)})\n            else:\n                model.update({save_items: getattr(self, save_items)})\n        torch.save(model, save_path)\n\n    def load_model(self, load_path="""", load_items=None):\n        r""""""Function to load the model and some necessary information along with it. List of items\n        loaded:\n\n        - Epoch\n        - Model States\n        - Optimizer States\n        - Loss Information\n        - Loss Objects\n        - Metric Objects\n        - Loss Logs\n\n        .. warning::\n            An Exception is raised if the model could not be loaded. Make sure that the model being\n            loaded was saved previously by ``torchgan Trainer`` itself. We currently do not support\n            loading any other form of models but this might be improved in the future.\n\n        Args:\n            load_path (str, optional): Path from which the model is to be loaded.\n            load_items (str, list, optional): Pass the variable name of any other item you want to load.\n                If the item cannot be found then a warning will be thrown and model will start to train\n                from scratch. So make sure that item was saved.\n        """"""\n        if load_path == """":\n            load_path = self.checkpoints + str(self.last_retained_checkpoint) + "".model""\n        print(""Loading Model From \'{}\'"".format(load_path))\n        try:\n            checkpoint = torch.load(load_path)\n            self.start_epoch = checkpoint[""epoch""]\n            self.losses = checkpoint[""loss_objects""]\n            self.metrics = checkpoint[""metric_objects""]\n            self.loss_information = checkpoint[""loss_information""]\n            (self.logger.get_loss_viz()).logs = checkpoint[""loss_logs""]\n            for load_item in self.model_names + self.optimizer_names:\n                getattr(self, load_item).load_state_dict(checkpoint[load_item])\n            if load_items is not None:\n                if type(load_items) is list:\n                    for itms in load_items:\n                        setattr(self, itms, checkpoint[""itms""])\n                else:\n                    setattr(self, load_items, checkpoint[""load_items""])\n        except:\n            raise Exception(""Model could not be loaded from {}."".format(load_path))\n\n    def _get_argument_maps(self, default_map, func):\n        r""""""Extracts the signature of the `func`. Then it returns the list of arguments that\n        are present in the object and need to be mapped and passed to the `func` when calling it.\n\n        Args:\n            default_map (dict): The keys of this dictionary override the function signature.\n            func (function): Function whose argument map is to be generated.\n\n        Returns:\n            List of arguments that need to be fed into the function. It contains all the positional\n            arguments and keyword arguments that are stored in the object. If any of the required\n            arguments are not present an error is thrown.\n        """"""\n        sig = signature(func)\n        arg_map = {}\n        for sig_param in sig.parameters.values():\n            arg = sig_param.name\n            arg_name = arg\n            if arg in default_map:\n                arg_name = default_map[arg]\n            if sig_param.default is not _empty:\n                if arg_name in self.__dict__:\n                    arg_map.update({arg: arg_name})\n            else:\n                if arg_name not in self.__dict__ and arg != ""kwargs"" and arg != ""args"":\n                    raise Exception(""Argument : {} not present."".format(arg_name))\n                else:\n                    arg_map.update({arg: arg_name})\n        return arg_map\n\n    def _store_metric_maps(self):\n        r""""""Creates a mapping between the metrics and the arguments from the object that need to be\n        passed to it.\n        """"""\n        if self.metrics is not None:\n            self.metric_arg_maps = {}\n            for name, metric in self.metrics.items():\n                self.metric_arg_maps[name] = self._get_argument_maps(\n                    metric.arg_map, metric.metric_ops\n                )\n\n    def _store_loss_maps(self):\n        r""""""Creates a mapping between the losses and the arguments from the object that need to be\n        passed to it.\n        """"""\n        self.loss_arg_maps = {}\n        for name, loss in self.losses.items():\n            self.loss_arg_maps[name] = self._get_argument_maps(\n                loss.arg_map, loss.train_ops\n            )\n\n    def _get_arguments(self, arg_map):\n        r""""""Get the argument values from the object and create a dictionary.\n\n        Args:\n            arg_map (dict): A dict of arguments that is generated by `_get_argument_maps`.\n\n        Returns:\n            A dictionary mapping the argument name to the value of the argument.\n        """"""\n        args = {}\n        for key, val in arg_map.items():\n            args[key] = self.__dict__[val]\n        return args\n\n    def train_iter_custom(self):\n        r""""""Function that needs to be extended if ``train_iter`` is to be modified. Use this function\n        to perform any sort of initialization that need to be done at the beginning of any train\n        iteration. Refer the model zoo and tutorials for more details on how to write this function.\n        """"""\n        pass\n\n    # TODO(avik-pal): Clean up this function and avoid returning values\n    def train_iter(self):\n        r""""""Calls the train_ops of the loss functions. This is the core function of the Trainer. In most\n        cases you will never have the need to extend this function. In extreme cases simply extend\n        ``train_iter_custom``.\n\n        .. warning::\n            This function is needed in this exact state for the Trainer to work correctly. So it is\n            highly recommended that this function is not changed even if the ``Trainer`` is subclassed.\n\n        Returns:\n            An NTuple of the ``generator loss``, ``discriminator loss``, ``number of times the generator\n            was trained`` and the ``number of times the discriminator was trained``.\n        """"""\n        self.train_iter_custom()\n        ldis, lgen, dis_iter, gen_iter = 0.0, 0.0, 0, 0\n        loss_logs = self.logger.get_loss_viz()\n        grad_logs = self.logger.get_grad_viz()\n        for name, loss in self.losses.items():\n            if isinstance(loss, GeneratorLoss) and isinstance(loss, DiscriminatorLoss):\n                # NOTE(avik-pal): In most cases this loss is meant to optimize the Discriminator\n                #                 but we might need to think of a better solution\n                if self.loss_information[""generator_iters""] % self.ngen == 0:\n                    cur_loss = loss.train_ops(\n                        **self._get_arguments(self.loss_arg_maps[name])\n                    )\n                    loss_logs.logs[name].append(cur_loss)\n                    if type(cur_loss) is tuple:\n                        lgen, ldis, gen_iter, dis_iter = (\n                            lgen + cur_loss[0],\n                            ldis + cur_loss[1],\n                            gen_iter + 1,\n                            dis_iter + 1,\n                        )\n                    else:\n                        # NOTE(avik-pal): We assume that it is a Discriminator Loss by default.\n                        ldis, dis_iter = ldis + cur_loss, dis_iter + 1\n                for model_name in self.model_names:\n                    grad_logs.update_grads(model_name, getattr(self, model_name))\n            elif isinstance(loss, GeneratorLoss):\n                if self.loss_information[""discriminator_iters""] % self.ncritic == 0:\n                    cur_loss = loss.train_ops(\n                        **self._get_arguments(self.loss_arg_maps[name])\n                    )\n                    loss_logs.logs[name].append(cur_loss)\n                    lgen, gen_iter = lgen + cur_loss, gen_iter + 1\n                for model_name in self.model_names:\n                    model = getattr(self, model_name)\n                    if isinstance(model, Generator):\n                        grad_logs.update_grads(model_name, model)\n            elif isinstance(loss, DiscriminatorLoss):\n                if self.loss_information[""generator_iters""] % self.ngen == 0:\n                    cur_loss = loss.train_ops(\n                        **self._get_arguments(self.loss_arg_maps[name])\n                    )\n                    loss_logs.logs[name].append(cur_loss)\n                    ldis, dis_iter = ldis + cur_loss, dis_iter + 1\n                for model_name in self.model_names:\n                    model = getattr(self, model_name)\n                    if isinstance(model, Discriminator):\n                        grad_logs.update_grads(model_name, model)\n        return lgen, ldis, gen_iter, dis_iter\n\n    def eval_ops(self, **kwargs):\n        r""""""Runs all evaluation operations at the end of every epoch. It calls all the metric functions\n        that are passed to the Trainer.\n        """"""\n        if self.metrics is not None:\n            for name, metric in self.metrics.items():\n                metric_logs = self.logger.get_metric_viz()\n                metric_logs.logs[name].append(\n                    metric.metric_ops(**self._get_arguments(self.metric_arg_maps[name]))\n                )\n\n    def optim_ops(self):\n        r""""""Runs all the schedulers at the end of every epoch.\n        """"""\n        for scheduler in self.schedulers:\n            scheduler.step()\n\n    def train(self, data_loader, **kwargs):\n        r""""""Uses the information passed by the user while creating the object and trains the model.\n        It iterates over the epochs and the DataLoader and calls the functions for training the models\n        and logging the required variables.\n\n        .. note::\n            Even though ``__call__`` calls this function, it is best if ``train`` is not called directly.\n            When ``__call__`` is invoked, we infer the ``batch_size`` from the ``data_loader``. Also,\n            we are certain not going to change the interface of the ``__call__`` function so it gives\n            the user a stable API, while we can change the flow of execution of ``train`` in future.\n\n        .. warning::\n            The user should never try to change this function in subclass. It is too delicate and\n            changing affects every other function present in this ``Trainer`` class.\n\n        This function controls the execution of all the components of the ``Trainer``. It controls the\n        ``logger``, ``train_iter``, ``save_model``, ``eval_ops`` and ``optim_ops``.\n\n        Args:\n            data_loader (torch.utils.data.DataLoader): A DataLoader for the trainer to iterate over\n                and train the models.\n        """"""\n        for name in self.optimizer_names:\n            getattr(self, name).zero_grad()\n\n        for epoch in range(self.start_epoch, self.epochs):\n\n            start_time = time.time()\n\n            for model in self.model_names:\n                getattr(self, model).train()\n\n            for data in data_loader:\n\n                if type(data) is tuple or type(data) is list:\n                    self.real_inputs = data[0].to(self.device)\n                    self.labels = data[1].to(self.device)\n                elif type(data) is torch.Tensor:\n                    self.real_inputs = data.to(self.device)\n                else:\n                    self.real_inputs = data\n\n                lgen, ldis, gen_iter, dis_iter = self.train_iter()\n                self.loss_information[""generator_losses""] += lgen\n                self.loss_information[""discriminator_losses""] += ldis\n                self.loss_information[""generator_iters""] += gen_iter\n                self.loss_information[""discriminator_iters""] += dis_iter\n\n                self.logger.run_mid_epoch(self)\n\n            if ""save_items"" in kwargs:\n                self.save_model(epoch, kwargs[""save_items""])\n            else:\n                self.save_model(epoch)\n\n            for model in self.model_names:\n                getattr(self, model).eval()\n\n            self.eval_ops(**kwargs)\n            self.logger.run_end_epoch(self, epoch, time.time() - start_time)\n            self.optim_ops()\n\n        print(""Training of the Model is Complete"")\n\n    def complete(self, **kwargs):\n        r""""""Marks the end of training. It saves the final model and turns off the logger.\n\n        .. note::\n            It is not necessary to call this function. If it is not called the logger is kept\n            alive in the background. So it might be considered a good practice to call this\n            function.\n        """"""\n        if ""save_items"" in kwargs:\n            self.save_model(-1, kwargs[""save_items""])\n        else:\n            self.save_model(-1)\n        self.logger.close()\n\n    def __call__(self, data_loader, **kwargs):\n        self.batch_size = data_loader.batch_size\n        self.train(data_loader, **kwargs)\n'"
torchgan/trainer/parallel_trainer.py,2,"b'import torch\n\nfrom ..logging.logger import Logger\nfrom ..losses.loss import DiscriminatorLoss, GeneratorLoss\nfrom ..models.model import Discriminator, Generator\nfrom .base_trainer import BaseTrainer\n\n__all__ = [""ParallelTrainer""]\n\n\nclass ParallelTrainer(BaseTrainer):\n    r""""""MultiGPU Trainer for GANs. Use the ``Trainer`` class for training on a single GPU or a CPU\n    machine.\n\n    Args:\n        models (dict): A dictionary containing a mapping between the variable name, storing the\n            ``generator``, ``discriminator`` and any other model that you might want to define, with the\n            function and arguments that are needed to construct the model. Refer to the examples to\n            see how to define complex models using this API.\n        losses_list (list): A list of the Loss Functions that need to be minimized. For a list of\n            pre-defined losses look at :mod:`torchgan.losses`. All losses in the list must be a\n            subclass of atleast ``GeneratorLoss`` or ``DiscriminatorLoss``.\n        devices (list): Devices in which the operations are to be carried out. If you\n            are using a CPU machine or a single GPU machine use the Trainer class.\n        metrics_list (list, optional): List of Metric Functions that need to be logged. For a list of\n            pre-defined metrics look at :mod:`torchgan.metrics`. All losses in the list must be a\n            subclass of ``EvaluationMetric``.\n        ncritic (int, optional): Setting it to a value will make the discriminator train that many\n            times more than the generator. If it is set to a negative value the generator will be\n            trained that many times more than the discriminator.\n        sample_size (int, optional): Total number of images to be generated at the end of an epoch\n            for logging purposes.\n        epochs (int, optional): Total number of epochs for which the models are to be trained.\n        checkpoints (str, optional): Path where the models are to be saved. The naming convention is\n            if checkpoints is ``./model/gan`` then models are saved as ``./model/gan0.model`` and so on.\n        retain_checkpoints (int, optional): Total number of checkpoints that should be retained. For\n            example, if the value is set to 3, we save at most 3 models and start rewriting the models\n            after that.\n        recon (str, optional): Directory where the sampled images are saved. Make sure the directory\n            exists from beforehand.\n        log_dir (str, optional): The directory for logging tensorboard. It is ignored if\n            TENSORBOARD_LOGGING is 0.\n        test_noise (torch.Tensor, optional): If provided then it will be used as the noise for image\n            sampling.\n        nrow (int, optional): Number of rows in which the image is to be stored.\n\n    Any other argument that you need to store in the object can be simply passed via keyword arguments.\n\n    Example:\n        >>> dcgan = ParallelTrainer(\n                    {""generator"": {""name"": DCGANGenerator, ""args"": {""out_channels"": 1, ""step_channels"":\n                                   16}, ""optimizer"": {""name"": Adam, ""args"": {""lr"": 0.0002,\n                                   ""betas"": (0.5, 0.999)}}},\n                     ""discriminator"": {""name"": DCGANDiscriminator, ""args"": {""in_channels"": 1,\n                                       ""step_channels"": 16}, ""optimizer"": {""var"": ""opt_discriminator"",\n                                       ""name"": Adam, ""args"": {""lr"": 0.0002, ""betas"": (0.5, 0.999)}}}},\n                    [MinimaxGeneratorLoss(), MinimaxDiscriminatorLoss()],\n                    [0, 1, 2],\n                    sample_size=64, epochs=20)\n    """"""\n\n    def __init__(\n        self,\n        models,\n        losses_list,\n        devices,\n        metrics_list=None,\n        ncritic=1,\n        epochs=5,\n        sample_size=8,\n        checkpoints=""./model/gan"",\n        retain_checkpoints=5,\n        recon=""./images"",\n        log_dir=None,\n        test_noise=None,\n        nrow=8,\n        **kwargs\n    ):\n        super(ParallelTrainer, self).__init__(\n            losses_list,\n            metrics_list=metrics_list,\n            device=devices[0],\n            ncritic=ncritic,\n            epochs=epochs,\n            sample_size=sample_size,\n            checkpoints=checkpoints,\n            retain_checkpoints=retain_checkpoints,\n            recon=recon,\n            log_dir=log_dir,\n            test_noise=test_noise,\n            nrow=nrow,\n            **kwargs\n        )\n\n        self.devices = devices\n        self.model_names = []\n        self.optimizer_names = []\n        self.schedulers = []\n        for key, model in models.items():\n            self.model_names.append(key)\n            if ""args"" in model:\n                setattr(self, key, (model[""name""](**model[""args""])).to(self.device))\n            else:\n                setattr(self, key, (model[""name""]()).to(self.device))\n            for m in getattr(self, key)._modules:\n                getattr(self, key)._modules[m] = torch.nn.DataParallel(\n                    getattr(self, key)._modules[m], device_ids=devices\n                )\n            opt = model[""optimizer""]\n            opt_name = ""optimizer_{}"".format(key)\n            if ""var"" in opt:\n                opt_name = opt[""var""]\n            self.optimizer_names.append(opt_name)\n            model_params = getattr(self, key).parameters()\n            if ""args"" in opt:\n                setattr(self, opt_name, (opt[""name""](model_params, **opt[""args""])))\n            else:\n                setattr(self, opt_name, (opt[""name""](model_params)))\n            if ""scheduler"" in opt:\n                sched = opt[""scheduler""]\n                if ""args"" in sched:\n                    self.schedulers.append(\n                        sched[""name""](getattr(self, opt_name), **sched[""args""])\n                    )\n                else:\n                    self.schedulers.append(sched[""name""](getattr(self, opt_name)))\n\n        self.logger = Logger(\n            self,\n            losses_list,\n            metrics_list,\n            log_dir=log_dir,\n            nrow=nrow,\n            test_noise=test_noise,\n        )\n\n        self._store_loss_maps()\n        self._store_metric_maps()\n'"
torchgan/trainer/trainer.py,3,"b'import torch\n\nfrom ..logging.logger import Logger\nfrom ..losses.loss import DiscriminatorLoss, GeneratorLoss\nfrom ..models.model import Discriminator, Generator\nfrom .base_trainer import BaseTrainer\n\n__all__ = [""Trainer""]\n\n\nclass Trainer(BaseTrainer):\n    r""""""Standard Trainer for various GANs. This has been designed to work only on one GPU in case\n    you are using a GPU.\n\n    Most of the functionalities provided by the Trainer are flexible enough and can be customized by\n    simply passing different arguments. You can train anything from a simple DCGAN to complex CycleGANs\n    without ever having to subclass this ``Trainer``.\n\n    Args:\n        models (dict): A dictionary containing a mapping between the variable name, storing the\n            ``generator``, ``discriminator`` and any other model that you might want to define, with the\n            function and arguments that are needed to construct the model. Refer to the examples to\n            see how to define complex models using this API.\n        losses_list (list): A list of the Loss Functions that need to be minimized. For a list of\n            pre-defined losses look at :mod:`torchgan.losses`. All losses in the list must be a\n            subclass of atleast ``GeneratorLoss`` or ``DiscriminatorLoss``.\n        metrics_list (list, optional): List of Metric Functions that need to be logged. For a list of\n            pre-defined metrics look at :mod:`torchgan.metrics`. All losses in the list must be a\n            subclass of ``EvaluationMetric``.\n        device (torch.device, optional): Device in which the operation is to be carried out. If you\n            are using a CPU machine make sure that you change it for proper functioning.\n        ncritic (int, optional): Setting it to a value will make the discriminator train that many\n            times more than the generator. If it is set to a negative value the generator will be\n            trained that many times more than the discriminator.\n        sample_size (int, optional): Total number of images to be generated at the end of an epoch\n            for logging purposes.\n        epochs (int, optional): Total number of epochs for which the models are to be trained.\n        checkpoints (str, optional): Path where the models are to be saved. The naming convention is\n            if checkpoints is ``./model/gan`` then models are saved as ``./model/gan0.model`` and so on.\n        retain_checkpoints (int, optional): Total number of checkpoints that should be retained. For\n            example, if the value is set to 3, we save at most 3 models and start rewriting the models\n            after that.\n        recon (str, optional): Directory where the sampled images are saved. Make sure the directory\n            exists from beforehand.\n        log_dir (str, optional): The directory for logging tensorboard. It is ignored if\n            TENSORBOARD_LOGGING is 0.\n        test_noise (torch.Tensor, optional): If provided then it will be used as the noise for image\n            sampling.\n        nrow (int, optional): Number of rows in which the image is to be stored.\n\n    Any other argument that you need to store in the object can be simply passed via keyword arguments.\n\n    Example:\n        >>> dcgan = Trainer(\n                    {""generator"": {""name"": DCGANGenerator, ""args"": {""out_channels"": 1, ""step_channels"":\n                                   16}, ""optimizer"": {""name"": Adam, ""args"": {""lr"": 0.0002,\n                                   ""betas"": (0.5, 0.999)}}},\n                     ""discriminator"": {""name"": DCGANDiscriminator, ""args"": {""in_channels"": 1,\n                                       ""step_channels"": 16}, ""optimizer"": {""var"": ""opt_discriminator"",\n                                       ""name"": Adam, ""args"": {""lr"": 0.0002, ""betas"": (0.5, 0.999)}}}},\n                    [MinimaxGeneratorLoss(), MinimaxDiscriminatorLoss()],\n                    sample_size=64, epochs=20)\n    """"""\n\n    def __init__(\n        self,\n        models,\n        losses_list,\n        metrics_list=None,\n        device=torch.device(""cuda:0""),\n        ncritic=1,\n        epochs=5,\n        sample_size=8,\n        checkpoints=""./model/gan"",\n        retain_checkpoints=5,\n        recon=""./images"",\n        log_dir=None,\n        test_noise=None,\n        nrow=8,\n        **kwargs\n    ):\n        super(Trainer, self).__init__(\n            losses_list,\n            metrics_list=metrics_list,\n            device=device,\n            ncritic=ncritic,\n            epochs=epochs,\n            sample_size=sample_size,\n            checkpoints=checkpoints,\n            retain_checkpoints=retain_checkpoints,\n            recon=recon,\n            log_dir=log_dir,\n            test_noise=test_noise,\n            nrow=nrow,\n            **kwargs\n        )\n        self.model_names = []\n        self.optimizer_names = []\n        self.schedulers = []\n        for key, model in models.items():\n            self.model_names.append(key)\n            if ""args"" in model:\n                setattr(self, key, (model[""name""](**model[""args""])).to(self.device))\n            else:\n                setattr(self, key, (model[""name""]()).to(self.device))\n            opt = model[""optimizer""]\n            opt_name = ""optimizer_{}"".format(key)\n            if ""var"" in opt:\n                opt_name = opt[""var""]\n            self.optimizer_names.append(opt_name)\n            model_params = getattr(self, key).parameters()\n            if ""args"" in opt:\n                setattr(self, opt_name, (opt[""name""](model_params, **opt[""args""])))\n            else:\n                setattr(self, opt_name, (opt[""name""](model_params)))\n            if ""scheduler"" in opt:\n                sched = opt[""scheduler""]\n                if ""args"" in sched:\n                    self.schedulers.append(\n                        sched[""name""](getattr(self, opt_name), **sched[""args""])\n                    )\n                else:\n                    self.schedulers.append(sched[""name""](getattr(self, opt_name)))\n\n        self.logger = Logger(\n            self,\n            losses_list,\n            metrics_list,\n            log_dir=log_dir,\n            nrow=nrow,\n            test_noise=test_noise,\n        )\n\n        self._store_loss_maps()\n        self._store_metric_maps()\n'"
