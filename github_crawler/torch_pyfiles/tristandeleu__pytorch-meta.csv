file_path,api_count,code
setup.py,0,"b""from setuptools import setup, find_packages\nfrom os import path\nimport sys\n\nfrom io import open\n\nextras = {\n    'tcga': ['pandas~=0.24.0', 'academictorrents~=2.1.0', 'six~=1.11.0'],\n}\n\nhere = path.abspath(path.dirname(__file__))\n\nsys.path.insert(0, path.join(here, 'torchmeta'))\nfrom version import VERSION\n\n# Get the long description from the README file\nwith open(path.join(here, 'README.md'), encoding='utf-8') as f:\n    long_description = f.read()\n\nsetup(\n    name='torchmeta',\n    version=VERSION,\n    description='Dataloaders for meta-learning in Pytorch',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    license='MIT',\n    author='Tristan Deleu',\n    author_email='tristan.deleu@gmail.com',\n    url='https://github.com/tristandeleu/pytorch-meta',\n    keywords=['meta-learning', 'pytorch', 'few-shot', 'few-shot learning'],\n    packages=find_packages(exclude=['data', 'contrib', 'docs', 'tests', 'examples']),\n    install_requires=[\n        'torch>=1.4.0,<1.6.0',\n        'torchvision>=0.5.0,<0.7.0',\n        'numpy>=1.14.0',\n        'Pillow>=7.0.0',\n        'h5py',\n        'tqdm>=4.0.0',\n        'requests' # Required by Torchvision\n    ],\n    extras_require=extras,\n    package_data={'torchmeta': ['torchmeta/datasets/assets/*']},\n    include_package_data=True,\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'Intended Audience :: Science/Research',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n        'Programming Language :: Python :: 3.7',\n        'License :: OSI Approved :: MIT License',\n    ],\n)\n"""
torchmeta/__init__.py,0,b'from torchmeta import datasets\nfrom torchmeta import modules\nfrom torchmeta import toy\nfrom torchmeta import transforms\nfrom torchmeta import utils\n\nfrom torchmeta.version import VERSION as __version__\n'
torchmeta/version.py,0,"b""VERSION = '1.4.4'"""
docs/scripts/api_reference.py,2,"b'import importlib\nimport inspect\nimport re\nimport yaml\nimport logging\nimport torch.nn as nn\n\nLAST_CHARACTER = re.compile(r\'^[\\w\\.,\\""\\`]$\')\nHEADER = re.compile(r\'^\\-+$\')\nREFERENCE = re.compile(r\'^\\.\\. \\[(\\d)+\\] (.+)$\')\n\ndef format_signature(string, maxlen=77):\n    """"""Format the signature of the function, with line breaks after\n    `maxlen + 3` characters.""""""\n    line, *elements = string.split(\', \')\n    lines = []\n    while elements:\n        elem, *elements = elements\n        if len(line) + len(elem) < maxlen:\n            line = \'{0}, {1}\'.format(line, elem)\n        else:\n            lines.append(\'{0},\'.format(line))\n            line = \'    {0}\'.format(elem)\n    if line:\n        lines.append(line)\n    return \'```python\\n{0}\\n```\'.format(\'\\n\'.join(lines))\n\ndef format_parameters(section):\n    """"""Format the ""Parameters"" section.""""""\n    def format_item(item):\n        item = map(lambda x: x.strip(), item)\n        return \' - **{0}**: *{1}*\\n {2}\'.format(*item)\n    return \'**Parameters**\\n\\n{0}\'.format(\'\\n\\n\'.join(\n        map(format_item, section)))\n\ndef format_notes(section):\n    """"""Format the ""Notes"" section.""""""\n    assert len(section) == 1\n    return \'!!! note ""Notes""\\n    {0}\'.format(section[0].strip())\n\ndef format_references(section):\n    """"""Format the ""References"" section.""""""\n    def format_item(item):\n        return \'    - **[{0}]** {1}\'.format(item[0], item[1].strip())\n    return \'!!! attention ""References""\\n{0}\'.format(\'\\n\'.join(\n        map(format_item, section)))\n\ndef format_docs(module, kls):\n    """"""Format the documentation for a module.""""""\n    assert getattr(kls, \'__doc__\') is not None\n    markdown = [\'## {0}\'.format(kls.__name__)]\n    sections = parse_docs(kls.__doc__)\n    for header, section in sections:\n        if header is None:\n            # Add special case for inherited documentation\n            if len(sections) > 1:\n                markdown.append(section[0].strip())\n            signature = \'{0}.{1}{2}\'.format(module.__name__, kls.__name__,\n                str(inspect.signature(kls)))\n            markdown.append(format_signature(signature))\n            if len(sections) == 1 and any(c is nn.Module\n                    for c in inspect.getmro(kls)):\n                markdown.append(format_notes([\'See: `torch.nn.{0}`\'.format(\n                    kls.__name__[4:])]))\n        elif header == \'Parameters\':\n            markdown.append(format_parameters(section))\n        elif header == \'Notes\':\n            markdown.append(format_notes(section))\n        elif header == \'References\':\n            markdown.append(format_references(section))\n    return \'\\n\\n\'.join(markdown)\n\ndef merge_lines(line_1, line_2):\n    """"""Merge two consecutive lines, depending on the last character of\n    the first line.""""""\n    if not line_1:\n        return line_2\n    pattern = \'{0} {1}\' if LAST_CHARACTER.match(line_1[-1]) else \'{0}{1}\'\n    return pattern.format(line_1, line_2)\n\ndef parse_docs(docs):\n    """"""Parse the docs as a string into multiple sections.""""""\n    lines = inspect.cleandoc(docs).split(\'\\n\')\n    sections, section = [], []\n    last_header, element = None, None\n    for i, line in enumerate(lines):\n        if not line:\n            line = \'\\n\'\n        if HEADER.match(line):\n            continue\n\n        if (i < (len(lines) - 1)) and HEADER.match(lines[i + 1]):\n            if element is not None:\n                section.append(element)\n                element = None\n            sections.append((last_header, section))\n            section = []\n            last_header = line\n            continue\n\n        if (last_header is None) or (last_header == \'Notes\'):\n            if not section:\n                section = [line]\n            else:\n                section[0] = merge_lines(section[0], line.strip(\' \'))\n\n        elif last_header == \'Parameters\':\n            if line[:4].strip():\n                if element is not None:\n                    section.append(element)\n                element = line.split(\':\', 1) + [\'\']\n            else:\n                element[2] = merge_lines(element[2], line[4:])\n\n        elif last_header == \'References\':\n            if line[:2] == \'..\':\n                if element is not None:\n                    section.append(element)\n                match = REFERENCE.match(line)\n                element = [int(match[1]), match[2]]\n            else:\n                element[1] = merge_lines(element[1], line.strip())\n\n    if element is not None:\n        section.append(element)\n    sections.append((last_header, section))\n\n    return sections\n\ndef main(args):\n    logging.basicConfig(level=logging.INFO if args.verbose else logging.WARNING)\n\n    with open(args.config, \'r\') as f:\n        config = yaml.safe_load(f)\n\n    for page in config[\'api-reference\']:\n        filename = next(iter(page))\n        name, apis = page[filename][0][\'name\'], page[filename][1][\'content\']\n        content = []\n        logging.info(\'Creating `{0}`...\'.format(filename))\n\n        for api in apis:\n            module_name = next(iter(api))\n            module = importlib.import_module(module_name)\n            class_names = api[module_name]\n\n            if (len(class_names) == 1) and (class_names[0] == \'__all__\'):\n                class_names = getattr(module, \'__all__\')\n                if class_names is None:\n                    continue\n\n            for class_name in class_names:\n                kls = getattr(module, class_name)\n                if getattr(kls, \'__doc__\') is None:\n                    continue\n                logging.info(\'  {0}.{1}\'.format(module_name, class_name))\n                content.append(format_docs(module, kls))\n\n        with open(filename, \'w\') as f:\n            f.write(\'\\n\\n\'.join(content))\n\nif __name__ == \'__main__\':\n    import argparse\n\n    parser = argparse.ArgumentParser(\'Torchmeta API reference\')\n    parser.add_argument(\'--config\', type=str, default=\'docs/scripts/config.yml\',\n                        help=\'Path to the configuration file.\')\n    parser.add_argument(\'--verbose\', action=\'store_true\')\n    args = parser.parse_args()\n\n    main(args)\n'"
docs/scripts/index.py,0,"b""import logging\n\ndef main(args):\n    logging.basicConfig(level=logging.INFO if args.verbose else logging.WARNING)\n\n    with open('README.md', encoding='utf-8') as f:\n        long_description = f.read()\n\n    with open('docs/index.md', 'w') as f:\n        f.write(long_description)\n\nif __name__ == '__main__':\n    import argparse\n\n    parser = argparse.ArgumentParser('Torchmeta Doc Index')\n    parser.add_argument('--verbose', action='store_true')\n    args = parser.parse_args()\n\n    main(args)\n"""
examples/anil/model.py,2,"b""import torch.nn as nn\nfrom torchmeta.modules import MetaModule, MetaLinear\nfrom torchmeta.modules.utils import get_subdict\n\ndef conv3x3(in_channels, out_channels, **kwargs):\n    # The convolutional layers (for feature extraction) use standard layers from\n    # `torch.nn`, since they do not require adaptation.\n    # See `examples/maml/model.py` for comparison.\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n        nn.BatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n\nclass ConvolutionalNeuralNetwork(MetaModule):\n    def __init__(self, in_channels, out_features, hidden_size=64):\n        super(ConvolutionalNeuralNetwork, self).__init__()\n        self.in_channels = in_channels\n        self.out_features = out_features\n        self.hidden_size = hidden_size\n\n        self.features = nn.Sequential(\n            conv3x3(in_channels, hidden_size),\n            conv3x3(hidden_size, hidden_size),\n            conv3x3(hidden_size, hidden_size),\n            conv3x3(hidden_size, hidden_size)\n        )\n\n        # Only the last (linear) layer is used for adaptation in ANIL\n        self.classifier = MetaLinear(hidden_size, out_features)\n\n    def forward(self, inputs, params=None):\n        features = self.features(inputs)\n        features = features.view((features.size(0), -1))\n        logits = self.classifier(features, params=get_subdict(params, 'classifier'))\n        return logits\n"""
examples/anil/train.py,8,"b'import os\nimport torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport logging\n\nfrom torchmeta.datasets.helpers import omniglot\nfrom torchmeta.utils.data import BatchMetaDataLoader\nfrom torchmeta.utils.gradient_based import gradient_update_parameters\n\nfrom model import ConvolutionalNeuralNetwork\nfrom utils import get_accuracy\n\nlogger = logging.getLogger(__name__)\n\n\ndef train(args):\n    # Training script identical to MAML, see `examples/maml/train.py`\n    logger.warning(\'This script is an example to showcase the MetaModule and \'\n                   \'data-loading features of Torchmeta, and as such has been \'\n                   \'very lightly tested.\')\n\n    dataset = omniglot(args.folder,\n                       shots=args.num_shots,\n                       ways=args.num_ways,\n                       shuffle=True,\n                       test_shots=15,\n                       meta_train=True,\n                       download=args.download)\n    dataloader = BatchMetaDataLoader(dataset,\n                                     batch_size=args.batch_size,\n                                     shuffle=True,\n                                     num_workers=args.num_workers)\n\n    model = ConvolutionalNeuralNetwork(1,\n                                       args.num_ways,\n                                       hidden_size=args.hidden_size)\n    model.to(device=args.device)\n    model.train()\n    meta_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # Training loop\n    with tqdm(dataloader, total=args.num_batches) as pbar:\n        for batch_idx, batch in enumerate(pbar):\n            model.zero_grad()\n\n            train_inputs, train_targets = batch[\'train\']\n            train_inputs = train_inputs.to(device=args.device)\n            train_targets = train_targets.to(device=args.device)\n\n            test_inputs, test_targets = batch[\'test\']\n            test_inputs = test_inputs.to(device=args.device)\n            test_targets = test_targets.to(device=args.device)\n\n            outer_loss = torch.tensor(0., device=args.device)\n            accuracy = torch.tensor(0., device=args.device)\n            for task_idx, (train_input, train_target, test_input,\n                    test_target) in enumerate(zip(train_inputs, train_targets,\n                    test_inputs, test_targets)):\n                train_logit = model(train_input)\n                inner_loss = F.cross_entropy(train_logit, train_target)\n\n                model.zero_grad()\n                params = gradient_update_parameters(model,\n                                                    inner_loss,\n                                                    step_size=args.step_size,\n                                                    first_order=args.first_order)\n\n                test_logit = model(test_input, params=params)\n                outer_loss += F.cross_entropy(test_logit, test_target)\n\n                with torch.no_grad():\n                    accuracy += get_accuracy(test_logit, test_target)\n\n            outer_loss.div_(args.batch_size)\n            accuracy.div_(args.batch_size)\n\n            outer_loss.backward()\n            meta_optimizer.step()\n\n            pbar.set_postfix(accuracy=\'{0:.4f}\'.format(accuracy.item()))\n            if batch_idx >= args.num_batches:\n                break\n\n    # Save model\n    if args.output_folder is not None:\n        filename = os.path.join(args.output_folder, \'anil_omniglot_\'\n            \'{0}shot_{1}way.th\'.format(args.num_shots, args.num_ways))\n\n        with open(filename, \'wb\') as f:\n            state_dict = model.state_dict()\n            torch.save(state_dict, f)\n\nif __name__ == \'__main__\':\n    import argparse\n\n    parser = argparse.ArgumentParser(\'Almost No Inner Loop (ANIL)\')\n\n    parser.add_argument(\'folder\', type=str,\n        help=\'Path to the folder the data is downloaded to.\')\n    parser.add_argument(\'--num-shots\', type=int, default=5,\n        help=\'Number of examples per class (k in ""k-shot"", default: 5).\')\n    parser.add_argument(\'--num-ways\', type=int, default=5,\n        help=\'Number of classes per task (N in ""N-way"", default: 5).\')\n\n    parser.add_argument(\'--first-order\', action=\'store_true\',\n        help=\'Use the first-order approximation of MAML.\')\n    parser.add_argument(\'--step-size\', type=float, default=0.4,\n        help=\'Step-size for the gradient step for adaptation (default: 0.4).\')\n    parser.add_argument(\'--hidden-size\', type=int, default=64,\n        help=\'Number of channels for each convolutional layer (default: 64).\')\n\n    parser.add_argument(\'--output-folder\', type=str, default=None,\n        help=\'Path to the output folder for saving the model (optional).\')\n    parser.add_argument(\'--batch-size\', type=int, default=16,\n        help=\'Number of tasks in a mini-batch of tasks (default: 16).\')\n    parser.add_argument(\'--num-batches\', type=int, default=100,\n        help=\'Number of batches the model is trained over (default: 100).\')\n    parser.add_argument(\'--num-workers\', type=int, default=1,\n        help=\'Number of workers for data loading (default: 1).\')\n    parser.add_argument(\'--download\', action=\'store_true\',\n        help=\'Download the Omniglot dataset in the data folder.\')\n    parser.add_argument(\'--use-cuda\', action=\'store_true\',\n        help=\'Use CUDA if available.\')\n\n    args = parser.parse_args()\n    args.device = torch.device(\'cuda\' if args.use_cuda\n        and torch.cuda.is_available() else \'cpu\')\n\n    train(args)\n'"
examples/anil/utils.py,5,"b'import torch\n\nfrom collections import OrderedDict\n\n\ndef get_accuracy(logits, targets):\n    """"""Compute the accuracy (after adaptation) of MAML on the test/query points\n\n    Parameters\n    ----------\n    logits : `torch.FloatTensor` instance\n        Outputs/logits of the model on the query points. This tensor has shape\n        `(num_examples, num_classes)`.\n\n    targets : `torch.LongTensor` instance\n        A tensor containing the targets of the query points. This tensor has \n        shape `(num_examples,)`.\n\n    Returns\n    -------\n    accuracy : `torch.FloatTensor` instance\n        Mean accuracy on the query points\n    """"""\n    _, predictions = torch.max(logits, dim=-1)\n    return torch.mean(predictions.eq(targets).float())\n'"
examples/maml-higher/train.py,15,"b'import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport logging\n\nfrom collections import OrderedDict\n\nimport higher  # tested with higher v0.2\n\nfrom torchmeta.datasets.helpers import omniglot\nfrom torchmeta.utils.data import BatchMetaDataLoader\n\nlogger = logging.getLogger(__name__)\n\n\ndef conv3x3(in_channels, out_channels, **kwargs):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n        nn.BatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n\nclass ConvolutionalNeuralNetwork(nn.Module):\n    def __init__(self, in_channels, out_features, hidden_size=64):\n        super(ConvolutionalNeuralNetwork, self).__init__()\n        self.in_channels = in_channels\n        self.out_features = out_features\n        self.hidden_size = hidden_size\n\n        self.features = nn.Sequential(\n            conv3x3(in_channels, hidden_size),\n            conv3x3(hidden_size, hidden_size),\n            conv3x3(hidden_size, hidden_size),\n            conv3x3(hidden_size, hidden_size)\n        )\n\n        self.classifier = nn.Linear(hidden_size, out_features)\n\n    def forward(self, inputs, params=None):\n        features = self.features(inputs)\n        features = features.view((features.size(0), -1))\n        logits = self.classifier(features)\n        return logits\n\n\ndef get_accuracy(logits, targets):\n    """"""Compute the accuracy (after adaptation) of MAML on the test/query points\n\n    Parameters\n    ----------\n    logits : `torch.FloatTensor` instance\n        Outputs/logits of the model on the query points. This tensor has shape\n        `(num_examples, num_classes)`.\n\n    targets : `torch.LongTensor` instance\n        A tensor containing the targets of the query points. This tensor has \n        shape `(num_examples,)`.\n\n    Returns\n    -------\n    accuracy : `torch.FloatTensor` instance\n        Mean accuracy on the query points\n    """"""\n    _, predictions = torch.max(logits, dim=-1)\n    return torch.mean(predictions.eq(targets).float())\n\n\ndef train(args):\n    logger.warning(\'This script is an example to showcase the data-loading \'\n                   \'features of Torchmeta in conjunction with using higher to \'\n                   \'make models ""unrollable"" and optimizers differentiable, \'\n                   \'and as such has been  very lightly tested.\')\n\n    dataset = omniglot(args.folder,\n                       shots=args.num_shots,\n                       ways=args.num_ways,\n                       shuffle=True,\n                       test_shots=15,\n                       meta_train=True,\n                       download=args.download)\n    dataloader = BatchMetaDataLoader(dataset,\n                                     batch_size=args.batch_size,\n                                     shuffle=True,\n                                     num_workers=args.num_workers)\n\n    model = ConvolutionalNeuralNetwork(1,\n                                       args.num_ways,\n                                       hidden_size=args.hidden_size)\n    model.to(device=args.device)\n    model.train()\n    inner_optimiser = torch.optim.SGD(model.parameters(), lr=args.step_size)\n    meta_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # Training loop\n    with tqdm(dataloader, total=args.num_batches) as pbar:\n        for batch_idx, batch in enumerate(pbar):\n            model.zero_grad()\n\n            train_inputs, train_targets = batch[\'train\']\n            train_inputs = train_inputs.to(device=args.device)\n            train_targets = train_targets.to(device=args.device)\n\n            test_inputs, test_targets = batch[\'test\']\n            test_inputs = test_inputs.to(device=args.device)\n            test_targets = test_targets.to(device=args.device)\n\n            outer_loss = torch.tensor(0., device=args.device)\n            accuracy = torch.tensor(0., device=args.device)\n\n            for task_idx, (train_input, train_target, test_input,\n                    test_target) in enumerate(zip(train_inputs, train_targets,\n                    test_inputs, test_targets)):\n                with higher.innerloop_ctx(model, inner_optimiser, copy_initial_weights=False) as (fmodel, diffopt):\n                    train_logit = fmodel(train_input)\n                    inner_loss = F.cross_entropy(train_logit, train_target)\n\n                    diffopt.step(inner_loss)\n\n                    test_logit = fmodel(test_input)\n                    outer_loss += F.cross_entropy(test_logit, test_target)\n\n                    with torch.no_grad():\n                        accuracy += get_accuracy(test_logit, test_target)\n\n            outer_loss.div_(args.batch_size)\n            accuracy.div_(args.batch_size)\n\n            outer_loss.backward()\n            meta_optimizer.step()\n\n            pbar.set_postfix(accuracy=\'{0:.4f}\'.format(accuracy.item()))\n            if batch_idx >= args.num_batches:\n                break\n\n    # Save model\n    if args.output_folder is not None:\n        filename = os.path.join(args.output_folder, \'maml_omniglot_\'\n            \'{0}shot_{1}way.th\'.format(args.num_shots, args.num_ways))\n        with open(filename, \'wb\') as f:\n            state_dict = model.state_dict()\n            torch.save(state_dict, f)\n\nif __name__ == \'__main__\':\n    import argparse\n\n    parser = argparse.ArgumentParser(\'Model-Agnostic Meta-Learning (MAML)\')\n\n    parser.add_argument(\'folder\', type=str,\n        help=\'Path to the folder the data is downloaded to.\')\n    parser.add_argument(\'--num-shots\', type=int, default=5,\n        help=\'Number of examples per class (k in ""k-shot"", default: 5).\')\n    parser.add_argument(\'--num-ways\', type=int, default=5,\n        help=\'Number of classes per task (N in ""N-way"", default: 5).\')\n\n    \n    parser.add_argument(\'--step-size\', type=float, default=0.4,\n        help=\'Step-size for the gradient step for adaptation (default: 0.4).\')\n    parser.add_argument(\'--hidden-size\', type=int, default=64,\n        help=\'Number of channels for each convolutional layer (default: 64).\')\n\n    parser.add_argument(\'--output-folder\', type=str, default=None,\n        help=\'Path to the output folder for saving the model (optional).\')\n    parser.add_argument(\'--batch-size\', type=int, default=16,\n        help=\'Number of tasks in a mini-batch of tasks (default: 16).\')\n    parser.add_argument(\'--num-batches\', type=int, default=100,\n        help=\'Number of batches the model is trained over (default: 100).\')\n    parser.add_argument(\'--num-workers\', type=int, default=1,\n        help=\'Number of workers for data loading (default: 1).\')\n    parser.add_argument(\'--download\', action=\'store_true\',\n        help=\'Download the Omniglot dataset in the data folder.\')\n    parser.add_argument(\'--use-cuda\', action=\'store_true\',\n        help=\'Use CUDA if available.\')\n\n    args = parser.parse_args()\n    args.device = torch.device(\'cuda\' if args.use_cuda\n        and torch.cuda.is_available() else \'cpu\')\n\n    train(args)\n'"
examples/maml/model.py,1,"b""import torch.nn as nn\nfrom torchmeta.modules import (MetaModule, MetaSequential, MetaConv2d,\n                               MetaBatchNorm2d, MetaLinear)\nfrom torchmeta.modules.utils import get_subdict\n\ndef conv3x3(in_channels, out_channels, **kwargs):\n    return MetaSequential(\n        MetaConv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n        MetaBatchNorm2d(out_channels, momentum=1., track_running_stats=False),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n\nclass ConvolutionalNeuralNetwork(MetaModule):\n    def __init__(self, in_channels, out_features, hidden_size=64):\n        super(ConvolutionalNeuralNetwork, self).__init__()\n        self.in_channels = in_channels\n        self.out_features = out_features\n        self.hidden_size = hidden_size\n\n        self.features = MetaSequential(\n            conv3x3(in_channels, hidden_size),\n            conv3x3(hidden_size, hidden_size),\n            conv3x3(hidden_size, hidden_size),\n            conv3x3(hidden_size, hidden_size)\n        )\n\n        self.classifier = MetaLinear(hidden_size, out_features)\n\n    def forward(self, inputs, params=None):\n        features = self.features(inputs, params=get_subdict(params, 'features'))\n        features = features.view((features.size(0), -1))\n        logits = self.classifier(features, params=get_subdict(params, 'classifier'))\n        return logits\n"""
examples/maml/train.py,8,"b'import os\nimport torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport logging\n\nfrom torchmeta.datasets.helpers import omniglot\nfrom torchmeta.utils.data import BatchMetaDataLoader\nfrom torchmeta.utils.gradient_based import gradient_update_parameters\n\nfrom model import ConvolutionalNeuralNetwork\nfrom utils import get_accuracy\n\nlogger = logging.getLogger(__name__)\n\n\ndef train(args):\n    logger.warning(\'This script is an example to showcase the MetaModule and \'\n                   \'data-loading features of Torchmeta, and as such has been \'\n                   \'very lightly tested. For a better tested implementation of \'\n                   \'Model-Agnostic Meta-Learning (MAML) using Torchmeta with \'\n                   \'more features (including multi-step adaptation and \'\n                   \'different datasets), please check `https://github.com/\'\n                   \'tristandeleu/pytorch-maml`.\')\n\n    dataset = omniglot(args.folder,\n                       shots=args.num_shots,\n                       ways=args.num_ways,\n                       shuffle=True,\n                       test_shots=15,\n                       meta_train=True,\n                       download=args.download)\n    dataloader = BatchMetaDataLoader(dataset,\n                                     batch_size=args.batch_size,\n                                     shuffle=True,\n                                     num_workers=args.num_workers)\n\n    model = ConvolutionalNeuralNetwork(1,\n                                       args.num_ways,\n                                       hidden_size=args.hidden_size)\n    model.to(device=args.device)\n    model.train()\n    meta_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # Training loop\n    with tqdm(dataloader, total=args.num_batches) as pbar:\n        for batch_idx, batch in enumerate(pbar):\n            model.zero_grad()\n\n            train_inputs, train_targets = batch[\'train\']\n            train_inputs = train_inputs.to(device=args.device)\n            train_targets = train_targets.to(device=args.device)\n\n            test_inputs, test_targets = batch[\'test\']\n            test_inputs = test_inputs.to(device=args.device)\n            test_targets = test_targets.to(device=args.device)\n\n            outer_loss = torch.tensor(0., device=args.device)\n            accuracy = torch.tensor(0., device=args.device)\n            for task_idx, (train_input, train_target, test_input,\n                    test_target) in enumerate(zip(train_inputs, train_targets,\n                    test_inputs, test_targets)):\n                train_logit = model(train_input)\n                inner_loss = F.cross_entropy(train_logit, train_target)\n\n                model.zero_grad()\n                params = gradient_update_parameters(model,\n                                                    inner_loss,\n                                                    step_size=args.step_size,\n                                                    first_order=args.first_order)\n\n                test_logit = model(test_input, params=params)\n                outer_loss += F.cross_entropy(test_logit, test_target)\n\n                with torch.no_grad():\n                    accuracy += get_accuracy(test_logit, test_target)\n\n            outer_loss.div_(args.batch_size)\n            accuracy.div_(args.batch_size)\n\n            outer_loss.backward()\n            meta_optimizer.step()\n\n            pbar.set_postfix(accuracy=\'{0:.4f}\'.format(accuracy.item()))\n            if batch_idx >= args.num_batches:\n                break\n\n    # Save model\n    if args.output_folder is not None:\n        filename = os.path.join(args.output_folder, \'maml_omniglot_\'\n            \'{0}shot_{1}way.th\'.format(args.num_shots, args.num_ways))\n        with open(filename, \'wb\') as f:\n            state_dict = model.state_dict()\n            torch.save(state_dict, f)\n\nif __name__ == \'__main__\':\n    import argparse\n\n    parser = argparse.ArgumentParser(\'Model-Agnostic Meta-Learning (MAML)\')\n\n    parser.add_argument(\'folder\', type=str,\n        help=\'Path to the folder the data is downloaded to.\')\n    parser.add_argument(\'--num-shots\', type=int, default=5,\n        help=\'Number of examples per class (k in ""k-shot"", default: 5).\')\n    parser.add_argument(\'--num-ways\', type=int, default=5,\n        help=\'Number of classes per task (N in ""N-way"", default: 5).\')\n\n    parser.add_argument(\'--first-order\', action=\'store_true\',\n        help=\'Use the first-order approximation of MAML.\')\n    parser.add_argument(\'--step-size\', type=float, default=0.4,\n        help=\'Step-size for the gradient step for adaptation (default: 0.4).\')\n    parser.add_argument(\'--hidden-size\', type=int, default=64,\n        help=\'Number of channels for each convolutional layer (default: 64).\')\n\n    parser.add_argument(\'--output-folder\', type=str, default=None,\n        help=\'Path to the output folder for saving the model (optional).\')\n    parser.add_argument(\'--batch-size\', type=int, default=16,\n        help=\'Number of tasks in a mini-batch of tasks (default: 16).\')\n    parser.add_argument(\'--num-batches\', type=int, default=100,\n        help=\'Number of batches the model is trained over (default: 100).\')\n    parser.add_argument(\'--num-workers\', type=int, default=1,\n        help=\'Number of workers for data loading (default: 1).\')\n    parser.add_argument(\'--download\', action=\'store_true\',\n        help=\'Download the Omniglot dataset in the data folder.\')\n    parser.add_argument(\'--use-cuda\', action=\'store_true\',\n        help=\'Use CUDA if available.\')\n\n    args = parser.parse_args()\n    args.device = torch.device(\'cuda\' if args.use_cuda\n        and torch.cuda.is_available() else \'cpu\')\n\n    train(args)\n'"
examples/maml/utils.py,5,"b'import torch\n\nfrom collections import OrderedDict\n\n\ndef get_accuracy(logits, targets):\n    """"""Compute the accuracy (after adaptation) of MAML on the test/query points\n\n    Parameters\n    ----------\n    logits : `torch.FloatTensor` instance\n        Outputs/logits of the model on the query points. This tensor has shape\n        `(num_examples, num_classes)`.\n\n    targets : `torch.LongTensor` instance\n        A tensor containing the targets of the query points. This tensor has \n        shape `(num_examples,)`.\n\n    Returns\n    -------\n    accuracy : `torch.FloatTensor` instance\n        Mean accuracy on the query points\n    """"""\n    _, predictions = torch.max(logits, dim=-1)\n    return torch.mean(predictions.eq(targets).float())\n'"
examples/protonet/model.py,1,"b'import torch.nn as nn\n\ndef conv3x3(in_channels, out_channels, **kwargs):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n\nclass PrototypicalNetwork(nn.Module):\n    def __init__(self, in_channels, out_channels, hidden_size=64):\n        super(PrototypicalNetwork, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.hidden_size = hidden_size\n\n        self.encoder = nn.Sequential(\n            conv3x3(in_channels, hidden_size),\n            conv3x3(hidden_size, hidden_size),\n            conv3x3(hidden_size, hidden_size),\n            conv3x3(hidden_size, out_channels)\n        )\n\n    def forward(self, inputs):\n        embeddings = self.encoder(inputs.view(-1, *inputs.shape[2:]))\n        return embeddings.view(*inputs.shape[:2], -1)\n'"
examples/protonet/train.py,5,"b'import os\nimport torch\nfrom tqdm import tqdm\nimport logging\n\nfrom torchmeta.datasets.helpers import omniglot\nfrom torchmeta.utils.data import BatchMetaDataLoader\nfrom torchmeta.utils.prototype import get_prototypes, prototypical_loss\n\nfrom model import PrototypicalNetwork\nfrom utils import get_accuracy\n\nlogger = logging.getLogger(__name__)\n\n\ndef train(args):\n    logger.warning(\'This script is an example to showcase the extensions and \'\n                   \'data-loading features of Torchmeta, and as such has been \'\n                   \'very lightly tested.\')\n\n    dataset = omniglot(args.folder,\n                       shots=args.num_shots,\n                       ways=args.num_ways,\n                       shuffle=True,\n                       test_shots=15,\n                       meta_train=True,\n                       download=args.download)\n    dataloader = BatchMetaDataLoader(dataset,\n                                     batch_size=args.batch_size,\n                                     shuffle=True,\n                                     num_workers=args.num_workers)\n\n    model = PrototypicalNetwork(1,\n                                args.embedding_size,\n                                hidden_size=args.hidden_size)\n    model.to(device=args.device)\n    model.train()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # Training loop\n    with tqdm(dataloader, total=args.num_batches) as pbar:\n        for batch_idx, batch in enumerate(pbar):\n            model.zero_grad()\n\n            train_inputs, train_targets = batch[\'train\']\n            train_inputs = train_inputs.to(device=args.device)\n            train_targets = train_targets.to(device=args.device)\n            train_embeddings = model(train_inputs)\n\n            test_inputs, test_targets = batch[\'test\']\n            test_inputs = test_inputs.to(device=args.device)\n            test_targets = test_targets.to(device=args.device)\n            test_embeddings = model(test_inputs)\n\n            prototypes = get_prototypes(train_embeddings, train_targets,\n                dataset.num_classes_per_task)\n            loss = prototypical_loss(prototypes, test_embeddings, test_targets)\n\n            loss.backward()\n            optimizer.step()\n\n            with torch.no_grad():\n                accuracy = get_accuracy(prototypes, test_embeddings, test_targets)\n                pbar.set_postfix(accuracy=\'{0:.4f}\'.format(accuracy.item()))\n\n            if batch_idx >= args.num_batches:\n                break\n\n    # Save model\n    if args.output_folder is not None:\n        filename = os.path.join(args.output_folder, \'protonet_omniglot_\'\n            \'{0}shot_{1}way.pt\'.format(args.num_shots, args.num_ways))\n        with open(filename, \'wb\') as f:\n            state_dict = model.state_dict()\n            torch.save(state_dict, f)\n\nif __name__ == \'__main__\':\n    import argparse\n\n    parser = argparse.ArgumentParser(\'Prototypical Networks\')\n\n    parser.add_argument(\'folder\', type=str,\n        help=\'Path to the folder the data is downloaded to.\')\n    parser.add_argument(\'--num-shots\', type=int, default=5,\n        help=\'Number of examples per class (k in ""k-shot"", default: 5).\')\n    parser.add_argument(\'--num-ways\', type=int, default=5,\n        help=\'Number of classes per task (N in ""N-way"", default: 5).\')\n\n    parser.add_argument(\'--embedding-size\', type=int, default=64,\n        help=\'Dimension of the embedding/latent space (default: 64).\')\n    parser.add_argument(\'--hidden-size\', type=int, default=64,\n        help=\'Number of channels for each convolutional layer (default: 64).\')\n\n    parser.add_argument(\'--output-folder\', type=str, default=None,\n        help=\'Path to the output folder for saving the model (optional).\')\n    parser.add_argument(\'--batch-size\', type=int, default=16,\n        help=\'Number of tasks in a mini-batch of tasks (default: 16).\')\n    parser.add_argument(\'--num-batches\', type=int, default=100,\n        help=\'Number of batches the prototypical network is trained over (default: 100).\')\n    parser.add_argument(\'--num-workers\', type=int, default=1,\n        help=\'Number of workers for data loading (default: 1).\')\n    parser.add_argument(\'--download\', action=\'store_true\',\n        help=\'Download the Omniglot dataset in the data folder.\')\n    parser.add_argument(\'--use-cuda\', action=\'store_true\',\n        help=\'Use CUDA if available.\')\n\n    args = parser.parse_args()\n    args.device = torch.device(\'cuda\' if args.use_cuda\n        and torch.cuda.is_available() else \'cpu\')\n\n    train(args)\n'"
examples/protonet/utils.py,7,"b'import torch\n\n\ndef get_accuracy(prototypes, embeddings, targets):\n    """"""Compute the accuracy of the prototypical network on the test/query points.\n\n    Parameters\n    ----------\n    prototypes : `torch.FloatTensor` instance\n        A tensor containing the prototypes for each class. This tensor has shape \n        `(meta_batch_size, num_classes, embedding_size)`.\n    embeddings : `torch.FloatTensor` instance\n        A tensor containing the embeddings of the query points. This tensor has \n        shape `(meta_batch_size, num_examples, embedding_size)`.\n    targets : `torch.LongTensor` instance\n        A tensor containing the targets of the query points. This tensor has \n        shape `(meta_batch_size, num_examples)`.\n\n    Returns\n    -------\n    accuracy : `torch.FloatTensor` instance\n        Mean accuracy on the query points.\n    """"""\n    sq_distances = torch.sum((prototypes.unsqueeze(1)\n        - embeddings.unsqueeze(2)) ** 2, dim=-1)\n    _, predictions = torch.min(sq_distances, dim=-1)\n    return torch.mean(predictions.eq(targets).float())\n'"
torchmeta/datasets/__init__.py,0,"b""from torchmeta.datasets.triplemnist import TripleMNIST\nfrom torchmeta.datasets.doublemnist import DoubleMNIST\nfrom torchmeta.datasets.cub import CUB\nfrom torchmeta.datasets.cifar100 import CIFARFS, FC100\nfrom torchmeta.datasets.miniimagenet import MiniImagenet\nfrom torchmeta.datasets.omniglot import Omniglot\nfrom torchmeta.datasets.tieredimagenet import TieredImagenet\nfrom torchmeta.datasets.tcga import TCGA\nfrom torchmeta.datasets.pascal5i import Pascal5i\n\nfrom torchmeta.datasets import helpers\n\n__all__ = [\n    'TCGA',\n    'Omniglot',\n    'MiniImagenet',\n    'TieredImagenet',\n    'CIFARFS',\n    'FC100',\n    'CUB',\n    'DoubleMNIST',\n    'TripleMNIST',\n    'Pascal5i',\n    'helpers'\n]\n"""
torchmeta/datasets/cub.py,0,"b'import numpy as np\nfrom PIL import Image\nimport os\nimport io\nimport json\nimport glob\nimport h5py\n\nfrom torchmeta.utils.data import Dataset, ClassDataset, CombinationMetaDataset\nfrom torchvision.datasets.utils import download_url\nfrom torchmeta.datasets.utils import get_asset\n\n\nclass CUB(CombinationMetaDataset):\n    """"""\n    The Caltech-UCSD Birds dataset, introduced in [1]. This dataset is based on\n    images from 200 species of birds from the Caltech-UCSD Birds dataset [2].\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `cub` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to ""N"" in ""N-way"" \n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These classes \n        are transformations of existing classes. E.g.\n        `torchmeta.transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the pickle files and processes the dataset in the root \n        directory (under the `cub` folder). If the dataset is already \n        available, this does not download/process the dataset again.\n\n    Notes\n    -----\n    The dataset is downloaded from [2]. The dataset contains images from 200\n    classes. The meta train/validation/test splits are over 100/50/50 classes.\n    The splits are taken from [3] ([code](https://github.com/wyharveychen/CloserLookFewShot)\n    for reproducibility).\n\n    References\n    ----------\n    .. [1] Hilliard, N., Phillips, L., Howland, S., Yankov, A., Corley, C. D.,\n           Hodas, N. O. (2018). Few-Shot Learning with Metric-Agnostic Conditional\n           Embeddings. (https://arxiv.org/abs/1802.04376)\n    .. [2] Wah, C., Branson, S., Welinder, P., Perona, P., Belongie, S. (2011).\n           The Caltech-UCSD Birds-200-2011 Dataset\n           (http://www.vision.caltech.edu/visipedia/CUB-200-2011.html)\n    .. [3] Chen, W., Liu, Y. and Kira, Z. and Wang, Y. and  Huang, J. (2019).\n           A Closer Look at Few-shot Classification. International Conference on\n           Learning Representations (https://openreview.net/forum?id=HkxLXnAcFQ)\n\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_val=False, meta_test=False, meta_split=None,\n                 transform=None, target_transform=None, dataset_transform=None,\n                 class_augmentations=None, download=False):\n        dataset = CUBClassDataset(root, meta_train=meta_train, meta_val=meta_val,\n            meta_test=meta_test, meta_split=meta_split, transform=transform,\n            class_augmentations=class_augmentations, download=download)\n        super(CUB, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform, dataset_transform=dataset_transform)\n\n\nclass CUBClassDataset(ClassDataset):\n    folder = \'cub\'\n    download_url = \'http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\'\n    tgz_md5 = \'97eceeb196236b17998738112f37df78\'\n    image_folder = \'CUB_200_2011/images\'\n\n    filename = \'{0}_data.hdf5\'\n    filename_labels = \'{0}_labels.json\'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False):\n        super(CUBClassDataset, self).__init__(meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            class_augmentations=class_augmentations)\n\n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.transform = transform\n\n        self.split_filename = os.path.join(self.root,\n            self.filename.format(self.meta_split))\n        self.split_filename_labels = os.path.join(self.root,\n            self.filename_labels.format(self.meta_split))\n\n        self._data_file = None\n        self._data = None\n        self._labels = None\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError(\'CUB integrity check failed\')\n        self._num_classes = len(self.labels)\n\n    def __getitem__(self, index):\n        label = self.labels[index % self.num_classes]\n        data = self.data[label]\n        transform = self.get_transform(index, self.transform)\n        target_transform = self.get_target_transform(index)\n\n        return CUBDataset(index, data, label, transform=transform,\n                          target_transform=target_transform)\n\n    @property\n    def num_classes(self):\n        return self._num_classes\n\n    @property\n    def data(self):\n        if self._data is None:\n            self._data_file = h5py.File(self.split_filename, \'r\')\n            self._data = self._data_file[\'datasets\']\n        return self._data\n    \n    @property\n    def labels(self):\n        if self._labels is None:\n            with open(self.split_filename_labels, \'r\') as f:\n                self._labels = json.load(f)\n        return self._labels\n\n    def _check_integrity(self):\n        return (os.path.isfile(self.split_filename)\n            and os.path.isfile(self.split_filename_labels))\n\n    def close(self):\n        if self._data_file is not None:\n            self._data_file.close()\n            self._data_file = None\n            self._data = None\n\n    def download(self):\n        import tarfile\n        import shutil\n        import glob\n        from tqdm import tqdm\n\n        if self._check_integrity():\n            return\n\n        filename = os.path.basename(self.download_url)\n        download_url(self.download_url, self.root, filename, self.tgz_md5)\n\n        tgz_filename = os.path.join(self.root, filename)\n        with tarfile.open(tgz_filename, \'r\') as f:\n            f.extractall(self.root)\n        image_folder = os.path.join(self.root, self.image_folder)\n\n        for split in [\'train\', \'val\', \'test\']:\n            filename = os.path.join(self.root, self.filename.format(split))\n            if os.path.isfile(filename):\n                continue\n\n            labels = get_asset(self.folder, \'{0}.json\'.format(split))\n            labels_filename = os.path.join(self.root, self.filename_labels.format(split))\n            with open(labels_filename, \'w\') as f:\n                json.dump(labels, f)\n\n            with h5py.File(filename, \'w\') as f:\n                group = f.create_group(\'datasets\')\n                dtype = h5py.special_dtype(vlen=np.uint8)\n                for i, label in enumerate(tqdm(labels, desc=filename)):\n                    images = glob.glob(os.path.join(image_folder, label, \'*.jpg\'))\n                    images.sort()\n                    dataset = group.create_dataset(label, (len(images),), dtype=dtype)\n                    for i, image in enumerate(images):\n                        with open(image, \'rb\') as f:\n                            array = bytearray(f.read())\n                            dataset[i] = np.asarray(array, dtype=np.uint8)\n\n        tar_folder, _ = os.path.splitext(tgz_filename)\n        if os.path.isdir(tar_folder):\n            shutil.rmtree(tar_folder)\n\n        attributes_filename = os.path.join(self.root, \'attributes.txt\')\n        if os.path.isfile(attributes_filename):\n            os.remove(attributes_filename)\n\n\nclass CUBDataset(Dataset):\n    def __init__(self, index, data, label,\n                 transform=None, target_transform=None):\n        super(CUBDataset, self).__init__(index, transform=transform,\n                                         target_transform=target_transform)\n        self.data = data\n        self.label = label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        image = Image.open(io.BytesIO(self.data[index])).convert(\'RGB\')\n        target = self.label\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (image, target)\n'"
torchmeta/datasets/doublemnist.py,0,"b'import numpy as np\nfrom PIL import Image\nimport os\nimport io\nimport json\nimport glob\nimport h5py\n\nfrom torchmeta.utils.data import Dataset, ClassDataset, CombinationMetaDataset\nfrom torchvision.datasets.utils import download_file_from_google_drive\nfrom torchmeta.datasets.utils import get_asset\n\n\nclass DoubleMNIST(CombinationMetaDataset):\n    """"""\n    The Double MNIST dataset, introduced in [1]. This dataset is based on\n    the MNIST dataset [2]. It consists of sampled images from MNIST\n    that are put together to create images with multiple digits. It contains\n    100,000 images from 100 different classes (1000 images per class, for the \n    numbers 00 to 99).\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `doublemnist` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to ""N"" in ""N-way"" \n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly\n        one of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly\n        one of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These\n        classes are transformations of existing classes. E.g.\n        `torchmeta.transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the pickle files and processes the dataset in the\n        root directory (under the `doublemnist` folder). If the dataset is\n        already available, this does not download/process the dataset again.\n\n    Notes\n    -----\n    The dataset is downloaded from the Multi-digit MNIST repository\n    [1](https://github.com/shaohua0116/MultiDigitMNIST). The dataset contains\n    images (MNIST double digits) from 100 classes, for the numbers 00 to 99.\n    The meta train/validation/test splits are 64/16/20 classes.\n    The splits are taken from [1].\n\n    References\n    ----------\n    .. [1] Sun, S. (2019). Multi-digit MNIST for Few-shot Learning.\n    (https://github.com/shaohua0116/MultiDigitMNIST)\n\n    .. [2] LeCun, Y., Cortes, C., and Burges, CJ. (2010). MNIST Handwritten\n    Digit Database. (http://yann.lecun.com/exdb/mnist)\n\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_val=False, meta_test=False, meta_split=None,\n                 transform=None, target_transform=None, dataset_transform=None,\n                 class_augmentations=None, download=False):\n        dataset = DoubleMNISTClassDataset(root,\n            meta_train=meta_train, meta_val=meta_val,\n            meta_test=meta_test, meta_split=meta_split, transform=transform,\n            class_augmentations=class_augmentations, download=download)\n        super(DoubleMNIST, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform,\n            dataset_transform=dataset_transform)\n\n\nclass DoubleMNISTClassDataset(ClassDataset):\n    folder = \'doublemnist\'\n    # Google Drive ID from https://github.com/shaohua0116/MultiDigitMNIST\n    gdrive_id = \'1MqQCdLt9TVE3joAMw4FwJp_B8F-htrAo\'\n    zip_filename = \'double_mnist_seed_123_image_size_64_64.zip\'\n    zip_md5 = \'6d8b185c0cde155eb39d0e3615ab4f23\'\n\n    filename = \'{0}_data.hdf5\'\n    filename_labels = \'{0}_labels.json\'\n\n    image_folder = \'double_mnist_seed_123_image_size_64_64\'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False):\n        super(DoubleMNISTClassDataset, self).__init__(meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            class_augmentations=class_augmentations)\n\n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.transform = transform\n\n        self.split_filename = os.path.join(self.root,\n            self.filename.format(self.meta_split))\n        self.split_filename_labels = os.path.join(self.root,\n            self.filename_labels.format(self.meta_split))\n\n        self._data_file = None\n        self._data = None\n        self._labels = None\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError(\'Double MNIST integrity check failed\')\n        self._num_classes = len(self.labels)\n\n    def __getitem__(self, index):\n        label = self.labels[index % self.num_classes]\n        data = self.data[label]\n        transform = self.get_transform(index, self.transform)\n        target_transform = self.get_target_transform(index)\n\n        return DoubleMNISTDataset(index, data, label, transform=transform,\n                                  target_transform=target_transform)\n\n    @property\n    def num_classes(self):\n        return self._num_classes\n\n    @property\n    def data(self):\n        if self._data is None:\n            self._data_file = h5py.File(self.split_filename, \'r\')\n            self._data = self._data_file[\'datasets\']\n        return self._data\n    \n    @property\n    def labels(self):\n        if self._labels is None:\n            with open(self.split_filename_labels, \'r\') as f:\n                self._labels = json.load(f)\n        return self._labels\n\n    def _check_integrity(self):\n        return (os.path.isfile(self.split_filename)\n            and os.path.isfile(self.split_filename_labels))\n\n    def close(self):\n        if self._data_file is not None:\n            self._data_file.close()\n            self._data_file = None\n            self._data = None\n\n    def download(self):\n        import zipfile\n        import shutil\n        import glob\n        from tqdm import tqdm\n\n        if self._check_integrity():\n            return\n\n        zip_filename = os.path.join(self.root, self.zip_filename)\n        if not os.path.isfile(zip_filename):\n            download_file_from_google_drive(self.gdrive_id, self.root,\n                self.zip_filename, md5=self.zip_md5)\n\n        zip_foldername = os.path.join(self.root, self.image_folder)\n        if not os.path.isdir(zip_foldername):\n            with zipfile.ZipFile(zip_filename, \'r\') as f:\n                for member in tqdm(f.infolist(), desc=\'Extracting \'):\n                    try:\n                        f.extract(member, self.root)\n                    except zipfile.BadZipFile:\n                        print(\'Error: Zip file is corrupted\')\n\n        for split in [\'train\', \'val\', \'test\']:\n            filename = os.path.join(self.root, self.filename.format(split))\n            if os.path.isfile(filename):\n                continue\n\n            labels = get_asset(self.folder, \'{0}.json\'.format(split))\n            labels_filename = os.path.join(self.root,\n                                           self.filename_labels.format(split))\n            with open(labels_filename, \'w\') as f:\n                json.dump(labels, f)\n\n            image_folder = os.path.join(zip_foldername, split)\n\n            with h5py.File(filename, \'w\') as f:\n                group = f.create_group(\'datasets\')\n                dtype = h5py.special_dtype(vlen=np.uint8)\n                for i, label in enumerate(tqdm(labels, desc=filename)):\n                    images = glob.glob(os.path.join(image_folder, label,\n                                                    \'*.png\'))\n                    images.sort()\n                    dataset = group.create_dataset(label, (len(images),),\n                                                   dtype=dtype)\n                    for i, image in enumerate(images):\n                        with open(image, \'rb\') as f:\n                            array = bytearray(f.read())\n                            dataset[i] = np.asarray(array, dtype=np.uint8)\n\n        if os.path.isdir(zip_foldername):\n            shutil.rmtree(zip_foldername)\n\n\nclass DoubleMNISTDataset(Dataset):\n    def __init__(self, index, data, label,\n                 transform=None, target_transform=None):\n        super(DoubleMNISTDataset, self).__init__(index, transform=transform,\n                                                 target_transform=target_transform)\n        self.data = data\n        self.label = label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        image = Image.open(io.BytesIO(self.data[index])).convert(\'RGB\')\n        target = self.label\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (image, target)\n'"
torchmeta/datasets/helpers.py,0,"b'import warnings\n\nfrom torchmeta.datasets import (Omniglot, MiniImagenet, TieredImagenet, CIFARFS,\n                                CUB, DoubleMNIST, TripleMNIST, Pascal5i)\nfrom torchmeta.transforms import Categorical, ClassSplitter, Rotation, SegmentationPairTransform\nfrom torchvision.transforms import Compose, Resize, CenterCrop, ToTensor\n\n__all__ = [\n    \'omniglot\',\n    \'miniimagenet\',\n    \'tieredimagenet\',\n    \'cifar_fs\',\n    \'cub\',\n    \'doublemnist\',\n    \'triplemnist\'\n]\n\ndef helper_with_default(klass, folder, shots, ways, shuffle=True,\n                        test_shots=None, seed=None, defaults={}, **kwargs):\n    if \'num_classes_per_task\' in kwargs:\n        warnings.warn(\'Both arguments `ways` and `num_classes_per_task` were \'\n            \'set in the helper function for the number of classes per task. \'\n            \'Ignoring the argument `ways`.\', stacklevel=2)\n        ways = kwargs[\'num_classes_per_task\']\n    if \'transform\' not in kwargs:\n        kwargs[\'transform\'] = defaults.get(\'transform\', ToTensor())\n    if \'target_transform\' not in kwargs:\n        kwargs[\'target_transform\'] = defaults.get(\'target_transform\',\n                                                  Categorical(ways))\n    if \'class_augmentations\' not in kwargs:\n        kwargs[\'class_augmentations\'] = defaults.get(\'class_augmentations\', None)\n    if test_shots is None:\n        test_shots = shots\n    dataset = klass(folder, num_classes_per_task=ways, **kwargs)\n    dataset = ClassSplitter(dataset, shuffle=shuffle,\n        num_train_per_class=shots, num_test_per_class=test_shots)\n    dataset.seed(seed)\n\n    return dataset\n\ndef omniglot(folder, shots, ways, shuffle=True, test_shots=None,\n             seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the Omniglot dataset.\n\n    Parameters\n    ----------\n    folder : string\n        Root directory where the dataset folder `omniglot` exists.\n\n    shots : int\n        Number of (training) examples per class in each task. This corresponds\n        to `k` in `k-shot` classification.\n\n    ways : int\n        Number of classes per task. This corresponds to `N` in `N-way`\n        classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples per class in each task. If `None`, then the\n        number of test examples is equal to the number of training examples per\n        class.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `Omniglot` class.\n\n    See also\n    --------\n    `datasets.Omniglot` : Meta-dataset for the Omniglot dataset.\n    """"""\n    defaults = {\n        \'transform\': Compose([Resize(28), ToTensor()]),\n        \'class_augmentations\': [Rotation([90, 180, 270])]\n    }\n\n    return helper_with_default(Omniglot, folder, shots, ways,\n                               shuffle=shuffle, test_shots=test_shots,\n                               seed=seed, defaults=defaults, **kwargs)\n\ndef miniimagenet(folder, shots, ways, shuffle=True, test_shots=None,\n                 seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the Mini-Imagenet dataset.\n\n    Parameters\n    ----------\n    folder : string\n        Root directory where the dataset folder `miniimagenet` exists.\n\n    shots : int\n        Number of (training) examples per class in each task. This corresponds\n        to `k` in `k-shot` classification.\n\n    ways : int\n        Number of classes per task. This corresponds to `N` in `N-way`\n        classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples per class in each task. If `None`, then the\n        number of test examples is equal to the number of training examples per\n        class.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `MiniImagenet` class.\n\n    See also\n    --------\n    `datasets.MiniImagenet` : Meta-dataset for the Mini-Imagenet dataset.\n    """"""\n    defaults = {\n        \'transform\': Compose([Resize(84), ToTensor()])\n    }\n\n    return helper_with_default(MiniImagenet, folder, shots, ways,\n                               shuffle=shuffle, test_shots=test_shots,\n                               seed=seed, defaults=defaults, **kwargs)\n\ndef tieredimagenet(folder, shots, ways, shuffle=True, test_shots=None,\n                   seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the Tiered-Imagenet dataset.\n\n    Parameters\n    ----------\n    folder : string\n        Root directory where the dataset folder `tieredimagenet` exists.\n\n    shots : int\n        Number of (training) examples per class in each task. This corresponds\n        to `k` in `k-shot` classification.\n\n    ways : int\n        Number of classes per task. This corresponds to `N` in `N-way`\n        classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples per class in each task. If `None`, then the\n        number of test examples is equal to the number of training examples per\n        class.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `TieredImagenet` class.\n\n    See also\n    --------\n    `datasets.TieredImagenet` : Meta-dataset for the Tiered-Imagenet dataset.\n    """"""\n    defaults = {\n        \'transform\': Compose([Resize(84), ToTensor()])\n    }\n\n    return helper_with_default(TieredImagenet, folder, shots, ways,\n                               shuffle=shuffle, test_shots=test_shots,\n                               seed=seed, defaults=defaults, **kwargs)\n\ndef cifar_fs(folder, shots, ways, shuffle=True, test_shots=None,\n             seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the CIFAR-FS dataset.\n\n    Parameters\n    ----------\n    folder : string\n        Root directory where the dataset folder `cifar100` exists.\n\n    shots : int\n        Number of (training) examples per class in each task. This corresponds\n        to `k` in `k-shot` classification.\n\n    ways : int\n        Number of classes per task. This corresponds to `N` in `N-way`\n        classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples per class in each task. If `None`, then the\n        number of test examples is equal to the number of training examples per\n        class.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `CIFARFS` class.\n\n    See also\n    --------\n    `datasets.cifar100.CIFARFS` : Meta-dataset for the CIFAR-FS dataset.\n    """"""\n    return helper_with_default(CIFARFS, folder, shots, ways,\n                               shuffle=shuffle, test_shots=test_shots,\n                               seed=seed, defaults={}, **kwargs)\n\ndef cub(folder, shots, ways, shuffle=True, test_shots=None,\n        seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the Caltech-UCSD Birds dataset.\n\n    Parameters\n    ----------\n    folder : string\n        Root directory where the dataset folder `cub` exists.\n\n    shots : int\n        Number of (training) examples per class in each task. This corresponds\n        to `k` in `k-shot` classification.\n\n    ways : int\n        Number of classes per task. This corresponds to `N` in `N-way`\n        classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples per class in each task. If `None`, then the\n        number of test examples is equal to the number of training examples per\n        class.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `CUB` class.\n\n    See also\n    --------\n    `datasets.cub.CUB` : Meta-dataset for the Caltech-UCSD Birds dataset.\n    """"""\n    image_size = 84\n    defaults = {\n        \'transform\': Compose([\n                        Resize(int(image_size * 1.5)),\n                        CenterCrop(image_size),\n                        ToTensor()\n                    ])\n    }\n\n    return helper_with_default(CUB, folder, shots, ways,\n                               shuffle=shuffle, test_shots=test_shots,\n                               seed=seed, defaults=defaults, **kwargs)\n\ndef doublemnist(folder, shots, ways, shuffle=True, test_shots=None,\n                seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the Double MNIST dataset.\n\n    Parameters\n    ----------\n    folder : string\n        Root directory where the dataset folder `doublemnist` exists.\n\n    shots : int\n        Number of (training) examples per class in each task. This corresponds\n        to `k` in `k-shot` classification.\n\n    ways : int\n        Number of classes per task. This corresponds to `N` in `N-way`\n        classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples per class in each task. If `None`, then the\n        number of test examples is equal to the number of training examples per\n        class.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `DoubleMNIST` class.\n\n    See also\n    --------\n    `datasets.doublemnist.DoubleMNIST` : Meta-dataset for the Double MNIST dataset.\n    """"""\n    return helper_with_default(DoubleMNIST, folder, shots, ways,\n                               shuffle=shuffle, test_shots=test_shots,\n                               seed=seed, defaults={}, **kwargs)\n\ndef triplemnist(folder, shots, ways, shuffle=True, test_shots=None,\n                seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the Triple MNIST dataset.\n\n    Parameters\n    ----------\n    folder : string\n        Root directory where the dataset folder `triplemnist` exists.\n\n    shots : int\n        Number of (training) examples per class in each task. This corresponds \n        to `k` in `k-shot` classification.\n\n    ways : int\n        Number of classes per task. This corresponds to `N` in `N-way` \n        classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples per class in each task. If `None`, then the \n        number of test examples is equal to the number of training examples per \n        class.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `TripleMNIST` class.\n\n    See also\n    --------\n    `datasets.triplemnist.TripleMNIST` : Meta-dataset for the Triple MNIST dataset.\n    """"""\n    return helper_with_default(TripleMNIST, folder, shots, ways,\n                               shuffle=shuffle, test_shots=test_shots,\n                               seed=seed, defaults={}, **kwargs)\n\ndef pascal5i(folder, shots, ways=1, shuffle=True, test_shots=None,\n             seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the PASCAL-VOC dataset.\n\n    Parameters\n    ----------\n    folder : string\n        Root directory where the dataset folder `omniglot` exists.\n\n    shots : int\n        Number of (training) examples per class in each task. This corresponds\n        to `k` in `k-shot` classification.\n\n    ways : int\n        Number of classes per task. This corresponds to `N` in `N-way`\n        classification. Only supports 1-way currently\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples per class in each task. If `None`, then the\n        number of test examples is equal to the number of training examples per\n        class.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `Omniglot` class.\n\n    """"""\n    defaults = {\n        \'transform\': SegmentationPairTransform(500),\n        \'class_augmentations\': []\n    }\n    return helper_with_default(Pascal5i, folder, shots, ways,\n                               shuffle=shuffle, test_shots=test_shots,\n                               seed=seed, defaults=defaults, **kwargs)\n'"
torchmeta/datasets/miniimagenet.py,0,"b'import os\nimport pickle\nfrom PIL import Image\nimport h5py\nimport json\n\nfrom torchmeta.utils.data import Dataset, ClassDataset, CombinationMetaDataset\nfrom torchvision.datasets.utils import download_file_from_google_drive\n\n\nclass MiniImagenet(CombinationMetaDataset):\n    """"""\n    The Mini-Imagenet dataset, introduced in [1]. This dataset contains images \n    of 100 different classes from the ILSVRC-12 dataset (Imagenet challenge). \n    The meta train/validation/test splits are taken from [2] for reproducibility.\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `miniimagenet` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to ""N"" in ""N-way"" \n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These classes \n        are transformations of existing classes. E.g.\n        `torchmeta.transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the pickle files and processes the dataset in the root \n        directory (under the `miniimagenet` folder). If the dataset is already \n        available, this does not download/process the dataset again.\n\n    Notes\n    -----\n    The dataset is downloaded from [this repository]\n    (https://github.com/renmengye/few-shot-ssl-public/). The meta train/\n    validation/test splits are over 64/16/20 classes.\n\n    References\n    ----------\n    .. [1] Vinyals, O., Blundell, C., Lillicrap, T. and Wierstra, D. (2016). \n           Matching Networks for One Shot Learning. In Advances in Neural \n           Information Processing Systems (pp. 3630-3638) (https://arxiv.org/abs/1606.04080)\n\n    .. [2] Ravi, S. and Larochelle, H. (2016). Optimization as a Model for \n           Few-Shot Learning. (https://openreview.net/forum?id=rJY0-Kcll)\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_val=False, meta_test=False, meta_split=None,\n                 transform=None, target_transform=None, dataset_transform=None,\n                 class_augmentations=None, download=False):\n        dataset = MiniImagenetClassDataset(root, meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            transform=transform, class_augmentations=class_augmentations,\n            download=download)\n        super(MiniImagenet, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform, dataset_transform=dataset_transform)\n\n\nclass MiniImagenetClassDataset(ClassDataset):\n    folder = \'miniimagenet\'\n    # Google Drive ID from https://github.com/renmengye/few-shot-ssl-public\n    gdrive_id = \'16V_ZlkW4SsnNDtnGmaBRq2OoPmUOc5mY\'\n    gz_filename = \'mini-imagenet.tar.gz\'\n    gz_md5 = \'b38f1eb4251fb9459ecc8e7febf9b2eb\'\n    pkl_filename = \'mini-imagenet-cache-{0}.pkl\'\n\n    filename = \'{0}_data.hdf5\'\n    filename_labels = \'{0}_labels.json\'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False):\n        super(MiniImagenetClassDataset, self).__init__(meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            class_augmentations=class_augmentations)\n        \n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.transform = transform\n\n        self.split_filename = os.path.join(self.root,\n            self.filename.format(self.meta_split))\n        self.split_filename_labels = os.path.join(self.root,\n            self.filename_labels.format(self.meta_split))\n\n        self._data = None\n        self._labels = None\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError(\'MiniImagenet integrity check failed\')\n        self._num_classes = len(self.labels)\n\n    def __getitem__(self, index):\n        class_name = self.labels[index % self.num_classes]\n        data = self.data[class_name]\n        transform = self.get_transform(index, self.transform)\n        target_transform = self.get_target_transform(index)\n\n        return MiniImagenetDataset(index, data, class_name,\n            transform=transform, target_transform=target_transform)\n\n    @property\n    def num_classes(self):\n        return self._num_classes\n\n    @property\n    def data(self):\n        if self._data is None:\n            self._data_file = h5py.File(self.split_filename, \'r\')\n            self._data = self._data_file[\'datasets\']\n        return self._data\n\n    @property\n    def labels(self):\n        if self._labels is None:\n            with open(self.split_filename_labels, \'r\') as f:\n                self._labels = json.load(f)\n        return self._labels\n\n    def _check_integrity(self):\n        return (os.path.isfile(self.split_filename)\n            and os.path.isfile(self.split_filename_labels))\n\n    def close(self):\n        if self._data_file is not None:\n            self._data_file.close()\n            self._data_file = None\n            self._data = None\n\n    def download(self):\n        import tarfile\n\n        if self._check_integrity():\n            return\n\n        download_file_from_google_drive(self.gdrive_id, self.root,\n            self.gz_filename, md5=self.gz_md5)\n\n        filename = os.path.join(self.root, self.gz_filename)\n        with tarfile.open(filename, \'r\') as f:\n            f.extractall(self.root)\n\n        for split in [\'train\', \'val\', \'test\']:\n            filename = os.path.join(self.root, self.filename.format(split))\n            if os.path.isfile(filename):\n                continue\n\n            pkl_filename = os.path.join(self.root, self.pkl_filename.format(split))\n            if not os.path.isfile(pkl_filename):\n                raise IOError()\n            with open(pkl_filename, \'rb\') as f:\n                data = pickle.load(f)\n                images, classes = data[\'image_data\'], data[\'class_dict\']\n\n            with h5py.File(filename, \'w\') as f:\n                group = f.create_group(\'datasets\')\n                for name, indices in classes.items():\n                    group.create_dataset(name, data=images[indices])\n\n            labels_filename = os.path.join(self.root, self.filename_labels.format(split))\n            with open(labels_filename, \'w\') as f:\n                labels = sorted(list(classes.keys()))\n                json.dump(labels, f)\n\n            if os.path.isfile(pkl_filename):\n                os.remove(pkl_filename)\n\n\nclass MiniImagenetDataset(Dataset):\n    def __init__(self, index, data, class_name,\n                 transform=None, target_transform=None):\n        super(MiniImagenetDataset, self).__init__(index, transform=transform,\n                                                  target_transform=target_transform)\n        self.data = data\n        self.class_name = class_name\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, index):\n        image = Image.fromarray(self.data[index])\n        target = self.class_name\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (image, target)\n'"
torchmeta/datasets/omniglot.py,0,"b'import os\nimport json\nimport glob\nimport h5py\nfrom PIL import Image, ImageOps\n\nfrom torchmeta.utils.data import Dataset, ClassDataset, CombinationMetaDataset\nfrom torchvision.datasets.utils import list_dir, download_url\nfrom torchmeta.datasets.utils import get_asset\n\n\nclass Omniglot(CombinationMetaDataset):\n    """"""\n    The Omniglot dataset [1]. A dataset of 1623 handwritten characters from \n    50 different alphabets. \n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `omniglot` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to ""N"" in ""N-way"" \n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    use_vinyals_split : bool (default: `True`)\n        If set to `True`, the dataset uses the splits defined in [3]. If `False`, \n        then the meta-train split corresponds to `images_background`, and the \n        meta-test split corresponds to `images_evaluation` (raises an error when \n        calling the meta-validation split).\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These classes \n        are transformations of existing classes. E.g.\n        `torchmeta.transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the zip files and processes the dataset in the root \n        directory (under the `omniglot` folder). If the dataset is already \n        available, this does not download/process the dataset again.\n\n    Notes\n    -----\n    The dataset is downloaded from the original [Omniglot repository]\n    (https://github.com/brendenlake/omniglot). The meta train/validation/test \n    splits used in [3] are taken from [this repository]\n    (https://github.com/jakesnell/prototypical-networks). These splits are \n    over 1028/172/423 classes (characters).\n\n    References\n    ----------\n    .. [1] Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level \n           concept learning through probabilistic program induction. Science, 350(6266), \n           1332-1338 (http://www.sciencemag.org/content/350/6266/1332.short)\n\n    .. [2] Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2019). The Omniglot \n           Challenge: A 3-Year Progress Report (https://arxiv.org/abs/1902.03477)\n\n    .. [3] Vinyals, O., Blundell, C., Lillicrap, T. and Wierstra, D. (2016). \n           Matching Networks for One Shot Learning. In Advances in Neural \n           Information Processing Systems (pp. 3630-3638) (https://arxiv.org/abs/1606.04080)\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_val=False, meta_test=False, meta_split=None,\n                 use_vinyals_split=True, transform=None, target_transform=None,\n                 dataset_transform=None, class_augmentations=None, download=False):\n        dataset = OmniglotClassDataset(root, meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test,\n            use_vinyals_split=use_vinyals_split, transform=transform,\n            meta_split=meta_split, class_augmentations=class_augmentations,\n            download=download)\n        super(Omniglot, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform, dataset_transform=dataset_transform)\n\n\nclass OmniglotClassDataset(ClassDataset):\n    folder = \'omniglot\'\n    download_url_prefix = \'https://github.com/brendenlake/omniglot/raw/master/python\'\n    zips_md5 = {\n        \'images_background\': \'68d2efa1b9178cc56df9314c21c6e718\',\n        \'images_evaluation\': \'6b91aef0f799c5bb55b94e3f2daec811\'\n    }\n\n    filename = \'data.hdf5\'\n    filename_labels = \'{0}{1}_labels.json\'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, use_vinyals_split=True, transform=None,\n                 class_augmentations=None, download=False):\n        super(OmniglotClassDataset, self).__init__(meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            class_augmentations=class_augmentations)\n\n        if self.meta_val and (not use_vinyals_split):\n            raise ValueError(\'Trying to use the meta-validation without the \'\n                \'Vinyals split. You must set `use_vinyals_split=True` to use \'\n                \'the meta-validation split.\')\n\n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.use_vinyals_split = use_vinyals_split\n        self.transform = transform\n\n        self.split_filename = os.path.join(self.root, self.filename)\n        self.split_filename_labels = os.path.join(self.root,\n            self.filename_labels.format(\'vinyals_\' if use_vinyals_split else \'\',\n            self.meta_split))\n\n        self._data = None\n        self._labels = None\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError(\'Omniglot integrity check failed\')\n        self._num_classes = len(self.labels)\n\n    def __getitem__(self, index):\n        character_name = \'/\'.join(self.labels[index % self.num_classes])\n        data = self.data[character_name]\n        transform = self.get_transform(index, self.transform)\n        target_transform = self.get_target_transform(index)\n\n        return OmniglotDataset(index, data, character_name,\n            transform=transform, target_transform=target_transform)\n\n    @property\n    def num_classes(self):\n        return self._num_classes\n\n    @property\n    def data(self):\n        if self._data is None:\n            self._data = h5py.File(self.split_filename, \'r\')\n        return self._data\n\n    @property\n    def labels(self):\n        if self._labels is None:\n            with open(self.split_filename_labels, \'r\') as f:\n                self._labels = json.load(f)\n        return self._labels\n\n    def _check_integrity(self):\n        return (os.path.isfile(self.split_filename)\n            and os.path.isfile(self.split_filename_labels))\n\n    def close(self):\n        if self._data is not None:\n            self._data.close()\n            self._data = None\n\n    def download(self):\n        import zipfile\n        import shutil\n\n        if self._check_integrity():\n            return\n\n        for name in self.zips_md5:\n            zip_filename = \'{0}.zip\'.format(name)\n            filename = os.path.join(self.root, zip_filename)\n            if os.path.isfile(filename):\n                continue\n\n            url = \'{0}/{1}\'.format(self.download_url_prefix, zip_filename)\n            download_url(url, self.root, zip_filename, self.zips_md5[name])\n\n            with zipfile.ZipFile(filename, \'r\') as f:\n                f.extractall(self.root)\n\n        filename = os.path.join(self.root, self.filename)\n        with h5py.File(filename, \'w\') as f:\n            for name in self.zips_md5:\n                group = f.create_group(name)\n\n                alphabets = list_dir(os.path.join(self.root, name))\n                characters = [(name, alphabet, character) for alphabet in alphabets\n                    for character in list_dir(os.path.join(self.root, name, alphabet))]\n\n                split = \'train\' if name == \'images_background\' else \'test\'\n                labels_filename = os.path.join(self.root,\n                    self.filename_labels.format(\'\', split))\n                with open(labels_filename, \'w\') as f_labels:\n                    labels = sorted(characters)\n                    json.dump(labels, f_labels)\n\n                for _, alphabet, character in characters:\n                    filenames = glob.glob(os.path.join(self.root, name,\n                        alphabet, character, \'*.png\'))\n                    dataset = group.create_dataset(\'{0}/{1}\'.format(alphabet,\n                        character), (len(filenames), 105, 105), dtype=\'uint8\')\n\n                    for i, char_filename in enumerate(filenames):\n                        image = Image.open(char_filename, mode=\'r\').convert(\'L\')\n                        dataset[i] = ImageOps.invert(image)\n\n                shutil.rmtree(os.path.join(self.root, name))\n\n        for split in [\'train\', \'val\', \'test\']:\n            filename = os.path.join(self.root, self.filename_labels.format(\n                \'vinyals_\', split))\n            data = get_asset(self.folder, \'{0}.json\'.format(split), dtype=\'json\')\n\n            with open(filename, \'w\') as f:\n                labels = sorted([(\'images_{0}\'.format(name), alphabet, character)\n                    for (name, alphabets) in data.items()\n                    for (alphabet, characters) in alphabets.items()\n                    for character in characters])\n                json.dump(labels, f)\n\n\nclass OmniglotDataset(Dataset):\n    def __init__(self, index, data, character_name,\n                 transform=None, target_transform=None):\n        super(OmniglotDataset, self).__init__(index, transform=transform,\n                                              target_transform=target_transform)\n        self.data = data\n        self.character_name = character_name\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        image = Image.fromarray(self.data[index])\n        target = self.character_name\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (image, target)\n'"
torchmeta/datasets/pascal5i.py,0,"b'""""""\n;==========================================\n; Title: Pascal-5i Dataset for Few-shot Object Segmentation\n; Author: Mennatullah Siam\n; Company: Huawei Technologies\n; Date:   18 March 2020\n;==========================================\n""""""\nimport os\nimport json\nimport glob\nimport h5py\nfrom PIL import Image, ImageOps\n\nfrom torchmeta.utils.data import Dataset, ClassDataset, CombinationMetaDataset\nfrom torchvision.datasets.utils import list_dir, download_url\nfrom torchmeta.datasets.utils import get_asset\nimport numpy as np\n\nclass Pascal5i(CombinationMetaDataset):\n    """"""\n    Pascal5i dataset [1]. A dataset for few-shot object segmentation supporting 4 folds\n    each fold has 15 training classes and 5 testing classes.\n    Using Preprocessed Masks from [2]\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `omniglot` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to ""N"" in ""N-way""\n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one\n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the\n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one\n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`,\n        and `meta_test` if all three are set to `False`.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed\n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a\n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These classes\n        are transformations of existing classes. E.g.\n        `torchmeta.transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the zip files and processes the dataset in the root\n        directory (under the `omniglot` folder). If the dataset is already\n        available, this does not download/process the dataset again.\n\n    fold : int (default: 0)\n        Fold number ranges between 0-3 that controls training(15) and testing(5) classes.\n\n    Notes\n    -----\n    Currently Only 1-way is supported\n\n    References\n    ----------\n    .. [1] Shaban, Amirreza, et al. ""One-shot learning for semantic segmentation.""\n            arXiv preprint arXiv:1709.03410 (2017).\n    .. [2] Zhang, Chi, et al. ""Canet: Class-agnostic segmentation networks with\n            iterative refinement and attentive few-shot learning.""\n            Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_test=False, meta_split=None,\n                 transform=None, target_transform=None,\n                 dataset_transform=None, class_augmentations=None,\n                 download=False, fold=0):\n\n        dataset = Pascal5iClassDataset(root, meta_train=meta_train,\n                                       meta_test=meta_test, transform=transform,\n                                       meta_split=meta_split, class_augmentations=class_augmentations,\n                                       download=download, fold=fold)\n\n        super(Pascal5i, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform, dataset_transform=dataset_transform)\n\nclass Pascal5iClassDataset(ClassDataset):\n    folder = \'pascal5i\'\n\n    downloads = [\n    {\n        \'url\' : \'http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\',\n        \'filename\' : \'VOCtrainval_11-May-2012.tar\',\n        \'md5\' : \'6cd6e144f989b92b3379bac3b3de84fd\'\n    },\n    {\n        \'url\' : \'https://github.com/icoz69/CaNet/raw/master/Binary_map_aug.zip\',\n        \'filename\': \'Binary_map_aug.zip\',\n        \'md5\': None\n    },\n    {\n        \'url\' : \'https://raw.github.com/NVIDIA/DIGITS/master/examples/semantic-segmentation/pascal-voc-classes.txt\',\n        \'filename\' : \'pascal-voc-classes.txt\',\n        \'md5\' : None\n    }\n    ]\n    split_filename_labels = \'pascal-voc-classes.txt\'\n\n    def __init__(self, root, meta_train=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False, fold=0):\n\n        super(Pascal5iClassDataset, self).__init__(meta_train=meta_train,\n            meta_val=False, meta_test=meta_test, meta_split=meta_split,\n            class_augmentations=class_augmentations)\n\n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.transform = transform\n\n        self.fold = fold\n\n        self._data = None\n        self._labels = None\n        self._masks = None\n\n        if download:\n            self.download()\n\n        self._num_classes = len(self.labels)\n\n    def __getitem__(self, index):\n        class_name = self.labels[index % self.num_classes]\n        data, masks = self.data[0][class_name], self.data[1][class_name]\n        transform = self.get_transform(index, self.transform)\n        target_transform = self.get_target_transform(index)\n        class_id = self.read_labels().index(class_name)\n\n        return PascalDataset((data, masks), class_id, transform=transform,\n            target_transform=target_transform)\n\n    @property\n    def num_classes(self):\n        return self._num_classes\n\n    def load_dict_per_class(self):\n        new_exist_class_list = {}\n\n        if self.meta_split == \'train\':\n            fold_list=[0, 1, 2, 3]\n            fold_list.remove(self.fold)\n        else:\n            fold_list = [self.fold]\n\n        for fold in fold_list:\n            f = open(os.path.join(self.root, \'Binary_map_aug\', self.meta_split,\n                                  \'split%1d_%s.txt\'%(fold, self.meta_split)))\n            while True:\n                item = f.readline()\n                if item == \'\':\n                    break\n                img_name = item[:11]\n                cat = int(item[13:15])\n                if cat not in new_exist_class_list:\n                    new_exist_class_list[cat] = []\n                new_exist_class_list[cat].append(img_name)\n\n        images = {}\n        masks = {}\n        classes_names = self.read_labels()\n\n        for k, v in new_exist_class_list.items():\n            cname = classes_names[k]\n            for path in v:\n                fname = os.path.join(self.root, \'VOCdevkit/VOC2012/JPEGImages\', path + \'.jpg\')\n                if cname not in images:\n                    images[cname] = []\n                images[cname].append(fname)\n                fname = os.path.join(self.root, \'Binary_map_aug\', self.meta_split, str(k),\n                                               path + \'.png\')\n                if cname not in masks:\n                    masks[cname] = []\n                masks[cname].append(fname)\n        return images, masks\n\n    @property\n    def data(self):\n        if self._data is None:\n            self._data, self._masks = self.load_dict_per_class()\n        return self._data, self._masks\n\n    def read_labels(self, fold=None):\n        labels = []\n        if fold is not None:\n            if self.meta_train:\n                in_classes = set(range(21)) - \\\n                                set(range(fold*5+1, (fold+1)*5+1))\n            else:\n                in_classes = set(range(fold*5+1, (fold+1)*5+1))\n        else:\n            in_classes = set(range(21))\n\n        with open(os.path.join(self.root, self.split_filename_labels), \'r\') as f:\n            for it, line in enumerate(f):\n                if line.strip() == \'\':\n                    break\n                if it in in_classes:\n                    labels.append(line.strip())\n        return labels\n\n    @property\n    def labels(self):\n        if self._labels is None:\n           self._labels = self.read_labels(self.fold)\n        return self._labels[1:]\n\n    def download(self):\n        import zipfile\n        import tarfile\n        import shutil\n\n        for dload in self.downloads:\n            filename = os.path.join(self.root, dload[\'filename\'])\n            if os.path.isfile(filename):\n                continue\n\n            download_url(dload[\'url\'], self.root, dload[\'filename\'], dload[\'md5\'])\n\n            if \'zip\' in dload[\'filename\']:\n                with zipfile.ZipFile(filename, \'r\') as f:\n                    f.extractall(self.root)\n            elif \'tar\' in dload[\'filename\']:\n                with tarfile.open(filename, \'r\') as f:\n                    f.extractall(self.root)\n\nclass PascalDataset(Dataset):\n    def __init__(self, data, class_id, transform=None, target_transform=None):\n        super(PascalDataset, self).__init__(transform=transform,\n            target_transform=target_transform)\n        self.data, self.masks = data\n        self.class_id = class_id\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        image = Image.open(self.data[index])\n        mask = Image.open(self.masks[index])\n        target = self.class_id\n\n        if self.transform is not None:\n            image, mask = self.transform(image, mask)\n\n        return (image, mask, target)\n'"
torchmeta/datasets/tcga.py,2,"b'import os\nimport json\nimport h5py\nimport numpy as np\nimport torch\nimport copy\n\nfrom torchmeta.utils.data import Task, MetaDataset\nfrom torchmeta.datasets.utils import get_asset\n\n\nclass TCGA(MetaDataset):\n    """"""\n    The TCGA dataset [1]. A dataset of classification tasks over the values of\n    an attribute, based on the gene expression data from patients diagnosed with\n    specific types of cancer. This dataset is based on data from the Cancer\n    Genome Atlas Program from the National Cancer Institute.\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `omniglot` exists.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    min_samples_per_class : int (default: 5)\n        Minimum number of samples per class in each classification task. This\n        filters tasks for which the amount of data for one of the classes is\n        too small.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `transforms.ClassSplitter()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the files and processes the dataset in the root \n        directory (under the `tcga` folder). If the dataset is already \n        available, this does not download/process the dataset again.\n\n    chunksize : int (default: 100)\n        Size of the chunks to be processed when reading the CSV file. This is\n        only used while downloading and converting the dataset to HDF5.\n\n    preload : bool (default: `True`)\n        Opens the gene expression dataset and keeps a reference to it in memory.\n        This decreases the loading time of individual tasks.\n\n    Notes\n    -----\n    A task is the combination of a cancer type and an attribute. The data is the\n    gene expression of patients diagnosed with the cancer defined by the task.\n    It consists in a vector of size `(20530,)`. The task is to classify the\n    patients according to the attribute given by the task definition. The meta\n    train/validation/test splits are over 137/29/29 tasks (ie. types of cancer).\n    However, the number of tasks depends on the minimum number of samples per\n    class specified by `min_samples_per_class`.\n\n    References\n    ----------\n    .. [1] Samiei, M., Wurfl, T., Deleu, T., Weiss, M., Dutil, F., Fevens, T.,\n           Boucher, G., Lemieux, S., and Cohen, J. P. (2019). The TCGA\n           Meta-Dataset Clinical Benchmark. (https://arxiv.org/abs/1910.08636)\n    """"""\n    folder = \'tcga\'\n    clinical_matrix_url = \'https://tcga.xenahubs.net/download/TCGA.{0}.sampleMap/{0}_clinicalMatrix.gz\'\n    clinical_matrix_filename, _ = os.path.splitext(os.path.basename(clinical_matrix_url))\n    gene_expression_filename = \'TCGA_HiSeqV2.hdf5\'\n    gene_expression_torrent = \'e4081b995625f9fc599ad860138acf7b6eb1cf6f\'\n\n    filename_tasks = \'{0}_labels.json\'\n\n    _task_variables = None\n    _cancers = None\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False, meta_split=None,\n                 min_samples_per_class=5, transform=None, target_transform=None,\n                 dataset_transform=None, download=False, chunksize=100, preload=True):\n        super(TCGA, self).__init__(meta_train, meta_val, meta_test, meta_split,\n            target_transform=target_transform, dataset_transform=dataset_transform)\n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.min_samples_per_class = min_samples_per_class\n        self.transform = transform\n\n        self._all_sample_ids = None\n        self._gene_ids = None\n        self._tasks = None\n\n        if download:\n            self.download(chunksize)\n\n        self.preloaded = False\n        self.gene_expression_data = None\n        self.gene_expression_file = None\n        if preload:\n            self._preload_gene_expression_data()\n            self.preloaded = True\n\n        self.task_ids = self.get_task_ids()\n        self.split_filename_tasks = os.path.join(self.root,\n            self.filename_tasks.format(self.meta_split))\n\n    def __len__(self):\n        return len(self.task_ids)\n\n    @property\n    def gene_expression_path(self):\n        filename = os.path.join(self.root, self.gene_expression_filename)\n        if not os.path.isfile(filename):\n            raise IOError(\'Gene expression data not found at {}\'.format(filename))\n        return filename\n\n    @property\n    def tasks(self):\n        if self._tasks is None:\n            with open(self.split_filename_tasks, \'r\') as f:\n                self._tasks = [task for task in json.load(f) if tuple(task) in self.task_ids]\n        return self._tasks\n\n    @property\n    def cancers(self):\n        if self._cancers is None:\n            self._cancers = get_cancers()\n        return self._cancers\n\n    @property\n    def task_variables(self):\n        if self._task_variables is None:\n            self._task_variables = frozenset(get_task_variables())\n        return self._task_variables\n\n    @property\n    def gene_ids(self):\n        if self._gene_ids is None:\n            gene_ids_file = os.path.join(self.root, \'gene_ids.json\')\n            if not os.path.isfile(gene_ids_file):\n                raise IOError(\'Gene id data not found at {}\'.format(gene_ids_file))\n            with open(gene_ids_file, \'r\') as f:\n                self._gene_ids = set(json.load(f))\n        return self._gene_ids\n\n    @property\n    def all_sample_ids(self):\n        if self._all_sample_ids is None:\n            all_sample_ids_file = os.path.join(self.root, \'all_sample_ids.json\')\n            if not os.path.isfile(all_sample_ids_file):\n                raise IOError(\'All sample id data not found at {}\'.format(all_sample_ids_file))\n            with open(all_sample_ids_file, \'r\') as f:\n                all_sample_ids = json.load(f)\n            self._all_sample_ids = dict((v, k) for (k, v) in enumerate(all_sample_ids))\n        return self._all_sample_ids\n\n    def get_processed_filename(self, cancer):\n        processed_folder = os.path.join(self.root, \'clinicalMatrices\', \'processed\')\n        filename = \'{0}.tsv\'.format(self.clinical_matrix_filename.format(cancer))\n        filepath = os.path.join(processed_folder, filename)\n        if not os.path.isfile(filepath):\n            raise IOError(\'Clinical matrix file not found at {}\'.format(filepath))\n        return filepath\n\n    def __getitem__(self, index):\n        import pandas as pd\n\n        label, cancer = self.tasks[index]\n        filename = self.get_processed_filename(cancer)\n        dataframe = pd.read_csv(filename, sep=\'\\t\', index_col=0, header=0)\n        labels = dataframe[label].dropna().astype(\'category\')\n        labels = labels[self.task_ids[(label, cancer)]]\n\n        if self.gene_expression_file is not None:\n            data = self.gene_expression_data[labels.index]\n        else:\n            with h5py.File(self.gene_expression_path, \'r\') as f:\n                data = f[\'expression_data\'][labels.index]\n\n        task = TCGATask((label, cancer), data, labels.cat.codes.tolist(),\n                        labels.cat.categories.tolist(), transform=self.transform,\n                        target_transform=self.target_transform)\n\n        if self.dataset_transform is not None:\n            task = self.dataset_transform(task)\n\n        return task\n\n    def _preload_gene_expression_data(self):\n        self.gene_expression_file = h5py.File(self.gene_expression_path, \'r\')\n        self.gene_expression_data = self.gene_expression_file[\'expression_data\']\n\n    def _process_clinical_matrices(self):\n        import pandas as pd\n        clinical_matrices_folder = os.path.join(self.root, \'clinicalMatrices\')\n        processed_folder = os.path.join(clinical_matrices_folder, \'processed\')\n        if not os.path.exists(processed_folder):\n            os.makedirs(processed_folder)\n\n        col_in_task_variables = lambda col: (col == \'sampleID\') or (col in self.task_variables)\n\n        for cancer in self.cancers:\n            filename = self.clinical_matrix_filename.format(cancer)\n            filepath = os.path.join(clinical_matrices_folder, \'{0}.tsv\'.format(filename))\n            processed = os.path.join(processed_folder, \'{0}.tsv\'.format(filename))\n\n            if not os.path.isfile(processed):\n                raw_df = pd.read_csv(filepath, sep=\'\\t\', index_col=0, header=0,\n                                     usecols=col_in_task_variables)\n                dataframe = raw_df[raw_df.index.isin(self.all_sample_ids)]\n                dataframe.index = dataframe.index.map(lambda index: self.all_sample_ids[index])\n                dataframe.index.names = [\'index\']\n                dataframe = dataframe.sort_index(axis=0)\n                dataframe.to_csv(processed, sep=\'\\t\')\n        return True\n\n    def get_task_ids(self):\n        tasks = get_task_id_splits(self.meta_split)\n        task_ids = dict()\n\n        for task_id in tasks:\n            indices, counts = tasks[task_id]\n            enough_samples = all(count > self.min_samples_per_class for count in counts.values())\n            if enough_samples:\n                task_id = tuple(task_id.split(\'|\', 1))\n                task_ids[task_id] = indices\n\n        return task_ids\n\n    def download(self, chunksize=100):\n        try:\n            import gzip\n            import shutil\n            import pandas as pd\n            from six.moves import urllib\n            import academictorrents as at\n        except ImportError as exception:\n            raise ImportError(\'{0}. To use the TCGA dataset, you need to \'\n                \'install the necessary dependencies with \'\n                \'`pip install torchmeta[tcga]`.\'.format(exception.message))\n\n        clinical_matrices_folder = os.path.join(self.root, \'clinicalMatrices\')\n        if not os.path.exists(clinical_matrices_folder):\n            os.makedirs(clinical_matrices_folder)\n\n        for cancer in self.cancers:\n            filename = self.clinical_matrix_filename.format(cancer)\n            rawpath = os.path.join(clinical_matrices_folder, \'{0}.gz\'.format(filename))\n            filepath = os.path.join(clinical_matrices_folder, \'{0}.tsv\'.format(filename))\n\n            if os.path.isfile(filepath):\n                continue\n\n            if not os.path.exists(rawpath):\n                print(\'Downloading `{0}.gz`...\'.format(filename))\n                url = self.clinical_matrix_url.format(cancer)\n                urllib.request.urlretrieve(url, rawpath)\n\n            print(\'Extracting `{0}.gz`...\'.format(filename))\n            with gzip.open(rawpath, \'rb\') as gzf:\n                with open(filepath, \'wb\') as f:\n                    shutil.copyfileobj(gzf, f)\n\n        gene_expression_file = os.path.join(self.root, self.gene_expression_filename)\n        if not os.path.isfile(gene_expression_file):\n            from tqdm import tqdm\n            print(\'Downloading `{0}` using `academictorrents`...\'.format(\n                self.gene_expression_filename))\n            csv_file = at.get(self.gene_expression_torrent, datastore=self.root)\n            print(\'Downloaded to: `{0}`\'.format(csv_file))\n\n            print(\'Converting TCGA CSV dataset to HDF5. This may take a while, \'\n                  \'but only happens on the first run.\')\n            reader = pd.read_csv(csv_file, compression=\'gzip\', sep=\'\\t\',\n                                 header=0, index_col=0, chunksize=chunksize)\n            shape = (10459, 20530)\n\n            with tqdm(total=shape[1]) as pbar:\n                with h5py.File(gene_expression_file, \'w\') as f:\n                    dataset = f.create_dataset(\'expression_data\',\n                                               shape=shape, dtype=\'f4\')\n                    gene_ids = []\n                    for idx, chunk in enumerate(reader):\n                        slice_ = slice(idx * chunksize, (idx + 1) * chunksize)\n                        dataset[:, slice_] = chunk.T\n                        gene_ids.extend(chunk.index)\n                        pbar.update(chunk.shape[0])\n                    all_sample_ids = chunk.columns.tolist()\n\n            gene_ids_file = os.path.join(self.root, \'gene_ids.json\')\n            with open(gene_ids_file, \'w\') as f:\n                json.dump(gene_ids, f)\n\n            all_sample_ids_file = os.path.join(self.root, \'all_sample_ids.json\')\n            with open(all_sample_ids_file, \'w\') as f:\n                json.dump(all_sample_ids, f)\n\n            if os.path.isfile(csv_file):\n                os.remove(csv_file)\n\n            print(\'Done\')\n\n        self._process_clinical_matrices()\n\n        # Create label files\n        for split in [\'train\', \'val\', \'test\']:\n            filename = os.path.join(self.root, self.filename_tasks.format(split))\n            data = get_asset(self.folder, \'{0}.json\'.format(split), dtype=\'json\')\n\n            with open(filename, \'w\') as f:\n                labels = sorted([key.split(\'|\', 1) for key in data])\n                json.dump(labels, f)\n\n        # Clean up\n        for cancer in self.cancers:\n            filename = self.clinical_matrix_filename.format(cancer)\n            rawpath = os.path.join(clinical_matrices_folder, \'{0}.gz\'.format(filename))\n            if os.path.isfile(rawpath):\n                os.remove(rawpath)\n\n    def close(self):\n        if self.preloaded:\n            self.gene_expression_file.close()\n            self.gene_expression_data = None\n            self.gene_expression_file = None\n            self.preloaded = False\n\n    def open(self):\n        if self.preloaded:\n            self._preload_gene_expression_data()\n            self.preloaded = True\n\n\nclass TCGATask(Task):\n    @classmethod\n    def from_id(cls, root, task_id, transform=None, target_transform=None):\n        import pandas as pd\n        root = os.path.join(os.path.expanduser(root), TCGA.folder)\n        gene_filepath = os.path.join(root, TCGA.gene_expression_filename)\n        if not os.path.isfile(gene_filepath):\n            raise IOError()\n\n        label, cancer = task_id\n\n        processed_folder = os.path.join(root, \'clinicalMatrices\', \'processed\')\n        filename = \'{0}.tsv\'.format(TCGA.clinical_matrix_filename.format(cancer))\n        filepath = os.path.join(processed_folder, filename)\n        if not os.path.isfile(filepath):\n            raise IOError()\n\n        dataframe = pd.read_csv(filepath, sep=\'\\t\', index_col=0, header=0)\n        labels = dataframe[label].dropna().astype(\'category\')\n\n        with h5py.File(gene_filepath, \'r\') as f:\n            data = f[\'expression_data\'][labels.index]\n\n        return cls(task_id, data, labels.cat.codes.tolist(),\n                   labels.cat.categories.tolist(), transform=transform,\n                   target_transform=target_transform)\n\n    def __init__(self, task_id, data, labels, categories,\n                 transform=None, target_transform=None):\n        super(TCGATask, self).__init__(task_id, len(categories),\n            transform=transform, target_transform=target_transform)\n        self.id = task_id\n        self.data = data\n        self.labels = labels\n        self.categories = categories\n\n    @property\n    def input_size(self):\n        return len(self.data[0])\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __iter__(self):\n        for index in range(len(self)):\n            yield self[index]\n\n    def __getitem__(self, index):\n        sample = self.data[index]\n        target = self.labels[index]\n\n        if self.transform is not None:\n            sample = self.transform(sample)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (sample, target)\n\n\ndef _assign_samples(tcga_metadataset):\n    import pandas as pd\n    import munkres\n\n    blacklist = []\n    sample_to_task_assignment = {}\n    for cancer in get_cancers():\n        filename = tcga_metadataset.get_processed_filename(cancer)\n        dataframe = pd.read_csv(filename, sep=\'\\t\', index_col=0, header=0)\n        dataframe = dataframe.drop(blacklist, errors=\'ignore\')\n        permutation = dataframe.index[torch.randperm(len(dataframe.index))]\n        dataframe = dataframe.reindex(permutation)\n        labels = dataframe.notna()\n        labels = labels.applymap(lambda x: 1. if x else munkres.DISALLOWED)\n        all_disallowed = labels.apply(lambda x: True if all(x == munkres.DISALLOWED) else False, axis=1)\n        labels = labels.drop(labels[all_disallowed].index)\n\n        matrix = labels.values\n        shape = matrix.shape\n        # The +5 allows for some slack in the assignment\n        # which is necessary for the used implementation to converge on BRCA\n        repeats = np.int(np.ceil(shape[0] / shape[1])) + 5\n        expanded_matrix = np.tile(matrix, (1, repeats))\n\n        indices = munkres.Munkres().compute(expanded_matrix)\n        mapped_indices = [(a, b % shape[1]) for a, b in indices]\n\n        for index, mapped_index in mapped_indices:\n            sample_to_task_assignment.setdefault((dataframe.columns[mapped_index], cancer), []).append(\n                dataframe.index[index])\n\n        blacklist.extend(dataframe.index.tolist())\n\n    return sample_to_task_assignment\n\n\ndef _expand_sample_usage(meta_dataset, all_allowed_samples, additional_samples):\n    expanded_metadataset = {}\n    all_samples_of_metadataset = set()\n    for key, value in meta_dataset.items():\n        all_samples_of_metadataset.update(value)\n    all_samples_of_metadataset.update(additional_samples)\n\n    used_additional_samples = set()\n    for key in meta_dataset.keys():\n        allowed_samples = set(all_allowed_samples[key])\n        intersection = allowed_samples.intersection(all_samples_of_metadataset)\n        expanded_metadataset[key] = list(intersection)\n        used_additional_samples = additional_samples.intersection(intersection)\n\n    return expanded_metadataset, used_additional_samples\n\n\ndef _split_tcga(tcga_metadataset, counts):\n    all_allowed_samples = tcga_metadataset.task_ids\n\n    # We first uniquely assing every sample to a task\n    sample_to_task_assignment = _assign_samples(tcga_metadataset)\n\n    keys = [i for i in all_allowed_samples.keys()]\n    difference = set(sample_to_task_assignment.keys()).difference(set(keys))\n\n    unassigned_samples = set()\n    for key in difference:\n        unassigned_samples.update(sample_to_task_assignment[key])\n\n    # Second we split the metadataset\n    # with a torch-based random sample\n    permutation = torch.randperm(len(keys)).numpy()\n\n    metadatasets = []\n    start = 0\n    end = 0\n    for count in counts:\n        end += count\n        current_keys = [keys[index] for index in permutation[start:end]]\n        metadatasets.append({key: sample_to_task_assignment[key] for key in current_keys})\n        start = end\n\n    expanded_metadatasets = [None] * len(metadatasets)\n    order = np.argsort([len(metadataset) for metadataset in metadatasets])\n\n    # Finally we expand the tasks by reusing samples wherever possible in the sets\n    blacklist = set()\n    for i in order:\n        additional_samples = unassigned_samples.difference(blacklist)\n        expanded_metadataset, used_additional_samples = _expand_sample_usage(metadatasets[i], all_allowed_samples,\n                                                                             additional_samples)\n        expanded_metadatasets[i] = (expanded_metadataset)\n        blacklist.update(used_additional_samples)\n\n    tcga_metadatasets = []\n    tcga_metadataset.close()\n    preloaded = tcga_metadataset.preloaded\n    for metadataset in expanded_metadatasets:\n        current_tcga_metadataset = copy.deepcopy(tcga_metadataset)\n        current_tcga_metadataset.task_ids = metadataset\n        if preloaded:\n            current_tcga_metadataset.open()\n        tcga_metadatasets.append(current_tcga_metadataset)\n\n    return tcga_metadatasets\n\n\ndef get_cancers():\n    return get_asset(TCGA.folder, \'cancers.json\', dtype=\'json\')\n\n\ndef get_task_variables():\n    return get_asset(TCGA.folder, \'task_variables.json\', dtype=\'json\')\n\n\ndef get_task_id_splits(meta_split):\n    return get_asset(TCGA.folder, \'{}.json\'.format(meta_split), dtype=\'json\')\n'"
torchmeta/datasets/tieredimagenet.py,0,"b'import numpy as np\nfrom PIL import Image\nimport h5py\nimport json\nimport os\nimport io\nimport pickle\n\nfrom torchmeta.utils.data import Dataset, ClassDataset, CombinationMetaDataset\nfrom torchvision.datasets.utils import download_file_from_google_drive\n\n\nclass TieredImagenet(CombinationMetaDataset):\n    """"""\n    The Tiered-Imagenet dataset, introduced in [1]. This dataset contains images \n    of 608 different classes from the ILSVRC-12 dataset (Imagenet challenge).\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `tieredimagenet` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to ""N"" in ""N-way"" \n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These classes \n        are transformations of existing classes. E.g.\n        `torchmeta.transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the pickle files and processes the dataset in the root \n        directory (under the `tieredimagenet` folder). If the dataset is already \n        available, this does not download/process the dataset again.\n\n    Notes\n    -----\n    The dataset is downloaded from [this repository]\n    (https://github.com/renmengye/few-shot-ssl-public/). The dataset contains \n    images from 34 categories. The meta train/validation/test splits are over \n    20/6/8 categories. Each category contains between 10 and 30 classes. The \n    splits over categories (instead of over classes) ensures that all the training \n    classes are sufficiently distinct from the test classes (unlike Mini-Imagenet).\n\n    References\n    ----------\n    .. [1] Ren, M., Triantafillou, E., Ravi, S., Snell, J., Swersky, K., \n           Tenenbaum, J.B., Larochelle, H. and Zemel, R.S. (2018). Meta-learning \n           for semi-supervised few-shot classification. International Conference \n           on Learning Representations. (https://arxiv.org/abs/1803.00676)\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_val=False, meta_test=False, meta_split=None,\n                 transform=None, target_transform=None, dataset_transform=None,\n                 class_augmentations=None, download=False):\n        dataset = TieredImagenetClassDataset(root, meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            transform=transform, class_augmentations=class_augmentations,\n            download=download)\n        super(TieredImagenet, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform, dataset_transform=dataset_transform)\n\n\nclass TieredImagenetClassDataset(ClassDataset):\n    folder = \'tieredimagenet\'\n    # Google Drive ID from https://github.com/renmengye/few-shot-ssl-public\n    gdrive_id = \'1g1aIDy2Ar_MViF2gDXFYDBTR-HYecV07\'\n    tar_filename = \'tiered-imagenet.tar\'\n    tar_md5 = \'e07e811b9f29362d159a9edd0d838c62\'\n    tar_folder = \'tiered-imagenet\'\n\n    filename = \'{0}_data.hdf5\'\n    filename_labels = \'{0}_labels.json\'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False):\n        super(TieredImagenetClassDataset, self).__init__(meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            class_augmentations=class_augmentations)\n\n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.transform = transform\n\n        self._data_file = None\n        self._data = None\n        self._labels_specific = None\n\n        self.split_filename = os.path.join(self.root,\n            self.filename.format(self.meta_split))\n        self.split_filename_labels = os.path.join(self.root,\n            self.filename_labels.format(self.meta_split))\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError(\'TieredImagenet integrity check failed\')\n        self._num_classes = len(self.labels_specific)\n\n    @property\n    def data(self):\n        if self._data is None:\n            self._data_file = h5py.File(self.split_filename, \'r\')\n            self._data = self._data_file[\'datasets\']\n        return self._data\n\n    @property\n    def labels_specific(self):\n        if self._labels_specific is None:\n            with open(self.split_filename_labels, \'r\') as f:\n                self._labels_specific = json.load(f)\n        return self._labels_specific\n\n    def __getitem__(self, index):\n        specific_class_name = self.labels_specific[index % self.num_classes]\n        data = self.data[specific_class_name]\n        general_class_name = data.attrs[\'label_general\']\n        transform = self.get_transform(index, self.transform)\n        target_transform = self.get_target_transform(index)\n\n        return TieredImagenetDataset(index, data,\n            general_class_name, specific_class_name,\n            transform=transform, target_transform=target_transform)\n\n    @property\n    def num_classes(self):\n        return self._num_classes\n\n    def close(self):\n        if self._data_file is not None:\n            self._data_file.close()\n            self._data_file = None\n            self._data = None\n\n    def _check_integrity(self):\n        return (os.path.isfile(self.split_filename)\n            and os.path.isfile(self.split_filename_labels))\n\n    def download(self):\n        import tarfile\n        import shutil\n        from tqdm import tqdm\n\n        if self._check_integrity():\n            return\n\n        download_file_from_google_drive(self.gdrive_id, self.root,\n            self.tar_filename, md5=self.tar_md5)\n\n        filename = os.path.join(self.root, self.tar_filename)\n        with tarfile.open(filename, \'r\') as f:\n            f.extractall(self.root)\n        tar_folder = os.path.join(self.root, self.tar_folder)\n\n        for split in [\'train\', \'val\', \'test\']:\n            filename = os.path.join(self.root, self.filename.format(split))\n            if os.path.isfile(filename):\n                continue\n\n            images_filename = os.path.join(tar_folder, \'{0}_images_png.pkl\'.format(split))\n            if not os.path.isfile(images_filename):\n                raise IOError(images_filename)\n            with open(images_filename, \'rb\') as f:\n                images = pickle.load(f, encoding=\'bytes\')\n\n            labels_filename = os.path.join(tar_folder, \'{0}_labels.pkl\'.format(split))\n            if not os.path.isfile(labels_filename):\n                raise IOError()\n            with open(labels_filename, \'rb\') as f:\n                labels = pickle.load(f, encoding=\'latin1\')\n\n            labels_str = labels[\'label_specific_str\']\n            general_labels_str = labels[\'label_general_str\']\n            general_labels = labels[\'label_general\']\n            with open(os.path.join(self.root, self.filename_labels.format(split)), \'w\') as f:\n                json.dump(labels_str, f)\n\n            with h5py.File(filename, \'w\') as f:\n                group = f.create_group(\'datasets\')\n                dtype = h5py.special_dtype(vlen=np.uint8)\n                for i, label in enumerate(tqdm(labels_str, desc=filename)):\n                    indices, = np.where(labels[\'label_specific\'] == i)\n                    dataset = group.create_dataset(label, (len(indices),), dtype=dtype)\n                    general_idx = general_labels[indices[0]]\n                    dataset.attrs[\'label_general\'] = (general_labels_str[general_idx]\n                        if general_idx < len(general_labels_str) else \'\')\n                    dataset.attrs[\'label_specific\'] = label\n                    for j, k in enumerate(indices):\n                        dataset[j] = np.squeeze(images[k])\n\n        if os.path.isdir(tar_folder):\n            shutil.rmtree(tar_folder)\n\n\nclass TieredImagenetDataset(Dataset):\n    def __init__(self, index, data, general_class_name, specific_class_name,\n                 transform=None, target_transform=None):\n        super(TieredImagenetDataset, self).__init__(index, transform=transform,\n                                                    target_transform=target_transform)\n        self.data = data\n        self.general_class_name = general_class_name\n        self.specific_class_name = specific_class_name\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        image = Image.open(io.BytesIO(self.data[index]))\n        target = (self.general_class_name, self.specific_class_name)\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (image, target)\n'"
torchmeta/datasets/triplemnist.py,0,"b'import numpy as np\nfrom PIL import Image\nimport os\nimport io\nimport json\nimport glob\nimport h5py\n\nfrom torchmeta.utils.data import Dataset, ClassDataset, CombinationMetaDataset\nfrom torchvision.datasets.utils import download_file_from_google_drive\nfrom torchmeta.datasets.utils import get_asset\n\n\nclass TripleMNIST(CombinationMetaDataset):\n    """"""\n    The Triple MNIST dataset, introduced in [1]. This dataset is based on\n    the MNIST dataset [2]. It consists of sampled images from MNIST\n    that are put together to create images with multiple digits. It contains\n    1,000,000 images from 1000 different classes (1000 images per class, for \n    the numbers 000 to 999).\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `triplemnist` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to ""N"" in ""N-way"" \n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly\n        one of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly\n        one of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These\n        classes are transformations of existing classes. E.g.\n        `torchmeta.transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the pickle files and processes the dataset in the\n        root directory (under the `triplemnist` folder). If the dataset is\n        already available, this does not download/process the dataset again.\n\n    Notes\n    -----\n    The dataset is downloaded from the Multi-digit MNIST repository\n    [1](https://github.com/shaohua0116/MultiDigitMNIST). The dataset contains\n    images (MNIST triple digits) from 1000 classes, for the numbers 000 to 999.\n    The meta train/validation/test splits are 640/160/200 classes.\n    The splits are taken from [1].\n\n    References\n    ----------\n    .. [1] Sun, S. (2019). Multi-digit MNIST for Few-shot Learning.\n    (https://github.com/shaohua0116/MultiDigitMNIST)\n\n    .. [2] LeCun, Y., Cortes, C., and Burges, CJ. (2010). MNIST Handwritten\n    Digit Database. (http://yann.lecun.com/exdb/mnist)\n\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_val=False, meta_test=False, meta_split=None,\n                 transform=None, target_transform=None, dataset_transform=None,\n                 class_augmentations=None, download=False):\n        dataset = TripleMNISTClassDataset(root,\n            meta_train=meta_train, meta_val=meta_val,\n            meta_test=meta_test, meta_split=meta_split, transform=transform,\n            class_augmentations=class_augmentations, download=download)\n        super(TripleMNIST, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform,\n            dataset_transform=dataset_transform)\n\n\nclass TripleMNISTClassDataset(ClassDataset):\n    folder = \'triplemnist\'\n    # Google Drive ID from https://github.com/shaohua0116/MultiDigitMNIST\n    gdrive_id = \'1xqyW289seXYaDSqD2jaBPMKVAAjPP9ee\'\n    zip_filename = \'triple_mnist_seed_123_image_size_84_84.zip\'\n    zip_md5 = \'9508b047f9fbb834c02bc13ef44245da\'\n\n    filename = \'{0}_data.hdf5\'\n    filename_labels = \'{0}_labels.json\'\n\n    image_folder = \'triple_mnist_seed_123_image_size_84_84\'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False):\n        super(TripleMNISTClassDataset, self).__init__(meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            class_augmentations=class_augmentations)\n\n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.transform = transform\n\n        self.split_filename = os.path.join(self.root,\n            self.filename.format(self.meta_split))\n        self.split_filename_labels = os.path.join(self.root,\n            self.filename_labels.format(self.meta_split))\n\n        self._data_file = None\n        self._data = None\n        self._labels = None\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError(\'Triple MNIST integrity check failed\')\n        self._num_classes = len(self.labels)\n\n    def __getitem__(self, index):\n        label = self.labels[index % self.num_classes]\n        data = self.data[label]\n        transform = self.get_transform(index, self.transform)\n        target_transform = self.get_target_transform(index)\n\n        return TripleMNISTDataset(index, data, label, transform=transform,\n                                  target_transform=target_transform)\n\n    @property\n    def num_classes(self):\n        return self._num_classes\n\n    @property\n    def data(self):\n        if self._data is None:\n            self._data_file = h5py.File(self.split_filename, \'r\')\n            self._data = self._data_file[\'datasets\']\n        return self._data\n    \n    @property\n    def labels(self):\n        if self._labels is None:\n            with open(self.split_filename_labels, \'r\') as f:\n                self._labels = json.load(f)\n        return self._labels\n\n    def _check_integrity(self):\n        return (os.path.isfile(self.split_filename)\n            and os.path.isfile(self.split_filename_labels))\n\n    def close(self):\n        if self._data_file is not None:\n            self._data_file.close()\n            self._data_file = None\n            self._data = None\n\n    def download(self):\n        import zipfile\n        import shutil\n        import glob\n        from tqdm import tqdm\n\n        if self._check_integrity():\n            return\n\n        zip_filename = os.path.join(self.root, self.zip_filename)\n        if not os.path.isfile(zip_filename):\n            download_file_from_google_drive(self.gdrive_id, self.root,\n                self.zip_filename, md5=self.zip_md5)\n\n        zip_foldername = os.path.join(self.root, self.image_folder)\n        if not os.path.isdir(zip_foldername):\n            with zipfile.ZipFile(zip_filename, \'r\') as f:\n                for member in tqdm(f.infolist(), desc=\'Extracting \'):\n                    try:\n                        f.extract(member, self.root)\n                    except zipfile.BadZipFile:\n                        print(\'Error: Zip file is corrupted\')\n\n        for split in [\'train\', \'val\', \'test\']:\n            filename = os.path.join(self.root, self.filename.format(split))\n            if os.path.isfile(filename):\n                continue\n\n            labels = get_asset(self.folder, \'{0}.json\'.format(split))\n            labels_filename = os.path.join(self.root,\n                                           self.filename_labels.format(split))\n            with open(labels_filename, \'w\') as f:\n                json.dump(labels, f)\n\n            image_folder = os.path.join(zip_foldername, split)\n\n            with h5py.File(filename, \'w\') as f:\n                group = f.create_group(\'datasets\')\n                dtype = h5py.special_dtype(vlen=np.uint8)\n                for i, label in enumerate(tqdm(labels, desc=filename)):\n                    images = glob.glob(os.path.join(image_folder, label,\n                                                    \'*.png\'))\n                    images.sort()\n                    dataset = group.create_dataset(label, (len(images),),\n                                                   dtype=dtype)\n                    for i, image in enumerate(images):\n                        with open(image, \'rb\') as f:\n                            array = bytearray(f.read())\n                            dataset[i] = np.asarray(array, dtype=np.uint8)\n\n        if os.path.isdir(zip_foldername):\n            shutil.rmtree(zip_foldername)\n\n\nclass TripleMNISTDataset(Dataset):\n    def __init__(self, index, data, label,\n                 transform=None, target_transform=None):\n        super(TripleMNISTDataset, self).__init__(index, transform=transform,\n                                                 target_transform=target_transform)\n        self.data = data\n        self.label = label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        image = Image.open(io.BytesIO(self.data[index])).convert(\'RGB\')\n        target = self.label\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (image, target)\n'"
torchmeta/datasets/utils.py,0,"b""import os\nimport json\n\n\ndef get_asset_path(*args):\n    basedir = os.path.dirname(__file__)\n    return os.path.join(basedir, 'assets', *args)\n\n\ndef get_asset(*args, dtype=None):\n    filename = get_asset_path(*args)\n    if not os.path.isfile(filename):\n        raise IOError('{} not found'.format(filename))\n\n    if dtype is None:\n        _, dtype = os.path.splitext(filename)\n        dtype = dtype[1:]\n\n    if dtype == 'json':\n        with open(filename, 'r') as f:\n            data = json.load(f)\n    else:\n        raise NotImplementedError()\n    return data\n"""
torchmeta/modules/__init__.py,0,"b""from torchmeta.modules.batchnorm import MetaBatchNorm1d, MetaBatchNorm2d, MetaBatchNorm3d\nfrom torchmeta.modules.container import MetaSequential\nfrom torchmeta.modules.conv import MetaConv1d, MetaConv2d, MetaConv3d\nfrom torchmeta.modules.linear import MetaLinear, MetaBilinear\nfrom torchmeta.modules.module import MetaModule\nfrom torchmeta.modules.normalization import MetaLayerNorm\nfrom torchmeta.modules.parallel import DataParallel\n\n__all__ = [\n    'MetaBatchNorm1d', 'MetaBatchNorm2d', 'MetaBatchNorm3d',\n    'MetaSequential',\n    'MetaConv1d', 'MetaConv2d', 'MetaConv3d',\n    'MetaLinear', 'MetaBilinear',\n    'MetaModule',\n    'MetaLayerNorm',\n    'DataParallel'\n]"""
torchmeta/modules/batchnorm.py,3,"b""import torch.nn as nn\nimport torch.nn.functional as F\n\nfrom collections import OrderedDict\nfrom torch.nn.modules.batchnorm import _BatchNorm\nfrom torchmeta.modules.module import MetaModule\n\nclass _MetaBatchNorm(_BatchNorm, MetaModule):\n    def forward(self, input, params=None):\n        self._check_input_dim(input)\n        if params is None:\n            params = OrderedDict(self.named_parameters())\n\n        # exponential_average_factor is self.momentum set to\n        # (when it is available) only so that if gets updated\n        # in ONNX graph when this node is exported to ONNX.\n        if self.momentum is None:\n            exponential_average_factor = 0.0\n        else:\n            exponential_average_factor = self.momentum\n\n        if self.training and self.track_running_stats:\n            if self.num_batches_tracked is not None:\n                self.num_batches_tracked += 1\n                if self.momentum is None:  # use cumulative moving average\n                    exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n                else:  # use exponential moving average\n                    exponential_average_factor = self.momentum\n\n        weight = params.get('weight', None)\n        bias = params.get('bias', None)\n\n        return F.batch_norm(\n            input, self.running_mean, self.running_var, weight, bias,\n            self.training or not self.track_running_stats,\n            exponential_average_factor, self.eps)\n\nclass MetaBatchNorm1d(_MetaBatchNorm):\n    __doc__ = nn.BatchNorm1d.__doc__\n\n    def _check_input_dim(self, input):\n        if input.dim() != 2 and input.dim() != 3:\n            raise ValueError('expected 2D or 3D input (got {}D input)'\n                             .format(input.dim()))\n\nclass MetaBatchNorm2d(_MetaBatchNorm):\n    __doc__ = nn.BatchNorm2d.__doc__\n\n    def _check_input_dim(self, input):\n        if input.dim() != 4:\n            raise ValueError('expected 4D input (got {}D input)'\n                             .format(input.dim()))\n\nclass MetaBatchNorm3d(_MetaBatchNorm):\n    __doc__ = nn.BatchNorm3d.__doc__\n\n    def _check_input_dim(self, input):\n        if input.dim() != 5:\n            raise ValueError('expected 5D input (got {}D input)'\n                             .format(input.dim()))\n"""
torchmeta/modules/container.py,1,"b""import torch.nn as nn\n\nfrom torchmeta.modules.module import MetaModule\nfrom torchmeta.modules.utils import get_subdict\n\nclass MetaSequential(nn.Sequential, MetaModule):\n    __doc__ = nn.Sequential.__doc__\n\n    def forward(self, input, params=None):\n        for name, module in self._modules.items():\n            if isinstance(module, MetaModule):\n                input = module(input, params=get_subdict(params, name))\n            elif isinstance(module, nn.Module):\n                input = module(input)\n            else:\n                raise TypeError('The module must be either a torch module '\n                    '(inheriting from `nn.Module`), or a `MetaModule`. '\n                    'Got type: `{0}`'.format(type(module)))\n        return input\n"""
torchmeta/modules/conv.py,3,"b""import torch.nn as nn\nimport torch.nn.functional as F\n\nfrom collections import OrderedDict\nfrom torch.nn.modules.utils import _single, _pair, _triple\nfrom torchmeta.modules.module import MetaModule\n\nclass MetaConv1d(nn.Conv1d, MetaModule):\n    __doc__ = nn.Conv1d.__doc__\n\n    def forward(self, input, params=None):\n        if params is None:\n            params = OrderedDict(self.named_parameters())\n        bias = params.get('bias', None)\n\n        if self.padding_mode == 'circular':\n            expanded_padding = ((self.padding[0] + 1) // 2, self.padding[0] // 2)\n            return F.conv1d(F.pad(input, expanded_padding, mode='circular'),\n                            params['weight'], bias, self.stride,\n                            _single(0), self.dilation, self.groups)\n\n        return F.conv1d(input, params['weight'], bias, self.stride,\n                        self.padding, self.dilation, self.groups)\n\nclass MetaConv2d(nn.Conv2d, MetaModule):\n    __doc__ = nn.Conv2d.__doc__\n\n    def forward(self, input, params=None):\n        if params is None:\n            params = OrderedDict(self.named_parameters())\n        bias = params.get('bias', None)\n\n        if self.padding_mode == 'circular':\n            expanded_padding = ((self.padding[1] + 1) // 2, self.padding[1] // 2,\n                                (self.padding[0] + 1) // 2, self.padding[0] // 2)\n            return F.conv2d(F.pad(input, expanded_padding, mode='circular'),\n                            params['weight'], bias, self.stride,\n                            _pair(0), self.dilation, self.groups)\n\n        return F.conv2d(input, params['weight'], bias, self.stride,\n                        self.padding, self.dilation, self.groups)\n\nclass MetaConv3d(nn.Conv3d, MetaModule):\n    __doc__ = nn.Conv3d.__doc__\n\n    def forward(self, input, params=None):\n        if params is None:\n            params = OrderedDict(self.named_parameters())\n        bias = params.get('bias', None)\n\n        if self.padding_mode == 'circular':\n            expanded_padding = ((self.padding[2] + 1) // 2, self.padding[2] // 2,\n                                (self.padding[1] + 1) // 2, self.padding[1] // 2,\n                                (self.padding[0] + 1) // 2, self.padding[0] // 2)\n            return F.conv3d(F.pad(input, expanded_padding, mode='circular'),\n                            params['weight'], bias, self.stride,\n                            _triple(0), self.dilation, self.groups)\n\n        return F.conv3d(input, params['weight'], bias, self.stride,\n                        self.padding, self.dilation, self.groups)\n"""
torchmeta/modules/linear.py,2,"b""import torch.nn as nn\nimport torch.nn.functional as F\n\nfrom collections import OrderedDict\nfrom torchmeta.modules.module import MetaModule\n\nclass MetaLinear(nn.Linear, MetaModule):\n    __doc__ = nn.Linear.__doc__\n\n    def forward(self, input, params=None):\n        if params is None:\n            params = OrderedDict(self.named_parameters())\n        bias = params.get('bias', None)\n        return F.linear(input, params['weight'], bias)\n\nclass MetaBilinear(nn.Bilinear, MetaModule):\n    __doc__ = nn.Bilinear.__doc__\n\n    def forward(self, input1, input2, params=None):\n        if params is None:\n            params = OrderedDict(self.named_parameters())\n        bias = params.get('bias', None)\n        return F.bilinear(input1, input2, params['weight'], bias)\n"""
torchmeta/modules/module.py,2,"b'import torch\nimport torch.nn as nn\n\nfrom collections import OrderedDict\n\nclass MetaModule(nn.Module):\n    """"""\n    Base class for PyTorch meta-learning modules. These modules accept an\n    additional argument `params` in their `forward` method.\n\n    Notes\n    -----\n    Objects inherited from `MetaModule` are fully compatible with PyTorch\n    modules from `torch.nn.Module`. The argument `params` is a dictionary of\n    tensors, with full support of the computation graph (for differentiation).\n    """"""\n    def meta_named_parameters(self, prefix=\'\', recurse=True):\n        gen = self._named_members(\n            lambda module: module._parameters.items()\n            if isinstance(module, MetaModule) else [],\n            prefix=prefix, recurse=recurse)\n        for elem in gen:\n            yield elem\n\n    def meta_parameters(self, recurse=True):\n        for name, param in self.meta_named_parameters(recurse=recurse):\n            yield param\n'"
torchmeta/modules/normalization.py,2,"b""import torch.nn as nn\nimport torch.nn.functional as F\n\nfrom collections import OrderedDict\nfrom torchmeta.modules.module import MetaModule\n\nclass MetaLayerNorm(nn.LayerNorm, MetaModule):\n    __doc__ = nn.LayerNorm.__doc__\n\n    def forward(self, input, params=None):\n        if params is None:\n            params = OrderedDict(self.named_parameters())\n        weight = params.get('weight', None)\n        bias = params.get('bias', None)\n        return F.layer_norm(\n            input, self.normalized_shape, weight, bias, self.eps)\n"""
torchmeta/modules/parallel.py,5,"b""import torch\nfrom torch.nn import DataParallel as DataParallel_\nfrom torchmeta.modules.module import MetaModule\nfrom collections import OrderedDict\n\nfrom torch.nn.parallel import parallel_apply\nfrom torch.nn.parallel.scatter_gather import scatter_kwargs\nfrom torch.nn.parallel.replicate import _broadcast_coalesced_reshape\n\n\nclass DataParallel(DataParallel_, MetaModule):\n    __doc__ = DataParallel_.__doc__\n\n    def scatter(self, inputs, kwargs, device_ids):\n        try:\n            params = kwargs.pop('params')\n        except KeyError:\n            return super(DataParallel, self).scatter(inputs, kwargs, device_ids)\n\n        inputs_, kwargs_ = scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\n        # Add params argument unchanged back in kwargs\n        replicas = self._replicate_params(params, inputs_, device_ids,\n                                          detach=not torch.is_grad_enabled())\n        kwargs_ = tuple(dict(params=replica, **kwarg)\n                        for (kwarg, replica) in zip(kwargs_, replicas))\n        return inputs_, kwargs_\n\n    def _replicate_params(self, params, inputs, device_ids, detach=False):\n        if params is None:\n            return tuple(None for _ in inputs)\n\n        replicas = _broadcast_coalesced_reshape(list(params.values()),\n                                                device_ids[:len(inputs)],\n                                                detach)\n        replicas = tuple(OrderedDict(zip(params.keys(), replica))\n                         for replica in replicas)\n        return replicas\n"""
torchmeta/modules/utils.py,0,"b""import re\nfrom collections import OrderedDict\n\ndef get_subdict(dictionary, key=None):\n    if dictionary is None:\n        return None\n\n    if (key is None) or (key == ''):\n        return dictionary\n\n    key_re = re.compile(r'^{0}\\.(.+)'.format(re.escape(key)))\n    # Compatibility with DataParallel\n    if not any(filter(key_re.match, dictionary.keys())):\n        key_re = re.compile(r'^module\\.{0}\\.(.+)'.format(re.escape(key)))\n\n    return OrderedDict((key_re.sub(r'\\1', k), value) for (k, value)\n        in dictionary.items() if key_re.match(k) is not None)\n"""
torchmeta/tests/__init__.py,0,b''
torchmeta/toy/__init__.py,0,"b""from torchmeta.toy.harmonic import Harmonic\nfrom torchmeta.toy.sinusoid import Sinusoid\nfrom torchmeta.toy.sinusoid_line import SinusoidAndLine\n\nfrom torchmeta.toy import helpers\n\n__all__ = ['Harmonic', 'Sinusoid', 'SinusoidAndLine', 'helpers']\n"""
torchmeta/toy/harmonic.py,0,"b'import numpy as np\n\nfrom torchmeta.utils.data import Task, MetaDataset\n\n\nclass Harmonic(MetaDataset):\n    """"""\n    Simple regression task, based on the sum of two sine waves, as introduced\n    in [1].\n\n    Parameters\n    ----------\n    num_samples_per_task : int\n        Number of examples per task.\n\n    num_tasks : int (default: 5,000)\n        Overall number of tasks to sample.\n\n    noise_std : float, optional\n        Amount of noise to include in the targets for each task. If `None`, then\n        nos noise is included, and the target is the sum of 2 sine functions of\n        the input.\n\n    transform : callable, optional\n        A function/transform that takes a numpy array of size (1,) and returns a\n        transformed version of the input.\n\n    target_transform : callable, optional\n        A function/transform that takes a numpy array of size (1,) and returns a\n        transformed version of the target.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    Notes\n    -----\n    The tasks are created randomly as the sum of two sinusoid functions, with\n    a frequency ratio of 2. The amplitudes vary within [5.0, 7.0], the phases\n    within [0, 2 * pi], and the inputs are sampled according to N(mu_x, 1), with\n    mu_x varying in [-4.0, 4.0]. Due to the way PyTorch handles datasets, the\n    number of tasks to be sampled needs to be fixed ahead of time (with\n    `num_tasks`). This will typically be equal to `meta_batch_size * num_batches`.\n\n    References\n    ----------\n    .. [1] Lacoste A., Oreshkin B., Chung W., Boquet T., Rostamzadeh N.,\n           Krueger D. (2018). Uncertainty in Multitask Transfer Learning. In\n           Advances in Neural Information Processing Systems (https://arxiv.org/abs/1806.07528)\n    """"""\n    def __init__(self, num_samples_per_task, num_tasks=5000,\n                 noise_std=None, transform=None, target_transform=None,\n                 dataset_transform=None):\n        super(Harmonic, self).__init__(meta_split=\'train\',\n            target_transform=target_transform, dataset_transform=dataset_transform)\n        self.num_samples_per_task = num_samples_per_task\n        self.num_tasks = num_tasks\n        self.noise_std = noise_std\n        self.transform = transform\n\n        self._domain_range = np.array([-4.0, 4.0])\n        self._frequency_range = np.array([5.0, 7.0])\n        self._phase_range = np.array([0, 2 * np.pi])\n\n        self._domains = None\n        self._frequencies = None\n        self._phases = None\n        self._amplitudes = None\n\n    @property\n    def domains(self):\n        if self._domains is None:\n            self._domains = self.np_random.uniform(self._domain_range[0],\n                self._domain_range[1], size=self.num_tasks)\n        return self._domains\n\n    @property\n    def frequencies(self):\n        if self._frequencies is None:\n            self._frequencies = self.np_random.uniform(self._frequency_range[0],\n                self._frequency_range[1], size=self.num_tasks)\n        return self._frequencies\n\n    @property\n    def phases(self):\n        if self._phases is None:\n            self._phases = self.np_random.uniform(self._phase_range[0],\n                self._phase_range[1], size=(self.num_tasks, 2))\n        return self._phases\n\n    @property\n    def amplitudes(self):\n        if self._amplitudes is None:\n            self._amplitudes = self.np_random.randn(self.num_tasks, 2)\n        return self._amplitudes\n\n    def __len__(self):\n        return self.num_tasks\n\n    def __getitem__(self, index):\n        domain = self.domains[index]\n        frequency = self.frequencies[index]\n        phases = self.phases[index]\n        amplitudes = self.amplitudes[index]\n\n        task = HarmonicTask(index, domain, frequency, phases, amplitudes,\n            self.noise_std, self.num_samples_per_task, self.transform,\n            self.target_transform, np_random=self.np_random)\n\n        if self.dataset_transform is not None:\n            task = self.dataset_transform(task)\n\n        return task\n\n\nclass HarmonicTask(Task):\n    def __init__(self, index, domain, frequency, phases, amplitudes,\n                 noise_std, num_samples, transform=None,\n                 target_transform=None, np_random=None):\n        super(HarmonicTask, self).__init__(index, None) # Regression task\n        self.domain = domain\n        self.frequency = frequency\n        self.phases = phases\n        self.amplitudes = amplitudes\n        self.noise_std = noise_std\n        self.num_samples = num_samples\n\n        self.transform = transform\n        self.target_transform = target_transform\n\n        if np_random is None:\n            np_random = np.random.RandomState(None)\n\n        a_1, a_2 = self.amplitudes\n        b_1, b_2 = self.phases\n\n        self._inputs = self.domain + np_random.randn(num_samples, 1)\n        self._targets = (a_1 * np.sin(frequency * self._inputs + b_1)\n            + a_2 * np.sin(2 * frequency * self._inputs + b_2))\n        if (noise_std is not None) and (noise_std > 0.):\n            self._targets += noise_std * np_random.randn(num_samples, 1)\n\n    def __len__(self):\n        return self.num_samples\n\n    def __getitem__(self, index):\n        input, target = self._inputs[index], self._targets[index]\n\n        if self.transform is not None:\n            input = self.transform(input)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (input, target)\n'"
torchmeta/toy/helpers.py,0,"b'import warnings\n\nfrom torchmeta.toy import Sinusoid, Harmonic\nfrom torchmeta.transforms import ClassSplitter\n\ndef sinusoid(shots, shuffle=True, test_shots=None, seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the Sinusoid toy dataset.\n\n    Parameters\n    ----------\n    shots : int\n        Number of (training) examples in each task. This corresponds to `k` in\n        `k-shot` classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples in each task. If `None`, then the number of test\n        examples is equal to the number of training examples in each task.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `Sinusoid` class.\n\n    See also\n    --------\n    `torchmeta.toy.Sinusoid` : Meta-dataset for the Sinusoid toy dataset.\n    """"""\n    if \'num_samples_per_task\' in kwargs:\n        warnings.warn(\'Both arguments `shots` and `num_samples_per_task` were \'\n            \'set in the helper function for the number of samples in each task. \'\n            \'Ignoring the argument `shots`.\', stacklevel=2)\n        if test_shots is not None:\n            shots = kwargs[\'num_samples_per_task\'] - test_shots\n            if shots <= 0:\n                raise ValueError(\'The argument `test_shots` ({0}) is greater \'\n                    \'than the number of samples per task ({1}). Either use the \'\n                    \'argument `shots` instead of `num_samples_per_task`, or \'\n                    \'increase the value of `num_samples_per_task`.\'.format(\n                    test_shots, kwargs[\'num_samples_per_task\']))\n        else:\n            shots = kwargs[\'num_samples_per_task\'] // 2\n    if test_shots is None:\n        test_shots = shots\n\n    dataset = Sinusoid(num_samples_per_task=shots + test_shots, **kwargs)\n    dataset = ClassSplitter(dataset, shuffle=shuffle,\n        num_train_per_class=shots, num_test_per_class=test_shots)\n    dataset.seed(seed)\n\n    return dataset\n\ndef harmonic(shots, shuffle=True, test_shots=None, seed=None, **kwargs):\n    """"""Helper function to create a meta-dataset for the Harmonic toy dataset.\n\n    Parameters\n    ----------\n    shots : int\n        Number of (training) examples in each task. This corresponds to `k` in\n        `k-shot` classification.\n\n    shuffle : bool (default: `True`)\n        Shuffle the examples when creating the tasks.\n\n    test_shots : int, optional\n        Number of test examples in each task. If `None`, then the number of test\n        examples is equal to the number of training examples in each task.\n\n    seed : int, optional\n        Random seed to be used in the meta-dataset.\n\n    kwargs\n        Additional arguments passed to the `Harmonic` class.\n\n    See also\n    --------\n    `torchmeta.toy.Harmonic` : Meta-dataset for the Harmonic toy dataset.\n    """"""\n    if \'num_samples_per_task\' in kwargs:\n        warnings.warn(\'Both arguments `shots` and `num_samples_per_task` were \'\n            \'set in the helper function for the number of samples in each task. \'\n            \'Ignoring the argument `shots`.\', stacklevel=2)\n        if test_shots is not None:\n            shots = kwargs[\'num_samples_per_task\'] - test_shots\n            if shots <= 0:\n                raise ValueError(\'The argument `test_shots` ({0}) is greater \'\n                    \'than the number of samples per task ({1}). Either use the \'\n                    \'argument `shots` instead of `num_samples_per_task`, or \'\n                    \'increase the value of `num_samples_per_task`.\'.format(\n                    test_shots, kwargs[\'num_samples_per_task\']))\n        else:\n            shots = kwargs[\'num_samples_per_task\'] // 2\n    if test_shots is None:\n        test_shots = shots\n\n    dataset = Harmonic(num_samples_per_task=shots + test_shots, **kwargs)\n    dataset = ClassSplitter(dataset, shuffle=shuffle,\n        num_train_per_class=shots, num_test_per_class=test_shots)\n    dataset.seed(seed)\n\n    return dataset\n'"
torchmeta/toy/sinusoid.py,0,"b'import numpy as np\n\nfrom torchmeta.utils.data import Task, MetaDataset\n\n\nclass Sinusoid(MetaDataset):\n    """"""\n    Simple regression task, based on sinusoids, as introduced in [1].\n\n    Parameters\n    ----------\n    num_samples_per_task : int\n        Number of examples per task.\n\n    num_tasks : int (default: 1,000,000)\n        Overall number of tasks to sample.\n\n    noise_std : float, optional\n        Amount of noise to include in the targets for each task. If `None`, then\n        nos noise is included, and the target is a sine function of the input.\n\n    transform : callable, optional\n        A function/transform that takes a numpy array of size (1,) and returns a\n        transformed version of the input.\n\n    target_transform : callable, optional\n        A function/transform that takes a numpy array of size (1,) and returns a\n        transformed version of the target.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    Notes\n    -----\n    The tasks are created randomly as random sinusoid function. The amplitude\n    varies within [0.1, 5.0], the phase within [0, pi], and the inputs are\n    sampled uniformly in [-5.0, 5.0]. Due to the way PyTorch handles datasets,\n    the number of tasks to be sampled needs to be fixed ahead of time (with\n    `num_tasks`). This will typically be equal to `meta_batch_size * num_batches`.\n\n    References\n    ----------\n    .. [1] Finn C., Abbeel P., and Levine, S. (2017). Model-Agnostic Meta-Learning\n           for Fast Adaptation of Deep Networks. International Conference on\n           Machine Learning (ICML) (https://arxiv.org/abs/1703.03400)\n    """"""\n    def __init__(self, num_samples_per_task, num_tasks=1000000,\n                 noise_std=None, transform=None, target_transform=None,\n                 dataset_transform=None):\n        super(Sinusoid, self).__init__(meta_split=\'train\',\n            target_transform=target_transform, dataset_transform=dataset_transform)\n        self.num_samples_per_task = num_samples_per_task\n        self.num_tasks = num_tasks\n        self.noise_std = noise_std\n        self.transform = transform\n\n        self._input_range = np.array([-5.0, 5.0])\n        self._amplitude_range = np.array([0.1, 5.0])\n        self._phase_range = np.array([0, np.pi])\n\n        self._amplitudes = None\n        self._phases = None\n\n    @property\n    def amplitudes(self):\n        if self._amplitudes is None:\n            self._amplitudes = self.np_random.uniform(self._amplitude_range[0],\n                self._amplitude_range[1], size=self.num_tasks)\n        return self._amplitudes\n\n    @property\n    def phases(self):\n        if self._phases is None:\n            self._phases = self.np_random.uniform(self._phase_range[0],\n                self._phase_range[1], size=self.num_tasks)\n        return self._phases\n\n    def __len__(self):\n        return self.num_tasks\n\n    def __getitem__(self, index):\n        amplitude, phase = self.amplitudes[index], self.phases[index]\n        task = SinusoidTask(index, amplitude, phase, self._input_range,\n            self.noise_std, self.num_samples_per_task, self.transform,\n            self.target_transform, np_random=self.np_random)\n\n        if self.dataset_transform is not None:\n            task = self.dataset_transform(task)\n\n        return task\n\n\nclass SinusoidTask(Task):\n    def __init__(self, index, amplitude, phase, input_range, noise_std,\n                 num_samples, transform=None, target_transform=None,\n                 np_random=None):\n        super(SinusoidTask, self).__init__(index, None) # Regression task\n        self.amplitude = amplitude\n        self.phase = phase\n        self.input_range = input_range\n        self.num_samples = num_samples\n        self.noise_std = noise_std\n\n        self.transform = transform\n        self.target_transform = target_transform\n\n        if np_random is None:\n            np_random = np.random.RandomState(None)\n\n        self._inputs = np_random.uniform(input_range[0], input_range[1],\n            size=(num_samples, 1))\n        self._targets = amplitude * np.sin(self._inputs - phase)\n        if (noise_std is not None) and (noise_std > 0.):\n            self._targets += noise_std * np_random.randn(num_samples, 1)\n\n    def __len__(self):\n        return self.num_samples\n\n    def __getitem__(self, index):\n        input, target = self._inputs[index], self._targets[index]\n\n        if self.transform is not None:\n            input = self.transform(input)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (input, target)\n'"
torchmeta/toy/sinusoid_line.py,0,"b'import numpy as np\n\nfrom torchmeta.utils.data import Task, MetaDataset\nfrom torchmeta.toy.sinusoid import SinusoidTask\n\n\nclass SinusoidAndLine(MetaDataset):\n    """"""\n    Simple multimodal regression task, based on sinusoids and lines, as\n    introduced in [1].\n\n    Parameters\n    ----------\n    num_samples_per_task : int\n        Number of examples per task.\n\n    num_tasks : int (default: 1,000,000)\n        Overall number of tasks to sample.\n\n    noise_std : float, optional\n        Amount of noise to include in the targets for each task. If `None`, then\n        nos noise is included, and the target is either a sine function, or a\n        linear function of the input.\n\n    transform : callable, optional\n        A function/transform that takes a numpy array of size (1,) and returns a\n        transformed version of the input.\n\n    target_transform : callable, optional\n        A function/transform that takes a numpy array of size (1,) and returns a\n        transformed version of the target.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `torchmeta.transforms.ClassSplitter()`.\n\n    Notes\n    -----\n    The tasks are created randomly as either random sinusoid functions, or\n    random linear functions. The amplitude of the sinusoids varies within\n    [0.1, 5.0] and the phase within [0, pi]. The slope and intercept of the lines\n    vary in [-3.0, 3.0]. The inputs are sampled uniformly in [-5.0, 5.0]. Due to\n    the way PyTorch handles datasets, the number of tasks to be sampled needs to\n    be fixed ahead of time (with `num_tasks`). This will typically be equal to\n    `meta_batch_size * num_batches`.\n\n    References\n    ----------\n    .. [1] Finn C., Xu K., Levine S. (2018). Probabilistic Model-Agnostic\n           Meta-Learning. In Advances in Neural Information Processing Systems\n           (https://arxiv.org/abs/1806.02817)\n    """"""\n    def __init__(self, num_samples_per_task, num_tasks=1000000,\n                 noise_std=None, transform=None, target_transform=None,\n                 dataset_transform=None):\n        super(SinusoidAndLine, self).__init__(meta_split=\'train\',\n            target_transform=target_transform, dataset_transform=dataset_transform)\n        self.num_samples_per_task = num_samples_per_task\n        self.num_tasks = num_tasks\n        self.noise_std = noise_std\n        self.transform = transform\n\n        self._input_range = np.array([-5.0, 5.0])\n        self._amplitude_range = np.array([0.1, 5.0])\n        self._phase_range = np.array([0, np.pi])\n        self._slope_range = np.array([-3.0, 3.0])\n        self._intercept_range = np.array([-3.0, 3.0])\n\n        \n        self._is_sinusoid = None\n        self._amplitudes = None\n        self._phases = None\n        self._slopes = None\n        self._intercepts = None\n\n    @property\n    def amplitudes(self):\n        if self._amplitudes is None:\n            self._amplitudes = self.np_random.uniform(self._amplitude_range[0],\n                self._amplitude_range[1], size=self.num_tasks)\n        return self._amplitudes\n\n    @property\n    def phases(self):\n        if self._phases is None:\n            self._phases = self.np_random.uniform(self._phase_range[0],\n                self._phase_range[1], size=self.num_tasks)\n        return self._phases\n\n    @property\n    def slopes(self):\n        if self._slopes is None:\n            self._slopes = self.np_random.uniform(self._slope_range[0],\n                self._slope_range[1], size=self.num_tasks)\n        return self._slopes\n\n    @property\n    def intercepts(self):\n        if self._intercepts is None:\n            self._intercepts = self.np_random.uniform(self._intercept_range[0],\n                self._intercept_range[1], size=self.num_tasks)\n        return self._intercepts\n\n    @property\n    def is_sinusoid(self):\n        if self._is_sinusoid is None:\n            self._is_sinusoid = np.zeros((self.num_tasks,), dtype=np.bool_)\n            self._is_sinusoid[self.num_tasks // 2:] = True\n            self.np_random.shuffle(self._is_sinusoid)\n        return self._is_sinusoid\n\n    def __len__(self):\n        return self.num_tasks\n\n    def __getitem__(self, index):\n        if self.is_sinusoid[index]:\n            amplitude, phase = self.amplitudes[index], self.phases[index]\n            task = SinusoidTask(index, amplitude, phase, self._input_range,\n                self.noise_std, self.num_samples_per_task, self.transform,\n                self.target_transform, np_random=self.np_random)\n        else:\n            slope, intercept = self.slopes[index], self.intercepts[index]\n            task = LinearTask(index, slope, intercept, self._input_range,\n                self.noise_std, self.num_samples_per_task, self.transform,\n                self.target_transform, np_random=self.np_random)\n\n        if self.dataset_transform is not None:\n            task = self.dataset_transform(task)\n\n        return task\n\n\nclass LinearTask(Task):\n    def __init__(self, index, slope, intercept, input_range, noise_std,\n                 num_samples, transform=None, target_transform=None,\n                 np_random=None):\n        super(LinearTask, self).__init__(index, None) # Regression task\n        self.slope = slope\n        self.intercept = intercept\n        self.input_range = input_range\n        self.num_samples = num_samples\n        self.noise_std = noise_std\n\n        self.transform = transform\n        self.target_transform = target_transform\n\n        if np_random is None:\n            np_random = np.random.RandomState(None)\n\n        self._inputs = np_random.uniform(input_range[0], input_range[1],\n            size=(num_samples, 1))\n        self._targets = intercept + slope * self._inputs\n        if (noise_std is not None) and (noise_std > 0.):\n            self._targets += noise_std * np_random.randn(num_samples, 1)\n\n    def __len__(self):\n        return self.num_samples\n\n    def __getitem__(self, index):\n        input, target = self._inputs[index], self._targets[index]\n\n        if self.transform is not None:\n            input = self.transform(input)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (input, target)\n'"
torchmeta/transforms/__init__.py,0,"b'from torchmeta.transforms.categorical import Categorical, FixedCategory\nfrom torchmeta.transforms.augmentations import Rotation, HorizontalFlip, VerticalFlip\nfrom torchmeta.transforms.splitters import Splitter, ClassSplitter, WeightedClassSplitter\nfrom torchmeta.transforms.target_transforms import TargetTransform, DefaultTargetTransform, SegmentationPairTransform\n'"
torchmeta/transforms/augmentations.py,0,"b""import torchvision.transforms.functional as F\n\nclass Rotation(object):\n    def __init__(self, angle, resample=False, expand=False, center=None):\n        super(Rotation, self).__init__()\n        if isinstance(angle, (list, tuple)):\n            self._angles = angle\n            self.angle = None\n        else:\n            self._angles = [angle]\n            self.angle = angle\n            if angle % 360 == 0:\n                import warnings\n                warnings.warn('Applying a rotation of {0} degrees (`{1}`) as a '\n                    'class augmentation on a dataset is equivalent to the original '\n                    'dataset.'.format(angle, self), UserWarning, stacklevel=2)\n\n        self.resample = resample\n        self.expand = expand\n        self.center = center\n\n    def __iter__(self):\n        return iter(Rotation(angle, resample=self.resample, expand=self.expand,\n            center=self.center) for angle in self._angles)\n\n    def __call__(self, image):\n        if self.angle is None:\n            raise ValueError('The value of the angle is unspecified.')\n        # QKFIX: Explicitly compute the pixel fill value due to an\n        # incompatibility between Torchvision 0.5 and Pillow 7.0.0\n        # https://github.com/pytorch/vision/issues/1759#issuecomment-583826810\n        # Will be fixed in Torchvision 0.6\n        fill = tuple([0] * len(image.getbands()))\n        return F.rotate(image, self.angle % 360, self.resample,\n                        self.expand, self.center, fill=fill)\n\n    def __hash__(self):\n        return hash(repr(self))\n\n    def __eq__(self, other):\n        if (self.angle is None) or (other.angle is None):\n            return self._angles == other._angles\n        return (self.angle % 360) == (other.angle % 360)\n\n    def __repr__(self):\n        if self.angle is None:\n            return 'Rotation({0})'.format(', '.join(map(str, self._angles)))\n        else:\n            return 'Rotation({0})'.format(self.angle % 360)\n\n    def __str__(self):\n        if self.angle is None:\n            return 'Rotation({0})'.format(', '.join(map(str, self._angles)))\n        else:\n            return 'Rotation({0})'.format(self.angle)\n\nclass HorizontalFlip(object):\n    def __iter__(self):\n        return iter([HorizontalFlip()])\n\n    def __call__(self, image):\n        return F.hflip(image)\n\n    def __repr__(self):\n        return 'HorizontalFlip()'\n\nclass VerticalFlip(object):\n    def __iter__(self):\n        return iter([VerticalFlip()])\n\n    def __call__(self, image):\n        return F.vflip(image)\n\n    def __repr__(self):\n        return 'VerticalFlip()'\n"""
torchmeta/transforms/categorical.py,2,"b'import torch\nfrom torchmeta.transforms.utils import apply_wrapper\nfrom collections import defaultdict\n\nfrom torchmeta.transforms.target_transforms import TargetTransform\n\n\nclass Categorical(TargetTransform):\n    """"""Target transform to return labels in `[0, num_classes)`.\n\n    Parameters\n    ----------\n    num_classes : int, optional\n        Number of classes. If `None`, then the number of classes is inferred\n        from the number of individual labels encountered.\n\n    Examples\n    --------\n    >>> dataset = Omniglot(\'data\', num_classes_per_task=5, meta_train=True)\n    >>> task = dataset.sample_task()\n    >>> task[0]\n    (<PIL.Image.Image image mode=L size=105x105 at 0x11EC797F0>,\n    (\'images_evaluation/Glagolitic/character12\', None))\n\n    >>> dataset = Omniglot(\'data\', num_classes_per_task=5, meta_train=True,\n    ... target_transform=Categorical(5))\n    >>> task = dataset.sample_task()\n    >>> task[0]\n    (<PIL.Image.Image image mode=L size=105x105 at 0x11ED3F668>, 2)\n    """"""\n    def __init__(self, num_classes=None):\n        super(Categorical, self).__init__()\n        self.num_classes = num_classes\n        self._classes = None\n        self._labels = None\n\n    def reset(self):\n        self._classes = None\n        self._labels = None\n\n    @property\n    def classes(self):\n        if self._classes is None:\n            self._classes = defaultdict(None)\n            if self.num_classes is None:\n                default_factory = lambda: len(self._classes)\n            else:\n                default_factory = lambda: self.labels[len(self._classes)]\n            self._classes.default_factory = default_factory\n        if (self.num_classes is not None) and (len(self._classes) > self.num_classes):\n            raise ValueError(\'The number of individual labels ({0}) is greater \'\n                \'than the number of classes defined by `num_classes` \'\n                \'({1}).\'.format(len(self._classes), self.num_classes))\n        return self._classes\n\n    @property\n    def labels(self):\n        if (self._labels is None) and (self.num_classes is not None):\n            # TODO: Replace torch.randperm with seed-friendly counterpart\n            self._labels = torch.randperm(self.num_classes).tolist()\n        return self._labels\n\n    def __call__(self, target):\n        return self.classes[target]\n\n    def __repr__(self):\n        return \'{0}({1})\'.format(self.__class__.__name__, self.num_classes or \'\')\n\n\nclass FixedCategory(object):\n    def __init__(self, transform=None):\n        self.transform = transform\n\n    def __call__(self, index):\n        return (index, self.transform)\n\n    def __repr__(self):\n        return (\'{0}({1})\'.format(self.__class__.__name__, self.transform))\n'"
torchmeta/transforms/splitters.py,0,"b'import torch\nimport numpy as np\n\nfrom collections import OrderedDict, defaultdict\nfrom torchmeta.utils.data.task import Task, ConcatTask, SubsetTask\nfrom torchmeta.transforms.utils import apply_wrapper\n\n__all__ = [\'Splitter\', \'ClassSplitter\', \'WeightedClassSplitter\']\n\n\nclass Splitter(object):\n    def __init__(self, splits, random_state_seed):\n        self.splits = splits\n        self.random_state_seed = random_state_seed\n        self.seed(random_state_seed)\n\n    def seed(self, seed):\n        self.np_random = np.random.RandomState(seed=seed)\n\n    def get_indices(self, task):\n        if isinstance(task, ConcatTask):\n            indices = self.get_indices_concattask(task)\n        elif isinstance(task, Task):\n            indices = self.get_indices_task(task)\n        else:\n            raise ValueError(\'The task must be of type `ConcatTask` or `Task`, \'\n                \'Got type `{0}`.\'.format(type(task)))\n        return indices\n\n    def get_indices_task(self, task):\n        raise NotImplementedError(\'Method `get_indices_task` must be \'\n            \'implemented in classes inherited from `Splitter`.\')\n\n    def get_indices_concattask(self, task):\n        raise NotImplementedError(\'Method `get_indices_concattask` must be \'\n            \'implemented in classes inherited from `Splitter`.\')\n\n    def _get_class_indices(self, task):\n        class_indices = defaultdict(list)\n        if task.num_classes is None: # Regression task\n            class_indices[\'regression\'] = range(len(task))\n        else:\n            for index in range(len(task)):\n                sample = task[index]\n                if (not isinstance(sample, tuple)) or (len(sample) < 2):\n                    raise ValueError(\'In order to split the dataset in train/\'\n                        \'test splits, `Splitter` must access the targets. Each \'\n                        \'sample from a task must be a tuple with at least 2 \'\n                        \'elements, with the last one being the target.\')\n                class_indices[sample[-1]].append(index)\n\n            if len(class_indices) != task.num_classes:\n                raise ValueError(\'The number of classes detected in `Splitter` \'\n                    \'({0}) is different from the property `num_classes` ({1}) \'\n                    \'in task `{2}`.\'.format(len(class_indices),\n                    task.num_classes, task))\n\n        return class_indices\n\n    def __call__(self, task):\n        indices = self.get_indices(task)\n        return OrderedDict([(split, SubsetTask(task, indices[split]))\n            for split in self.splits])\n\n    def __len__(self):\n        return len(self.splits)\n\n\nclass ClassSplitter_(Splitter):\n    def __init__(self, shuffle=True, num_samples_per_class=None,\n                 num_train_per_class=None, num_test_per_class=None,\n                 num_support_per_class=None, num_query_per_class=None,\n                 random_state_seed=0):\n        """"""\n        Transforms a dataset into train/test splits for few-shot learning tasks,\n        based on a fixed number of samples per class for each split. This is a\n        dataset transformation to be applied as a `dataset_transform` in a\n        `MetaDataset`.\n\n        Parameters\n        ----------\n        shuffle : bool (default: `True`)\n            Shuffle the data in the dataset before the split.\n\n        num_samples_per_class : dict, optional\n            Dictionary containing the names of the splits (as keys) and the\n            corresponding number of samples per class in each split (as values).\n            If not `None`, then the arguments `num_train_per_class`,\n            `num_test_per_class`, `num_support_per_class` and\n            `num_query_per_class` are ignored.\n\n        num_train_per_class : int, optional\n            Number of samples per class in the training split. This corresponds\n            to the number of ""shots"" in ""k-shot learning"". If not `None`, this\n            creates an item `train` for each task.\n\n        num_test_per_class : int, optional\n            Number of samples per class in the test split. If not `None`, this\n            creates an item `test` for each task.\n\n        num_support_per_class : int, optional\n            Alias for `num_train_per_class`. If `num_train_per_class` is not\n            `None`, then this argument is ignored. If not `None`, this creates\n            an item `support` for each task.\n\n        num_query_per_class : int, optional\n            Alias for `num_test_per_class`. If `num_test_per_class` is not\n            `None`, then this argument is ignored. If not `None`, this creates\n            an item `query` for each task.\n\n        random_state_seed : int, optional\n            seed of the np.RandomState. Defaults to \'0\'.\n\n        Examples\n        --------\n        >>> transform = ClassSplitter(num_samples_per_class={\n        ...     \'train\': 5, \'test\': 15})\n        >>> dataset = Omniglot(\'data\', num_classes_per_task=5,\n        ...                    dataset_transform=transform, meta_train=True)\n        >>> task = dataset.sample_task()\n        >>> task.keys()\n        [\'train\', \'test\']\n        >>> len(task[\'train\']), len(task[\'test\'])\n        (25, 75)\n        """"""\n        self.shuffle = shuffle\n\n        if num_samples_per_class is None:\n            num_samples_per_class = OrderedDict()\n            if num_train_per_class is not None:\n                num_samples_per_class[\'train\'] = num_train_per_class\n            elif num_support_per_class is not None:\n                num_samples_per_class[\'support\'] = num_support_per_class\n            if num_test_per_class is not None:\n                num_samples_per_class[\'test\'] = num_test_per_class\n            elif num_query_per_class is not None:\n                num_samples_per_class[\'query\'] = num_query_per_class\n        assert len(num_samples_per_class) > 0\n\n        self._min_samples_per_class = sum(num_samples_per_class.values())\n        super(ClassSplitter_, self).__init__(num_samples_per_class, random_state_seed)\n\n    def get_indices_task(self, task):\n        all_class_indices = self._get_class_indices(task)\n        indices = OrderedDict([(split, []) for split in self.splits])\n\n        for name, class_indices in all_class_indices.items():\n            num_samples = len(class_indices)\n            if num_samples < self._min_samples_per_class:\n                raise ValueError(\'The number of samples for class `{0}` ({1}) \'\n                    \'is smaller than the minimum number of samples per class \'\n                    \'required by `ClassSplitter` ({2}).\'.format(name,\n                    num_samples, self._min_samples_per_class))\n\n            if self.shuffle:\n                seed = (hash(task) + self.random_state_seed) % (2 ** 32)\n                dataset_indices = np.random.RandomState(seed).permutation(num_samples)\n            else:\n                dataset_indices = np.arange(num_samples)\n\n            ptr = 0\n            for split, num_split in self.splits.items():\n                split_indices = dataset_indices[ptr:ptr + num_split]\n                if self.shuffle:\n                    self.np_random.shuffle(split_indices)\n                indices[split].extend([class_indices[idx] for idx in split_indices])\n                ptr += num_split\n\n        return indices\n\n    def get_indices_concattask(self, task):\n        indices = OrderedDict([(split, []) for split in self.splits])\n        cum_size = 0\n\n        for dataset in task.datasets:\n            num_samples = len(dataset)\n            if num_samples < self._min_samples_per_class:\n                raise ValueError(\'The number of samples for one class ({0}) \'\n                    \'is smaller than the minimum number of samples per class \'\n                    \'required by `ClassSplitter` ({1}).\'.format(num_samples,\n                    self._min_samples_per_class))\n\n            if self.shuffle:\n                seed = (hash(task) + self.random_state_seed) % (2 ** 32)\n                dataset_indices = np.random.RandomState(seed).permutation(num_samples)\n            else:\n                dataset_indices = np.arange(num_samples)\n\n            ptr = 0\n            for split, num_split in self.splits.items():\n                split_indices = dataset_indices[ptr:ptr + num_split]\n                if self.shuffle:\n                    self.np_random.shuffle(split_indices)\n                indices[split].extend(split_indices + cum_size)\n                ptr += num_split\n            cum_size += num_samples\n\n        return indices\n\n\nclass WeightedClassSplitter_(Splitter):\n    def __init__(self, shuffle=True, min_num_samples=1, max_num_samples=None,\n                 weights=None, train_weights=None, test_weights=None,\n                 support_weights=None, query_weights=None,\n                 force_equal_per_class=False, random_state_seed=0):\n        """"""\n        Transforms a dataset into train/test splits for few-shot learning tasks.\n        The number of samples per class is proportional to the number of samples\n        per class in the original dataset. This is a dataset transformation to\n        be applied as a `dataset_transform` in a `MetaDataset`.\n\n        Parameters\n        ----------\n        shuffle : bool (default: `True`)\n            Shuffle the data in the dataset before the split.\n\n        min_num_samples : int or dict, optional (default: 1)\n            Minimum number of samples per class.\n\n        max_num_samples : int or dict, optional\n            Maximum number of samples per class.\n\n        weights : dict, optional\n            Dictionary containing the names of the splits (as keys) and the\n            corresponding proportions of samples per class in each split (as\n            values). If not `None`, then the arguments `train_weights`,\n            `test_weights`, `support_weights` and `query_weights` are ignored.\n\n        train_weights : float, optional\n            Proportion of samples from each class in the training split. If not\n            `None`, this creates an item `train` for each task.\n\n        test_weights : float, optional\n            Proportion of samples from each class in the training split. If not\n            `None`, this creates an item `test` for each task.\n\n        support_weights : float, optional\n            Alias for `train_weights`. If `train_weights` is not `None`, then\n            this argument is ignored. If not `None`, this creates an item\n            `support` for each task.\n\n        query_weights : float, optional\n            Alias for `test_weights`. If `test_weights` is not `None`, then this\n            argument is ignored. If not `None`, this creates an item `query` for\n            each task.\n\n        force_equal_per_class : bool (default: `False`)\n            If `True`, then the number of samples per class is equal for each\n            class; this is then proportional to the number of samples in the\n            class with the minimum number of samples.\n\n        random_state_seed : int, optional\n            seed of the np.RandomState. Defaults to \'0\'.\n        """"""\n        self.shuffle = shuffle\n        self.force_equal_per_class = force_equal_per_class\n\n        if weights is None:\n            weights = OrderedDict()\n            if train_weights is not None:\n                weights[\'train\'] = train_weights\n            elif support_weights is not None:\n                weights[\'support\'] = support_weights\n            if test_weights is not None:\n                weights[\'test\'] = test_weights\n            elif query_weights is not None:\n                weights[\'query\'] = query_weights\n        assert len(weights) > 0\n        assert sum(weights.values()) <= 1.\n\n        if (min_num_samples is None) or isinstance(min_num_samples, int):\n            if min_num_samples is None:\n                min_num_samples = 0\n            self.min_num_samples = OrderedDict([(split, min_num_samples)\n                for split in weights])\n        elif isinstance(min_num_samples, dict):\n            self.min_num_samples = OrderedDict(min_num_samples)\n        else:\n            raise NotImplementedError(\'Argument `min_num_samples` in \'\n                \'`WeightedClassSplitter` must be of type `dict` or `int`. Got \'\n                \'type `{0}`.\'.format(type(min_num_samples)))\n\n        if max_num_samples is None:\n            self.max_num_samples = None\n        elif isinstance(max_num_samples, int):\n            self.max_num_samples = OrderedDict([(split, max_num_samples)\n                for split in weights])\n        elif isinstance(max_num_samples, dict):\n            self.max_num_samples = OrderedDict(max_num_samples)\n        else:\n            raise NotImplementedError(\'Argument `max_num_samples` in \'\n                \'`WeightedClassSplitter` must be of type `dict` or `int`. Got \'\n                \'type `{0}`.\'.format(type(min_num_samples)))\n\n        self._min_samples_per_class = sum(self.min_num_samples.values())\n        super(WeightedClassSplitter_, self).__init__(weights, random_state_seed)\n\n    def get_indices_task(self, task):\n        all_class_indices = self._get_class_indices(task)\n        indices = OrderedDict([(split, []) for split in self.splits])\n\n        min_samples = min([len(class_indices) for class_indices\n            in all_class_indices.values()])\n        if min_samples < self._min_samples_per_class:\n            raise ValueError(\'The smallest number of samples in a class ({0}) \'\n                    \'is smaller than the minimum number of samples per class \'\n                    \'required by `WeightedClassSplitter` ({1}).\'.format(\n                    min_samples, self._min_samples_per_class))\n\n        for class_indices in all_class_indices.values():\n            num_samples = (min_samples if self.force_equal_per_class\n                else len(class_indices))\n            if self.shuffle:\n                seed = (hash(task) + self.random_state_seed) % (2 ** 32)\n                dataset_indices = np.random.RandomState(seed).permutation(num_samples)\n            else:\n                dataset_indices = np.arange(num_samples)\n\n            ptr = 0\n            for split, weight in self.splits.items():\n                num_split = max(self.min_num_samples[split], int(weight * num_samples))\n                if self.max_num_samples is not None:\n                    num_split = min(self.max_num_samples[split], num_split)\n                split_indices = dataset_indices[ptr:ptr + num_split]\n                if self.shuffle:\n                    self.np_random.shuffle(split_indices)\n                indices[split].extend([class_indices[idx] for idx in split_indices])\n                ptr += num_split\n\n        return indices\n\n    def get_indices_concattask(self, task):\n        indices = OrderedDict([(split, []) for split in self.splits])\n        cum_size = 0\n\n        min_samples = min([len(dataset) for dataset in task.datasets])\n        if min_samples < self._min_samples_per_class:\n            raise ValueError(\'The smallest number of samples in a class ({0}) \'\n                    \'is smaller than the minimum number of samples per class \'\n                    \'required by `WeightedClassSplitter` ({1}).\'.format(\n                    min_samples, self._min_samples_per_class))\n\n        for dataset in task.datasets:\n            num_samples = (min_samples if self.force_equal_per_class\n                else len(dataset))\n            if self.shuffle:\n                seed = (hash(task) + self.random_state_seed) % (2 ** 32)\n                dataset_indices = np.random.RandomState(seed).permutation(num_samples)\n            else:\n                dataset_indices = np.arange(num_samples)\n\n            ptr = 0\n            for split, weight in self.splits.items():\n                num_split = max(self.min_num_samples, int(weight * num_samples))\n                split_indices = dataset_indices[ptr:ptr + num_split]\n                if self.shuffle:\n                    self.np_random.shuffle(split_indices)\n                indices[split].extend(split_indices + cum_size)\n            cum_size += num_samples\n\n        return indices\n\n\ndef ClassSplitter(task=None, *args, **kwargs):\n    return apply_wrapper(ClassSplitter_(*args, **kwargs), task)\n\ndef WeightedClassSplitter(task=None, *args, **kwargs):\n    return apply_wrapper(WeightedClassSplitter_(*args, **kwargs), task)\n'"
torchmeta/transforms/target_transforms.py,0,"b'from torchvision.transforms import Compose, Resize, ToTensor\nimport PIL\n\nclass SegmentationPairTransform(object):\n    def __init__(self, target_size):\n        self.image_transform = Compose([Resize((target_size, target_size)), ToTensor()])\n        self.mask_transform = Compose([Resize((target_size, target_size),\n                                               interpolation=PIL.Image.NEAREST),\n                                       ToTensor()])\n\n    def __call__(self, image, mask):\n        image = self.image_transform(image)\n        mask = self.mask_transform(mask)\n        return image, mask\n\nclass TargetTransform(object):\n    def __call__(self, target):\n        raise NotImplementedError()\n\n    def __repr__(self):\n        return str(self.__class__.__name__)\n\n\nclass DefaultTargetTransform(TargetTransform):\n    def __init__(self, class_augmentations):\n        super(DefaultTargetTransform, self).__init__()\n        self.class_augmentations = class_augmentations\n\n        self._augmentations = dict((augmentation, i + 1)\n            for (i, augmentation) in enumerate(class_augmentations))\n        self._augmentations[None] = 0\n\n    def __call__(self, target):\n        assert isinstance(target, tuple) and len(target) == 2\n        label, augmentation = target\n        return (label, self._augmentations[augmentation])\n'"
torchmeta/transforms/utils.py,0,"b'from torchvision.transforms import Compose\nfrom torchmeta.utils.data.task import Task\n\ndef apply_wrapper(wrapper, task_or_dataset=None):\n    if task_or_dataset is None:\n        return wrapper\n\n    from torchmeta.utils.data import MetaDataset\n    if isinstance(task_or_dataset, Task):\n        return wrapper(task_or_dataset)\n    elif isinstance(task_or_dataset, MetaDataset):\n        if task_or_dataset.dataset_transform is None:\n            dataset_transform = wrapper\n        else:\n            dataset_transform = Compose([\n                task_or_dataset.dataset_transform, wrapper])\n        task_or_dataset.dataset_transform = dataset_transform\n        return task_or_dataset\n    else:\n        raise NotImplementedError()\n\ndef wrap_transform(transform, fn, transform_type=None):\n    if (transform_type is None) or isinstance(transform, transform_type):\n        return fn(transform)\n    elif isinstance(transform, Compose):\n        return Compose([wrap_transform(subtransform, fn, transform_type)\n            for subtransform in transform.transforms])\n    else:\n        return transform\n'"
torchmeta/utils/__init__.py,0,"b""from torchmeta.utils import data\nfrom torchmeta.utils.gradient_based import gradient_update_parameters\nfrom torchmeta.utils.metrics import hardness_metric\nfrom torchmeta.utils.prototype import get_num_samples, get_prototypes, prototypical_loss\n\n__all__ = [\n    'data',\n    'gradient_update_parameters',\n    'hardness_metric',\n    'get_num_samples',\n    'get_prototypes',\n    'prototypical_loss'\n]\n"""
torchmeta/utils/gradient_based.py,3,"b'import torch\n\nfrom collections import OrderedDict\nfrom torchmeta.modules import MetaModule\n\n\ndef gradient_update_parameters(model,\n                               loss,\n                               params=None,\n                               step_size=0.5,\n                               first_order=False):\n    """"""Update of the meta-parameters with one step of gradient descent on the\n    loss function.\n\n    Parameters\n    ----------\n    model : `torchmeta.modules.MetaModule` instance\n        The model.\n\n    loss : `torch.Tensor` instance\n        The value of the inner-loss. This is the result of the training dataset\n        through the loss function.\n\n    params : `collections.OrderedDict` instance, optional\n        Dictionary containing the meta-parameters of the model. If `None`, then\n        the values stored in `model.meta_named_parameters()` are used. This is\n        useful for running multiple steps of gradient descent as the inner-loop.\n\n    step_size : int, `torch.Tensor`, or `collections.OrderedDict` instance (default: 0.5)\n        The step size in the gradient update. If an `OrderedDict`, then the\n        keys must match the keys in `params`.\n\n    first_order : bool (default: `False`)\n        If `True`, then the first order approximation of MAML is used.\n\n    Returns\n    -------\n    updated_params : `collections.OrderedDict` instance\n        Dictionary containing the updated meta-parameters of the model, with one\n        gradient update wrt. the inner-loss.\n    """"""\n    if not isinstance(model, MetaModule):\n        raise ValueError(\'The model must be an instance of `torchmeta.modules.\'\n                         \'MetaModule`, got `{0}`\'.format(type(model)))\n\n    if params is None:\n        params = OrderedDict(model.meta_named_parameters())\n\n    grads = torch.autograd.grad(loss,\n                                params.values(),\n                                create_graph=not first_order)\n\n    updated_params = OrderedDict()\n\n    if isinstance(step_size, (dict, OrderedDict)):\n        for (name, param), grad in zip(params.items(), grads):\n            updated_params[name] = param - step_size[name] * grad\n\n    else:\n        for (name, param), grad in zip(params.items(), grads):\n            updated_params[name] = param - step_size * grad\n\n    return updated_params\n'"
torchmeta/utils/metrics.py,7,"b'import torch\nimport torch.nn.functional as F\n\nfrom torchmeta.utils.prototype import get_prototypes\n\n__all__ = [\'hardness_metric\']\n\n\ndef _pad_images(inputs, size=(224, 224), **kwargs):\n    height, width = inputs.shape[-2:]\n    pad_height, pad_width = (size[0] - height) // 2, (size[1] - width) // 2\n    padding = (pad_width, size[1] - width - pad_width,\n               pad_height, size[0] - height - pad_height)\n    return F.pad(inputs, padding, **kwargs)\n\n\ndef hardness_metric(batch, num_classes):\n    """"""Hardness metric of an episode, as defined in [1].\n\n    Parameters\n    ----------\n    batch : dict\n        The batch of tasks over which the metric is computed. The batch of tasks\n        is a dictionary containing the keys `train` (or `support`) and `test`\n        (or `query`). This is typically the output of `BatchMetaDataLoader`.\n\n    num_classes : int\n        The number of classes in the classification task. This corresponds to\n        the number of ways in an `N`-way classification problem.\n\n    Returns\n    -------\n    metric : `torch.FloatTensor` instance\n        Values of the hardness metric for each task in the batch.\n\n    References\n    ----------\n    .. [1] Dhillon, G. S., Chaudhari, P., Ravichandran, A. and Soatto S. (2019).\n           A Baseline for Few-Shot Image Classification. (https://arxiv.org/abs/1909.02729)\n    """"""\n    if (\'train\' not in batch) and (\'support\' not in batch):\n        raise ValueError(\'The tasks do not contain any training/support set. \'\n                         \'Make sure the tasks contain either the ""train"" or the \'\n                         \'""support"" key.\')\n    if (\'test\' not in batch) and (\'query\' not in batch):\n        raise ValueError(\'The tasks do not contain any test/query set. Make \'\n                         \'sure the tasks contain either the ""test"" of the \'\n                         \'""query"" key.\')\n\n    train = \'train\' if (\'train\' in batch) else \'support\'\n    test = \'test\' if (\'test\' in batch) else \'query\'\n\n    with torch.no_grad():\n        # Load a pre-trained backbone Resnet-152 model from PyTorch Hub\n        backbone = torch.hub.load(\'pytorch/vision:v0.5.0\',\n                                  \'resnet152\',\n                                  pretrained=True,\n                                  verbose=False)\n        backbone.eval()\n\n        train_inputs, train_targets = batch[train]\n        test_inputs, test_targets = batch[test]\n        batch_size, num_images, num_channels = train_inputs.shape[:3]\n        num_test_images = test_inputs.size(1)\n\n        backbone.to(device=train_inputs.device)\n\n        if num_channels != 3:\n            raise ValueError(\'The images must be RGB images.\')\n\n        # Pad the images so that they are compatible with the pre-trained model\n        padded_train_inputs = _pad_images(train_inputs,\n            size=(224, 224), mode=\'constant\', value=0.)\n        padded_test_inputs = _pad_images(test_inputs,\n            size=(224, 224), mode=\'constant\', value=0.)\n\n        # Compute the features from the logits returned by the pre-trained\n        # model on the train/support examples. These features are z(x, theta)_+,\n        # averaged for each class\n        train_logits = backbone(padded_train_inputs.view(-1, 3, 224, 224))\n        train_logits = F.relu(train_logits.view(batch_size, num_images, -1))\n        train_features = get_prototypes(train_logits, train_targets, num_classes)\n\n        # Get the weights by normalizing the features\n        weights = F.normalize(train_features, p=2, dim=2)\n\n        # Compute and normalize the logits of the test/query examples\n        test_logits = backbone(padded_test_inputs.view(-1, 3, 224, 224))\n        test_logits = test_logits.view(batch_size, num_test_images, -1)\n        test_logits = F.normalize(test_logits, p=2, dim=2)\n\n        # Compute the log probabilities of the test/query examples\n        test_logits = torch.bmm(weights, test_logits.transpose(1, 2))\n        test_log_probas = -F.cross_entropy(test_logits, test_targets,\n                                           reduction=\'none\')\n\n        # Compute the log-odds ratios for each image of the test/query set\n        log_odds_ratios = torch.log1p(-test_log_probas.exp()) - test_log_probas\n\n    return torch.mean(log_odds_ratios, dim=1)\n'"
torchmeta/utils/prototype.py,12,"b'import torch\nimport torch.nn.functional as F\n\n__all__ = [\'get_num_samples\', \'get_prototypes\', \'prototypical_loss\']\n\n\ndef get_num_samples(targets, num_classes, dtype=None):\n    batch_size = targets.size(0)\n    with torch.no_grad():\n        ones = torch.ones_like(targets, dtype=dtype)\n        num_samples = ones.new_zeros((batch_size, num_classes))\n        num_samples.scatter_add_(1, targets, ones)\n    return num_samples\n\n\ndef get_prototypes(embeddings, targets, num_classes):\n    """"""Compute the prototypes (the mean vector of the embedded training/support \n    points belonging to its class) for each classes in the task.\n\n    Parameters\n    ----------\n    embeddings : `torch.FloatTensor` instance\n        A tensor containing the embeddings of the support points. This tensor \n        has shape `(batch_size, num_examples, embedding_size)`.\n\n    targets : `torch.LongTensor` instance\n        A tensor containing the targets of the support points. This tensor has \n        shape `(batch_size, num_examples)`.\n\n    num_classes : int\n        Number of classes in the task.\n\n    Returns\n    -------\n    prototypes : `torch.FloatTensor` instance\n        A tensor containing the prototypes for each class. This tensor has shape\n        `(batch_size, num_classes, embedding_size)`.\n    """"""\n    batch_size, embedding_size = embeddings.size(0), embeddings.size(-1)\n    \n    num_samples = get_num_samples(targets, num_classes, dtype=embeddings.dtype)\n    num_samples.unsqueeze_(-1)\n    num_samples = torch.max(num_samples, torch.ones_like(num_samples))\n\n    prototypes = embeddings.new_zeros((batch_size, num_classes, embedding_size))\n    indices = targets.unsqueeze(-1).expand_as(embeddings)\n    prototypes.scatter_add_(1, indices, embeddings).div_(num_samples)\n\n    return prototypes\n\n\ndef prototypical_loss(prototypes, embeddings, targets, **kwargs):\n    """"""Compute the loss (i.e. negative log-likelihood) for the prototypical \n    network, on the test/query points.\n\n    Parameters\n    ----------\n    prototypes : `torch.FloatTensor` instance\n        A tensor containing the prototypes for each class. This tensor has shape \n        `(batch_size, num_classes, embedding_size)`.\n\n    embeddings : `torch.FloatTensor` instance\n        A tensor containing the embeddings of the query points. This tensor has \n        shape `(batch_size, num_examples, embedding_size)`.\n\n    targets : `torch.LongTensor` instance\n        A tensor containing the targets of the query points. This tensor has \n        shape `(batch_size, num_examples)`.\n\n    Returns\n    -------\n    loss : `torch.FloatTensor` instance\n        The negative log-likelihood on the query points.\n    """"""\n    squared_distances = torch.sum((prototypes.unsqueeze(2)\n        - embeddings.unsqueeze(1)) ** 2, dim=-1)\n    return F.cross_entropy(-squared_distances, targets, **kwargs)\n'"
torchmeta/datasets/cifar100/__init__.py,0,"b""from torchmeta.datasets.cifar100.cifar_fs import CIFARFS\nfrom torchmeta.datasets.cifar100.fc100 import FC100\n\n__all__ = ['CIFARFS', 'FC100']\n"""
torchmeta/datasets/cifar100/base.py,0,"b""import numpy as np\nimport os\nimport json\nimport h5py\nfrom PIL import Image\n\nfrom torchvision.datasets.utils import check_integrity, download_url\nfrom torchmeta.utils.data import Dataset, ClassDataset\n\n\nclass CIFAR100ClassDataset(ClassDataset):\n    folder = 'cifar100'\n    subfolder = None\n    download_url = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n    gz_folder = 'cifar-100-python'\n    gz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n    files_md5 = {\n        'train': '16019d7e3df5f24257cddd939b257f8d',\n        'test': 'f0ef6b0ae62326f3e7ffdfab6717acfc',\n        'meta': '7973b15100ade9c7d40fb424638fde48'\n    }\n\n    filename = 'data.hdf5'\n    filename_labels = '{0}_labels.json'\n    filename_fine_names = 'fine_names.json'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False):\n        super(CIFAR100ClassDataset, self).__init__(meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            class_augmentations=class_augmentations)\n\n        if self.subfolder is None:\n            raise ValueError()\n\n        self.root = os.path.join(os.path.expanduser(root), self.folder)\n        self.transform = transform\n\n        self.split_filename_labels = os.path.join(self.root, self.subfolder,\n            self.filename_labels.format(self.meta_split))\n        self._data = None\n        self._labels = None\n\n        if download:\n            self.download()\n\n        if not self._check_integrity():\n            raise RuntimeError('CIFAR100 integrity check failed')\n        self._num_classes = len(self.labels)\n\n    def __getitem__(self, index):\n        coarse_label_name, fine_label_name = self.labels[index % self.num_classes]\n        data = self.data['{0}/{1}'.format(coarse_label_name, fine_label_name)]\n        transform = self.get_transform(index, self.transform)\n        target_transform = self.get_target_transform(index)\n\n        return CIFAR100Dataset(index, data, coarse_label_name, fine_label_name,\n            transform=transform, target_transform=target_transform)\n\n    @property\n    def num_classes(self):\n        return self._num_classes\n\n    @property\n    def data(self):\n        if self._data is None:\n            self._data = h5py.File(os.path.join(self.root, self.filename), 'r')\n        return self._data\n\n    @property\n    def labels(self):\n        if self._labels is None:\n            with open(self.split_filename_labels, 'r') as f:\n                self._labels = json.load(f)\n        return self._labels\n\n    def _check_integrity(self):\n        return (self._check_integrity_data()\n            and os.path.isfile(self.split_filename_labels)\n            and os.path.isfile(os.path.join(self.root, self.filename_fine_names)))\n\n    def _check_integrity_data(self):\n        return os.path.isfile(os.path.join(self.root, self.filename))\n\n    def close(self):\n        if self._data is not None:\n            self._data.close()\n            self._data = None\n\n    def download(self):\n        import tarfile\n        import pickle\n        import shutil\n\n        if self._check_integrity_data():\n            return\n\n        gz_filename = '{0}.tar.gz'.format(self.gz_folder)\n        download_url(self.download_url, self.root, filename=gz_filename,\n                     md5=self.gz_md5)\n        with tarfile.open(os.path.join(self.root, gz_filename), 'r:gz') as tar:\n            tar.extractall(path=self.root)\n\n        train_filename = os.path.join(self.root, self.gz_folder, 'train')\n        check_integrity(train_filename, self.files_md5['train'])\n        with open(train_filename, 'rb') as f:\n            data = pickle.load(f, encoding='bytes')\n            images = data[b'data']\n            fine_labels = data[b'fine_labels']\n            coarse_labels = data[b'coarse_labels']\n\n        test_filename = os.path.join(self.root, self.gz_folder, 'test')\n        check_integrity(test_filename, self.files_md5['test'])\n        with open(test_filename, 'rb') as f:\n            data = pickle.load(f, encoding='bytes')\n            images = np.concatenate((images, data[b'data']), axis=0)\n            fine_labels = np.concatenate((fine_labels, data[b'fine_labels']), axis=0)\n            coarse_labels = np.concatenate((coarse_labels, data[b'coarse_labels']), axis=0)\n\n        images = images.reshape((-1, 3, 32, 32))\n        images = images.transpose((0, 2, 3, 1))\n\n        meta_filename = os.path.join(self.root, self.gz_folder, 'meta')\n        check_integrity(meta_filename, self.files_md5['meta'])\n        with open(meta_filename, 'rb') as f:\n            data = pickle.load(f, encoding='latin1')\n            fine_label_names = data['fine_label_names']\n            coarse_label_names = data['coarse_label_names']\n\n        filename = os.path.join(self.root, self.filename)\n        fine_names = dict()\n        with h5py.File(filename, 'w') as f:\n            for i, coarse_name in enumerate(coarse_label_names):\n                group = f.create_group(coarse_name)\n                fine_indices = np.unique(fine_labels[coarse_labels == i])\n                for j in fine_indices:\n                    dataset = group.create_dataset(fine_label_names[j],\n                        data=images[fine_labels == j])\n                fine_names[coarse_name] = [fine_label_names[j] for j in fine_indices]\n\n        filename_fine_names = os.path.join(self.root, self.filename_fine_names)\n        with open(filename_fine_names, 'w') as f:\n            json.dump(fine_names, f)\n\n        gz_folder = os.path.join(self.root, self.gz_folder)\n        if os.path.isdir(gz_folder):\n            shutil.rmtree(gz_folder)\n        if os.path.isfile('{0}.tar.gz'.format(gz_folder)):\n            os.remove('{0}.tar.gz'.format(gz_folder))\n\n\nclass CIFAR100Dataset(Dataset):\n    def __init__(self, index, data, coarse_label_name, fine_label_name,\n                 transform=None, target_transform=None):\n        super(CIFAR100Dataset, self).__init__(index, transform=transform,\n                                              target_transform=target_transform)\n        self.data = data\n        self.coarse_label_name = coarse_label_name\n        self.fine_label_name = fine_label_name\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, index):\n        image = Image.fromarray(self.data[index])\n        target = (self.coarse_label_name, self.fine_label_name)\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return (image, target)\n"""
torchmeta/datasets/cifar100/cifar_fs.py,0,"b'import os\nimport json\n\nfrom torchmeta.datasets.cifar100.base import CIFAR100ClassDataset\nfrom torchmeta.datasets.utils import get_asset\nfrom torchmeta.utils.data import ClassDataset, CombinationMetaDataset\n\n\nclass CIFARFS(CombinationMetaDataset):\n    """"""\n    The CIFAR-FS dataset, introduced in [1]. This dataset contains\n    images of 100 different classes from the CIFAR100 dataset [2].\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `cifar100` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to `N` in `N-way` \n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These classes \n        are transformations of existing classes. E.g. `transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the pickle files and processes the dataset in the root \n        directory (under the `cifar100` folder). If the dataset is already \n        available, this does not download/process the dataset again.\n\n    Notes\n    -----\n    The meta train/validation/test splits are over 64/16/20 classes from the\n    CIFAR100 dataset.\n\n    References\n    ----------\n    .. [1] Bertinetto L., Henriques J. F., Torr P. H.S., Vedaldi A. (2019).\n           Meta-learning with differentiable closed-form solvers. In International\n           Conference on Learning Representations (https://arxiv.org/abs/1805.08136)\n\n    .. [2] Krizhevsky A. (2009). Learning Multiple Layers of Features from Tiny\n           Images. (https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_val=False, meta_test=False, meta_split=None,\n                 transform=None, target_transform=None, dataset_transform=None,\n                 class_augmentations=None, download=False):\n        dataset = CIFARFSClassDataset(root, meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            transform=transform, class_augmentations=class_augmentations,\n            download=download)\n        super(CIFARFS, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform, dataset_transform=dataset_transform)\n\n\nclass CIFARFSClassDataset(CIFAR100ClassDataset):\n    subfolder = \'cifar-fs\'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False):\n        super(CIFARFSClassDataset, self).__init__(root, meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            transform=transform, class_augmentations=class_augmentations,\n            download=download)\n\n    def download(self):\n        if self._check_integrity():\n            return\n        super(CIFARFSClassDataset, self).download()\n\n        subfolder = os.path.join(self.root, self.subfolder)\n        if not os.path.exists(subfolder):\n            os.makedirs(subfolder)\n\n        for split in [\'train\', \'val\', \'test\']:\n            split_filename_labels = os.path.join(subfolder,\n                self.filename_labels.format(split))\n            if os.path.isfile(split_filename_labels):\n                continue\n\n            data = get_asset(self.folder, self.subfolder,\n                \'{0}.json\'.format(split), dtype=\'json\')\n            with open(split_filename_labels, \'w\') as f:\n                json.dump(data, f)\n'"
torchmeta/datasets/cifar100/fc100.py,0,"b'import os\nimport json\n\nfrom torchmeta.datasets.cifar100.base import CIFAR100ClassDataset\nfrom torchmeta.datasets.utils import get_asset\nfrom torchmeta.utils.data import ClassDataset, CombinationMetaDataset\n\n\nclass FC100(CombinationMetaDataset):\n    """"""\n    The Fewshot-CIFAR100 dataset, introduced in [1]. This dataset contains\n    images of 100 different classes from the CIFAR100 dataset [2].\n\n    Parameters\n    ----------\n    root : string\n        Root directory where the dataset folder `cifar100` exists.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to `N` in `N-way` \n        classification.\n\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test` if all three are set to `False`.\n\n    transform : callable, optional\n        A function/transform that takes a `PIL` image, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `transforms.ClassSplitter()`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These classes \n        are transformations of existing classes. E.g. `transforms.HorizontalFlip()`.\n\n    download : bool (default: `False`)\n        If `True`, downloads the pickle files and processes the dataset in the root \n        directory (under the `cifar100` folder). If the dataset is already \n        available, this does not download/process the dataset again.\n\n    Notes\n    -----\n    The meta train/validation/test splits are over 12/4/4 superclasses from the\n    CIFAR100 dataset. The meta train/validation/test splits contain 60/20/20\n    classes.\n\n    References\n    ----------\n    .. [1] Oreshkin B. N., Rodriguez P., Lacoste A. (2018). TADAM: Task dependent\n           adaptive metric for improved few-shot learning. In Advances in Neural \n           Information Processing Systems (https://arxiv.org/abs/1805.10123)\n\n    .. [2] Krizhevsky A. (2009). Learning Multiple Layers of Features from Tiny\n           Images. (https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)\n    """"""\n    def __init__(self, root, num_classes_per_task=None, meta_train=False,\n                 meta_val=False, meta_test=False, meta_split=None,\n                 transform=None, target_transform=None, dataset_transform=None,\n                 class_augmentations=None, download=False):\n        dataset = FC100ClassDataset(root, meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            transform=transform, class_augmentations=class_augmentations,\n            download=download)\n        super(FC100, self).__init__(dataset, num_classes_per_task,\n            target_transform=target_transform, dataset_transform=dataset_transform)\n\n\nclass FC100ClassDataset(CIFAR100ClassDataset):\n    subfolder = \'fc100\'\n\n    def __init__(self, root, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, transform=None, class_augmentations=None,\n                 download=False):\n        super(FC100ClassDataset, self).__init__(root, meta_train=meta_train,\n            meta_val=meta_val, meta_test=meta_test, meta_split=meta_split,\n            transform=transform, class_augmentations=class_augmentations,\n            download=download)\n\n    def download(self):\n        if self._check_integrity():\n            return\n        super(FC100ClassDataset, self).download()\n\n        subfolder = os.path.join(self.root, self.subfolder)\n        if not os.path.exists(subfolder):\n            os.makedirs(subfolder)\n\n        filename_fine_names = os.path.join(self.root, self.filename_fine_names)\n        with open(filename_fine_names, \'r\') as f:\n            fine_names = json.load(f)\n\n        for split in [\'train\', \'val\', \'test\']:\n            split_filename_labels = os.path.join(subfolder,\n                self.filename_labels.format(split))\n            if os.path.isfile(split_filename_labels):\n                continue\n\n            data = get_asset(self.folder, self.subfolder,\n                \'{0}.json\'.format(split), dtype=\'json\')\n            with open(split_filename_labels, \'w\') as f:\n                labels = [[coarse_name, fine_name] for coarse_name in data\n                    for fine_name in fine_names[coarse_name]]\n                json.dump(labels, f)\n'"
torchmeta/tests/datasets/__init__.py,0,b''
torchmeta/tests/datasets/test_datasets_helpers.py,0,"b""import pytest\n\nimport os\nimport torch\n\nfrom torchmeta.utils.data import MetaDataset, Task\nfrom torchmeta.datasets import helpers\n\nis_local = (os.getenv('TORCHMETA_DATA_FOLDER') is not None)\n\n\n@pytest.mark.skipif(not is_local, reason='Requires datasets downloaded locally')\n@pytest.mark.parametrize('name', helpers.__all__)\n@pytest.mark.parametrize('shots', [1, 5])\n@pytest.mark.parametrize('split', ['train', 'val', 'test'])\ndef test_datasets_helpers(name, shots, split):\n    function = getattr(helpers, name)\n    folder = os.getenv('TORCHMETA_DATA_FOLDER')\n    download = bool(os.getenv('TORCHMETA_DOWNLOAD', False))\n\n    dataset = function(folder,\n                       ways=5,\n                       shots=shots,\n                       test_shots=15,\n                       meta_split=split,\n                       download=download)\n\n    assert isinstance(dataset, MetaDataset)\n\n    task = dataset.sample_task()\n\n    # Task is a dictionary with keys [train, test]\n    assert isinstance(task, dict)\n    assert set(task.keys()) == set(['train', 'test'])\n\n    # Train\n    assert isinstance(task['train'], Task)\n    assert task['train'].num_classes == 5\n    assert len(task['train']) == 5 * shots\n\n    # Test\n    assert isinstance(task['test'], Task)\n    assert task['test'].num_classes == 5\n    assert len(task['test']) == 5 * 15 # test_shots\n"""
torchmeta/tests/modules/__init__.py,0,b''
torchmeta/tests/modules/test_container.py,11,"b""import pytest\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom collections import OrderedDict\n\nfrom torchmeta.modules import MetaSequential, MetaModule, MetaLinear\n\n\ndef test_metasequential():\n    meta_model = MetaSequential(\n        nn.Linear(2, 3, bias=True),\n        nn.ReLU(),\n        MetaLinear(3, 5, bias=True))\n    model = nn.Sequential(\n        nn.Linear(2, 3, bias=True),\n        nn.ReLU(),\n        nn.Linear(3, 5, bias=True))\n\n    assert isinstance(meta_model, MetaModule)\n    assert isinstance(meta_model, nn.Sequential)\n\n    params = OrderedDict(meta_model.meta_named_parameters())\n    assert set(params.keys()) == set(['2.weight', '2.bias'])\n\n    # Set same weights for both models\n    weight0 = torch.randn(3, 2)\n    meta_model[0].weight.data.copy_(weight0)\n    model[0].weight.data.copy_(weight0)\n\n    bias0 = torch.randn(3)\n    meta_model[0].bias.data.copy_(bias0)\n    model[0].bias.data.copy_(bias0)\n\n    weight2 = torch.randn(5, 3)\n    meta_model[2].weight.data.copy_(weight2)\n    model[2].weight.data.copy_(weight2)\n\n    bias2 = torch.randn(5)\n    meta_model[2].bias.data.copy_(bias2)\n    model[2].bias.data.copy_(bias2)\n\n    inputs = torch.randn(5, 2)\n\n    outputs_torchmeta = meta_model(inputs, params=None)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\ndef test_metasequential_params():\n    meta_model = MetaSequential(\n        nn.Linear(2, 3, bias=True),\n        nn.ReLU(),\n        MetaLinear(3, 5, bias=True))\n    model = nn.Sequential(\n        nn.Linear(2, 3, bias=True),\n        nn.ReLU(),\n        nn.Linear(3, 5, bias=True))\n\n    # Set same weights for both models (first layer)\n    weight0 = torch.randn(3, 2)\n    meta_model[0].weight.data.copy_(weight0)\n    model[0].weight.data.copy_(weight0)\n\n    bias0 = torch.randn(3)\n    meta_model[0].bias.data.copy_(bias0)\n    model[0].bias.data.copy_(bias0)\n\n    params = OrderedDict()\n    params['2.weight'] = torch.randn(5, 3)\n    model[2].weight.data.copy_(params['2.weight'])\n\n    params['2.bias'] = torch.randn(5)\n    model[2].bias.data.copy_(params['2.bias'])\n\n    inputs = torch.randn(5, 2)\n\n    outputs_torchmeta = meta_model(inputs, params=params)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n"""
torchmeta/tests/modules/test_conv.py,19,"b""import pytest\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom collections import OrderedDict\n\nfrom torchmeta.modules import MetaModule\nfrom torchmeta.modules.conv import MetaConv1d, MetaConv2d, MetaConv3d\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metaconv1d(bias):\n    meta_model = MetaConv1d(2, 3, kernel_size=5, bias=bias)\n    model = nn.Conv1d(2, 3, kernel_size=5, bias=bias)\n\n    assert isinstance(meta_model, MetaModule)\n    assert isinstance(meta_model, nn.Conv1d)\n\n    # Set same weights for both models\n    weight = torch.randn(3, 2, 5)\n    meta_model.weight.data.copy_(weight)\n    model.weight.data.copy_(weight)\n\n    if bias:\n        bias = torch.randn(3)\n        meta_model.bias.data.copy_(bias)\n        model.bias.data.copy_(bias)\n\n    inputs = torch.randn(7, 2, 11)\n\n    outputs_torchmeta = meta_model(inputs, params=None)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metaconv1d_params(bias):\n    meta_model = MetaConv1d(2, 3, kernel_size=5, bias=bias)\n    model = nn.Conv1d(2, 3, kernel_size=5, bias=bias)\n\n    params = OrderedDict()\n    params['weight'] = torch.randn(3, 2, 5)\n    model.weight.data.copy_(params['weight'])\n\n    if bias:\n        params['bias'] = torch.randn(3)\n        model.bias.data.copy_(params['bias'])\n\n    inputs = torch.randn(7, 2, 11)\n\n    outputs_torchmeta = meta_model(inputs, params=params)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metaconv2d(bias):\n    meta_model = MetaConv2d(2, 3, kernel_size=(5, 7), bias=bias)\n    model = nn.Conv2d(2, 3, kernel_size=(5, 7), bias=bias)\n\n    assert isinstance(meta_model, MetaModule)\n    assert isinstance(meta_model, nn.Conv2d)\n\n    # Set same weights for both models\n    weight = torch.randn(3, 2, 5, 7)\n    meta_model.weight.data.copy_(weight)\n    model.weight.data.copy_(weight)\n\n    if bias:\n        bias = torch.randn(3)\n        meta_model.bias.data.copy_(bias)\n        model.bias.data.copy_(bias)\n\n    inputs = torch.randn(11, 2, 13, 17)\n\n    outputs_torchmeta = meta_model(inputs, params=None)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metaconv2d_params(bias):\n    meta_model = MetaConv2d(2, 3, kernel_size=(5, 7), bias=bias)\n    model = nn.Conv2d(2, 3, kernel_size=(5, 7), bias=bias)\n\n    params = OrderedDict()\n    params['weight'] = torch.randn(3, 2, 5, 7)\n    model.weight.data.copy_(params['weight'])\n\n    if bias:\n        params['bias'] = torch.randn(3)\n        model.bias.data.copy_(params['bias'])\n\n    inputs = torch.randn(11, 2, 13, 17)\n\n    outputs_torchmeta = meta_model(inputs, params=params)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metaconv3d(bias):\n    meta_model = MetaConv3d(2, 3, kernel_size=(5, 7, 11), bias=bias)\n    model = nn.Conv3d(2, 3, kernel_size=(5, 7, 11), bias=bias)\n\n    assert isinstance(meta_model, MetaModule)\n    assert isinstance(meta_model, nn.Conv3d)\n\n    # Set same weights for both models\n    weight = torch.randn(3, 2, 5, 7, 11)\n    meta_model.weight.data.copy_(weight)\n    model.weight.data.copy_(weight)\n\n    if bias:\n        bias = torch.randn(3)\n        meta_model.bias.data.copy_(bias)\n        model.bias.data.copy_(bias)\n\n    inputs = torch.randn(13, 2, 17, 23, 29)\n\n    outputs_torchmeta = meta_model(inputs, params=None)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metaconv3d_params(bias):\n    meta_model = MetaConv3d(2, 3, kernel_size=(5, 7, 11), bias=bias)\n    model = nn.Conv3d(2, 3, kernel_size=(5, 7, 11), bias=bias)\n\n    params = OrderedDict()\n    params['weight'] = torch.randn(3, 2, 5, 7, 11)\n    model.weight.data.copy_(params['weight'])\n\n    if bias:\n        params['bias'] = torch.randn(3)\n        model.bias.data.copy_(params['bias'])\n\n    inputs = torch.randn(13, 2, 17, 23, 29)\n\n    outputs_torchmeta = meta_model(inputs, params=params)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n"""
torchmeta/tests/modules/test_dataparallel.py,13,"b""import pytest\n\nimport torch\nimport torch.nn as nn\n\nfrom torchmeta.modules import MetaLinear, MetaSequential\nfrom torchmeta.modules import DataParallel\n\nis_multi_gpu = (torch.cuda.device_count() > 1)\n\n@pytest.fixture\ndef model():\n    model = MetaSequential(\n        MetaLinear(2, 3, bias=True),\n        nn.ReLU(),\n        MetaLinear(3, 1, bias=False))\n\n    return model\n\n@pytest.fixture\ndef params():\n    device = torch.device('cuda:0')\n    weight_0 = torch.tensor([\n        [0.02, 0.03],\n        [0.05, 0.07],\n        [0.11, 0.13]], device=device, dtype=torch.float32)\n    bias_0 = torch.tensor([0.17, 0.19, 0.23],\n                          device=device, dtype=torch.float32)\n    weight_2 = torch.tensor([[0.29, 0.31, 0.37]],\n                            device=device, dtype=torch.float32)\n\n    return {'0.weight': weight_0, '0.bias': bias_0, '2.weight': weight_2}\n\n\n@pytest.mark.skipif(not is_multi_gpu, reason='Requires Multi-GPU support')\ndef test_dataparallel(model):\n    device = torch.device('cuda:0')\n    model = DataParallel(model)\n    model.to(device=device)\n\n    inputs = torch.rand(5, 2).to(device=device)\n    outputs = model(inputs)\n\n    assert outputs.shape == (5, 1)\n    assert outputs.device == device\n\n\n@pytest.mark.skipif(not is_multi_gpu, reason='Requires Multi-GPU support')\ndef test_dataparallel_params(model, params):\n    device = torch.device('cuda:0')\n    model = DataParallel(model)\n    model.to(device=device)\n\n    inputs = torch.rand(5, 2).to(device=device)\n    outputs = model(inputs, params=params)\n\n    assert outputs.shape == (5, 1)\n    assert outputs.device == device\n"""
torchmeta/tests/modules/test_linear.py,15,"b""import pytest\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom collections import OrderedDict\n\nfrom torchmeta.modules import MetaModule\nfrom torchmeta.modules.linear import MetaLinear, MetaBilinear\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metalinear(bias):\n    meta_model = MetaLinear(2, 3, bias=bias)\n    model = nn.Linear(2, 3, bias=bias)\n\n    assert isinstance(meta_model, MetaModule)\n    assert isinstance(meta_model, nn.Linear)\n\n    # Set same weights for both models\n    weight = torch.randn(3, 2)\n    meta_model.weight.data.copy_(weight)\n    model.weight.data.copy_(weight)\n\n    if bias:\n        bias = torch.randn(3)\n        meta_model.bias.data.copy_(bias)\n        model.bias.data.copy_(bias)\n\n    inputs = torch.randn(5, 2)\n\n    outputs_torchmeta = meta_model(inputs, params=None)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metalinear_params(bias):\n    meta_model = MetaLinear(2, 3, bias=bias)\n    model = nn.Linear(2, 3, bias=bias)\n\n    params = OrderedDict()\n    params['weight'] = torch.randn(3, 2)\n    model.weight.data.copy_(params['weight'])\n\n    if bias:\n        params['bias'] = torch.randn(3)\n        model.bias.data.copy_(params['bias'])\n\n    inputs = torch.randn(5, 2)\n\n    outputs_torchmeta = meta_model(inputs, params=params)\n    outputs_nn = model(inputs)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metabilinear(bias):\n    meta_model = MetaBilinear(2, 3, 5, bias=bias)\n    model = nn.Bilinear(2, 3, 5, bias=bias)\n\n    assert isinstance(meta_model, MetaModule)\n    assert isinstance(meta_model, nn.Bilinear)\n\n    # Set same weights for both models\n    weight = torch.randn(5, 2, 3)\n    meta_model.weight.data.copy_(weight)\n    model.weight.data.copy_(weight)\n\n    if bias:\n        bias = torch.randn(5)\n        meta_model.bias.data.copy_(bias)\n        model.bias.data.copy_(bias)\n\n    inputs1 = torch.randn(7, 2)\n    inputs2 = torch.randn(7, 3)\n\n    outputs_torchmeta = meta_model(inputs1, inputs2, params=None)\n    outputs_nn = model(inputs1, inputs2)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n\n\n@pytest.mark.parametrize('bias', [True, False])\ndef test_metabilinear_params(bias):\n    meta_model = MetaBilinear(2, 3, 5, bias=bias)\n    model = nn.Bilinear(2, 3, 5, bias=bias)\n\n    params = OrderedDict()\n    params['weight'] = torch.randn(5, 2, 3)\n    model.weight.data.copy_(params['weight'])\n\n    if bias:\n        params['bias'] = torch.randn(5)\n        model.bias.data.copy_(params['bias'])\n\n    inputs1 = torch.randn(7, 2)\n    inputs2 = torch.randn(7, 3)\n\n    outputs_torchmeta = meta_model(inputs1, inputs2, params=params)\n    outputs_nn = model(inputs1, inputs2)\n\n    np.testing.assert_equal(outputs_torchmeta.detach().numpy(),\n                            outputs_nn.detach().numpy())\n"""
torchmeta/tests/toy/__init__.py,0,b''
torchmeta/tests/toy/test_toy.py,0,"b""import pytest\n\nimport numpy as np\nfrom collections import OrderedDict\n\nfrom torchmeta.utils.data import Task, MetaDataset\nfrom torchmeta.toy import Sinusoid, Harmonic, SinusoidAndLine\nfrom torchmeta.toy import helpers\n\n\n@pytest.mark.parametrize('dataset_class',\n    [Sinusoid, Harmonic, SinusoidAndLine])\ndef test_toy_meta_dataset(dataset_class):\n    dataset = dataset_class(10, num_tasks=1000, noise_std=None)\n\n    assert isinstance(dataset, MetaDataset)\n    assert len(dataset) == 1000\n\n\n@pytest.mark.parametrize('dataset_class',\n    [Sinusoid, Harmonic, SinusoidAndLine])\ndef test_toy_task(dataset_class):\n    dataset = dataset_class(10, num_tasks=1000, noise_std=None)\n    task = dataset[0]\n\n    assert isinstance(task, Task)\n    assert len(task) == 10\n\n\n@pytest.mark.parametrize('dataset_class',\n    [Sinusoid, Harmonic, SinusoidAndLine])\ndef test_toy_sample(dataset_class):\n    dataset = dataset_class(10, num_tasks=1000, noise_std=None)\n    task = dataset[0]\n    input, target = task[0]\n\n    assert isinstance(input, np.ndarray)\n    assert isinstance(target, np.ndarray)\n    assert input.shape == (1,)\n    assert target.shape == (1,)\n\n\n@pytest.mark.parametrize('name,dataset_class',\n    [('sinusoid', Sinusoid), ('harmonic', Harmonic)])\ndef test_toy_helpers(name, dataset_class):\n    dataset_fn = getattr(helpers, name)\n    dataset = dataset_fn(shots=5, test_shots=15)\n    assert isinstance(dataset, dataset_class)\n\n    task = dataset[0]\n    assert isinstance(task, OrderedDict)\n    assert 'train' in task\n    assert 'test' in task\n\n    train, test = task['train'], task['test']\n    assert isinstance(train, Task)\n    assert isinstance(test, Task)\n    assert len(train) == 5\n    assert len(test) == 15\n"""
torchmeta/tests/transforms/__init__.py,0,b''
torchmeta/tests/transforms/test_splitters.py,0,"b'import pytest\n\nimport numpy as np\nfrom collections import OrderedDict\n\nfrom torchmeta.transforms.splitters import ClassSplitter\nfrom torchmeta.toy import Sinusoid\nfrom torchmeta.utils.data import Task\n\ndef test_seed_class_splitter():\n    dataset_transform = ClassSplitter(shuffle=True,\n        num_train_per_class=5, num_test_per_class=5)\n    dataset = Sinusoid(10, num_tasks=1000, noise_std=0.1,\n        dataset_transform=dataset_transform)\n    dataset.seed(1)\n\n    expected_train_inputs = np.array([-2.03870077,  0.09898378,  3.75388738,  1.08565437, -1.56211897])\n    expected_train_targets = np.array([-0.1031986 , -1.61885041,  0.91773121, -0.00309463, -1.37650356])\n\n    expected_test_inputs = np.array([ 4.62078213, -2.48340416,  0.32922559,  0.76977846, -3.15504396])\n    expected_test_targets = np.array([-0.9346262 ,  0.73113509, -1.52508997, -0.4698061 ,  1.86656819])\n\n    task = dataset[0]\n    train_dataset, test_dataset = task[\'train\'], task[\'test\']\n\n    assert len(train_dataset) == 5\n    assert len(test_dataset) == 5\n\n    for i, (train_input, train_target) in enumerate(train_dataset):\n        assert np.isclose(train_input, expected_train_inputs[i])\n        assert np.isclose(train_target, expected_train_targets[i])\n\n    for i, (test_input, test_target) in enumerate(test_dataset):\n        assert np.isclose(test_input, expected_test_inputs[i])\n        assert np.isclose(test_target, expected_test_targets[i])\n\ndef test_class_splitter_for_fold_overlaps():\n    class DemoTask(Task):\n        def __init__(self):\n            super(DemoTask, self).__init__(index=0, num_classes=None)\n            self._inputs = np.arange(10)\n\n        def __len__(self):\n            return len(self._inputs)\n\n        def __getitem__(self, index):\n            return self._inputs[index]\n\n    splitter = ClassSplitter(shuffle=True, num_train_per_class=5, num_test_per_class=5)\n    task = DemoTask()\n\n    all_train_samples = list()\n    all_test_samples = list()\n\n    # split task ten times into train and test\n    for i in range(10):\n        tasks_split = splitter(task)\n        train_task = tasks_split[""train""]\n        test_task = tasks_split[""test""]\n\n        train_samples = set([train_task[i] for i in range(len(train_task))])\n        test_samples = set([test_task[i] for i in range(len(train_task))])\n\n        # no overlap between train and test splits at single split\n        assert len(train_samples.intersection(test_samples)) == 0\n\n        all_train_samples.append(train_samples)\n        all_train_samples.append(train_samples)\n\n    # gather unique samples from multiple splits\n    samples_in_all_train_splits = set().union(*all_train_samples)\n    samples_in_all_test_splits = set().union(*all_test_samples)\n\n    # no overlap between train and test splits at multiple splits\n    assert len(samples_in_all_test_splits.intersection(samples_in_all_train_splits)) == 0'"
torchmeta/tests/utils/__init__.py,0,b''
torchmeta/tests/utils/test_dataloaders.py,13,"b""import pytest\n\nimport os\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom torchmeta.datasets import helpers\nfrom torchmeta.toy import Sinusoid\nfrom torchmeta.transforms import ClassSplitter\nfrom torchmeta.utils.data import Task, MetaDataLoader, BatchMetaDataLoader\n\nis_local = (os.getenv('TORCHMETA_DATA_FOLDER') is not None)\n\n\ndef test_meta_dataloader():\n    dataset = Sinusoid(10, num_tasks=1000, noise_std=None)\n    meta_dataloader = MetaDataLoader(dataset, batch_size=4)\n    assert isinstance(meta_dataloader, DataLoader)\n    assert len(meta_dataloader) == 250 # 1000 / 4\n    \n    batch = next(iter(meta_dataloader))\n    assert isinstance(batch, list)\n    assert len(batch) == 4\n\n    task = batch[0]\n    assert isinstance(task, Task)\n    assert len(task) == 10\n\n\ndef test_meta_dataloader_task_loader():\n    dataset = Sinusoid(10, num_tasks=1000, noise_std=None)\n    meta_dataloader = MetaDataLoader(dataset, batch_size=4)\n    batch = next(iter(meta_dataloader))\n\n    dataloader = DataLoader(batch[0], batch_size=5)\n    inputs, targets = next(iter(dataloader))\n\n    assert len(dataloader) == 2 # 10 / 5\n    # PyTorch dataloaders convert numpy array to tensors\n    assert isinstance(inputs, torch.Tensor)\n    assert isinstance(targets, torch.Tensor)\n    assert inputs.shape == (5, 1)\n    assert targets.shape == (5, 1)\n\n\ndef test_batch_meta_dataloader():\n    dataset = Sinusoid(10, num_tasks=1000, noise_std=None)\n    meta_dataloader = BatchMetaDataLoader(dataset, batch_size=4)\n    assert isinstance(meta_dataloader, DataLoader)\n    assert len(meta_dataloader) == 250 # 1000 / 4\n\n    inputs, targets = next(iter(meta_dataloader))\n    assert isinstance(inputs, torch.Tensor)\n    assert isinstance(targets, torch.Tensor)\n    assert inputs.shape == (4, 10, 1)\n    assert targets.shape == (4, 10, 1)\n\n\ndef test_batch_meta_dataloader_splitter():\n    dataset = Sinusoid(20, num_tasks=1000, noise_std=None)\n    dataset = ClassSplitter(dataset, num_train_per_class=5,\n        num_test_per_class=15)\n    meta_dataloader = BatchMetaDataLoader(dataset, batch_size=4)\n\n    batch = next(iter(meta_dataloader))\n    assert isinstance(batch, dict)\n    assert 'train' in batch\n    assert 'test' in batch\n\n    train_inputs, train_targets = batch['train']\n    test_inputs, test_targets = batch['test']\n\n    assert isinstance(train_inputs, torch.Tensor)\n    assert isinstance(train_targets, torch.Tensor)\n    assert train_inputs.shape == (4, 5, 1)\n    assert train_targets.shape == (4, 5, 1)\n\n    assert isinstance(test_inputs, torch.Tensor)\n    assert isinstance(test_targets, torch.Tensor)\n    assert test_inputs.shape == (4, 15, 1)\n    assert test_targets.shape == (4, 15, 1)\n\n\n@pytest.mark.skipif(not is_local, reason='Requires datasets downloaded locally')\n@pytest.mark.parametrize('name', helpers.__all__)\n@pytest.mark.parametrize('shots', [1, 5])\n@pytest.mark.parametrize('split', ['train', 'val', 'test'])\ndef test_datasets_helpers_dataloader(name, shots, split):\n    function = getattr(helpers, name)\n    folder = os.getenv('TORCHMETA_DATA_FOLDER')\n    download = bool(os.getenv('TORCHMETA_DOWNLOAD', False))\n\n    dataset = function(folder,\n                       ways=5,\n                       shots=shots,\n                       test_shots=15,\n                       meta_split=split,\n                       download=download)\n\n    meta_dataloader = BatchMetaDataLoader(dataset, batch_size=4)\n\n    batch = next(iter(meta_dataloader))\n    assert isinstance(batch, dict)\n    assert 'train' in batch\n    assert 'test' in batch\n\n    train_inputs, train_targets = batch['train']\n    test_inputs, test_targets = batch['test']\n\n    assert isinstance(train_inputs, torch.Tensor)\n    assert isinstance(train_targets, torch.Tensor)\n    assert train_inputs.ndim == 5\n    assert train_inputs.shape[:2] == (4, 5 * shots)\n    assert train_targets.ndim == 2\n    assert train_targets.shape[:2] == (4, 5 * shots)\n\n    assert isinstance(test_inputs, torch.Tensor)\n    assert isinstance(test_targets, torch.Tensor)\n    assert test_inputs.ndim == 5\n    assert test_inputs.shape[:2] == (4, 5 * 15) # test_shots\n    assert test_targets.ndim == 2\n    assert test_targets.shape[:2] == (4, 5 * 15)\n"""
torchmeta/tests/utils/test_gradient_based.py,18,"b'import pytest\nimport torch\n\nfrom torchmeta.modules import MetaLinear\nfrom torchmeta.utils.gradient_based import gradient_update_parameters\n\n@pytest.fixture\ndef model():\n    model = MetaLinear(3, 1, bias=False)\n    model.weight.data = torch.tensor([[2., 3., 5.]])\n    return model\n\n\ndef test_update_parameters(model):\n    """"""\n    The loss function (with respect to the weights of the model w) is defined as\n        f(w) = 0.5 * (1 * w_1 + 2 * w_2 + 3 * w_3) ** 2\n    with w = [2, 3, 5].\n\n    The gradient of the function f with respect to w, and evaluated\n    at w = [2, 3, 5], is:\n        df / dw_1 = 1 * (1 * w_1 + 2 * w_2 + 3 * w_3) = 23\n        df / dw_2 = 2 * (1 * w_1 + 2 * w_2 + 3 * w_3) = 46\n        df / dw_3 = 3 * (1 * w_1 + 2 * w_2 + 3 * w_3) = 69\n\n    The updated parameter w\' is then given by one step of gradient descent,\n    with step size 0.5:\n        w\'_1 = w_1 - 0.5 * df / dw_1 = 2 - 0.5 * 23 = -9.5\n        w\'_2 = w_2 - 0.5 * df / dw_2 = 3 - 0.5 * 46 = -20\n        w\'_3 = w_3 - 0.5 * df / dw_3 = 5 - 0.5 * 68 = -29.5\n    """"""\n    train_inputs = torch.tensor([[1., 2., 3.]])\n    train_loss = 0.5 * (model(train_inputs) ** 2)\n\n    params = gradient_update_parameters(model,\n                                        train_loss,\n                                        params=None,\n                                        step_size=0.5,\n                                        first_order=False)\n\n    assert train_loss.item() == 264.5\n    assert list(params.keys()) == [\'weight\']\n    assert torch.all(params[\'weight\'].data == torch.tensor([[-9.5, -20., -29.5]]))\n\n    """"""\n    The new loss function (still with respect to the weights of the model w) is\n    defined as:\n        g(w) = 0.5 * (4 * w\'_1 + 5 * w\'_2 + 6 * w\'_3) ** 2\n             = 0.5 * (4 * (w_1 - 0.5 * df / dw_1)\n                    + 5 * (w_2 - 0.5 * df / dw_2)\n                    + 6 * (w_3 - 0.5 * df / dw_3)) ** 2\n             = 0.5 * (4 * (w_1 - 0.5 * 1 * (1 * w_1 + 2 * w_2 + 3 * w_3))\n                    + 5 * (w_2 - 0.5 * 2 * (1 * w_1 + 2 * w_2 + 3 * w_3))\n                    + 6 * (w_3 - 0.5 * 3 * (1 * w_1 + 2 * w_2 + 3 * w_3))) ** 2\n             = 0.5 * ((4 - 4 * 0.5 - 5 * 1.0 - 6 * 1.5) * w_1\n                    + (5 - 4 * 1.0 - 5 * 2.0 - 6 * 3.0) * w_2\n                    + (6 - 4 * 1.5 - 5 * 3.0 - 6 * 4.5) * w_3) ** 2\n             = 0.5 * (-12 * w_1 - 27 * w_2 - 42 * w_3) ** 2\n\n    Therefore the gradient of the function g with respect to w (and evaluated\n    at w = [2, 3, 5]) is:\n        dg / dw_1 = -12 * (-12 * w_1 - 27 * w_2 - 42 * w_3) =  3780\n        dg / dw_2 = -27 * (-12 * w_1 - 27 * w_2 - 42 * w_3) =  8505\n        dg / dw_3 = -42 * (-12 * w_1 - 27 * w_2 - 42 * w_3) = 13230\n    """"""\n    test_inputs = torch.tensor([[4., 5., 6.]])\n    test_loss = 0.5 * (model(test_inputs, params=params) ** 2)\n\n    grads = torch.autograd.grad(test_loss, model.parameters())\n\n    assert test_loss.item() == 49612.5\n    assert len(grads) == 1\n    assert torch.all(grads[0].data == torch.tensor([[3780., 8505., 13230.]]))\n\n\ndef test_update_parameters_first_order(model):\n    """"""\n    The loss function (with respect to the weights of the model w) is defined as\n        f(w) = 0.5 * (4 * w_1 + 5 * w_2 + 6 * w_3) ** 2\n    with w = [2, 3, 5].\n\n    The gradient of the function f with respect to w, and evaluated\n    at w = [2, 3, 5] is:\n        df / dw_1 = 4 * (4 * w_1 + 5 * w_2 + 6 * w_3) = 212\n        df / dw_2 = 5 * (4 * w_1 + 5 * w_2 + 6 * w_3) = 265\n        df / dw_3 = 6 * (4 * w_1 + 5 * w_2 + 6 * w_3) = 318\n\n    The updated parameter w\' is then given by one step of gradient descent,\n    with step size 0.5:\n        w\'_1 = w_1 - 0.5 * df / dw_1 = 2 - 0.5 * 212 = -104\n        w\'_2 = w_2 - 0.5 * df / dw_2 = 3 - 0.5 * 265 = -129.5\n        w\'_3 = w_3 - 0.5 * df / dw_3 = 5 - 0.5 * 318 = -154\n    """"""\n    train_inputs = torch.tensor([[4., 5., 6.]])\n    train_loss = 0.5 * (model(train_inputs) ** 2)\n\n    params = gradient_update_parameters(model,\n                                        train_loss,\n                                        params=None,\n                                        step_size=0.5,\n                                        first_order=True)\n\n    assert train_loss.item() == 1404.5\n    assert list(params.keys()) == [\'weight\']\n    assert torch.all(params[\'weight\'].data == torch.tensor([[-104., -129.5, -154.]]))\n\n    """"""\n    The new loss function (still with respect to the weights of the model w) is\n    defined as:\n        g(w) = 0.5 * (1 * w\'_1 + 2 * w\'_2 + 3 * w\'_3) ** 2\n\n    Since we computed w\' with the first order approximation, the gradient of the\n    function g with respect to w, and evaluated at w = [2, 3, 5], is:\n        dg / dw_1 = 1 * (1 * w\'_1 + 2 * w\'_2 + 3 * w\'_3) =  -825\n        dg / dw_2 = 2 * (1 * w\'_1 + 2 * w\'_2 + 3 * w\'_3) = -1650\n        dg / dw_3 = 3 * (1 * w\'_1 + 2 * w\'_2 + 3 * w\'_3) = -2475\n    """"""\n    test_inputs = torch.tensor([[1., 2., 3.]])\n    test_loss = 0.5 * (model(test_inputs, params=params) ** 2)\n\n    grads = torch.autograd.grad(test_loss, model.parameters())\n\n    assert test_loss.item() == 340312.5\n    assert len(grads) == 1\n    assert torch.all(grads[0].data == torch.tensor([[-825., -1650., -2475.]]))\n\n\ndef test_multiple_update_parameters(model):\n    """"""\n    The loss function (with respect to the weights of the model w) is defined as\n        f(w) = 0.5 * (1 * w_1 + 2 * w_2 + 3 * w_3) ** 2\n    with w = [2, 3, 5].\n\n    The gradient of f with respect to w is:\n        df / dw_1 = 1 * (1 * w_1 + 2 * w_2 + 3 * w_3) = 23\n        df / dw_2 = 2 * (1 * w_1 + 2 * w_2 + 3 * w_3) = 46\n        df / dw_3 = 3 * (1 * w_1 + 2 * w_2 + 3 * w_3) = 69\n\n    The updated parameters are given by:\n        w\'_1 = w_1 - 1. * df / dw_1 = 2 - 1. * 23 = -21\n        w\'_2 = w_2 - 1. * df / dw_2 = 3 - 1. * 46 = -43\n        w\'_3 = w_3 - 1. * df / dw_3 = 5 - 1. * 69 = -64\n    """"""\n    train_inputs = torch.tensor([[1., 2., 3.]])\n\n    train_loss_1 = 0.5 * (model(train_inputs) ** 2)\n    params_1 = gradient_update_parameters(model,\n                                          train_loss_1,\n                                          params=None,\n                                          step_size=1.,\n                                          first_order=False)\n\n    assert train_loss_1.item() == 264.5\n    assert list(params_1.keys()) == [\'weight\']\n    assert torch.all(params_1[\'weight\'].data == torch.tensor([[-21., -43., -64.]]))\n\n    """"""\n    The new loss function is defined as\n        g(w\') = 0.5 * (1 * w\'_1 + 2 * w\'_2 + 3 * w\'_3) ** 2\n    with w\' = [-21, -43, -64].\n\n    The gradient of g with respect to w\' is:\n        dg / dw\'_1 = 1 * (1 * w\'_1 + 2 * w\'_2 + 3 * w\'_3) = -299\n        dg / dw\'_2 = 2 * (1 * w\'_1 + 2 * w\'_2 + 3 * w\'_3) = -598\n        dg / dw\'_3 = 3 * (1 * w\'_1 + 2 * w\'_2 + 3 * w\'_3) = -897\n\n    The updated parameters are given by:\n        w\'\'_1 = w\'_1 - 1. * dg / dw\'_1 = -21 - 1. * -299 = 278\n        w\'\'_2 = w\'_2 - 1. * dg / dw\'_2 = -43 - 1. * -598 = 555\n        w\'\'_3 = w\'_3 - 1. * dg / dw\'_3 = -64 - 1. * -897 = 833\n    """"""\n    train_loss_2 = 0.5 * (model(train_inputs, params=params_1) ** 2)\n    params_2 = gradient_update_parameters(model,\n                                          train_loss_2,\n                                          params=params_1,\n                                          step_size=1.,\n                                          first_order=False)\n\n    assert train_loss_2.item() == 44700.5\n    assert list(params_2.keys()) == [\'weight\']\n    assert torch.all(params_2[\'weight\'].data == torch.tensor([[278., 555., 833.]]))\n\n    """"""\n    The new loss function is defined as\n        h(w\'\') = 0.5 * (1 * w\'\'_1 + 2 * w\'\'_2 + 3 * w\'\'_3) ** 2\n    with w\'\' = [278, 555, 833].\n\n    The gradient of h with respect to w\'\' is:\n        dh / dw\'\'_1 = 1 * (1 * w\'\'_1 + 2 * w\'\'_2 + 3 * w\'\'_3) =  3887\n        dh / dw\'\'_2 = 2 * (1 * w\'\'_1 + 2 * w\'\'_2 + 3 * w\'\'_3) =  7774\n        dh / dw\'\'_3 = 3 * (1 * w\'\'_1 + 2 * w\'\'_2 + 3 * w\'\'_3) = 11661\n\n    The updated parameters are given by:\n        w\'\'\'_1 = w\'\'_1 - 1. * dh / dw\'\'_1 = 278 - 1. *  3887 =  -3609\n        w\'\'\'_2 = w\'\'_2 - 1. * dh / dw\'\'_2 = 555 - 1. *  7774 =  -7219\n        w\'\'\'_3 = w\'\'_3 - 1. * dh / dw\'\'_3 = 833 - 1. * 11661 = -10828\n    """"""\n    train_loss_3 = 0.5 * (model(train_inputs, params=params_2) ** 2)\n    params_3 = gradient_update_parameters(model,\n                                          train_loss_3,\n                                          params=params_2,\n                                          step_size=1.,\n                                          first_order=False)\n\n    assert train_loss_3.item() == 7554384.5\n    assert list(params_3.keys()) == [\'weight\']\n    assert torch.all(params_3[\'weight\'].data == torch.tensor([[-3609., -7219., -10828.]]))\n\n    """"""\n    The new loss function is defined as\n        l(w) = 4 * w\'\'\'_1 + 5 * w\'\'\'_2 + 6 * w\'\'\'_3\n    with w = [2, 3, 5] and w\'\'\' = [-3609, -7219, -10828].\n\n    The gradient of l with respect to w is:\n        dl / dw_1 = 4 * dw\'\'\'_1 / dw_1 + 5 * dw\'\'\'_2 / dw_1 + 6 * dw\'\'\'_3 / dw_1\n                  = ... =  -5020\n        dl / dw_2 = 4 * dw\'\'\'_1 / dw_2 + 5 * dw\'\'\'_2 / dw_2 + 6 * dw\'\'\'_3 / dw_2\n                  = ... = -10043\n        dl / dw_3 = 4 * dw\'\'\'_1 / dw_3 + 5 * dw\'\'\'_2 / dw_3 + 6 * dw\'\'\'_3 / dw_3\n                  = ... = -15066\n    """"""\n    test_inputs = torch.tensor([[4., 5., 6.]])\n    test_loss = model(test_inputs, params=params_3)\n    grads = torch.autograd.grad(test_loss, model.parameters())\n\n    assert test_loss.item() == -115499.\n    assert len(grads) == 1\n    assert torch.all(grads[0].data == torch.tensor([[-5020., -10043., -15066.]]))\n'"
torchmeta/tests/utils/test_prototype.py,4,"b""import pytest\n\nimport numpy as np\nimport torch\n\nfrom torchmeta.utils.prototype import get_num_samples, get_prototypes, prototypical_loss\n\n\n@pytest.mark.parametrize('dtype', [None, torch.float32])\ndef test_get_num_samples(dtype):\n    # Numpy\n    num_classes = 3\n    targets_np = np.random.randint(0, num_classes, size=(2, 5))\n\n    # PyTorch\n    targets_th = torch.as_tensor(targets_np)\n    num_samples_th = get_num_samples(targets_th, num_classes, dtype=dtype)\n\n    num_samples_np = np.zeros((2, num_classes), dtype=np.int_)\n    for i in range(2):\n        for j in range(5):\n            num_samples_np[i, targets_np[i, j]] += 1\n\n    assert num_samples_th.shape == (2, num_classes)\n    if dtype is not None:\n        assert num_samples_th.dtype == dtype\n    np.testing.assert_equal(num_samples_th.numpy(), num_samples_np)\n\n\ndef test_get_prototypes():\n    # Numpy\n    num_classes = 3\n    embeddings_np = np.random.rand(2, 5, 7).astype(np.float32)\n    targets_np = np.random.randint(0, num_classes, size=(2, 5))\n\n    # PyTorch\n    embeddings_th = torch.as_tensor(embeddings_np)\n    targets_th = torch.as_tensor(targets_np)\n    prototypes_th = get_prototypes(embeddings_th, targets_th, num_classes)\n\n    assert prototypes_th.shape == (2, num_classes, 7)\n    assert prototypes_th.dtype == embeddings_th.dtype\n\n    prototypes_np = np.zeros((2, num_classes, 7), dtype=np.float32)\n    num_samples_np = np.zeros((2, num_classes), dtype=np.int_)\n    for i in range(2):\n        for j in range(5):\n            num_samples_np[i, targets_np[i, j]] += 1\n            for k in range(7):\n                prototypes_np[i, targets_np[i, j], k] += embeddings_np[i, j, k]\n\n    for i in range(2):\n        for j in range(num_classes):\n            for k in range(7):\n                prototypes_np[i, j, k] /= max(num_samples_np[i, j], 1)\n\n    np.testing.assert_allclose(prototypes_th.detach().numpy(), prototypes_np)\n"""
torchmeta/utils/data/__init__.py,0,"b""from torchmeta.utils.data.dataloader import MetaDataLoader, BatchMetaDataLoader\nfrom torchmeta.utils.data.dataset import ClassDataset, MetaDataset, CombinationMetaDataset\nfrom torchmeta.utils.data.sampler import CombinationSequentialSampler, CombinationRandomSampler\nfrom torchmeta.utils.data.task import Dataset, Task, ConcatTask, SubsetTask\n\n__all__ = [\n    'MetaDataLoader',\n    'BatchMetaDataLoader',\n    'ClassDataset',\n    'MetaDataset',\n    'CombinationMetaDataset',\n    'CombinationSequentialSampler',\n    'CombinationRandomSampler',\n    'Dataset',\n    'Task',\n    'ConcatTask',\n    'SubsetTask'\n]\n"""
torchmeta/utils/data/dataloader.py,3,"b'from collections import OrderedDict\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataloader import default_collate\nfrom torch.utils.data.dataset import Dataset as TorchDataset\n\nfrom torchmeta.utils.data.dataset import CombinationMetaDataset\nfrom torchmeta.utils.data.sampler import (CombinationSequentialSampler,\n                                          CombinationRandomSampler)\n\nclass BatchMetaCollate(object):\n\n    def __init__(self, collate_fn):\n        super().__init__()\n        self.collate_fn = collate_fn\n\n    def collate_task(self, task):\n        if isinstance(task, TorchDataset):\n            return self.collate_fn([task[idx] for idx in range(len(task))])\n        elif isinstance(task, OrderedDict):\n            return OrderedDict([(key, self.collate_task(subtask))\n                for (key, subtask) in task.items()])\n        else:\n            raise NotImplementedError()\n\n    def __call__(self, batch):\n        return self.collate_fn([self.collate_task(task) for task in batch])\n\ndef no_collate(batch):\n    return batch\n\nclass MetaDataLoader(DataLoader):\n    def __init__(self, dataset, batch_size=1, shuffle=True, sampler=None,\n                 batch_sampler=None, num_workers=0, collate_fn=None,\n                 pin_memory=False, drop_last=False, timeout=0,\n                 worker_init_fn=None):\n        if collate_fn is None:\n            collate_fn = no_collate\n\n        if isinstance(dataset, CombinationMetaDataset) and (sampler is None):\n            if shuffle:\n                sampler = CombinationRandomSampler(dataset)\n            else:\n                sampler = CombinationSequentialSampler(dataset)\n            shuffle = False\n\n        super(MetaDataLoader, self).__init__(dataset, batch_size=batch_size,\n            shuffle=shuffle, sampler=sampler, batch_sampler=batch_sampler,\n            num_workers=num_workers, collate_fn=collate_fn,\n            pin_memory=pin_memory, drop_last=drop_last, timeout=timeout,\n            worker_init_fn=worker_init_fn)\n\n\nclass BatchMetaDataLoader(MetaDataLoader):\n    def __init__(self, dataset, batch_size=1, shuffle=True, sampler=None, num_workers=0,\n                 pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None):\n        collate_fn = BatchMetaCollate(default_collate)\n\n        super(BatchMetaDataLoader, self).__init__(dataset,\n            batch_size=batch_size, shuffle=shuffle, sampler=sampler,\n            batch_sampler=None, num_workers=num_workers,\n            collate_fn=collate_fn, pin_memory=pin_memory, drop_last=drop_last,\n            timeout=timeout, worker_init_fn=worker_init_fn)\n'"
torchmeta/utils/data/dataset.py,0,"b'import numpy as np\nimport warnings\nfrom copy import deepcopy\n\nfrom itertools import combinations\nfrom torchvision.transforms import Compose\n\nfrom torchmeta.utils.data.task import ConcatTask\nfrom torchmeta.transforms import FixedCategory, Categorical, DefaultTargetTransform\nfrom torchmeta.transforms.utils import wrap_transform\n\n__all__ = [\'ClassDataset\', \'MetaDataset\', \'CombinationMetaDataset\']\n\n\nclass ClassDataset(object):\n    """"""Base class for a dataset of classes. Each item from a `ClassDataset` is \n    a dataset containing examples from the same class.\n\n    Parameters\n    ----------\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test`.\n\n    class_augmentations : list of callable, optional\n        A list of functions that augment the dataset with new classes. These classes \n        are transformations of existing classes. E.g. `transforms.HorizontalFlip()`.\n    """"""\n    def __init__(self, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, class_augmentations=None):\n        if meta_train + meta_val + meta_test == 0:\n            if meta_split is None:\n                raise ValueError(\'The meta-split is undefined. Use either the \'\n                    \'argument `meta_train=True` (or `meta_val`/`meta_test`), or \'\n                    \'the argument `meta_split=""train""` (or ""val""/""test"").\')\n            elif meta_split not in [\'train\', \'val\', \'test\']:\n                raise ValueError(\'Unknown meta-split name `{0}`. The meta-split \'\n                    \'must be in [`train`, `val`, `test`].\'.format(meta_split))\n            meta_train = (meta_split == \'train\')\n            meta_val = (meta_split == \'val\')\n            meta_test = (meta_split == \'test\')\n        elif meta_train + meta_val + meta_test > 1:\n            raise ValueError(\'Multiple arguments among `meta_train`, `meta_val` \'\n                \'and `meta_test` are set to `True`. Exactly one must be set to \'\n                \'`True`.\')\n        self.meta_train = meta_train\n        self.meta_val = meta_val\n        self.meta_test = meta_test\n        self._meta_split = meta_split\n\n        if class_augmentations is not None:\n            if not isinstance(class_augmentations, list):\n                raise TypeError(\'Unknown type for `class_augmentations`. \'\n                    \'Expected `list`, got `{0}`.\'.format(type(class_augmentations)))\n            unique_augmentations = set()\n            for augmentations in class_augmentations:\n                for transform in augmentations:\n                    if transform in unique_augmentations:\n                        warnings.warn(\'The class augmentation `{0}` already \'\n                            \'exists in the list of class augmentations (`{1}`). \'\n                            \'To avoid any duplicate, this transformation is \'\n                            \'ignored.\'.format(transform, repr(transform)),\n                            UserWarning, stacklevel=2)\n                    unique_augmentations.add(transform)\n            class_augmentations = list(unique_augmentations)\n        else:\n            class_augmentations = []\n        self.class_augmentations = class_augmentations\n\n    def get_class_augmentation(self, index):\n        transform_index = (index // self.num_classes) - 1\n        if transform_index < 0:\n            return None\n        return self.class_augmentations[transform_index]\n\n    def get_transform(self, index, transform=None):\n        class_transform = self.get_class_augmentation(index)\n        if class_transform is None:\n            return transform\n        if transform is None:\n            return class_transform\n        return Compose([class_transform, transform])\n\n    def get_target_transform(self, index):\n        class_transform = self.get_class_augmentation(index)\n        return FixedCategory(class_transform)\n\n    @property\n    def meta_split(self):\n        if self._meta_split is None:\n            if self.meta_train:\n                self._meta_split = \'train\'\n            elif self.meta_val:\n                self._meta_split = \'val\'\n            elif self.meta_test:\n                self._meta_split = \'test\'\n            else:\n                raise NotImplementedError()\n        return self._meta_split\n\n    def __getitem__(self, index):\n        raise NotImplementedError()\n\n    @property\n    def num_classes(self):\n        raise NotImplementedError()\n\n    def __len__(self):\n        return self.num_classes * (len(self.class_augmentations) + 1)\n\n\nclass MetaDataset(object):\n    """"""Base class for a meta-dataset.\n\n    Parameters\n    ----------\n    meta_train : bool (default: `False`)\n        Use the meta-train split of the dataset. If set to `True`, then the\n        arguments `meta_val` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_val : bool (default: `False`)\n        Use the meta-validation split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_test` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_test : bool (default: `False`)\n        Use the meta-test split of the dataset. If set to `True`, then the \n        arguments `meta_train` and `meta_val` must be set to `False`. Exactly one \n        of these three arguments must be set to `True`.\n\n    meta_split : string in {\'train\', \'val\', \'test\'}, optional\n        Name of the split to use. This overrides the arguments `meta_train`, \n        `meta_val` and `meta_test`.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `transforms.ClassSplitter()`.\n    """"""\n    def __init__(self, meta_train=False, meta_val=False, meta_test=False,\n                 meta_split=None, target_transform=None, dataset_transform=None):\n        if meta_train + meta_val + meta_test == 0:\n            if meta_split is None:\n                raise ValueError(\'The meta-split is undefined. Use either the \'\n                    \'argument `meta_train=True` (or `meta_val`/`meta_test`), or \'\n                    \'the argument `meta_split=""train""` (or ""val""/""test"").\')\n            elif meta_split not in [\'train\', \'val\', \'test\']:\n                raise ValueError(\'Unknown meta-split name `{0}`. The meta-split \'\n                    \'must be in [`train`, `val`, `test`].\'.format(meta_split))\n            meta_train = (meta_split == \'train\')\n            meta_val = (meta_split == \'val\')\n            meta_test = (meta_split == \'test\')\n        elif meta_train + meta_val + meta_test > 1:\n            raise ValueError(\'Multiple arguments among `meta_train`, `meta_val` \'\n                \'and `meta_test` are set to `True`. Exactly one must be set to \'\n                \'`True`.\')\n        self.meta_train = meta_train\n        self.meta_val = meta_val\n        self.meta_test = meta_test\n        self._meta_split = meta_split\n        self.target_transform = target_transform\n        self.dataset_transform = dataset_transform\n        self.seed()\n\n    @property\n    def meta_split(self):\n        if self._meta_split is None:\n            if self.meta_train:\n                self._meta_split = \'train\'\n            elif self.meta_val:\n                self._meta_split = \'val\'\n            elif self.meta_test:\n                self._meta_split = \'test\'\n            else:\n                raise NotImplementedError()\n        return self._meta_split\n\n    def seed(self, seed=None):\n        self.np_random = np.random.RandomState(seed=seed)\n        # Seed the dataset transform\n        _seed_dataset_transform(self.dataset_transform, seed=seed)\n\n    def __iter__(self):\n        for index in range(len(self)):\n            yield self[index]\n\n    def sample_task(self):\n        index = self.np_random.randint(len(self))\n        return self[index]\n\n    def __getitem__(self, index):\n        raise NotImplementedError()\n\n    def __len__(self):\n        raise NotImplementedError()\n\n\nclass CombinationMetaDataset(MetaDataset):\n    """"""Base class for a meta-dataset, where the classification tasks are over \n    multiple classes from a `ClassDataset`.\n\n    Parameters\n    ----------\n    dataset : `ClassDataset` instance\n        A dataset of classes. Each item of `dataset` is a dataset, containing \n        all the examples from the same class.\n\n    num_classes_per_task : int\n        Number of classes per tasks. This corresponds to `N` in `N-way` \n        classification.\n\n    target_transform : callable, optional\n        A function/transform that takes a target, and returns a transformed \n        version. See also `torchvision.transforms`.\n\n    dataset_transform : callable, optional\n        A function/transform that takes a dataset (ie. a task), and returns a \n        transformed version of it. E.g. `transforms.ClassSplitter()`.\n    """"""\n    def __init__(self, dataset, num_classes_per_task, target_transform=None,\n                 dataset_transform=None):\n        if not isinstance(num_classes_per_task, int):\n            raise TypeError(\'Unknown type for `num_classes_per_task`. Expected \'\n                \'`int`, got `{0}`.\'.format(type(num_classes_per_task)))\n        self.dataset = dataset\n        self.num_classes_per_task = num_classes_per_task\n        # If no target_transform, then use a default target transform that\n        # is well behaved for the `default_collate` function (assign class\n        # augmentations ot integers).\n        if target_transform is None:\n            target_transform = DefaultTargetTransform(dataset.class_augmentations)\n\n        super(CombinationMetaDataset, self).__init__(meta_train=dataset.meta_train,\n            meta_val=dataset.meta_val, meta_test=dataset.meta_test,\n            meta_split=dataset.meta_split, target_transform=target_transform,\n            dataset_transform=dataset_transform)\n\n    def __iter__(self):\n        num_classes = len(self.dataset)\n        for index in combinations(num_classes, self.num_classes_per_task):\n            yield self[index]\n\n    def sample_task(self):\n        index = self.np_random.choice(len(self.dataset),\n            size=self.num_classes_per_task, replace=False)\n        return self[tuple(index)]\n\n    def __getitem__(self, index):\n        if isinstance(index, int):\n            raise ValueError(\'The index of a `CombinationMetaDataset` must be \'\n                \'a tuple of integers, and not an integer. For example, call \'\n                \'`dataset[({0})]` to get a task with classes from 0 to {1} \'\n                \'(got `{2}`).\'.format(\', \'.join([str(idx)\n                for idx in range(self.num_classes_per_task)]),\n                self.num_classes_per_task - 1, index))\n        assert len(index) == self.num_classes_per_task\n        datasets = [self.dataset[i] for i in index]\n        # Use deepcopy on `Categorical` target transforms, to avoid any side\n        # effect across tasks.\n        task = ConcatTask(datasets, self.num_classes_per_task,\n            target_transform=wrap_transform(self.target_transform,\n            self._copy_categorical, transform_type=Categorical))\n\n        if self.dataset_transform is not None:\n            task = self.dataset_transform(task)\n\n        return task\n\n    def _copy_categorical(self, transform):\n        assert isinstance(transform, Categorical)\n        transform.reset()\n        if transform.num_classes is None:\n            transform.num_classes = self.num_classes_per_task\n        return deepcopy(transform)\n\n    def __len__(self):\n        num_classes, length = len(self.dataset), 1\n        for i in range(1, self.num_classes_per_task + 1):\n            length *= (num_classes - i + 1) / i\n        return int(length)\n\n\ndef _seed_dataset_transform(transform, seed=None):\n    if isinstance(transform, Compose):\n        for subtransform in transform.transforms:\n            _seed_dataset_transform(subtransform, seed=seed)\n    elif hasattr(transform, \'seed\'):\n        transform.seed(seed=seed)\n'"
torchmeta/utils/data/sampler.py,1,"b""import random\nfrom itertools import combinations\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\n\nfrom torchmeta.utils.data.dataset import CombinationMetaDataset\n\n__all__ = ['CombinationSequentialSampler', 'CombinationRandomSampler']\n\n\nclass CombinationSequentialSampler(SequentialSampler):\n    def __init__(self, data_source):\n        if not isinstance(data_source, CombinationMetaDataset):\n            raise TypeError('Expected `data_source` to be an instance of '\n                            '`CombinationMetaDataset`, but found '\n                            '{0}'.format(type(data_source)))\n        super(CombinationSequentialSampler, self).__init__(data_source)\n\n    def __iter__(self):\n        num_classes = len(self.data_source.dataset)\n        num_classes_per_task = self.data_source.num_classes_per_task\n        return combinations(range(num_classes), num_classes_per_task)\n\n\nclass CombinationRandomSampler(RandomSampler):\n    def __init__(self, data_source):\n        if not isinstance(data_source, CombinationMetaDataset):\n            raise TypeError('Expected `data_source` to be an instance of '\n                            '`CombinationMetaDataset`, but found '\n                            '{0}'.format(type(data_source)))\n        super(CombinationRandomSampler, self).__init__(data_source)\n\n    def __iter__(self):\n        num_classes = len(self.data_source.dataset)\n        num_classes_per_task = self.data_source.num_classes_per_task\n        for _ in combinations(range(num_classes), num_classes_per_task):\n            yield tuple(random.sample(range(num_classes), num_classes_per_task))\n"""
torchmeta/utils/data/task.py,2,"b'from torch.utils.data import ConcatDataset, Subset\nfrom torch.utils.data import Dataset as Dataset_\nfrom torchvision.transforms import Compose\n\n__all__ = [\'Dataset\', \'Task\', \'ConcatTask\', \'SubsetTask\']\n\n\nclass Dataset(Dataset_):\n    def __init__(self, index, transform=None, target_transform=None):\n        self.index = index\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def target_transform_append(self, transform):\n        if transform is None:\n            return\n        if self.target_transform is None:\n            self.target_transform = transform\n        else:\n            self.target_transform = Compose([self.target_transform, transform])\n\n    def __hash__(self):\n        return hash(self.index)\n\n\nclass Task(Dataset):\n    """"""Base class for a classification task.\n\n    Parameters\n    ----------\n    num_classes : int\n        Number of classes for the classification task.\n    """"""\n    def __init__(self, index, num_classes,\n                 transform=None, target_transform=None):\n        super(Task, self).__init__(index, transform=transform,\n                                   target_transform=target_transform)\n        self.num_classes = num_classes\n\n\nclass ConcatTask(Task, ConcatDataset):\n    def __init__(self, datasets, num_classes, target_transform=None):\n        index = tuple(task.index for task in datasets)\n        Task.__init__(self, index, num_classes)\n        ConcatDataset.__init__(self, datasets)\n        for task in self.datasets:\n            task.target_transform_append(target_transform)\n\n    def __getitem__(self, index):\n        return ConcatDataset.__getitem__(self, index)\n\n\nclass SubsetTask(Task, Subset):\n    def __init__(self, dataset, indices, num_classes=None,\n                 target_transform=None):\n        if num_classes is None:\n            num_classes = dataset.num_classes\n        Task.__init__(self, dataset.index, num_classes)\n        Subset.__init__(self, dataset, indices)\n        self.dataset.target_transform_append(target_transform)\n\n    def __getitem__(self, index):\n        return Subset.__getitem__(self, index)\n\n    def __hash__(self):\n        return hash((self.index, tuple(self.indices)))\n'"
