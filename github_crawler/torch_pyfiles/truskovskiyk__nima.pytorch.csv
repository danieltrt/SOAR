file_path,api_count,code
setup.py,0,"b'# -*- coding: utf-8 -*-\n\nimport re\n\nfrom setuptools import find_packages, setup\n\n\nwith open(""README.md"") as f:\n    readme = f.read()\n\nwith open(""requirements.txt"") as f:\n    install_requires = f.read().splitlines()\n\n\nwith open(""nima/__init__.py"") as f:\n    txt = f.read()\n    try:\n        version = re.findall(r\'^__version__ = ""([^""]+)""\\r?$\', txt, re.M)[0]\n    except IndexError:\n        raise RuntimeError(""Unable to determine version."")\n\nsetup(\n    name=""nima"",\n    version=version,\n    python_requires="">=3.7.0"",\n    install_requires=install_requires,\n    include_package_data=True,\n    description=""Neural IMage Assessment"",\n    long_description=readme,\n    long_description_content_type=""text/markdown; charset=UTF-8; variant=GFM"",\n    packages=find_packages(),\n    entry_points={""console_scripts"": ""nima-cli=nima.cli:main""},\n)\n'"
nima/__init__.py,0,"b'__version__ = ""19.6.29""\n'"
nima/api.py,0,"b'import asyncio\nimport io\nimport logging\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\nimport aiohttp.multipart\nimport aiohttp.web\nfrom PIL import Image\n\nfrom nima.worker import WorkersConfig, init_workers, predict\n\n\nlogger = logging.getLogger(__name__)\n\n\nclass ModelHandler:\n    def __init__(self, executor: ThreadPoolExecutor):\n        self._loop = asyncio.get_event_loop()\n        self._executor = executor\n\n    def register(self, app: aiohttp.web.Application) -> None:\n        app.add_routes((aiohttp.web.post(""/predict"", self.handle_predict, name=""predict""),))\n        app.add_routes((aiohttp.web.get(""/ping"", self.handle_ping),))\n\n    @staticmethod\n    async def handle_ping(request: aiohttp.web.Request) -> aiohttp.web.Response:\n        return aiohttp.web.Response()\n\n    async def handle_predict(self, request: aiohttp.web.Request) -> aiohttp.web.Response:\n        start = time.monotonic()\n        form = await request.post()\n        raw_data = form[""file""].file.read()\n        image = Image.open(io.BytesIO(raw_data))\n        #\n        executor = self._executor\n        result = await self._loop.run_in_executor(executor, predict, image)\n        end = time.monotonic()\n        total_time = end - start\n        result[""total_time""] = total_time\n        logger.info(f""total request time is {total_time}"")\n        return aiohttp.web.json_response(result)\n\n\n@aiohttp.web.middleware\nasync def handle_exceptions(request: aiohttp.web.Request, handler) -> aiohttp.web.Response:  # type: ignore\n    try:\n        return await handler(request)\n    except ValueError as e:\n        payload = {""error"": str(e)}\n        return aiohttp.web.json_response(payload, status=aiohttp.web.HTTPBadRequest.status_code)\n    except aiohttp.web.HTTPException:\n        raise\n    except Exception as e:\n        msg_str = f""Unexpected exception: {str(e)}. "" f""Path with query: {request.path_qs}.""\n        logging.exception(msg_str)\n        payload = {""error"": msg_str}\n        return aiohttp.web.json_response(payload, status=aiohttp.web.HTTPInternalServerError.status_code)\n\n\nasync def create_models_app(\n    executor: ThreadPoolExecutor, models_app: aiohttp.web.Application\n) -> aiohttp.web.Application:\n    models_handler = ModelHandler(executor)\n    models_handler.register(models_app)\n    return models_app\n\n\nasync def create_app(config: ""Config"") -> aiohttp.web.Application:\n    app = aiohttp.web.Application(middlewares=[handle_exceptions])\n    app[""config""] = config\n\n    executor = await init_workers(app, config.worker)\n    app[""executor""] = executor\n    app = await create_models_app(executor=executor, models_app=app)\n    return app\n\n\n@dataclass(frozen=True)\nclass ServerConfig:\n    host: str = ""0.0.0.0""\n    port: int = 8080\n\n\n@dataclass(frozen=True)\nclass Config:\n    server: ServerConfig\n    worker: WorkersConfig\n\n\ndef run_api(path_to_model_state: Path, port: int = 8080, host: str = ""0.0.0.0"") -> None:\n    config = Config(\n        server=ServerConfig(port=port, host=host), worker=WorkersConfig(path_to_model_state=path_to_model_state)\n    )\n    logging.info(""Loaded config: %r"", config)\n    loop = asyncio.get_event_loop()\n    app = loop.run_until_complete(create_app(config))\n    aiohttp.web.run_app(app, host=config.server.host, port=config.server.port)\n'"
nima/clean_dataset.py,0,"b'import logging\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.datasets.folder import default_loader\nfrom tqdm import tqdm\n\n\nlogger = logging.getLogger(__file__)\n\n\ndef _remove_all_not_found_image(df: pd.DataFrame, path_to_images: Path) -> pd.DataFrame:\n    clean_rows = []\n    for _, row in df.iterrows():\n        image_id = row[""image_id""]\n        try:\n            file_name = path_to_images / f""{image_id}.jpg""\n            _ = default_loader(file_name)\n        except (FileNotFoundError, OSError, UnboundLocalError) as ex:\n            logger.info(f""broken image {file_name} : {ex}"")\n        else:\n            clean_rows.append(row)\n    df_clean = pd.DataFrame(clean_rows)\n    return df_clean\n\n\ndef remove_all_not_found_image(df: pd.DataFrame, path_to_images: Path, num_workers: int) -> pd.DataFrame:\n    futures = []\n    results = []\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        for df_batch in np.array_split(df, num_workers):\n            future = executor.submit(_remove_all_not_found_image, df=df_batch, path_to_images=path_to_images)\n            futures.append(future)\n        for future in tqdm(as_completed(futures), total=len(futures)):\n            results.append(future.result())\n    new_df = pd.concat(results)\n    return new_df\n\n\ndef read_ava_txt(path_to_ava: Path) -> pd.DataFrame:\n    # NIMA origin file format and indexes\n    df = pd.read_csv(path_to_ava, header=None, sep="" "")\n    del df[0]\n    score_first_column = 2\n    score_last_column = 12\n    tag_first_column = 1\n    tag_last_column = 4\n    score_names = [f""score{i}"" for i in range(score_first_column, score_last_column)]\n    tag_names = [f""tag{i}"" for i in range(tag_first_column, tag_last_column)]\n    df.columns = [""image_id""] + score_names + tag_names\n    # leave only score columns\n    df = df[[""image_id""] + score_names]\n    return df\n\n\ndef clean_and_split(\n    path_to_ava_txt: Path, path_to_save_csv: Path, path_to_images: Path, train_size: float, num_workers: int\n):\n    logger.info(""read ava txt"")\n    df = read_ava_txt(path_to_ava_txt)\n    logger.info(""removing broken images"")\n    df = remove_all_not_found_image(df, path_to_images, num_workers=num_workers)\n    logger.info(""train val test split"")\n    df_train, df_val_test = train_test_split(df, train_size=train_size)\n    df_val, df_test = train_test_split(df_val_test, train_size=0.5)\n    train_path = path_to_save_csv / ""train.csv""\n    val_path = path_to_save_csv / ""val.csv""\n    test_path = path_to_save_csv / ""test.csv""\n    logger.info(f""saving to {train_path} {val_path} and {test_path}"")\n    df_train.to_csv(train_path, index=False)\n    df_val.to_csv(val_path, index=False)\n    df_test.to_csv(test_path, index=False)\n'"
nima/cli.py,0,"b'import logging\nfrom pathlib import Path\n\nimport click\n\nfrom nima.api import run_api\nfrom nima.clean_dataset import clean_and_split\nfrom nima.common import set_up_seed\nfrom nima.inference_model import InferenceModel\nfrom nima.trainer import Trainer, validate_and_test\n\n\ndef init_logging() -> None:\n    logging.basicConfig(level=logging.DEBUG, format=""%(asctime)s - %(name)s - %(levelname)s - %(message)s"")\n\n\n@click.group()\ndef cli():\n    pass\n\n\n@click.command(""prepare-dataset"", short_help=""Parse, clean and split dataset"")\n@click.option(""--path_to_ava_txt"", help=""origin AVA.txt file"", required=True, type=Path)\n@click.option(""--path_to_save_csv"", help=""where save train.csv|val.csv|test.csv"", required=True, type=Path)\n@click.option(""--path_to_images"", help=""images directory"", required=True, type=Path)\n@click.option(""--train_size"", help=""train dataset size"", default=0.8, type=float)\n@click.option(""--num_workers"", help=""num workers for parallel processing"", default=64, type=int)\ndef prepare_dataset(\n    path_to_ava_txt: Path, path_to_save_csv: Path, path_to_images: Path, train_size: float, num_workers: int\n):\n    click.echo(f""Clean and split dataset to train|val|test in {num_workers} threads. It will takes several minutes"")\n    clean_and_split(\n        path_to_ava_txt=path_to_ava_txt,\n        path_to_save_csv=path_to_save_csv,\n        path_to_images=path_to_images,\n        train_size=train_size,\n        num_workers=num_workers,\n    )\n    click.echo(""Done!"")\n\n\n@click.command(""train-model"", short_help=""Train model"")\n@click.option(""--path_to_save_csv"", help=""where save train.csv|val.csv|test.csv"", required=True, type=Path)\n@click.option(""--path_to_images"", help=""images directory"", required=True, type=Path)\n@click.option(""--experiment_dir"", help=""directory name to save all logs and weight"", required=True, type=Path)\n@click.option(""--model_type"", help=""res net model type"", default=""resnet18"", type=str)\n@click.option(""--batch_size"", help=""batch size"", default=128, type=int)\n@click.option(""--num_workers"", help=""number of reading workers"", default=16, type=int)\n@click.option(""--num_epoch"", help=""number of epoch"", default=32, type=int)\n@click.option(""--init_lr"", help=""initial learning rate"", default=0.0001, type=float)\n@click.option(""--drop_out"", help=""drop out"", default=0.5, type=float)\n@click.option(""--optimizer_type"", help=""optimizer type"", default=""adam"", type=str)\n@click.option(""--seed"", help=""random seed"", default=42, type=int)\ndef train_model(\n    path_to_save_csv: Path,\n    path_to_images: Path,\n    experiment_dir: Path,\n    model_type: str,\n    batch_size: int,\n    num_workers: int,\n    num_epoch: int,\n    init_lr: float,\n    drop_out: float,\n    optimizer_type: str,\n    seed: int,\n):\n    click.echo(""Train and validate model"")\n    set_up_seed(seed)\n    trainer = Trainer(\n        path_to_save_csv=path_to_save_csv,\n        path_to_images=path_to_images,\n        experiment_dir=experiment_dir,\n        model_type=model_type,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        num_epoch=num_epoch,\n        init_lr=init_lr,\n        drop_out=drop_out,\n        optimizer_type=optimizer_type,\n    )\n    trainer.train_model()\n    click.echo(""Done!"")\n\n\n@click.command(""get-image-score"", short_help=""Get image scores"")\n@click.option(""--path_to_model_state"", help=""path to model weight .pth file"", required=True, type=Path)\n@click.option(""--path_to_image"", help=""image "", required=True, type=Path)\ndef get_image_score(path_to_model_state, path_to_image):\n    model = InferenceModel(path_to_model_state=path_to_model_state)\n    result = model.predict_from_file(path_to_image)\n    click.echo(result)\n\n\n@click.command(""validate-model"", short_help=""Validate model"")\n@click.option(""--path_to_model_state"", help=""path to model weight .pth file"", required=True, type=Path)\n@click.option(""--path_to_save_csv"", help=""where save train.csv|val.csv|test.csv"", required=True, type=Path)\n@click.option(""--path_to_images"", help=""images directory"", required=True, type=Path)\n@click.option(""--batch_size"", help=""batch size"", default=128, type=int)\n@click.option(""--num_workers"", help=""number of reading workers"", default=16, type=int)\n@click.option(""--drop_out"", help=""drop out"", default=0.0, type=float)\ndef validate_model(path_to_model_state, path_to_save_csv, path_to_images, batch_size, num_workers, drop_out):\n    validate_and_test(\n        path_to_model_state=path_to_model_state,\n        path_to_save_csv=path_to_save_csv,\n        path_to_images=path_to_images,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        drop_out=drop_out,\n    )\n    click.echo(""Done!"")\n\n\n@click.command(""run-web-api"", short_help=""Start server for model serving"")\n@click.option(""--path_to_model_state"", help=""path to model weight .pth file"", required=True, type=Path)\n@click.option(""--port"", help=""port for web app"", default=8080, type=int)\n@click.option(""--host"", help=""host for web app"", default=""0.0.0.0"", type=str)\ndef run_web_api(path_to_model_state: Path, port: int, host: str):\n    run_api(path_to_model_state=path_to_model_state, port=port, host=host)\n\n\ndef main():\n    init_logging()\n    cli.add_command(prepare_dataset)\n    cli.add_command(train_model)\n    cli.add_command(validate_model)\n    cli.add_command(get_image_score)\n    cli.add_command(run_web_api)\n    cli()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
nima/common.py,3,"b'import numpy as np\nimport torch\nfrom torchvision import transforms\n\n\nIMAGE_NET_MEAN = [0.485, 0.456, 0.406]\nIMAGE_NET_STD = [0.229, 0.224, 0.225]\n\n\nclass Transform:\n    def __init__(self):\n        normalize = transforms.Normalize(mean=IMAGE_NET_MEAN, std=IMAGE_NET_STD)\n\n        self._train_transform = transforms.Compose(\n            [\n                transforms.Resize((256, 256)),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomCrop((224, 224)),\n                transforms.ToTensor(),\n                normalize,\n            ]\n        )\n\n        self._val_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), normalize])\n\n    @property\n    def train_transform(self):\n        return self._train_transform\n\n    @property\n    def val_transform(self):\n        return self._val_transform\n\n\ndef get_mean_score(score):\n    buckets = np.arange(1, 11)\n    mu = (buckets * score).sum()\n    return mu\n\n\ndef get_std_score(scores):\n    si = np.arange(1, 11)\n    mean = get_mean_score(scores)\n    std = np.sqrt(np.sum(((si - mean) ** 2) * scores))\n    return std\n\n\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef set_up_seed(seed=42):\n    torch.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)\n\n\ndef format_output(mean_score, std_score, prob):\n    return {""mean_score"": float(mean_score), ""std_score"": float(std_score), ""scores"": [float(x) for x in prob]}\n'"
nima/dataset.py,2,"b'from pathlib import Path\nfrom typing import Tuple\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision.datasets.folder import default_loader\n\n\nclass AVADataset(Dataset):\n    def __init__(self, path_to_csv: Path, images_path: Path, transform):\n        self.df = pd.read_csv(path_to_csv)\n        self.images_path = images_path\n        self.transform = transform\n\n    def __len__(self) -> int:\n        return self.df.shape[0]\n\n    def __getitem__(self, item: int) -> Tuple[torch.Tensor, np.ndarray]:\n        row = self.df.iloc[item]\n\n        image_id = row[""image_id""]\n        image_path = self.images_path / f""{image_id}.jpg""\n        image = default_loader(image_path)\n        x = self.transform(image)\n\n        y = row[1:].values.astype(""float32"")\n        p = y / y.sum()\n\n        return x, p\n'"
nima/emd_loss.py,5,"b'import torch\nimport torch.nn as nn\n\n\nclass EDMLoss(nn.Module):\n    def __init__(self):\n        super(EDMLoss, self).__init__()\n\n    def forward(self, p_target: torch.Tensor, p_estimate: torch.Tensor):\n        assert p_target.shape == p_estimate.shape\n        # cdf for values [1, 2, ..., 10]\n        cdf_target = torch.cumsum(p_target, dim=1)\n        # cdf for values [1, 2, ..., 10]\n        cdf_estimate = torch.cumsum(p_estimate, dim=1)\n        cdf_diff = cdf_estimate - cdf_target\n        samplewise_emd = torch.sqrt(torch.mean(torch.pow(torch.abs(cdf_diff), 2)))\n        return samplewise_emd.mean()\n'"
nima/inference_model.py,4,"b'from pathlib import Path\n\nimport torch\nfrom PIL.Image import Image\nfrom torchvision.datasets.folder import default_loader\n\nfrom nima.common import Transform, format_output, get_mean_score, get_std_score\nfrom nima.model import create_model\n\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(""cuda"" if use_cuda else ""cpu"")\n\n\nclass InferenceModel:\n    def __init__(self, path_to_model_state: Path):\n        self.transform = Transform().val_transform\n        model_state = torch.load(path_to_model_state, map_location=lambda storage, loc: storage)\n        self.model = create_model(model_type=model_state[""model_type""], drop_out=0)\n        self.model.load_state_dict(model_state[""state_dict""])\n        self.model = self.model.to(device)\n        self.model.eval()\n\n    def predict_from_file(self, image_path: Path):\n        image = default_loader(image_path)\n        return self.predict(image)\n\n    def predict_from_pil_image(self, image: Image):\n        image = image.convert(""RGB"")\n        return self.predict(image)\n\n    @torch.no_grad()\n    def predict(self, image):\n        image = self.transform(image)\n        image = image.unsqueeze_(0)\n        image = image.to(device)\n        prob = self.model(image).data.cpu().numpy()[0]\n\n        mean_score = get_mean_score(prob)\n        std_score = get_std_score(prob)\n\n        return format_output(mean_score, std_score, prob)\n'"
nima/model.py,1,"b'import torch.nn as nn\nimport torchvision as tv\n\n\nMODELS = {\n    ""resnet18"": (tv.models.resnet18, 512),\n    ""resnet34"": (tv.models.resnet34, 512),\n    ""resnet50"": (tv.models.resnet50, 2048),\n    ""resnet101"": (tv.models.resnet101, 2048),\n    ""resnet152"": (tv.models.resnet152, 2048),\n}\n\n\nclass NIMA(nn.Module):\n    def __init__(self, base_model: nn.Module, input_features: int, drop_out: float):\n        super(NIMA, self).__init__()\n        self.base_model = base_model\n\n        self.head = nn.Sequential(\n            nn.ReLU(inplace=True), nn.Dropout(p=drop_out), nn.Linear(input_features, 10), nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n        x = self.base_model(x)\n        x = x.view(x.size(0), -1)\n        x = self.head(x)\n        return x\n\n\ndef create_model(model_type: str, drop_out: float) -> NIMA:\n    create_function, input_features = MODELS[model_type]\n    base_model = create_function(pretrained=True)\n    base_model = nn.Sequential(*list(base_model.children())[:-1])\n    return NIMA(base_model=base_model, input_features=input_features, drop_out=drop_out)\n'"
nima/trainer.py,14,"b'import logging\nimport time\nfrom pathlib import Path\nfrom typing import Tuple\n\nimport torch\nimport torch.optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\n\nfrom nima.common import AverageMeter, Transform\nfrom nima.dataset import AVADataset\nfrom nima.emd_loss import EDMLoss\nfrom nima.model import NIMA, create_model\n\n\nlogger = logging.getLogger(__file__)\n\n\ndef get_dataloaders(\n    path_to_save_csv: Path, path_to_images: Path, batch_size: int, num_workers: int\n) -> Tuple[DataLoader, DataLoader, DataLoader]:\n    transform = Transform()\n\n    train_ds = AVADataset(path_to_save_csv / ""train.csv"", path_to_images, transform.train_transform)\n    val_ds = AVADataset(path_to_save_csv / ""val.csv"", path_to_images, transform.val_transform)\n    test_ds = AVADataset(path_to_save_csv / ""test.csv"", path_to_images, transform.val_transform)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n    test_ds = DataLoader(test_ds, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n    return train_loader, val_loader, test_ds\n\n\ndef validate_and_test(\n    path_to_save_csv: Path,\n    path_to_images: Path,\n    batch_size: int,\n    num_workers: int,\n    drop_out: float,\n    path_to_model_state: Path,\n) -> None:\n    _, val_loader, test_loader = get_dataloaders(\n        path_to_save_csv=path_to_save_csv, path_to_images=path_to_images, batch_size=batch_size, num_workers=num_workers\n    )\n\n    device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n    criterion = EDMLoss().to(device)\n\n    best_state = torch.load(path_to_model_state)\n\n    model = create_model(best_state[""model_type""], drop_out=drop_out).to(device)\n    model.load_state_dict(best_state[""state_dict""])\n\n    model.eval()\n    validate_losses = AverageMeter()\n\n    with torch.no_grad():\n        for (x, y) in tqdm(val_loader):\n            x = x.to(device)\n            y = y.to(device)\n            y_pred = model(x)\n            loss = criterion(p_target=y, p_estimate=y_pred)\n            validate_losses.update(loss.item(), x.size(0))\n\n    test_losses = AverageMeter()\n    with torch.no_grad():\n        for (x, y) in tqdm(test_loader):\n            x = x.to(device)\n            y = y.to(device)\n            y_pred = model(x)\n            loss = criterion(p_target=y, p_estimate=y_pred)\n            test_losses.update(loss.item(), x.size(0))\n    logger.info(f""val loss {validate_losses.avg}; test loss {test_losses.avg}"")\n\n\ndef get_optimizer(optimizer_type: str, model: NIMA, init_lr: float) -> torch.optim.Optimizer:\n    if optimizer_type == ""adam"":\n        optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n    elif optimizer_type == ""sgd"":\n        optimizer = torch.optim.SGD(model.parameters(), lr=init_lr, momentum=0.5, weight_decay=9)\n    else:\n        raise ValueError(f""not such optimizer {optimizer_type}"")\n    return optimizer\n\n\nclass Trainer:\n    def __init__(\n        self,\n        *,\n        path_to_save_csv: Path,\n        path_to_images: Path,\n        num_epoch: int,\n        model_type: str,\n        num_workers: int,\n        batch_size: int,\n        init_lr: float,\n        experiment_dir: Path,\n        drop_out: float,\n        optimizer_type: str,\n    ):\n\n        train_loader, val_loader, _ = get_dataloaders(\n            path_to_save_csv=path_to_save_csv,\n            path_to_images=path_to_images,\n            batch_size=batch_size,\n            num_workers=num_workers,\n        )\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n\n        self.device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")\n\n        model = create_model(model_type, drop_out=drop_out).to(self.device)\n        optimizer = get_optimizer(optimizer_type=optimizer_type, model=model, init_lr=init_lr)\n\n        self.model = model\n        self.optimizer = optimizer\n\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=self.optimizer, mode=""min"", patience=5)\n        self.criterion = EDMLoss().to(self.device)\n        self.model_type = model_type\n\n        experiment_dir.mkdir(exist_ok=True, parents=True)\n        self.experiment_dir = experiment_dir\n        self.writer = SummaryWriter(str(experiment_dir / ""logs""))\n        self.num_epoch = num_epoch\n        self.global_train_step = 0\n        self.global_val_step = 0\n        self.print_freq = 100\n\n    def train_model(self):\n        best_loss = float(""inf"")\n        best_state = None\n        for e in range(1, self.num_epoch + 1):\n            train_loss = self.train()\n            val_loss = self.validate()\n            self.scheduler.step(metrics=val_loss)\n\n            self.writer.add_scalar(""train/loss"", train_loss, global_step=e)\n            self.writer.add_scalar(""val/loss"", val_loss, global_step=e)\n\n            if best_state is None or val_loss < best_loss:\n                logger.info(f""updated loss from {best_loss} to {val_loss}"")\n                best_loss = val_loss\n                best_state = {\n                    ""state_dict"": self.model.state_dict(),\n                    ""model_type"": self.model_type,\n                    ""epoch"": e,\n                    ""best_loss"": best_loss,\n                }\n                torch.save(best_state, self.experiment_dir / ""best_state.pth"")\n\n    def train(self):\n        self.model.train()\n        train_losses = AverageMeter()\n        total_iter = len(self.train_loader.dataset) // self.train_loader.batch_size\n\n        for idx, (x, y) in enumerate(self.train_loader):\n            s = time.monotonic()\n\n            x = x.to(self.device)\n            y = y.to(self.device)\n            y_pred = self.model(x)\n            loss = self.criterion(p_target=y, p_estimate=y_pred)\n            self.optimizer.zero_grad()\n\n            loss.backward()\n\n            self.optimizer.step()\n            train_losses.update(loss.item(), x.size(0))\n\n            self.writer.add_scalar(""train/current_loss"", train_losses.val, self.global_train_step)\n            self.writer.add_scalar(""train/avg_loss"", train_losses.avg, self.global_train_step)\n            self.global_train_step += 1\n\n            e = time.monotonic()\n            if idx % self.print_freq:\n                log_time = self.print_freq * (e - s)\n                eta = ((total_iter - idx) * log_time) / 60.0\n                print(f""iter #[{idx}/{total_iter}] "" f""loss = {loss:.3f} "" f""time = {log_time:.2f} "" f""eta = {eta:.2f}"")\n\n        return train_losses.avg\n\n    def validate(self):\n        self.model.eval()\n        validate_losses = AverageMeter()\n\n        with torch.no_grad():\n            for idx, (x, y) in enumerate(self.val_loader):\n                x = x.to(self.device)\n                y = y.to(self.device)\n                y_pred = self.model(x)\n                loss = self.criterion(p_target=y, p_estimate=y_pred)\n                validate_losses.update(loss.item(), x.size(0))\n\n                self.writer.add_scalar(""val/current_loss"", validate_losses.val, self.global_val_step)\n                self.writer.add_scalar(""val/avg_loss"", validate_losses.avg, self.global_val_step)\n                self.global_val_step += 1\n\n        return validate_losses.avg\n'"
nima/worker.py,0,"b'import asyncio\nimport logging\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom aiohttp import web\nfrom PIL import Image\n\nfrom nima.inference_model import InferenceModel\n\n\nlogger = logging.getLogger(__name__)\n_model = None\n\n\ndef warm(path_to_model_state: Path) -> None:\n    logger.info(f""warm model"")\n    global _model\n    if _model is None:\n        # load model\n        _model = InferenceModel(path_to_model_state=path_to_model_state)\n        logger.info(f""created model {_model}"")\n\n\ndef clean() -> None:\n    global _model\n    _model = None\n\n\ndef predict(image: Image.Image, model: Optional[InferenceModel] = None):\n    if model is None:\n        model = _model\n\n    if model is None:\n        raise RuntimeError(""Model should be loaded first"")\n    result = model.predict_from_pil_image(image)\n    return result\n\n\n@dataclass(frozen=True)\nclass WorkersConfig:\n    path_to_model_state: Path\n    max_workers: int = 1\n\n\nasync def init_workers(app: web.Application, conf: WorkersConfig) -> ThreadPoolExecutor:\n    n = conf.max_workers\n    executor = ThreadPoolExecutor(max_workers=n)\n\n    loop = asyncio.get_event_loop()\n    run = loop.run_in_executor\n    fs = [run(executor, warm, conf.path_to_model_state) for _ in range(0, n)]\n    await asyncio.gather(*fs)\n\n    async def close_executor(app: web.Application) -> None:\n        fs = [run(executor, clean) for _ in range(0, n)]\n        await asyncio.shield(asyncio.gather(*fs))\n        executor.shutdown(wait=True)\n\n    app.on_cleanup.append(close_executor)\n    app[""executor""] = executor\n    return executor\n'"
tests/integration/__init__.py,0,b''
tests/integration/conftest.py,1,"b'import io\nimport os\nimport shutil\nfrom pathlib import Path\n\nimport pandas as pd\nimport pytest\nimport torch\nfrom click.testing import CliRunner\nfrom PIL import Image\n\nfrom nima.model import create_model\n\n\n@pytest.fixture\ndef data_dir() -> Path:\n    return Path(""tests/data"")\n\n\n@pytest.fixture\ndef model_type() -> str:\n    return ""resnet18""\n\n\n@pytest.yield_fixture\ndef state_dict_path(data_dir: Path, model_type: str):\n    model = create_model(model_type=model_type, drop_out=0.0)\n\n    best_state = {""state_dict"": model.state_dict(), ""model_type"": model_type, ""epoch"": 100, ""best_loss"": 0.0}\n\n    best_state_path = data_dir / ""tmp_test_best_state_path.pth""\n    torch.save(best_state, best_state_path)\n    yield best_state_path\n\n    os.remove(best_state_path)\n\n\n@pytest.yield_fixture\ndef image_path(data_dir: Path):\n    im = Image.new(""RGB"", (1024, 1024))\n\n    image_path = data_dir / ""tmp_test_image.jpg""\n    im.save(image_path)\n    yield image_path\n\n    os.remove(image_path)\n\n\n@pytest.yield_fixture\ndef image_file_obj(image_path: Image.Image):\n    byte_io = io.BytesIO()\n    Image.open(image_path).save(byte_io, ""JPEG"")\n    byte_io.seek(0)\n\n    yield byte_io\n\n    byte_io.close()\n\n\n@pytest.yield_fixture\ndef images_path(image_path: Path) -> Path:\n    return image_path.parents[0]\n\n\n@pytest.yield_fixture\ndef ava_csv_path(data_dir: Path):\n    data = [\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n        ""1 tmp_test_image 0 1 5 17 38 36 15 6 5 1 1 22 1396\\n"",\n    ]\n\n    temp_ava_path = data_dir / ""tmp_test_ava.csv""\n    with open(temp_ava_path, ""w"") as f:\n        f.writelines(data)\n    yield temp_ava_path\n    os.remove(temp_ava_path)\n\n\n@pytest.yield_fixture\ndef path_to_save_result(data_dir: Path):\n    temp_dir_with_results = data_dir / ""temp_results""\n    temp_dir_with_results.mkdir(parents=True, exist_ok=False)\n    yield temp_dir_with_results\n    shutil.rmtree(temp_dir_with_results)\n\n\n@pytest.yield_fixture\ndef experiment_dir(path_to_save_result: Path):\n    temp_experiment_dir = path_to_save_result / ""temp_exp""\n    temp_experiment_dir.mkdir(parents=True, exist_ok=False)\n    yield temp_experiment_dir\n    shutil.rmtree(temp_experiment_dir)\n\n\n@pytest.yield_fixture\ndef folder_with_csv(path_to_save_result: Path):\n    df = pd.DataFrame(\n        {\n            ""image_id"": [""tmp_test_image""],\n            ""score10"": [5],\n            ""score11"": [1],\n            ""score2"": [0],\n            ""score3"": [1],\n            ""score4"": [5],\n            ""score5"": [17],\n            ""score6"": [38],\n            ""score7"": [36],\n            ""score8"": [15],\n            ""score9"": [6],\n        }\n    )\n\n    df.to_csv(path_to_save_result / ""train.csv"", index=False)\n    df.to_csv(path_to_save_result / ""val.csv"", index=False)\n    df.to_csv(path_to_save_result / ""test.csv"", index=False)\n\n    yield path_to_save_result\n\n    os.remove(path_to_save_result / ""train.csv"")\n    os.remove(path_to_save_result / ""val.csv"")\n    os.remove(path_to_save_result / ""test.csv"")\n\n\n@pytest.fixture\ndef cli_runner() -> CliRunner:\n    runner = CliRunner()\n    return runner\n'"
tests/integration/test_api.py,0,"b'import io\nfrom typing import AsyncIterator, NamedTuple\n\nimport aiohttp\nimport pytest\nfrom aiohttp import FormData\nfrom aiohttp.web import HTTPOk\n\nfrom nima.api import Config, ServerConfig, WorkersConfig, create_app\n\n\n@pytest.fixture\ndef config(state_dict_path) -> Config:\n    server_config = ServerConfig()\n    workers_config = WorkersConfig(path_to_model_state=state_dict_path)\n    return Config(server=server_config, worker=workers_config)\n\n\nclass ApiConfig(NamedTuple):\n    host: str\n    port: int\n\n    @property\n    def endpoint(self) -> str:\n        return f""http://{self.host}:{self.port}""\n\n    @property\n    def model_base_url(self) -> str:\n        return self.endpoint\n\n    @property\n    def ping_url(self) -> str:\n        return self.endpoint + ""/ping""\n\n\n@pytest.fixture\nasync def api(config: Config) -> AsyncIterator[ApiConfig]:\n    app = await create_app(config)\n    runner = aiohttp.web.AppRunner(app)\n    await runner.setup()\n    api_config = ApiConfig(host=""0.0.0.0"", port=8080)\n    site = aiohttp.web.TCPSite(runner, api_config.host, api_config.port)\n    await site.start()\n    yield api_config\n    await runner.cleanup()\n\n\n@pytest.fixture\nasync def client() -> AsyncIterator[aiohttp.ClientSession]:\n    async with aiohttp.ClientSession() as session:\n        yield session\n\n\nclass TestModelApi:\n    @pytest.mark.asyncio\n    async def test_predict(self, api: ApiConfig, client: aiohttp.ClientSession, image_file_obj: io.BytesIO) -> None:\n        predict_url = api.model_base_url + ""/predict""\n\n        data = FormData()\n        data.add_field(""file"", image_file_obj, filename=""test_image.jpg"", content_type=""image/img"")\n\n        async with client.post(predict_url, data=data) as response:\n            assert response.status == HTTPOk.status_code\n            res_data = await response.json()\n            assert ""mean_score"" in res_data\n            assert ""std_score"" in res_data\n            assert ""scores"" in res_data\n            assert ""total_time"" in res_data\n\n\nclass TestApi:\n    @pytest.mark.asyncio\n    async def test_ping(self, api: ApiConfig, client: aiohttp.ClientSession) -> None:\n        async with client.get(api.ping_url) as response:\n            assert response.status == HTTPOk.status_code\n'"
tests/integration/test_cli.py,1,"b'import ast\nfrom pathlib import Path\n\nimport torch\nfrom click.testing import CliRunner\n\nfrom nima.cli import get_image_score, prepare_dataset, train_model, validate_model\n\n\nclass TestCli:\n    def test_get_image_score(self, cli_runner: CliRunner, state_dict_path: Path, image_path: Path):\n        result = cli_runner.invoke(\n            get_image_score, f""--path_to_model_state {state_dict_path} --path_to_image {image_path}""\n        )\n        res = ast.literal_eval(result.output)\n\n        assert ""mean_score"" in res\n        assert ""std_score"" in res\n        assert ""scores"" in res\n        assert len(res[""scores""]) == 10\n        assert result.exit_code == 0\n\n    def test_prepare_dataset(\n        self, cli_runner: CliRunner, ava_csv_path: Path, path_to_save_result: Path, images_path: Path\n    ):\n\n        result = cli_runner.invoke(\n            prepare_dataset,\n            f""--path_to_ava_txt {ava_csv_path} ""\n            f""--path_to_save_csv {path_to_save_result} ""\n            f""--path_to_images {images_path}"",\n        )\n        assert (path_to_save_result / ""train.csv"").exists()\n        assert (path_to_save_result / ""val.csv"").exists()\n        assert (path_to_save_result / ""test.csv"").exists()\n        assert result.exit_code == 0\n\n    def test_train_model(self, cli_runner: CliRunner, images_path: Path, experiment_dir: Path, folder_with_csv: Path):\n        assert not (experiment_dir / ""logs"").exists()\n        assert not (experiment_dir / ""best_state.pth"").exists()\n\n        result = cli_runner.invoke(\n            train_model,\n            f""--path_to_save_csv {folder_with_csv} ""\n            f""--path_to_images {images_path} ""\n            f""--experiment_dir {experiment_dir} ""\n            f""--batch_size 1 --num_epoch 5"",\n        )\n\n        assert result.exit_code == 0\n        assert (experiment_dir / ""logs"").exists()\n        assert (experiment_dir / ""best_state.pth"").exists()\n\n        best_state = torch.load(experiment_dir / ""best_state.pth"")\n\n        assert ""state_dict"" in best_state\n        assert ""model_type"" in best_state\n        assert ""epoch"" in best_state\n        assert ""best_loss"" in best_state\n\n    def test_validate_model(\n        self, cli_runner: CliRunner, images_path: Path, state_dict_path: Path, folder_with_csv: Path\n    ):\n        result = cli_runner.invoke(\n            validate_model,\n            f""--path_to_model_state {state_dict_path} ""\n            f""--path_to_save_csv {folder_with_csv} ""\n            f""--path_to_images {images_path}"",\n        )\n        assert result.exit_code == 0\n'"
tests/unit/__init__.py,0,b''
tests/unit/test_emd_loss.py,0,b'def test_emd_loss():\n    assert 1 == 1\n'
