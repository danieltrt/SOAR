file_path,api_count,code
dataset.py,2,"b""import torch.utils.data as data\r\nimport torch\r\nimport h5py\r\n\r\nclass DatasetFromHdf5(data.Dataset):\r\n    def __init__(self, file_path):\r\n        super(DatasetFromHdf5, self).__init__()\r\n        hf = h5py.File(file_path)\r\n        self.data = hf.get('data')\r\n        self.target = hf.get('label')\r\n\r\n    def __getitem__(self, index):\r\n        return torch.from_numpy(self.data[index,:,:,:]).float(), torch.from_numpy(self.target[index,:,:,:]).float()\r\n        \r\n    def __len__(self):\r\n        return self.data.shape[0]"""
demo.py,4,"b'import argparse, os\r\nimport torch\r\nfrom torch.autograd import Variable\r\nfrom scipy.ndimage import imread\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport time, math\r\nimport matplotlib.pyplot as plt\r\n\r\nparser = argparse.ArgumentParser(description=""PyTorch VDSR Demo"")\r\nparser.add_argument(""--cuda"", action=""store_true"", help=""use cuda?"")\r\nparser.add_argument(""--model"", default=""model/model_epoch_50.pth"", type=str, help=""model path"")\r\nparser.add_argument(""--image"", default=""butterfly_GT"", type=str, help=""image name"")\r\nparser.add_argument(""--scale"", default=4, type=int, help=""scale factor, Default: 4"")\r\nparser.add_argument(""--gpus"", default=""0"", type=str, help=""gpu ids (default: 0)"")\r\n\r\ndef PSNR(pred, gt, shave_border=0):\r\n    height, width = pred.shape[:2]\r\n    pred = pred[shave_border:height - shave_border, shave_border:width - shave_border]\r\n    gt = gt[shave_border:height - shave_border, shave_border:width - shave_border]\r\n    imdff = pred - gt\r\n    rmse = math.sqrt(np.mean(imdff ** 2))\r\n    if rmse == 0:\r\n        return 100\r\n    return 20 * math.log10(255.0 / rmse)\r\n    \r\ndef colorize(y, ycbcr): \r\n    img = np.zeros((y.shape[0], y.shape[1], 3), np.uint8)\r\n    img[:,:,0] = y\r\n    img[:,:,1] = ycbcr[:,:,1]\r\n    img[:,:,2] = ycbcr[:,:,2]\r\n    img = Image.fromarray(img, ""YCbCr"").convert(""RGB"")\r\n    return img\r\n\r\nopt = parser.parse_args()\r\ncuda = opt.cuda\r\n\r\nif cuda:\r\n    print(""=> use gpu id: \'{}\'"".format(opt.gpus))\r\n    os.environ[""CUDA_VISIBLE_DEVICES""] = opt.gpus\r\n    if not torch.cuda.is_available():\r\n            raise Exception(""No GPU found or Wrong gpu id, please run without --cuda"")\r\n\r\n\r\nmodel = torch.load(opt.model, map_location=lambda storage, loc: storage)[""model""]\r\n\r\nim_gt_ycbcr = imread(""Set5/"" + opt.image + "".bmp"", mode=""YCbCr"")\r\nim_b_ycbcr = imread(""Set5/""+ opt.image + ""_scale_""+ str(opt.scale) + "".bmp"", mode=""YCbCr"")\r\n    \r\nim_gt_y = im_gt_ycbcr[:,:,0].astype(float)\r\nim_b_y = im_b_ycbcr[:,:,0].astype(float)\r\n\r\npsnr_bicubic = PSNR(im_gt_y, im_b_y,shave_border=opt.scale)\r\n\r\nim_input = im_b_y/255.\r\n\r\nim_input = Variable(torch.from_numpy(im_input).float()).view(1, -1, im_input.shape[0], im_input.shape[1])\r\n\r\nif cuda:\r\n    model = model.cuda()\r\n    im_input = im_input.cuda()\r\nelse:\r\n    model = model.cpu()\r\n\r\nstart_time = time.time()\r\nout = model(im_input)\r\nelapsed_time = time.time() - start_time\r\n\r\nout = out.cpu()\r\n\r\nim_h_y = out.data[0].numpy().astype(np.float32)\r\n\r\nim_h_y = im_h_y * 255.\r\nim_h_y[im_h_y < 0] = 0\r\nim_h_y[im_h_y > 255.] = 255.\r\n\r\npsnr_predicted = PSNR(im_gt_y, im_h_y[0,:,:], shave_border=opt.scale)\r\n\r\nim_h = colorize(im_h_y[0,:,:], im_b_ycbcr)\r\nim_gt = Image.fromarray(im_gt_ycbcr, ""YCbCr"").convert(""RGB"")\r\nim_b = Image.fromarray(im_b_ycbcr, ""YCbCr"").convert(""RGB"")\r\n\r\nprint(""Scale="",opt.scale)\r\nprint(""PSNR_predicted="", psnr_predicted)\r\nprint(""PSNR_bicubic="", psnr_bicubic)\r\nprint(""It takes {}s for processing"".format(elapsed_time))\r\n\r\nfig = plt.figure()\r\nax = plt.subplot(""131"")\r\nax.imshow(im_gt)\r\nax.set_title(""GT"")\r\n\r\nax = plt.subplot(""132"")\r\nax.imshow(im_b)\r\nax.set_title(""Input(bicubic)"")\r\n\r\nax = plt.subplot(""133"")\r\nax.imshow(im_h)\r\nax.set_title(""Output(vdsr)"")\r\nplt.show()\r\n'"
eval.py,4,"b'import argparse, os\nimport torch\nfrom torch.autograd import Variable\nimport numpy as np\nimport time, math, glob\nimport scipy.io as sio\n\nparser = argparse.ArgumentParser(description=""PyTorch VDSR Eval"")\nparser.add_argument(""--cuda"", action=""store_true"", help=""use cuda?"")\nparser.add_argument(""--model"", default=""model/model_epoch_50.pth"", type=str, help=""model path"")\nparser.add_argument(""--dataset"", default=""Set5"", type=str, help=""dataset name, Default: Set5"")\nparser.add_argument(""--gpus"", default=""0"", type=str, help=""gpu ids (default: 0)"")\n\ndef PSNR(pred, gt, shave_border=0):\n    height, width = pred.shape[:2]\n    pred = pred[shave_border:height - shave_border, shave_border:width - shave_border]\n    gt = gt[shave_border:height - shave_border, shave_border:width - shave_border]\n    imdff = pred - gt\n    rmse = math.sqrt(np.mean(imdff ** 2))\n    if rmse == 0:\n        return 100\n    return 20 * math.log10(255.0 / rmse)\n\nopt = parser.parse_args()\ncuda = opt.cuda\n\nif cuda:\n    print(""=> use gpu id: \'{}\'"".format(opt.gpus))\n    os.environ[""CUDA_VISIBLE_DEVICES""] = opt.gpus\n    if not torch.cuda.is_available():\n            raise Exception(""No GPU found or Wrong gpu id, please run without --cuda"")\n\nmodel = torch.load(opt.model, map_location=lambda storage, loc: storage)[""model""]\n\nscales = [2,3,4]\n\nimage_list = glob.glob(opt.dataset+""_mat/*.*"") \n\nfor scale in scales:\n    avg_psnr_predicted = 0.0\n    avg_psnr_bicubic = 0.0\n    avg_elapsed_time = 0.0\n    count = 0.0\n    for image_name in image_list:\n        if str(scale) in image_name:\n            count += 1\n            print(""Processing "", image_name)\n            im_gt_y = sio.loadmat(image_name)[\'im_gt_y\']\n            im_b_y = sio.loadmat(image_name)[\'im_b_y\']\n                       \n            im_gt_y = im_gt_y.astype(float)\n            im_b_y = im_b_y.astype(float)\n\n            psnr_bicubic = PSNR(im_gt_y, im_b_y,shave_border=scale)\n            avg_psnr_bicubic += psnr_bicubic\n\n            im_input = im_b_y/255.\n\n            im_input = Variable(torch.from_numpy(im_input).float()).view(1, -1, im_input.shape[0], im_input.shape[1])\n\n            if cuda:\n                model = model.cuda()\n                im_input = im_input.cuda()\n            else:\n                model = model.cpu()\n\n            start_time = time.time()\n            HR = model(im_input)\n            elapsed_time = time.time() - start_time\n            avg_elapsed_time += elapsed_time\n\n            HR = HR.cpu()\n\n            im_h_y = HR.data[0].numpy().astype(np.float32)\n\n            im_h_y = im_h_y * 255.\n            im_h_y[im_h_y < 0] = 0\n            im_h_y[im_h_y > 255.] = 255.\n            im_h_y = im_h_y[0,:,:]\n\n            psnr_predicted = PSNR(im_gt_y, im_h_y,shave_border=scale)\n            avg_psnr_predicted += psnr_predicted\n\n    print(""Scale="", scale)\n    print(""Dataset="", opt.dataset)\n    print(""PSNR_predicted="", avg_psnr_predicted/count)\n    print(""PSNR_bicubic="", avg_psnr_bicubic/count)\n    print(""It takes average {}s for processing"".format(avg_elapsed_time/count))\n'"
main_vdsr.py,11,"b'import argparse, os\r\nimport torch\r\nimport random\r\nimport torch.backends.cudnn as cudnn\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\nfrom torch.autograd import Variable\r\nfrom torch.utils.data import DataLoader\r\nfrom vdsr import Net\r\nfrom dataset import DatasetFromHdf5\r\n\r\n# Training settings\r\nparser = argparse.ArgumentParser(description=""PyTorch VDSR"")\r\nparser.add_argument(""--batchSize"", type=int, default=128, help=""Training batch size"")\r\nparser.add_argument(""--nEpochs"", type=int, default=50, help=""Number of epochs to train for"")\r\nparser.add_argument(""--lr"", type=float, default=0.1, help=""Learning Rate. Default=0.1"")\r\nparser.add_argument(""--step"", type=int, default=10, help=""Sets the learning rate to the initial LR decayed by momentum every n epochs, Default: n=10"")\r\nparser.add_argument(""--cuda"", action=""store_true"", help=""Use cuda?"")\r\nparser.add_argument(""--resume"", default="""", type=str, help=""Path to checkpoint (default: none)"")\r\nparser.add_argument(""--start-epoch"", default=1, type=int, help=""Manual epoch number (useful on restarts)"")\r\nparser.add_argument(""--clip"", type=float, default=0.4, help=""Clipping Gradients. Default=0.4"")\r\nparser.add_argument(""--threads"", type=int, default=1, help=""Number of threads for data loader to use, Default: 1"")\r\nparser.add_argument(""--momentum"", default=0.9, type=float, help=""Momentum, Default: 0.9"")\r\nparser.add_argument(""--weight-decay"", ""--wd"", default=1e-4, type=float, help=""Weight decay, Default: 1e-4"")\r\nparser.add_argument(\'--pretrained\', default=\'\', type=str, help=\'path to pretrained model (default: none)\')\r\nparser.add_argument(""--gpus"", default=""0"", type=str, help=""gpu ids (default: 0)"")\r\n\r\ndef main():\r\n    global opt, model\r\n    opt = parser.parse_args()\r\n    print(opt)\r\n\r\n    cuda = opt.cuda\r\n    if cuda:\r\n        print(""=> use gpu id: \'{}\'"".format(opt.gpus))\r\n        os.environ[""CUDA_VISIBLE_DEVICES""] = opt.gpus\r\n        if not torch.cuda.is_available():\r\n                raise Exception(""No GPU found or Wrong gpu id, please run without --cuda"")\r\n\r\n    opt.seed = random.randint(1, 10000)\r\n    print(""Random Seed: "", opt.seed)\r\n    torch.manual_seed(opt.seed)\r\n    if cuda:\r\n        torch.cuda.manual_seed(opt.seed)\r\n\r\n    cudnn.benchmark = True\r\n\r\n    print(""===> Loading datasets"")\r\n    train_set = DatasetFromHdf5(""data/train.h5"")\r\n    training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)\r\n\r\n    print(""===> Building model"")\r\n    model = Net()\r\n    criterion = nn.MSELoss(size_average=False)\r\n\r\n    print(""===> Setting GPU"")\r\n    if cuda:\r\n        model = model.cuda()\r\n        criterion = criterion.cuda()\r\n\r\n    # optionally resume from a checkpoint\r\n    if opt.resume:\r\n        if os.path.isfile(opt.resume):\r\n            print(""=> loading checkpoint \'{}\'"".format(opt.resume))\r\n            checkpoint = torch.load(opt.resume)\r\n            opt.start_epoch = checkpoint[""epoch""] + 1\r\n            model.load_state_dict(checkpoint[""model""].state_dict())\r\n        else:\r\n            print(""=> no checkpoint found at \'{}\'"".format(opt.resume))\r\n\r\n    # optionally copy weights from a checkpoint\r\n    if opt.pretrained:\r\n        if os.path.isfile(opt.pretrained):\r\n            print(""=> loading model \'{}\'"".format(opt.pretrained))\r\n            weights = torch.load(opt.pretrained)\r\n            model.load_state_dict(weights[\'model\'].state_dict())\r\n        else:\r\n            print(""=> no model found at \'{}\'"".format(opt.pretrained))  \r\n\r\n    print(""===> Setting Optimizer"")\r\n    optimizer = optim.SGD(model.parameters(), lr=opt.lr, momentum=opt.momentum, weight_decay=opt.weight_decay)\r\n\r\n    print(""===> Training"")\r\n    for epoch in range(opt.start_epoch, opt.nEpochs + 1):\r\n        train(training_data_loader, optimizer, model, criterion, epoch)\r\n        save_checkpoint(model, epoch)\r\n\r\ndef adjust_learning_rate(optimizer, epoch):\r\n    """"""Sets the learning rate to the initial LR decayed by 10 every 10 epochs""""""\r\n    lr = opt.lr * (0.1 ** (epoch // opt.step))\r\n    return lr\r\n\r\ndef train(training_data_loader, optimizer, model, criterion, epoch):\r\n    lr = adjust_learning_rate(optimizer, epoch-1)\r\n\r\n    for param_group in optimizer.param_groups:\r\n        param_group[""lr""] = lr\r\n\r\n    print(""Epoch = {}, lr = {}"".format(epoch, optimizer.param_groups[0][""lr""]))\r\n\r\n    model.train()\r\n\r\n    for iteration, batch in enumerate(training_data_loader, 1):\r\n        input, target = Variable(batch[0]), Variable(batch[1], requires_grad=False)\r\n\r\n        if opt.cuda:\r\n            input = input.cuda()\r\n            target = target.cuda()\r\n\r\n        loss = criterion(model(input), target)\r\n        optimizer.zero_grad()\r\n        loss.backward() \r\n        nn.utils.clip_grad_norm(model.parameters(),opt.clip) \r\n        optimizer.step()\r\n\r\n        if iteration%100 == 0:\r\n            print(""===> Epoch[{}]({}/{}): Loss: {:.10f}"".format(epoch, iteration, len(training_data_loader), loss.data[0]))\r\n\r\ndef save_checkpoint(model, epoch):\r\n    model_out_path = ""checkpoint/"" + ""model_epoch_{}.pth"".format(epoch)\r\n    state = {""epoch"": epoch ,""model"": model}\r\n    if not os.path.exists(""checkpoint/""):\r\n        os.makedirs(""checkpoint/"")\r\n\r\n    torch.save(state, model_out_path)\r\n\r\n    print(""Checkpoint saved to {}"".format(model_out_path))\r\n\r\nif __name__ == ""__main__"":\r\n    main()'"
vdsr.py,2,"b'import torch\r\nimport torch.nn as nn\r\nfrom math import sqrt\r\n\r\nclass Conv_ReLU_Block(nn.Module):\r\n    def __init__(self):\r\n        super(Conv_ReLU_Block, self).__init__()\r\n        self.conv = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.relu = nn.ReLU(inplace=True)\r\n        \r\n    def forward(self, x):\r\n        return self.relu(self.conv(x))\r\n        \r\nclass Net(nn.Module):\r\n    def __init__(self):\r\n        super(Net, self).__init__()\r\n        self.residual_layer = self.make_layer(Conv_ReLU_Block, 18)\r\n        self.input = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.output = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\r\n        self.relu = nn.ReLU(inplace=True)\r\n    \r\n        for m in self.modules():\r\n            if isinstance(m, nn.Conv2d):\r\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\r\n                m.weight.data.normal_(0, sqrt(2. / n))\r\n                \r\n    def make_layer(self, block, num_of_layer):\r\n        layers = []\r\n        for _ in range(num_of_layer):\r\n            layers.append(block())\r\n        return nn.Sequential(*layers)\r\n\r\n    def forward(self, x):\r\n        residual = x\r\n        out = self.relu(self.input(x))\r\n        out = self.residual_layer(out)\r\n        out = self.output(out)\r\n        out = torch.add(out,residual)\r\n        return out\r\n '"
