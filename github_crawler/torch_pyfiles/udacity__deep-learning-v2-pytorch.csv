file_path,api_count,code
cycle-gan/helpers.py,6,"b'# helper functions for saving sample data and models\n\n# import data loading libraries\nimport os\nimport pdb\nimport pickle\nimport argparse\n\nimport warnings\nwarnings.filterwarnings(""ignore"")\n\n# import torch\nimport torch\n\n\n# numpy & scipy imports\nimport numpy as np\nimport scipy\nimport scipy.misc\n\n\ndef checkpoint(iteration, G_XtoY, G_YtoX, D_X, D_Y, checkpoint_dir=\'checkpoints_cyclegan\'):\n    """"""Saves the parameters of both generators G_YtoX, G_XtoY and discriminators D_X, D_Y.\n        """"""\n    G_XtoY_path = os.path.join(checkpoint_dir, \'G_XtoY.pkl\')\n    G_YtoX_path = os.path.join(checkpoint_dir, \'G_YtoX.pkl\')\n    D_X_path = os.path.join(checkpoint_dir, \'D_X.pkl\')\n    D_Y_path = os.path.join(checkpoint_dir, \'D_Y.pkl\')\n    torch.save(G_XtoY.state_dict(), G_XtoY_path)\n    torch.save(G_YtoX.state_dict(), G_YtoX_path)\n    torch.save(D_X.state_dict(), D_X_path)\n    torch.save(D_Y.state_dict(), D_Y_path)\n\n\ndef merge_images(sources, targets, batch_size=16):\n    """"""Creates a grid consisting of pairs of columns, where the first column in\n        each pair contains images source images and the second column in each pair\n        contains images generated by the CycleGAN from the corresponding images in\n        the first column.\n        """"""\n    _, _, h, w = sources.shape\n    row = int(np.sqrt(batch_size))\n    merged = np.zeros([3, row*h, row*w*2])\n    for idx, (s, t) in enumerate(zip(sources, targets)):\n        i = idx // row\n        j = idx % row\n        merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n        merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n    merged = merged.transpose(1, 2, 0)\n    return merged\n    \n\ndef to_data(x):\n    """"""Converts variable to numpy.""""""\n    if torch.cuda.is_available():\n        x = x.cpu()\n    x = x.data.numpy()\n    x = ((x +1)*255 / (2)).astype(np.uint8) # rescale to 0-255\n    return x\n\ndef save_samples(iteration, fixed_Y, fixed_X, G_YtoX, G_XtoY, batch_size=16, sample_dir=\'samples_cyclegan\'):\n    """"""Saves samples from both generators X->Y and Y->X.\n        """"""\n    # move input data to correct device\n    device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")\n\n    fake_X = G_YtoX(fixed_Y.to(device))\n    fake_Y = G_XtoY(fixed_X.to(device))\n    \n    X, fake_X = to_data(fixed_X), to_data(fake_X)\n    Y, fake_Y = to_data(fixed_Y), to_data(fake_Y)\n    \n    merged = merge_images(X, fake_Y, batch_size)\n    path = os.path.join(sample_dir, \'sample-{:06d}-X-Y.png\'.format(iteration))\n    scipy.misc.imsave(path, merged)\n    print(\'Saved {}\'.format(path))\n    \n    merged = merge_images(Y, fake_X, batch_size)\n    path = os.path.join(sample_dir, \'sample-{:06d}-Y-X.png\'.format(iteration))\n    scipy.misc.imsave(path, merged)\n    print(\'Saved {}\'.format(path))\n'"
intro-to-pytorch/fc_model.py,4,"b'import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass Network(nn.Module):\n    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n        \'\'\' Builds a feedforward network with arbitrary hidden layers.\n        \n            Arguments\n            ---------\n            input_size: integer, size of the input layer\n            output_size: integer, size of the output layer\n            hidden_layers: list of integers, the sizes of the hidden layers\n        \n        \'\'\'\n        super().__init__()\n        # Input to a hidden layer\n        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n        \n        # Add a variable number of more hidden layers\n        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n        \n        self.output = nn.Linear(hidden_layers[-1], output_size)\n        \n        self.dropout = nn.Dropout(p=drop_p)\n        \n    def forward(self, x):\n        \'\'\' Forward pass through the network, returns the output logits \'\'\'\n        \n        for each in self.hidden_layers:\n            x = F.relu(each(x))\n            x = self.dropout(x)\n        x = self.output(x)\n        \n        return F.log_softmax(x, dim=1)\n\n\ndef validation(model, testloader, criterion):\n    accuracy = 0\n    test_loss = 0\n    for images, labels in testloader:\n\n        images = images.resize_(images.size()[0], 784)\n\n        output = model.forward(images)\n        test_loss += criterion(output, labels).item()\n\n        ## Calculating the accuracy \n        # Model\'s output is log-softmax, take exponential to get the probabilities\n        ps = torch.exp(output)\n        # Class with highest probability is our predicted class, compare with true label\n        equality = (labels.data == ps.max(1)[1])\n        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n        accuracy += equality.type_as(torch.FloatTensor()).mean()\n\n    return test_loss, accuracy\n\n\ndef train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n    \n    steps = 0\n    running_loss = 0\n    for e in range(epochs):\n        # Model in training mode, dropout is on\n        model.train()\n        for images, labels in trainloader:\n            steps += 1\n            \n            # Flatten images into a 784 long vector\n            images.resize_(images.size()[0], 784)\n            \n            optimizer.zero_grad()\n            \n            output = model.forward(images)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n\n            if steps % print_every == 0:\n                # Model in inference mode, dropout is off\n                model.eval()\n                \n                # Turn off gradients for validation, will speed up inference\n                with torch.no_grad():\n                    test_loss, accuracy = validation(model, testloader, criterion)\n                \n                print(""Epoch: {}/{}.. "".format(e+1, epochs),\n                      ""Training Loss: {:.3f}.. "".format(running_loss/print_every),\n                      ""Test Loss: {:.3f}.. "".format(test_loss/len(testloader)),\n                      ""Test Accuracy: {:.3f}"".format(accuracy/len(testloader)))\n                \n                running_loss = 0\n                \n                # Make sure dropout and grads are on for training\n                model.train()\n'"
intro-to-pytorch/helper.py,1,"b'import matplotlib.pyplot as plt\r\nimport numpy as np\r\nfrom torch import nn, optim\r\nfrom torch.autograd import Variable\r\n\r\n\r\ndef test_network(net, trainloader):\r\n\r\n    criterion = nn.MSELoss()\r\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\r\n\r\n    dataiter = iter(trainloader)\r\n    images, labels = dataiter.next()\r\n\r\n    # Create Variables for the inputs and targets\r\n    inputs = Variable(images)\r\n    targets = Variable(images)\r\n\r\n    # Clear the gradients from all Variables\r\n    optimizer.zero_grad()\r\n\r\n    # Forward pass, then backward pass, then update weights\r\n    output = net.forward(inputs)\r\n    loss = criterion(output, targets)\r\n    loss.backward()\r\n    optimizer.step()\r\n\r\n    return True\r\n\r\n\r\ndef imshow(image, ax=None, title=None, normalize=True):\r\n    """"""Imshow for Tensor.""""""\r\n    if ax is None:\r\n        fig, ax = plt.subplots()\r\n    image = image.numpy().transpose((1, 2, 0))\r\n\r\n    if normalize:\r\n        mean = np.array([0.485, 0.456, 0.406])\r\n        std = np.array([0.229, 0.224, 0.225])\r\n        image = std * image + mean\r\n        image = np.clip(image, 0, 1)\r\n\r\n    ax.imshow(image)\r\n    ax.spines[\'top\'].set_visible(False)\r\n    ax.spines[\'right\'].set_visible(False)\r\n    ax.spines[\'left\'].set_visible(False)\r\n    ax.spines[\'bottom\'].set_visible(False)\r\n    ax.tick_params(axis=\'both\', length=0)\r\n    ax.set_xticklabels(\'\')\r\n    ax.set_yticklabels(\'\')\r\n\r\n    return ax\r\n\r\n\r\ndef view_recon(img, recon):\r\n    \'\'\' Function for displaying an image (as a PyTorch Tensor) and its\r\n        reconstruction also a PyTorch Tensor\r\n    \'\'\'\r\n\r\n    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\r\n    axes[0].imshow(img.numpy().squeeze())\r\n    axes[1].imshow(recon.data.numpy().squeeze())\r\n    for ax in axes:\r\n        ax.axis(\'off\')\r\n        ax.set_adjustable(\'box-forced\')\r\n\r\ndef view_classify(img, ps, version=""MNIST""):\r\n    \'\'\' Function for viewing an image and it\'s predicted classes.\r\n    \'\'\'\r\n    ps = ps.data.numpy().squeeze()\r\n\r\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\r\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\r\n    ax1.axis(\'off\')\r\n    ax2.barh(np.arange(10), ps)\r\n    ax2.set_aspect(0.1)\r\n    ax2.set_yticks(np.arange(10))\r\n    if version == ""MNIST"":\r\n        ax2.set_yticklabels(np.arange(10))\r\n    elif version == ""Fashion"":\r\n        ax2.set_yticklabels([\'T-shirt/top\',\r\n                            \'Trouser\',\r\n                            \'Pullover\',\r\n                            \'Dress\',\r\n                            \'Coat\',\r\n                            \'Sandal\',\r\n                            \'Shirt\',\r\n                            \'Sneaker\',\r\n                            \'Bag\',\r\n                            \'Ankle Boot\'], size=\'small\');\r\n    ax2.set_title(\'Class Probability\')\r\n    ax2.set_xlim(0, 1.1)\r\n\r\n    plt.tight_layout()\r\n'"
project-bikesharing/my_answers.py,0,"b""import numpy as np\n\n\nclass NeuralNetwork(object):\n    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n        # Set number of nodes in input, hidden and output layers.\n        self.input_nodes = input_nodes\n        self.hidden_nodes = hidden_nodes\n        self.output_nodes = output_nodes\n\n        # Initialize weights\n        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n                                       (self.input_nodes, self.hidden_nodes))\n\n        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5, \n                                       (self.hidden_nodes, self.output_nodes))\n        self.lr = learning_rate\n        \n        #### TODO: Set self.activation_function to your implemented sigmoid function ####\n        #\n        # Note: in Python, you can define a function with a lambda expression,\n        # as shown below.\n        self.activation_function = lambda x : 0  # Replace 0 with your sigmoid calculation.\n        \n        ### If the lambda code above is not something you're familiar with,\n        # You can uncomment out the following three lines and put your \n        # implementation there instead.\n        #\n        #def sigmoid(x):\n        #    return 0  # Replace 0 with your sigmoid calculation here\n        #self.activation_function = sigmoid\n                    \n\n    def train(self, features, targets):\n        ''' Train the network on batch of features and targets. \n        \n            Arguments\n            ---------\n            \n            features: 2D array, each row is one data record, each column is a feature\n            targets: 1D array of target values\n        \n        '''\n        n_records = features.shape[0]\n        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n        for X, y in zip(features, targets):\n            \n            final_outputs, hidden_outputs = self.forward_pass_train(X)  # Implement the forward pass function below\n            # Implement the backproagation function below\n            delta_weights_i_h, delta_weights_h_o = self.backpropagation(final_outputs, hidden_outputs, X, y, \n                                                                        delta_weights_i_h, delta_weights_h_o)\n        self.update_weights(delta_weights_i_h, delta_weights_h_o, n_records)\n\n\n    def forward_pass_train(self, X):\n        ''' Implement forward pass here \n         \n            Arguments\n            ---------\n            X: features batch\n\n        '''\n        #### Implement the forward pass here ####\n        ### Forward pass ###\n        # TODO: Hidden layer - Replace these values with your calculations.\n        hidden_inputs = None # signals into hidden layer\n        hidden_outputs = None # signals from hidden layer\n\n        # TODO: Output layer - Replace these values with your calculations.\n        final_inputs = None # signals into final output layer\n        final_outputs = None # signals from final output layer\n        \n        return final_outputs, hidden_outputs\n\n    def backpropagation(self, final_outputs, hidden_outputs, X, y, delta_weights_i_h, delta_weights_h_o):\n        ''' Implement backpropagation\n         \n            Arguments\n            ---------\n            final_outputs: output from forward pass\n            y: target (i.e. label) batch\n            delta_weights_i_h: change in weights from input to hidden layers\n            delta_weights_h_o: change in weights from hidden to output layers\n\n        '''\n        #### Implement the backward pass here ####\n        ### Backward pass ###\n\n        # TODO: Output error - Replace this value with your calculations.\n        error = None # Output layer error is the difference between desired target and actual output.\n        \n        # TODO: Calculate the hidden layer's contribution to the error\n        hidden_error = None\n        \n        # TODO: Backpropagated error terms - Replace these values with your calculations.\n        output_error_term = None\n        \n        hidden_error_term = None\n        \n        # Weight step (input to hidden)\n        delta_weights_i_h += None\n        # Weight step (hidden to output)\n        delta_weights_h_o += None\n        return delta_weights_i_h, delta_weights_h_o\n\n    def update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n        ''' Update weights on gradient descent step\n         \n            Arguments\n            ---------\n            delta_weights_i_h: change in weights from input to hidden layers\n            delta_weights_h_o: change in weights from hidden to output layers\n            n_records: number of records\n\n        '''\n        self.weights_hidden_to_output += None # update hidden-to-output weights with gradient descent step\n        self.weights_input_to_hidden += None # update input-to-hidden weights with gradient descent step\n\n    def run(self, features):\n        ''' Run a forward pass through the network with input features \n        \n            Arguments\n            ---------\n            features: 1D array of feature values\n        '''\n        \n        #### Implement the forward pass here ####\n        # TODO: Hidden layer - replace these values with the appropriate calculations.\n        hidden_inputs = None # signals into hidden layer\n        hidden_outputs = None # signals from hidden layer\n        \n        # TODO: Output layer - Replace these values with the appropriate calculations.\n        final_inputs = None # signals into final output layer\n        final_outputs = None # signals from final output layer \n        \n        return final_outputs\n\n\n#########################################################\n# Set your hyperparameters here\n##########################################################\niterations = 100\nlearning_rate = 0.1\nhidden_nodes = 2\noutput_nodes = 1\n"""
project-face-generation/problem_unittests.py,6,"b""from unittest.mock import MagicMock, patch\nimport numpy as np\nimport torch\n\n\ndef _print_success_message():\n    print('Tests Passed')\n\n\nclass AssertTest(object):\n    def __init__(self, params):\n        self.assert_param_message = '\\n'.join([str(k) + ': ' + str(v) + '' for k, v in params.items()])\n\n    def test(self, assert_condition, assert_message):\n        assert assert_condition, assert_message + '\\n\\nUnit Test Function Parameters\\n' + self.assert_param_message\n        \n\ndef test_discriminator(Discriminator):\n    batch_size = 50\n    conv_dim=10\n    D = Discriminator(conv_dim)\n\n    # create random image input\n    x = torch.from_numpy(np.random.randint(1, size=(batch_size, 3, 32, 32))*2 -1).float()\n    \n    train_on_gpu = torch.cuda.is_available()\n    if train_on_gpu:\n        x.cuda()\n\n    output = D(x)\n    assert_test = AssertTest({\n        'Conv Dim': conv_dim,\n        'Batch Size': batch_size,\n        'Input': x})\n\n    correct_output_size = (batch_size, 1)\n    assert_condition = output.size() == correct_output_size\n    assert_message = 'Wrong output size. Expected type {}. Got type {}'.format(correct_output_size, output.size())\n    assert_test.test(assert_condition, assert_message)\n\n    _print_success_message()\n    \ndef test_generator(Generator):\n    batch_size = 50\n    z_size = 25\n    conv_dim=10\n    G = Generator(z_size, conv_dim)\n\n    # create random input\n    z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n    z = torch.from_numpy(z).float()\n    \n    train_on_gpu = torch.cuda.is_available()\n    if train_on_gpu:\n        z.cuda()\n    #b = torch.LongTensor(a)\n    #nn_input = torch.autograd.Variable(b)\n\n    output = G(z)\n    assert_test = AssertTest({\n        'Z size': z_size,\n        'Conv Dim': conv_dim,\n        'Batch Size': batch_size,\n        'Input': z})\n\n    correct_output_size = (batch_size, 3, 32, 32)\n    assert_condition = output.size() == correct_output_size\n    assert_message = 'Wrong output size. Expected type {}. Got type {}'.format(correct_output_size, output.size())\n    assert_test.test(assert_condition, assert_message)\n\n    _print_success_message()\n"""
project-tv-script-generation/helper.py,2,"b'import os\nimport pickle\nimport torch\n\n\nSPECIAL_WORDS = {\'PADDING\': \'<PAD>\'}\n\n\ndef load_data(path):\n    """"""\n    Load Dataset from File\n    """"""\n    input_file = os.path.join(path)\n    with open(input_file, ""r"") as f:\n        data = f.read()\n\n    return data\n\n\ndef preprocess_and_save_data(dataset_path, token_lookup, create_lookup_tables):\n    """"""\n    Preprocess Text Data\n    """"""\n    text = load_data(dataset_path)\n    \n    # Ignore notice, since we don\'t use it for analysing the data\n    text = text[81:]\n\n    token_dict = token_lookup()\n    for key, token in token_dict.items():\n        text = text.replace(key, \' {} \'.format(token))\n\n    text = text.lower()\n    text = text.split()\n\n    vocab_to_int, int_to_vocab = create_lookup_tables(text + list(SPECIAL_WORDS.values()))\n    int_text = [vocab_to_int[word] for word in text]\n    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), open(\'preprocess.p\', \'wb\'))\n\n\ndef load_preprocess():\n    """"""\n    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n    """"""\n    return pickle.load(open(\'preprocess.p\', mode=\'rb\'))\n\n\ndef save_model(filename, decoder):\n    save_filename = os.path.splitext(os.path.basename(filename))[0] + \'.pt\'\n    torch.save(decoder, save_filename)\n\n\ndef load_model(filename):\n    save_filename = os.path.splitext(os.path.basename(filename))[0] + \'.pt\'\n    return torch.load(save_filename)\n'"
project-tv-script-generation/problem_unittests.py,9,"b'from unittest.mock import MagicMock, patch\nimport numpy as np\nimport torch\n\n\nclass _TestNN(torch.nn.Module):\n    def __init__(self, input_size, output_size):\n        super(_TestNN, self).__init__()\n        self.decoder = torch.nn.Linear(input_size, output_size)\n        self.forward_called = False\n    \n    def forward(self, nn_input, hidden):\n        self.forward_called = True\n        output = self.decoder(nn_input)\n        \n        return output, hidden\n\n\ndef _print_success_message():\n    print(\'Tests Passed\')\n\n\nclass AssertTest(object):\n    def __init__(self, params):\n        self.assert_param_message = \'\\n\'.join([str(k) + \': \' + str(v) + \'\' for k, v in params.items()])\n    \n    def test(self, assert_condition, assert_message):\n        assert assert_condition, assert_message + \'\\n\\nUnit Test Function Parameters\\n\' + self.assert_param_message\n\n\ndef test_create_lookup_tables(create_lookup_tables):\n    test_text = \'\'\'\n        Moe_Szyslak Moe\'s Tavern Where the elite meet to drink\n        Bart_Simpson Eh yeah hello is Mike there Last name Rotch\n        Moe_Szyslak Hold on I\'ll check Mike Rotch Mike Rotch Hey has anybody seen Mike Rotch lately\n        Moe_Szyslak Listen you little puke One of these days I\'m gonna catch you and I\'m gonna carve my name on your back with an ice pick\n        Moe_Szyslak Whats the matter Homer You\'re not your normal effervescent self\n        Homer_Simpson I got my problems Moe Give me another one\n        Moe_Szyslak Homer hey you should not drink to forget your problems\n        Barney_Gumble Yeah you should only drink to enhance your social skills\'\'\'\n    \n    test_text = test_text.lower()\n    test_text = test_text.split()\n    \n    vocab_to_int, int_to_vocab = create_lookup_tables(test_text)\n    \n    # Check types\n    assert isinstance(vocab_to_int, dict),\\\n        \'vocab_to_int is not a dictionary.\'\n    assert isinstance(int_to_vocab, dict),\\\n        \'int_to_vocab is not a dictionary.\'\n    \n    # Compare lengths of dicts\n    assert len(vocab_to_int) == len(int_to_vocab),\\\n        \'Length of vocab_to_int and int_to_vocab don\\\'t match. \' \\\n        \'vocab_to_int is length {}. int_to_vocab is length {}\'.format(len(vocab_to_int), len(int_to_vocab))\n\n    # Make sure the dicts have the same words\n    vocab_to_int_word_set = set(vocab_to_int.keys())\n    int_to_vocab_word_set = set(int_to_vocab.values())\n\n    assert not (vocab_to_int_word_set - int_to_vocab_word_set),\\\n    \'vocab_to_int and int_to_vocab don\\\'t have the same words.\' \\\n        \'{} found in vocab_to_int, but not in int_to_vocab\'.format(vocab_to_int_word_set - int_to_vocab_word_set)\n    assert not (int_to_vocab_word_set - vocab_to_int_word_set),\\\n        \'vocab_to_int and int_to_vocab don\\\'t have the same words.\' \\\n        \'{} found in int_to_vocab, but not in vocab_to_int\'.format(int_to_vocab_word_set - vocab_to_int_word_set)\n    \n    # Make sure the dicts have the same word ids\n    vocab_to_int_word_id_set = set(vocab_to_int.values())\n    int_to_vocab_word_id_set = set(int_to_vocab.keys())\n    \n    assert not (vocab_to_int_word_id_set - int_to_vocab_word_id_set),\\\n        \'vocab_to_int and int_to_vocab don\\\'t contain the same word ids.\' \\\n        \'{} found in vocab_to_int, but not in int_to_vocab\'.format(vocab_to_int_word_id_set - int_to_vocab_word_id_set)\n    assert not (int_to_vocab_word_id_set - vocab_to_int_word_id_set),\\\n        \'vocab_to_int and int_to_vocab don\\\'t contain the same word ids.\' \\\n        \'{} found in int_to_vocab, but not in vocab_to_int\'.format(int_to_vocab_word_id_set - vocab_to_int_word_id_set)\n    \n    # Make sure the dicts make the same lookup\n    missmatches = [(word, id, id, int_to_vocab[id]) for word, id in vocab_to_int.items() if int_to_vocab[id] != word]\n    \n    assert not missmatches,\\\n        \'Found {} missmatche(s). First missmatch: vocab_to_int[{}] = {} and int_to_vocab[{}] = {}\'.format(len(missmatches),\n                                                                                                          *missmatches[0])\n    \n    assert len(vocab_to_int) > len(set(test_text))/2,\\\n        \'The length of vocab seems too small.  Found a length of {}\'.format(len(vocab_to_int))\n    \n    _print_success_message()\n\n\ndef test_tokenize(token_lookup):\n    symbols = set([\'.\', \',\', \'""\', \';\', \'!\', \'?\', \'(\', \')\', \'-\', \'\\n\'])\n    token_dict = token_lookup()\n    \n    # Check type\n    assert isinstance(token_dict, dict), \\\n        \'Returned type is {}.\'.format(type(token_dict))\n\n    # Check symbols\n    missing_symbols = symbols - set(token_dict.keys())\n    unknown_symbols = set(token_dict.keys()) - symbols\n\n    assert not missing_symbols, \\\n    \'Missing symbols: {}\'.format(missing_symbols)\n    assert not unknown_symbols, \\\n        \'Unknown symbols: {}\'.format(unknown_symbols)\n\n    # Check values type\n    bad_value_type = [type(val) for val in token_dict.values() if not isinstance(val, str)]\n    \n    assert not bad_value_type,\\\n        \'Found token as {} type.\'.format(bad_value_type[0])\n\n    # Check for spaces\n    key_has_spaces = [k for k in token_dict.keys() if \' \' in k]\n    val_has_spaces = [val for val in token_dict.values() if \' \' in val]\n    \n    assert not key_has_spaces,\\\n        \'The key ""{}"" includes spaces. Remove spaces from keys and values\'.format(key_has_spaces[0])\n    assert not val_has_spaces,\\\n    \'The value ""{}"" includes spaces. Remove spaces from keys and values\'.format(val_has_spaces[0])\n    \n    # Check for symbols in values\n    symbol_val = ()\n    for symbol in symbols:\n        for val in token_dict.values():\n            if symbol in val:\n                symbol_val = (symbol, val)\n\n    assert not symbol_val,\\\n    \'Don\\\'t use a symbol that will be replaced in your tokens. Found the symbol {} in value {}\'.format(*symbol_val)\n    \n    _print_success_message()\n\n\ndef test_rnn(RNN, train_on_gpu):\n    batch_size = 50\n    sequence_length = 3\n    vocab_size = 20\n    output_size=20\n    embedding_dim=15\n    hidden_dim = 10\n    n_layers = 2\n    \n    # create test RNN\n    # params: (vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n    rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n    \n    # create test input\n    a = np.random.randint(vocab_size, size=(batch_size, sequence_length))\n    #b = torch.LongTensor(a)\n    b = torch.from_numpy(a)\n    hidden = rnn.init_hidden(batch_size)\n    \n    if(train_on_gpu):\n        rnn.cuda()\n        b = b.cuda()\n    \n    output, hidden_out = rnn(b, hidden)\n    \n    assert_test = AssertTest({\n                             \'Input Size\': vocab_size,\n                             \'Output Size\': output_size,\n                             \'Hidden Dim\': hidden_dim,\n                             \'N Layers\': n_layers,\n                             \'Batch Size\': batch_size,\n                             \'Sequence Length\': sequence_length,\n                             \'Input\': b})\n    \n    # initialization\n    correct_hidden_size = (n_layers, batch_size, hidden_dim)\n    \n    if type(hidden) == tuple:\n        # LSTM\n        assert_condition = hidden[0].size() == correct_hidden_size\n    else:\n        # GRU\n        assert_condition = hidden.size() == correct_hidden_size\n\n    assert_message = \'Wrong hidden state size. Expected type {}. Got type {}\'.format(correct_hidden_size, hidden[0].size())\n    assert_test.test(assert_condition, assert_message)\n    \n    # output of rnn\n    correct_hidden_size = (n_layers, batch_size, hidden_dim)\n    \n    if type(hidden) == tuple:\n        # LSTM        \n        assert_condition = hidden_out[0].size() == correct_hidden_size\n    else:\n        # GRU\n        assert_condition = hidden_out.size() == correct_hidden_size\n\n    assert_message = \'Wrong hidden state size. Expected type {}. Got type {}\'.format(correct_hidden_size, hidden_out[0].size())\n    assert_test.test(assert_condition, assert_message)\n    \n    correct_output_size = (batch_size, output_size)\n    assert_condition = output.size() == correct_output_size\n    assert_message = \'Wrong output size. Expected type {}. Got type {}\'.format(correct_output_size, output.size())\n    assert_test.test(assert_condition, assert_message)\n    \n    _print_success_message()\n\n\ndef test_forward_back_prop(RNN, forward_back_prop, train_on_gpu):\n    batch_size = 200\n    input_size = 20\n    output_size = 10\n    sequence_length = 3\n    embedding_dim=15\n    hidden_dim = 10\n    n_layers = 2\n    learning_rate = 0.01\n    \n    # create test RNN\n    rnn = RNN(input_size, output_size, embedding_dim, hidden_dim, n_layers)\n    \n    mock_decoder = MagicMock(wraps=_TestNN(input_size, output_size))\n    if train_on_gpu:\n        mock_decoder.cuda()\n    \n    mock_decoder_optimizer = MagicMock(wraps=torch.optim.Adam(mock_decoder.parameters(), lr=learning_rate))\n    mock_criterion = MagicMock(wraps=torch.nn.CrossEntropyLoss())\n    \n    with patch.object(torch.autograd, \'backward\', wraps=torch.autograd.backward) as mock_autograd_backward:\n        inp = torch.FloatTensor(np.random.rand(batch_size, input_size))\n        target = torch.LongTensor(np.random.randint(output_size, size=batch_size))\n        \n        hidden = rnn.init_hidden(batch_size)\n        \n        loss, hidden_out = forward_back_prop(mock_decoder, mock_decoder_optimizer, mock_criterion, inp, target, hidden)\n    \n    if type(hidden_out) == tuple:\n        # LSTM\n        assert (hidden_out[0][0]==hidden[0][0]).sum()==batch_size*hidden_dim, \'Returned hidden state is the incorrect size.\'\n    else:\n        # GRU\n        assert (hidden_out[0]==hidden[0]).sum()==batch_size*hidden_dim, \'Returned hidden state is the incorrect size.\'\n    \n    assert mock_decoder.zero_grad.called or mock_decoder_optimizer.zero_grad.called, \'Didn\\\'t set the gradients to 0.\'\n    assert mock_decoder.forward_called, \'Forward propagation not called.\'\n    assert mock_autograd_backward.called, \'Backward propagation not called\'\n    assert mock_decoder_optimizer.step.called, \'Optimization step not performed\'\n    assert type(loss) == float, \'Wrong return type. Expected {}, got {}\'.format(float, type(loss))\n    \n    _print_success_message()\n'"
weight-initialization/helpers.py,4,"b'import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim\n\n\ndef _get_loss_acc(model, train_loader, valid_loader):\n    """"""\n    Get losses and validation accuracy of example neural network\n    """"""\n    n_epochs = 2\n    learning_rate = 0.001\n    \n    # Training loss\n    criterion = nn.CrossEntropyLoss()\n\n    # Optimizer\n    optimizer = optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n\n    # Measurements used for graphing loss\n    loss_batch = []\n\n    for epoch in range(1, n_epochs+1):\n        # initialize var to monitor training loss\n        train_loss = 0.0\n        ###################\n        # train the model #\n        ###################\n        for data, target in train_loader:\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # record average batch loss \n            loss_batch.append(loss.item())\n             \n    # after training for 2 epochs, check validation accuracy \n    correct = 0\n    total = 0\n    for data, target in valid_loader:\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # get the predicted class from the maximum class score\n        _, predicted = torch.max(output.data, 1)\n        # count up total number of correct labels\n        # for which the predicted and true labels are equal\n        total += target.size(0)\n        correct += (predicted == target).sum()\n      \n    # calculate the accuracy\n    # to convert `correct` from a Tensor into a scalar, use .item()\n    valid_acc = correct.item() / total\n\n    # return model stats\n    return loss_batch, valid_acc\n\n\ndef compare_init_weights(\n        model_list,\n        plot_title,\n        train_loader,\n        valid_loader,\n        plot_n_batches=100):\n    """"""\n    Plot loss and print stats of weights using an example neural network\n    """"""\n    colors = [\'r\', \'b\', \'g\', \'c\', \'y\', \'k\']\n    label_accs = []\n    label_loss = []\n\n    assert len(model_list) <= len(colors), \'Too many initial weights to plot\'\n\n    for i, (model, label) in enumerate(model_list):\n        loss, val_acc = _get_loss_acc(model, train_loader, valid_loader)\n\n        plt.plot(loss[:plot_n_batches], colors[i], label=label)\n        label_accs.append((label, val_acc))\n        label_loss.append((label, loss[-1]))\n\n    plt.title(plot_title)\n    plt.xlabel(\'Batches\')\n    plt.ylabel(\'Loss\')\n    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    plt.show()\n\n    print(\'After 2 Epochs:\')\n    print(\'Validation Accuracy\')\n    for label, val_acc in label_accs:\n        print(\'  {:7.3f}% -- {}\'.format(val_acc*100, label))\n    print(\'Training Loss\')\n    for label, loss in label_loss:\n        print(\'  {:7.3f}  -- {}\'.format(loss, label))\n        \n\ndef hist_dist(title, distribution_tensor, hist_range=(-4, 4)):\n    """"""\n    Display histogram of values in a given distribution tensor\n    """"""\n    plt.title(title)\n    plt.hist(distribution_tensor, np.linspace(*hist_range, num=len(distribution_tensor)/2))\n    plt.show()'"
word2vec-embeddings/utils.py,0,"b'import re\nfrom collections import Counter\n\ndef preprocess(text):\n\n    # Replace punctuation with tokens so we can use them in our model\n    text = text.lower()\n    text = text.replace(\'.\', \' <PERIOD> \')\n    text = text.replace(\',\', \' <COMMA> \')\n    text = text.replace(\'""\', \' <QUOTATION_MARK> \')\n    text = text.replace(\';\', \' <SEMICOLON> \')\n    text = text.replace(\'!\', \' <EXCLAMATION_MARK> \')\n    text = text.replace(\'?\', \' <QUESTION_MARK> \')\n    text = text.replace(\'(\', \' <LEFT_PAREN> \')\n    text = text.replace(\')\', \' <RIGHT_PAREN> \')\n    text = text.replace(\'--\', \' <HYPHENS> \')\n    text = text.replace(\'?\', \' <QUESTION_MARK> \')\n    # text = text.replace(\'\\n\', \' <NEW_LINE> \')\n    text = text.replace(\':\', \' <COLON> \')\n    words = text.split()\n    \n    # Remove all words with  5 or fewer occurences\n    word_counts = Counter(words)\n    trimmed_words = [word for word in words if word_counts[word] > 5]\n\n    return trimmed_words\n\n\ndef create_lookup_tables(words):\n    """"""\n    Create lookup tables for vocabulary\n    :param words: Input list of words\n    :return: Two dictionaries, vocab_to_int, int_to_vocab\n    """"""\n    word_counts = Counter(words)\n    # sorting the words from most to least frequent in text occurrence\n    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n    # create int_to_vocab dictionaries\n    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n\n    return vocab_to_int, int_to_vocab\n\n'"
project-bikesharing/.udacity-pa/projects.py,0,"b""import argparse\nimport subprocess as sp\nfrom udacity_pa import udacity\n\nnanodegree = 'nd101'\nprojects = ['first_neural_network']\nfilenames = ['my_answers.py', 'Your_first_neural_network.ipynb']\n\ndef submit(args):\n\n  # Do we prefer ipynb, html or both?\n  # sp.call(['jupyter', 'nbconvert', '--to', 'html', 'dlnd_image_classification.ipynb'])\n\n  udacity.submit(nanodegree, projects[0], filenames, \n                 environment = args.environment,\n                 jwt_path = args.jwt_path)\n"""
