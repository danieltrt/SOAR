file_path,api_count,code
src/fast_gradient_sign_targeted.py,4,"b'""""""\nCreated on Fri Dec 16 01:24:11 2017\n\n@author: Utku Ozbulak - github.com/utkuozbulak\n""""""\nimport os\nimport numpy as np\nimport cv2\n\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\n# from torch.autograd.gradcheck import zero_gradients  # See processed_image.grad = None\n\nfrom misc_functions import preprocess_image, recreate_image, get_params\n\n\nclass FastGradientSignTargeted():\n    """"""\n        Fast gradient sign untargeted adversarial attack, maximizes the target class activation\n        with iterative grad sign updates\n    """"""\n    def __init__(self, model, alpha):\n        self.model = model\n        self.model.eval()\n        # Movement multiplier per iteration\n        self.alpha = alpha\n        # Create the folder to export images if not exists\n        if not os.path.exists(\'../generated\'):\n            os.makedirs(\'../generated\')\n\n    def generate(self, original_image, org_class, target_class):\n        # I honestly dont know a better way to create a variable with specific value\n        # Targeting the specific class\n        im_label_as_var = Variable(torch.from_numpy(np.asarray([target_class])))\n        # Define loss functions\n        ce_loss = nn.CrossEntropyLoss()\n        # Process image\n        processed_image = preprocess_image(original_image)\n        # Start iteration\n        for i in range(10):\n            print(\'Iteration:\', str(i))\n            # zero_gradients(x)\n            # Zero out previous gradients\n            # Can also use zero_gradients(x)\n            processed_image.grad = None\n            # Forward pass\n            out = self.model(processed_image)\n            # Calculate CE loss\n            pred_loss = ce_loss(out, im_label_as_var)\n            # Do backward pass\n            pred_loss.backward()\n            # Create Noise\n            # Here, processed_image.grad.data is also the same thing is the backward gradient from\n            # the first layer, can use that with hooks as well\n            adv_noise = self.alpha * torch.sign(processed_image.grad.data)\n            # Add noise to processed image\n            processed_image.data = processed_image.data - adv_noise\n\n            # Confirming if the image is indeed adversarial with added noise\n            # This is necessary (for some cases) because when we recreate image\n            # the values become integers between 1 and 255 and sometimes the adversariality\n            # is lost in the recreation process\n\n            # Generate confirmation image\n            recreated_image = recreate_image(processed_image)\n            # Process confirmation image\n            prep_confirmation_image = preprocess_image(recreated_image)\n            # Forward pass\n            confirmation_out = self.model(prep_confirmation_image)\n            # Get prediction\n            _, confirmation_prediction = confirmation_out.data.max(1)\n            # Get Probability\n            confirmation_confidence = \\\n                nn.functional.softmax(confirmation_out)[0][confirmation_prediction].data.numpy()[0]\n            # Convert tensor to int\n            confirmation_prediction = confirmation_prediction.numpy()[0]\n            # Check if the prediction is different than the original\n            if confirmation_prediction == target_class:\n                print(\'Original image was predicted as:\', org_class,\n                      \'with adversarial noise converted to:\', confirmation_prediction,\n                      \'and predicted with confidence of:\', confirmation_confidence)\n                # Create the image for noise as: Original image - generated image\n                noise_image = original_image - recreated_image\n                cv2.imwrite(\'../generated/targeted_adv_noise_from_\' + str(org_class) + \'_to_\' +\n                            str(confirmation_prediction) + \'.jpg\', noise_image)\n                # Write image\n                cv2.imwrite(\'../generated/targeted_adv_img_from_\' + str(org_class) + \'_to_\' +\n                            str(confirmation_prediction) + \'.jpg\', recreated_image)\n                break\n\n        return 1\n\n\nif __name__ == \'__main__\':\n    target_example = 0  # Apple\n    (original_image, prep_img, org_class, _, pretrained_model) =\\\n        get_params(target_example)\n    target_class = 62  # Mud turtle\n\n    FGS_untargeted = FastGradientSignTargeted(pretrained_model, 0.01)\n    FGS_untargeted.generate(original_image, org_class, target_class)\n'"
src/fast_gradient_sign_untargeted.py,4,"b'""""""\nCreated on Fri Dec 15 19:57:34 2017\n\n@author: Utku Ozbulak - github.com/utkuozbulak\n""""""\nimport os\nimport numpy as np\nimport cv2\n\nimport torch\nfrom torch import nn\nfrom torch.autograd import Variable\n# from torch.autograd.gradcheck import zero_gradients  # See processed_image.grad = None\n\nfrom misc_functions import preprocess_image, recreate_image, get_params\n\n\nclass FastGradientSignUntargeted():\n    """"""\n        Fast gradient sign untargeted adversarial attack, minimizes the initial class activation\n        with iterative grad sign updates\n    """"""\n    def __init__(self, model, alpha):\n        self.model = model\n        self.model.eval()\n        # Movement multiplier per iteration\n        self.alpha = alpha\n        # Create the folder to export images if not exists\n        if not os.path.exists(\'../generated\'):\n            os.makedirs(\'../generated\')\n\n    def generate(self, original_image, im_label):\n        # I honestly dont know a better way to create a variable with specific value\n        im_label_as_var = Variable(torch.from_numpy(np.asarray([im_label])))\n        # Define loss functions\n        ce_loss = nn.CrossEntropyLoss()\n        # Process image\n        processed_image = preprocess_image(original_image)\n        # Start iteration\n        for i in range(10):\n            print(\'Iteration:\', str(i))\n            # zero_gradients(x)\n            # Zero out previous gradients\n            # Can also use zero_gradients(x)\n            processed_image.grad = None\n            # Forward pass\n            out = self.model(processed_image)\n            # Calculate CE loss\n            pred_loss = ce_loss(out, im_label_as_var)\n            # Do backward pass\n            pred_loss.backward()\n            # Create Noise\n            # Here, processed_image.grad.data is also the same thing is the backward gradient from\n            # the first layer, can use that with hooks as well\n            adv_noise = self.alpha * torch.sign(processed_image.grad.data)\n            # Add Noise to processed image\n            processed_image.data = processed_image.data + adv_noise\n\n            # Confirming if the image is indeed adversarial with added noise\n            # This is necessary (for some cases) because when we recreate image\n            # the values become integers between 1 and 255 and sometimes the adversariality\n            # is lost in the recreation process\n\n            # Generate confirmation image\n            recreated_image = recreate_image(processed_image)\n            # Process confirmation image\n            prep_confirmation_image = preprocess_image(recreated_image)\n            # Forward pass\n            confirmation_out = self.model(prep_confirmation_image)\n            # Get prediction\n            _, confirmation_prediction = confirmation_out.data.max(1)\n            # Get Probability\n            confirmation_confidence = \\\n                nn.functional.softmax(confirmation_out)[0][confirmation_prediction].data.numpy()[0]\n            # Convert tensor to int\n            confirmation_prediction = confirmation_prediction.numpy()[0]\n            # Check if the prediction is different than the original\n            if confirmation_prediction != im_label:\n                print(\'Original image was predicted as:\', im_label,\n                      \'with adversarial noise converted to:\', confirmation_prediction,\n                      \'and predicted with confidence of:\', confirmation_confidence)\n                # Create the image for noise as: Original image - generated image\n                noise_image = original_image - recreated_image\n                cv2.imwrite(\'../generated/untargeted_adv_noise_from_\' + str(im_label) + \'_to_\' +\n                            str(confirmation_prediction) + \'.jpg\', noise_image)\n                # Write image\n                cv2.imwrite(\'../generated/untargeted_adv_img_from_\' + str(im_label) + \'_to_\' +\n                            str(confirmation_prediction) + \'.jpg\', recreated_image)\n                break\n\n        return 1\n\n\nif __name__ == \'__main__\':\n    target_example = 2  # Eel\n    (original_image, prep_img, target_class, _, pretrained_model) =\\\n        get_params(target_example)\n\n    FGS_untargeted = FastGradientSignUntargeted(pretrained_model, 0.01)\n    FGS_untargeted.generate(original_image, target_class)\n'"
src/gradient_ascent_adv.py,2,"b'""""""\nCreated on Thu Oct 29 14:09:01 2017\n\n@author: Utku Ozbulak - github.com/utkuozbulak\n""""""\nimport os\nimport cv2\n\nfrom torch.optim import SGD\nfrom torchvision import models\nfrom torch.nn import functional\n\nfrom misc_functions import preprocess_image, recreate_image, get_params\n\n\nclass DisguisedFoolingSampleGeneration():\n    """"""\n        Produces an image that maximizes a certain class with gradient ascent, breaks as soon as\n        the target prediction confidence is captured\n    """"""\n    def __init__(self, model, initial_image, target_class, minimum_confidence):\n        self.model = model\n        self.model.eval()\n        self.target_class = target_class\n        self.minimum_confidence = minimum_confidence\n        # Generate a random image\n        self.initial_image = initial_image\n        # Create the folder to export images if not exists\n        if not os.path.exists(\'../generated\'):\n            os.makedirs(\'../generated\')\n\n    def generate(self):\n        for i in range(1, 500):\n            # Process image and return variable\n            self.processed_image = preprocess_image(self.initial_image)\n            # Define optimizer for the image\n            optimizer = SGD([self.processed_image], lr=0.7)\n            # Forward\n            output = self.model(self.processed_image)\n            # Get confidence from softmax\n            target_confidence = functional.softmax(output)[0][self.target_class].data.numpy()[0]\n            if target_confidence > self.minimum_confidence:\n                # Reading the raw image and pushing it through model to see the prediction\n                # this is needed because the format of preprocessed image is float and when\n                # it is written back to file it is converted to uint8, so there is a chance that\n                # there are some losses while writing\n                confirmation_image = cv2.imread(\'../generated/ga_adv_class_\' +\n                                                str(self.target_class) + \'.jpg\', 1)\n                # Preprocess image\n                confirmation_processed_image = preprocess_image(confirmation_image)\n                # Get prediction\n                confirmation_output = self.model(confirmation_processed_image)\n                # Get confidence\n                softmax_confirmation = \\\n                    functional.softmax(confirmation_output)[0][self.target_class].data.numpy()[0]\n                if softmax_confirmation > self.minimum_confidence:\n                    print(\'Generated disguised fooling image with\', ""{0:.2f}"".format(softmax_confirmation),\n                          \'confidence at\', str(i) + \'th iteration.\')\n                    break\n            # Target specific class\n            class_loss = -output[0, self.target_class]\n            print(\'Iteration:\', str(i), \'Target confidence\', ""{0:.4f}"".format(target_confidence))\n            # Zero grads\n            self.model.zero_grad()\n            # Backward\n            class_loss.backward()\n            # Update image\n            optimizer.step()\n            # Recreate image\n            self.initial_image = recreate_image(self.processed_image)\n            # Save image\n            cv2.imwrite(\'../generated/ga_adv_class_\' + str(self.target_class) + \'.jpg\',\n                        self.initial_image)\n        return confirmation_image\n\n\nif __name__ == \'__main__\':\n    target_example = 0  # Appple\n    (original_image, prep_img, _, _, pretrained_model) =\\\n        get_params(target_example)\n\n    fooling_target_class = 398  # Abacus\n    min_confidence = 0.99\n    fool = DisguisedFoolingSampleGeneration(pretrained_model,\n                                            original_image,\n                                            fooling_target_class,\n                                            min_confidence)\n    generated_image = fool.generate()\n'"
src/gradient_ascent_fooling.py,2,"b'""""""\nCreated on Thu Oct 28 08:12:10 2017\n\n@author: Utku Ozbulak - github.com/utkuozbulak\n""""""\nimport os\nimport cv2\nimport numpy as np\n\nfrom torch.optim import SGD\nfrom torchvision import models\nfrom torch.nn import functional\n\nfrom misc_functions import preprocess_image, recreate_image\n\n\nclass FoolingSampleGeneration():\n    """"""\n        Produces an image that maximizes a certain class with gradient ascent, breaks as soon as\n        the target prediction confidence is captured\n    """"""\n    def __init__(self, model, target_class, minimum_confidence):\n        self.model = model\n        self.model.eval()\n        self.target_class = target_class\n        self.minimum_confidence = minimum_confidence\n        # Generate a random image\n        self.created_image = np.uint8(np.random.uniform(0, 255, (224, 224, 3)))\n        # Create the folder to export images if not exists\n        if not os.path.exists(\'../generated\'):\n            os.makedirs(\'../generated\')\n\n    def generate(self):\n        for i in range(1, 200):\n            # Process image and return variable\n            self.processed_image = preprocess_image(self.created_image)\n            # Define optimizer for the image\n            optimizer = SGD([self.processed_image], lr=6)\n            # Forward\n            output = self.model(self.processed_image)\n            # Get confidence from softmax\n            target_confidence = functional.softmax(output)[0][self.target_class].data.numpy()[0]\n            if target_confidence > self.minimum_confidence:\n                # Reading the raw image and pushing it through model to see the prediction\n                # this is needed because the format of preprocessed image is float and when\n                # it is written back to file it is converted to uint8, so there is a chance that\n                # there are some losses while writing\n                confirmation_image = cv2.imread(\'../generated/ga_fooling_class_\' +\n                                                str(self.target_class) + \'.jpg\', 1)\n                # Preprocess image\n                confirmation_processed_image = preprocess_image(confirmation_image)\n                # Get prediction\n                confirmation_output = self.model(confirmation_processed_image)\n                # Get confidence\n                softmax_confirmation = \\\n                    functional.softmax(confirmation_output)[0][self.target_class].data.numpy()[0]\n                if softmax_confirmation > self.minimum_confidence:\n                    print(\'Generated fooling image with\', ""{0:.2f}"".format(softmax_confirmation),\n                          \'confidence at\', str(i) + \'th iteration.\')\n                    break\n            # Target specific class\n            class_loss = -output[0, self.target_class]\n            print(\'Iteration:\', str(i), \'Target Confidence\', ""{0:.4f}"".format(target_confidence))\n            # Zero grads\n            self.model.zero_grad()\n            # Backward\n            class_loss.backward()\n            # Update image\n            optimizer.step()\n            # Recreate image\n            self.created_image = recreate_image(self.processed_image)\n            # Save image\n            cv2.imwrite(\'../generated/ga_fooling_class_\' + str(self.target_class) + \'.jpg\',\n                        self.created_image)\n        return self.processed_image\n\n\nif __name__ == \'__main__\':\n    target_class = 483  # Castle\n    pretrained_model = models.alexnet(pretrained=True)\n    cig = FoolingSampleGeneration(pretrained_model, target_class, 0.99)\n    cig.generate()\n'"
src/misc_functions.py,2,"b'""""""\nCreated on Thu Oct 21 11:09:09 2017\n\n@author: Utku Ozbulak - github.com/utkuozbulak\n""""""\nimport copy\nimport cv2\nimport numpy as np\n\nimport torch\nfrom torch.autograd import Variable\nfrom torchvision import models\n\n\ndef preprocess_image(cv2im, resize_im=True):\n    """"""\n        Processes image for CNNs\n\n    Args:\n        PIL_img (PIL_img): Image to process\n        resize_im (bool): Resize to 224 or not\n    returns:\n        im_as_var (Pytorch variable): Variable that contains processed float tensor\n    """"""\n    # mean and std list for channels (Imagenet)\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    # Resize image\n    if resize_im:\n        cv2im = cv2.resize(cv2im, (224, 224))\n    im_as_arr = np.float32(cv2im)\n    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])\n    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n    # Normalize the channels\n    for channel, _ in enumerate(im_as_arr):\n        im_as_arr[channel] /= 255\n        im_as_arr[channel] -= mean[channel]\n        im_as_arr[channel] /= std[channel]\n    # Convert to float tensor\n    im_as_ten = torch.from_numpy(im_as_arr).float()\n    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n    im_as_ten.unsqueeze_(0)\n    # Convert to Pytorch variable\n    im_as_var = Variable(im_as_ten, requires_grad=True)\n    return im_as_var\n\n\ndef recreate_image(im_as_var):\n    """"""\n        Recreates images from a torch variable, sort of reverse preprocessing\n\n    Args:\n        im_as_var (torch variable): Image to recreate\n\n    returns:\n        recreated_im (numpy arr): Recreated image in array\n    """"""\n    reverse_mean = [-0.485, -0.456, -0.406]\n    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n    recreated_im = copy.copy(im_as_var.data.numpy()[0])\n    for c in range(3):\n        recreated_im[c] /= reverse_std[c]\n        recreated_im[c] -= reverse_mean[c]\n    recreated_im[recreated_im > 1] = 1\n    recreated_im[recreated_im < 0] = 0\n    recreated_im = np.round(recreated_im * 255)\n\n    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n    # Convert RBG to GBR\n    recreated_im = recreated_im[..., ::-1]\n    return recreated_im\n\n\ndef get_params(example_index):\n    """"""\n        Gets used variables for almost all visualizations, like the image, model etc.\n\n    Args:\n        example_index (int): Image id to use from examples\n\n    returns:\n        original_image (numpy arr): Original image read from the file\n        prep_img (numpy_arr): Processed image\n        target_class (int): Target class for the image\n        file_name_to_export (string): File name to export the visualizations\n        pretrained_model(Pytorch model): Model to use for the operations\n    """"""\n    # Pick one of the examples\n    example_list = [[\'../input_images/apple.JPEG\', 948],\n                    [\'../input_images/eel.JPEG\', 390],\n                    [\'../input_images/bird.JPEG\', 13]]\n    selected_example = example_index\n    img_path = example_list[selected_example][0]\n    target_class = example_list[selected_example][1]\n    file_name_to_export = img_path[img_path.rfind(\'/\')+1:img_path.rfind(\'.\')]\n    # Read image\n    original_image = cv2.imread(img_path, 1)\n    # Process image\n    prep_img = preprocess_image(original_image)\n    # Define model\n    pretrained_model = models.alexnet(pretrained=True)\n    return (original_image,\n            prep_img,\n            target_class,\n            file_name_to_export,\n            pretrained_model)\n'"
