file_path,api_count,code
test.py,13,"b'""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nimport argparse\nimport torch\n\nfrom src.deep_q_network import DeepQNetwork\nfrom src.flappy_bird import FlappyBird\nfrom src.utils import pre_processing\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(\n        """"""Implementation of Deep Q Network to play Flappy Bird"""""")\n    parser.add_argument(""--image_size"", type=int, default=84, help=""The common width and height for all images"")\n    parser.add_argument(""--saved_path"", type=str, default=""trained_models"")\n\n    args = parser.parse_args()\n    return args\n\n\ndef test(opt):\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(123)\n    else:\n        torch.manual_seed(123)\n    if torch.cuda.is_available():\n        model = torch.load(""{}/flappy_bird"".format(opt.saved_path))\n    else:\n        model = torch.load(""{}/flappy_bird"".format(opt.saved_path), map_location=lambda storage, loc: storage)\n    model.eval()\n    game_state = FlappyBird()\n    image, reward, terminal = game_state.next_frame(0)\n    image = pre_processing(image[:game_state.screen_width, :int(game_state.base_y)], opt.image_size, opt.image_size)\n    image = torch.from_numpy(image)\n    if torch.cuda.is_available():\n        model.cuda()\n        image = image.cuda()\n    state = torch.cat(tuple(image for _ in range(4)))[None, :, :, :]\n\n    while True:\n        prediction = model(state)[0]\n        action = torch.argmax(prediction)[0]\n\n        next_image, reward, terminal = game_state.next_frame(action)\n        next_image = pre_processing(next_image[:game_state.screen_width, :int(game_state.base_y)], opt.image_size,\n                                    opt.image_size)\n        next_image = torch.from_numpy(next_image)\n        if torch.cuda.is_available():\n            next_image = next_image.cuda()\n        next_state = torch.cat((state[0, 1:, :, :], next_image))[None, :, :, :]\n\n        state = next_state\n\n\nif __name__ == ""__main__"":\n    opt = get_args()\n    test(opt)\n'"
train.py,24,"b'""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nimport argparse\nimport os\nimport shutil\nfrom random import random, randint, sample\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom tensorboardX import SummaryWriter\n\nfrom src.deep_q_network import DeepQNetwork\nfrom src.flappy_bird import FlappyBird\nfrom src.utils import pre_processing\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(\n        """"""Implementation of Deep Q Network to play Flappy Bird"""""")\n    parser.add_argument(""--image_size"", type=int, default=84, help=""The common width and height for all images"")\n    parser.add_argument(""--batch_size"", type=int, default=32, help=""The number of images per batch"")\n    parser.add_argument(""--optimizer"", type=str, choices=[""sgd"", ""adam""], default=""adam"")\n    parser.add_argument(""--lr"", type=float, default=1e-6)\n    parser.add_argument(""--gamma"", type=float, default=0.99)\n    parser.add_argument(""--initial_epsilon"", type=float, default=0.1)\n    parser.add_argument(""--final_epsilon"", type=float, default=1e-4)\n    parser.add_argument(""--num_iters"", type=int, default=2000000)\n    parser.add_argument(""--replay_memory_size"", type=int, default=50000,\n                        help=""Number of epoches between testing phases"")\n    parser.add_argument(""--log_path"", type=str, default=""tensorboard"")\n    parser.add_argument(""--saved_path"", type=str, default=""trained_models"")\n\n    args = parser.parse_args()\n    return args\n\n\ndef train(opt):\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(123)\n    else:\n        torch.manual_seed(123)\n    model = DeepQNetwork()\n    if os.path.isdir(opt.log_path):\n        shutil.rmtree(opt.log_path)\n    os.makedirs(opt.log_path)\n    writer = SummaryWriter(opt.log_path)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n    criterion = nn.MSELoss()\n    game_state = FlappyBird()\n    image, reward, terminal = game_state.next_frame(0)\n    image = pre_processing(image[:game_state.screen_width, :int(game_state.base_y)], opt.image_size, opt.image_size)\n    image = torch.from_numpy(image)\n    if torch.cuda.is_available():\n        model.cuda()\n        image = image.cuda()\n    state = torch.cat(tuple(image for _ in range(4)))[None, :, :, :]\n\n    replay_memory = []\n    iter = 0\n    while iter < opt.num_iters:\n        prediction = model(state)[0]\n        # Exploration or exploitation\n        epsilon = opt.final_epsilon + (\n                (opt.num_iters - iter) * (opt.initial_epsilon - opt.final_epsilon) / opt.num_iters)\n        u = random()\n        random_action = u <= epsilon\n        if random_action:\n            print(""Perform a random action"")\n            action = randint(0, 1)\n        else:\n\n            action = torch.argmax(prediction)[0]\n\n        next_image, reward, terminal = game_state.next_frame(action)\n        next_image = pre_processing(next_image[:game_state.screen_width, :int(game_state.base_y)], opt.image_size,\n                                    opt.image_size)\n        next_image = torch.from_numpy(next_image)\n        if torch.cuda.is_available():\n            next_image = next_image.cuda()\n        next_state = torch.cat((state[0, 1:, :, :], next_image))[None, :, :, :]\n        replay_memory.append([state, action, reward, next_state, terminal])\n        if len(replay_memory) > opt.replay_memory_size:\n            del replay_memory[0]\n        batch = sample(replay_memory, min(len(replay_memory), opt.batch_size))\n        state_batch, action_batch, reward_batch, next_state_batch, terminal_batch = zip(*batch)\n\n        state_batch = torch.cat(tuple(state for state in state_batch))\n        action_batch = torch.from_numpy(\n            np.array([[1, 0] if action == 0 else [0, 1] for action in action_batch], dtype=np.float32))\n        reward_batch = torch.from_numpy(np.array(reward_batch, dtype=np.float32)[:, None])\n        next_state_batch = torch.cat(tuple(state for state in next_state_batch))\n\n        if torch.cuda.is_available():\n            state_batch = state_batch.cuda()\n            action_batch = action_batch.cuda()\n            reward_batch = reward_batch.cuda()\n            next_state_batch = next_state_batch.cuda()\n        current_prediction_batch = model(state_batch)\n        next_prediction_batch = model(next_state_batch)\n\n        y_batch = torch.cat(\n            tuple(reward if terminal else reward + opt.gamma * torch.max(prediction) for reward, terminal, prediction in\n                  zip(reward_batch, terminal_batch, next_prediction_batch)))\n\n        q_value = torch.sum(current_prediction_batch * action_batch, dim=1)\n        optimizer.zero_grad()\n        # y_batch = y_batch.detach()\n        loss = criterion(q_value, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        state = next_state\n        iter += 1\n        print(""Iteration: {}/{}, Action: {}, Loss: {}, Epsilon {}, Reward: {}, Q-value: {}"".format(\n            iter + 1,\n            opt.num_iters,\n            action,\n            loss,\n            epsilon, reward, torch.max(prediction)))\n        writer.add_scalar(\'Train/Loss\', loss, iter)\n        writer.add_scalar(\'Train/Epsilon\', epsilon, iter)\n        writer.add_scalar(\'Train/Reward\', reward, iter)\n        writer.add_scalar(\'Train/Q-value\', torch.max(prediction), iter)\n        if (iter+1) % 1000000 == 0:\n            torch.save(model, ""{}/flappy_bird_{}"".format(opt.saved_path, iter+1))\n    torch.save(model, ""{}/flappy_bird"".format(opt.saved_path))\n\n\nif __name__ == ""__main__"":\n    opt = get_args()\n    train(opt)\n'"
src/deep_q_network.py,1,"b'""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nimport torch.nn as nn\n\nclass DeepQNetwork(nn.Module):\n    def __init__(self):\n        super(DeepQNetwork, self).__init__()\n\n        self.conv1 = nn.Sequential(nn.Conv2d(4, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True))\n        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True))\n        self.conv3 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1), nn.ReLU(inplace=True))\n\n        self.fc1 = nn.Sequential(nn.Linear(7 * 7 * 64, 512), nn.ReLU(inplace=True))\n        self.fc2 = nn.Linear(512, 2)\n        self._create_weights()\n\n    def _create_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n                nn.init.uniform(m.weight, -0.01, 0.01)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, input):\n        output = self.conv1(input)\n        output = self.conv2(output)\n        output = self.conv3(output)\n        output = output.view(output.size(0), -1)\n        output = self.fc1(output)\n        output = self.fc2(output)\n\n        return output\n'"
src/flappy_bird.py,0,"b'""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nfrom itertools import cycle\nfrom numpy.random import randint\nfrom pygame import Rect, init, time, display\nfrom pygame.event import pump\nfrom pygame.image import load\nfrom pygame.surfarray import array3d, pixels_alpha\nfrom pygame.transform import rotate\nimport numpy as np\n\n\nclass FlappyBird(object):\n    init()\n    fps_clock = time.Clock()\n    screen_width = 288\n    screen_height = 512\n    screen = display.set_mode((screen_width, screen_height))\n    display.set_caption(\'Deep Q-Network Flappy Bird\')\n    base_image = load(\'assets/sprites/base.png\').convert_alpha()\n    background_image = load(\'assets/sprites/background-black.png\').convert()\n\n    pipe_images = [rotate(load(\'assets/sprites/pipe-green.png\').convert_alpha(), 180),\n                   load(\'assets/sprites/pipe-green.png\').convert_alpha()]\n    bird_images = [load(\'assets/sprites/redbird-upflap.png\').convert_alpha(),\n                   load(\'assets/sprites/redbird-midflap.png\').convert_alpha(),\n                   load(\'assets/sprites/redbird-downflap.png\').convert_alpha()]\n    # number_images = [load(\'assets/sprites/{}.png\'.format(i)).convert_alpha() for i in range(10)]\n\n    bird_hitmask = [pixels_alpha(image).astype(bool) for image in bird_images]\n    pipe_hitmask = [pixels_alpha(image).astype(bool) for image in pipe_images]\n\n    fps = 30\n    pipe_gap_size = 100\n    pipe_velocity_x = -4\n\n    # parameters for bird\n    min_velocity_y = -8\n    max_velocity_y = 10\n    downward_speed = 1\n    upward_speed = -9\n\n    bird_index_generator = cycle([0, 1, 2, 1])\n\n    def __init__(self):\n\n        self.iter = self.bird_index = self.score = 0\n\n        self.bird_width = self.bird_images[0].get_width()\n        self.bird_height = self.bird_images[0].get_height()\n        self.pipe_width = self.pipe_images[0].get_width()\n        self.pipe_height = self.pipe_images[0].get_height()\n\n        self.bird_x = int(self.screen_width / 5)\n        self.bird_y = int((self.screen_height - self.bird_height) / 2)\n\n        self.base_x = 0\n        self.base_y = self.screen_height * 0.79\n        self.base_shift = self.base_image.get_width() - self.background_image.get_width()\n\n        pipes = [self.generate_pipe(), self.generate_pipe()]\n        pipes[0][""x_upper""] = pipes[0][""x_lower""] = self.screen_width\n        pipes[1][""x_upper""] = pipes[1][""x_lower""] = self.screen_width * 1.5\n        self.pipes = pipes\n\n        self.current_velocity_y = 0\n        self.is_flapped = False\n\n    def generate_pipe(self):\n        x = self.screen_width + 10\n        gap_y = randint(2, 10) * 10 + int(self.base_y / 5)\n        return {""x_upper"": x, ""y_upper"": gap_y - self.pipe_height, ""x_lower"": x, ""y_lower"": gap_y + self.pipe_gap_size}\n\n    def is_collided(self):\n        # Check if the bird touch ground\n        if self.bird_height + self.bird_y + 1 >= self.base_y:\n            return True\n        bird_bbox = Rect(self.bird_x, self.bird_y, self.bird_width, self.bird_height)\n        pipe_boxes = []\n        for pipe in self.pipes:\n            pipe_boxes.append(Rect(pipe[""x_upper""], pipe[""y_upper""], self.pipe_width, self.pipe_height))\n            pipe_boxes.append(Rect(pipe[""x_lower""], pipe[""y_lower""], self.pipe_width, self.pipe_height))\n            # Check if the bird\'s bounding box overlaps to the bounding box of any pipe\n            if bird_bbox.collidelist(pipe_boxes) == -1:\n                return False\n            for i in range(2):\n                cropped_bbox = bird_bbox.clip(pipe_boxes[i])\n                min_x1 = cropped_bbox.x - bird_bbox.x\n                min_y1 = cropped_bbox.y - bird_bbox.y\n                min_x2 = cropped_bbox.x - pipe_boxes[i].x\n                min_y2 = cropped_bbox.y - pipe_boxes[i].y\n                if np.any(self.bird_hitmask[self.bird_index][min_x1:min_x1 + cropped_bbox.width,\n                       min_y1:min_y1 + cropped_bbox.height] * self.pipe_hitmask[i][min_x2:min_x2 + cropped_bbox.width,\n                                                              min_y2:min_y2 + cropped_bbox.height]):\n                    return True\n        return False\n\n    def next_frame(self, action):\n        pump()\n        reward = 0.1\n        terminal = False\n        # Check input action\n        if action == 1:\n            self.current_velocity_y = self.upward_speed\n            self.is_flapped = True\n\n        # Update score\n        bird_center_x = self.bird_x + self.bird_width / 2\n        for pipe in self.pipes:\n            pipe_center_x = pipe[""x_upper""] + self.pipe_width / 2\n            if pipe_center_x < bird_center_x < pipe_center_x + 5:\n                self.score += 1\n                reward = 1\n                break\n\n        # Update index and iteration\n        if (self.iter + 1) % 3 == 0:\n            self.bird_index = next(self.bird_index_generator)\n            self.iter = 0\n        self.base_x = -((-self.base_x + 100) % self.base_shift)\n\n        # Update bird\'s position\n        if self.current_velocity_y < self.max_velocity_y and not self.is_flapped:\n            self.current_velocity_y += self.downward_speed\n        if self.is_flapped:\n            self.is_flapped = False\n        self.bird_y += min(self.current_velocity_y, self.bird_y - self.current_velocity_y - self.bird_height)\n        if self.bird_y < 0:\n            self.bird_y = 0\n\n        # Update pipes\' position\n        for pipe in self.pipes:\n            pipe[""x_upper""] += self.pipe_velocity_x\n            pipe[""x_lower""] += self.pipe_velocity_x\n        # Update pipes\n        if 0 < self.pipes[0][""x_lower""] < 5:\n            self.pipes.append(self.generate_pipe())\n        if self.pipes[0][""x_lower""] < -self.pipe_width:\n            del self.pipes[0]\n        if self.is_collided():\n            terminal = True\n            reward = -1\n            self.__init__()\n\n        # Draw everything\n        self.screen.blit(self.background_image, (0, 0))\n        self.screen.blit(self.base_image, (self.base_x, self.base_y))\n        self.screen.blit(self.bird_images[self.bird_index], (self.bird_x, self.bird_y))\n        for pipe in self.pipes:\n            self.screen.blit(self.pipe_images[0], (pipe[""x_upper""], pipe[""y_upper""]))\n            self.screen.blit(self.pipe_images[1], (pipe[""x_lower""], pipe[""y_lower""]))\n        image = array3d(display.get_surface())\n        display.update()\n        self.fps_clock.tick(self.fps)\n        return image, reward, terminal\n'"
src/utils.py,0,"b'""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nimport cv2\nimport numpy as np\n\n\ndef pre_processing(image, width, height):\n    image = cv2.cvtColor(cv2.resize(image, (width, height)), cv2.COLOR_BGR2GRAY)\n    _, image = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\n    return image[None, :, :].astype(np.float32)\n'"
