file_path,api_count,code
camera_app.py,5,"b'""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nimport argparse\nfrom collections import deque\n\nimport cv2\nimport numpy as np\nimport torch\n\n# from src.dataset import CLASSES\nfrom src.config import *\nfrom src.utils import get_images, get_overlay\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(\n        """"""Implementation of Google\'s Quick Draw Project (https://quickdraw.withgoogle.com/#)"""""")\n    parser.add_argument(""-c"", ""--color"", type=str, choices=[""green"", ""blue"", ""red""], default=""green"",\n                        help=""Color which could be captured by camera and seen as pointer"")\n    parser.add_argument(""-a"", ""--area"", type=int, default=3000, help=""Minimum area of captured object"")\n    parser.add_argument(""-d"", ""--display"", type=int, default=3, help=""How long is prediction shown in second(s)"")\n    parser.add_argument(""-s"", ""--canvas"", type=bool, default=False, help=""Display black & white canvas"")\n    args = parser.parse_args()\n    return args\n\n\ndef main(opt):\n    # Define color range\n    if opt.color == ""red"":  # We shouldn\'t use red as color for pointer, since it\n        # could be confused with our skin\'s color under some circumstances\n        color_lower = np.array(RED_HSV_LOWER)\n        color_upper = np.array(RED_HSV_UPPER)\n        color_pointer = RED_RGB\n    elif opt.color == ""green"":\n        color_lower = np.array(GREEN_HSV_LOWER)\n        color_upper = np.array(GREEN_HSV_UPPER)\n        color_pointer = GREEN_RGB\n    else:\n        color_lower = np.array(BLUE_HSV_LOWER)\n        color_upper = np.array(BLUE_HSV_UPPER)\n        color_pointer = BLUE_RGB\n\n    # Initialize deque for storing detected points and canvas for drawing\n    points = deque(maxlen=512)\n    canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n\n    # Load the video from camera (Here I use built-in webcam)\n    camera = cv2.VideoCapture(0)\n    is_drawing = False\n    is_shown = False\n\n    # Load images for classes:\n    class_images = get_images(""images"", CLASSES)\n    predicted_class = None\n\n    # Load model\n    if torch.cuda.is_available():\n        model = torch.load(""trained_models/whole_model_quickdraw"")\n    else:\n        model = torch.load(""trained_models/whole_model_quickdraw"", map_location=lambda storage, loc: storage)\n    model.eval()\n\n    while True:\n        key = cv2.waitKey(10)\n        if key == ord(""q""):\n            break\n        elif key == ord("" ""):\n            is_drawing = not is_drawing\n            if is_drawing:\n                if is_shown:\n                    points = deque(maxlen=512)\n                    canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n                is_shown = False\n        if not is_drawing and not is_shown:\n            if len(points):\n                canvas_gs = cv2.cvtColor(canvas, cv2.COLOR_BGR2GRAY)\n                # Blur image\n                median = cv2.medianBlur(canvas_gs, 9)\n                gaussian = cv2.GaussianBlur(median, (5, 5), 0)\n                # Otsu\'s thresholding\n                _, thresh = cv2.threshold(gaussian, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n                _, contour_gs, _ = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n                if len(contour_gs):\n                    contour = sorted(contour_gs, key=cv2.contourArea, reverse=True)[0]\n                    # Check if the largest contour satisfy the condition of minimum area\n                    if cv2.contourArea(contour) > opt.area:\n                        x, y, w, h = cv2.boundingRect(contour)\n                        image = canvas_gs[y:y + h, x:x + w]\n                        image = cv2.resize(image, (28, 28))\n                        image = np.array(image, dtype=np.float32)[None, None, :, :]\n                        image = torch.from_numpy(image)\n                        logits = model(image)\n                        predicted_class = torch.argmax(logits[0])\n                        # print (CLASSES[predicted_class])\n                        is_shown = True\n                    else:\n                        print(""The object drawn is too small. Please draw a bigger one!"")\n                        points = deque(maxlen=512)\n                        canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n\n        # Read frame from camera\n        ret, frame = camera.read()\n        frame = cv2.flip(frame, 1)\n        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n        kernel = np.ones((5, 5), np.uint8)\n        # Detect pixels fall within the pre-defined color range. Then, blur the image\n        mask = cv2.inRange(hsv, color_lower, color_upper)\n        mask = cv2.erode(mask, kernel, iterations=2)\n        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n        mask = cv2.dilate(mask, kernel, iterations=1)\n\n        _, contours, _ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Check to see if any contours are found\n        if len(contours):\n            # Take the biggest contour, since it is possible that there are other objects in front of camera\n            # whose color falls within the range of our pre-defined color\n            contour = sorted(contours, key=cv2.contourArea, reverse=True)[0]\n            ((x, y), radius) = cv2.minEnclosingCircle(contour)\n            # Draw the circle around the contour\n            cv2.circle(frame, (int(x), int(y)), int(radius), YELLOW_RGB, 2)\n            if is_drawing:\n                M = cv2.moments(contour)\n                center = (int(M[\'m10\'] / M[\'m00\']), int(M[\'m01\'] / M[\'m00\']))\n                points.appendleft(center)\n                for i in range(1, len(points)):\n                    if points[i - 1] is None or points[i] is None:\n                        continue\n                    cv2.line(canvas, points[i - 1], points[i], WHITE_RGB, 5)\n                    cv2.line(frame, points[i - 1], points[i], color_pointer, 2)\n\n        if is_shown:\n            cv2.putText(frame, \'You are drawing\', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color_pointer, 5, cv2.LINE_AA)\n            frame[5:65, 490:550] = get_overlay(frame[5:65, 490:550], class_images[predicted_class], (60,60))\n\n\n        cv2.imshow(""Camera"", frame)\n        if opt.canvas:\n            cv2.imshow(""Canvas"", 255-canvas)\n\n    camera.release()\n    cv2.destroyAllWindows()\n\n\nif __name__ == \'__main__\':\n    opt = get_args()\n    main(opt)\n'"
draw.py,0,"b'import cv2\nimport numpy as np\n\ndrawing = False  # true if mouse is pressed\n\n\n# mouse callback function\ndef paint_draw(event, x, y, flags, param):\n    global ix, iy, drawing, mode\n    if event == cv2.EVENT_LBUTTONDOWN:\n        drawing = True\n        ix, iy = x, y\n    elif event == cv2.EVENT_MOUSEMOVE:\n        if drawing == True:\n            cv2.line(image, (ix, iy), (x, y), (255, 255, 255), 5)\n            ix = x\n            iy = y\n    elif event == cv2.EVENT_LBUTTONUP:\n        drawing = False\n        cv2.line(image, (ix, iy), (x, y), (255, 255, 255), 5)\n        ix = x\n        iy = y\n    return x, y\n\n\nimage = np.zeros((480, 640, 3), dtype=np.uint8)\ncv2.namedWindow(""Canvas"")\ncv2.setMouseCallback(\'Canvas\', paint_draw)\nwhile (1):\n    cv2.imshow(\'Canvas\', 255-image)\n    k = cv2.waitKey(1) & 0xFF\n    if k == 27:  # Escape KEY\n        cv2.imwrite(""painted_image.jpg"", image)\n        break\ncv2.destroyAllWindows()'"
painting_app.py,5,"b'import cv2\nimport numpy as np\nfrom src.config import *\nfrom src.dataset import CLASSES\nimport torch\n\n\n\ndef main():\n    # Load model\n    if torch.cuda.is_available():\n        model = torch.load(""trained_models/whole_model_quickdraw"")\n    else:\n        model = torch.load(""trained_models/whole_model_quickdraw"", map_location=lambda storage, loc: storage)\n    model.eval()\n    image = np.zeros((480, 640, 3), dtype=np.uint8)\n    cv2.namedWindow(""Canvas"")\n    global ix, iy, is_drawing\n    is_drawing = False\n\n    def paint_draw(event, x, y, flags, param):\n        global ix, iy, is_drawing\n        if event == cv2.EVENT_LBUTTONDOWN:\n            is_drawing = True\n            ix, iy = x, y\n        elif event == cv2.EVENT_MOUSEMOVE:\n            if is_drawing == True:\n                cv2.line(image, (ix, iy), (x, y), WHITE_RGB, 5)\n                ix = x\n                iy = y\n        elif event == cv2.EVENT_LBUTTONUP:\n            is_drawing = False\n            cv2.line(image, (ix, iy), (x, y), WHITE_RGB, 5)\n            ix = x\n            iy = y\n        return x, y\n\n    cv2.setMouseCallback(\'Canvas\', paint_draw)\n    while (1):\n        cv2.imshow(\'Canvas\', 255 - image)\n        key = cv2.waitKey(10)\n        if key == ord("" ""):\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            ys, xs = np.nonzero(image)\n            min_y = np.min(ys)\n            max_y = np.max(ys)\n            min_x = np.min(xs)\n            max_x = np.max(xs)\n            image = image[min_y:max_y, min_x: max_x]\n\n            image = cv2.resize(image, (28, 28))\n            image = np.array(image, dtype=np.float32)[None, None, :, :]\n            image = torch.from_numpy(image)\n            logits = model(image)\n            print(CLASSES[torch.argmax(logits[0])])\n            image = np.zeros((480, 640, 3), dtype=np.uint8)\n            ix = -1\n            iy = -1\n\n\n\n\n\n\n\nif __name__ == \'__main__\':\n    main()\n'"
train.py,14,"b'# -*- coding: utf-8 -*-\n""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nimport argparse\nimport os\nimport shutil\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom tensorboardX import SummaryWriter\nfrom torch.utils.data import DataLoader\n\nfrom src.dataset import MyDataset\nfrom src.model import QuickDraw\nfrom src.utils import get_evaluation\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(\n        """"""Implementation of the Quick Draw model proposed by Google"""""")\n    parser.add_argument(""--optimizer"", type=str, choices=[""sgd"", ""adam""], default=""sgd"")\n    parser.add_argument(""--total_images_per_class"", type=int, default=10000)\n    parser.add_argument(""--ratio"", type=float, default=0.8, help=""the ratio between training and test sets"")\n    parser.add_argument(""--batch_size"", type=int, default=32)\n    parser.add_argument(""--num_epochs"", type=int, default=20)\n    parser.add_argument(""--lr"", type=float,\n                        default=0.01)  # recommended learning rate for sgd is 0.01, while for adam is 0.001\n    parser.add_argument(""--es_min_delta"", type=float, default=0.0,\n                        help=""Early stopping\'s parameter: minimum change loss to qualify as an improvement"")\n    parser.add_argument(""--es_patience"", type=int, default=3,\n                        help=""Early stopping\'s parameter: number of epochs with no improvement after which training will be stopped. Set to 0 to disable this technique."")\n    parser.add_argument(""--data_path"", type=str, default=""data"", help=""the root folder of dataset"")\n    parser.add_argument(""--log_path"", type=str, default=""tensorboard"")\n    parser.add_argument(""--saved_path"", type=str, default=""trained_models"")\n    args = parser.parse_args()\n    return args\n\n\ndef train(opt):\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(123)\n    else:\n        torch.manual_seed(123)\n    training_params = {""batch_size"": opt.batch_size,\n                       ""shuffle"": True}\n\n    test_params = {""batch_size"": opt.batch_size,\n                   ""shuffle"": False}\n\n    output_file = open(opt.saved_path + os.sep + ""logs.txt"", ""w"")\n    output_file.write(""Model\'s parameters: {}"".format(vars(opt)))\n\n    training_set = MyDataset(opt.data_path, opt.total_images_per_class, opt.ratio, ""train"")\n    training_generator = DataLoader(training_set, **training_params)\n    print (""there are {} images for training phase"".format(training_set.__len__()))\n    test_set = MyDataset(opt.data_path, opt.total_images_per_class, opt.ratio, ""test"")\n    test_generator = DataLoader(test_set, **test_params)\n    print(""there are {} images for test phase"".format(test_set.__len__()))\n\n\n    model = QuickDraw(num_classes=training_set.num_classes)\n\n    if os.path.isdir(opt.log_path):\n        shutil.rmtree(opt.log_path)\n    os.makedirs(opt.log_path)\n    writer = SummaryWriter(opt.log_path)\n    # writer.add_graph(model, torch.rand(opt.batch_size, 1, 28, 28))\n\n    if torch.cuda.is_available():\n        model.cuda()\n\n    criterion = nn.CrossEntropyLoss()\n    if opt.optimizer == ""adam"":\n        optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n    elif opt.optimizer == ""sgd"":\n        optimizer = torch.optim.SGD(model.parameters(), lr=opt.lr, momentum=0.9)\n    else:\n        print(""invalid optimizer"")\n        exit(0)\n\n    best_loss = 1e5\n    best_epoch = 0\n    model.train()\n    num_iter_per_epoch = len(training_generator)\n    for epoch in range(opt.num_epochs):\n        for iter, batch in enumerate(training_generator):\n            images, labels = batch\n            if torch.cuda.is_available():\n                images = images.cuda()\n                labels = labels.cuda()\n            optimizer.zero_grad()\n            predictions = model(images)\n            loss = criterion(predictions, labels)\n            loss.backward()\n            optimizer.step()\n            training_metrics = get_evaluation(labels.cpu().numpy(), predictions.cpu().detach().numpy(),\n                                              list_metrics=[""accuracy""])\n            print(""Epoch: {}/{}, Iteration: {}/{}, Lr: {}, Loss: {}, Accuracy: {}"".format(\n                epoch + 1,\n                opt.num_epochs,\n                iter + 1,\n                num_iter_per_epoch,\n                optimizer.param_groups[0][\'lr\'],\n                loss, training_metrics[""accuracy""]))\n            writer.add_scalar(\'Train/Loss\', loss, epoch * num_iter_per_epoch + iter)\n            writer.add_scalar(\'Train/Accuracy\', training_metrics[""accuracy""], epoch * num_iter_per_epoch + iter)\n\n        model.eval()\n        loss_ls = []\n        te_label_ls = []\n        te_pred_ls = []\n        for idx, te_batch in enumerate(test_generator):\n            te_images, te_labels = te_batch\n            num_samples = te_labels.size()[0]\n            if torch.cuda.is_available():\n                te_images = te_images.cuda()\n                te_labels = te_labels.cuda()\n            with torch.no_grad():\n                te_predictions = model(te_images)\n            te_loss = criterion(te_predictions, te_labels)\n            loss_ls.append(te_loss * num_samples)\n            te_label_ls.extend(te_labels.clone().cpu())\n            te_pred_ls.append(te_predictions.clone().cpu())\n        te_loss = sum(loss_ls) / test_set.__len__()\n        te_pred = torch.cat(te_pred_ls, 0)\n        te_label = np.array(te_label_ls)\n        test_metrics = get_evaluation(te_label, te_pred.numpy(), list_metrics=[""accuracy"", ""confusion_matrix""])\n        output_file.write(\n            ""Epoch: {}/{} \\nTest loss: {} Test accuracy: {} \\nTest confusion matrix: \\n{}\\n\\n"".format(\n                epoch + 1, opt.num_epochs,\n                te_loss,\n                test_metrics[""accuracy""],\n                test_metrics[""confusion_matrix""]))\n        print(""Epoch: {}/{}, Lr: {}, Loss: {}, Accuracy: {}"".format(\n            epoch + 1,\n            opt.num_epochs,\n            optimizer.param_groups[0][\'lr\'],\n            te_loss, test_metrics[""accuracy""]))\n        writer.add_scalar(\'Test/Loss\', te_loss, epoch)\n        writer.add_scalar(\'Test/Accuracy\', test_metrics[""accuracy""], epoch)\n        model.train()\n        if te_loss + opt.es_min_delta < best_loss:\n            best_loss = te_loss\n            best_epoch = epoch\n            torch.save(model, opt.saved_path + os.sep + ""whole_model_quickdraw"")\n        if epoch - best_epoch > opt.es_patience > 0:\n            print(""Stop training at epoch {}. The lowest loss achieved is {}"".format(epoch, te_loss))\n            break\n    writer.close()\n    output_file.close()\n\n\nif __name__ == ""__main__"":\n    opt = get_args()\n    train(opt)\n'"
src/config.py,0,"b'RED_HSV_LOWER = [0, 100, 100]\nRED_HSV_UPPER = [20, 255, 255]\nRED_RGB = (0, 0, 255)\n\nGREEN_HSV_LOWER = [36, 0, 0]\nGREEN_HSV_UPPER = [86, 255, 255]\nGREEN_RGB = (0, 255, 0)\n\nBLUE_HSV_LOWER = [100, 60, 60]\nBLUE_HSV_UPPER = [140, 255, 255]\nBLUE_RGB = (255, 0, 0)\n\nYELLOW_RGB = (0, 255, 255)\nWHITE_RGB = (255, 255, 255)\n\nCLASSES = [""apple"", ""book"", ""bowtie"", ""candle"", ""cloud"", ""cup"", ""door"", ""envelope"", ""eyeglasses"", ""guitar"", ""hammer"",\n           ""hat"", ""ice cream"", ""leaf"", ""scissors"", ""star"", ""t-shirt"", ""pants"", ""lightning"", ""tree""]\n'"
src/dataset.py,1,"b'""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nfrom torch.utils.data import Dataset\nimport numpy as np\n\nfrom src.config import CLASSES\n\n\nclass MyDataset(Dataset):\n    def __init__(self, root_path=""data"", total_images_per_class=10000, ratio=0.8, mode=""train""):\n        self.root_path = root_path\n        self.num_classes = len(CLASSES)\n\n        if mode == ""train"":\n            self.offset = 0\n            self.num_images_per_class = int(total_images_per_class * ratio)\n\n        else:\n            self.offset = int(total_images_per_class * ratio)\n            self.num_images_per_class = int(total_images_per_class * (1 - ratio))\n        self.num_samples = self.num_images_per_class * self.num_classes\n\n    def __len__(self):\n        return self.num_samples\n\n    def __getitem__(self, item):\n        file_ = ""{}/full_numpy_bitmap_{}.npy"".format(self.root_path, CLASSES[int(item / self.num_images_per_class)])\n        image = np.load(file_).astype(np.float32)[self.offset + (item % self.num_images_per_class)]\n        image /= 255\n        return image.reshape((1, 28, 28)), int(item / self.num_images_per_class)\n\n\nif __name__ == ""__main__"":\n    training_set = MyDataset(""../data"", 500, 0.8, ""train"")\n    print(training_set.__getitem__(3))\n'"
src/model.py,1,"b'import torch\nimport torch.nn as nn\nfrom math import pow\n\nclass QuickDraw(nn.Module):\n    def __init__(self, input_size = 28, num_classes = 15):\n        super(QuickDraw, self).__init__()\n        self.num_classes = num_classes\n        self.conv1 = nn.Sequential(nn.Conv2d(1, 32, 5, bias=False), nn.ReLU(inplace=True), nn.MaxPool2d(2,2))\n        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, 5, bias=False), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2))\n        dimension = int(64 * pow(input_size/4 - 3, 2))\n        self.fc1 = nn.Sequential(nn.Linear(dimension, 512), nn.Dropout(0.5))\n        self.fc2 = nn.Sequential(nn.Linear(512, 128), nn.Dropout(0.5))\n        self.fc3 = nn.Sequential(nn.Linear(128, num_classes))\n\n    def forward(self, input):\n        output = self.conv1(input)\n        output = self.conv2(output)\n        output = output.view(output.size(0), -1)\n        output = self.fc1(output)\n        output = self.fc2(output)\n        output = self.fc3(output)\n        return output'"
src/utils.py,0,"b'""""""\n@author: Viet Nguyen <nhviet1009@gmail.com>\n""""""\nimport cv2\nimport numpy as np\nfrom sklearn import metrics\n\n\ndef get_evaluation(y_true, y_prob, list_metrics):\n    y_pred = np.argmax(y_prob, -1)\n    output = {}\n    if \'accuracy\' in list_metrics:\n        output[\'accuracy\'] = metrics.accuracy_score(y_true, y_pred)\n    if \'loss\' in list_metrics:\n        try:\n            output[\'loss\'] = metrics.log_loss(y_true, y_prob)\n        except ValueError:\n            output[\'loss\'] = -1\n    if \'confusion_matrix\' in list_metrics:\n        output[\'confusion_matrix\'] = str(metrics.confusion_matrix(y_true, y_pred))\n    return output\n\n\ndef get_images(path, classes):\n    images = [cv2.imread(""{}/{}.png"".format(path, item), cv2.IMREAD_UNCHANGED) for item in classes]\n    return images\n\n\ndef get_overlay(bg_image, fg_image, sizes=(40, 40)):\n    fg_image = cv2.resize(fg_image, sizes)\n    fg_mask = fg_image[:, :, 3:]\n    fg_image = fg_image[:, :, :3]\n    bg_mask = 255 - fg_mask\n    bg_image = bg_image/255\n    fg_image = fg_image/255\n    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)/255\n    bg_mask = cv2.cvtColor(bg_mask, cv2.COLOR_GRAY2BGR)/255\n    image = cv2.addWeighted(bg_image*bg_mask, 255, fg_image*fg_mask, 255, 0.).astype(np.uint8)\n    return image\n\n\n\n\n\n# if __name__ == \'__main__\':\n#     images = get_images(""../images"", [""apple"", ""star""])\n#     print(images[0].shape)\n#     print(np.max(images[0]))\n'"
