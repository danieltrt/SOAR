file_path,api_count,code
magnet_loss_test.py,7,"b'import matplotlib\nmatplotlib.use(\'agg\')\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nfrom math import ceil\nfrom tqdm import tqdm\nimport pdb\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch import optim\nimport torch.nn.init as init\n\nimport torchvision\nfrom torchvision.datasets import MNIST, CIFAR10\nfrom torchvision import transforms\nimport torchvision.models as models\n\nfrom models.vgg import VGG\nfrom models.lenet import LeNet\n\nfrom magnet_loss.magnet_tools import *\nfrom magnet_loss.magnet_loss import MagnetLoss\nfrom magnet_loss.utils import plot_embedding, plot_smooth\n\nfrom utils.train_settings import parse_settings\nfrom utils.sampler import SubsetSequentialSampler\nfrom utils.average_meter import AverageMeter\n\nfrom visualizer.visualizer import VisdomLinePlotter\n\nfrom datasets.load_dataset import load_dataset\n\nargs = parse_settings()\n\ndef run_magnet_loss():\n\t\'\'\'\n\tTest function for the magnet loss\n\t\'\'\'\n\tm = 8\n\td = 8\n\tk = 8\n\talpha = 1.0\n\tbatch_size = m * d\n\n\tglobal plotter\n\tplotter = VisdomLinePlotter(env_name=args.name)\n\n\ttrainloader, testloader, trainset, testset, n_train = load_dataset(args)\n\n\temb_dim = 2\n\tn_epochs = 15\n\tepoch_steps = len(trainloader)\n\tn_steps = epoch_steps * 15\n\tcluster_refresh_interval = epoch_steps\n\n\tif args.mnist:\n\t\tmodel = torch.nn.DataParallel(LeNet(emb_dim)).cuda()\n\tif args.cifar10:\n\t\tmodel = torch.nn.DataParallel(VGG(depth=16, num_classes=emb_dim))\n\tprint(model)\n\n\toptimizer = optim.Adam(model.parameters(), lr=args.lr)\n\n\tminibatch_magnet_loss = MagnetLoss()\n\n\timages = getattr(trainset, \'train_data\')\n\tlabels = getattr(trainset, \'train_labels\')\n\n\t# Get initial embedding\n\tinitial_reps = compute_reps(model, trainset, 400)\n\n\tif args.cifar10:\n\t\tlabels = np.array(labels, dtype=np.float32)\n\n\t# Create batcher\n\tbatch_builder = ClusterBatchBuilder(labels, k, m, d)\n\tbatch_builder.update_clusters(initial_reps)\n\n\tbatch_losses = []\n\n\tbatch_example_inds, batch_class_inds = batch_builder.gen_batch()\n\ttrainloader.sampler.batch_indices = batch_example_inds\n\n\t_ = model.train()\n\n\tlosses = AverageMeter()\n\n\tfor i in tqdm(range(n_steps)):\n\t\tfor batch_idx, (img, target) in enumerate(trainloader):\n\n\t\t\timg = Variable(img).cuda()\n\t\t\ttarget = Variable(target).cuda()\n\n\t\t\toptimizer.zero_grad()\n\t\t\toutput, features = model(img)\n\n\t\t\tbatch_loss, batch_example_losses = minibatch_magnet_loss(output,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   \t  \t\t\tbatch_class_inds,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   \t  \t\t\tm,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   \t  \t\t\td,\n\t\t\t\t\t\t\t\t\t\t\t\t\t   \t  \t\t\talpha)\n\t\t\tbatch_loss.backward()\n\t\t\toptimizer.step()\n\n\t\t# Update loss index\n\t\tbatch_builder.update_losses(batch_example_inds,\n\t\t\t\t\t\t\t\t\tbatch_example_losses)\n\n\t\tbatch_losses.append(batch_loss.data[0])\n\n\t\tif not i % 1000:\n\t\t\tprint (i, batch_loss)\n\n\t\tif not i % cluster_refresh_interval:\n\t\t\tprint(""Refreshing clusters"")\n\t\t\treps = compute_reps(model, trainset, 400)\n\t\t\tbatch_builder.update_clusters(reps)\n\n\t\tif not i % 2000:\n\t\t\tn_plot = 10000\n\t\t\tplot_embedding(compute_reps(model, trainset, 400)[:n_plot], labels[:n_plot], name=i)\n\n\t\tbatch_example_inds, batch_class_inds = batch_builder.gen_batch()\n\t\ttrainloader.sampler.batch_indices = batch_example_inds\n\n\t\tlosses.update(batch_loss, 1)\n\n\t\t# Log the training loss\n\t\tif args.visdom:\n\t\t\tplotter.plot(\'loss\', \'train\', i, losses.avg.data[0])\n\n\t# Plot loss curve\n\tplot_smooth(batch_losses, ""batch-losses"")\n\nif __name__ == \'__main__\':\n\trun_magnet_loss()\n'"
datasets/__init__.py,0,b''
datasets/fashion.py,7,"b'from __future__ import print_function\nimport torch.utils.data as data\nfrom PIL import Image\nimport os\nimport os.path\nimport errno\nimport torch\nimport codecs\n\n\nclass FASHION(data.Dataset):\n    """"""`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n    Args:\n        root (string): Root directory of dataset where ``processed/training.pt``\n            and  ``processed/test.pt`` exist.\n        train (bool, optional): If True, creates dataset from ``training.pt``,\n            otherwise from ``test.pt``.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n        transform (callable, optional): A function/transform that  takes in an PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n    """"""\n    urls = [\n        \'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\',\n        \'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\',\n        \'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\',\n        \'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\',\n    ]\n    raw_folder = \'raw\'\n    processed_folder = \'processed\'\n    training_file = \'training.pt\'\n    test_file = \'test.pt\'\n\n    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n        self.root = os.path.expanduser(root)\n        self.transform = transform\n        self.target_transform = target_transform\n        self.train = train  # training set or test set\n\n        if download:\n            self.download()\n\n        if not self._check_exists():\n            raise RuntimeError(\'Dataset not found.\' +\n                               \' You can use download=True to download it\')\n\n        if self.train:\n            self.train_data, self.train_labels = torch.load(\n                os.path.join(root, self.processed_folder, self.training_file))\n        else:\n            self.test_data, self.test_labels = torch.load(os.path.join(root, self.processed_folder, self.test_file))\n\n    def __getitem__(self, index):\n        """"""\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        """"""\n        if self.train:\n            img, target = self.train_data[index], self.train_labels[index]\n        else:\n            img, target = self.test_data[index], self.test_labels[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(img.numpy(), mode=\'L\')\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target\n\n    def __len__(self):\n        if self.train:\n            return len(self.train_data)\n        else:\n            return len(self.test_data)\n\n    def _check_exists(self):\n        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n\n    def download(self):\n        """"""Download the MNIST data if it doesn\'t exist in processed_folder already.""""""\n        from six.moves import urllib\n        import gzip\n\n        if self._check_exists():\n            return\n\n        # download files\n        try:\n            os.makedirs(os.path.join(self.root, self.raw_folder))\n            os.makedirs(os.path.join(self.root, self.processed_folder))\n        except OSError as e:\n            if e.errno == errno.EEXIST:\n                pass\n            else:\n                raise\n\n        for url in self.urls:\n            print(\'Downloading \' + url)\n            data = urllib.request.urlopen(url)\n            filename = url.rpartition(\'/\')[2]\n            file_path = os.path.join(self.root, self.raw_folder, filename)\n            with open(file_path, \'wb\') as f:\n                f.write(data.read())\n            with open(file_path.replace(\'.gz\', \'\'), \'wb\') as out_f, \\\n                    gzip.GzipFile(file_path) as zip_f:\n                out_f.write(zip_f.read())\n            os.unlink(file_path)\n\n        # process and save as torch files\n        print(\'Processing...\')\n\n        training_set = (\n            read_image_file(os.path.join(self.root, self.raw_folder, \'train-images-idx3-ubyte\')),\n            read_label_file(os.path.join(self.root, self.raw_folder, \'train-labels-idx1-ubyte\'))\n        )\n        test_set = (\n            read_image_file(os.path.join(self.root, self.raw_folder, \'t10k-images-idx3-ubyte\')),\n            read_label_file(os.path.join(self.root, self.raw_folder, \'t10k-labels-idx1-ubyte\'))\n        )\n        with open(os.path.join(self.root, self.processed_folder, self.training_file), \'wb\') as f:\n            torch.save(training_set, f)\n        with open(os.path.join(self.root, self.processed_folder, self.test_file), \'wb\') as f:\n            torch.save(test_set, f)\n\n        print(\'Done!\')\n\n\ndef get_int(b):\n    return int(codecs.encode(b, \'hex\'), 16)\n\n\ndef parse_byte(b):\n    if isinstance(b, str):\n        return ord(b)\n    return b\n\n\ndef read_label_file(path):\n    with open(path, \'rb\') as f:\n        data = f.read()\n        assert get_int(data[:4]) == 2049\n        length = get_int(data[4:8])\n        labels = [parse_byte(b) for b in data[8:]]\n        assert len(labels) == length\n        return torch.LongTensor(labels)\n\n\ndef read_image_file(path):\n    with open(path, \'rb\') as f:\n        data = f.read()\n        assert get_int(data[:4]) == 2051\n        length = get_int(data[4:8])\n        num_rows = get_int(data[8:12])\n        num_cols = get_int(data[12:16])\n        images = []\n        idx = 16\n        for l in range(length):\n            img = []\n            images.append(img)\n            for r in range(num_rows):\n                row = []\n                img.append(row)\n                for c in range(num_cols):\n                    row.append(parse_byte(data[idx]))\n                    idx += 1\n        assert len(images) == length\n        return torch.ByteTensor(images).view(-1, 28, 28)'"
datasets/load_dataset.py,4,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch import optim\n\nimport torchvision\nfrom torchvision.datasets import MNIST, CIFAR10\nfrom torchvision import transforms\n\nfrom datasets.fashion import FASHION\n\nimport numpy\nfrom utils.sampler import SubsetSequentialSampler\n\ndef load_dataset(args):\n\t\'\'\'\n\t\tLoads the dataset specified\n\t\'\'\'\n\n\t# MNIST dataset\n\tif args.mnist:\n\t\ttrans_img = transforms.Compose([\n\t\t\t\ttransforms.ToTensor()\n\t\t\t])\n\n\t\tprint(""Downloading MNIST data..."")\n\t\ttrainset = MNIST(\'./data\', train=True, transform=trans_img, download=True)\n\t\ttestset = MNIST(\'./data\', train=False, transform=trans_img, download=True)\n\n\t# CIFAR-10 dataset\n\tif args.cifar10:\n\t\t# Data\n\t\tprint(\'==> Preparing data..\')\n\t\ttransform_train = transforms.Compose([\n\t\t    transforms.RandomCrop(32, padding=4),\n\t\t    transforms.RandomHorizontalFlip(),\n\t\t    transforms.ToTensor(),\n\t\t    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n\t\t])\n\n\t\ttransform_test = transforms.Compose([\n\t\t    transforms.ToTensor(),\n\t\t    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n\t\t])\n\n\t\ttrainset = CIFAR10(root=\'./data\', train=True, transform=transform_train, download=True)\n\t\ttestset = CIFAR10(root=\'./data\', train=False, transform=transform_test, download=True)\n\n\tif args.fashionmnist:\n\n\t\tnormalize = transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n                                     \t std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n\n\t\ttransform = transforms.Compose([transforms.ToTensor(),\n\t\t                                transforms.Normalize((0.1307,), (0.3081,))])\n\n\t\ttrainset = FASHION(root=\'./data\',\n\t\t\t\t\t\t\t\ttrain=True,\n\t\t\t\t\t\t\t\ttransform=transform,\n\t\t\t\t\t\t\t\tdownload=True\n\t\t\t\t\t\t\t\t)\n\n\t\ttestset = FASHION(root=\'./data\',\n\t\t\t\t\t\t\t   train=False,\n\t\t\t\t\t\t\t   transform=transform,\n\t\t\t\t\t\t\t   download=True)\n\n\t# Deep Metric Learning\n\tif args.magnet_loss:\n\t\tn_train = len(trainset)\n\t\ttrain_sampler = SubsetSequentialSampler(range(len(trainset)), range(args.batch_size))\n\t\ttrainloader = DataLoader(trainset,\n\t\t\t\t\t\t\t\t batch_size=args.batch_size,\n\t\t\t\t\t\t\t\t shuffle=False,\n\t\t\t\t\t\t\t\t num_workers=1,\n\t\t\t\t\t\t\t\t sampler=train_sampler)\n\n\t\ttestloader = DataLoader(testset,\n\t\t\t\t\t\t\t\tbatch_size=args.batch_size,\n\t\t\t\t\t\t\t\tshuffle=True,\n\t\t\t\t\t\t\t\tnum_workers=1)\n\t# Random sampling\n\telse:\n\t\tn_train = len(trainset)\n\t\ttrainloader = DataLoader(trainset,\n\t\t\t\t\t\t\t\t batch_size=args.batch_size,\n\t\t\t\t\t\t\t\t shuffle=True,\n\t\t\t\t\t\t\t\t num_workers=4)\n\n\t\ttestloader = DataLoader(testset,\n\t\t\t\t\t\t\t\tbatch_size=args.batch_size,\n\t\t\t\t\t\t\t\tshuffle=True,\n\t\t\t\t\t\t\t\tnum_workers=4)\n\n\treturn trainloader, testloader, trainset, testset, n_train\n'"
magnet_loss/__init__.py,0,b''
magnet_loss/magnet_loss.py,22,"b'import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nimport numpy as np\nimport pdb\n\nclass MagnetLoss(nn.Module):\n    """"""\n    Magnet loss technique presented in the paper:\n    \'\'Metric Learning with Adaptive Density Discrimination\'\' by Oren Rippel, Manohar Paluri, Piotr Dollar, Lubomir Bourdev in\n    https://research.fb.com/wp-content/uploads/2016/05/metric-learning-with-adaptive-density-discrimination.pdf?\n\n    Args:\n        r: A batch of features.\n        classes: Class labels for each example.\n        clusters: Cluster labels for each example.\n        cluster_classes: Class label for each cluster.\n        n_clusters: Total number of clusters.\n        alpha: The cluster separation gap hyperparameter.\n\n    Returns:\n        total_loss: The total magnet loss for the batch.\n        losses: The loss for each example in the batch.\n    """"""\n    def __init__(self, alpha=1.0):\n        super(MagnetLoss, self).__init__()\n        self.r = None\n        self.classes = None\n        self.clusters = None\n        self.cluster_classes = None\n        self.n_clusters = None\n        self.alpha = alpha\n\n    def forward(self, r, classes, m, d, alpha=1.0):\n        GPU_INT_DTYPE = torch.cuda.IntTensor\n        GPU_LONG_DTYPE = torch.cuda.LongTensor\n        GPU_FLOAT_DTYPE = torch.cuda.FloatTensor\n\n        self.r = r\n        self.classes = torch.from_numpy(classes).type(GPU_LONG_DTYPE)\n        self.clusters, _ = torch.sort(torch.arange(0, float(m)).repeat(d))\n        self.clusters = self.clusters.type(GPU_INT_DTYPE)\n        self.cluster_classes = self.classes[0:m*d:d]\n        self.n_clusters = m\n        self.alpha = alpha\n\n        # Take cluster means within the batch\n        cluster_examples = dynamic_partition(self.r, self.clusters, self.n_clusters)\n\n        cluster_means = torch.stack([torch.mean(x, dim=0) for x in cluster_examples])\n\n        sample_costs = compute_euclidean_distance(cluster_means, expand_dims(r, 1))\n\n        clusters_tensor = self.clusters.type(GPU_FLOAT_DTYPE)\n        n_clusters_tensor = torch.arange(0, self.n_clusters).type(GPU_FLOAT_DTYPE)\n\n        intra_cluster_mask = Variable(comparison_mask(clusters_tensor, n_clusters_tensor).type(GPU_FLOAT_DTYPE))\n\n        intra_cluster_costs = torch.sum(intra_cluster_mask * sample_costs, dim=1)\n\n        N = r.size()[0]\n\n        variance = torch.sum(intra_cluster_costs) / float(N - 1)\n\n        var_normalizer = -1 / (2 * variance**2)\n\n        # Compute numerator\n        numerator = torch.exp(var_normalizer * intra_cluster_costs - self.alpha)\n\n        classes_tensor = self.classes.type(GPU_FLOAT_DTYPE)\n        cluster_classes_tensor = self.cluster_classes.type(GPU_FLOAT_DTYPE)\n\n        # Compute denominator\n        diff_class_mask = Variable(comparison_mask(classes_tensor, cluster_classes_tensor).type(GPU_FLOAT_DTYPE))\n\n        diff_class_mask = 1 - diff_class_mask # Logical not on ByteTensor\n\n        denom_sample_costs = torch.exp(var_normalizer * sample_costs)\n\n        denominator = torch.sum(diff_class_mask * denom_sample_costs, dim=1)\n\n        epsilon = 1e-8\n\n        losses = F.relu(-torch.log(numerator / (denominator + epsilon) + epsilon))\n\n        total_loss = torch.mean(losses)\n\n        return total_loss, losses\n\ndef expand_dims(var, dim=0):\n    """""" Is similar to [numpy.expand_dims](https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html).\n        var = torch.range(0, 9).view(-1, 2)\n        torch.expand_dims(var, 0).size()\n        # (1, 5, 2)\n    """"""\n    sizes = list(var.size())\n    sizes.insert(dim, 1)\n    return var.view(*sizes)\n\ndef comparison_mask(a_labels, b_labels):\n    """"""Computes boolean mask for distance comparisons""""""\n    return torch.eq(expand_dims(a_labels, 1),\n                    expand_dims(b_labels, 0))\n\ndef dynamic_partition(X, partitions, n_clusters):\n    """"""Partitions the data into the number of cluster bins""""""\n    cluster_bin = torch.chunk(X, n_clusters)\n    return cluster_bin\n\ndef compute_euclidean_distance(x, y):\n    return torch.sum((x - y)**2, dim=2)\n'"
magnet_loss/magnet_tools.py,2,"b'""""""\nClusterBatchBuilder framework ported from https://github.com/pumpikano/tf-magnet-loss/blob/master/magnet_tools.py.\n""""""\nfrom math import ceil\nimport numpy as np\nfrom tqdm import tqdm\nimport pdb\n\nfrom sklearn.cluster import KMeans\n\nimport torch\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\n\ndef compute_reps(model, X, chunk_size):\n    """"""Compute representations for input in chunks.""""""\n    chunks = int(ceil(float(len(X)) / chunk_size))\n    reps = []\n    labels = []\n\n    trainloader = DataLoader(X,\n                         batch_size=chunks,\n                         shuffle=False,\n                         num_workers=4)\n\n    for batch_idx, (img, target) in tqdm(enumerate(trainloader)):\n        img = Variable(img).cuda()\n        output, train_features = model(img)\n        embeddings = output.data\n        reps.append(embeddings.cpu().numpy())\n    return np.vstack(reps)\n\nclass ClusterBatchBuilder(object):\n    """"""Sample minibatches for magnet loss.""""""\n    def __init__(self, labels, k, m, d):\n\n        if isinstance(labels, np.ndarray):\n            self.num_classes = np.unique(labels).shape[0]\n            self.labels = labels\n        else:\n            self.num_classes = np.unique(labels.numpy()).shape[0]\n            self.labels = labels.numpy()\n\n        self.k = k\n        self.m = m\n        self.d = d\n\n        self.centroids = None\n\n        if isinstance(labels, np.ndarray):\n            self.assignments = np.zeros_like(labels, int)\n        else:\n            self.assignments = np.zeros_like(labels.numpy(), int)\n\n        self.cluster_assignments = {}\n        self.cluster_classes = np.repeat(range(self.num_classes), k)\n        self.example_losses = None\n        self.cluster_losses = None\n        self.has_loss = None\n\n\n    def update_clusters(self, rep_data, max_iter=20):\n        """"""Given an array of representations for the entire training set,\n        recompute clusters and store example cluster assignments in a\n        quickly sampleable form.""""""\n        # Lazily allocate array for centroids\n        if self.centroids is None:\n            self.centroids = np.zeros([self.num_classes * self.k, rep_data.shape[1]])\n\n\n        for c in range(self.num_classes):\n\n            class_mask = self.labels == c\n            class_examples = rep_data[class_mask]\n            kmeans = KMeans(n_clusters=self.k, init=\'k-means++\', n_init=1, max_iter=max_iter)\n            kmeans.fit(class_examples)\n\n            # Save cluster centroids for finding impostor clusters\n            start = self.get_cluster_ind(c, 0)\n            stop = self.get_cluster_ind(c, self.k)\n            self.centroids[start:stop] = kmeans.cluster_centers_\n\n            # Update assignments with new global cluster indexes\n            self.assignments[class_mask] = self.get_cluster_ind(c, kmeans.predict(class_examples))\n\n        # Construct a map from cluster to example indexes for fast batch creation\n        for cluster in range(self.k * self.num_classes):\n            cluster_mask = self.assignments == cluster\n            self.cluster_assignments[cluster] = np.flatnonzero(cluster_mask)\n\n\n    def update_losses(self, indexes, losses):\n        """"""Given a list of examples indexes and corresponding losses\n        store the new losses and update corresponding cluster losses.""""""\n        # Lazily allocate structures for losses\n        if self.example_losses is None:\n            self.example_losses = np.zeros_like(self.labels, float)\n            self.cluster_losses = np.zeros([self.k * self.num_classes], float)\n            self.has_loss = np.zeros_like(self.labels, bool)\n\n        losses = losses.data.cpu().numpy()\n\n        self.example_losses[indexes] = losses\n        self.has_loss[indexes] = losses\n\n        # Find affected clusters and update the corresponding cluster losses\n        clusters = np.unique(self.assignments[indexes])\n        for cluster in clusters:\n            cluster_inds = self.assignments == cluster\n            cluster_example_losses = self.example_losses[cluster_inds]\n\n            # Take the average closs in the cluster of examples for which we have measured a loss\n            self.cluster_losses[cluster] = np.mean(cluster_example_losses[self.has_loss[cluster_inds]])\n\n    def gen_batch(self):\n        """"""Sample a batch by first sampling a seed cluster proportionally to\n        the mean loss of the clusters, then finding nearest neighbor\n        ""impostor"" clusters, then sampling d examples uniformly from each cluster.\n\n        The generated batch will consist of m clusters each with d consecutive\n        examples.""""""\n\n        # Sample seed cluster proportionally to cluster losses if available\n        if self.cluster_losses is not None:\n            p = self.cluster_losses / np.sum(self.cluster_losses)\n            seed_cluster = np.random.choice(self.num_classes * self.k, p=p)\n        else:\n            seed_cluster = np.random.choice(self.num_classes * self.k)\n\n        # Get imposter clusters by ranking centroids by distance\n        sq_dists = ((self.centroids[seed_cluster] - self.centroids) ** 2).sum(axis=1)\n\n        # Assure only clusters of different class from seed are chosen\n        sq_dists[self.get_class_ind(seed_cluster) == self.cluster_classes] = np.inf\n\n        # Get top impostor clusters and add seed\n        clusters = np.argpartition(sq_dists, self.m-1)[:self.m-1]\n        clusters = np.concatenate([[seed_cluster], clusters])\n\n        # Sample examples uniformly from cluster\n        batch_indexes = np.empty([self.m * self.d], int)\n        for i, c in enumerate(clusters):\n            x = np.random.choice(self.cluster_assignments[c], self.d, replace=False)\n            start = i * self.d\n            stop = start + self.d\n            batch_indexes[start:stop] = x\n\n        # Translate class indexes to index for classes within the batch\n        class_inds = self.get_class_ind(clusters)\n        batch_class_inds = []\n        inds_map = {}\n        class_count = 0\n        for c in class_inds:\n            if c not in inds_map:\n                inds_map[c] = class_count\n                class_count += 1\n            batch_class_inds.append(inds_map[c])\n\n        return batch_indexes, np.repeat(batch_class_inds, self.d)\n\n    def get_cluster_ind(self, c, i):\n        """"""Given a class index and a cluster index within the class\n        return the global cluster index""""""\n        return c * self.k + i\n\n    def get_class_ind(self, c):\n        """"""Given a cluster index return the class index.""""""\n        return c / self.k\n'"
magnet_loss/utils.py,0,"b'#import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import offsetbox\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.utils import linear_assignment_\nfrom scipy.stats import itemfreq\nfrom sklearn.cluster import KMeans\nfrom itertools import chain\nimport pdb\n\n# Visualization\ndef moving_average(a, n=3) :\n    # Adapted from http://stackoverflow.com/questions/14313510/does-numpy-have-a-function-for-calculating-moving-average\n    ret = np.cumsum(a, dtype=float)\n    ret[n:] = ret[n:] - ret[:-n]\n    return ret[n - 1:] / n\n\ndef plot_smooth(history, name):\n    #pdb.set_trace()\n    plt.plot(history, \'c\', moving_average(history, 20), \'b\')\n    plt.savefig(""results"" + str(name) + \'.svg\')\n\ndef show_images(H):\n    # make a square grid\n    num = H.shape[0]\n    rows = int(np.ceil(np.sqrt(float(num))))\n\n    fig = plt.figure(1, [10, 10])\n    grid = ImageGrid(fig, 111, nrows_ncols=[rows, rows])\n\n    for i in range(num):\n        grid[i].axis(\'off\')\n        grid[i].imshow(H[i], cmap=\'Greys\')\n\n    # Turn any unused axes off\n    for j in range(i, len(grid)):\n        grid[j].axis(\'off\')\n\n\ndef plot_embedding(X, y, imgs=None, title=None, name=None):\n    # Adapted from http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n    x_min, x_max = np.min(X, 0), np.max(X, 0)\n    X = (X - x_min) / (x_max - x_min)\n\n    # Plot colors numbers\n    plt.figure(figsize=(10,10))\n    ax = plt.subplot(111)\n    for i in range(X.shape[0]):\n        # plot colored number\n        plt.text(X[i, 0], X[i, 1], str(y[i]),\n                 color=plt.cm.Set1(y[i] / 10.),\n                 fontdict={\'weight\': \'bold\', \'size\': 9})\n\n    # Add image overlays\n    if imgs is not None and hasattr(offsetbox, \'AnnotationBbox\'):\n        # only print thumbnails with matplotlib > 1.0\n        shown_images = np.array([[1., 1.]])  # just something big\n        for i in range(X.shape[0]):\n            dist = np.sum((X[i] - shown_images) ** 2, 1)\n            if np.min(dist) < 4e-3:\n                # don\'t show points that are too close\n                continue\n            shown_images = np.r_[shown_images, [X[i]]]\n            imagebox = offsetbox.AnnotationBbox(\n                offsetbox.OffsetImage(imgs[i], cmap=plt.cm.gray_r), X[i])\n            ax.add_artist(imagebox)\n\n    plt.xticks([]), plt.yticks([])\n    if title is not None:\n        plt.title(title)\n\n    plt.savefig(""results/"" + str(name) + \'.svg\')\n\ndef zip_chain(a, b):\n    return list(chain(*zip(a, b)))\n\n\ndef plot_metric(*args, **kwargs):\n\n    name = args[0]\n    plot_data = []\n    for i in range(1, len(args), 2):\n        metrics = args[i]\n        d = [m[name] for m in metrics]\n        color = args[i + 1]\n        plot_data.extend(zip_chain(d, color * len(d)))\n\n    plt.plot(*plot_data)\n    if kwargs[\'title\']:\n        plt.title(kwargs[\'title\'])\n    plt.show()\n\n\n\n# Evaluation\n\ndef compute_rand_index(emb, labels):\n    """"""\n    https://en.wikipedia.org/wiki/Rand_index\n    """"""\n    n = len(emb)\n    k = np.unique(labels).size\n\n    m = KMeans(k)\n    m.fit(emb)\n    emb_labels = m.predict(emb)\n\n    agreements = 0\n    for i, j in zip(*np.triu_indices(n, 1)):\n        emb_same = emb_labels[i] == emb_labels[j]\n        gt_same = labels[i] == labels[j]\n\n        if emb_same == gt_same:\n            agreements += 1\n\n    return float(agreements) / (n * (n-1) / 2)\n\n\ndef unsupervised_clustering_accuracy(emb, labels):\n    k = np.unique(labels).size\n    kmeans = KMeans(n_clusters=k, max_iter=35, n_init=15, n_jobs=-1).fit(emb)\n    emb_labels = kmeans.labels_\n    G = np.zeros((k,k))\n    for i in range(k):\n        lbl = labels[emb_labels == i]\n        uc = itemfreq(lbl)\n        for uu, cc in uc:\n            G[i,uu] = -cc\n    A = linear_assignment_.linear_assignment(G)\n    acc = 0.0\n    for (cluster, best) in A:\n        acc -= G[cluster,best]\n    return acc / float(len(labels))\n'"
models/__init__.py,0,b''
models/lenet.py,2,"b""import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Build Network\nclass LeNet(nn.Module):\n\n\tdef __init__(self, emb_dim):\n\t\tself.emb_dim = emb_dim\n\n\t\t'''\n\t\tDefine the initialization function of LeNet, this function defines\n\t\tthe basic structure of the neural network\n\t\t'''\n\t\tsuper(LeNet, self).__init__()\n\t\tself.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n\t\tself.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n\t\tself.emb = nn.Linear(64*7*7, self.emb_dim)\n\n\t\tself.layer1 = None\n\t\tself.layer2 = None\n\t\tself.features = None\n\t\tself.embeddings = None\n\t\tself.norm_embeddings = None\n\n\tdef forward(self, x):\n\t\tx = F.max_pool2d(F.relu(self.conv1(x)), 2)\n\t\tself.layer1 = x\n\n\t\tx = F.max_pool2d(F.relu(self.conv2(x)), 2)\n\t\tself.layer2 = x\n\n\t\tx = x.view(-1, self.num_flat_features(x))\n\t\tself.features = x\n\n\t\tx = self.emb(x)\n\t\tembeddings = x\n\n\t\treturn embeddings, self.features\n\n\tdef num_flat_features(self, x):\n\t\t'''\n\t\tCalculate the total tensor x feature amount\n\t\t'''\n\n\t\tsize = x.size()[1:] # All dimensions except batch dimension\n\t\tnum_features = 1\n\t\tfor s in size:\n\t\t\tnum_features *= s\n\n\t\treturn num_features\n\n\tdef name(self):\n\t\treturn 'lenet-magnet'\n"""
models/vgg.py,2,"b""import torch.nn as nn\nimport torch.nn.functional as F\n\ncfg = {\n    11: [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    13: [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n    16: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n    19: [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n}\n\nclass VGG(nn.Module):\n    def __init__(self, depth, num_classes=10, channels=3):\n        assert depth in cfg, 'Error: model depth invalid or undefined!'\n\n        super(VGG, self).__init__()\n        self.feature_extractor = self._make_layers(cfg[depth], channels)\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(512, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        x = x.view(x.size(0), -1)\n        features = x\n        x = self.classifier(x)\n        return x, features\n\n    def _make_layers(self, config, channels):\n        layers = []\n        in_channels = channels\n        for x_cfg in config:\n            if x_cfg == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                layers += [nn.Conv2d(in_channels, x_cfg, kernel_size=3, padding=1),\n                           nn.BatchNorm2d(x_cfg),\n                           nn.ReLU(inplace=True)]\n                in_channels = x_cfg\n        return nn.Sequential(*layers)\n"""
utils/__init__.py,0,b''
utils/average_meter.py,0,"b'class AverageMeter(object):\n    """"""Computes and stores the average and current value""""""\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count'"
utils/sampler.py,0,"b'import torch\n\nclass Sampler(object):\n    """"""Base class for all Samplers.\n\n    Every Sampler subclass has to provide an __iter__ method, providing a way\n    to iterate over indices of dataset elements, and a __len__ method that\n    returns the length of the returned iterators.\n    """"""\n\n    def __init__(self, data_source):\n        pass\n\n    def __iter__(self):\n        raise NotImplementedError\n\n    def __len__(self):\n        raise NotImplementedError\n\nclass SubsetSequentialSampler(Sampler):\n    """"""Samples elements sequentially from a given list of indices, without replacement.\n\n    Arguments:\n        indices (list): a list of indices\n    """"""\n\n    def __init__(self, indices, batch_indices):\n        self.indices = indices\n        self.batch_indices = batch_indices\n\n    def __iter__(self):\n        return (self.indices[i] for i in self.batch_indices)\n\n    def __len__(self):\n        return len(self.indices)\n'"
utils/train_settings.py,1,"b'import argparse\nimport os\nimport shutil\n\ndef parse_settings():\n\n\t# Training settings\n\tparser = argparse.ArgumentParser(description=\'PyTorch Magnet Loss\')\n\tprint(parser)\n\tparser.add_argument(\'--batch-size\', type=int, default=64,\n\t                    help=\'input batch size for training (default: 32)\')\n\tparser.add_argument(\'--epochs\', type=int, default=50,\n\t                    help=\'number of epochs to train (default: 10)\')\n\tparser.add_argument(\'--lr\', type=float, default=1e-3,\n\t                    help=\'learning rate (default: 0.01)\')\n\tparser.add_argument(\'--magnet-loss\', action=\'store_true\', default=False,\n\t\t\t\t\t\thelp=\'Enables the magnet loss for representation learning\')\n\tparser.add_argument(\'--mnist\', action=\'store_true\', default=False,\n\t\t\t\t\t\thelp=\'Use the mnist dataset\')\n\tparser.add_argument(\'--cifar10\', action=\'store_true\', default=False,\n\t\t\t\t\t\thelp=\'Use the CIFAR-10 dataset\')\n\tparser.add_argument(\'--fashionmnist\', action=\'store_true\', default=False,\n\t\t\t\t\t\thelp=\'Use the Fasnion MNIST dataset\')\n\tparser.add_argument(\'--visdom\', dest=\'visdom\', action=\'store_true\', default=False, help=\'Use visdom to track and plot\')\n\tparser.add_argument(\'--name\', default=\'MagnetLoss\', type=str,\n\t\t\t\t\t\thelp=\'name of experiment\')\n\treturn parser.parse_args()\n\ndef save_checkpoint(state, is_best, filename=\'checkpoint.pth.tar\', args):\n    """"""Saves checkpoint to disk""""""\n    directory = ""runs/%s/""%(args.name)\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    filename = directory + filename\n    torch.save(state, filename)\n\n    if is_best:\n        shutil.copyfile(filename, \'runs/%s/\'%(args.name) + \'model_best.pth.tar\')\n'"
visualizer/__init__.py,0,b''
visualizer/visualizer.py,0,"b'from visdom import Visdom\nimport numpy as np\n\nclass VisdomLinePlotter(object):\n    """"""Plots to Visdom""""""\n    def __init__(self, env_name=\'main\'):\n        self.viz = Visdom()\n        self.env = env_name\n        self.plots = {}\n\n    def plot(self, var_name, split_name, x, y):\n        if var_name not in self.plots:\n            self.plots[var_name] = self.viz.line(X=np.array([x,x]), Y=np.array([y,y]), env=self.env, opts=dict(\n                legend=[split_name],\n                title=var_name,\n                xlabel=\'Epochs\',\n                ylabel=var_name\n            ))\n        else:\n            self.viz.updateTrace(X=np.array([x]), Y=np.array([y]), env=self.env, win=self.plots[var_name], name=split_name)\n'"
