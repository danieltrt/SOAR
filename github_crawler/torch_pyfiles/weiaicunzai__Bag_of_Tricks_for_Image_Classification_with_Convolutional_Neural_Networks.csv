file_path,api_count,code
lr_find.py,4,"b""\nimport argparse\nimport glob\nimport os\n\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport numpy as np\n\n#from PIL import Image\nimport transforms \n#from torchvision import transforms\nfrom tensorboardX import SummaryWriter\nfrom conf import settings\nfrom utils import *\nfrom lr_scheduler import FindLR\nfrom criterion import LSR\n\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-net', type=str, required=True, help='net type')\n    parser.add_argument('-w', type=int, default=2, help='number of workers for dataloader')\n    parser.add_argument('-b', type=int, default=64, help='batch size for dataloader')\n    parser.add_argument('-base_lr', type=float, default=1e-7, help='min learning rate')\n    parser.add_argument('-max_lr', type=float, default=10, help='max learning rate')\n    parser.add_argument('-num_iter', type=int, default=100, help='num of iteration')\n    parser.add_argument('-gpus', nargs='+', type=int, default=0, help='gpu device')\n    args = parser.parse_args()\n\n\n    train_transforms = transforms.Compose([\n        #transforms.ToPILImage(),\n        transforms.ToCVImage(),\n        transforms.RandomResizedCrop(settings.IMAGE_SIZE),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(brightness=0.4, saturation=0.4, hue=0.4),\n        #transforms.RandomErasing(),\n        #transforms.CutOut(56),\n        transforms.ToTensor(),\n        transforms.Normalize(settings.TRAIN_MEAN, settings.TRAIN_STD)\n    ])\n\n    train_dataloader = get_train_dataloader(\n        settings.DATA_PATH,\n        train_transforms,\n        args.b,\n        args.w\n    )\n\n    net = get_network(args)\n    net = init_weights(net)\n\n    if isinstance(args.gpus, int):\n        args.gpus = [args.gpus]\n    \n    net = nn.DataParallel(net, device_ids=args.gpus)\n    net = net.cuda()\n\n    lsr_loss = LSR()\n\n    #apply no weight decay on bias\n    params = split_weights(net)\n    optimizer = optim.SGD(params, lr=args.base_lr, momentum=0.9, weight_decay=1e-4, nesterov=True)\n\n    #set up warmup phase learning rate scheduler\n    lr_scheduler = FindLR(optimizer, max_lr=args.max_lr, num_iter=args.num_iter)\n    epoches = int(args.num_iter / len(train_dataloader)) + 1\n\n    n = 0\n    learning_rate = []\n    losses = []\n    for epoch in range(epoches):\n\n        #training procedure\n        net.train()\n        \n        for batch_index, (images, labels) in enumerate(train_dataloader):\n            if n > args.num_iter:\n                break\n\n            lr_scheduler.step()\n\n            images = images.cuda()\n            labels = labels.cuda()\n\n            optimizer.zero_grad()\n            predicts = net(images)\n            loss = lsr_loss(predicts, labels)\n            if torch.isnan(loss).any():\n                n += 1e8\n                break\n            loss.backward()\n            optimizer.step()\n\n            n_iter = (epoch - 1) * len(train_dataloader) + batch_index + 1\n            print('Iterations: {iter_num} [{trained_samples}/{total_samples}]\\tLoss: {:0.4f}\\tLR: {:0.8f}'.format(\n                loss.item(),\n                optimizer.param_groups[0]['lr'],\n                iter_num=n,\n                trained_samples=batch_index * args.b + len(images),\n                total_samples=len(train_dataloader.dataset),\n            ))\n\n            learning_rate.append(optimizer.param_groups[0]['lr'])\n            losses.append(loss.item())\n            n += 1\n\n    learning_rate = learning_rate[10:-5]\n    losses = losses[10:-5]\n\n    fig, ax = plt.subplots(1,1)\n    ax.plot(learning_rate, losses)\n    ax.set_xlabel('learning rate')\n    ax.set_ylabel('losses')\n    ax.set_xscale('log')\n    ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n\n    fig.savefig('result.jpg')\n\n"""
train.py,5,"b'\n""""""author \n   baiyu\n""""""\n\nimport argparse\nimport glob\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\n\n#from PIL import Image\nimport transforms \n#from torchvision import transforms\nfrom tensorboardX import SummaryWriter\nfrom conf import settings\nfrom utils import *\nfrom lr_scheduler import WarmUpLR\nfrom criterion import LSR\n\nif __name__ == \'__main__\':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'-net\', type=str, required=True, help=\'net type\')\n    parser.add_argument(\'-w\', type=int, default=2, help=\'number of workers for dataloader\')\n    parser.add_argument(\'-b\', type=int, default=256, help=\'batch size for dataloader\')\n    parser.add_argument(\'-lr\', type=float, default=0.04, help=\'initial learning rate\')\n    parser.add_argument(\'-e\', type=int, default=450, help=\'training epoches\')\n    parser.add_argument(\'-warm\', type=int, default=5, help=\'warm up phase\')\n    parser.add_argument(\'-gpus\', nargs=\'+\', type=int, default=0, help=\'gpu device\')\n    args = parser.parse_args()\n\n    #checkpoint directory\n    checkpoint_path = os.path.join(settings.CHECKPOINT_PATH, args.net, settings.TIME_NOW)\n    if not os.path.exists(checkpoint_path):\n        os.makedirs(checkpoint_path)\n    checkpoint_path = os.path.join(checkpoint_path, \'{net}-{epoch}-{type}.pth\')\n\n    #tensorboard log directory\n    log_path = os.path.join(settings.LOG_DIR, args.net, settings.TIME_NOW)\n    if not os.path.exists(log_path):\n        os.makedirs(log_path)\n    writer = SummaryWriter(log_dir=log_path)\n\n    #get dataloader\n    train_transforms = transforms.Compose([\n        #transforms.ToPILImage(),\n        transforms.ToCVImage(),\n        transforms.RandomResizedCrop(settings.IMAGE_SIZE),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(brightness=0.4, saturation=0.4, hue=0.4),\n        #transforms.RandomErasing(),\n        #transforms.CutOut(56),\n        transforms.ToTensor(),\n        transforms.Normalize(settings.TRAIN_MEAN, settings.TRAIN_STD)\n    ])\n\n    test_transforms = transforms.Compose([\n        transforms.ToCVImage(),\n        transforms.CenterCrop(settings.IMAGE_SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize(settings.TRAIN_MEAN, settings.TRAIN_STD)\n    ])\n\n    train_dataloader = get_train_dataloader(\n        settings.DATA_PATH,\n        train_transforms,\n        args.b,\n        args.w\n    )\n\n    test_dataloader = get_test_dataloader(\n        settings.DATA_PATH,\n        test_transforms,\n        args.b,\n        args.w\n    )\n\n    #device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") \n    net = get_network(args)\n    net = init_weights(net)\n\n    \n    if isinstance(args.gpus, int):\n        args.gpus = [args.gpus]\n    \n    net = nn.DataParallel(net, device_ids=args.gpus)\n    net = net.cuda()\n\n    #visualize the network\n    visualize_network(writer, net.module)\n\n    #cross_entropy = nn.CrossEntropyLoss() \n    lsr_loss = LSR()\n\n    #apply no weight decay on bias\n    params = split_weights(net)\n    optimizer = optim.SGD(params, lr=args.lr, momentum=0.9, weight_decay=1e-4, nesterov=True)\n\n    #set up warmup phase learning rate scheduler\n    iter_per_epoch = len(train_dataloader)\n    warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * args.warm)\n\n    #set up training phase learning rate scheduler\n    train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=settings.MILESTONES)\n    #train_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.e - args.warm)\n\n    best_acc = 0.0\n    for epoch in range(1, args.e + 1):\n        if epoch > args.warm:\n            train_scheduler.step(epoch)\n\n        #training procedure\n        net.train()\n        \n        for batch_index, (images, labels) in enumerate(train_dataloader):\n            if epoch <= args.warm:\n                warmup_scheduler.step()\n\n            images = images.cuda()\n            labels = labels.cuda()\n\n            optimizer.zero_grad()\n            predicts = net(images)\n            loss = lsr_loss(predicts, labels)\n            loss.backward()\n            optimizer.step()\n\n            n_iter = (epoch - 1) * len(train_dataloader) + batch_index + 1\n            print(\'Training Epoch: {epoch} [{trained_samples}/{total_samples}]\\tLoss: {:0.4f}\\t\'.format(\n                loss.item(),\n                epoch=epoch,\n                trained_samples=batch_index * args.b + len(images),\n                total_samples=len(train_dataloader.dataset),\n            ))\n\n            #visualization\n            visualize_lastlayer(writer, net, n_iter)\n            visualize_train_loss(writer, loss.item(), n_iter)\n\n        visualize_learning_rate(writer, optimizer.param_groups[0][\'lr\'], epoch)\n        visualize_param_hist(writer, net, epoch) \n\n        net.eval()\n\n        total_loss = 0\n        correct = 0\n        for images, labels in test_dataloader:\n\n            images = images.cuda()\n            labels = labels.cuda()\n\n            predicts = net(images)\n            _, preds = predicts.max(1)\n            correct += preds.eq(labels).sum().float()\n\n            loss = lsr_loss(predicts, labels)\n            total_loss += loss.item()\n\n        test_loss = total_loss / len(test_dataloader)\n        acc = correct / len(test_dataloader.dataset)\n        print(\'Test set: loss: {:.4f}, Accuracy: {:.4f}\'.format(test_loss, acc))\n        print()\n\n        visualize_test_loss(writer, test_loss, epoch)\n        visualize_test_acc(writer, acc, epoch)\n\n        #save weights file\n        if epoch > settings.MILESTONES[1] and best_acc < acc:\n            torch.save(net.state_dict(), checkpoint_path.format(net=args.net, epoch=epoch, type=\'best\'))\n            best_acc = acc\n            continue\n        \n        if not epoch % settings.SAVE_EPOCH:\n            torch.save(net.state_dict(), checkpoint_path.format(net=args.net, epoch=epoch, type=\'regular\'))\n    \n    writer.close()\n\n\n\n\n\n\n\n\n\n\n    \n\n\n    \n\n'"
utils.py,5,"b'\n\nimport os\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nfrom conf import settings\nfrom dataset.dataset import CUB_200_2011_Train, CUB_200_2011_Test\n\ndef get_network(args):\n\n    if args.net == \'vgg16\':\n        from models.vgg import vgg16\n        net = vgg16()\n\n    elif args.net == \'vgg11\':\n        from models.vgg import vgg11\n        net = vgg11()\n    \n    elif args.net == \'vgg13\':\n        from models.vgg import vgg13\n        net = vgg13()\n    \n    elif args.net == \'vgg19\':\n        from models.vgg import vgg19\n        net = vgg19()\n\n    return net\n\ndef get_train_dataloader(path, transforms, batch_size, num_workers, target_transforms=None):\n    """""" return training dataloader\n    Args:\n        path: path to CUB_200_2011 dataset\n        transforms: transforms of dataset\n        target_transforms: transforms for targets\n        batch_size: dataloader batchsize\n        num_workers: dataloader num_works\n    Returns: train_data_loader:torch dataloader object\n    """"""\n    train_dataset = CUB_200_2011_Train(\n        path, \n        transform=transforms,\n        target_transform=target_transforms\n    )\n    train_dataloader =  DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        shuffle=True\n    )\n\n    return train_dataloader\n\ndef get_test_dataloader(path, transforms, batch_size, num_workers, target_transforms=None):\n    """""" return training dataloader\n    Args:\n        path: path to CUB_200_2011 dataset\n        transforms: transforms of dataset\n        target_transforms: transforms for targets\n        batch_size: dataloader batchsize\n        num_workers: dataloader num_works\n    Returns: train_data_loader:torch dataloader object\n    """"""\n    test_dataset = CUB_200_2011_Test(\n        path, \n        transform=transforms,\n        target_transform=target_transforms\n    )\n\n    test_dataloader =  DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        shuffle=True\n    )\n\n    return test_dataloader\n\ndef get_lastlayer_params(net):\n    """"""get last trainable layer of a net\n    Args:\n        network architectur\n    \n    Returns:\n        last layer weights and last layer bias\n    """"""\n    last_layer_weights = None\n    last_layer_bias = None\n    for name, para in net.named_parameters():\n        if \'weight\' in name:\n            last_layer_weights = para\n        if \'bias\' in name:\n            last_layer_bias = para\n        \n    return last_layer_weights, last_layer_bias\n\ndef visualize_network(writer, net):\n    """"""visualize network architecture""""""\n    input_tensor = torch.Tensor(3, 3, settings.IMAGE_SIZE, settings.IMAGE_SIZE) \n    input_tensor = input_tensor.to(next(net.parameters()).device)\n    writer.add_graph(net, Variable(input_tensor, requires_grad=True))\n\ndef visualize_lastlayer(writer, net, n_iter):\n    """"""visualize last layer grads""""""\n    weights, bias = get_lastlayer_params(net)\n    writer.add_scalar(\'LastLayerGradients/grad_norm2_weights\', weights.grad.norm(), n_iter)\n    writer.add_scalar(\'LastLayerGradients/grad_norm2_bias\', bias.grad.norm(), n_iter)\n\ndef visualize_train_loss(writer, loss, n_iter):\n    """"""visualize training loss""""""\n    writer.add_scalar(\'Train/loss\', loss, n_iter)\n\ndef visualize_param_hist(writer, net, epoch):\n    """"""visualize histogram of params""""""\n    for name, param in net.named_parameters():\n        layer, attr = os.path.splitext(name)\n        attr = attr[1:]\n        writer.add_histogram(""{}/{}"".format(layer, attr), param, epoch)\n\ndef visualize_test_loss(writer, loss, epoch):\n    """"""visualize test loss""""""\n    writer.add_scalar(\'Test/loss\', loss, epoch)\n\ndef visualize_test_acc(writer, acc, epoch):\n    """"""visualize test acc""""""\n    writer.add_scalar(\'Test/Accuracy\', acc, epoch)\n\ndef visualize_learning_rate(writer, lr, epoch):\n    """"""visualize learning rate""""""\n    writer.add_scalar(\'Train/LearningRate\', lr, epoch)\n\ndef init_weights(net):\n    """"""the weights of conv layer and fully connected layers \n    are both initilized with Xavier algorithm, In particular,\n    we set the parameters to random values uniformly drawn from [-a, a]\n    where a = sqrt(6 * (din + dout)), for batch normalization \n    layers, y=1, b=0, all bias initialized to 0.\n    """"""\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            nn.init.xavier_uniform_(m.weight)\n            #nn.init.kaiming_normal_(m.weight, mode=\'fan_out\', nonlinearity=\'relu\')\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n            \n        elif isinstance(m, nn.BatchNorm2d):\n            nn.init.constant_(m.weight, 1)\n            nn.init.constant_(m.bias, 0)\n        \n        elif isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n\n    return net\n\ndef split_weights(net):\n    """"""split network weights into to categlories,\n    one are weights in conv layer and linear layer,\n    others are other learnable paramters(conv bias, \n    bn weights, bn bias, linear bias)\n\n    Args:\n        net: network architecture\n    \n    Returns:\n        a dictionary of params splite into to categlories\n    """"""\n\n    decay = []\n    no_decay = []\n\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n            decay.append(m.weight)\n\n            if m.bias is not None:\n                no_decay.append(m.bias)\n        \n        else: \n            if hasattr(m, \'weight\'):\n                no_decay.append(m.weight)\n            if hasattr(m, \'bias\'):\n                no_decay.append(m.bias)\n        \n    assert len(list(net.parameters())) == len(decay) + len(no_decay)\n\n    return [dict(params=decay), dict(params=no_decay, weight_decay=0)]\n\ndef mixup_data(x, y, alpha=0.2):\n\n    """"""Returns mixed up inputs pairs of targets and lambda""""""\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    \n    batch_size = x.size(0)\n    index = torch.randperm(batch_size)\n    index = index.to(x.device)\n\n    lam = max(lam, 1 - lam)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n\n    y_a = y\n    y_b = y[index, :]\n\n    return mixed_x, y_a, y_b, lam\n\n\n\n    '"
conf/__init__.py,0,"b'"""""" dynamically load settings\nauthor baiyu\n""""""\n\nimport conf.settings as settings\n\n\nclass Settings:\n    def __init__(self, settings):\n        for attr in dir(settings):\n            if attr.isupper():\n                setattr(self, attr, getattr(settings, attr))\n\nsettings = Settings(settings)\n\n'"
conf/settings.py,0,"b""\n#TRAIN_PATH = '/Users/didi/Downloads/train'\n#LABEL_PATH = '/Users/didi/Downloads/'\n\n#TRAIN_STD = [0.2648431067741028, 0.2606256902653438, 0.26538460981082046]\n#TRAIN_MEAN = [0.39091378793393816, 0.45037754368027466, 0.47364248847284746]\n\nfrom datetime import datetime\n\n\n#cv2\n#TRAIN_MEAN = [0.43237713785804116, 0.49941626449353244, 0.48560741861744905]\n#TRAIN_STD = [0.2665100547329813, 0.22770540015765814, 0.2321024260764962]\n\nTRAIN_MEAN = [0.48560741861744905, 0.49941626449353244, 0.43237713785804116]\nTRAIN_STD = [0.2321024260764962, 0.22770540015765814, 0.2665100547329813]\n\n#TEST_MEAN = [0.4311430419332438, 0.4998156522834164, 0.4862169586881995]\n#TEST_STD = [0.26667253517177186, 0.22781080253662814, 0.23264268069040475]\n\nTEST_MEAN = [0.4862169586881995, 0.4998156522834164, 0.4311430419332438]\nTEST_STD = [0.23264268069040475, 0.22781080253662814, 0.26667253517177186]\n\n#DATA_PATH = '/nfs/cold_project/baiyu/Caltech-UCSD Birds-200-2011/CUB_200_2011'\nDATA_PATH = '/nfs/project/baiyu/CUB200_2011/CUB_200_2011'\n\n#MILESTONES = [100, 130, 160]\nMILESTONES = [300, 350, 400]\n\n#weights file directory\nCHECKPOINT_PATH = 'checkpoints'\n\nTIME_NOW = datetime.now().isoformat()\n\n#tensorboard log file directory\nLOG_DIR = 'runs'\n\n#save weights file per SAVE_EPOCH epoch\nSAVE_EPOCH = 10\n\n#input image size for network\nIMAGE_SIZE = 224\n\n\n\n"""
criterion/FocalLoss.py,1,b'\n\nimport torch\nimport torch.nn as nn\n\n'
criterion/LabelSmoothing.py,6,"b'\nimport torch\nimport torch.nn as nn\n\n\nclass LSR(nn.Module):\n\n    def __init__(self, e=0.1, reduction=\'mean\'):\n        super().__init__()\n\n        self.log_softmax = nn.LogSoftmax(dim=1)\n        self.e = e\n        self.reduction = reduction\n    \n    def _one_hot(self, labels, classes, value=1):\n        """"""\n            Convert labels to one hot vectors\n        \n        Args:\n            labels: torch tensor in format [label1, label2, label3, ...]\n            classes: int, number of classes\n            value: label value in one hot vector, default to 1\n        \n        Returns:\n            return one hot format labels in shape [batchsize, classes]\n        """"""\n\n        one_hot = torch.zeros(labels.size(0), classes)\n\n        #labels and value_added  size must match\n        labels = labels.view(labels.size(0), -1)\n        value_added = torch.Tensor(labels.size(0), 1).fill_(value)\n\n        value_added = value_added.to(labels.device)\n        one_hot = one_hot.to(labels.device)\n\n        one_hot.scatter_add_(1, labels, value_added)\n\n        return one_hot\n\n    def _smooth_label(self, target, length, smooth_factor):\n        """"""convert targets to one-hot format, and smooth\n        them.\n\n        Args:\n            target: target in form with [label1, label2, label_batchsize]\n            length: length of one-hot format(number of classes)\n            smooth_factor: smooth factor for label smooth\n        \n        Returns:\n            smoothed labels in one hot format\n        """"""\n        one_hot = self._one_hot(target, length, value=1 - smooth_factor)\n        one_hot += smooth_factor / length\n\n        return one_hot.to(target.device)\n\n    def forward(self, x, target):\n\n        if x.size(0) != target.size(0):\n            raise ValueError(\'Expected input batchsize ({}) to match target batch_size({})\'\n                    .format(x.size(0), target.size(0)))\n\n        if x.dim() < 2:\n            raise ValueError(\'Expected input tensor to have least 2 dimensions(got {})\'\n                    .format(x.size(0)))\n\n        if x.dim() != 2:\n            raise ValueError(\'Only 2 dimension tensor are implemented, (got {})\'\n                    .format(x.size()))\n\n\n        smoothed_target = self._smooth_label(target, x.size(1), self.e)\n        x = self.log_softmax(x)\n        loss = torch.sum(- x * smoothed_target, dim=1)\n\n        if self.reduction == \'none\':\n            return loss\n        \n        elif self.reduction == \'sum\':\n            return torch.sum(loss)\n        \n        elif self.reduction == \'mean\':\n            return torch.mean(loss)\n        \n        else:\n            raise ValueError(\'unrecognized option, expect reduction to be one of none, mean, sum\')\n\n'"
criterion/__init__.py,0,b'\nfrom .LabelSmoothing import LSR'
dataset/dataset.py,1,"b'\nimport os\n\nimport cv2\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\nclass CUB_200_2011_Train(Dataset):\n\n    def __init__(self, path, transform=None, target_transform=None):\n\n        self.root = path\n        self.transform = transform\n        self.target_transform = target_transform\n        self.images_path = {}\n        with open(os.path.join(self.root, \'images.txt\')) as f:\n            for line in f:\n                image_id, path = line.split()\n                self.images_path[image_id] = path\n\n        self.class_ids = {}\n        with open(os.path.join(self.root, \'image_class_labels.txt\')) as f:\n            for line in f:\n                image_id, class_id = line.split()\n                self.class_ids[image_id] = class_id\n        \n        self.train_id = []\n        with open(os.path.join(self.root, \'train_test_split.txt\')) as f:\n            for line in f:\n                image_id, is_train = line.split()\n                if int(is_train):\n                    self.train_id.append(image_id)\n\n    def __len__(self):\n        return len(self.train_id)\n    \n    def __getitem__(self, index):\n        """"""\n        Args:\n            index: index of training dataset\n        Returns:\n            image and its corresponding label\n        """"""\n        image_id = self.train_id[index]\n        class_id = int(self._get_class_by_id(image_id)) - 1\n        path = self._get_path_by_id(image_id)\n        image = cv2.imread(os.path.join(self.root, \'images\', path))\n        #image = Image.open(os.path.join(self.root, \'images\', path))\n        #if image.mode != \'RGB\':\n        #    image = image.convert(\'RGB\')\n        #if len(image.shape) != 3:\n        #    image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n        #image = np.array(image)\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.target_transform:\n            class_id = self.target_transform(class_id)\n        return image, class_id\n\n    def _get_path_by_id(self, image_id):\n\n        return self.images_path[image_id]\n    \n    def _get_class_by_id(self, image_id):\n\n        return self.class_ids[image_id]\n\n\nclass CUB_200_2011_Test(Dataset):\n\n    def __init__(self, path, transform=None, target_transform=None):\n\n        self.root = path\n        self.transform = transform\n        self.target_transform = target_transform\n        self.images_path = {}\n        with open(os.path.join(self.root, \'images.txt\')) as f:\n            for line in f:\n                image_id, path = line.split()\n                self.images_path[image_id] = path\n\n        self.class_ids = {}\n        with open(os.path.join(self.root, \'image_class_labels.txt\')) as f:\n            for line in f:\n                image_id, class_id = line.split()\n                self.class_ids[image_id] = class_id\n        \n        self.train_id = []\n        with open(os.path.join(self.root, \'train_test_split.txt\')) as f:\n            for line in f:\n                image_id, is_train = line.split()\n                if not int(is_train):\n                    self.train_id.append(image_id)\n\n    def __len__(self):\n        return len(self.train_id)\n    \n    def __getitem__(self, index):\n        """"""\n        Args:\n            index: index of training dataset\n        Returns:\n            image and its corresponding label\n        """"""\n        image_id = self.train_id[index]\n        class_id = int(self._get_class_by_id(image_id)) - 1\n        path = self._get_path_by_id(image_id)\n        image = cv2.imread(os.path.join(self.root, \'images\', path))\n        #image = Image.open(os.path.join(self.root, \'images\', path))\n        #if image.mode != \'RGB\':\n        #    image = image.convert(\'RGB\')\n        #image = np.array(image)\n\n\n        #if len(image.shape) != 3:\n        #    image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.target_transform:\n            class_id = self.target_transform(class_id)\n\n        return image, class_id\n\n    def _get_path_by_id(self, image_id):\n\n        return self.images_path[image_id]\n    \n    def _get_class_by_id(self, image_id):\n\n        return self.class_ids[image_id]\n\n\ndef compute_mean_and_std(dataset):\n    """"""Compute dataset mean and std, and normalize it\n\n    Args:\n        dataset: instance of CUB_200_2011_Train, CUB_200_2011_Test\n    \n    Returns:\n        return: mean and std of this dataset\n    """"""\n\n    mean_r = 0\n    mean_g = 0\n    mean_b = 0\n\n    for img, _ in dataset:\n        mean_b += np.mean(img[:, :, 0])\n        mean_g += np.mean(img[:, :, 1])\n        mean_r += np.mean(img[:, :, 2])\n\n    mean_b /= len(dataset)\n    mean_g /= len(dataset)\n    mean_r /= len(dataset)\n\n    diff_r = 0\n    diff_g = 0\n    diff_b = 0\n\n    N = 0\n\n    for img, _ in dataset:\n\n        diff_b += np.sum(np.power(img[:, :, 0] - mean_b, 2))\n        diff_g += np.sum(np.power(img[:, :, 1] - mean_g, 2))\n        diff_r += np.sum(np.power(img[:, :, 2] - mean_r, 2))\n\n        N += np.prod(img[:, :, 0].shape)\n\n    std_b = np.sqrt(diff_b / N)\n    std_g = np.sqrt(diff_g / N)\n    std_r = np.sqrt(diff_r / N)\n\n    mean = (mean_b.item() / 255.0, mean_g.item() / 255.0, mean_r.item() / 255.0)\n    std = (std_b.item() / 255.0, std_g.item() / 255.0, std_r.item() / 255.0)\n    return mean, std\n'"
lr_scheduler/FindLR.py,1,"b'\nimport torch\nfrom torch.optim.lr_scheduler import _LRScheduler\n\n\nclass FindLR(_LRScheduler):\n    """"""exponentially increasing learning rate\n\n    Args:\n        optimizer: optimzier(e.g. SGD)\n        num_iter: totoal_iters \n        max_lr: maximum  learning rate\n    """"""\n    def __init__(self, optimizer, max_lr=10, num_iter=100, last_epoch=-1):\n        \n        self.total_iters = num_iter\n        self.max_lr = max_lr\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n\n        return [base_lr * (self.max_lr / base_lr) ** (self.last_epoch / (self.total_iters + 1e-32)) for base_lr in self.base_lrs]\n\n'"
lr_scheduler/WarmUpLR.py,1,"b'\nimport torch\nfrom torch.optim.lr_scheduler import _LRScheduler\n\n\nclass WarmUpLR(_LRScheduler):\n    """"""warmup_training learning rate scheduler\n\n    Args:\n        optimizer: optimzier(e.g. SGD)\n        total_iters: totoal_iters of warmup phase\n    """"""\n    def __init__(self, optimizer, total_iters, last_epoch=-1):\n        \n        self.total_iters = total_iters\n        super().__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        """"""we will use the first m batches, and set the learning\n        rate to base_lr * m / total_iters\n        """"""\n        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n\n\n'"
lr_scheduler/__init__.py,0,b'\nfrom .WarmUpLR import WarmUpLR\nfrom .FindLR import FindLR'
models/vgg.py,1,"b'""""""[1] Simonyan, Karen, and Andrew Zisserman. \xe2\x80\x9cVery Deep Convolutional \n       Networks for Large-Scale Image Recognition.\xe2\x80\x9d International Conference\n       on Learning Representations, 2015.""""""\n\n\nimport torch\nimport torch.nn as nn\n\nclass BasicConv(nn.Module):\n\n    def __init__(self, input_channels, output_channels, kernel_size, **kwargs):\n        super().__init__()\n        self.conv = nn.Conv2d(input_channels, output_channels, kernel_size, **kwargs)\n        self.bn = nn.BatchNorm2d(output_channels)\n        self.relu = nn.ReLU(inplace=True)\n    \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n\n        return x\n\nclass VGG(nn.Module):\n\n    def __init__(self, blocks, num_class=200):\n        super().__init__()\n        self.input_channels = 3\n        self.conv1 = self._make_layers(64, blocks[0])\n        self.conv2 = self._make_layers(128, blocks[1])\n        self.conv3 = self._make_layers(256, blocks[2])\n        self.conv4 = self._make_layers(512, blocks[3])\n        self.conv5 = self._make_layers(512, blocks[4])\n    \n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, num_class)\n        )\n\n    def forward(self, x):\n\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n\n        return x\n\n    def _make_layers(self, output_channels, layer_num):\n        layers = []\n        while layer_num:\n            layers.append(\n                BasicConv(\n                    self.input_channels, \n                    output_channels, \n                    kernel_size=3, \n                    padding=1, \n                    bias=False\n                )\n            )\n            self.input_channels = output_channels\n            layer_num -= 1\n        layers.append(nn.MaxPool2d(2, stride=2))\n\n        return nn.Sequential(*layers)\n\ndef vgg11():\n    return VGG([1, 1, 2, 2, 2])\n\ndef vgg13():\n    return VGG([2, 2, 2, 2, 2])\n\ndef vgg16():\n    return VGG([2, 2, 3, 3, 3])\n\ndef vgg19():\n    return VGG([2, 2, 4, 4, 4])\n'"
transforms/__init__.py,0,"b'\nfrom .transforms import (\n    CenterCrop,\n    ColorJitter,\n    Compose,\n    CutOut,\n    Normalize,\n    RandomHorizontalFlip,\n    RandomResizedCrop,\n    RandomErasing,\n    ToTensor,\n    ToCVImage\n)'"
transforms/transforms.py,4,"b'\nimport random\nimport math\nimport numbers\n\nimport cv2\nimport numpy as np\n\nimport torch\n\nclass Compose:\n    """"""Composes several transforms together.\n\n    Args:\n        transforms(list of \'Transform\' object): list of transforms to compose\n\n    """"""    \n\n    def __init__(self, transforms):\n        self.transforms = transforms\n    \n    def __call__(self, img):\n\n        for trans in self.transforms:\n            img = trans(img)\n        \n        return img\n    \n    def __repr__(self):\n        format_string = self.__class__.__name__ + \'(\'\n        for t in self.transforms:\n            format_string += \'\\n\'\n            format_string += \'    {0}\'.format(t)\n        format_string += \'\\n)\'\n        return format_string\n\n\nclass ToCVImage:\n    """"""Convert an Opencv image to a 3 channel uint8 image\n    """"""\n\n    def __call__(self, image):\n        """"""\n        Args:\n            image (numpy array): Image to be converted to 32-bit floating point\n        \n        Returns:\n            image (numpy array): Converted Image\n        """"""\n        if len(image.shape) == 2:\n            image = cv2.cvtColor(iamge, cv2.COLOR_GRAY2BGR)\n        \n        image = image.astype(\'uint8\')\n            \n        return image\n\n\nclass RandomResizedCrop:\n    """"""Randomly crop a rectangle region whose aspect ratio is randomly sampled \n    in [3/4, 4/3] and area randomly sampled in [8%, 100%], then resize the cropped\n    region into a 224-by-224 square image.\n\n    Args:\n        size: expected output size of each edge\n        scale: range of size of the origin size cropped\n        ratio: range of aspect ratio of the origin aspect ratio cropped (w / h)\n        interpolation: Default: cv2.INTER_LINEAR: \n    """"""\n\n    def __init__(self, size, scale=(0.08, 1.0), ratio=(3.0 / 4.0, 4.0 / 3.0), interpolation=\'linear\'):\n\n        self.methods={\n            ""area"":cv2.INTER_AREA, \n            ""nearest"":cv2.INTER_NEAREST, \n            ""linear"" : cv2.INTER_LINEAR, \n            ""cubic"" : cv2.INTER_CUBIC, \n            ""lanczos4"" : cv2.INTER_LANCZOS4\n        }\n\n        self.size = (size, size)\n        self.interpolation = self.methods[interpolation]\n        self.scale = scale\n        self.ratio = ratio\n\n    def __call__(self, img):\n        h, w, _ = img.shape\n\n        area = w * h\n\n        for attempt in range(10):\n            target_area = random.uniform(*self.scale) * area\n            target_ratio = random.uniform(*self.ratio) \n\n            output_h = int(round(math.sqrt(target_area * target_ratio)))\n            output_w = int(round(math.sqrt(target_area / target_ratio))) \n\n            if random.random() < 0.5:\n                output_w, output_h = output_h, output_w \n\n            if output_w <= w and output_h <= h:\n                topleft_x = random.randint(0, w - output_w)\n                topleft_y = random.randint(0, h - output_h)\n                break\n\n        if output_w > w or output_h > h:\n            output_w = min(w, h)\n            output_h = output_w\n            topleft_x = random.randint(0, w - output_w) \n            topleft_y = random.randint(0, h - output_w)\n\n        cropped = img[topleft_y : topleft_y + output_h, topleft_x : topleft_x + output_w]\n\n        resized = cv2.resize(cropped, self.size, interpolation=self.interpolation)\n\n        return resized\n    \n    def __repr__(self):\n        for name, inter in self.methods.items():\n            if inter == self.interpolation:\n                inter_name = name\n\n        interpolate_str = inter_name\n        format_str = self.__class__.__name__ + \'(size={0}\'.format(self.size)\n        format_str += \', scale={0}\'.format(tuple(round(s, 4) for s in self.scale))\n        format_str += \', ratio={0}\'.format(tuple(round(r, 4) for r in self.ratio))\n        format_str += \', interpolation={0})\'.format(interpolate_str)\n\n        return format_str\n\n\nclass RandomHorizontalFlip:\n    """"""Horizontally flip the given opencv image with given probability p.\n\n    Args:\n        p: probability of the image being flipped\n    """"""\n    def __init__(self, p=0.5):\n        self.p = p\n    \n    def __call__(self, img):\n        """"""\n        Args:\n            the image to be flipped\n        Returns:\n            flipped image\n        """"""\n        if random.random() < self.p:\n            img = cv2.flip(img, 1)\n        \n        return img\n\nclass ColorJitter:\n\n    """"""Randomly change the brightness, contrast and saturation of an image\n\n    Args:\n        brightness: (float or tuple of float(min, max)): how much to jitter\n            brightness, brightness_factor is choosen uniformly from[max(0, 1-brightness),\n            1 + brightness] or the given [min, max], Should be non negative numbe\n        contrast: same as brightness\n        saturation: same as birghtness\n        hue: same as brightness\n    """"""        \n\n    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0):\n        self.brightness = self._check_input(brightness)\n        self.contrast = self._check_input(contrast)\n        self.saturation = self._check_input(saturation)\n        self.hue = self._check_input(hue)\n\n    def _check_input(self, value):\n\n        if isinstance(value, numbers.Number):\n            assert value >= 0, \'value should be non negative\'\n            value = [max(0, 1 - value), 1 + value]\n        \n        elif isinstance(value, (list, tuple)):\n            assert len(value) == 2, \'brightness should be a tuple/list with 2 elements\'\n            assert 0 <= value[0] <= value[1], \'max should be larger than or equal to min,\\\n            and both larger than 0\'\n\n        else:\n            raise TypeError(\'need to pass int, float, list or tuple, instead got{}\'.format(type(value).__name__))\n\n        return value\n\n    def __call__(self, img):\n        """"""\n        Args:\n            img to be jittered\n        Returns:\n            jittered img\n        """"""\n\n        img_dtype = img.dtype\n        h_factor = random.uniform(*self.hue)\n        b_factor = random.uniform(*self.brightness)\n        s_factor = random.uniform(*self.saturation)\n        c_factor = random.uniform(*self.contrast)\n\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n        img = img.astype(\'float32\')\n\n        #h\n        img[:, :, 0] *= h_factor\n        img[:, :, 0] = np.clip(img[:, :, 0], 0, 179)\n\n        #s\n        img[:, :, 1] *= s_factor\n        img[:, :, 1] = np.clip(img[:, :, 1], 0, 255)\n\n        #v\n        img[:, :, 2] *= b_factor\n        img[:, :, 2] = np.clip(img[:, :, 2], 0, 255)\n\n        img = img.astype(img_dtype)\n        img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n\n        #c\n        img = img * c_factor\n        img = img.astype(img_dtype)\n        img = np.clip(img, 0, 255)\n\n        return img\n\nclass ToTensor:\n    """"""convert an opencv image (h, w, c) ndarray range from 0 to 255 to a pytorch \n    float tensor (c, h, w) ranged from 0 to 1\n    """"""\n\n    def __call__(self, img):\n        """"""\n        Args:\n            a numpy array (h, w, c) range from [0, 255]\n        \n        Returns:\n            a pytorch tensor\n        """"""\n        #convert format H W C to C H W\n        img = img.transpose(2, 0, 1)\n        img = torch.from_numpy(img)\n        img = img.float() / 255.0\n\n        return img\n\nclass Normalize:\n    """"""Normalize a torch tensor (H, W, BGR order) with mean and standard deviation\n    \n    for each channel in torch tensor:\n        ``input[channel] = (input[channel] - mean[channel]) / std[channel]``\n\n    Args:\n        mean: sequence of means for each channel\n        std: sequence of stds for each channel\n    """"""\n\n    def __init__(self, mean, std, inplace=False):\n        self.mean = mean\n        self.std = std\n        self.inplace = inplace\n    \n    def __call__(self, img):\n        """"""\n        Args:\n            (H W C) format numpy array range from [0, 255]\n        Returns:\n            (H W C) format numpy array in float32 range from [0, 1]\n        """"""        \n        assert torch.is_tensor(img) and img.ndimension() == 3, \'not an image tensor\'\n\n        if not self.inplace:\n            img = img.clone()\n\n        mean = torch.tensor(self.mean, dtype=torch.float32)\n        std = torch.tensor(self.std, dtype=torch.float32)\n        img.sub_(mean[:, None, None]).div_(std[:, None, None])\n\n        return img\n\nclass CenterCrop:\n    """"""resize each image\xe2\x80\x99s shorter edge to r pixels while keeping its aspect ratio. \n    Next, we crop out the cropped region in the center \n    Args:\n        resized: resize image\' shorter edge to resized pixels while keeping the aspect ratio\n        cropped: output image size(h, w), if cropped is an int, then output cropped * cropped size\n                 image\n    """"""\n\n    def __init__(self, cropped, resized=256, interpolation=\'linear\'):\n\n        methods = {\n            ""area"":cv2.INTER_AREA, \n            ""nearest"":cv2.INTER_NEAREST, \n            ""linear"" : cv2.INTER_LINEAR, \n            ""cubic"" : cv2.INTER_CUBIC, \n            ""lanczos4"" : cv2.INTER_LANCZOS4\n        }\n        self.interpolation = methods[interpolation]\n\n        self.resized = resized\n\n        if isinstance(cropped, numbers.Number):\n            cropped = (cropped, cropped)\n        \n        self.cropped = cropped\n\n    def __call__(self, img):\n\n        shorter = min(*img.shape[:2])\n\n        scaler = float(self.resized) / shorter\n\n        img = cv2.resize(img, (0, 0), fx=scaler, fy=scaler, interpolation=self.interpolation)\n\n        h, w, _ = img.shape\n\n        topleft_x = int((w - self.cropped[1]) / 2)\n        topleft_y = int((h - self.cropped[0]) / 2)\n\n        center_cropped = img[topleft_y : topleft_y + self.cropped[0], \n                             topleft_x : topleft_x + self.cropped[1]]\n\n        return center_cropped\n\nclass RandomErasing:\n    """"""Random erasing the an rectangle region in Image.\n    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al.\n\n    Args:\n        sl: min erasing area region \n        sh: max erasing area region\n        r1: min aspect ratio range of earsing region\n        p: probability of performing random erasing\n    """"""\n\n    def __init__(self, p=0.5, sl=0.02, sh=0.4, r1=0.3):\n\n        self.p = p\n        self.s = (sl, sh)\n        self.r = (r1, 1/r1)\n    \n\n    def __call__(self, img):\n        """"""\n        perform random erasing\n        Args:\n            img: opencv numpy array in form of [w, h, c] range \n                 from [0, 255]\n        \n        Returns:\n            erased img\n        """"""\n\n        assert len(img.shape) == 3, \'image should be a 3 dimension numpy array\'\n\n        if random.random() > self.p:\n            return img\n        \n        else:\n            while True:\n                Se = random.uniform(*self.s) * img.shape[0] * img.shape[1]\n                re = random.uniform(*self.r) \n\n                He = int(round(math.sqrt(Se * re)))\n                We = int(round(math.sqrt(Se / re)))\n\n                xe = random.randint(0, img.shape[1])\n                ye = random.randint(0, img.shape[0])\n\n                if xe + We <= img.shape[1] and ye + He <= img.shape[0]:\n                    img[ye : ye + He, xe : xe + We, :] = np.random.randint(low=0, high=255, size=(He, We, img.shape[2]))\n\n                    return img\n\nclass CutOut:\n    """"""Randomly mask out one or more patches from an image. An image\n    is a opencv format image (h,w,c numpy array)\n\n    Args:\n        n_holes (int): Number of patches to cut out of each image.\n        length (int): The length (in pixels) of each square patch.\n    """"""\n\n    def __init__(self, length, n_holes=1):\n        self.n_holes = n_holes\n        self.length = length\n    \n    def __call__(self, img):\n\n        while self.n_holes:\n\n            y = random.randint(0, img.shape[0] - 1)\n            x = random.randint(0, img.shape[1] - 1)\n\n            tl_x = int(max(0, x - self.length / 2))\n            tl_y = int(max(0, y - self.length / 2))\n\n            img[tl_y : tl_y + self.length, tl_x : tl_x + self.length, :] = 0\n\n            self.n_holes -= 1\n        \n        return img\n\n\n'"
