file_path,api_count,code
main.py,8,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom __future__ import print_function, absolute_import, division\n\nimport os\nimport sys\nimport time\nfrom pprint import pprint\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\n\nfrom opt import Options\nfrom src.procrustes import get_transformation\nimport src.data_process as data_process\nfrom src import Bar\nimport src.utils as utils\nimport src.misc as misc\nimport src.log as log\n\nfrom src.model import LinearModel, weight_init\nfrom src.datasets.human36m import Human36M\n\n\ndef main(opt):\n    start_epoch = 0\n    err_best = 1000\n    glob_step = 0\n    lr_now = opt.lr\n\n    # save options\n    log.save_options(opt, opt.ckpt)\n\n    # create model\n    print("">>> creating model"")\n    model = LinearModel()\n    model = model.cuda()\n    model.apply(weight_init)\n    print("">>> total params: {:.2f}M"".format(sum(p.numel() for p in model.parameters()) / 1000000.0))\n    criterion = nn.MSELoss(size_average=True).cuda()\n    optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n\n    # load ckpt\n    if opt.load:\n        print("">>> loading ckpt from \'{}\'"".format(opt.load))\n        ckpt = torch.load(opt.load)\n        start_epoch = ckpt[\'epoch\']\n        err_best = ckpt[\'err\']\n        glob_step = ckpt[\'step\']\n        lr_now = ckpt[\'lr\']\n        model.load_state_dict(ckpt[\'state_dict\'])\n        optimizer.load_state_dict(ckpt[\'optimizer\'])\n        print("">>> ckpt loaded (epoch: {} | err: {})"".format(start_epoch, err_best))\n    if opt.resume:\n        logger = log.Logger(os.path.join(opt.ckpt, \'log.txt\'), resume=True)\n    else:\n        logger = log.Logger(os.path.join(opt.ckpt, \'log.txt\'))\n        logger.set_names([\'epoch\', \'lr\', \'loss_train\', \'loss_test\', \'err_test\'])\n\n    # list of action(s)\n    actions = misc.define_actions(opt.action)\n    num_actions = len(actions)\n    print("">>> actions to use (total: {}):"".format(num_actions))\n    pprint(actions, indent=4)\n    print("">>>"")\n\n    # data loading\n    print("">>> loading data"")\n    # load statistics data\n    stat_3d = torch.load(os.path.join(opt.data_dir, \'stat_3d.pth.tar\'))\n    # test\n    if opt.test:\n        err_set = []\n        for action in actions:\n            print ("">>> TEST on _{}_"".format(action))\n            test_loader = DataLoader(\n                dataset=Human36M(actions=action, data_path=opt.data_dir, use_hg=opt.use_hg, is_train=False),\n                batch_size=opt.test_batch,\n                shuffle=False,\n                num_workers=opt.job,\n                pin_memory=True)\n            _, err_test = test(test_loader, model, criterion, stat_3d, procrustes=opt.procrustes)\n            err_set.append(err_test)\n        print ("">>>>>> TEST results:"")\n        for action in actions:\n            print (""{}"".format(action), end=\'\\t\')\n        print (""\\n"")\n        for err in err_set:\n            print (""{:.4f}"".format(err), end=\'\\t\')\n        print ("">>>\\nERRORS: {}"".format(np.array(err_set).mean()))\n        sys.exit()\n\n    # load dadasets for training\n    test_loader = DataLoader(\n        dataset=Human36M(actions=actions, data_path=opt.data_dir, use_hg=opt.use_hg, is_train=False),\n        batch_size=opt.test_batch,\n        shuffle=False,\n        num_workers=opt.job,\n        pin_memory=True)\n    train_loader = DataLoader(\n        dataset=Human36M(actions=actions, data_path=opt.data_dir, use_hg=opt.use_hg),\n        batch_size=opt.train_batch,\n        shuffle=True,\n        num_workers=opt.job,\n        pin_memory=True)\n    print("">>> data loaded !"")\n\n    cudnn.benchmark = True\n    for epoch in range(start_epoch, opt.epochs):\n        print(\'==========================\')\n        print(\'>>> epoch: {} | lr: {:.5f}\'.format(epoch + 1, lr_now))\n\n        # per epoch\n        glob_step, lr_now, loss_train = train(\n            train_loader, model, criterion, optimizer,\n            lr_init=opt.lr, lr_now=lr_now, glob_step=glob_step, lr_decay=opt.lr_decay, gamma=opt.lr_gamma,\n            max_norm=opt.max_norm)\n        loss_test, err_test = test(test_loader, model, criterion, stat_3d, procrustes=opt.procrustes)\n\n        # update log file\n        logger.append([epoch + 1, lr_now, loss_train, loss_test, err_test],\n                      [\'int\', \'float\', \'float\', \'flaot\', \'float\'])\n\n        # save ckpt\n        is_best = err_test < err_best\n        err_best = min(err_test, err_best)\n        if is_best:\n            log.save_ckpt({\'epoch\': epoch + 1,\n                           \'lr\': lr_now,\n                           \'step\': glob_step,\n                           \'err\': err_best,\n                           \'state_dict\': model.state_dict(),\n                           \'optimizer\': optimizer.state_dict()},\n                          ckpt_path=opt.ckpt,\n                          is_best=True)\n        else:\n            log.save_ckpt({\'epoch\': epoch + 1,\n                           \'lr\': lr_now,\n                           \'step\': glob_step,\n                           \'err\': err_best,\n                           \'state_dict\': model.state_dict(),\n                           \'optimizer\': optimizer.state_dict()},\n                          ckpt_path=opt.ckpt,\n                          is_best=False)\n\n    logger.close()\n\n\ndef train(train_loader, model, criterion, optimizer,\n          lr_init=None, lr_now=None, glob_step=None, lr_decay=None, gamma=None,\n          max_norm=True):\n    losses = utils.AverageMeter()\n\n    model.train()\n\n    start = time.time()\n    batch_time = 0\n    bar = Bar(\'>>>\', fill=\'>\', max=len(train_loader))\n\n    for i, (inps, tars) in enumerate(train_loader):\n        glob_step += 1\n        if glob_step % lr_decay == 0 or glob_step == 1:\n            lr_now = utils.lr_decay(optimizer, glob_step, lr_init, lr_decay, gamma)\n        inputs = Variable(inps.cuda())\n        targets = Variable(tars.cuda(async=True))\n\n        outputs = model(inputs)\n\n        # calculate loss\n        optimizer.zero_grad()\n        loss = criterion(outputs, targets)\n        losses.update(loss.item(), inputs.size(0))\n        loss.backward()\n        if max_norm:\n            nn.utils.clip_grad_norm(model.parameters(), max_norm=1)\n        optimizer.step()\n\n        # update summary\n        if (i + 1) % 100 == 0:\n            batch_time = time.time() - start\n            start = time.time()\n\n        bar.suffix = \'({batch}/{size}) | batch: {batchtime:.4}ms | Total: {ttl} | ETA: {eta:} | loss: {loss:.4f}\' \\\n            .format(batch=i + 1,\n                    size=len(train_loader),\n                    batchtime=batch_time * 10.0,\n                    ttl=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg)\n        bar.next()\n\n    bar.finish()\n    return glob_step, lr_now, losses.avg\n\n\ndef test(test_loader, model, criterion, stat_3d, procrustes=False):\n    losses = utils.AverageMeter()\n\n    model.eval()\n\n    all_dist = []\n    start = time.time()\n    batch_time = 0\n    bar = Bar(\'>>>\', fill=\'>\', max=len(test_loader))\n\n    for i, (inps, tars) in enumerate(test_loader):\n        inputs = Variable(inps.cuda())\n        targets = Variable(tars.cuda(async=True))\n\n        outputs = model(inputs)\n\n        # calculate loss\n        outputs_coord = outputs\n        loss = criterion(outputs_coord, targets)\n\n        losses.update(loss.item(), inputs.size(0))\n\n        tars = targets\n\n        # calculate erruracy\n        targets_unnorm = data_process.unNormalizeData(tars.data.cpu().numpy(), stat_3d[\'mean\'], stat_3d[\'std\'], stat_3d[\'dim_use\'])\n        outputs_unnorm = data_process.unNormalizeData(outputs.data.cpu().numpy(), stat_3d[\'mean\'], stat_3d[\'std\'], stat_3d[\'dim_use\'])\n\n        # remove dim ignored\n        dim_use = np.hstack((np.arange(3), stat_3d[\'dim_use\']))\n\n        outputs_use = outputs_unnorm[:, dim_use]\n        targets_use = targets_unnorm[:, dim_use]\n\n        if procrustes:\n            for ba in range(inps.size(0)):\n                gt = targets_use[ba].reshape(-1, 3)\n                out = outputs_use[ba].reshape(-1, 3)\n                _, Z, T, b, c = get_transformation(gt, out, True)\n                out = (b * out.dot(T)) + c\n                outputs_use[ba, :] = out.reshape(1, 51)\n\n        sqerr = (outputs_use - targets_use) ** 2\n\n        distance = np.zeros((sqerr.shape[0], 17))\n        dist_idx = 0\n        for k in np.arange(0, 17 * 3, 3):\n            distance[:, dist_idx] = np.sqrt(np.sum(sqerr[:, k:k + 3], axis=1))\n            dist_idx += 1\n        all_dist.append(distance)\n\n        # update summary\n        if (i + 1) % 100 == 0:\n            batch_time = time.time() - start\n            start = time.time()\n\n        bar.suffix = \'({batch}/{size}) | batch: {batchtime:.4}ms | Total: {ttl} | ETA: {eta:} | loss: {loss:.6f}\' \\\n            .format(batch=i + 1,\n                    size=len(test_loader),\n                    batchtime=batch_time * 10.0,\n                    ttl=bar.elapsed_td,\n                    eta=bar.eta_td,\n                    loss=losses.avg)\n        bar.next()\n\n    all_dist = np.vstack(all_dist)\n    joint_err = np.mean(all_dist, axis=0)\n    ttl_err = np.mean(all_dist)\n    bar.finish()\n    print ("">>> error: {} <<<"".format(ttl_err))\n    return losses.avg, ttl_err\n\n\nif __name__ == ""__main__"":\n    option = Options().parse()\n    main(option)\n'"
opt.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport os\nimport argparse\nfrom pprint import pprint\n\n__all__ = [\'Options\']\n\nactions = [""all"",\n           ""All"",\n           ""Directions"",\n           ""Discussion"",\n           ""Eating"",\n           ""Greeting"",\n           ""Phoning"",\n           ""Photo"",\n           ""Posing"",\n           ""Purchases"",\n           ""Sitting"",\n           ""SittingDown"",\n           ""Smoking"",\n           ""Waiting"",\n           ""WalkDog"",\n           ""Walking"",\n           ""WalkTogether""]\n\n\nclass Options:\n    def __init__(self):\n        self.parser = argparse.ArgumentParser()\n        self.opt = None\n\n    def _initial(self):\n        # ===============================================================\n        #                     General options\n        # ===============================================================\n        self.parser.add_argument(\'--data_dir\',       type=str, default=\'data/\', help=\'path to dataset\')\n        self.parser.add_argument(\'--exp\',            type=str, default=\'test\', help=\'ID of experiment\')\n        self.parser.add_argument(\'--ckpt\',           type=str, default=\'checkpoint/\', help=\'path to save checkpoint\')\n        self.parser.add_argument(\'--load\',           type=str, default=\'\', help=\'path to load a pretrained checkpoint\')\n\n        self.parser.add_argument(\'--test\',           dest=\'test\', action=\'store_true\', help=\'test\')\n        self.parser.add_argument(\'--resume\',         dest=\'resume\', action=\'store_true\', help=\'resume to train\')\n\n        self.parser.add_argument(\'--action\',         type=str, default=\'All\', choices=actions, help=\'All for all actions\')\n\n        # ===============================================================\n        #                     Model options\n        # ===============================================================\n        self.parser.add_argument(\'--max_norm\',       dest=\'max_norm\', action=\'store_true\', help=\'maxnorm constraint to weights\')\n        self.parser.add_argument(\'--linear_size\',    type=int, default=1024, help=\'size of each model layer\')\n        self.parser.add_argument(\'--num_stage\',      type=int, default=2, help=\'# layers in linear model\')\n\n        # ===============================================================\n        #                     Running options\n        # ===============================================================\n        self.parser.add_argument(\'--use_hg\',         dest=\'use_hg\', action=\'store_true\', help=\'whether use 2d pose from hourglass\')\n        self.parser.add_argument(\'--lr\',             type=float,  default=1.0e-3)\n        self.parser.add_argument(\'--lr_decay\',       type=int,    default=100000, help=\'# steps of lr decay\')\n        self.parser.add_argument(\'--lr_gamma\',       type=float,  default=0.96)\n        self.parser.add_argument(\'--epochs\',         type=int,    default=200)\n        self.parser.add_argument(\'--dropout\',        type=float,  default=0.5, help=\'dropout probability, 1.0 to make no dropout\')\n        self.parser.add_argument(\'--train_batch\',    type=int,    default=64)\n        self.parser.add_argument(\'--test_batch\',     type=int,    default=64)\n        self.parser.add_argument(\'--job\',            type=int,    default=8, help=\'# subprocesses to use for data loading\')\n        self.parser.add_argument(\'--no_max\',         dest=\'max_norm\', action=\'store_false\', help=\'if use max_norm clip on grad\')\n        self.parser.add_argument(\'--max\',            dest=\'max_norm\', action=\'store_true\', help=\'if use max_norm clip on grad\')\n        self.parser.set_defaults(max_norm=True)\n        self.parser.add_argument(\'--procrustes\',     dest=\'procrustes\', action=\'store_true\', help=\'use procrustes analysis at testing\')\n\n    def _print(self):\n        print(""\\n==================Options================="")\n        pprint(vars(self.opt), indent=4)\n        print(""==========================================\\n"")\n\n    def parse(self):\n        self._initial()\n        self.opt = self.parser.parse_args()\n        # do some pre-check\n        ckpt = os.path.join(self.opt.ckpt, self.opt.exp)\n        if not os.path.isdir(ckpt):\n            os.makedirs(ckpt)\n        if self.opt.load:\n            if not os.path.isfile(self.opt.load):\n                print (""{} is not found"".format(self.opt.load))\n        self.opt.is_train = False if self.opt.test else True\n        self.opt.ckpt = ckpt\n        self._print()\n        return self.opt\n'"
src/__init__.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport os\nimport sys\n\nsys.path.append(os.path.join(os.path.dirname(__file__), ""progress""))\n\nfrom progress.bar import Bar as Bar\n\n'"
src/camera.py,0,"b'from __future__ import division\n\nimport h5py\nimport numpy as np\n\n\ndef project_point_radial(P, R, T, f, c, k, p):\n    """"""\n    Args\n    P: Nx3 points in world coordinates\n    R: 3x3 Camera rotation matrix\n    T: 3x1 Camera translation parameters\n    f: 2x1 (scalar) Camera focal length\n    c: 2x1 Camera center\n    k: 3x1 Camera radial distortion coefficients\n    p: 2x1 Camera tangential distortion coefficients\n    Returns\n    Proj: Nx2 points in pixel space\n    D: 1xN depth of each point in camera space\n    radial: 1xN radial distortion per point\n    tan: 1xN tangential distortion per point\n    r2: 1xN squared radius of the projected points before distortion\n    """"""\n\n    # P is a matrix of 3-dimensional points\n    assert len(P.shape) == 2\n    assert P.shape[1] == 3\n\n    N = P.shape[0]\n    X = R.dot(P.T - T)  # rotate and translate\n    XX = X[:2, :] / X[2, :]  # 2x16\n    r2 = XX[0, :] ** 2 + XX[1, :] ** 2  # 16,\n\n    radial = 1 + np.einsum(\'ij,ij->j\', np.tile(k, (1, N)), np.array([r2, r2 ** 2, r2 ** 3]))  # 16,\n    tan = p[0] * XX[1, :] + p[1] * XX[0, :]  # 16,\n\n    tm = np.outer(np.array([p[1], p[0]]).reshape(-1), r2)  # 2x16\n\n    XXX = XX * np.tile(radial + tan, (2, 1)) + tm  # 2x16\n\n    Proj = (f * XXX) + c  # 2x16\n    Proj = Proj.T\n\n    D = X[2, ]\n\n    return Proj, D, radial, tan, r2\n\n\ndef world_to_camera_frame(P, R, T):\n    """"""\n    :param P: Nx3 points in world coords\n    :param R: 3x3 camera rotation matrix\n    :param T: 3x1 camera translation params\n    :return: X_cam: Nx3 3d points in camera coords\n    """"""\n\n    assert len(P.shape) == 2\n    assert P.shape[1] == 3\n\n    X_cam = R.dot(P.T - T)  # rotate and translate\n\n    return X_cam.T\n\n\ndef camera_to_world_frame(P, R, T):\n    """"""Inverse of world_to_camera_frame\n\n  Args\n    P: Nx3 points in camera coordinates\n    R: 3x3 Camera rotation matrix\n    T: 3x1 Camera translation parameters\n  Returns\n    X_cam: Nx3 points in world coordinates\n  """"""\n\n    assert len(P.shape) == 2\n    assert P.shape[1] == 3\n\n    X_cam = R.T.dot(P.T) + T  # rotate and translate\n\n    return X_cam.T\n\n\ndef load_camera_params(hf, path):\n    """"""\n    load camera paprameters\n    :param hf:\n    :param path: keys in hf\n    :return:\n        R: 3x3 cam rotation matric\n        T: 3x1 cam translation param\n        f:\n    """"""\n    R = hf[path.format(\'R\')][:]\n    R = R.T\n\n    T = hf[path.format(\'T\')][:]\n    f = hf[path.format(\'f\')][:]\n    c = hf[path.format(\'c\')][:]\n    k = hf[path.format(\'k\')][:]\n    p = hf[path.format(\'p\')][:]\n\n    name = hf[path.format(\'Name\')][:]\n    name = """".join([chr(item) for item in name])\n\n    return R, T, f, c, k, p, name\n\n\ndef load_cameras(bpath=\'cameras.h5\', subjects=None):\n    """"""\n    :param bpath: *.h5\n    :param subjects:\n    :return: (dict)\n    """"""\n\n    if subjects is None:\n        subjects = [1, 5, 6, 7, 8, 9, 11]\n    rcams = {}\n\n    with h5py.File(bpath, \'r\') as hf:\n        for s in subjects:\n            for c in range(4):  # There are 4 cameras in human3.6m\n                a = load_camera_params(hf, \'subject%d/camera%d/{0}\' % (s, c + 1))\n                rcams[(s, c + 1)] = a\n\n    return rcams\n'"
src/data_process.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom __future__ import division\n\nimport numpy as np\n\n\ndef unNormalizeData(normalized_data, data_mean, data_std, dimensions_to_use):\n    T = normalized_data.shape[0]  # Batch size\n    D = data_mean.shape[0]  # 96\n\n    orig_data = np.zeros((T, D), dtype=np.float32)\n\n    orig_data[:, dimensions_to_use] = normalized_data\n\n    # Multiply times stdev and add the mean\n    stdMat = data_std.reshape((1, D))\n    stdMat = np.repeat(stdMat, T, axis=0)\n    meanMat = data_mean.reshape((1, D))\n    meanMat = np.repeat(meanMat, T, axis=0)\n    orig_data = np.multiply(orig_data, stdMat) + meanMat\n    return orig_data\n'"
src/log.py,2,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\n\nimport json\nimport os\nimport torch\n\n\nclass Logger(object):\n    def __init__(self, fpath, title=None, resume=False):\n        self.file = None\n        self.resume = resume\n        self.title = \'\' if not title else title\n        if fpath is not None:\n            if resume:\n                self.file = open(fpath, \'r\')\n                name = self.file.readline()\n                self.names = name.rstrip().split(\'\\t\')\n                self.numbers = {}\n                for _, name in enumerate(self.names):\n                    self.numbers[name] = []\n\n                for numbers in self.file:\n                    numbers = numbers.rstrip().split(\'\\t\')\n                    for i in range(0, len(numbers)):\n                        self.numbers[self.names[i]].append(numbers[i])\n                self.file.close()\n                self.file = open(fpath, \'a\')\n            else:\n                self.file = open(fpath, \'w\')\n\n    def set_names(self, names):\n        if self.resume:\n            pass\n        self.numbers = {}\n        self.names = names\n        for _, name in enumerate(self.names):\n            self.file.write(name)\n            self.file.write(\'\\t\')\n            self.numbers[name] = []\n        self.file.write(\'\\n\')\n        self.file.flush()\n\n    def append(self, member, mem_type):\n        assert len(self.names) == len(member), \'# of data does not match title\'\n        for index, mem in enumerate(member):\n            if mem_type[index] == \'int\':\n                self.file.write(""{}"".format(mem))\n            else:\n                self.file.write(""{0:.5f}"".format(mem))\n            self.file.write(\'\\t\')\n            self.numbers[self.names[index]].append(mem)\n        self.file.write(\'\\n\')\n        self.file.flush()\n\n    def close(self):\n        if self.file:\n            self.file.close()\n\n\ndef save_options(opt, path):\n    file_path = os.path.join(path, \'opt.json\')\n    with open(file_path, \'w\') as f:\n        f.write(json.dumps(vars(opt), sort_keys=True, indent=4))\n\n\ndef save_ckpt(state, ckpt_path, is_best=True):\n    if is_best:\n        file_path = os.path.join(ckpt_path, \'ckpt_best.pth.tar\')\n        torch.save(state, file_path)\n    else:\n        file_path = os.path.join(ckpt_path, \'ckpt_last.pth.tar\')\n        torch.save(state, file_path)\n'"
src/misc.py,0,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n\ndef define_actions(action):\n    """"""\n    :param action: specified action\n    :return: a list of action(s)\n    """"""\n    actions = [""Directions"",\n               ""Discussion"",\n               ""Eating"",\n               ""Greeting"",\n               ""Phoning"",\n               ""Photo"",\n               ""Posing"",\n               ""Purchases"",\n               ""Sitting"",\n               ""SittingDown"",\n               ""Smoking"",\n               ""Waiting"",\n               ""WalkDog"",\n               ""Walking"",\n               ""WalkTogether""]\n\n    if action == ""All"" or action == ""all"":\n        return actions\n\n    if action not in actions:\n        raise (ValueError, ""Unincluded action: {}"".format(action))\n\n    return [action]\n'"
src/model.py,1,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom __future__ import absolute_import\nfrom __future__ import print_function\n\nimport torch.nn as nn\n\n\ndef weight_init(m):\n    if isinstance(m, nn.Linear):\n        nn.init.kaiming_normal(m.weight)\n\n\nclass Linear(nn.Module):\n    def __init__(self, linear_size, p_dropout=0.5):\n        super(Linear, self).__init__()\n        self.l_size = linear_size\n\n        self.relu = nn.ReLU(inplace=True)\n        self.dropout = nn.Dropout(p_dropout)\n\n        self.w1 = nn.Linear(self.l_size, self.l_size)\n        self.batch_norm1 = nn.BatchNorm1d(self.l_size)\n\n        self.w2 = nn.Linear(self.l_size, self.l_size)\n        self.batch_norm2 = nn.BatchNorm1d(self.l_size)\n\n    def forward(self, x):\n        y = self.w1(x)\n        y = self.batch_norm1(y)\n        y = self.relu(y)\n        y = self.dropout(y)\n\n        y = self.w2(y)\n        y = self.batch_norm2(y)\n        y = self.relu(y)\n        y = self.dropout(y)\n\n        out = x + y\n\n        return out\n\n\nclass LinearModel(nn.Module):\n    def __init__(self,\n                 linear_size=1024,\n                 num_stage=2,\n                 p_dropout=0.5):\n        super(LinearModel, self).__init__()\n\n        self.linear_size = linear_size\n        self.p_dropout = p_dropout\n        self.num_stage = num_stage\n\n        # 2d joints\n        self.input_size =  16 * 2\n        # 3d joints\n        self.output_size = 16 * 3\n\n        # process input to linear size\n        self.w1 = nn.Linear(self.input_size, self.linear_size)\n        self.batch_norm1 = nn.BatchNorm1d(self.linear_size)\n\n        self.linear_stages = []\n        for l in range(num_stage):\n            self.linear_stages.append(Linear(self.linear_size, self.p_dropout))\n        self.linear_stages = nn.ModuleList(self.linear_stages)\n\n        # post processing\n        self.w2 = nn.Linear(self.linear_size, self.output_size)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.dropout = nn.Dropout(self.p_dropout)\n\n    def forward(self, x):\n        # pre-processing\n        y = self.w1(x)\n        y = self.batch_norm1(y)\n        y = self.relu(y)\n        y = self.dropout(y)\n\n        # linear layers\n        for i in range(self.num_stage):\n            y = self.linear_stages[i](y)\n\n        y = self.w2(y)\n\n        return y\n'"
src/procrustes.py,0,"b'\nimport numpy as np\n\n\ndef get_transformation(X, Y, compute_optimal_scale=False):\n    muX = X.mean(0)\n    muY = Y.mean(0)\n\n    X0 = X - muX\n    Y0 = Y - muY\n\n    ssX = (X0 ** 2.).sum()\n    ssY = (Y0 ** 2.).sum()\n\n    # centred Frobenius norm\n    normX = np.sqrt(ssX)\n    normY = np.sqrt(ssY)\n\n    # scale to equal (unit) norm\n    X0 = X0 / normX\n    Y0 = Y0 / normY\n\n    # optimum rotation matrix of Y\n    A = np.dot(X0.T, Y0)\n    U, s, Vt = np.linalg.svd(A, full_matrices=False)\n    V = Vt.T\n    T = np.dot(V, U.T)\n\n    # Make sure we have a rotation\n    detT = np.linalg.det(T)\n    V[:, -1] *= np.sign(detT)\n    s[-1] *= np.sign(detT)\n    T = np.dot(V, U.T)\n\n    traceTA = s.sum()\n\n    if compute_optimal_scale:  # Compute optimum scaling of Y.\n        b = traceTA * normX / normY\n        d = 1 - traceTA ** 2\n        Z = normX * traceTA * np.dot(Y0, T) + muX\n    else:  # If no scaling allowed\n        b = 1\n        d = 1 + ssY / ssX - 2 * traceTA * normY / normX\n        Z = normY * np.dot(Y0, T) + muX\n\n    c = muX - b * np.dot(muY, T)\n\n    return d, Z, T, b, c\n'"
src/utils.py,0,"b""#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n\nclass AverageMeter(object):\n    def __init__(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef lr_decay(optimizer, step, lr, decay_step, gamma):\n    lr = lr * gamma ** (step/decay_step)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n    return lr\n"""
src/datasets/__init__.py,0,b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\n'
src/datasets/human36m.py,9,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nfrom __future__ import print_function, absolute_import\n\nimport os\nimport torch\nfrom torch.utils.data import Dataset\n\n\nTRAIN_SUBJECTS = [1, 5, 6, 7, 8]\nTEST_SUBJECTS = [9, 11]\n\n\nclass Human36M(Dataset):\n    def __init__(self, actions, data_path, use_hg=True, is_train=True):\n        """"""\n        :param actions: list of actions to use\n        :param data_path: path to dataset\n        :param use_hg: use stacked hourglass detections\n        :param is_train: load train/test dataset\n        """"""\n\n        self.actions = actions\n        self.data_path = data_path\n\n        self.is_train = is_train\n        self.use_hg = use_hg\n\n        self.train_inp, self.train_out, self.test_inp, self.test_out = [], [], [], []\n        self.train_meta, self.test_meta = [], []\n\n        # loading data\n        if self.use_hg:\n            train_2d_file = \'train_2d_ft.pth.tar\'\n            test_2d_file = \'test_2d_ft.pth.tar\'\n        else:\n            train_2d_file = \'train_2d.pth.tar\'\n            test_2d_file = \'test_2d.pth.tar\'\n\n        if self.is_train:\n            # load train data\n            self.train_3d = torch.load(os.path.join(data_path, \'train_3d.pth.tar\'))\n            self.train_2d = torch.load(os.path.join(data_path, train_2d_file))\n            for k2d in self.train_2d.keys():\n                (sub, act, fname) = k2d\n                k3d = k2d\n                k3d = (sub, act, fname[:-3]) if fname.endswith(\'-sh\') else k3d\n                num_f, _ = self.train_2d[k2d].shape\n                assert self.train_3d[k3d].shape[0] == self.train_2d[k2d].shape[0], \'(training) 3d & 2d shape not matched\'\n                for i in range(num_f):\n                    self.train_inp.append(self.train_2d[k2d][i])\n                    self.train_out.append(self.train_3d[k3d][i])\n\n        else:\n            # load test data\n            self.test_3d = torch.load(os.path.join(data_path, \'test_3d.pth.tar\'))\n            self.test_2d = torch.load(os.path.join(data_path, test_2d_file))\n            for k2d in self.test_2d.keys():\n                (sub, act, fname) = k2d\n                if act not in self.actions:\n                    continue\n                k3d = k2d\n                k3d = (sub, act, fname[:-3]) if fname.endswith(\'-sh\') else k3d\n                num_f, _ = self.test_2d[k2d].shape\n                assert self.test_2d[k2d].shape[0] == self.test_3d[k3d].shape[0], \'(test) 3d & 2d shape not matched\'\n                for i in range(num_f):\n                    self.test_inp.append(self.test_2d[k2d][i])\n                    self.test_out.append(self.test_3d[k3d][i])\n\n    def __getitem__(self, index):\n        if self.is_train:\n            inputs = torch.from_numpy(self.train_inp[index]).float()\n            outputs = torch.from_numpy(self.train_out[index]).float()\n\n        else:\n            inputs = torch.from_numpy(self.test_inp[index]).float()\n            outputs = torch.from_numpy(self.test_out[index]).float()\n\n        return inputs, outputs\n\n    def __len__(self):\n        if self.is_train:\n            return len(self.train_inp)\n        else:\n            return len(self.test_inp)\n'"
