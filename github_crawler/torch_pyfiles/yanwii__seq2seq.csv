file_path,api_count,code
preprocessing.py,0,"b'import jieba\nimport re\n\nclass preprocessing():\n    __PAD__ = 0\n    __GO__ = 1\n    __EOS__ = 2\n    __UNK__ = 3\n    vocab = [\'__PAD__\', \'__GO__\', \'__EOS__\', \'__UNK__\']\n    def __init__(self):\n        #self.encoderFile = ""/home/yanwii/Python/NLP/seq2seq/seq2seq_no_buckets/preprocessing/MySeq2seq/Data/alldata_ask.txt""\n        #self.decoderFile = \'/home/yanwii/Python/NLP/seq2seq/seq2seq_no_buckets/preprocessing/MySeq2seq/Data/alldata_answer.txt\'\n        #self.savePath = \'/home/yanwii/Python/NLP/seq2seq/seq2seq_pytorch/data/\'\n        self.encoderFile = ""./data/question.txt""\n        self.decoderFile = ""./data/answer.txt""\n        self.savePath = \'./data/\'\n        \n        jieba.load_userdict(""./data/supplementvocab.txt"")\n    \n    def wordToVocabulary(self, originFile, vocabFile, segementFile):\n        vocabulary = []\n        sege = open(segementFile, ""w"")\n        with open(originFile, \'r\') as en:\n            for sent in en.readlines():\n                # \xe5\x8e\xbb\xe6\xa0\x87\xe7\x82\xb9\n                if ""enc"" in segementFile:\n                    #sentence = re.sub(""[\\s+\\.\\!\\/_,$%^*(+\\""\\\']+|[+\xe2\x80\x94\xe2\x80\x94\xef\xbc\x81\xef\xbc\x8c\xe3\x80\x82\xe2\x80\x9c\xe2\x80\x9d\xe2\x80\x99\xe2\x80\x98\xef\xbc\x9f?\xe3\x80\x81~@#\xef\xbf\xa5%\xe2\x80\xa6\xe2\x80\xa6&*\xef\xbc\x88\xef\xbc\x89]+"", """", sent.strip())\n                    sentence = sent.strip()\n                    words = jieba.lcut(sentence)\n                    print(words)\n                else:\n                    words = jieba.lcut(sent.strip())\n                vocabulary.extend(words)\n                for word in words:\n                    sege.write(word+"" "")\n                sege.write(""\\n"")\n        sege.close()\n\n        # \xe5\x8e\xbb\xe9\x87\x8d\xe5\xb9\xb6\xe5\xad\x98\xe5\x85\xa5\xe8\xaf\x8d\xe5\x85\xb8\n        vocab_file = open(vocabFile, ""w"")\n        _vocabulary = list(set(vocabulary))\n        _vocabulary.sort(key=vocabulary.index)\n        _vocabulary = self.vocab + _vocabulary\n        for index, word in enumerate(_vocabulary):\n            vocab_file.write(word+""\\n"")\n        vocab_file.close()\n\n    def toVec(self, segementFile, vocabFile, doneFile):\n        word_dicts = {}\n        vec = []\n        with open(vocabFile, ""r"") as dict_f:\n            for index, word in enumerate(dict_f.readlines()):\n                word_dicts[word.strip()] = index\n\n        f = open(doneFile, ""w"")\n        if ""enc.vec"" in doneFile:\n            f.write(""3 3 3 3\\n"")\n            f.write(""3\\n"")\n        elif ""dec.vec"" in doneFile:\n            f.write(str(word_dicts.get(""other"", 3))+""\\n"")\n            f.write(str(word_dicts.get(""other"", 3))+""\\n"")\n        with open(segementFile, ""r"") as sege_f:\n            for sent in sege_f.readlines():\n                sents = [i.strip() for i in sent.split("" "")[:-1]]\n                vec.extend(sents)\n                for word in sents:\n                    f.write(str(word_dicts.get(word))+"" "")\n                f.write(""\\n"")\n        f.close()\n            \n\n    def main(self):\n        # \xe8\x8e\xb7\xe5\xbe\x97\xe5\xad\x97\xe5\x85\xb8\n        self.wordToVocabulary(self.encoderFile, self.savePath+\'enc.vocab\', self.savePath+\'enc.segement\')\n        self.wordToVocabulary(self.decoderFile, self.savePath+\'dec.vocab\', self.savePath+\'dec.segement\')\n        # \xe8\xbd\xac\xe5\x90\x91\xe9\x87\x8f\n        self.toVec(self.savePath+""enc.segement"", \n                   self.savePath+""enc.vocab"", \n                   self.savePath+""enc.vec"")\n        self.toVec(self.savePath+""dec.segement"", \n                   self.savePath+""dec.vocab"", \n                   self.savePath+""dec.vec"")\n\n\nif __name__ == \'__main__\':\n    pre = preprocessing()\n    pre.main()\n'"
seq2seq.py,33,"b'# -*- coding: UTF-8 -*-\nimport math\nimport os\nimport random\nimport sys\nimport time\n\nimport jieba\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.autograd import Variable\n\nUSE_CUDA = torch.cuda.is_available()\nSOS_token = 2\nEOS_token = 1\n\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, n_layers=1):\n        super(EncoderRNN, self).__init__()\n\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.n_layers = n_layers\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n\n    def forward(self, word_inputs, hidden):\n        seq_len = len(word_inputs)\n        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n        output, hidden = self.gru(embedded, hidden)\n        return output, hidden\n\n    def init_hidden(self):\n        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n        if USE_CUDA: hidden = hidden.cuda()\n        return hidden\n\n\nclass Attn(nn.Module):\n    def __init__(self, method, hidden_size, max_length):\n        super(Attn, self).__init__()\n\n        self.method = method\n        self.hidden_size = hidden_size\n\n        if self.method == \'general\':\n            self.attn = nn.Linear(self.hidden_size, hidden_size)\n\n        elif self.method == \'concat\':\n            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n\n    def forward(self, hidden, encoder_outputs):\n        seq_len = len(encoder_outputs)\n\n        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n        if USE_CUDA: attn_energies = attn_energies.cuda()\n\n        for i in range(seq_len):\n            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n\n        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n\n    def score(self, hidden, encoder_output):\n        if self.method == \'dot\':\n            energy = torch.dot(hidden.view(-1), encoder_output.view(-1))\n            return energy\n\n        elif self.method == \'general\':\n            energy = self.attn(encoder_output)\n            energy = torch.dot(hidden.view(-1), encoder_output.view(-1))\n            return energy\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=10):\n        super(AttnDecoderRNN, self).__init__()\n\n        self.attn_model = attn_model\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n        self.out = nn.Linear(hidden_size * 2, output_size)\n\n        if attn_model != \'none\':\n            self.attn = Attn(attn_model, hidden_size, self.max_length)\n\n    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n\n        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n\n        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n\n        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n\n        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n        context = context.squeeze(1)       # B x S=1 x N -> B x N\n        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n        #output = self.out(torch.cat((rnn_output, context), 1))\n        return output, context, hidden, attn_weights\n\n\nclass seq2seq(nn.Module):\n    def __init__(self):\n        super(seq2seq, self).__init__()\n        self.max_epoches = 100000\n        self.batch_index = 0\n        self.GO_token = 2\n        self.EOS_token = 1\n        self.input_size = 14\n        self.output_size = 15\n        self.hidden_size = 100\n        self.max_length = 15\n        self.show_epoch = 100\n        self.use_cuda = USE_CUDA\n        self.model_path = ""./model/""\n        self.n_layers = 1\n        self.dropout_p = 0.05\n        self.beam_search = True\n        self.top_k = 5\n        self.alpha = 0.5\n\n        self.enc_vec = []\n        self.dec_vec = []\n\n        # \xe5\x88\x9d\xe5\xa7\x8b\xe5\x8c\x96encoder\xe5\x92\x8cdecoder\n        self.encoder = EncoderRNN(self.input_size, self.hidden_size, self.n_layers)\n        self.decoder = AttnDecoderRNN(\'general\', self.hidden_size, self.output_size, self.n_layers, self.dropout_p, self.max_length)\n\n        if USE_CUDA:\n            self.encoder = self.encoder.cuda()\n            self.decoder = self.decoder.cuda()\n\n        self.encoder_optimizer = optim.Adam(self.encoder.parameters())\n        self.decoder_optimizer = optim.Adam(self.decoder.parameters())\n        self.criterion = nn.NLLLoss()\n\n    def loadData(self):\n        with open(""./data/enc.vec"") as enc:\n            line = enc.readline()\n            while line:\n                self.enc_vec.append(line.strip().split())\n                line = enc.readline()\n\n        with open(""./data/dec.vec"") as dec:\n            line = dec.readline()\n            while line:\n                self.dec_vec.append(line.strip().split())\n                line = dec.readline()\n\n    def next(self, batch_size, eos_token=1, go_token=2, shuffle=False):\n        inputs = []\n        targets = []\n\n        if shuffle:\n            ind = random.choice(range(len(self.enc_vec)))\n            enc = [self.enc_vec[ind]]\n            dec = [self.dec_vec[ind]]\n        else:\n            if self.batch_index+batch_size >= len(self.enc_vec):\n                enc = self.enc_vec[self.batch_index:]\n                dec = self.dec_vec[self.batch_index:]\n                self.batch_index = 0\n            else:\n                enc = self.enc_vec[self.batch_index:self.batch_index+batch_size]\n                dec = self.dec_vec[self.batch_index:self.batch_index+batch_size]\n                self.batch_index += batch_size\n        for index in range(len(enc)):\n            enc = enc[0][:self.max_length] if len(enc[0]) > self.max_length else enc[0]\n            dec = dec[0][:self.max_length] if len(dec[0]) > self.max_length else dec[0]\n\n            enc = [int(i) for i in enc]\n            dec = [int(i) for i in dec]\n            dec.append(eos_token)\n\n            inputs.append(enc)\n            targets.append(dec)\n\n        inputs = Variable(torch.LongTensor(inputs)).transpose(1, 0).contiguous()\n        targets = Variable(torch.LongTensor(targets)).transpose(1, 0).contiguous()\n        if USE_CUDA:\n            inputs = inputs.cuda()\n            targets = targets.cuda()\n        return inputs, targets\n\n    def train(self):\n        self.loadData()\n        try:\n            self.load_state_dict(torch.load(self.model_path+\'params.pkl\'))\n        except Exception as e:\n            print(e)\n            print(""No model!"")\n        loss_track = []\n\n        for epoch in range(self.max_epoches):\n            start = time.time()\n            inputs, targets = self.next(1, shuffle=False)\n            loss, logits = self.step(inputs, targets, self.max_length)\n            loss_track.append(loss)\n            _,v = torch.topk(logits, 1)\n            pre = v.cpu().data.numpy().T.tolist()[0][0]\n            tar = targets.cpu().data.numpy().T.tolist()[0]\n            stop = time.time()\n            if epoch % self.show_epoch == 0:\n                print(""-""*50)\n                print(""epoch:"", epoch)\n                print(""    loss:"", loss)\n                print(""    target:%s\\n    output:%s"" % (tar, pre))\n                print(""    per-time:"", (stop-start))\n                torch.save(self.state_dict(), self.model_path+\'params.pkl\')\n\n    def step(self, input_variable, target_variable, max_length):\n        teacher_forcing_ratio = 0.1\n        clip = 5.0\n        loss = 0 # Added onto for each word\n\n        self.encoder_optimizer.zero_grad()\n        self.decoder_optimizer.zero_grad()\n\n        input_length = input_variable.size()[0]\n        target_length = target_variable.size()[0]\n\n        encoder_hidden = self.encoder.init_hidden()\n        encoder_outputs, encoder_hidden = self.encoder(input_variable, encoder_hidden)\n\n        decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n        decoder_context = Variable(torch.zeros(1, self.decoder.hidden_size))\n        decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n        if USE_CUDA:\n            decoder_input = decoder_input.cuda()\n            decoder_context = decoder_context.cuda()\n\n        decoder_outputs = []\n        use_teacher_forcing = random.random() < teacher_forcing_ratio\n        use_teacher_forcing = True\n        if use_teacher_forcing:\n            for di in range(target_length):\n                decoder_output, decoder_context, decoder_hidden, decoder_attention = self.decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n                loss += self.criterion(decoder_output, target_variable[di])\n                decoder_input = target_variable[di]\n                decoder_outputs.append(decoder_output.unsqueeze(0))\n        else:\n            for di in range(target_length):\n                decoder_output, decoder_context, decoder_hidden, decoder_attention = self.decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n                loss += self.criterion(decoder_output, target_variable[di])\n                decoder_outputs.append(decoder_output.unsqueeze(0))\n                topv, topi = decoder_output.data.topk(1)\n                ni = topi[0][0]\n\n                decoder_input = Variable(torch.LongTensor([[ni]]))\n                if USE_CUDA: decoder_input = decoder_input.cuda()\n                if ni == EOS_token: break\n        loss.backward()\n        torch.nn.utils.clip_grad_norm(self.encoder.parameters(), clip)\n        torch.nn.utils.clip_grad_norm(self.decoder.parameters(), clip)\n        self.encoder_optimizer.step()\n        self.decoder_optimizer.step()\n        decoder_outputs = torch.cat(decoder_outputs, 0)\n        return loss.data[0] / target_length, decoder_outputs\n\n    def make_infer_fd(self, input_vec):\n        inputs = []\n        enc = input_vec[:self.max_length] if len(input_vec) > self.max_length else input_vec\n        inputs.append(enc)\n        inputs = Variable(torch.LongTensor(inputs)).transpose(1, 0).contiguous()\n        if USE_CUDA:\n            inputs = inputs.cuda()\n        return inputs\n\n    def predict(self):\n        try:\n            self.load_state_dict(torch.load(self.model_path+\'params.pkl\'))\n        except Exception as e:\n            print(e)\n            print(""No model!"")\n        loss_track = []\n\n        # \xe5\x8a\xa0\xe8\xbd\xbd\xe5\xad\x97\xe5\x85\xb8\n        str_to_vec = {}\n        with open(""./data/enc.vocab"") as enc_vocab:\n            for index,word in enumerate(enc_vocab.readlines()):\n                str_to_vec[word.strip()] = index\n\n        vec_to_str = {}\n        with open(""./data/dec.vocab"") as dec_vocab:\n            for index,word in enumerate(dec_vocab.readlines()):\n                vec_to_str[index] = word.strip()\n\n        while True:\n            input_strs = input(""me > "")\n            # \xe5\xad\x97\xe7\xac\xa6\xe4\xb8\xb2\xe8\xbd\xac\xe5\x90\x91\xe9\x87\x8f\n            segement = jieba.lcut(input_strs)\n            input_vec = [str_to_vec.get(i, 3) for i in segement]\n            input_vec = self.make_infer_fd(input_vec)\n\n            # inference\n            if self.beam_search:\n                samples = self.beamSearchDecoder(input_vec)\n                for sample in samples:\n                    outstrs = []\n                    for i in sample[0]:\n                        if i == 1:\n                            break\n                        outstrs.append(vec_to_str.get(i, ""Un""))\n                    print(""ai > "", """".join(outstrs), sample[3])\n            else:\n                logits = self.infer(input_vec)\n                _,v = torch.topk(logits, 1)\n                pre = v.cpu().data.numpy().T.tolist()[0][0]\n                outstrs = []\n                for i in pre:\n                    if i == 1:\n                        break\n                    outstrs.append(vec_to_str.get(i, ""Un""))\n                print(""ai > "", """".join(outstrs))\n\n    def infer(self, input_variable):\n        input_length = input_variable.size()[0]\n\n        encoder_hidden = self.encoder.init_hidden()\n        encoder_outputs, encoder_hidden = self.encoder(input_variable, encoder_hidden)\n\n        decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n        decoder_context = Variable(torch.zeros(1, self.decoder.hidden_size))\n        decoder_hidden = encoder_hidden\n        if USE_CUDA:\n            decoder_input = decoder_input.cuda()\n            decoder_context = decoder_context.cuda()\n        decoder_outputs = []\n\n        for i in range(self.max_length):\n            decoder_output, decoder_context, decoder_hidden, decoder_attention = self.decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n            decoder_outputs.append(decoder_output.unsqueeze(0))\n            topv, topi = decoder_output.data.topk(1)\n            ni = topi[0][0]\n            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n            if USE_CUDA: decoder_input = decoder_input.cuda()\n            if ni == EOS_token: break\n\n        decoder_outputs = torch.cat(decoder_outputs, 0)\n        return decoder_outputs\n\n    def tensorToList(self, tensor):\n        return tensor.cpu().data.numpy().tolist()[0]\n\n    def beamSearchDecoder(self, input_variable):\n        input_length = input_variable.size()[0]\n        encoder_hidden = self.encoder.init_hidden()\n        encoder_outputs, encoder_hidden = self.encoder(input_variable, encoder_hidden)\n\n        decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n        decoder_context = Variable(torch.zeros(1, self.decoder.hidden_size))\n        decoder_hidden = encoder_hidden\n        if USE_CUDA:\n            decoder_input = decoder_input.cuda()\n            decoder_context = decoder_context.cuda()\n\n        decoder_output, decoder_context, decoder_hidden, decoder_attention = self.decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n        topk = decoder_output.data.topk(self.top_k)\n        samples = [[] for i in range(self.top_k)]\n        dead_k = 0\n        final_samples = []\n        for index in range(self.top_k):\n            topk_prob = topk[0][0][index]\n            topk_index = int(topk[1][0][index])\n            samples[index] = [[topk_index], topk_prob, 0, 0, decoder_context, decoder_hidden, decoder_attention, encoder_outputs]\n\n        for _ in range(self.max_length):\n            tmp = []\n            for index in range(len(samples)):\n                tmp.extend(self.beamSearchInfer(samples[index], index))\n            samples = []\n\n            # \xe7\xad\x9b\xe9\x80\x89\xe5\x87\xbatopk\n            df = pd.DataFrame(tmp)\n            df.columns = [\'sequence\', \'pre_socres\', \'fin_scores\', ""ave_scores"", ""decoder_context"", ""decoder_hidden"", ""decoder_attention"", ""encoder_outputs""]\n            sequence_len = df.sequence.apply(lambda x:len(x))\n            df[\'ave_scores\'] = df[\'fin_scores\'] / sequence_len\n            df = df.sort_values(\'ave_scores\', ascending=False).reset_index().drop([\'index\'], axis=1)\n            df = df[:(self.top_k-dead_k)]\n            for index in range(len(df)):\n                group = df.ix[index]\n                if group.tolist()[0][-1] == 1:\n                    final_samples.append(group.tolist())\n                    df = df.drop([index], axis=0)\n                    dead_k += 1\n                    print(""drop {}, {}"".format(group.tolist()[0], dead_k))\n            samples = df.values.tolist()\n            if len(samples) == 0:\n                break\n\n        if len(final_samples) < self.top_k:\n            final_samples.extend(samples[:(self.top_k-dead_k)])\n        return final_samples\n\n    def beamSearchInfer(self, sample, k):\n        samples = []\n        decoder_input = Variable(torch.LongTensor([[sample[0][-1]]]))\n        if USE_CUDA:\n            decoder_input = decoder_input.cuda()\n        sequence, pre_scores, fin_scores, ave_scores, decoder_context, decoder_hidden, decoder_attention, encoder_outputs = sample\n        decoder_output, decoder_context, decoder_hidden, decoder_attention = self.decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n\n        # choose topk\n        topk = decoder_output.data.topk(self.top_k)\n        for k in range(self.top_k):\n            topk_prob = topk[0][0][k]\n            topk_index = int(topk[1][0][k])\n            pre_scores += topk_prob\n            fin_scores = pre_scores - (k - 1 ) * self.alpha\n            samples.append([sequence+[topk_index], pre_scores, fin_scores, ave_scores, decoder_context, decoder_hidden, decoder_attention, encoder_outputs])\n        return samples\n\n    def retrain(self):\n        try:\n            os.remove(self.model_path)\n        except Exception as e:\n            pass\n        self.train()\n\nif __name__ == \'__main__\':\n    seq = seq2seq()\n    if sys.argv[1] == \'train\':\n        seq.train()\n    elif sys.argv[1] == \'predict\':\n        seq.predict()\n    elif sys.argv[1] == \'retrain\':\n        seq.retrain()\n'"
