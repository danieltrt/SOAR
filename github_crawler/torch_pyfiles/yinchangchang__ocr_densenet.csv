file_path,api_count,code
code/ocr/dataloader.py,1,"b'# encoding: utf-8\n\n""""""\nRead images and corresponding labels.\n""""""\n\nimport numpy as np\nimport os\nimport json\n# import skimage\n# from skimage import io\nfrom PIL import Image,ImageDraw,ImageFont,ImageFilter\nfrom torch.utils.data import Dataset\nimport time\n\nfilters = [\n            ImageFilter.SMOOTH,                 # \xe5\xb9\xb3\xe6\xbb\x91\xef\xbc\x8c\xe5\xa4\xa7\xe4\xba\x8e16\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n            ImageFilter.SMOOTH_MORE,            # \xe5\xb9\xb3\xe6\xbb\x91\xef\xbc\x8c\xe5\xa4\xa7\xe4\xba\x8e16\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n            ImageFilter.GaussianBlur(radius=1), # \xe5\xa4\xa7\xe4\xba\x8e16\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n\n            ImageFilter.GaussianBlur(radius=2), # \xe5\xa4\xa7\xe4\xba\x8e32\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n            ImageFilter.BLUR,                   # \xe5\xa4\xa7\xe4\xba\x8e32\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n        ]\n\ndef histeq (im,nbr_bins =256):  \n    # \xe5\xaf\xb9\xe4\xb8\x80\xe5\x89\xaf\xe7\x81\xb0\xe5\xba\xa6\xe5\x9b\xbe\xe5\x83\x8f\xe8\xbf\x9b\xe8\xa1\x8c\xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe\xe5\x9d\x87\xe8\xa1\xa1\xe5\x8c\x96  \n    #\xe8\xaf\xa5\xe5\x87\xbd\xe6\x95\xb0\xe6\x9c\x89\xe4\xb8\xa4\xe4\xb8\xaa\xe8\xbe\x93\xe5\x85\xa5\xe5\x8f\x82\xe6\x95\xb0\xef\xbc\x8c\xe4\xb8\x80\xe4\xb8\xaa\xe6\x98\xaf\xe7\x81\xb0\xe5\xba\xa6\xe5\x9b\xbe\xe5\x83\x8f\xef\xbc\x8c\xe4\xb8\x80\xe4\xb8\xaa\xe6\x98\xaf\xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe\xe4\xb8\xad\xe4\xbd\xbf\xe7\x94\xa8\xe5\xb0\x8f\xe5\x8c\xba\xe9\x97\xb4\xe7\x9a\x84\xe6\x95\xb0\xe7\x9b\xae  \n    #\xe5\x87\xbd\xe6\x95\xb0\xe8\xbf\x94\xe5\x9b\x9e\xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe\xe5\x9d\x87\xe8\xa1\xa1\xe5\x8c\x96\xe5\x90\x8e\xe7\x9a\x84\xe5\x9b\xbe\xe5\x83\x8f\xef\xbc\x8c\xe4\xbb\xa5\xe5\x8f\x8a\xe7\x94\xa8\xe6\x9d\xa5\xe5\x81\x9a\xe5\x83\x8f\xe7\xb4\xa0\xe5\x80\xbc\xe6\x98\xa0\xe5\xb0\x84\xe7\x9a\x84\xe7\xb4\xaf\xe8\xae\xa1\xe5\x88\x86\xe5\xb8\x83\xe5\x87\xbd\xe6\x95\xb0  \n    # \xe8\xae\xa1\xe7\xae\x97\xe5\x9b\xbe\xe5\x83\x8f\xe7\x9a\x84\xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe  \n    imhist,bins =np.histogram(im.flatten(),nbr_bins,normed=True)  \n    cdf =imhist.cumsum() #cumulative distribution function  \n    cdf =255*cdf/cdf[-1] #\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xef\xbc\x8c\xe5\x87\xbd\xe6\x95\xb0\xe4\xb8\xad\xe4\xbd\xbf\xe7\x94\xa8\xe7\xb4\xaf\xe8\xae\xa1\xe5\x88\x86\xe5\xb8\x83\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe4\xb8\xaa\xe5\x85\x83\xe7\xb4\xa0\xef\xbc\x88\xe4\xb8\x8b\xe6\xa0\x87\xe4\xb8\xba-1\xef\xbc\x8c\xe7\x9b\xae\xe6\xa0\x87\xe6\x98\xaf  \n    # \xe5\xb0\x86\xe5\x85\xb6\xe5\xbd\x92\xe4\xb8\x80\xe5\x8c\x96\xe5\x88\xb00-1\xe8\x8c\x83\xe5\x9b\xb4 \xef\xbc\x89  \n    # \xe4\xbd\xbf\xe7\x94\xa8\xe7\xb4\xaf\xe8\xae\xa1\xe5\x88\x86\xe5\xb8\x83\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe7\xba\xbf\xe6\x80\xa7\xe6\x8f\x92\xe5\x80\xbc\xef\xbc\x8c\xe8\xae\xa1\xe7\xae\x97\xe6\x96\xb0\xe7\x9a\x84\xe5\x83\x8f\xe7\xb4\xa0\xe5\x80\xbc  \n    im2=np.interp(im.flatten(),bins[:-1],cdf) # im2 is an array  \n    return im2.reshape(im.shape),cdf  \n\n\nclass DataSet(Dataset):\n    def __init__(self, \n            image_names, \n            image_label_dict, \n            class_num, \n            transform=None, \n            image_size=None,        # \xe6\x9c\x80\xe5\x90\x8e\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\xa7\xe5\xb0\x8f\n            word_index_dict=None,   # \xe5\xad\x97\xe7\xac\xa6\xe4\xb8\x8eindex\xe7\x9a\x84\xe5\xaf\xb9\xe5\xba\x94\n            phase=\'train\',          # phase\n            args=None,              # \xe5\x85\xa8\xe5\xb1\x80\xe5\x8f\x82\xe6\x95\xb0\n            font_range=None,        # \xe7\x94\x9f\xe6\x88\x90\xe5\xad\x97\xe7\xac\xa6\xe5\xa4\xa7\xe5\xb0\x8f\xe8\x8c\x83\xe5\x9b\xb4\n            rotate_range=None,      # \xe5\x9b\xbe\xe7\x89\x87\xe6\x97\x8b\xe8\xbd\xac\xe8\x8c\x83\xe5\x9b\xb4\n            margin=None             # \xe5\x9b\xbe\xe7\x89\x87\xe8\xbe\xb9\xe7\xbc\x98\xe4\xb8\x8d\xe8\xa6\x86\xe7\x9b\x96\xe5\xad\x97\xe7\xac\xa6\xef\xbc\x8c\xe4\xbb\xa5\xe5\x85\x8d\xe6\x97\x8b\xe8\xbd\xac\xe6\x97\xb6\xe5\x80\x99\xe4\xb8\xa2\xe5\xa4\xb1\n            ):\n\n        self.font_range = font_range\n        self.rotate_range = rotate_range\n        self.margin = margin\n        self.image_names = image_names\n        self.image_label_dict = image_label_dict\n        self.transform = transform\n        self.phase = phase\n        self.class_num = class_num\n        self.word_labels = { }\n        self.image_size = image_size\n        self.word_index_dict = word_index_dict\n        self.args = args\n        if self.phase != \'pretrain\':\n            for image_name in image_names:\n                image_name = image_name.split(\'/\')[-1]\n                if image_name not in image_label_dict:\n                    try:\n                        image_label_dict[image_name] = image_label_dict[image_name.replace(\'seg.\',\'\').split(\'.png\')[0]+\'.png\']\n                    except:\n                        image_label_dict[image_name] = \'\'\n                word_label = np.zeros(class_num)\n                label = image_label_dict[image_name]\n                for l in label.split():\n                    word_label[int(l)] = 1\n                self.word_labels[image_name] = word_label.astype(np.float32)\n\n    def __getitem__(self, index):\n        image_name = self.image_names[index]\n        # print self.image_size\n        if self.phase == \'pretrain\':\n            image = Image.open(image_name).convert(\'RGB\')\n            # \xe6\x94\xb9\xe5\x8f\x98\xe7\x81\xb0\xe5\xba\xa6\n            image = np.array(image)\n            r = get_random(index) \n            # \xe9\x80\x9a\xe5\xb8\xb8\xe8\x83\x8c\xe6\x99\xaf\xe4\xb8\xba\xe9\xab\x98\xe4\xba\xae\xe5\xba\xa6\xe9\xa2\x9c\xe8\x89\xb2\n            if r < 0.3:\n                min_rgb = 192.\n            elif r < 0.7:\n                min_rgb = 128.\n            else:\n                min_rgb = 64.\n            if self.args.model == \'resnet\':\n                pass\n            elif index % 2 == 0:\n                image = image / (255. - min_rgb) + min_rgb\n            else:\n                image[image<min_rgb] = min_rgb\n            image = Image.fromarray(image.astype(np.uint8))\n            no_aug = get_random(index+1000) < 0.1\n            if self.args.epoch < 40:\n                no_aug = 1\n            image, label, bbox_label, seg_label, font_size = generate_image( index, image, no_aug, self)\n\n            # \xe8\xbd\xac\xe5\x8c\x96\xe4\xb8\xbanumpy\xe6\x95\xb0\xe7\xbb\x84\xe4\xb9\x8b\xe5\x90\x8e\xef\xbc\x8c\xe5\xa2\x9e\xe5\x8a\xa0\xe4\xb8\x80\xe4\xba\x9b\xe5\x85\xb6\xe4\xbb\x96\xe7\x9a\x84augmentation\n            image = np.transpose(np.array(image), [2,0,1]).astype(np.float32)\n\n            if get_random(index+1) < 0.2:\n                # \xe7\x81\xb0\xe5\xba\xa6\xe5\x8f\x8d\xe5\x90\x91\xef\xbc\x8c\xe5\x8f\x98\xe6\x88\x90\xe9\xbb\x91\xe5\xba\x95\xef\xbc\x8c\xe7\x99\xbd\xe5\xad\x97\n                image = 255. - image\n\n            if not no_aug:\n                # \xe6\xaf\x8f\xe4\xb8\x80\xe5\x88\x97\xe7\x81\xb0\xe5\xba\xa6\xe6\x9c\x89\xe6\x89\x80\xe6\x94\xb9\xe5\x8f\x98\n                if get_random(index + 3) < 0.3:\n                    change_level = 256. / image.shape[1]\n                    gray_change = 0 \n                    for j in range(image.shape[1]):\n                        gray_change += change_level * get_random(j+index) - change_level / 2\n                        image[:,j,:] += int(gray_change)\n                # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe7\x81\xb0\xe5\xba\xa6\xe6\x9c\x89\xe6\x89\x80\xe6\x94\xb9\xe5\x8f\x98\n                if get_random(index + 4) < 0.3:\n                    change_level = 256. / image.shape[2]\n                    gray_change = 0\n                    for k in range(image.shape[2]):\n                        gray_change += change_level * get_random(10+k+index) - change_level / 2\n                        image[:,:,k] += int(gray_change)\n                image_name = image_name.split(\'/\')[-1]\n            \'\'\'\n            # \xe5\xa2\x9e\xe5\x8a\xa0\xe5\x99\xaa\xe5\xa3\xb0\n            if get_random(index+5) > 0.5 and self.args.epoch > 35:\n                noise_level = 10\n                noise = np.random.random(image.shape) * noise_level - noise_level / 2.\n                image = image + noise\n            \'\'\'\n            image = (image / 128. - 1).astype(np.float32)\n\n            if font_size > 32:\n                size_label = 1\n            elif font_size < 16:\n                size_label = 0\n            else:\n                size_label = 11\n            size_label = np.array([size_label]).astype(np.float32)\n\n            return image_name, image.astype(np.float32), label, bbox_label, seg_label, size_label\n\n        elif self.phase == \'seg\':\n\t\t\t\t# \xe4\xbf\x9d\xe6\x8c\x81\xe5\x92\x8c\xe5\x8e\x9f\xe5\x9b\xbe\xe7\x9b\xb8\xe5\x90\x8c\xe7\x9a\x84\xe5\x88\x86\xe8\xbe\xa8\xe7\x8e\x87\n                image = Image.open(image_name).convert(\'RGB\')\n                # image_name = image_name.split(\'/\')[-1]\n                # image = image.resize(self.image_size)\n                image = np.transpose(np.array(image), [2,0,1]).astype(np.float32)\n                min_size = 32\n                shape = (np.array(image.shape).astype(np.int32) / min_size) * min_size + min_size # * 2\n                new_image = np.zeros([3, shape[1], shape[2]], dtype=np.float32) \n                \'\'\'\n                for i in range(3):\n                    gray = sorted(image[i].reshape(-1))\n                    gray = gray[len(gray)/2]\n                    new_image[i] = gray\n                \'\'\'\n                # new_image[:, min_size/2:image.shape[1]+min_size/2, min_size/2:image.shape[2]+min_size/2] = image\n                new_image[:, :image.shape[1], :image.shape[2]] = image\n                image = new_image\n                # word_label = self.word_labels[image_name]\n                image = (image / 128. - 1).astype(np.float32)\n                return image_name, image, np.zeros(self.class_num, dtype=np.float32)\n        else:\n            seg_name = image_name.replace(\'train\',\'seg.train\').replace(\'test\',\'seg.test\') + \'.seg.crop.png\'\n            no_aug = self.args.no_aug\n            if os.path.exists(seg_name):\n                # image, word_label = random_crop_image(seg_name, self.image_label_dict[image_name.split(\'/\')[-1]], self.image_size, self.class_num, self.phase, index, no_aug)\n                image, word_label = random_crop_image(image_name, self.image_label_dict[image_name.split(\'/\')[-1]], self.image_size, self.class_num, self.phase, index, no_aug, self.args)\n            else:\n                image, word_label = random_crop_image(image_name, self.image_label_dict[image_name.split(\'/\')[-1]], self.image_size, self.class_num, self.phase, index, no_aug, self.args)\n\n            # \xe7\x81\xb0\xe5\xba\xa6\xe5\x8f\x8d\xe5\x90\x91\xe7\xbf\xbb\xe8\xbd\xac\xef\xbc\x8c\xe5\x8f\x98\xe6\x88\x90\xe9\xbb\x91\xe5\xba\x95\xef\xbc\x8c\xe7\x99\xbd\xe5\xad\x97\n            if self.phase == \'train\':\n                r = get_random(index+111) \n                if r < 0.1:\n                    image[0,:,:] = 255 - image[0,:,:]\n                elif r < 0.2:\n                    image[1,:,:] = 255 - image[1,:,:]\n                elif r < 0.3:\n                    image[2,:,:] = 255 - image[2,:,:]\n                if get_random(index+112) < 0.2:\n                    image = 255. - image\n\n            image = (image / 128. - 1).astype(np.float32)\n            return image_name, image, word_label\n\n    def __len__(self):\n        return len(self.image_names) \n\nlast_random = 10\ndef get_random(idx):\n    global last_random\n    if last_random < 1:\n        np.random.seed(int(last_random * 1000000 + time.time()) + idx)\n    else:\n        np.random.seed(int((time.time())))\n    x = np.random.random()\n    while np.abs(last_random - x) < 0.1:\n        x = np.random.random()\n    last_random = x\n    return x\n\ndef comput_iou(font, proposal):\n    fx,fy,fh,fw = font\n    px,py,pd = proposal\n    overlap_x =  max(min(pd, fh) - np.abs(fx - px), 0)\n    overlap_y =  max(min(pd, fw) - np.abs(fy - py), 0)\n    # \xe9\x9d\xa2\xe7\xa7\xaf\n    sf = fh * fw\n    sp = pd * pd\n    so = overlap_x * overlap_y\n    iou = float(so) / (sf + sp - so)\n    return iou\n\ndef generate_bbox_label(image, font_place, font_size, font_num, args, image_size):\n    imgh,imgw = image.size\n    seg_label = np.zeros((image_size[0]/2, image_size[1]/2), dtype=np.float32)\n    sx = float(font_place[0]) / image.size[0] * image_size[0]\n    ex = sx + float(font_size) / image.size[0] * image_size[0] * font_num\n    sy = float(font_place[1]) / image.size[1] * image_size[1]\n    ey = sy + float(font_size) / image.size[1] * image_size[1]\n    seg_label[int(sx)/2:int(ex)/2, int(sy)/2:int(ey)/2] = 1\n    seg_label = seg_label.transpose((1,0))\n\n    bbox_label = np.zeros((\n        image_size[0]/args.stride,  # 16\n        image_size[1]/args.stride,  # 16\n        len(args.anchors),          # 4\n        4                           # dx,dy,dd,c\n        ), dtype=np.float32)\n    fonts= []\n    for i in range(font_num):\n        x = font_place[0] + font_size/2. + i * font_size\n        y = font_place[1] + font_size/2.\n        h = font_size\n        w = font_size\n\n        x = float(x) * image_size[0] / imgh\n        h = float(h) * image_size[0] / imgh\n        y = float(y) * image_size[1] / imgw\n        w = float(w) * image_size[1] / imgw\n        fonts.append([x,y,h,w])\n\n    # print bbox_label.shape\n    for ix in range(bbox_label.shape[0]):\n        for iy in range(bbox_label.shape[1]):\n            for ia in range(bbox_label.shape[2]):\n                proposal = [ix*args.stride + args.stride/2, iy*args.stride + args.stride/2, args.anchors[ia]]\n                iou_fi = []\n                for fi, font in enumerate(fonts):\n                    iou = comput_iou(font, proposal)\n                    iou_fi.append((iou, fi))\n                max_iou, max_fi = sorted(iou_fi)[-1]\n                if max_iou > 0.5:\n                    # \xe6\xad\xa3\xe4\xbe\x8b\n                    dx = (font[0] - proposal[0]) / float(proposal[2])\n                    dy = (font[1] - proposal[1]) / float(proposal[2])\n                    fd = max(font[2:])\n                    dd = np.log(fd / float(proposal[2]))\n                    # bbox_label[ix,iy,ia] = [dx, dy, dd, 1]\n                    bbox_label[ix,iy,ia] = [dx, dy, dd, 1]\n                elif max_iou > 0.25:\n                    # \xe5\xbf\xbd\xe7\x95\xa5\n                    bbox_label[ix,iy,ia,3] = 0\n                else:\n                    # \xe8\xb4\x9f\xe4\xbe\x8b\n                    bbox_label[ix,iy,ia,3] = -1\n    # \xe8\xbf\x99\xe9\x87\x8c\xe6\x9c\x89\xe4\xb8\x80\xe4\xb8\xaatranspose\xe6\x93\x8d\xe4\xbd\x9c\n    bbox_label = bbox_label.transpose((1,0,2,3))\n\n\n                # \xe8\xae\xa1\xe7\xae\x97anchor\xe4\xbf\xa1\xe6\x81\xaf\n    return bbox_label, seg_label\n\ndef get_resize_para(size, idx):\n    if size > 48:\n        rh, rw = 4,4\n    elif size > 32:\n        if idx % 2:\n            rh, rw = 2,4\n        else:\n            rh, rw = 4,2\n    elif size > 16:\n        if idx % 2:\n            rh, rw = 1,2\n        else:\n            rh, rw = 2,1\n    else:\n        return 1,1\n\n    rhs = range(rh)\n    np.random.seed(int(time.time()) + idx + 1)\n    np.random.shuffle(rhs)\n    rh = rhs[0] + 1\n\n    rws = range(rw)\n    np.random.seed(int(time.time()) + idx + 2)\n    np.random.shuffle(rws)\n    rw = rws[0] + 1\n\n    return rh, rw\n\n# def generate_image(idx, image, word_index_dict, class_num, args, image_size, no_aug, epoch):\ndef generate_image( idx, image, no_aug, dataset):\n    \'\'\'\n    args.model == \'resnet\' \xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xe5\x8f\xaa\xe6\x98\xaf\xe7\x94\xa8\xe4\xba\x8e\xe8\xae\xad\xe7\xbb\x83\xe5\x88\x86\xe5\x89\xb2\xe7\xbd\x91\xe7\xbb\x9c\xef\xbc\x8c\xe5\xa4\xa7\xe9\x83\xa8\xe5\x88\x86augmentation\xe9\x83\xbd\xe4\xb8\x8d\xe7\x94\xa8\n    \xe8\xbf\x99\xe9\x87\x8c\xe7\x9a\x84\xe6\xb3\xa8\xe9\x87\x8a\xef\xbc\x8c\xe9\xbb\x98\xe8\xae\xa4\xe5\x8f\x82\xe6\x95\xb0\xe6\x98\xaf\n        image_size [512, 64]\n        rotate_range [-5, 5]\n        font_range [8,32]\n    \'\'\'\n\n    word_index_dict = dataset.word_index_dict\n    class_num = dataset.class_num\n    args = dataset.args\n    image_size = dataset.image_size\n    font_range = dataset.font_range\n    rotate_range = dataset.rotate_range \n    epoch = args.epoch\n    margin = dataset.margin\n\n    # \xe9\x80\x89\xe6\x8b\xa9\xe6\x96\x87\xe5\xad\x97\xe8\x83\x8c\xe6\x99\xaf\n    image = image.resize((1024,1024))\n    h,w = image.size\n    # \xe9\x9a\x8f\xe6\x9c\xbacrop\xe4\xb8\x80\xe4\xb8\xaa\xe9\x83\xa8\xe5\x88\x86\xef\xbc\x8cresize\xe6\x88\x90\xe5\x9b\xba\xe5\xae\x9a\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8c\xe4\xbc\x9a\xe5\xaf\xb9\xe6\x96\x87\xe5\xad\x97\xe6\x9c\x89\xe4\xb8\x80\xe5\xae\x9a\xe7\x9a\x84\xe6\xb0\xb4\xe5\xb9\xb3\xe7\xab\x96\xe7\x9b\xb4\xe6\x96\xb9\xe5\x90\x91\xe6\x8b\x89\xe4\xbc\xb8\n    h_crop = int(get_random(idx + 10) * image_size[0] * 2 / 8) + image_size[0] * 6 / 8 # \xe9\x95\xbf\xe5\xba\xa6\xe8\x8c\x83\xe5\x9b\xb4 [374, 512]\n    w_crop = int(get_random(idx + 11) * image_size[1] * 2 / 8) + image_size[1] * 6 / 8 # \xe5\xae\xbd\xe5\xba\xa6\xe8\x8c\x83\xe5\x9b\xb4 [48, 64]\n    if args.model == \'resnet\' or no_aug or epoch < 60:\n        # resnet: \xe5\x88\x86\xe5\x89\xb2\xe7\xbd\x91\xe7\xbb\x9c\xe9\x87\x87\xe7\x94\xa8\xe5\x9b\xba\xe5\xae\x9a\xe5\xa4\xa7\xe5\xb0\x8fcrop\n        # epoch<60: \xe7\xbd\x91\xe7\xbb\x9c\xe8\xae\xad\xe7\xbb\x83\xe5\x88\x9d\xe6\x9c\x9f\xe9\x87\x87\xe7\x94\xa8\xe5\x9b\xba\xe5\xae\x9a\xe5\xa4\xa7\xe5\xb0\x8f\xef\xbc\x8c\xe5\x8a\xa0\xe9\x80\x9f\xe6\x94\xb6\xe6\x95\x9b\n        h_crop = image_size[0]\n        w_crop = image_size[1]\n    # \xe9\x80\x89\xe6\x8b\xa9\xe6\x96\x87\xe5\xad\x97\xe8\x83\x8c\xe6\x99\xaf\xef\xbc\x8c\xe9\x9a\x8f\xe6\x9c\xba\xe9\x80\x89\xe6\x8b\xa9crop\xe8\xb5\xb7\xe5\xa7\x8b\xe4\xbd\x8d\xe7\xbd\xae\n    x = int(get_random(idx+12) * (h - h_crop))\n    y = int(get_random(idx+13) * (w - w_crop))\n    image = image.crop((x,y,x+h_crop,y+w_crop))\n\n\n    # \xe5\xad\x97\xe4\xbd\x93\xe5\xa4\xa7\xe5\xb0\x8f\xe6\x98\xaf\xe6\x9c\x80\xe5\xae\xb9\xe6\x98\x93\xe5\xbc\x95\xe8\xb5\xb7\xe9\x94\x99\xe8\xaf\xaf\xe7\x9a\x84\xe5\x8f\x98\xe9\x87\x8f\xef\xbc\x8c\xe5\xad\x97\xe4\xbd\x93\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xb8\x8d\xe8\x83\xbd\xe8\xb6\x85\xe5\x87\xba\xe5\x9b\xbe\xe7\x89\x87\xe4\xb8\xad\xe5\xbf\x83\xe5\x8c\xba\xe5\x9f\x9f\xe5\xa4\xa7\xe5\xb0\x8f\n    size = font_range[0] + int(get_random(idx+20) * (font_range[1] - font_range[0]))\n    size = min(size, h_crop - 2*margin - 2, w_crop - 2*margin - 2)\n\n    # \xe5\xad\x97\xe4\xbd\x93\xe6\x95\xb0\xe9\x87\x8f\xef\xbc\x8c\xe8\xb6\x85\xe8\xbf\x87\xe5\x8f\xaf\xe5\xae\xb9\xe7\xba\xb3\xe6\x95\xb0\xe9\x87\x8f\xe7\x9a\x84\xe4\xb8\x80\xe5\x8d\x8a\xe4\xbb\xa5\xe4\xb8\x8a\xef\xbc\x8c\xe8\x87\xb3\xe5\xb0\x91\xe5\x8c\x85\xe5\x90\xab\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe7\xac\xa6\n    large_num = max(0, (h_crop - 2 * margin)/ size - 1)     \n    word_num = int(min(large_num / 2, 5) + get_random(idx+21) * large_num / 2) + 1\n    # word_num = int(large_num / 2 + get_random(idx+21) * large_num / 2) + 1\n    word_num = max(1, word_num)\n\n    # \xe6\xb7\xbb\xe5\x8a\xa0\xe5\xad\x97\xe4\xbd\x93\xe4\xbd\x8d\xe7\xbd\xae\xef\xbc\x8c\xe5\xb9\xb6\xe7\x94\x9f\xe6\x88\x90label\xe4\xbf\xa1\xe6\x81\xaf\n    place_x = int(get_random(idx+22) * (h_crop - word_num * size - margin)) + margin\n    if margin == 0:\n        # \xe7\x94\xa8\xe4\xba\x8e\xe6\xb7\xbb\xe5\x8a\xa0\xe4\xb8\xa4\xe6\x8e\x92\xe6\x96\x87\xe5\xad\x97\n        place_y = int(get_random(idx+23) * (w_crop/2 - size - margin)) + margin\n    else:\n        place_y = int(get_random(idx+23) * (w_crop - size - margin)) + margin\n    place = (place_x, place_y)\n    label = np.zeros(class_num).astype(np.float32)\n\n    text = u\'\'\n    words = word_index_dict.keys()\n\n    if margin == 0:\n        # \xe4\xb8\xa4\xe6\x8e\x92\xe6\x96\x87\xe5\xad\x97\n        word_num *= 2\n    while len(text) < word_num:\n        np.random.shuffle(words)\n        w = words[len(text)]\n        if w in u\'""(),\':\n            # \xe9\x83\xa8\xe5\x88\x86\xe5\xad\x97\xe7\xac\xa6\xe4\xb8\x8d\xe5\xbb\xba\xe8\xae\xae\xe7\x94\x9f\xe6\x88\x90\n            continue\n        text = text + w\n        index = word_index_dict[w]\n        label[index] = 1\n\n    # \xe5\xbe\x97\xe5\x88\xb0bbox_label\n    if args.model == \'resnet\':\n        bbox_label, seg_label = generate_bbox_label(image, place, size, word_num, args, image_size)\n    else:\n        bbox_label, seg_label = 0,0\n\n    # \xe5\xad\x97\xe4\xbd\x93\xef\xbc\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe6\xb7\xbb\xe5\x8a\xa0\xe5\x85\xb6\xe4\xbb\x96\xe5\xad\x97\xe4\xbd\x93\n    fonts = [\'../../files/ttf/simsun.ttf\']\n    np.random.shuffle(fonts)\n    font = fonts[0]\n\n    # \xe9\xa2\x9c\xe8\x89\xb2\n    r = get_random(idx+24)\n    if no_aug or r < 0.7:\n        # \xe9\x80\x89\xe6\x8b\xa9\xe4\xb8\x8d\xe5\x90\x8c\xe7\xa8\x8b\xe5\xba\xa6\xe7\x9a\x84\xe9\xbb\x91\xe8\x89\xb2\n        if r < 0.3:\n            c = int(get_random(idx + 25) * 64)\n            color = (c,c,c)\n        else:\n            rgb = 64\n            r = int(get_random(idx + 27) * rgb)\n            g = int(get_random(idx + 28) * rgb)\n            b = int(get_random(idx + 29) * rgb)\n            color = (r,g,b)\n    else:\n        # \xe9\x9a\x8f\xe6\x9c\xba\xe9\xa2\x9c\xe8\x89\xb2\xef\xbc\x8c\xe4\xbd\x86\xe6\x98\xaf\xe9\x80\x89\xe6\x8b\xa9\xe8\xbe\x83\xe6\x9a\x97\xe7\x9a\x84\xe9\xa2\x9c\xe8\x89\xb2\n        rgb = 256\n        r = int(get_random(idx + 27) * rgb)\n        g = int(get_random(idx + 28) * rgb)\n        b = int(get_random(idx + 29) * rgb)\n        ra = get_random(idx + 30)\n        if ra < 0.5:\n            ra = int(1000 * ra) % 3\n            if ra == 0:\n                r = 0\n            elif ra == 1:\n                g = 0\n            else:\n                b = 0\n        color = (r,g,b)\n\n    # \xe5\xa2\x9e\xe5\x8a\xa0\xe6\x96\x87\xe5\xad\x97\xe5\x88\xb0\xe5\x9b\xbe\xe7\x89\x87\n    if margin == 0:\n        image = add_text_to_img(image, text[:word_num/2], size, font, color, place)\n        image = add_text_to_img(image, text[word_num/2:], size, font, color, (place[0], place[1]+image_size[1]/2))\n    else:\n        image = add_text_to_img(image, text, size, font, color, place)\n\n    \'\'\'\n    # \xe9\x9a\x8f\xe6\x9c\xba\xe7\xbf\xbb\xe8\xbd\xac\xef\xbc\x8c\xe5\xa2\x9e\xe5\x8a\xa0\xe6\xb3\x9b\xe5\x8c\x96\xe7\xa8\x8b\xe5\xba\xa6\n    if args.model != \'resnet\':\n        if get_random(idx+130) < 0.3:\n            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n        if get_random(idx+131) < 0.3:\n            image = image.transpose(Image.FLIP_TOP_BOTTOM)\n\n    # \xe5\x85\x88\xe5\x81\x9a\xe6\x97\x8b\xe8\xbd\xac\xef\xbc\x8c\xe7\x84\xb6\xe5\x90\x8e\xe5\x9c\xa8\xe6\x8b\x89\xe4\xbc\xb8\xe5\x9b\xbe\xe7\x89\x87\n    h,w = image.size\n    max_hw, min_hw = float(max(h,w)), float(min(h,w))\n    if max_hw / min_hw >= 5:\n        rotate_size = 5\n    elif max_hw / min_hw >= 3:\n        rotate_size = 10\n    elif max_hw / min_hw >= 1.5:\n        rotate_size = 30\n    else:\n        rotate_size = 50\n    if args.model != \'resnet\' and not no_aug and epoch>70 and get_random(idx+50) < 0.8:\n        theta = int(rotate_size * 2 * get_random(idx+32)) - rotate_size\n        image = image.rotate(theta)\n    else:\n        theta = 0\n    \'\'\'\n\n\n    # \xe8\xbf\x98\xe5\x8e\x9f\xe6\x88\x90 [512, 64] \xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\n    image = image.resize(image_size)\n\n\n    # \xe6\x9c\x80\xe5\x90\x8e\xe7\x94\x9f\xe6\x88\x90\xe5\x9b\xbe\xe7\x89\x87\xe5\x90\x8e\xe5\x86\x8d\xe4\xb8\x80\xe6\xac\xa1\xe6\x97\x8b\xe8\xbd\xac\xef\xbc\x8c\xe5\x9b\xbe\xe7\x89\x87\xe6\xa8\xa1\xe7\xb3\x8a\xe5\x8c\x96\n    if args.model == \'resnet\' or (get_random(idx+50) < 0.8 and not no_aug):\n\n        # \xe6\x97\x8b\xe8\xbd\xac\n        if args.model == \'resnet\' :\n            rotate_size = 10\n        else:\n            rotate_size = rotate_range[0] + int(get_random(idx+32) * (rotate_range[1] - rotate_range[0]))\n        theta = int(rotate_size * 2 * get_random(idx+33)) - rotate_size\n        image = image.rotate(theta)\n        if args.model == \'resnet\':\n            # \xe4\xbd\x9c\xe5\x88\x86\xe5\x89\xb2\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe6\xa0\x87\xe7\xad\xbe\xe4\xbf\xa1\xe6\x81\xaf\xe4\xb9\x9f\xe9\x9c\x80\xe8\xa6\x81\xe4\xb8\x80\xe8\xb5\xb7\xe6\x97\x8b\xe8\xbd\xac\n            seg_label = np.array([seg_label, seg_label, seg_label]) * 255\n            seg_label = np.array(Image.fromarray(seg_label.transpose([1,2,0]).astype(np.uint8)).rotate(theta))\n            seg_label = (seg_label[:,:,0] > 128).astype(np.float32)\n\n    filters = [\n            ImageFilter.SMOOTH,                 # \xe5\xb9\xb3\xe6\xbb\x91\xef\xbc\x8c\xe5\xa4\xa7\xe4\xba\x8e16\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n            ImageFilter.SMOOTH_MORE,            # \xe5\xb9\xb3\xe6\xbb\x91\xef\xbc\x8c\xe5\xa4\xa7\xe4\xba\x8e16\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n            ImageFilter.GaussianBlur(radius=1), # \xe5\xa4\xa7\xe4\xba\x8e16\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n\n            ImageFilter.GaussianBlur(radius=2), # \xe5\xa4\xa7\xe4\xba\x8e32\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n            ImageFilter.BLUR,                   # \xe5\xa4\xa7\xe4\xba\x8e32\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8\n            ImageFilter.GaussianBlur(radius=2), # \xe5\xa4\x9a\xe6\x9d\xa5\xe4\xb8\xa4\xe6\xac\xa1\n            ImageFilter.BLUR,                   # \xe5\xa4\x9a\xe6\x9d\xa5\xe4\xb8\xa4\xe6\xac\xa1\n            ]\n\n    # \xe5\xbd\x93\xe6\x96\x87\xe5\xad\x97\xe6\xaf\x94\xe8\xbe\x83\xe5\xa4\xa7\xe7\x9a\x84\xe6\x97\xb6\xe5\x80\x99\xef\xbc\x8c\xe5\xa2\x9e\xe5\x8a\xa0\xe4\xb8\x80\xe4\xba\x9b\xe6\xa8\xa1\xe7\xb3\x8a\n    if size > 16:\n        if size < 32:\n            filters = filters[:3]\n        np.random.shuffle(filters)\n        image = image.filter(filters[idx % len(filters)])\n\n    if args.model == \'resnet\':\n        # add noise\n        noise_level = 32\n        image = np.array(image)\n        noise = np.random.random(image.shape) * noise_level - noise_level / 2.\n        image = image + noise\n        image = image.astype(np.uint8)\n        image = Image.fromarray(image)\n\n\n    # \xe6\x9c\x89\xe6\x97\xb6\xe5\x80\x99\xe9\x9c\x80\xe8\xa6\x81\xe4\xbd\x8e\xe5\x88\x86\xe8\xbe\xa8\xe7\x8e\x87\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\n    resize_0, resize_1 = get_resize_para(size, idx)\n    image = image.resize([image_size[0]/resize_0, image_size[1]/resize_1])\n\n    # \xe8\xbf\x98\xe5\x8e\x9f\xe6\x88\x90 [512, 64] \xe7\x9a\x84\xe5\xa4\xa7\xe5\xb0\x8f\n    image = image.resize(image_size)\n\n    return image, label, bbox_label, seg_label, size\n\ndef add_text_to_img(img, text, size, font, color, place):\n    imgdraw = ImageDraw.Draw(img)\n    imgfont = ImageFont.truetype(font,size=size)\n    imgdraw.text(place, text, fill=color, font=imgfont)\n    return img\n\ndef random_crop_image(image_name, text, image_size, class_num, phase, idx, no_aug, args):\n    # label\n    text = text.split()\n    word_label = np.zeros(class_num, dtype=np.float32)\n\n    \n    if args.hist:\n        if get_random(idx+34) < 0.4 and phase == \'train\':\n            image = Image.open(image_name).convert(\'RGB\')\n        else:\n            # \xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe\xe5\x9d\x87\xe8\xa1\xa1\xe5\x8c\x96\n            image = Image.open(image_name).convert(\'YCbCr\')\n            image = np.array(image)\n            imy = image[:,:,0]\n            imy,_ = histeq(imy)\n            image[:,:,0] = imy\n            image = Image.fromarray(image, mode=\'YCbCr\').convert(\'RGB\')\n    else:\n        image = Image.open(image_name).convert(\'RGB\')\n    x = np.array(image)\n    assert x.min() >= 0\n    assert x.max() < 256\n\n    if phase == \'train\' and not no_aug:\n        # \xe6\x97\x8b\xe8\xbd\xac\n        if get_random(idx+11) < 0.8:\n            theta = int(6 * get_random(idx+1)) - 3\n            image = image.rotate(theta)\n\n        # \xe6\xa8\xa1\xe7\xb3\x8a\xe5\xa4\x84\xe7\x90\x86\n        if get_random(idx+2) < 0.3:\n            np.random.shuffle(filters)\n            image = image.filter(filters[0])\n\n        # \xe7\x9f\xad\xe8\xbe\xb9\xe5\xb0\x8f\xe4\xba\x8e64\xef\xbc\x8c \xe7\x9b\xb4\xe6\x8e\xa5\xe5\xa1\xab0\n        h,w = image.size\n        if w < image_size[1] and h > 64:\n            if get_random(idx+3) < 0.3:\n                image = np.array(image)\n                start_index = (image_size[1] - w)/2\n                new_image = np.zeros((image_size[1], h, 3), dtype=np.uint8)\n                new_image[start_index:start_index+w, :, :] = image\n                image = Image.fromarray(new_image)\n\n\n    # \xe5\x85\x88\xe5\xa4\x84\xe7\x90\x86\xe6\x88\x90 X * 64 \xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\n    h,w = image.size\n    h = int(float(h) * image_size[1] / w)\n    image = image.resize((h, image_size[1]))\n\n    if phase == \'train\' and not no_aug:\n\n        # \xe6\x94\xbe\xe7\xbc\xa9 0.8~1.2\n        h,w = image.size\n        r = get_random(idx+4) / 4. + 0.8\n        image = image.resize((int(h*r), int(w*r)))\n\n        # crop\n        if min(h,w) > 32:\n            crop_size = 20\n            x = int((crop_size * get_random(idx+5) - crop_size/2) * r)\n            y = int((crop_size * get_random(idx+6) - crop_size/2) * r)\n            image = image.crop((max(0,x),max(0,y),min(0,x)+h,min(0,y)+w))\n\n        # \xe6\x9c\x89\xe6\x97\xb6\xe9\x9c\x80\xe8\xa6\x81\xe7\x94\x9f\xe6\x88\x90\xe4\xb8\x80\xe4\xba\x9b\xe4\xbd\x8e\xe5\x88\x86\xe8\xbe\xa8\xe7\x8e\x87\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\n        h,w = image.size\n        r = get_random(idx+7)\n        \n        \'\'\'\n        if r < 0.01 and min(h,w) > 64:\n            image = image.resize((h/8, w/8))\n        elif r < 0.1 and min(h,w) > 64:\n            image = image.resize((h/4, w/4))\n        elif r < 0.3 and min(h,w) > 32:\n            image = image.resize((h/2, w/2))\n        \'\'\'\n\n        # \xe4\xbb\x8e\xe6\x96\xb0\xe5\x8f\x98\xe4\xb8\xba X * 64 \xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\n        h = int(float(h) * image_size[1] / w)\n        image = image.resize((h, image_size[1]))\n\n    # \xe5\xa1\xab\xe5\x85\x85\xe6\x88\x90\xe5\x9b\xba\xe5\xae\x9a\xe5\xa4\xa7\xe5\xb0\x8f\n    image = np.transpose(np.array(image), [2,0,1]).astype(np.float32)\n    if image.shape[2] < image_size[0]:\n        # \xe9\x95\xbf\xe5\xae\xbd\xe6\xaf\x94\xe4\xbe\x8b\xe5\xb0\x8f\xe4\xba\x8e8(16)\xef\xbc\x8c\xe7\x9b\xb4\xe6\x8e\xa5\xe5\xa1\xab\xe5\x85\x85\n        if phase == \'test\':\n            # \xe6\xad\xa3\xe4\xb8\xad\xe9\x97\xb4\n            start = np.abs(image_size[0] - image.shape[2])/2\n        else:\n            start = int(np.random.random() * np.abs(image_size[0] - image.shape[2]))\n        new_image = np.zeros((3, image_size[1], image_size[0]), dtype=np.float32)\n        new_image[:,:,start:start+image.shape[2]] = image\n        if phase == \'test\':\n            new_image = np.array([new_image]).astype(np.float32)\n        for w in text:\n            word_label[int(w)] = 1\n    else:\n        # \xe9\x95\xbf\xe5\xae\xbd\xe6\xaf\x94\xe4\xbe\x8b\xe5\xa4\xa7\xe4\xba\x8e16\xef\xbc\x8c\xe9\x9a\x8f\xe6\x9c\xba\xe6\x88\xaa\xe5\x8f\x96\n        if phase == \'test\':\n            # \xe6\xb5\x8b\xe8\xaf\x95\xe9\x98\xb6\xe6\xae\xb5\xe7\x9b\xb4\xe6\x8e\xa5\xe5\x90\x88\xe5\xb9\xb6\n            crop_num = image.shape[2] * 2 / image_size[0] + 1\n            new_image = np.zeros((crop_num, 3, image_size[1], image_size[0]), dtype=np.float32)\n            for i in range(crop_num):\n                start_index = i * image_size[0] / 2\n                end_index = start_index + image_size[0]\n                if end_index > image.shape[2]:\n                    new_image[i,:,:,:image.shape[2] - start_index] = image[:,:,start_index:end_index]\n                else:\n                    new_image[i] = image[:,:,start_index:end_index]\n            for w in text:\n                word_label[int(w)] = 1\n        else:\n            # \xe8\xae\xad\xe7\xbb\x83\xe9\x98\xb6\xe6\xae\xb5\xe4\xb8\x8d\xe7\xae\x97\xe8\xb4\x9f\xe4\xbe\x8bloss\n            start = int(np.random.random() * np.abs(image_size[0] - image.shape[2]))\n            new_image = image[:,:,start:start+image_size[0]]\n            for w in text:\n                word_label[int(w)] = -1\n\n    image = new_image\n    if phase == \'train\':\n        image = image.astype(np.float32)\n        \'\'\'\n        # \xe6\xaf\x8f\xe4\xb8\x80\xe5\x88\x97\xe7\x81\xb0\xe5\xba\xa6\xe6\x9c\x89\xe6\x89\x80\xe6\x94\xb9\xe5\x8f\x98\n        if get_random(idx+9) < 0.3:\n            change_level = 256. / image.shape[1]\n            gray_change = 0 \n            for j in range(image.shape[1]):\n                gray_change += change_level * get_random(j+idx) - change_level / 2\n                image[:,j,:] += gray_change\n        # \xe6\xaf\x8f\xe4\xb8\x80\xe8\xa1\x8c\xe7\x81\xb0\xe5\xba\xa6\xe6\x9c\x89\xe6\x89\x80\xe6\x94\xb9\xe5\x8f\x98\n        if get_random(idx+10) < 0.3:\n            change_level = 256. / image.shape[2]\n            gray_change = 0\n            for k in range(image.shape[2]):\n                gray_change += change_level * get_random(10+k+idx) - change_level / 2\n                image[:,:,k] += gray_change\n        \'\'\'\n        # \xe5\xa2\x9e\xe5\x8a\xa0\xe5\x99\xaa\xe5\xa3\xb0\n        if get_random(idx+8) < 0.1:\n            noise_level = 64\n            noise = np.random.random(image.shape) * noise_level - noise_level / 2.\n            image = image + noise \n            # noise = np.random.random(image.shape[1:]) * noise_level - noise_level / 2.\n            # image = image + np.array([noise, noise, noise])\n            image = image.astype(np.float32)\n\n    return image, word_label\n'"
code/ocr/densenet.py,8,"b'import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.model_zoo as model_zoo\nfrom collections import OrderedDict\n\n__all__ = [\'DenseNet\', \'densenet121\', \'densenet169\', \'densenet201\', \'densenet161\']\n\n\nmodel_urls = {\n    \'densenet121\': \'https://download.pytorch.org/models/densenet121-a639ec97.pth\',\n    \'densenet169\': \'https://download.pytorch.org/models/densenet169-b2777c0a.pth\',\n    \'densenet201\': \'https://download.pytorch.org/models/densenet201-c1103571.pth\',\n    \'densenet161\': \'https://download.pytorch.org/models/densenet161-8d451a50.pth\',\n}\n\n\ndef densenet121(pretrained=False, small=0,**kwargs):\n    r""""""Densenet-121 model from\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16), small=small,\n                     **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'densenet121\']))\n    return model\n\n\ndef densenet169(pretrained=False, **kwargs):\n    r""""""Densenet-169 model from\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 32, 32),\n                     **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'densenet169\']))\n    return model\n\n\ndef densenet201(pretrained=False, **kwargs):\n    r""""""Densenet-201 model from\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = DenseNet(num_init_features=64, growth_rate=32, block_config=(6, 12, 48, 32),\n                     **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'densenet201\']))\n    return model\n\n\ndef densenet161(pretrained=False, **kwargs):\n    r""""""Densenet-161 model from\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = DenseNet(num_init_features=96, growth_rate=48, block_config=(6, 12, 36, 24),\n                     **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'densenet161\']))\n    return model\n\n\nclass _DenseLayer(nn.Sequential):\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super(_DenseLayer, self).__init__()\n        self.add_module(\'norm.1\', nn.BatchNorm2d(num_input_features)),\n        self.add_module(\'relu.1\', nn.ReLU(inplace=True)),\n        self.add_module(\'conv.1\', nn.Conv2d(num_input_features, bn_size *\n                        growth_rate, kernel_size=1, stride=1, bias=False)),\n        self.add_module(\'norm.2\', nn.BatchNorm2d(bn_size * growth_rate)),\n        self.add_module(\'relu.2\', nn.ReLU(inplace=True)),\n        self.add_module(\'conv.2\', nn.Conv2d(bn_size * growth_rate, growth_rate,\n                        kernel_size=3, stride=1, padding=1, bias=False)),\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super(_DenseLayer, self).forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n        return torch.cat([x, new_features], 1)\n\n\nclass _DenseBlock(nn.Sequential):\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n            self.add_module(\'denselayer%d\' % (i + 1), layer)\n\n\nclass _Transition(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features, use_pool):\n        super(_Transition, self).__init__()\n        self.add_module(\'norm\', nn.BatchNorm2d(num_input_features))\n        self.add_module(\'relu\', nn.ReLU(inplace=True))\n        self.add_module(\'conv\', nn.Conv2d(num_input_features, num_output_features,\n                                          kernel_size=1, stride=1, bias=False))\n        if use_pool:\n            self.add_module(\'pool\', nn.AvgPool2d(kernel_size=2, stride=2))\n\n\nclass DenseNet(nn.Module):\n    r""""""Densenet-BC model class, based on\n    `""Densely Connected Convolutional Networks"" <https://arxiv.org/pdf/1608.06993.pdf>`_\n\n    Args:\n        growth_rate (int) - how many filters to add each layer (`k` in paper)\n        block_config (list of 4 ints) - how many layers in each pooling block\n        num_init_features (int) - the number of filters to learn in the first convolution layer\n        bn_size (int) - multiplicative factor for number of bottle neck layers\n          (i.e. bn_size * k features in the bottleneck layer)\n        drop_rate (float) - dropout rate after each dense layer\n        num_classes (int) - number of classification classes\n    """"""\n    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16), small=0,\n                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000):\n\n        super(DenseNet, self).__init__()\n\n        # First convolution\n        self.features = nn.Sequential(OrderedDict([\n            (\'conv0\', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n            (\'norm0\', nn.BatchNorm2d(num_init_features)),\n            (\'relu0\', nn.ReLU(inplace=True)),\n            (\'pool0\', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n        ]))\n\n        # Each denseblock\n        num_features = num_init_features\n        for i, num_layers in enumerate(block_config):\n            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n            self.features.add_module(\'denseblock%d\' % (i + 1), block)\n            num_features = num_features + num_layers * growth_rate\n            if i != len(block_config) - 1:\n                if small and i > 0:\n                    use_pool = 0\n                else:\n                    use_pool = 1\n                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2, use_pool=use_pool)\n                self.features.add_module(\'transition%d\' % (i + 1), trans)\n                num_features = num_features // 2\n\n        # Final batch norm\n        self.features.add_module(\'norm5\', nn.BatchNorm2d(num_features))\n\n        # Linear layer\n        self.classifier = nn.Linear(num_features, num_classes)\n\n    def forward(self, x):\n        features = self.features(x)\n        return features\n        att_feats = features\n        out = F.relu(features, inplace=True)\n        out = F.avg_pool2d(out, kernel_size=7, stride=1).view(features.size(0), -1)\n        # out = F.avg_pool2d(out, kernel_size=3, stride=1).view(features.size(0), -1)\n        fc_feats = out\n        out = self.classifier(out)\n        return att_feats, fc_feats, out\n'"
code/ocr/main.py,14,"b'# coding=utf8\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the ""License"");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an ""AS IS"" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\n""""""ResNet Train/Eval module.\n""""""\nimport time\nimport sys\nimport os\n\nimport numpy as np\nimport dataloader\nimport json\nfrom tqdm import tqdm\n\nimport densenet\nimport resnet\nfrom PIL import Image\n\nimport torchvision\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom tools import parse\nfrom glob import glob\nfrom skimage import measure\nimport sys\nreload(sys)\nsys.setdefaultencoding(\'utf8\')\nimport traceback\n\nargs = parse.args\n# anchor\xe5\xa4\xa7\xe5\xb0\x8f\nargs.anchors = [8, 12, 18, 27, 40, 60]\nargs.stride = 8\nargs.image_size = [512,64]\n\n\nclass DenseNet121(nn.Module):\n    """"""Model modified.\n\n    The architecture of our model is the same as standard DenseNet121\n    except the classifier layer which has an additional sigmoid function.\n\n    """"""\n    def __init__(self, out_size):\n        super(DenseNet121, self).__init__()\n        self.inplanes = 1024\n        self.densenet121 = densenet.densenet121(pretrained=True, small=args.small)\n        num_ftrs = self.densenet121.classifier.in_features\n        self.classifier_font = nn.Sequential(\n                # \xe8\xbf\x99\xe9\x87\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa8fc\xe5\x81\x9a\xe5\x88\x86\xe7\xb1\xbb\n                # nn.Linear(num_ftrs, out_size)\n                # \xe8\xbf\x99\xe9\x87\x8c\xe5\x8f\xaf\xe4\xbb\xa5\xe7\x94\xa81\xc3\x971\xe5\x8d\xb7\xe7\xa7\xaf\xe5\x81\x9a\xe5\x88\x86\xe7\xb1\xbb\n                nn.Conv2d(num_ftrs, out_size, kernel_size=1, bias=False)\n        )\n        self.train_params = []\n        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x, phase=\'train\'):\n        feats = self.densenet121(x)     # (32, 1024, 2, 16)\n        if not args.small:\n            feats = F.max_pool2d(feats, kernel_size=2, stride=2) # (32, 1024, 1, 8)\n        out = self.classifier_font(feats) # (32, 1824, 1, 8)\n        out_size = out.size()\n        # print out.size()\n        out = out.view(out.size(0),out.size(1),-1) # (32, 1824, 8)\n        # print out.size()\n        if phase == \'train\':\n            out = F.adaptive_max_pool1d(out, output_size=(1)).view(out.size(0),-1) # (32, 1824)\n            return out\n        else:\n            out = out.transpose(1,2).contiguous()\n            out = out.view(out_size[0],out_size[2], out_size[3], out_size[1]) # (32, 1, 8, 1824)\n            return out, feats\n\nclass Loss(nn.Module):\n    def __init__(self):\n        super(Loss, self).__init__()\n        self.classify_loss = nn.BCELoss()\n        self.sigmoid = nn.Sigmoid()\n        self.regress_loss = nn.SmoothL1Loss()\n\n    def forward(self, font_output, font_target, weight=None, use_hard_mining=False):\n        font_output = self.sigmoid(font_output)\n        font_loss = F.binary_cross_entropy(font_output, font_target, weight)\n\n        # hard_mining \n        if use_hard_mining:\n            font_output = font_output.view(-1)\n            font_target = font_target.view(-1)\n            pos_index = font_target > 0.5\n            neg_index = font_target == 0\n\n            # pos\n            pos_output = font_output[pos_index]\n            pos_target = font_target[pos_index]\n            num_hard_pos = max(len(pos_output)/4, min(5, len(pos_output)))\n            if len(pos_output) > 5:\n                pos_output, pos_target = hard_mining(pos_output, pos_target, num_hard_pos, largest=False)\n            pos_loss = self.classify_loss(pos_output, pos_target) * 0.5\n\n\n            # neg\n            num_hard_neg = len(pos_output) * 2\n            neg_output = font_output[neg_index]\n            neg_target = font_target[neg_index]\n            neg_output, neg_target = hard_mining(neg_output, neg_target, num_hard_neg, largest=True)\n            neg_loss = self.classify_loss(neg_output, neg_target) * 0.5\n\n            font_loss += pos_loss + neg_loss\n\n        else:\n            pos_loss, neg_loss = font_loss, font_loss\n        return [font_loss, pos_loss, neg_loss]\n\n    def _forward(self, font_output, font_target, weight, bbox_output=None, bbox_label=None, seg_output=None, seg_labels=None):\n        font_output = self.sigmoid(font_output)\n        font_loss = F.binary_cross_entropy(font_output, font_target, weight)\n\n        acc = []\n        if bbox_output is not None:\n            # bbox_loss = 0\n            bbox_output = bbox_output.view((-1, 4))\n            bbox_label = bbox_label.view((-1, 4))\n            pos_index = bbox_label[:,-1] >= 0.5\n            pos_index = pos_index.unsqueeze(1).expand(pos_index.size(0), 4)\n            neg_index = bbox_label[:,-1] <= -0.5\n            neg_index = neg_index.unsqueeze(1).expand(neg_index.size(0), 4)\n\n            # \xe6\xad\xa3\xe4\xbe\x8b\n            pos_label = bbox_label[pos_index].view((-1,4))\n            pos_output = bbox_output[pos_index].view((-1,4))\n            lx,ly,ld,lc = pos_label[:,0],pos_label[:,1],pos_label[:,2],pos_label[:,3]\n            ox,oy,od,oc = pos_output[:,0],pos_output[:,1],pos_output[:,2],pos_output[:,3]\n            regress_loss = [\n                    self.regress_loss(ox, lx),\n                    self.regress_loss(oy, ly),\n                    self.regress_loss(od, ld),\n                    ]\n            pc = self.sigmoid(oc)\n            acc.append((pc>=0.5).data.cpu().numpy().astype(np.float32).sum())\n            acc.append(len(pc))\n            # print pc.size(), lc.size()\n            classify_loss = self.classify_loss(pc, lc) * 0.5\n\n            # \xe8\xb4\x9f\xe4\xbe\x8b\n            neg_label = bbox_label[neg_index].view((-1,4))\n            neg_output = bbox_output[neg_index].view((-1,4))\n            lc = neg_label[:, 3]\n            oc = neg_output[:, 3]\n            pc = self.sigmoid(oc)\n            acc.append((pc<=0.5).data.cpu().numpy().astype(np.float32).sum())\n            acc.append(len(pc))\n            # print pc.size(), lc.size()\n            classify_loss += self.classify_loss(pc, lc+1) * 0.5\n\n            # seg_loss\n            seg_output = seg_output.view(-1)\n            seg_labels = seg_labels.view(-1)\n            pos_index = seg_labels > 0.5\n            neg_index = seg_labels < 0.5\n            seg_loss = 0.5 * self.classify_loss(seg_output[pos_index], seg_labels[pos_index]) + \\\n                       0.5 * self.classify_loss(seg_output[neg_index], seg_labels[neg_index])\n            seg_tpr = (seg_output[pos_index] > 0.5).data.cpu().numpy().astype(np.float32).sum() / len(seg_labels[pos_index])\n            seg_tnr = (seg_output[neg_index] < 0.5).data.cpu().numpy().astype(np.float32).sum() / len(seg_labels[neg_index])\n            # print seg_output[neg_index]\n            # print seg_labels[neg_index]\n\n\n\n\n        else:\n            return font_loss\n\n        if args.model == \'resnet\':\n            loss = font_loss + classify_loss + seg_loss\n        else:\n            loss = font_loss + classify_loss + seg_loss\n        for reg in regress_loss:\n            loss += reg\n        # if args.model == \'resnet\':\n        #     loss = seg_loss\n\n        return [loss, font_loss, seg_loss, classify_loss] + regress_loss + acc + [seg_tpr, seg_tnr]\n\n        font_num = font_target.sum(0).data.cpu().numpy()\n        font_loss = 0\n        for di in range(font_num.shape[0]):\n            if font_num[di] > 0:\n                font_output_i = font_output[:,di]\n                font_target_i = font_target[:,di]\n                pos_font_index = font_target_i > 0.5\n                font_loss  += 0.5 * self.classify_loss(font_output_i[pos_font_index], font_target_i[pos_font_index])\n                neg_font_index = font_target_i < 0.5\n                if len(font_target_i[neg_font_index]) > 0:\n                    font_loss  += 0.5 * self.classify_loss(font_output_i[neg_font_index], font_target_i[neg_font_index])\n        font_loss = font_loss / (font_num>0).sum()\n\n        return font_loss\n        # \'\'\'\n\ndef hard_mining(neg_output, neg_labels, num_hard, largest=True):\n    num_hard = min(max(num_hard, 10), len(neg_output))\n    _, idcs = torch.topk(neg_output, min(num_hard, len(neg_output)), largest=largest)\n    neg_output = torch.index_select(neg_output, 0, idcs)\n    neg_labels = torch.index_select(neg_labels, 0, idcs)\n    return neg_output, neg_labels\n\ndef save_model(save_dir, phase, name, epoch, f1score, model):\n    if not os.path.exists(save_dir):\n        os.mkdir(save_dir)\n    save_dir = os.path.join(save_dir, args.model)\n    if not os.path.exists(save_dir):\n        os.mkdir(save_dir)\n    save_dir = os.path.join(save_dir, phase)\n    if not os.path.exists(save_dir):\n        os.mkdir(save_dir)\n    state_dict = model.state_dict()\n    for key in state_dict.keys():\n        state_dict[key] = state_dict[key].cpu()\n    state_dict_all = {\n            \'state_dict\': state_dict,\n            \'epoch\': epoch,\n            \'f1score\': f1score,\n            }\n    torch.save( state_dict_all , os.path.join(save_dir, \'{:s}.ckpt\'.format(name)))\n    if \'best\' in name and f1score > 0.3:\n        torch.save( state_dict_all , os.path.join(save_dir, \'{:s}_{:s}.ckpt\'.format(name, str(epoch))))\n\ndef mkdir(path):\n    if not os.path.exists(path):\n        os.mkdir(path)\n\ndef test(epoch, model, train_loader, phase=\'test\'):\n    print \'\\ntest {:s}_files, epoch: {:d}\'.format(phase, epoch)\n    mkdir(\'../../data/result\')\n    model.eval()\n    f1score_list = []\n    recall_list = []\n    precision_list = []\n    word_index_dict = json.load(open(args.word_index_json))\n    index_word_dict = { v:k for k,v in word_index_dict.items() }\n    result_file = open(\'../../data/result/{:d}_{:s}_result.csv\'.format(epoch, phase), \'w\')\n    result_file.write(\'name,content\\n\')\n    name_f1score_dict = dict()\n\n    # \xe4\xbf\x9d\xe5\xad\x98densenet\xe7\x94\x9f\xe6\x88\x90\xe7\x9a\x84feature\n    feat_dir = args.data_dir.replace(\'dataset\', \'feats\')\n    mkdir(feat_dir)\n    feat_dir = os.path.join(feat_dir, phase)\n    print feat_dir\n    mkdir(feat_dir)\n\n    names = []\n    if phase != \'test\':\n        gt_file = open(\'../../data/result/{:d}_{:s}_gt.csv\'.format(epoch, phase), \'w\')\n        gt_file.write(\'name,content\\n\')\n        analysis_file = open(\'../../data/result/{:s}_{:s}_gt.csv\'.format(\'analysis\', phase), \'w\')\n        os.system(\'rm -r ../../data/analysis/{:s}\'.format(phase))\n        labels_all = []\n    probs_all = []\n    for i,data in enumerate(tqdm(train_loader)):\n        name = data[0][0].split(\'/\')[-1].split(\'.seg\')[0]\n        names.append(name)\n        images, labels = [Variable(x.cuda(async=True)) for x in data[1:3]]\n        if len(images.size()) == 5:\n            images = images[0]\n\n        probs, feats = model(images, \'test\')\n        probs_all.append(probs.data.cpu().numpy().max(2).max(1).max(0))\n\n        preds = probs.data.cpu().numpy() > 0.5 # (-1, 8, 1824)\n\n        # result_file.write(name+\',\')\n        result = u\'\'\n        last_set = set()\n        all_set = set()\n\n        if args.feat:\n            # \xe4\xbf\x9d\xe5\xad\x98\xe6\x89\x80\xe6\x9c\x89\xe7\x9a\x84feat\n            feats = feats.data.cpu().numpy()\n            if i == 0:\n                print feats.shape\n            np.save(os.path.join(feat_dir, name.replace(\'.png\',\'.npy\')), feats)\n            if len(feats) > 1: # feats: [-1, 1024, 1, 8]\n                # \xe5\xa4\x9a\xe4\xb8\xaapatch\n                new_feats = []\n                for i,feat in enumerate(feats):\n                    if i == 0:\n                        # \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaapatch,\xe4\xbf\x9d\xe5\xad\x98\xe5\x89\x8d6\xe4\xb8\xaa\n                        new_feats.append(feat[:,:,:6])\n                    elif i == len(feats) - 1:\n                        # \xe6\x9c\x80\xe5\x90\x8e\xe4\xb8\x80\xe4\xb8\xaapatch,\xe4\xbf\x9d\xe5\xad\x98\xe5\x90\x8e6\xe4\xb8\xaa\n                        new_feats.append(feat[:,:,2:])\n                    else:\n                        # \xe4\xbf\x9d\xe5\xad\x98\xe4\xb8\xad\xe9\x97\xb44\xe4\xb8\xaa\n                        new_feats.append(feat[:,:,2:6])\n                feats = np.concatenate(new_feats, 2)\n\n        # \xe8\xbf\x99\xe7\xa7\x8d\xe6\x96\xb9\xe6\xb3\x95\xe7\x94\xa8\xe4\xba\x8e\xe6\xa3\x80\xe6\xb5\x8b\xe4\xb8\x8d\xe5\x90\x8c\xe5\x8c\xba\xe5\x9f\x9f\xe7\x9a\x84\xe5\x90\x8c\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xef\xbc\x8c\xe5\xbd\x93\xe5\x90\x8c\xe4\xb8\x80\xe4\xb8\xaa\xe5\xad\x97\xe5\x90\x8c\xe4\xb8\x80\xe4\xb8\xaa\xe5\x8c\xba\xe5\x9f\x9f\xe5\x87\xba\xe7\x8e\xb0\xe6\x97\xb6\xef\xbc\x8c\xe5\x8f\xaf\xe8\x83\xbd\xe6\xa3\x80\xe6\xb5\x8b\xe4\xb8\x8d\xe5\x88\xb0\xe5\xa4\x9a\xe6\xac\xa1\n        preds = preds.max(1) # \xe6\xb2\xbf\xe7\x9d\x80\xe7\xab\x96\xe7\x9b\xb4\xe6\x96\xb9\xe5\x90\x91pooling\n        # if len(preds) > 1:\n        #     print name\n        for patch_i, patch_pred in enumerate(preds):\n            for part_i, part_pred in enumerate(patch_pred):\n                new_set = set()\n                for idx,p in enumerate(part_pred):\n                    if p:\n                        # \xe5\x87\xba\xe7\x8e\xb0\xe4\xba\x86\xe8\xbf\x99\xe4\xb8\xaa\xe5\xad\x97\n                        w = index_word_dict[idx]\n                        new_set.add(w)\n                        if w not in all_set:\n                            # \xe4\xbb\x8e\xe6\xb2\xa1\xe8\xa7\x81\xe8\xbf\x87\xe7\x9a\x84\xe5\xad\x97\n                            all_set.add(w)\n                            result += w\n                        elif w not in last_set:\n                            # \xe4\xbb\xa5\xe5\x89\x8d\xe5\x87\xba\xe7\x8e\xb0\xe8\xbf\x87\n                            if patch_i == 0:\n                                # \xe7\xac\xac\xe4\xb8\x80\xe4\xb8\xaapatch # \xe4\xb8\x8a\xe4\xb8\x80\xe4\xb8\xaa\xe9\x83\xa8\xe5\x88\x86\xe6\xb2\xa1\xe6\x9c\x89\xe8\xbf\x99\xe4\xb8\xaa\xe5\xad\x97\n                                result += w\n                            elif part_i >= preds.shape[1]/2 :\n                                # \xe5\x90\x8e\xe7\xbb\xadpatch\xe7\x9a\x84\xe5\x90\x8e\xe4\xb8\x80\xe5\x8d\x8a\xef\xbc\x8c\xe4\xb8\x8d\xe5\x86\x99 # \xe4\xb8\x8a\xe4\xb8\x80\xe4\xb8\xaa\xe9\x83\xa8\xe5\x88\x86\xe6\xb2\xa1\xe6\x9c\x89\xe8\xbf\x99\xe4\xb8\xaa\xe5\xad\x97\n                                result += w\n                last_set = new_set\n        # if len(result) > len(set(result)):\n        #     print name\n\n\n\n\n        \'\'\'\n        for idx,p in enumerate(preds.reshape(-1)):\n            if p:\n                # result_file.write(index_word_dict[idx])\n                result = result + index_word_dict[idx]\n        \'\'\'\n\n        result = result.replace(u\'""\', u\'\')\n        if u\',\'  in result:\n            result = \'""\' + result + \'""\'\n        if len(result) == 0:\n            global_prob = probs.data.cpu().numpy().max(0).max(0).max(0)\n            max_index = global_prob.argmax()\n            result = index_word_dict[max_index]\n            print name\n\n        result_file.write(name+\',\'+result+\'\\n\')\n        # result_file.write(\'\\n\')\n\n        if phase == \'test\':\n            continue\n        labels = labels.data.cpu().numpy()\n        gt_file.write(name+\',\')\n        gt = u\'\'\n        for idx,l in enumerate(labels.reshape(-1)):\n            if l:\n                gt = gt + index_word_dict[idx]\n                gt_file.write(index_word_dict[idx])\n        gt_file.write(\'\\n\')\n\n        \n        labels_all.append(labels[0])\n        # \xe5\x85\xa8\xe5\xb1\x80pooling\n        preds = np.array([preds.max(1).max(0)])\n        # print preds.shape\n        for pred, label in zip(preds, labels):\n            tp = (pred + label == 2).sum()\n            tn = (pred + label == 0).sum()\n            fp = (pred - label == 1).sum()\n            fn = (pred - label ==-1).sum()\n            precision = 1.0 * tp / max(tp + fp , 10e-20)\n            recall   = 1.0 * tp / max(tp + fn , 10e-20)\n            f1score = 2. * precision * recall / max(precision + recall , 10e-20)\n            precision_list.append(precision)\n            recall_list.append(recall)\n            f1score_list.append(f1score)\n            name_f1score_dict[name] = f1score\n\n            # \xe5\x88\x86\xe6\x9e\x90\xe4\xb8\x8d\xe5\xa5\xbd\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\n            if phase == \'train_val\':\n                th = 0.8\n            elif phase == \'train\':\n                th = 0.95\n            else:\n                th = 0.6\n            if f1score < th:\n                save_dir = \'../../data/analysis\'\n                if not os.path.exists(save_dir):\n                    os.mkdir(save_dir)\n                save_dir = os.path.join(save_dir, phase)\n                if not os.path.exists(save_dir):\n                    os.mkdir(save_dir)\n                os.system(\'cp ../../data/dataset/train/{:s} {:s}/{:d}_{:s}\'.format(name, save_dir, 100000+i, name))\n                analysis_file.write(name+\'\\t\\t\')\n                gt = set(gt)\n                result = set(result.strip(\'""\'))\n                analysis_file.write(\'\'.join(sorted(gt - result))+\'\\t\\t\')\n                analysis_file.write(\'\'.join(sorted(result - gt))+\'\\t\\n\')\n                \n            \n    \n    if phase != \'test\':\n        # f1score = np.mean(f1score_list)\n        # print \'f1score all\', f1score\n        # f1score_list = sorted(f1score_list)[500:]\n        f1score = np.mean(f1score_list)\n        recall = np.mean(recall_list)\n        precision = np.mean(precision_list)\n        print \'f1score\', f1score\n        print \'recall\', recall\n        print \'precision\', precision\n        gt_file.write(\'f1score,\' +  str(f1score))\n        gt_file.write(\'recall,\' +  str(recall))\n        gt_file.write(\'precision,\' +  str(precision))\n        gt_file.close()\n        result_file.write(\'f1score,\' +  str(f1score))\n        result_file.write(\'recall,\' +  str(recall))\n        result_file.write(\'precision,\' +  str(precision))\n        with open(\'../../data/result/name_f1score_dict.json\',\'w\') as f:\n            f.write(json.dumps(name_f1score_dict, indent=4))\n        np.save(\'../../data/result/{:d}_{:s}_labels.npy\'.format(epoch, phase), labels_all)\n    result_file.close()\n    os.system(\'cp ../../data/result/{:d}_{:s}_result.csv ../../data/result/{:s}_result.csv\'.format(epoch, phase, phase))\n\n    np.save(\'../../data/result/{:d}_{:s}_probs.npy\'.format(epoch, phase), probs_all)\n    with open(\'../../data/result/{:s}_names.json\'.format(phase), \'w\') as f:\n        f.write(json.dumps(names, indent=4))\n\ndef get_weight(labels):\n    labels = labels.data.cpu().numpy()\n    weights = np.zeros_like(labels)\n    # weight_false = 1.0 / ((labels<0.5).sum() + 10e-20)\n    # weight_true  = 1.0 / ((labels>0.5).sum() + 10e-20)\n    weight_false = 1.0 / ((labels<0.5).sum(0) + 10e-20)\n    label_true = (labels>0.5).sum(0)\n    for i in range(labels.shape[1]):\n        label_i = labels[:,i]\n        weight_i = np.ones(labels.shape[0]) * weight_false[i]\n        # weight_i = np.ones(labels.shape[0]) * weight_false\n        if label_true[i] > 0:\n            weight_i[label_i>0.5] = 1.0 / label_true[i]\n        weights[:,i] = weight_i\n    weights *= np.ones_like(labels).sum() / (weights.sum() + 10e-20)\n    weights[labels<-0.5] = 0\n    return weights\n\ndef train_eval(epoch, model, train_loader, loss, optimizer, best_f1score=0, phase=\'train\'):\n    print \'\\n\',epoch, phase\n    if \'train\' in phase:\n        model.train()\n    else:\n        model.eval()\n    loss_list = []\n    f1score_list = []\n    recall_list = []\n    precision_list = []\n    for i,data in enumerate(tqdm(train_loader)):\n        images, labels = [Variable(x.cuda(async=True)) for x in data[1:3]]\n        weights = torch.from_numpy(get_weight(labels)).cuda(async=True)\n        probs = model(images)\n\n        # \xe8\xae\xad\xe7\xbb\x83\xe9\x98\xb6\xe6\xae\xb5\n        if \'train\' in phase:\n            loss_output = loss(probs, labels, weights, args.hard_mining)\n            try:\n                optimizer.zero_grad()\n                loss_output[0].backward()\n                optimizer.step()\n                loss_list.append([x.data.cpu().numpy()[0] for x in loss_output])\n            except:\n                # pass\n                traceback.print_exc()\n\n\n        # \xe8\xae\xa1\xe7\xae\x97 f1score, recall, precision\n        \'\'\'\n        x = probs.data.cpu().numpy() \n        l = labels.data.cpu().numpy()\n        print (get_weight(labels) * l).sum()\n        l = 1 - l\n        print (get_weight(labels) * l).sum()\n        print x.max()\n        print x.min()\n        print x.mean()\n        print\n        # \'\'\'\n        preds = probs.data.cpu().numpy() > 0\n        labels = labels.data.cpu().numpy()\n        for pred, label in zip(preds, labels):\n            pred[label<0] = -1\n            if label.sum() < 0.5:\n                continue\n            tp = (pred + label == 2).sum()\n            tn = (pred + label == 0).sum()\n            fp = (pred - label == 1).sum()\n            fn = (pred - label ==-1).sum()\n            precision = 1.0 * tp / (tp + fp + 10e-20)\n            recall   = 1.0 * tp / (tp + fn + 10e-20)\n            f1score = 2. * precision * recall / (precision + recall + 10e-20)\n            precision_list.append(precision)\n            recall_list.append(recall)\n            f1score_list.append(f1score)\n    \n            \n        # \xe4\xbf\x9d\xe5\xad\x98\xe4\xb8\xad\xe9\x97\xb4\xe7\xbb\x93\xe6\x9e\x9c\xe5\x88\xb0 data/middle_result\xef\xbc\x8c\xe7\x94\xa8\xe4\xba\x8e\xe5\x88\x86\xe6\x9e\x90\n        if i == 0:\n            images = images.data.cpu().numpy() * 128 + 128\n            if phase == \'pretrain\':\n                bbox_labels = bbox_labels.data.cpu().numpy()\n                seg_labels = seg_labels.data.cpu().numpy()\n                seg_output = seg_output.data.cpu().numpy()\n            for ii in range(len(images)):\n                middle_dir = os.path.join(args.save_dir, \'middle_result\')\n                if not os.path.exists(middle_dir):\n                    os.mkdir(middle_dir)\n                middle_dir = os.path.join(middle_dir, phase)\n                if not os.path.exists(middle_dir):\n                    os.mkdir(middle_dir)\n                Image.fromarray(images[ii].astype(np.uint8).transpose(1,2,0)).save(os.path.join(middle_dir, str(ii)+\'.image.png\'))\n                if phase == \'pretrain\':\n                    segi = seg_labels[ii]\n                    _segi = np.array([segi, segi, segi]) * 255\n                    segi = np.zeros([3, _segi.shape[1]*2, _segi.shape[2]*2])\n                    for si in range(segi.shape[1]):\n                        for sj in range(segi.shape[2]):\n                            segi[:,si,sj] = _segi[:,si/2,sj/2]\n                    Image.fromarray(segi.transpose(1,2,0).astype(np.uint8)).save(os.path.join(middle_dir, str(ii)+\'.seg.png\'))\n                    segi = seg_output[ii]\n                    _segi = np.array([segi, segi, segi]) * 255\n                    segi = np.zeros([3, _segi.shape[1]*2, _segi.shape[2]*2])\n                    for si in range(segi.shape[1]):\n                        for sj in range(segi.shape[2]):\n                            segi[:,si,sj] = _segi[:,si/2,sj/2]\n                    Image.fromarray(segi.transpose(1,2,0).astype(np.uint8)).save(os.path.join(middle_dir, str(ii)+\'.seg.out.png\'))\n\n    f1score = np.mean(f1score_list)\n    print \'f1score\', f1score\n    print \'recall\', np.mean(recall_list)\n    print \'precision\', np.mean(precision_list)\n    if \'train\' in phase:\n        loss_mean = np.array(loss_list).mean(0)\n        print \'loss: {:3.4f}    pos loss: {:3.4f}   neg loss: {:3.4f}\'.format(loss_mean[0], loss_mean[1], loss_mean[2])\n\n    # \xe4\xbf\x9d\xe5\xad\x98\xe6\xa8\xa1\xe5\x9e\x8b\n    if (\'eval\' in phase or \'pretrain\' in phase)and best_f1score < 2: \n        if args.small:\n            save_dir = os.path.join(args.save_dir, \'models-small\')\n        else:\n            save_dir = os.path.join(args.save_dir, \'models\')\n        if not os.path.exists(save_dir):\n            os.mkdir(save_dir)\n        if epoch % 5 == 0:\n            save_model(save_dir, phase, str(epoch), epoch, f1score, model)\n        if f1score > best_f1score:\n            save_model(save_dir, phase, \'best_f1score\', epoch, f1score, model)\n        if args.model == \'resnet\':\n            tpnr = loss[11] + loss[12]\n            # \xe8\xbf\x99\xe9\x87\x8c\xe7\x94\xa8 best_f1score \xe4\xb9\x9f\xe5\xbd\x93tpnr\xe5\xa5\xbd\xe4\xba\x86\xef\xbc\x8c\xe6\x87\x92\xe5\xbe\x97\xe6\x94\xb9\n            if tpnr > best_f1score:\n                best_f1score = tpnr\n                save_model(save_dir, phase, \'best_tpnr\', epoch, f1score, model)\n            print \'best tpnr\', best_f1score\n        else:\n            best_f1score = max(best_f1score, f1score)\n            if best_f1score < 1:\n                print \'\\n\\t{:s}\\tbest f1score {:3.4f}\\n\'.format(phase, best_f1score)\n        return best_f1score\n\n\ndef main():\n    word_index_dict = json.load(open(args.word_index_json))\n    num_classes = len(word_index_dict)\n    image_label_dict = json.load(open(args.image_label_json))\n\n    cudnn.benchmark = True\n    if args.model == \'densenet\':\n        # \xe4\xb8\xa4\xe5\x8d\x83\xe5\xa4\x9a\xe7\xa7\x8d\xe5\xad\x97\xe7\xac\xa6\xef\xbc\x8cmulti-label\xe5\x88\x86\xe7\xb1\xbb\n        model = DenseNet121(num_classes).cuda()\n    elif args.model == \'resnet\':\n        # resnet\xe4\xb8\xbb\xe8\xa6\x81\xe7\x94\xa8\xe4\xba\x8e\xe6\x96\x87\xe5\xad\x97\xe5\x8c\xba\xe5\x9f\x9f\xe7\x9a\x84segmentation\xe4\xbb\xa5\xe5\x8f\x8aobject detection\xe6\x93\x8d\xe4\xbd\x9c\n        model = resnet.ResNet(num_classes=num_classes, args=args).cuda()\n    else:\n        return\n    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n    # model = torch.nn.DataParallel(model).cuda()\n    loss = Loss().cuda()\n\n    if args.resume:\n        state_dict = torch.load(args.resume)\n        model.load_state_dict(state_dict[\'state_dict\'])\n        best_f1score = state_dict[\'f1score\']\n        start_epoch = state_dict[\'epoch\'] + 1\n    else:\n        best_f1score = 0\n        if args.model == \'resnet\':\n            start_epoch = 100\n        else:\n            start_epoch = 1\n    args.epoch = start_epoch\n    print \'best_f1score\', best_f1score\n\n\n    # \xe5\x88\x92\xe5\x88\x86\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\n    test_filelist = sorted(glob(os.path.join(args.data_dir,\'test\',\'*\')))\n    trainval_filelist = sorted(glob(os.path.join(args.data_dir,\'train\',\'*\')))\n\n    # \xe4\xb8\xa4\xe7\xa7\x8d\xe8\xbe\x93\xe5\x85\xa5size\xe8\xae\xad\xe7\xbb\x83\n    # train_filelist1: \xe9\x95\xbf\xe5\xae\xbd\xe6\xaf\x94\xe5\xb0\x8f\xe4\xba\x8e8:1\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe7\xbb\x8f\xe8\xbf\x87padding\xe5\x90\x8e\xe5\x8f\x98\xe6\x88\x90 64*512 \xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\n    # train_filelist2: \xe9\x95\xbf\xe5\xae\xbd\xe6\xaf\x94\xe5\xa4\xa7\xe4\xba\x8e8:1\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87\xef\xbc\x8c\xe7\xbb\x8f\xe8\xbf\x87padding,crop\xe5\x90\x8e\xe5\x8f\x98\xe6\x88\x90 64*1024\xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5\n    train_filelist1, train_filelist2 = [],[]\n\n    # \xe9\xbb\x91\xe5\x90\x8d\xe5\x8d\x95\xef\xbc\x8c\xe8\xbf\x99\xe4\xba\x9b\xe5\x9b\xbe\xe7\x89\x87\xe7\x9a\x84label\xe6\x98\xaf\xe6\x9c\x89\xe9\x97\xae\xe9\xa2\x98\xe7\x9a\x84\n    black_list = set(json.load(open(args.black_json))[\'black_list\'])\n    image_hw_ratio_dict = json.load(open(args.image_hw_ratio_json))\n    for f in trainval_filelist:\n        image = f.split(\'/\')[-1]\n        if image in black_list:\n            continue\n        r = image_hw_ratio_dict[image]\n        if r == 0:\n            train_filelist1.append(f)\n        else:\n            train_filelist2.append(f)\n    train_val_filelist = train_filelist1 + train_filelist2\n    val_filelist = train_filelist1[-2048:]\n    train_filelist1 = train_filelist1[:-2048]\n\n    train_filelist2 = train_filelist2\n    image_size = [512, 64]\n\n    if args.phase in [\'test\', \'val\', \'train_val\']:\n        # \xe6\xb5\x8b\xe8\xaf\x95\xe8\xbe\x93\xe5\x87\xba\xe6\x96\x87\xe5\xad\x97\xe6\xa3\x80\xe6\xb5\x8b\xe7\xbb\x93\xe6\x9e\x9c\n        test_dataset = dataloader.DataSet(\n                test_filelist, \n                image_label_dict,\n                num_classes, \n                # transform=train_transform, \n                args=args,\n                image_size=image_size,\n                phase=\'test\')\n        test_loader = DataLoader(\n                dataset=test_dataset, \n                batch_size=1, \n                shuffle=False, \n                num_workers=8, \n                pin_memory=True)\n        train_filelist = train_filelist1[-2048:]\n        train_dataset  = dataloader.DataSet(\n                train_filelist, \n                image_label_dict, \n                num_classes, \n                image_size=image_size,\n                args=args,\n                phase=\'test\')\n        train_loader = DataLoader(\n                dataset=train_dataset, \n                batch_size=1,\n                shuffle=False, \n                num_workers=8, \n                pin_memory=True)\n\n        val_dataset  = dataloader.DataSet(\n                val_filelist, \n                image_label_dict, \n                num_classes, \n                image_size=image_size,\n                args=args,\n                phase=\'test\')\n        val_loader = DataLoader(\n                dataset=val_dataset, \n                batch_size=1,\n                shuffle=False, \n                num_workers=8, \n                pin_memory=True)\n\n        train_val_dataset  = dataloader.DataSet(\n                train_val_filelist, \n                image_label_dict, \n                num_classes, \n                image_size=image_size,\n                args=args,\n                phase=\'test\')\n        train_val_loader= DataLoader(\n                dataset=train_val_dataset, \n                batch_size=1,\n                shuffle=False, \n                num_workers=8, \n                pin_memory=True)\n\n        if args.phase == \'test\':\n            test(start_epoch - 1, model, val_loader, \'val\')\n            test(start_epoch - 1, model, test_loader, \'test\')\n            # test(start_epoch - 1, model, train_val_loader, \'train_val\')\n        elif args.phase == \'val\':\n            test(start_epoch - 1, model, train_loader, \'train\')\n            test(start_epoch - 1, model, val_loader, \'val\')\n        elif args.phase == \'train_val\':\n            test(start_epoch - 1, model, train_val_loader, \'train_val\')\n        return\n\n    elif args.phase == \'train\':\n\n        train_dataset1 = dataloader.DataSet(\n                train_filelist1,\n                image_label_dict,\n                num_classes, \n                image_size=image_size,\n                args=args,\n                phase=\'train\')\n        train_loader1 = DataLoader(\n                dataset=train_dataset1, \n                batch_size=args.batch_size, \n                shuffle=True, \n                num_workers=8, \n                pin_memory=True)\n        train_dataset2 = dataloader.DataSet(\n                train_filelist2, \n                image_label_dict,\n                num_classes, \n                image_size=(1024,64),\n                args=args,\n                phase=\'train\')\n        train_loader2 = DataLoader(\n                dataset=train_dataset2, \n                batch_size=args.batch_size / 2, \n                shuffle=True, \n                num_workers=8, \n                pin_memory=True)\n        val_dataset  = dataloader.DataSet(\n                val_filelist, \n                image_label_dict, \n                num_classes, \n                image_size=image_size,\n                args=args,\n                phase=\'val\')\n        val_loader = DataLoader(\n                dataset=val_dataset, \n                batch_size=min(8,args.batch_size),\n                shuffle=False, \n                num_workers=8, \n                pin_memory=True)\n        filelist = glob(os.path.join(args.bg_dir,\'*\'))\n        pretrain_dataset1 = dataloader.DataSet(\n                filelist, \n                image_label_dict,\n                num_classes, \n                image_size=args.image_size,\n                word_index_dict = word_index_dict,\n                args=args,\n                font_range=[8,32],\n                margin=10,\n                rotate_range=[-10., 10. ],\n                phase=\'pretrain\')\n        pretrain_loader1 = DataLoader(\n                dataset=pretrain_dataset1, \n                batch_size=args.batch_size, \n                shuffle=True, \n                num_workers=8, \n                pin_memory=True)\n        pretrain_dataset2 = dataloader.DataSet(\n                filelist, \n                image_label_dict,\n                num_classes, \n                image_size=(256, 128),\n                word_index_dict = word_index_dict,\n                args=args,\n                font_range=[24,64],\n                margin=20,\n                rotate_range=[-20., 20.],\n                phase=\'pretrain\')\n        pretrain_loader2 = DataLoader(\n                dataset=pretrain_dataset2, \n                batch_size=args.batch_size, \n                shuffle=True, \n                num_workers=8, \n                pin_memory=True)\n    \n        best_f1score = 0\n        # eval_mode = \'pretrain-2\'\n        eval_mode = \'eval\'\n        for epoch in range(start_epoch, args.epochs):\n\n            args.epoch = epoch\n\n            if eval_mode == \'eval\':\n                if best_f1score > 0.9:\n                    args.lr = 0.0001\n                if best_f1score > 0.9:\n                    args.hard_mining = 1\n\n            for param_group in optimizer.param_groups:\n                param_group[\'lr\'] = args.lr\n\n            train_eval(epoch, model, train_loader1, loss, optimizer, 2., \'train-1\')\n            if best_f1score > 0.9:\n                train_eval(epoch, model, train_loader2, loss, optimizer, 2., \'train-2\')\n            best_f1score = train_eval(epoch, model, val_loader, loss, optimizer, best_f1score, \'eval-{:d}-{:d}\'.format(args.batch_size, args.hard_mining))\n            continue\n            \'\'\'\n\n            if eval_mode == \'pretrain-2\':\n                args.epoch = 1\n                best_f1score = train_eval(epoch, model, pretrain_loader2, loss, optimizer, best_f1score, \'pretrain-2\')\n                if best_f1score > 0.8:\n                    eval_mode = \'pretrain-1\'\n                    best_f1score = 0\n            elif eval_mode == \'pretrain-1\':\n                args.epoch = max(100, epoch)\n                train_eval(epoch, model, pretrain_loader2, loss, optimizer, 2.0 , \'pretrain-2\')\n                best_f1score = train_eval(epoch, model, pretrain_loader1, loss, optimizer, best_f1score, \'pretrain-1\')\n                if best_f1score > 0.5:\n                    eval_mode = \'eval\'\n                    best_f1score = 0\n            else:\n                train_eval(epoch, model, train_loader1, loss, optimizer, 2., \'train-1\')\n                train_eval(epoch, model, train_loader2, loss, optimizer, 2., \'train-2\')\n                best_f1score = train_eval(epoch, model, val_loader, loss, optimizer, best_f1score, \'eval-{:d}-{:d}\'.format(args.batch_size, args.hard_mining))\n\n            \'\'\'\n\n\n    \n\n\n\nif __name__ == \'__main__\':\n    main()\n'"
code/ocr/resnet.py,7,"b""# Implementation of https://arxiv.org/pdf/1512.03385.pdf.\n# See section 4.2 for model architecture on CIFAR-10.\n# Some part of the code was referenced below.\n# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\nimport torch \nimport torch.nn as nn\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\n# 3x3 Convolution\ndef conv3x3(in_channels, out_channels, stride=1):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n                     stride=stride, padding=1, bias=False)\n\n# Residual Block\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = conv3x3(in_channels, out_channels, stride)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(out_channels, out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = downsample\n        \n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        return out\n\n# ResNet Module\nclass ResNet(nn.Module):\n    def __init__(self, block=ResidualBlock, layers=[2,3], num_classes=10, args=None):\n        super(ResNet, self).__init__()\n        self.in_channels = 16\n        self.conv = conv3x3(3, 16)\n        self.bn = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self.make_layer(block, 32, layers[0], 2)\n        self.layer2 = self.make_layer(block, 64, layers[0], 2)\n        self.layer3 = self.make_layer(block, 128, layers[0], 2)\n        self.layer4 = self.make_layer(block, 128, layers[0], 2)\n        self.layer5 = self.make_layer(block, 128, layers[0], 2)\n        self.fc = nn.Linear(128, num_classes)\n\n        # detect\n        self.convt1 = nn.Sequential(\n                nn.ConvTranspose2d(128,128,kernel_size=2, stride=2), \n                nn.BatchNorm2d(128),\n                nn.ReLU(inplace=True))\n        self.convt2 = nn.Sequential(\n                nn.ConvTranspose2d(128,128,kernel_size=2, stride=2), \n                nn.BatchNorm2d(128),\n                nn.ReLU(inplace=True))\n        self.convt3 = nn.Sequential(\n                nn.ConvTranspose2d(128,128,kernel_size=2, stride=2), \n                nn.BatchNorm2d(128),\n                nn.ReLU(inplace=True))\n        self.convt4 = nn.Sequential(\n                nn.ConvTranspose2d(128,128,kernel_size=2, stride=2), \n                nn.BatchNorm2d(128),\n                nn.ReLU(inplace=True))\n        self.in_channels = 256\n        self.dec1 = self.make_layer(block, 128, layers[0])\n        self.in_channels = 256\n        self.dec2 = self.make_layer(block, 128, layers[0])\n        self.in_channels = 192\n        self.dec3 = self.make_layer(block, 128, layers[0])\n        self.in_channels = 160\n        # self.dec4 = self.make_layer(block, 1, layers[0])\n        self.dec4 = nn.Sequential(\n                nn.Conv2d(160, 256, kernel_size=3, padding=1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(256, 1, kernel_size=1, bias=True)\n                )\n        self.in_channels = 256\n        # self.dec2 = self.make_layer(block, 256, layers[0])\n        # self.output = conv3x3(256, 4 * len(args.anchors))\n        self.bbox = nn.Sequential(\n                nn.Conv2d(256, 256, kernel_size=3, padding=1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(256, 4 * len(args.anchors), kernel_size=1, bias=True)\n                )\n        self.sigmoid = nn.Sigmoid()\n\n        \n    def make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if (stride != 1) or (self.in_channels != out_channels):\n            downsample = nn.Sequential(\n                conv3x3(self.in_channels, out_channels, stride=stride),\n                nn.BatchNorm2d(out_channels))\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels\n        for i in range(1, blocks):\n            layers.append(block(out_channels, out_channels))\n        return nn.Sequential(*layers)\n    \n    def forward(self, x, phase='train'):\n        out = self.conv(x)\n        # print out.size()\n        out = self.bn(out)\n        # print out.size()\n        out = self.relu(out)\n        # print out.size()\n        out1 = self.layer1(out)     # 64\n        # print out1.size()\n        out2 = self.layer2(out1)    # 32\n        # print out2.size()\n        out3 = self.layer3(out2)    # 16\n        # print out3.size()\n        out4 = self.layer4(out3)    # 8\n        # print out4.size()\n        out5 = self.layer5(out4)    # 4\n        # print out5.size()\n\n        # out = F.adaptive_max_pool2d(out5, output_size=(1,1)).view(out.size(0), -1) # 128\n        # out = out.view(out.size(0), -1)\n\n        if phase == 'seg':\n            out = F.adaptive_max_pool2d(out5, output_size=(1,1)).view(out.size(0), -1) # 128\n            out = self.fc(out)\n            out = out.view(out.size(0), -1)\n        else:\n            out = F.max_pool2d(out5, 2)\n            out_size = out.size()\n            # out = out.view(out_size[0],out_size[1],out_size[3]).transpose(1,2).contiguous().view(-1, out_size[1])\n            out = out.view(out_size[0],out_size[1],out_size[2] * out_size[3]).transpose(1,2).contiguous().view(-1, out_size[1])\n            out = self.fc(out)\n            out = out.view(out_size[0], out_size[2] * out_size[3], -1).transpose(1,2).contiguous()\n            out = F.adaptive_max_pool1d(out, output_size=(1)).view(out_size[0], -1)\n\n        # print out.size()\n        if phase not in ['seg', 'pretrain', 'pretrain2']:\n            return out\n\n        # detect\n        cat1 = torch.cat([self.convt1(out5), out4], 1)\n        # print cat1.size()\n        dec1 = self.dec1(cat1)\n        # print dec1.size()\n        # print out3.size()\n        cat2 = torch.cat([self.convt2(dec1), out3], 1) \n        # print cat2.size()\n        dec2 = self.dec2(cat2)\n        cat3 = torch.cat([self.convt3(dec2), out2], 1)\n        dec3 = self.dec3(cat3)\n        cat4 = torch.cat([self.convt4(dec3), out1], 1)\n        seg = self.dec4(cat4)\n        seg = seg.view((seg.size(0), seg.size(2), seg.size(3)))\n        seg = self.sigmoid(seg)\n        \n        bbox = self.bbox(cat2)\n        # dec2 = self.output(dec2)\n        # print dec2.size()\n        size = bbox.size()\n        bbox = bbox.view((size[0], size[1], -1)).transpose(1,2).contiguous()\n        bbox = bbox.view((size[0], size[2],size[3],-1, 4))\n\n        return out, bbox, seg\n    \n# resnet = ResNet(ResidualBlock, [2, 2, 2, 2])\n"""
code/preprocessing/analysis_dataset.py,0,"b""# coding=utf8\n#########################################################################\n# File Name: analysis_dataset.py\n# Author: ccyin\n# mail: ccyin04@gmail.com\n# Created Time: Fri 18 May 2018 04:19:58 PM CST\n#########################################################################\n'''\n\xe6\xad\xa4\xe6\x96\x87\xe4\xbb\xb6\xe7\x94\xa8\xe4\xba\x8e\xe5\x88\x86\xe6\x9e\x90\xe5\x8e\x9f\xe6\x9c\x89\xe6\x95\xb0\xe6\x8d\xae\xe9\x9b\x86\xe4\xbf\xa1\xe6\x81\xaf\n    stati_image_size: \xe7\xbb\x9f\xe8\xae\xa1\xe5\x9b\xbe\xe7\x89\x87\xe5\xa4\xa7\xe5\xb0\x8f\xe4\xbf\xa1\xe6\x81\xaf\n    stati_label_length: \xe7\xbb\x9f\xe8\xae\xa1\xe6\x96\x87\xe5\xad\x97\xe9\x95\xbf\xe5\xba\xa6\xe4\xbf\xa1\xe6\x81\xaf\n'''\n\nimport os\nimport json\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\nimport sys\nsys.path.append('../ocr')\nfrom tools import plot\n\ndef stati_image_size(image_dir, save_dir, big_w_dir):\n    if not os.path.exists(big_w_dir):\n        os.mkdir(big_w_dir)\n    if not os.path.exists(save_dir):\n        os.mkdir(save_dir)\n    h_count_dict, w_count_dict, r_count_dict = { }, { }, { }\n    image_hw_ratio_dict = { }\n    for image in os.listdir(image_dir):\n        h,w = Image.open(os.path.join(image_dir, image)).size\n        if w > 80:\n            cmd = 'cp ../../data/dataset/train/{:s} {:s}'.format(image, big_w_dir)\n            # os.system(cmd)\n\n        r = int(h / 8. / w)\n        h = h / 10\n        w = w / 10\n        r_count_dict[r] = r_count_dict.get(r, 0) + 1\n        h_count_dict[h] = h_count_dict.get(h, 0) + 1\n        w_count_dict[w] = w_count_dict.get(w, 0) + 1\n        image_hw_ratio_dict[image] = r\n\n    with open(os.path.join(save_dir, 'image_hw_ratio_dict.json'), 'w') as f:\n        f.write(json.dumps(image_hw_ratio_dict, indent=4))\n\n    x = range(max(h_count_dict.keys())+1)\n    y = [0 for _ in x]\n    for h in sorted(h_count_dict.keys()):\n        print '\xe5\x9b\xbe\xe7\x89\x87\xe9\x95\xbf\xe5\xba\xa6:{:d}~{:d}\xef\xbc\x8c\xe6\x9c\x89{:d}\xe5\xbc\xa0\xe5\x9b\xbe'.format(10*h, 10*h+10, h_count_dict[h])\n        y[h] = h_count_dict[h]\n    plot.plot_multi_line([x], [y], ['Length'], save_path='../../data/length.png', show=True)\n\n    x = range(max(w_count_dict.keys())+1)\n    y = [0 for _ in x]\n    for w in sorted(w_count_dict.keys()):\n        print '\xe5\x9b\xbe\xe7\x89\x87\xe5\xae\xbd\xe5\xba\xa6:{:d}~{:d}\xef\xbc\x8c\xe6\x9c\x89{:d}\xe5\xbc\xa0\xe5\x9b\xbe'.format(10*w, 10*w+10, w_count_dict[w])\n        y[w] = w_count_dict[w]\n    plot.plot_multi_line([x], [y], ['Width'], save_path='../../data/width.png', show=True)\n\n    x = range(max(r_count_dict.keys())+1)\n    y = [0 for _ in x]\n    for r in sorted(r_count_dict.keys()):\n        print '\xe5\x9b\xbe\xe7\x89\x87\xe6\xaf\x94\xe4\xbe\x8b:{:d}~{:d}\xef\xbc\x8c\xe6\x9c\x89{:d}\xe5\xbc\xa0\xe5\x9b\xbe'.format(8*r, 8*r+8, r_count_dict[r])\n        y[r] = r_count_dict[r]\n    x = [8*(_+1) for _ in x]\n    plot.plot_multi_line([x], [y], ['L/W'], save_path='../../data/ratio.png', show=True)\n\n    print '\\n\xe6\x9c\x80\xe5\xa4\x9a\xe7\x9a\x84\xe9\x95\xbf\\n', sorted(h_count_dict.keys(), key=lambda h:h_count_dict[h])[-1] * 10\n    print '\\n\xe6\x9c\x80\xe5\xa4\x9a\xe7\x9a\x84\xe5\xae\xbd\\n', sorted(w_count_dict.keys(), key=lambda w:w_count_dict[w])[-1] * 10\n\n    print '\xe5\xbb\xba\xe8\xae\xae\xe4\xbd\xbf\xe7\x94\xa8 64 * 512 \xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5'\n    print '    \xe9\x83\xa8\xe5\x88\x86\xe4\xbd\xbf\xe7\x94\xa8 64 * 1024 \xe7\x9a\x84\xe8\xbe\x93\xe5\x85\xa5'\n    print '    \xe5\x89\xa9\xe4\xb8\x8b\xe7\x9a\x84\xe5\xbf\xbd\xe7\x95\xa5'\n    print '\xe5\xbb\xba\xe8\xae\xae\xe4\xbd\xbf\xe7\x94\xa8FCN\xe6\x9d\xa5\xe5\x81\x9a\xef\xbc\x8c\xe5\x85\xa8\xe5\xb1\x80\xe5\x8f\x96\xe6\x9c\x80\xe5\xa4\xa7\xe5\x80\xbc\xe5\xbe\x97\xe5\x88\xb0\xe6\x9c\x80\xe7\xbb\x88\xe7\xbb\x93\xe6\x9e\x9c'\n\ndef stati_label_length(label_json, long_text_dir):\n    if not os.path.exists(long_text_dir):\n        os.mkdir(long_text_dir)\n    image_label_json = json.load(open(label_json))\n    l_count_dict = { }\n    for image, label in image_label_json.items():\n        l = len(label.split())\n        l_count_dict[l] = l_count_dict.get(l, 0) + 1\n        if l > 25:\n            cmd = 'cp ../../data/dataset/train/{:s} {:s}'.format(image, long_text_dir)\n            # os.system(cmd)\n\n    word_num = 0.\n    x = range(max(l_count_dict.keys())+1)\n    y = [0 for _ in x]\n    for l in sorted(l_count_dict.keys()):\n        word_num += l * l_count_dict[l]\n        print '\xe6\x96\x87\xe5\xad\x97\xe9\x95\xbf\xe5\xba\xa6:{:d}\xef\xbc\x8c\xe6\x9c\x89{:d}\xe5\xbc\xa0\xe5\x9b\xbe'.format(l, l_count_dict[l])\n        y[l] = l_count_dict[l]\n    plot.plot_multi_line([x], [y], ['Word Number'], save_path='../../data/word_num.png', show=True)\n    print '\xe5\xb9\xb3\xe5\x9d\x87\xe6\xaf\x8f\xe5\xbc\xa0\xe5\x9b\xbe\xe7\x89\x87{:3.4f}\xe4\xb8\xaa\xe5\xad\x97'.format(word_num / sum(l_count_dict.values()))\n\ndef stati_image_gray(image_dir):\n    print 'eval train image gray'\n    for image in tqdm(os.listdir(image_dir)):\n        image = Image.open(os.path.join(image_dir, image)).convert('RGB')\n        image = np.array(image)\n        mi,ma = image.min(), image.max()\n        assert mi >= 0\n        assert ma < 256\n\n    print 'eval test image gray'\n    image_dir = image_dir.replace('train', 'test')\n    for image in tqdm(os.listdir(image_dir)):\n        image = Image.open(os.path.join(image_dir, image)).convert('RGB')\n        image = np.array(image)\n        mi,ma = image.min(), image.max()\n        assert mi >= 0\n        assert ma < 256\n\n\n\ndef main():\n    image_dir = '../../data/dataset/train'\n    save_dir = '../../files/'\n    big_w_dir = '../../data/big_w_dir'\n    stati_image_size(image_dir, save_dir, big_w_dir)\n\n    train_label_json = '../../files/train_alphabet.json'\n    long_text_dir = '../../data/long_text_dir'\n    stati_label_length(train_label_json, long_text_dir)\n    # stati_image_gray(image_dir)\n\nif __name__ == '__main__':\n    main()\n"""
code/preprocessing/map_word_to_index.py,0,"b'# coding=utf8\n#########################################################################\n# File Name: map_word_to_index.py\n# Author: ccyin\n# mail: ccyin04@gmail.com\n# Created Time: Fri 18 May 2018 03:30:26 PM CST\n#########################################################################\n\'\'\'\n\xe6\xad\xa4\xe4\xbb\xa3\xe7\xa0\x81\xe7\x94\xa8\xe4\xba\x8e\xe5\xb0\x86\xe6\x89\x80\xe6\x9c\x89\xe6\x96\x87\xe5\xad\x97\xe6\x98\xa0\xe5\xb0\x84\xe5\x88\xb0index\xe4\xb8\x8a\xef\xbc\x8c\xe6\x9c\x89\xe4\xb8\xa4\xe7\xa7\x8d\xe6\x96\xb9\xe5\xbc\x8f\n    1. \xe6\x98\xa0\xe5\xb0\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8b\xb1\xe6\x96\x87\xe5\x8d\x95\xe8\xaf\x8d\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaaindex\n    2. \xe6\x98\xa0\xe5\xb0\x84\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe8\x8b\xb1\xe6\x96\x87\xe5\xad\x97\xe6\xaf\x8d\xe4\xb8\xba\xe4\xb8\x80\xe4\xb8\xaaindex\n\'\'\'\n\nimport os\nimport sys\nreload(sys)\nsys.setdefaultencoding(\'utf8\')\nimport json\nfrom collections import OrderedDict\n\ndef map_word_to_index(train_word_file, word_index_json, word_count_json, index_label_json, alphabet_to_index=True):\n    with open(train_word_file, \'r\') as f:\n        labels = f.read().strip().decode(\'utf8\')\n    word_count_dict = { }\n    for line in labels.split(\'\\n\')[1:]:\n        line = line.strip()\n        image, sentence = line.strip().split(\'.png,\')\n        sentence = sentence.strip(\'""\')\n        for w in sentence:\n            word_count_dict[w] = word_count_dict.get(w,0) + 1\n    print \'\xe4\xb8\x80\xe5\x85\xb1\xe6\x9c\x89{:d}\xe7\xa7\x8d\xe5\xad\x97\xe7\xac\xa6\xef\xbc\x8c\xe5\x85\xb1{:d}\xe4\xb8\xaa\'.format(len(word_count_dict), sum(word_count_dict.values()))\n    word_sorted = sorted(word_count_dict.keys(), key=lambda k:word_count_dict[k], reverse=True)\n    # word_index_dict = { w:i for i,w in enumerate(word_sorted) }\n    word_index_dict = json.load(open(word_index_json))\n\n    with open(word_count_json, \'w\') as f:\n        f.write(json.dumps(word_count_dict, indent=4, ensure_ascii=False))\n    # with open(word_index_json, \'w\') as f:\n    #     f.write(json.dumps(word_index_dict, indent=4, ensure_ascii=False))\n        \n    image_label_dict = OrderedDict()\n    for line in labels.split(\'\\n\')[1:]:\n        line = line.strip()\n        image, sentence = line.strip().split(\'.png,\')\n        sentence = sentence.strip(\'""\')\n\n        # \xe6\x8d\xa2\xe6\x8e\x89\xe9\x83\xa8\xe5\x88\x86\xe7\x9b\xb8\xe4\xbc\xbc\xe7\xac\xa6\xe5\x8f\xb7\n        for c in u""\xe3\x80\x80 "":\n            sentence = sentence.replace(c, \'\')\n        replace_words = [\n                u\'(\xef\xbc\x88\',\n                u\')\xef\xbc\x89\',\n                u\',\xef\xbc\x8c\',\n                u""\xc2\xb4\'\xe2\x80\xb2"", \n                u""\xe2\x80\xb3\xef\xbc\x82\xe2\x80\x9c"",\n                u""\xef\xbc\x8e."",\n                u""\xe2\x80\x94-""\n                ]\n        for words in replace_words:\n            for w in words[:-1]:\n                sentence = sentence.replace(w, words[-1])\n\n        index_list = []\n        for w in sentence:\n            index_list.append(str(word_index_dict[w]))\n        image_label_dict[image + \'.png\'] = \' \'.join(index_list)\n    with open(index_label_json, \'w\') as f:\n        f.write(json.dumps(image_label_dict, indent=4))\n\n\ndef main():\n\n    # \xe6\x98\xa0\xe5\xb0\x84\xe5\xad\x97\xe6\xaf\x8d\xe4\xb8\xbaindex\n    train_word_file = \'../../files/train.csv\'\n    word_index_json = \'../../files/alphabet_index_dict.json\'\n    word_count_json = \'../../files/alphabet_count_dict.json\'\n    index_label_json = \'../../files/train_alphabet.json\'\n    map_word_to_index(train_word_file, word_index_json, word_count_json, index_label_json, True)\n\nif __name__ == \'__main__\':\n    main()\n'"
code/preprocessing/show_black.py,0,"b""# coding=utf8\n#########################################################################\n# File Name: show_black.py\n# Author: ccyin\n# mail: ccyin04@gmail.com\n# Created Time: 2018\xe5\xb9\xb406\xe6\x9c\x8807\xe6\x97\xa5 \xe6\x98\x9f\xe6\x9c\x9f\xe5\x9b\x9b 01\xe6\x97\xb606\xe5\x88\x8622\xe7\xa7\x92\n#########################################################################\n\nimport os\nimport sys\nimport json\nsys.path.append('../ocr')\nfrom tools import parse, py_op\nargs = parse.args\n\ndef cp_black_list(black_json, black_dir):\n    word_index_dict = json.load(open(args.word_index_json))\n    index_word_dict = { v:k for k,v in word_index_dict.items() }\n    train_word_dict = json.load(open(args.image_label_json))\n    train_word_dict = { k:''.join([index_word_dict[int(i)] for i in v.split()]) for k,v in train_word_dict.items() }\n\n    py_op.mkdir(black_dir)\n    black_list = json.load(open(black_json))['black_list']\n    for i,name in enumerate(black_list):\n        cmd = 'cp {:s} {:s}'.format(os.path.join(args.data_dir, 'train', name), black_dir)\n        if train_word_dict[name] in ['Err:501', '#NAME?', '###']:\n            continue\n        print name\n        print train_word_dict[name]\n        os.system(cmd)\n        if i > 30:\n            break\n\nif __name__ == '__main__':\n    black_dir = os.path.join(args.save_dir, 'black')\n    cp_black_list(args.black_json, black_dir)\n"""
code/ocr/tools/__init__.py,0,b''
code/ocr/tools/measures.py,0,"b""# coding=utf8\nimport os\nimport numpy as np\nfrom sklearn import metrics\nfrom PIL import Image\nimport traceback\n\ndef stati_class_number_true_flase(label, pred):\n    label = np.array(label)\n    pred = np.array(pred)\n\n    cls_list = set(label) | set(pred)\n    d = dict()\n    for cls in cls_list:\n        d[cls] = dict()\n        d[cls]['number'] = np.sum(label==cls)\n        d[cls]['true'] = np.sum(label[label==cls]==pred[label==cls])\n        d[cls]['pred'] = np.sum(pred==cls)\n    return d\n\ndef stati_class_number_true_flase_multi_label_margin(labels, preds):\n\n    d = dict()\n    for label, pred in zip(labels, preds):\n        label = set(label[label>=0])\n        for cls in range(len(pred)):\n            if cls not in d:\n                d[cls] = dict()\n                d[cls]['number'] = 0\n                d[cls]['true'] = 0\n                d[cls]['pred'] = 0\n            if cls in label:\n                d[cls]['number'] += 1\n                if pred[cls] > 0.5:\n                    d[cls]['true'] += 1\n            if pred[cls] > 0.5:\n                d[cls]['pred'] += 1\n    return d\n\ndef stati_class_number_true_flase_bce(labels, preds):\n    d = dict()\n    labels = labels.astype(np.int64).reshape(-1)\n    preds = preds.reshape(-1) > 0\n    index = labels >= 0\n    labels = labels[index]\n    preds = preds[index]\n\n    preds_num = preds.sum(0)\n    true_num = (labels+preds==2).sum(0)\n    for cls in range(2):\n        d[cls] = dict()\n        d[cls]['number'] = (labels==cls).sum()\n        d[cls]['true'] = (labels+preds==2*cls).sum()\n        d[cls]['pred'] = (labels==cls).sum()\n    return d\n\ndef measures(d_list):\n    # \xe5\x90\x88\xe5\xb9\xb6\xe6\xaf\x8f\xe4\xb8\x80\xe4\xb8\xaa\xe9\xa2\x84\xe6\xb5\x8b\xe7\x9a\x84\xe7\xbb\x93\xe6\x9e\x9c\n    d_all = dict()\n    for d in d_list:\n        for cls in d.keys():\n            if cls not in d_all:\n                d_all[cls] = dict()\n            for k in d[cls].keys():\n                if k not in d_all[cls]:\n                    d_all[cls][k] = 0\n                d_all[cls][k] += d[cls][k]\n    m = dict()\n    number = sum([d_all[cls]['number'] for cls in d_all.keys()])\n    for cls in d_all:\n        m[cls] = dict()\n        m[cls]['number'] = d_all[cls]['number']\n        m[cls]['true'] = d_all[cls]['true']\n        m[cls]['pred'] = d_all[cls]['pred']\n        m[cls]['ratio'] = d_all[cls]['number'] / (float(number) + 10e-10)\n        m[cls]['accuracy'] = d_all[cls]['true'] / (float(d_all[cls]['number']) + 10e-10)\n        m[cls]['precision'] = d_all[cls]['true'] /(float(d_all[cls]['pred']) + 10e-10) \n    return m\n\ndef print_measures(m, s = 'measures'):\n    print s\n    accuracy = 0\n    for cls in sorted(m.keys()):\n        print '\\tclass: {:d}\\taccuracy:{:.6f}\\tprecision:{:.6f}\\tratio:{:.6f}\\t\\tN/T/P:{:d}/{:d}/{:d}\\\n            '.format(cls, m[cls]['accuracy'],m[cls]['precision'],m[cls]['ratio'],m[cls]['number'],m[cls]['true'],m[cls]['pred'])\n\taccuracy += m[cls]['accuracy'] * m[cls]['ratio']\n    print '\\tacc:{:.6f}'.format(accuracy)\n    return accuracy\n\ndef mse(pred_image, image):\n    pred_image = pred_image.reshape(-1).astype(np.float32)\n    image = image.reshape(-1).astype(np.float32)\n    mse_err = metrics.mean_squared_error(pred_image,image)\n    return mse_err\n\ndef psnr(pred_image, image):\n    return 10 * np.log10(255*255/mse(pred_image,image))\n\n\ndef psnr_pred(stain_vis=20, end= 10000):\n    clean_dir = '../../data/AI/testB/'\n    psnr_list = []\n    f = open('../../data/result.csv','w')\n    for i,clean in enumerate(os.listdir(clean_dir)):\n        clean = os.path.join(clean_dir, clean)\n        clean_file = clean\n        pred = clean.replace('.jpg','.png').replace('data','data/test_clean')\n        stain = clean.replace('trainB','trainA').replace('testB','testA').replace('.jpg','_.jpg')\n\n        try:\n            pred = np.array(Image.open(pred).resize((250,250))).astype(np.float32)\n            clean = np.array(Image.open(clean).resize((250,250))).astype(np.float32)\n            stain = np.array(Image.open(stain).resize((250,250))).astype(np.float32)\n\n            # diff = np.abs(stain - pred)\n            # vis = 20\n            # pred[diff<vis] = stain[diff<vis]\n\n            # gray_vis = 240\n            # pred[stain>gray_vis] = stain[stain>gray_vis]\n\n            if end < 1000:\n                diff = np.abs(clean - stain)\n                # stain[diff>stain_vis] = pred[diff>stain_vis]\n                stain[diff>stain_vis] = clean[diff>stain_vis]\n\n            psnr_pred  = psnr(clean, pred)\n            psnr_stain = psnr(clean, stain)\n            psnr_list.append([psnr_stain, psnr_pred])\n        except:\n            continue\n        if i>end:\n            break\n        print i, min(end, 1000)\n\n        f.write(clean_file.split('/')[-1].split('.')[0])\n        f.write(',')\n        f.write(str(psnr_stain))\n        f.write(',')\n        f.write(str(psnr_pred))\n        f.write(',')\n        f.write(str(psnr_pred/psnr_stain - 1))\n        f.write('\\n')\n    # print '\xe9\xa2\x84\xe6\xb5\x8b',np.mean(psnr_list)\n    psnr_list = np.array(psnr_list)\n    psnr_mean = ((psnr_list[:,1] - psnr_list[:,0]) / psnr_list[:,0]).mean()\n    if end > 1000:\n        print '\xe7\xbd\x91\xe7\xba\xb9\xe5\x9b\xbePSNR', psnr_list[:,0].mean()\n        print '\xe9\xa2\x84\xe6\xb5\x8b\xe5\x9b\xbePSNR', psnr_list[:,1].mean()\n        print '\xe5\xa2\x9e\xe7\x9b\x8a\xe7\x8e\x87', psnr_mean\n    f.write(str(psnr_mean))\n    f.close()\n    return psnr_list[:,0].mean()\n\ndef main():\n    pmax = [0.,0.]\n    for vis in range(1, 30):\n        p = psnr_pred(vis, 10)\n        print vis, p\n        if p > pmax[1]:\n            pmax = [vis, p]\n    print '...'\n    # print 256,psnr_pred(256)\n    print pmax\n    # print 10 * np.log10(255*255/metrics.mean_squared_error([3],[9]))\n\n\nif __name__ == '__main__':\n    psnr_pred(4000)\n    # main()\n    # for v in range(1,10):\n    #     print v, 10 * np.log10(255*255/v/v)\n"""
code/ocr/tools/parse.py,0,"b""# coding=utf8\n\nimport argparse\n\nparser = argparse.ArgumentParser(description='medical caption GAN')\n\nparser.add_argument(\n        '--model',\n        '-m',\n        type=str,\n        default='densenet',\n        help='model'\n        )\nparser.add_argument(\n        '--data-dir',\n        '-d',\n        type=str,\n        default='../../data/dataset/',\n        help='data directory'\n        )\nparser.add_argument(\n        '--bg-dir',\n        type=str,\n        default='../../data/images',\n        help='back groud images directory'\n        )\nparser.add_argument(\n        '--hard-mining',\n        type=int,\n        default=0,\n        help='use hard mining'\n        )\nparser.add_argument('--phase',\n        default='train',\n        type=str,\n        metavar='S',\n        help='pretrain/train/test phase')\nparser.add_argument(\n        '--batch-size',\n        '-b',\n        metavar='BATCH SIZE',\n        type=int,\n        default=16,\n        help='batch size'\n        )\nparser.add_argument('--save-dir',\n        default='../../data',\n        type=str,\n        metavar='S',\n        help='save dir')\nparser.add_argument('--word-index-json',\n        default='../../files/alphabet_index_dict.json',\n        type=str,\n        metavar='S',\n        help='save dir')\nparser.add_argument('--black-json',\n        default='../../files/black.json',\n        type=str,\n        metavar='S',\n        help='black_list json')\nparser.add_argument('--image-hw-ratio-json',\n        default='../../files/image_hw_ratio_dict.json',\n        type=str,\n        metavar='S',\n        help='image h:w ratio dict')\nparser.add_argument('--word-count-json',\n        default='../../files/alphabet_count_dict.json',\n        type=str,\n        metavar='S',\n        help='word count file')\nparser.add_argument('--image-label-json',\n        default='../../files/train_alphabet.json',\n        type=str,\n        metavar='S',\n        help='image label json')\nparser.add_argument('--resume',\n        default='',\n        type=str,\n        metavar='S',\n        help='start from checkpoints')\nparser.add_argument('--no-aug',\n        default=0,\n        type=int,\n        metavar='S',\n        help='no augmentation')\nparser.add_argument('--small',\n        default=1,\n        type=int,\n        metavar='S',\n        help='small fonts')\nparser.add_argument('--difficult',\n        default=0,\n        type=int,\n        metavar='S',\n        help='\xe5\x8f\xaa\xe8\xae\xa1\xe7\xae\x97\xe6\xaf\x94\xe8\xbe\x83\xe9\x9a\xbe\xe7\x9a\x84\xe5\x9b\xbe\xe7\x89\x87')\nparser.add_argument('--hist',\n        default=0,\n        type=int,\n        metavar='S',\n        help='\xe9\x87\x87\xe7\x94\xa8\xe7\x9b\xb4\xe6\x96\xb9\xe5\x9b\xbe\xe5\x9d\x87\xe8\xa1\xa1\xe5\x8c\x96')\nparser.add_argument('--feat',\n        default=0,\n        type=int,\n        metavar='S',\n        help='\xe7\x94\x9f\xe6\x88\x90LSTM\xe7\x9a\x84feature')\n\n#####\nparser.add_argument('-j',\n        '--workers',\n        default=8,\n        type=int,\n        metavar='N',\n        help='number of data loading workers (default: 32)')\nparser.add_argument('--lr',\n        '--learning-rate',\n        default=0.001,\n        type=float,\n        metavar='LR',\n        help='initial learning rate')\nparser.add_argument('--epochs',\n        default=10000,\n        type=int,\n        metavar='N',\n        help='number of total epochs to run')\nparser.add_argument('--save-freq',\n        default='5',\n        type=int,\n        metavar='S',\n        help='save frequency')\nparser.add_argument('--save-pred-freq',\n        default='10',\n        type=int,\n        metavar='S',\n        help='save pred clean frequency')\nparser.add_argument('--val-freq',\n        default='5',\n        type=int,\n        metavar='S',\n        help='val frequency')\nparser.add_argument('--debug',\n        default=0,\n        type=int,\n        metavar='S',\n        help='debug')\nparser.add_argument('--input-filter',\n        default=7,\n        type=int,\n        metavar='S',\n        help='val frequency')\nparser.add_argument('--use-gan',\n        default=0,\n        type=int,\n        metavar='S',\n        help='use GAN')\nparser.add_argument('--write-pred',\n        default=0,\n        type=int,\n        metavar='S',\n        help='writ predictions')\nparser.add_argument(\n        '--result-file',\n        '-r',\n        type=str,\n        default='../../data/result/test_result.csv',\n        help='result file'\n        )\nparser.add_argument(\n        '--output-file',\n        '-o',\n        type=str,\n        default='../../data/result/test.csv',\n        help='output file'\n        )\nargs = parser.parse_args()\n"""
code/ocr/tools/plot.py,0,"b""# coding=utf8\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_multi_graph(image_list, name_list, save_path=None, show=False):\n    graph_place = int(np.sqrt(len(name_list) - 1)) + 1\n    for i, (image, name) in enumerate(zip(image_list, name_list)):\n        ax1 = plt.subplot(graph_place,graph_place,i+1)\n        ax1.set_title(name)\n        # plt.imshow(image,cmap='gray')\n        plt.imshow(image)\n        plt.axis('off')\n    if save_path:\n        plt.savefig(save_path)\n        pass\n    if show:\n        plt.show()\n\ndef plot_multi_line(x_list, y_list, name_list, save_path=None, show=False):\n    graph_place = int(np.sqrt(len(name_list) - 1)) + 1\n    for i, (x, y, name) in enumerate(zip(x_list, y_list, name_list)):\n        ax1 = plt.subplot(graph_place,graph_place,i+1)\n        ax1.set_title(name)\n        plt.plot(x,y)\n        # plt.imshow(image,cmap='gray')\n    if save_path:\n        plt.savefig(save_path)\n    if show:\n        plt.show()\n\n\n"""
code/ocr/tools/py_op.py,0,"b'# -*- coding: utf-8 -*-\n""""""\n\xe6\xad\xa4\xe6\x96\x87\xe4\xbb\xb6\xe7\x94\xa8\xe4\xba\x8e\xe5\xb8\xb8\xe7\x94\xa8python\xe5\x87\xbd\xe6\x95\xb0\xe7\x9a\x84\xe4\xbd\xbf\xe7\x94\xa8\n""""""\nimport os\nimport json\nimport traceback\nfrom collections import OrderedDict \nimport random\nfrom fuzzywuzzy import fuzz\n\nimport sys\nreload(sys)\nsys.setdefaultencoding(\'utf-8\')\n\n################################################################################\n### pre define variables\n#:: enumerate\n#:: raw_input\n#:: listdir\n#:: sorted\n### pre define function\ndef mywritejson(save_path,content):\n    content = json.dumps(content,indent=4,ensure_ascii=False)\n    with open(save_path,\'w\') as f:\n        f.write(content)\n\ndef myreadjson(load_path):\n    with open(load_path,\'r\') as f:\n        return json.loads(f.read())\n\ndef mywritefile(save_path,content):\n    with open(save_path,\'w\') as f:\n        f.write(content)\n\ndef myreadfile(load_path):\n    with open(load_path,\'r\') as f:\n        return f.read()\n\ndef myprint(content):\n    print json.dumps(content,indent=4,ensure_ascii=False)\n\ndef rm(fi):\n    os.system(\'rm \' + fi)\n\ndef mystrip(s):\n    return \'\'.join(s.split())\n\ndef mysorteddict(d,key = lambda s:s, reverse=False):\n    dordered = OrderedDict()\n    for k in sorted(d.keys(),key = key,reverse=reverse):\n        dordered[k] = d[k]\n    return dordered\n\ndef mysorteddictfile(src,obj):\n    mywritejson(obj,mysorteddict(myreadjson(src)))\n\ndef myfuzzymatch(srcs,objs,grade=80):\n    matchDict = OrderedDict()\n    for src in srcs:\n        for obj in objs:\n            value = fuzz.partial_ratio(src,obj)\n            if value > grade:\n                try:\n                    matchDict[src].append(obj)\n                except:\n                    matchDict[src] = [obj]\n    return matchDict\n\ndef mydumps(x):\n    return json.dumps(content,indent=4,ensure_ascii=False)\n\ndef get_random_list(l,num=-1,isunique=0):\n    if isunique:\n        l = set(l)\n    if num < 0:\n        num = len(l)\n    if isunique and num > len(l):\n        return \n    lnew = []\n    l = list(l)\n    while(num>len(lnew)):\n        x = l[int(random.random()*len(l))]\n        if isunique and x in lnew:\n            continue\n        lnew.append(x)\n    return lnew\n\ndef fuzz_list(node1_list,node2_list,score_baseline=66,proposal_num=10,string_map=None):\n    node_dict = { }\n    for i,node1 in enumerate(node1_list):\n        match_score_dict = { }\n        for node2 in node2_list:\n            if node1 != node2:\n                if string_map is not None:\n                    n1 = string_map(node1)\n                    n2 = string_map(node2)\n                    score = fuzz.partial_ratio(n1,n2)\n                    if n1 == n2:\n                        node2_list.remove(node2)\n                else:\n                    score = fuzz.partial_ratio(node1,node2)\n                if score > score_baseline:\n                    match_score_dict[node2] = score\n            else:\n                node2_list.remove(node2)\n        node2_sort = sorted(match_score_dict.keys(), key=lambda k:match_score_dict[k],reverse=True)\n        node_dict[node1] = [[n,match_score_dict[n]] for n in node2_sort[:proposal_num]]\n        print i,len(node1_list)\n    return node_dict, node2_list\n\ndef swap(a,b):\n    return b, a\n\ndef mkdir(d):\n    path = d.split(\'/\')\n    for i in range(len(path)):\n        d = \'/\'.join(path[:i+1])\n        if not os.path.exists(d):\n            os.mkdir(d)\n\n'"
code/ocr/tools/segmentation.py,0,"b'# coding=utf8\nimport matplotlib.pyplot as plt\nfrom scipy import ndimage as ndi\nfrom skimage import morphology,color,data\nfrom skimage import filters\nimport numpy as np\nimport skimage \nimport os\nfrom skimage import measure\n\n\n\ndef watershed(image, label=None):\n    denoised = filters.rank.median(image, morphology.disk(2)) #\xe8\xbf\x87\xe6\xbb\xa4\xe5\x99\xaa\xe5\xa3\xb0\n    #\xe5\xb0\x86\xe6\xa2\xaf\xe5\xba\xa6\xe5\x80\xbc\xe4\xbd\x8e\xe4\xba\x8e10\xe7\x9a\x84\xe4\xbd\x9c\xe4\xb8\xba\xe5\xbc\x80\xe5\xa7\x8b\xe6\xa0\x87\xe8\xae\xb0\xe7\x82\xb9\n    markers = filters.rank.gradient(denoised, morphology.disk(5)) < 10\n    markers = ndi.label(markers)[0]\n\n    gradient = filters.rank.gradient(denoised, morphology.disk(2)) #\xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\n    labels =morphology.watershed(gradient, markers, mask=image) #\xe5\x9f\xba\xe4\xba\x8e\xe6\xa2\xaf\xe5\xba\xa6\xe7\x9a\x84\xe5\x88\x86\xe6\xb0\xb4\xe5\xb2\xad\xe7\xae\x97\xe6\xb3\x95\n\n    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(6, 6))\n    axes = axes.ravel()\n    ax0, ax1, ax2, ax3 = axes\n\n    ax0.imshow(image, cmap=plt.cm.gray, interpolation=\'nearest\')\n    ax0.set_title(""Original"")\n    # ax1.imshow(gradient, cmap=plt.cm.spectral, interpolation=\'nearest\')\n    ax1.imshow(gradient, cmap=plt.cm.gray, interpolation=\'nearest\')\n    ax1.set_title(""Gradient"")\n    if label is not None:\n        # ax2.imshow(markers, cmap=plt.cm.spectral, interpolation=\'nearest\')\n        ax2.imshow(label, cmap=plt.cm.gray, interpolation=\'nearest\')\n    else:\n        ax2.imshow(markers, cmap=plt.cm.spectral, interpolation=\'nearest\')\n    ax2.set_title(""Markers"")\n    ax3.imshow(labels, cmap=plt.cm.spectral, interpolation=\'nearest\')\n    ax3.set_title(""Segmented"")\n\n    for ax in axes:\n        ax.axis(\'off\')\n\n    fig.tight_layout()\n    plt.show()\n\ndef plot_4(image, gradient,label,segmentation, save_path=None):\n    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(6, 6))\n    axes = axes.ravel()\n    ax0, ax1, ax2, ax3 = axes\n    ax0.imshow(image, cmap=plt.cm.gray, interpolation=\'nearest\')\n    ax0.set_title(""Original"")\n    ax1.imshow(gradient, cmap=plt.cm.gray, interpolation=\'nearest\')\n    ax1.set_title(""Gradient"")\n    ax2.imshow(label, cmap=plt.cm.gray, interpolation=\'nearest\')\n    ax2.set_title(""label"")\n    ax3.imshow(segmentation, cmap=plt.cm.spectral, interpolation=\'nearest\')\n    ax3.set_title(""Segmented"")\n\n    for ax in axes:\n        ax.axis(\'off\')\n\n    fig.tight_layout()\n    if save_path:\n        print save_path\n        plt.savefig(save_path)\n    else:\n        plt.show()\n\ndef fill(image):\n    \'\'\'\n    \xe5\xa1\xab\xe5\x85\x85\xe5\x9b\xbe\xe7\x89\x87\xe5\x86\x85\xe9\x83\xa8\xe7\xa9\xba\xe7\x99\xbd\n    \xe4\xb8\xb4\xe6\x97\xb6\xe5\x86\x99\xe7\x9a\x84\xe5\x87\xbd\xe6\x95\xb0\n    \xe5\xbb\xba\xe8\xae\xae\xe5\x90\x8e\xe6\x9c\x9f\xe6\x9b\xbf\xe6\x8d\xa2\n    \'\'\'\n    label_img = measure.label(image, background=1)\n    props = measure.regionprops(label_img)\n    max_area = np.array([p.area for p in props]).max()\n    for i,prop in enumerate(props):\n        if prop.area < max_area:\n            image[prop.coords[:,0],prop.coords[:,1]] = 1\n    return image\n\n\n\ndef my_watershed(image, label=None, min_gray=480, max_gray=708, min_gradient=5, show=False, save_path=\'/tmp/x.jpg\'):\n    image = image - min_gray\n    image[image>max_gray] = 0\n    image[image< 10]  = 0\n    image = image * 5\n\n    denoised = filters.rank.median(image, morphology.disk(2)) #\xe8\xbf\x87\xe6\xbb\xa4\xe5\x99\xaa\xe5\xa3\xb0\n    #\xe5\xb0\x86\xe6\xa2\xaf\xe5\xba\xa6\xe5\x80\xbc\xe4\xbd\x8e\xe4\xba\x8e10\xe7\x9a\x84\xe4\xbd\x9c\xe4\xb8\xba\xe5\xbc\x80\xe5\xa7\x8b\xe6\xa0\x87\xe8\xae\xb0\xe7\x82\xb9\n    markers = filters.rank.gradient(denoised, morphology.disk(5)) < 10\n    markers = ndi.label(markers)[0]\n\n    gradient = filters.rank.gradient(denoised, morphology.disk(2)) #\xe8\xae\xa1\xe7\xae\x97\xe6\xa2\xaf\xe5\xba\xa6\n    labels = gradient > min_gradient\n\n    mask = gradient > min_gradient\n    label_img = measure.label(mask, background=0)\n    props = measure.regionprops(label_img)\n    pred = np.zeros_like(gradient)\n    for i,prop in enumerate(props):\n        if prop.area > 50:\n            region = np.array(prop.coords)\n            vx,vy = region.var(0)\n            v = vx + vy\n            if v < 200:\n                pred[prop.coords[:,0],prop.coords[:,1]] = 1\n\n    # \xe5\xa1\xab\xe5\x85\x85\xe8\xbe\xb9\xe7\xbc\x98\xe5\x86\x85\xe9\x83\xa8\xe7\xa9\xba\xe7\x99\xbd\n    pred = fill(pred)\n\n    if show:\n        plot_4(image, gradient, label, pred)\n    else:\n        plot_4(image, gradient, label, pred, save_path)\n\n    return pred\n\ndef segmentation(image_npy, label_npy,save_path):\n    print image_npy\n    image = np.load(image_npy)\n    label = np.load(label_npy)\n    if np.sum(label) == 0:\n        return\n    min_gray,max_gray = 480, 708\n    my_watershed(image,label,min_gray, max_gray,show=False, save_path=save_path)\n\ndef main():\n    data_dir = \'/home/yin/all/PVL_DATA/preprocessed/2D/\'\n    save_dir = \'/home/yin/all/PVL_DATA/tool_result/\'\n    os.system(\'rm -r \' + save_dir)\n    os.system(\'mkdir \' + save_dir)\n    for patient in os.listdir(data_dir):\n        patient_dir = os.path.join(data_dir, patient)\n        for f in os.listdir(patient_dir):\n            if \'roi.npy\' in f:\n                label_npy = os.path.join(patient_dir,f)\n                image_npy = label_npy.replace(\'.roi.npy\',\'.npy\')\n                segmentation(image_npy,label_npy, os.path.join(save_dir,label_npy.strip(\'/\').replace(\'/\',\'.\').replace(\'npy\',\'jpg\')))\n\nif __name__ == \'__main__\':\n    # image =color.rgb2gray(data.camera())\n    # watershed(image)\n    main()\n    image_npy = \'/home/yin/all/PVL_DATA/preprocessed/2D/JD_chen_xi/23.npy\'\n    image_npy = \'/home/yin/all/PVL_DATA/preprocessed/2D/JD_chen_xi/14.npy\' \n    image_npy = \'/home/yin/all/PVL_DATA/preprocessed/2D/JD_zhang_yu_chen/23.npy\'\n    label_npy = image_npy.replace(\'.npy\',\'.roi.npy\')\n    segmentation(image_npy,label_npy)\n\n\n'"
code/ocr/tools/utils.py,7,"b'#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n#\n# Copyright (c) 2017 www.drcubic.com, Inc. All Rights Reserved\n#\n""""""\nFile: utils.py\nAuthor: shileicao(shileicao@stu.xjtu.edu.cn)\nDate: 2017-06-20 14:56:54\n\n**Note.** This code absorb some code from following source.\n1. [DSB2017](https://github.com/lfz/DSB2017)\n""""""\n\nimport os\nimport sys\n\nimport numpy as np\nimport torch\n\n\ndef getFreeId():\n    import pynvml\n\n    pynvml.nvmlInit()\n\n    def getFreeRatio(id):\n        handle = pynvml.nvmlDeviceGetHandleByIndex(id)\n        use = pynvml.nvmlDeviceGetUtilizationRates(handle)\n        ratio = 0.5 * (float(use.gpu + float(use.memory)))\n        return ratio\n\n    deviceCount = pynvml.nvmlDeviceGetCount()\n    available = []\n    for i in range(deviceCount):\n        if getFreeRatio(i) < 70:\n            available.append(i)\n    gpus = \'\'\n    for g in available:\n        gpus = gpus + str(g) + \',\'\n    gpus = gpus[:-1]\n    return gpus\n\n\ndef setgpu(gpuinput):\n    freeids = getFreeId()\n    if gpuinput == \'all\':\n        gpus = freeids\n    else:\n        gpus = gpuinput\n        busy_gpu = [g not in freeids for g in gpus.split(\',\')]\n        if any(busy_gpu):\n            raise ValueError(\'gpu\' + \' \'.join(busy_gpu) + \'is being used\')\n    print(\'using gpu \' + gpus)\n    os.environ[\'CUDA_VISIBLE_DEVICES\'] = gpus\n    return len(gpus.split(\',\'))\n\n\ndef error_mask_stats(labels, filenames):\n    error_f = []\n    for i, f in enumerate(filenames):\n#         if not np.all(labels[i] > 0):\n#             error_f.append(f)\n        for bbox_i in range(labels[i].shape[0]):\n            imgs = np.load(f)\n            if not np.all(\n                    np.array(imgs.shape[1:]) - labels[i][bbox_i][:-1] > 0):\n                error_f.append(f)\n    error_f = list(set(error_f))\n    fileid_list = [os.path.split(filename)[1].split(\'_\')[0]\n                   for filename in error_f]\n    print(""\',\'"".join(fileid_list))\n    return error_f\n\n\nclass Logger(object):\n    def __init__(self, logfile):\n        self.terminal = sys.stdout\n        self.log = open(logfile, ""a"")\n\n    def write(self, message):\n        self.terminal.write(message)\n        self.log.write(message)\n\n    def flush(self):\n        #this flush method is needed for python 3 compatibility.\n        #this handles the flush command by doing nothing.\n        #you might want to specify some extra behavior here.\n        pass\n\n\ndef split4(data, max_stride, margin):\n    splits = []\n    data = torch.Tensor.numpy(data)\n    _, c, z, h, w = data.shape\n\n    w_width = np.ceil(float(w / 2 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    h_width = np.ceil(float(h / 2 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    pad = int(np.ceil(float(z) / max_stride) * max_stride) - z\n    leftpad = pad / 2\n    pad = [[0, 0], [0, 0], [leftpad, pad - leftpad], [0, 0], [0, 0]]\n    data = np.pad(data, pad, \'constant\', constant_values=-1)\n    data = torch.from_numpy(data)\n    splits.append(data[:, :, :, :h_width, :w_width])\n    splits.append(data[:, :, :, :h_width, -w_width:])\n    splits.append(data[:, :, :, -h_width:, :w_width])\n    splits.append(data[:, :, :, -h_width:, -w_width:])\n\n    return torch.cat(splits, 0)\n\n\ndef combine4(output, h, w):\n    splits = []\n    for i in range(len(output)):\n        splits.append(output[i])\n\n    output = np.zeros(\n        (splits[0].shape[0], h, w, splits[0].shape[3],\n         splits[0].shape[4]), np.float32)\n\n    h0 = output.shape[1] / 2\n    h1 = output.shape[1] - h0\n    w0 = output.shape[2] / 2\n    w1 = output.shape[2] - w0\n\n    splits[0] = splits[0][:, :h0, :w0, :, :]\n    output[:, :h0, :w0, :, :] = splits[0]\n\n    splits[1] = splits[1][:, :h0, -w1:, :, :]\n    output[:, :h0, -w1:, :, :] = splits[1]\n\n    splits[2] = splits[2][:, -h1:, :w0, :, :]\n    output[:, -h1:, :w0, :, :] = splits[2]\n\n    splits[3] = splits[3][:, -h1:, -w1:, :, :]\n    output[:, -h1:, -w1:, :, :] = splits[3]\n\n    return output\n\n\ndef split8(data, max_stride, margin):\n    splits = []\n    if isinstance(data, np.ndarray):\n        c, z, h, w = data.shape\n    else:\n        _, c, z, h, w = data.size()\n\n    z_width = np.ceil(float(z / 2 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    w_width = np.ceil(float(w / 2 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    h_width = np.ceil(float(h / 2 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    for zz in [[0, z_width], [-z_width, None]]:\n        for hh in [[0, h_width], [-h_width, None]]:\n            for ww in [[0, w_width], [-w_width, None]]:\n                if isinstance(data, np.ndarray):\n                    splits.append(data[np.newaxis, :, zz[0]:zz[1], hh[0]:hh[1],\n                                       ww[0]:ww[1]])\n                else:\n                    splits.append(data[:, :, zz[0]:zz[1], hh[0]:hh[1], ww[0]:\n                                       ww[1]])\n\n    if isinstance(data, np.ndarray):\n        return np.concatenate(splits, 0)\n    else:\n        return torch.cat(splits, 0)\n\n\ndef combine8(output, z, h, w):\n    splits = []\n    for i in range(len(output)):\n        splits.append(output[i])\n\n    output = np.zeros(\n        (z, h, w, splits[0].shape[3], splits[0].shape[4]), np.float32)\n\n    z_width = z / 2\n    h_width = h / 2\n    w_width = w / 2\n    i = 0\n    for zz in [[0, z_width], [z_width - z, None]]:\n        for hh in [[0, h_width], [h_width - h, None]]:\n            for ww in [[0, w_width], [w_width - w, None]]:\n                output[zz[0]:zz[1], hh[0]:hh[1], ww[0]:ww[1], :, :] = splits[\n                    i][zz[0]:zz[1], hh[0]:hh[1], ww[0]:ww[1], :, :]\n                i = i + 1\n\n    return output\n\n\ndef split16(data, max_stride, margin):\n    splits = []\n    _, c, z, h, w = data.size()\n\n    z_width = np.ceil(float(z / 4 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    z_pos = [z * 3 / 8 - z_width / 2, z * 5 / 8 - z_width / 2]\n    h_width = np.ceil(float(h / 2 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    w_width = np.ceil(float(w / 2 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    for zz in [[0, z_width], [z_pos[0], z_pos[0] + z_width],\n               [z_pos[1], z_pos[1] + z_width], [-z_width, None]]:\n        for hh in [[0, h_width], [-h_width, None]]:\n            for ww in [[0, w_width], [-w_width, None]]:\n                splits.append(data[:, :, zz[0]:zz[1], hh[0]:hh[1], ww[0]:ww[\n                    1]])\n\n    return torch.cat(splits, 0)\n\n\ndef combine16(output, z, h, w):\n    splits = []\n    for i in range(len(output)):\n        splits.append(output[i])\n\n    output = np.zeros(\n        (z, h, w, splits[0].shape[3], splits[0].shape[4]), np.float32)\n\n    z_width = z / 4\n    h_width = h / 2\n    w_width = w / 2\n    splitzstart = splits[0].shape[0] / 2 - z_width / 2\n    z_pos = [z * 3 / 8 - z_width / 2, z * 5 / 8 - z_width / 2]\n    i = 0\n    for zz, zz2 in zip(\n        [[0, z_width], [z_width, z_width * 2], [z_width * 2, z_width * 3],\n         [z_width * 3 - z, None]],\n        [[0, z_width], [splitzstart, z_width + splitzstart],\n         [splitzstart, z_width + splitzstart], [z_width * 3 - z, None]]):\n        for hh in [[0, h_width], [h_width - h, None]]:\n            for ww in [[0, w_width], [w_width - w, None]]:\n                output[zz[0]:zz[1], hh[0]:hh[1], ww[0]:ww[1], :, :] = splits[\n                    i][zz2[0]:zz2[1], hh[0]:hh[1], ww[0]:ww[1], :, :]\n                i = i + 1\n\n    return output\n\n\ndef split32(data, max_stride, margin):\n    splits = []\n    _, c, z, h, w = data.size()\n\n    z_width = np.ceil(float(z / 2 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    w_width = np.ceil(float(w / 4 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    h_width = np.ceil(float(h / 4 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n\n    w_pos = [w * 3 / 8 - w_width / 2, w * 5 / 8 - w_width / 2]\n    h_pos = [h * 3 / 8 - h_width / 2, h * 5 / 8 - h_width / 2]\n\n    for zz in [[0, z_width], [-z_width, None]]:\n        for hh in [[0, h_width], [h_pos[0], h_pos[0] + h_width],\n                   [h_pos[1], h_pos[1] + h_width], [-h_width, None]]:\n            for ww in [[0, w_width], [w_pos[0], w_pos[0] + w_width],\n                       [w_pos[1], w_pos[1] + w_width], [-w_width, None]]:\n                splits.append(data[:, :, zz[0]:zz[1], hh[0]:hh[1], ww[0]:ww[\n                    1]])\n\n    return torch.cat(splits, 0)\n\n\ndef combine32(splits, z, h, w):\n\n    output = np.zeros(\n        (z, h, w, splits[0].shape[3], splits[0].shape[4]), np.float32)\n\n    z_width = int(np.ceil(float(z) / 2))\n    h_width = int(np.ceil(float(h) / 4))\n    w_width = int(np.ceil(float(w) / 4))\n    splithstart = splits[0].shape[1] / 2 - h_width / 2\n    splitwstart = splits[0].shape[2] / 2 - w_width / 2\n\n    i = 0\n    for zz in [[0, z_width], [z_width - z, None]]:\n\n        for hh, hh2 in zip(\n            [[0, h_width], [h_width, h_width * 2], [h_width * 2, h_width * 3],\n             [h_width * 3 - h, None]],\n            [[0, h_width], [splithstart, h_width + splithstart],\n             [splithstart, h_width + splithstart], [h_width * 3 - h, None]]):\n\n            for ww, ww2 in zip(\n                [[0, w_width], [w_width, w_width * 2],\n                 [w_width * 2, w_width * 3], [w_width * 3 - w, None]],\n                [[0, w_width], [splitwstart, w_width + splitwstart],\n                 [splitwstart, w_width + splitwstart],\n                 [w_width * 3 - w, None]]):\n\n                output[zz[0]:zz[1], hh[0]:hh[1], ww[0]:ww[1], :, :] = splits[\n                    i][zz[0]:zz[1], hh2[0]:hh2[1], ww2[0]:ww2[1], :, :]\n                i = i + 1\n\n    return output\n\n\ndef split64(data, max_stride, margin):\n    splits = []\n    _, c, z, h, w = data.size()\n\n    z_width = np.ceil(float(z / 4 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    w_width = np.ceil(float(w / 4 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n    h_width = np.ceil(float(h / 4 + margin) /\n                      max_stride).astype(\'int\') * max_stride\n\n    z_pos = [z * 3 / 8 - z_width / 2, z * 5 / 8 - z_width / 2]\n    w_pos = [w * 3 / 8 - w_width / 2, w * 5 / 8 - w_width / 2]\n    h_pos = [h * 3 / 8 - h_width / 2, h * 5 / 8 - h_width / 2]\n\n    for zz in [[0, z_width], [z_pos[0], z_pos[0] + z_width],\n               [z_pos[1], z_pos[1] + z_width], [-z_width, None]]:\n        for hh in [[0, h_width], [h_pos[0], h_pos[0] + h_width],\n                   [h_pos[1], h_pos[1] + h_width], [-h_width, None]]:\n            for ww in [[0, w_width], [w_pos[0], w_pos[0] + w_width],\n                       [w_pos[1], w_pos[1] + w_width], [-w_width, None]]:\n                splits.append(data[:, :, zz[0]:zz[1], hh[0]:hh[1], ww[0]:ww[\n                    1]])\n\n    return torch.cat(splits, 0)\n\n\ndef combine64(output, z, h, w):\n    splits = []\n    for i in range(len(output)):\n        splits.append(output[i])\n\n    output = np.zeros(\n        (z, h, w, splits[0].shape[3], splits[0].shape[4]), np.float32)\n\n    z_width = int(np.ceil(float(z) / 4))\n    h_width = int(np.ceil(float(h) / 4))\n    w_width = int(np.ceil(float(w) / 4))\n    splitzstart = splits[0].shape[0] / 2 - z_width / 2\n    splithstart = splits[0].shape[1] / 2 - h_width / 2\n    splitwstart = splits[0].shape[2] / 2 - w_width / 2\n\n    i = 0\n    for zz, zz2 in zip(\n        [[0, z_width], [z_width, z_width * 2], [z_width * 2, z_width * 3],\n         [z_width * 3 - z, None]],\n        [[0, z_width], [splitzstart, z_width + splitzstart],\n         [splitzstart, z_width + splitzstart], [z_width * 3 - z, None]]):\n\n        for hh, hh2 in zip(\n            [[0, h_width], [h_width, h_width * 2], [h_width * 2, h_width * 3],\n             [h_width * 3 - h, None]],\n            [[0, h_width], [splithstart, h_width + splithstart],\n             [splithstart, h_width + splithstart], [h_width * 3 - h, None]]):\n\n            for ww, ww2 in zip(\n                [[0, w_width], [w_width, w_width * 2],\n                 [w_width * 2, w_width * 3], [w_width * 3 - w, None]],\n                [[0, w_width], [splitwstart, w_width + splitwstart],\n                 [splitwstart, w_width + splitwstart],\n                 [w_width * 3 - w, None]]):\n\n                output[zz[0]:zz[1], hh[0]:hh[1], ww[0]:ww[1], :, :] = splits[\n                    i][zz2[0]:zz2[1], hh2[0]:hh2[1], ww2[0]:ww2[1], :, :]\n                i = i + 1\n\n    return output\n'"
