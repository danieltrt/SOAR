file_path,api_count,code
data_loader.py,2,"b'import torch\nfrom torchvision import datasets\nfrom torchvision import transforms\n\ndef get_loader(config):\n    """"""Builds and returns Dataloader for MNIST and SVHN dataset.""""""\n    \n    transform = transforms.Compose([\n                    transforms.Scale(config.image_size),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n    \n    svhn = datasets.SVHN(root=config.svhn_path, download=True, transform=transform)\n    mnist = datasets.MNIST(root=config.mnist_path, download=True, transform=transform)\n\n    svhn_loader = torch.utils.data.DataLoader(dataset=svhn,\n                                              batch_size=config.batch_size,\n                                              shuffle=True,\n                                              num_workers=config.num_workers)\n\n    mnist_loader = torch.utils.data.DataLoader(dataset=mnist,\n                                               batch_size=config.batch_size,\n                                               shuffle=True,\n                                               num_workers=config.num_workers)\n    return svhn_loader, mnist_loader'"
main.py,1,"b""import argparse\nimport os\nfrom solver import Solver\nfrom torch.backends import cudnn\nfrom data_loader import get_loader\n\ndef str2bool(v):\n    return v.lower() in ('true')\n\ndef main(config):\n    svhn_loader, mnist_loader = get_loader(config)\n    \n    solver = Solver(config, svhn_loader, mnist_loader)\n    cudnn.benchmark = True \n    \n    # create directories if not exist\n    if not os.path.exists(config.model_path):\n        os.makedirs(config.model_path)\n    if not os.path.exists(config.sample_path):\n        os.makedirs(config.sample_path)\n    \n    if config.mode == 'train':\n        solver.train()\n    elif config.mode == 'sample':\n        solver.sample()\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    \n    # model hyper-parameters\n    parser.add_argument('--image_size', type=int, default=32)\n    parser.add_argument('--g_conv_dim', type=int, default=64)\n    parser.add_argument('--d_conv_dim', type=int, default=64)\n    parser.add_argument('--use_reconst_loss', required=True, type=str2bool)\n    parser.add_argument('--use_labels', required=True, type=str2bool)\n    parser.add_argument('--num_classes', type=int, default=10)\n    \n    # training hyper-parameters\n    parser.add_argument('--train_iters', type=int, default=40000)\n    parser.add_argument('--batch_size', type=int, default=64)\n    parser.add_argument('--num_workers', type=int, default=2)\n    parser.add_argument('--lr', type=float, default=0.0002)\n    parser.add_argument('--beta1', type=float, default=0.5)\n    parser.add_argument('--beta2', type=float, default=0.999)\n    \n    # misc\n    parser.add_argument('--mode', type=str, default='train')\n    parser.add_argument('--model_path', type=str, default='./models')\n    parser.add_argument('--sample_path', type=str, default='./samples')\n    parser.add_argument('--mnist_path', type=str, default='./mnist')\n    parser.add_argument('--svhn_path', type=str, default='./svhn')\n    parser.add_argument('--log_step', type=int , default=10)\n    parser.add_argument('--sample_step', type=int , default=500)\n\n    config = parser.parse_args()\n    print(config)\n    main(config)"""
model.py,2,"b'import torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n    """"""Custom deconvolutional layer for simplicity.""""""\n    layers = []\n    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n    if bn:\n        layers.append(nn.BatchNorm2d(c_out))\n    return nn.Sequential(*layers)\n\ndef conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n    """"""Custom convolutional layer for simplicity.""""""\n    layers = []\n    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n    if bn:\n        layers.append(nn.BatchNorm2d(c_out))\n    return nn.Sequential(*layers)\n\nclass G12(nn.Module):\n    """"""Generator for transfering from mnist to svhn""""""\n    def __init__(self, conv_dim=64):\n        super(G12, self).__init__()\n        # encoding blocks\n        self.conv1 = conv(1, conv_dim, 4)\n        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n        \n        # residual blocks\n        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n        \n        # decoding blocks\n        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n        \n    def forward(self, x):\n        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n        \n        out = F.leaky_relu(self.conv3(out), 0.05)    # ( "" )\n        out = F.leaky_relu(self.conv4(out), 0.05)    # ( "" )\n        \n        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n        out = F.tanh(self.deconv2(out))              # (?, 3, 32, 32)\n        return out\n    \nclass G21(nn.Module):\n    """"""Generator for transfering from svhn to mnist""""""\n    def __init__(self, conv_dim=64):\n        super(G21, self).__init__()\n        # encoding blocks\n        self.conv1 = conv(3, conv_dim, 4)\n        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n        \n        # residual blocks\n        self.conv3 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n        self.conv4 = conv(conv_dim*2, conv_dim*2, 3, 1, 1)\n        \n        # decoding blocks\n        self.deconv1 = deconv(conv_dim*2, conv_dim, 4)\n        self.deconv2 = deconv(conv_dim, 1, 4, bn=False)\n        \n    def forward(self, x):\n        out = F.leaky_relu(self.conv1(x), 0.05)      # (?, 64, 16, 16)\n        out = F.leaky_relu(self.conv2(out), 0.05)    # (?, 128, 8, 8)\n        \n        out = F.leaky_relu(self.conv3(out), 0.05)    # ( "" )\n        out = F.leaky_relu(self.conv4(out), 0.05)    # ( "" )\n        \n        out = F.leaky_relu(self.deconv1(out), 0.05)  # (?, 64, 16, 16)\n        out = F.tanh(self.deconv2(out))              # (?, 1, 32, 32)\n        return out\n    \nclass D1(nn.Module):\n    """"""Discriminator for mnist.""""""\n    def __init__(self, conv_dim=64, use_labels=False):\n        super(D1, self).__init__()\n        self.conv1 = conv(1, conv_dim, 4, bn=False)\n        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n        n_out = 11 if use_labels else 1\n        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n        \n    def forward(self, x):\n        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n        out = self.fc(out).squeeze()\n        return out\n\nclass D2(nn.Module):\n    """"""Discriminator for svhn.""""""\n    def __init__(self, conv_dim=64, use_labels=False):\n        super(D2, self).__init__()\n        self.conv1 = conv(3, conv_dim, 4, bn=False)\n        self.conv2 = conv(conv_dim, conv_dim*2, 4)\n        self.conv3 = conv(conv_dim*2, conv_dim*4, 4)\n        n_out = 11 if use_labels else 1\n        self.fc = conv(conv_dim*4, n_out, 4, 1, 0, False)\n        \n    def forward(self, x):\n        out = F.leaky_relu(self.conv1(x), 0.05)    # (?, 64, 16, 16)\n        out = F.leaky_relu(self.conv2(out), 0.05)  # (?, 128, 8, 8)\n        out = F.leaky_relu(self.conv3(out), 0.05)  # (?, 256, 4, 4)\n        out = self.fc(out).squeeze()\n        return out'"
solver.py,19,"b'import torch\nimport torch.nn as nn\nimport torchvision\nimport os\nimport pickle\nimport scipy.io\nimport numpy as np\n\nfrom torch.autograd import Variable\nfrom torch import optim\nfrom model import G12, G21\nfrom model import D1, D2\n\n\nclass Solver(object):\n    def __init__(self, config, svhn_loader, mnist_loader):\n        self.svhn_loader = svhn_loader\n        self.mnist_loader = mnist_loader\n        self.g12 = None\n        self.g21 = None\n        self.d1 = None\n        self.d2 = None\n        self.g_optimizer = None\n        self.d_optimizer = None\n        self.use_reconst_loss = config.use_reconst_loss\n        self.use_labels = config.use_labels\n        self.num_classes = config.num_classes\n        self.beta1 = config.beta1\n        self.beta2 = config.beta2\n        self.g_conv_dim = config.g_conv_dim\n        self.d_conv_dim = config.d_conv_dim\n        self.train_iters = config.train_iters\n        self.batch_size = config.batch_size\n        self.lr = config.lr\n        self.log_step = config.log_step\n        self.sample_step = config.sample_step\n        self.sample_path = config.sample_path\n        self.model_path = config.model_path\n        self.build_model()\n        \n    def build_model(self):\n        """"""Builds a generator and a discriminator.""""""\n        self.g12 = G12(conv_dim=self.g_conv_dim)\n        self.g21 = G21(conv_dim=self.g_conv_dim)\n        self.d1 = D1(conv_dim=self.d_conv_dim, use_labels=self.use_labels)\n        self.d2 = D2(conv_dim=self.d_conv_dim, use_labels=self.use_labels)\n        \n        g_params = list(self.g12.parameters()) + list(self.g21.parameters())\n        d_params = list(self.d1.parameters()) + list(self.d2.parameters())\n        \n        self.g_optimizer = optim.Adam(g_params, self.lr, [self.beta1, self.beta2])\n        self.d_optimizer = optim.Adam(d_params, self.lr, [self.beta1, self.beta2])\n        \n        if torch.cuda.is_available():\n            self.g12.cuda()\n            self.g21.cuda()\n            self.d1.cuda()\n            self.d2.cuda()\n    \n    def merge_images(self, sources, targets, k=10):\n        _, _, h, w = sources.shape\n        row = int(np.sqrt(self.batch_size))\n        merged = np.zeros([3, row*h, row*w*2])\n        for idx, (s, t) in enumerate(zip(sources, targets)):\n            i = idx // row\n            j = idx % row\n            merged[:, i*h:(i+1)*h, (j*2)*h:(j*2+1)*h] = s\n            merged[:, i*h:(i+1)*h, (j*2+1)*h:(j*2+2)*h] = t\n        return merged.transpose(1, 2, 0)\n    \n    def to_var(self, x):\n        """"""Converts numpy to variable.""""""\n        if torch.cuda.is_available():\n            x = x.cuda()\n        return Variable(x)\n    \n    def to_data(self, x):\n        """"""Converts variable to numpy.""""""\n        if torch.cuda.is_available():\n            x = x.cpu()\n        return x.data.numpy()\n    \n    def reset_grad(self):\n        """"""Zeros the gradient buffers.""""""\n        self.g_optimizer.zero_grad()\n        self.d_optimizer.zero_grad()\n\n    def train(self):\n        svhn_iter = iter(self.svhn_loader)\n        mnist_iter = iter(self.mnist_loader)\n        iter_per_epoch = min(len(svhn_iter), len(mnist_iter))\n        \n        # fixed mnist and svhn for sampling\n        fixed_svhn = self.to_var(svhn_iter.next()[0])\n        fixed_mnist = self.to_var(mnist_iter.next()[0])\n        \n        # loss if use_labels = True\n        criterion = nn.CrossEntropyLoss()\n        \n        for step in range(self.train_iters+1):\n            # reset data_iter for each epoch\n            if (step+1) % iter_per_epoch == 0:\n                mnist_iter = iter(self.mnist_loader)\n                svhn_iter = iter(self.svhn_loader)\n            \n            # load svhn and mnist dataset\n            svhn, s_labels = svhn_iter.next() \n            svhn, s_labels = self.to_var(svhn), self.to_var(s_labels).long().squeeze()\n            mnist, m_labels = mnist_iter.next() \n            mnist, m_labels = self.to_var(mnist), self.to_var(m_labels)\n\n            if self.use_labels:\n                mnist_fake_labels = self.to_var(\n                    torch.Tensor([self.num_classes]*svhn.size(0)).long())\n                svhn_fake_labels = self.to_var(\n                    torch.Tensor([self.num_classes]*mnist.size(0)).long())\n            \n            #============ train D ============#\n            \n            # train with real images\n            self.reset_grad()\n            out = self.d1(mnist)\n            if self.use_labels:\n                d1_loss = criterion(out, m_labels)\n            else:\n                d1_loss = torch.mean((out-1)**2)\n            \n            out = self.d2(svhn)\n            if self.use_labels:\n                d2_loss = criterion(out, s_labels)\n            else:\n                d2_loss = torch.mean((out-1)**2)\n            \n            d_mnist_loss = d1_loss\n            d_svhn_loss = d2_loss\n            d_real_loss = d1_loss + d2_loss\n            d_real_loss.backward()\n            self.d_optimizer.step()\n            \n            # train with fake images\n            self.reset_grad()\n            fake_svhn = self.g12(mnist)\n            out = self.d2(fake_svhn)\n            if self.use_labels:\n                d2_loss = criterion(out, svhn_fake_labels)\n            else:\n                d2_loss = torch.mean(out**2)\n            \n            fake_mnist = self.g21(svhn)\n            out = self.d1(fake_mnist)\n            if self.use_labels:\n                d1_loss = criterion(out, mnist_fake_labels)\n            else:\n                d1_loss = torch.mean(out**2)\n            \n            d_fake_loss = d1_loss + d2_loss\n            d_fake_loss.backward()\n            self.d_optimizer.step()\n            \n            #============ train G ============#\n            \n            # train mnist-svhn-mnist cycle\n            self.reset_grad()\n            fake_svhn = self.g12(mnist)\n            out = self.d2(fake_svhn)\n            reconst_mnist = self.g21(fake_svhn)\n            if self.use_labels:\n                g_loss = criterion(out, m_labels) \n            else:\n                g_loss = torch.mean((out-1)**2) \n\n            if self.use_reconst_loss:\n                g_loss += torch.mean((mnist - reconst_mnist)**2)\n\n            g_loss.backward()\n            self.g_optimizer.step()\n\n            # train svhn-mnist-svhn cycle\n            self.reset_grad()\n            fake_mnist = self.g21(svhn)\n            out = self.d1(fake_mnist)\n            reconst_svhn = self.g12(fake_mnist)\n            if self.use_labels:\n                g_loss = criterion(out, s_labels) \n            else:\n                g_loss = torch.mean((out-1)**2) \n\n            if self.use_reconst_loss:\n                g_loss += torch.mean((svhn - reconst_svhn)**2)\n\n            g_loss.backward()\n            self.g_optimizer.step()\n            \n            # print the log info\n            if (step+1) % self.log_step == 0:\n                print(\'Step [%d/%d], d_real_loss: %.4f, d_mnist_loss: %.4f, d_svhn_loss: %.4f, \'\n                      \'d_fake_loss: %.4f, g_loss: %.4f\' \n                      %(step+1, self.train_iters, d_real_loss.data[0], d_mnist_loss.data[0], \n                        d_svhn_loss.data[0], d_fake_loss.data[0], g_loss.data[0]))\n\n            # save the sampled images\n            if (step+1) % self.sample_step == 0:\n                fake_svhn = self.g12(fixed_mnist)\n                fake_mnist = self.g21(fixed_svhn)\n                \n                mnist, fake_mnist = self.to_data(fixed_mnist), self.to_data(fake_mnist)\n                svhn , fake_svhn = self.to_data(fixed_svhn), self.to_data(fake_svhn)\n                \n                merged = self.merge_images(mnist, fake_svhn)\n                path = os.path.join(self.sample_path, \'sample-%d-m-s.png\' %(step+1))\n                scipy.misc.imsave(path, merged)\n                print (\'saved %s\' %path)\n                \n                merged = self.merge_images(svhn, fake_mnist)\n                path = os.path.join(self.sample_path, \'sample-%d-s-m.png\' %(step+1))\n                scipy.misc.imsave(path, merged)\n                print (\'saved %s\' %path)\n            \n            if (step+1) % 5000 == 0:\n                # save the model parameters for each epoch\n                g12_path = os.path.join(self.model_path, \'g12-%d.pkl\' %(step+1))\n                g21_path = os.path.join(self.model_path, \'g21-%d.pkl\' %(step+1))\n                d1_path = os.path.join(self.model_path, \'d1-%d.pkl\' %(step+1))\n                d2_path = os.path.join(self.model_path, \'d2-%d.pkl\' %(step+1))\n                torch.save(self.g12.state_dict(), g12_path)\n                torch.save(self.g21.state_dict(), g21_path)\n                torch.save(self.d1.state_dict(), d1_path)\n                torch.save(self.d2.state_dict(), d2_path)'"
