file_path,api_count,code
cifar.py,10,"b'\'\'\'Train CIFAR10 with PyTorch.\'\'\'\nfrom __future__ import print_function\n\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\nimport lib.custom_transforms as custom_transforms\n\nimport os\nimport argparse\nimport time\n\nimport models\nimport datasets\nimport math\n\nfrom lib.NCEAverage import NCEAverage\nfrom lib.LinearAverage import LinearAverage\nfrom lib.NCECriterion import NCECriterion\nfrom lib.utils import AverageMeter\nfrom test import NN, kNN\n\nparser = argparse.ArgumentParser(description=\'PyTorch CIFAR10 Training\')\nparser.add_argument(\'--lr\', default=0.03, type=float, help=\'learning rate\')\nparser.add_argument(\'--resume\', \'-r\', default=\'\', type=str, help=\'resume from checkpoint\')\nparser.add_argument(\'--test-only\', action=\'store_true\', help=\'test only\')\nparser.add_argument(\'--low-dim\', default=128, type=int,\n                    metavar=\'D\', help=\'feature dimension\')\nparser.add_argument(\'--nce-k\', default=4096, type=int,\n                    metavar=\'K\', help=\'number of negative samples for NCE\')\nparser.add_argument(\'--nce-t\', default=0.1, type=float,\n                    metavar=\'T\', help=\'temperature parameter for softmax\')\nparser.add_argument(\'--nce-m\', default=0.5, type=float,\n                    metavar=\'M\', help=\'momentum for non-parametric updates\')\n\nargs = parser.parse_args()\n\ndevice = \'cuda\' if torch.cuda.is_available() else \'cpu\'\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint(\'==> Preparing data..\')\ntransform_train = transforms.Compose([\n    transforms.RandomResizedCrop(size=32, scale=(0.2,1.)),\n    transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n    transforms.RandomGrayscale(p=0.2),\n    #transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = datasets.CIFAR10Instance(root=\'./data\', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n\ntestset = datasets.CIFAR10Instance(root=\'./data\', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n\nclasses = (\'plane\', \'car\', \'bird\', \'cat\', \'deer\', \'dog\', \'frog\', \'horse\', \'ship\', \'truck\')\nndata = trainset.__len__()\n\nprint(\'==> Building model..\')\nnet = models.__dict__[\'ResNet18\'](low_dim=args.low_dim)\n# define leminiscate\nif args.nce_k > 0:\n    lemniscate = NCEAverage(args.low_dim, ndata, args.nce_k, args.nce_t, args.nce_m)\nelse:\n    lemniscate = LinearAverage(args.low_dim, ndata, args.nce_t, args.nce_m)\n\nif device == \'cuda\':\n    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n    cudnn.benchmark = True\n\n# Model\nif args.test_only or len(args.resume)>0:\n    # Load checkpoint.\n    print(\'==> Resuming from checkpoint..\')\n    assert os.path.isdir(\'checkpoint\'), \'Error: no checkpoint directory found!\'\n    checkpoint = torch.load(\'./checkpoint/\'+args.resume)\n    net.load_state_dict(checkpoint[\'net\'])\n    lemniscate = checkpoint[\'lemniscate\']\n    best_acc = checkpoint[\'acc\']\n    start_epoch = checkpoint[\'epoch\']\n    \n# define loss function\nif hasattr(lemniscate, \'K\'):\n    criterion = NCECriterion(ndata)\nelse:\n    criterion = nn.CrossEntropyLoss()\n\nnet.to(device)\nlemniscate.to(device)\ncriterion.to(device)\n\nif args.test_only:\n    acc = kNN(0, net, lemniscate, trainloader, testloader, 200, args.nce_t, 1)\n    sys.exit(0)\n\noptimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 30 epochs""""""\n    lr = args.lr\n    if epoch >= 80:\n        lr = args.lr * (0.1 ** ((epoch-80) // 40))\n    print(lr)\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n# Training\ndef train(epoch):\n    print(\'\\nEpoch: %d\' % epoch)\n    adjust_learning_rate(optimizer, epoch)\n    train_loss = AverageMeter()\n    data_time = AverageMeter()\n    batch_time = AverageMeter()\n    correct = 0\n    total = 0\n\n    # switch to train mode\n    net.train()\n\n    end = time.time()\n    for batch_idx, (inputs, targets, indexes) in enumerate(trainloader):\n        data_time.update(time.time() - end)\n        inputs, targets, indexes = inputs.to(device), targets.to(device), indexes.to(device)\n        optimizer.zero_grad()\n\n        features = net(inputs)\n        outputs = lemniscate(features, indexes)\n        loss = criterion(outputs, indexes)\n\n        loss.backward()\n        optimizer.step()\n\n        train_loss.update(loss.item(), inputs.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        print(\'Epoch: [{}][{}/{}]\'\n              \'Time: {batch_time.val:.3f} ({batch_time.avg:.3f}) \'\n              \'Data: {data_time.val:.3f} ({data_time.avg:.3f}) \'\n              \'Loss: {train_loss.val:.4f} ({train_loss.avg:.4f})\'.format(\n              epoch, batch_idx, len(trainloader), batch_time=batch_time, data_time=data_time, train_loss=train_loss))\n\nfor epoch in range(start_epoch, start_epoch+200):\n    train(epoch)\n    acc = kNN(epoch, net, lemniscate, trainloader, testloader, 200, args.nce_t, 0)\n\n    if acc > best_acc:\n        print(\'Saving..\')\n        state = {\n            \'net\': net.state_dict(),\n            \'lemniscate\': lemniscate,\n            \'acc\': acc,\n            \'epoch\': epoch,\n        }\n        if not os.path.isdir(\'checkpoint\'):\n            os.mkdir(\'checkpoint\')\n        torch.save(state, \'./checkpoint/ckpt.t7\')\n        best_acc = acc\n\n    print(\'best accuracy: {:.2f}\'.format(best_acc*100))\n\nacc = kNN(0, net, lemniscate, trainloader, testloader, 200, args.nce_t, 1)\nprint(\'last accuracy: {:.2f}\'.format(acc*100))\n'"
main.py,16,"b'import argparse\nimport os\nimport sys\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\n\nimport datasets\nimport models\nimport math\n\nfrom lib.NCEAverage import NCEAverage\nfrom lib.LinearAverage import LinearAverage\nfrom lib.NCECriterion import NCECriterion\nfrom lib.utils import AverageMeter\nfrom test import NN, kNN\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(""__"")\n    and callable(models.__dict__[name]))\n\nparser = argparse.ArgumentParser(description=\'PyTorch ImageNet Training\')\nparser.add_argument(\'data\', metavar=\'DIR\',\n                    help=\'path to dataset\')\nparser.add_argument(\'--arch\', \'-a\', metavar=\'ARCH\', default=\'resnet18\',\n                    choices=model_names,\n                    help=\'model architecture: \' +\n                        \' | \'.join(model_names) +\n                        \' (default: resnet18)\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'number of data loading workers (default: 4)\')\nparser.add_argument(\'--epochs\', default=200, type=int, metavar=\'N\',\n                    help=\'number of total epochs to run\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\',\n                    help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'-b\', \'--batch-size\', default=256, type=int,\n                    metavar=\'N\', help=\'mini-batch size (default: 256)\')\nparser.add_argument(\'--lr\', \'--learning-rate\', default=0.03, type=float,\n                    metavar=\'LR\', help=\'initial learning rate\')\nparser.add_argument(\'--momentum\', default=0.9, type=float, metavar=\'M\',\n                    help=\'momentum\')\nparser.add_argument(\'--weight-decay\', \'--wd\', default=1e-4, type=float,\n                    metavar=\'W\', help=\'weight decay (default: 1e-4)\')\nparser.add_argument(\'--print-freq\', \'-p\', default=10, type=int,\n                    metavar=\'N\', help=\'print frequency (default: 10)\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\',\n                    help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--test-only\', action=\'store_true\', help=\'test only\')\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\',\n                    help=\'evaluate model on validation set\')\nparser.add_argument(\'--pretrained\', dest=\'pretrained\', action=\'store_true\',\n                    help=\'use pre-trained model\')\nparser.add_argument(\'--world-size\', default=1, type=int,\n                    help=\'number of distributed processes\')\nparser.add_argument(\'--dist-url\', default=\'tcp://224.66.41.62:23456\', type=str,\n                    help=\'url used to set up distributed training\')\nparser.add_argument(\'--dist-backend\', default=\'gloo\', type=str,\n                    help=\'distributed backend\')\nparser.add_argument(\'--low-dim\', default=128, type=int,\n                    metavar=\'D\', help=\'feature dimension\')\nparser.add_argument(\'--nce-k\', default=4096, type=int,\n                    metavar=\'K\', help=\'number of negative samples for NCE\')\nparser.add_argument(\'--nce-t\', default=0.07, type=float, \n                    metavar=\'T\', help=\'temperature parameter for softmax\')\nparser.add_argument(\'--nce-m\', default=0.5, type=float,\n                    help=\'momentum for non-parametric updates\')\nparser.add_argument(\'--iter_size\', default=1, type=int,\n                    help=\'caffe style iter size\')\n\nbest_prec1 = 0\n\ndef main():\n    global args, best_prec1\n    args = parser.parse_args()\n\n    args.distributed = args.world_size > 1\n\n    if args.distributed:\n        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                                world_size=args.world_size)\n\n    # create model\n    if args.pretrained:\n        print(""=> using pre-trained model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch](pretrained=True)\n    else:\n        print(""=> creating model \'{}\'"".format(args.arch))\n        model = models.__dict__[args.arch](low_dim=args.low_dim)\n\n    if not args.distributed:\n        if args.arch.startswith(\'alexnet\') or args.arch.startswith(\'vgg\'):\n            model.features = torch.nn.DataParallel(model.features)\n            model.cuda()\n        else:\n            model = torch.nn.DataParallel(model).cuda()\n    else:\n        model.cuda()\n        model = torch.nn.parallel.DistributedDataParallel(model)\n\n\n    # Data loading code\n    traindir = os.path.join(args.data, \'train\')\n    valdir = os.path.join(args.data, \'val\')\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_dataset = datasets.ImageFolderInstance(\n        traindir,\n        transforms.Compose([\n            transforms.RandomResizedCrop(224, scale=(0.2,1.)),\n            transforms.RandomGrayscale(p=0.2),\n            transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ]))\n\n    if args.distributed:\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n    else:\n        train_sampler = None\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = torch.utils.data.DataLoader(\n        datasets.ImageFolderInstance(valdir, transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    # define lemniscate and loss function (criterion)\n    ndata = train_dataset.__len__()\n    if args.nce_k > 0:\n        lemniscate = NCEAverage(args.low_dim, ndata, args.nce_k, args.nce_t, args.nce_m).cuda()\n        criterion = NCECriterion(ndata).cuda()\n    else:\n        lemniscate = LinearAverage(args.low_dim, ndata, args.nce_t, args.nce_m).cuda()\n        criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            args.start_epoch = checkpoint[\'epoch\']\n            best_prec1 = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            lemniscate = checkpoint[\'lemniscate\']\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    cudnn.benchmark = True\n\n    if args.evaluate:\n        kNN(0, model, lemniscate, train_loader, val_loader, 200, args.nce_t)\n        return\n\n    for epoch in range(args.start_epoch, args.epochs):\n        if args.distributed:\n            train_sampler.set_epoch(epoch)\n        adjust_learning_rate(optimizer, epoch)\n\n        # train for one epoch\n        train(train_loader, model, lemniscate, criterion, optimizer, epoch)\n\n        # evaluate on validation set\n        prec1 = NN(epoch, model, lemniscate, train_loader, val_loader)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec1 > best_prec1\n        best_prec1 = max(prec1, best_prec1)\n        save_checkpoint({\n            \'epoch\': epoch + 1,\n            \'arch\': args.arch,\n            \'state_dict\': model.state_dict(),\n            \'lemniscate\': lemniscate,\n            \'best_prec1\': best_prec1,\n            \'optimizer\' : optimizer.state_dict(),\n        }, is_best)\n    # evaluate KNN after last epoch\n    kNN(0, model, lemniscate, train_loader, val_loader, 200, args.nce_t)\n\n\ndef train(train_loader, model, lemniscate, criterion, optimizer, epoch):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n\n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    optimizer.zero_grad()\n    for i, (input, _, index) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        index = index.cuda(async=True)\n\n        # compute output\n        feature = model(input)\n        output = lemniscate(feature, index)\n        loss = criterion(output, index) / args.iter_size\n\n        loss.backward()\n\n        # measure accuracy and record loss\n        losses.update(loss.item() * args.iter_size, input.size(0))\n\n        if (i+1) % args.iter_size == 0:\n            # compute gradient and do SGD step\n            optimizer.step()\n            optimizer.zero_grad()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print(\'Epoch: [{0}][{1}/{2}]\\t\'\n                  \'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\'\n                  \'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\'\n                  \'Loss {loss.val:.4f} ({loss.avg:.4f})\\t\'.format(\n                   epoch, i, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses))\n\n\ndef save_checkpoint(state, is_best, filename=\'checkpoint.pth.tar\'):\n    torch.save(state, filename)\n    if is_best:\n        shutil.copyfile(filename, \'model_best.pth.tar\')\n\ndef adjust_learning_rate(optimizer, epoch):\n    """"""Sets the learning rate to the initial LR decayed by 10 every 100 epochs""""""\n    lr = args.lr\n    if epoch < 120:\n        lr = args.lr\n    elif epoch >= 120 and epoch < 160:\n        lr = args.lr * 0.1\n    else:\n        lr = args.lr * 0.01\n    #lr = args.lr * (0.1 ** (epoch // 100))\n    for param_group in optimizer.param_groups:\n        param_group[\'lr\'] = lr\n\n\ndef accuracy(output, target, topk=(1,)):\n    """"""Computes the precision@k for the specified values of k""""""\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res\n\n\nif __name__ == \'__main__\':\n    main()\n'"
test.py,16,"b""import torch\nimport time\nimport datasets\nfrom lib.utils import AverageMeter\nimport torchvision.transforms as transforms\nimport numpy as np\n\ndef NN(epoch, net, lemniscate, trainloader, testloader, recompute_memory=0):\n    net.eval()\n    net_time = AverageMeter()\n    cls_time = AverageMeter()\n    losses = AverageMeter()\n    correct = 0.\n    total = 0\n    testsize = testloader.dataset.__len__()\n\n    trainFeatures = lemniscate.memory.t()\n    if hasattr(trainloader.dataset, 'imgs'):\n        trainLabels = torch.LongTensor([y for (p, y) in trainloader.dataset.imgs]).cuda()\n    else:\n        trainLabels = torch.LongTensor(trainloader.dataset.train_labels).cuda()\n\n    if recompute_memory:\n        transform_bak = trainloader.dataset.transform\n        trainloader.dataset.transform = testloader.dataset.transform\n        temploader = torch.utils.data.DataLoader(trainloader.dataset, batch_size=100, shuffle=False, num_workers=1)\n        for batch_idx, (inputs, targets, indexes) in enumerate(temploader):\n            targets = targets.cuda(async=True)\n            batchSize = inputs.size(0)\n            features = net(inputs)\n            trainFeatures[:, batch_idx*batchSize:batch_idx*batchSize+batchSize] = features.data.t()\n        trainLabels = torch.LongTensor(temploader.dataset.train_labels).cuda()\n        trainloader.dataset.transform = transform_bak\n    \n    end = time.time()\n    with torch.no_grad():\n        for batch_idx, (inputs, targets, indexes) in enumerate(testloader):\n            targets = targets.cuda(async=True)\n            batchSize = inputs.size(0)\n            features = net(inputs)\n            net_time.update(time.time() - end)\n            end = time.time()\n\n            dist = torch.mm(features, trainFeatures)\n\n            yd, yi = dist.topk(1, dim=1, largest=True, sorted=True)\n            candidates = trainLabels.view(1,-1).expand(batchSize, -1)\n            retrieval = torch.gather(candidates, 1, yi)\n\n            retrieval = retrieval.narrow(1, 0, 1).clone().view(-1)\n            yd = yd.narrow(1, 0, 1)\n\n            total += targets.size(0)\n            correct += retrieval.eq(targets.data).sum().item()\n            \n            cls_time.update(time.time() - end)\n            end = time.time()\n\n            print('Test [{}/{}]\\t'\n                  'Net Time {net_time.val:.3f} ({net_time.avg:.3f})\\t'\n                  'Cls Time {cls_time.val:.3f} ({cls_time.avg:.3f})\\t'\n                  'Top1: {:.2f}'.format(\n                  total, testsize, correct*100./total, net_time=net_time, cls_time=cls_time))\n\n    return correct/total\n\ndef kNN(epoch, net, lemniscate, trainloader, testloader, K, sigma, recompute_memory=0):\n    net.eval()\n    net_time = AverageMeter()\n    cls_time = AverageMeter()\n    total = 0\n    testsize = testloader.dataset.__len__()\n\n    trainFeatures = lemniscate.memory.t()\n    if hasattr(trainloader.dataset, 'imgs'):\n        trainLabels = torch.LongTensor([y for (p, y) in trainloader.dataset.imgs]).cuda()\n    else:\n        trainLabels = torch.LongTensor(trainloader.dataset.train_labels).cuda()\n    C = trainLabels.max() + 1\n\n    if recompute_memory:\n        transform_bak = trainloader.dataset.transform\n        trainloader.dataset.transform = testloader.dataset.transform\n        temploader = torch.utils.data.DataLoader(trainloader.dataset, batch_size=100, shuffle=False, num_workers=1)\n        for batch_idx, (inputs, targets, indexes) in enumerate(temploader):\n            targets = targets.cuda(async=True)\n            batchSize = inputs.size(0)\n            features = net(inputs)\n            trainFeatures[:, batch_idx*batchSize:batch_idx*batchSize+batchSize] = features.data.t()\n        trainLabels = torch.LongTensor(temploader.dataset.train_labels).cuda()\n        trainloader.dataset.transform = transform_bak\n    \n    top1 = 0.\n    top5 = 0.\n    end = time.time()\n    with torch.no_grad():\n        retrieval_one_hot = torch.zeros(K, C).cuda()\n        for batch_idx, (inputs, targets, indexes) in enumerate(testloader):\n            end = time.time()\n            targets = targets.cuda(async=True)\n            batchSize = inputs.size(0)\n            features = net(inputs)\n            net_time.update(time.time() - end)\n            end = time.time()\n\n            dist = torch.mm(features, trainFeatures)\n\n            yd, yi = dist.topk(K, dim=1, largest=True, sorted=True)\n            candidates = trainLabels.view(1,-1).expand(batchSize, -1)\n            retrieval = torch.gather(candidates, 1, yi)\n\n            retrieval_one_hot.resize_(batchSize * K, C).zero_()\n            retrieval_one_hot.scatter_(1, retrieval.view(-1, 1), 1)\n            yd_transform = yd.clone().div_(sigma).exp_()\n            probs = torch.sum(torch.mul(retrieval_one_hot.view(batchSize, -1 , C), yd_transform.view(batchSize, -1, 1)), 1)\n            _, predictions = probs.sort(1, True)\n\n            # Find which predictions match the target\n            correct = predictions.eq(targets.data.view(-1,1))\n            cls_time.update(time.time() - end)\n\n            top1 = top1 + correct.narrow(1,0,1).sum().item()\n            top5 = top5 + correct.narrow(1,0,5).sum().item()\n\n            total += targets.size(0)\n\n            print('Test [{}/{}]\\t'\n                  'Net Time {net_time.val:.3f} ({net_time.avg:.3f})\\t'\n                  'Cls Time {cls_time.val:.3f} ({cls_time.avg:.3f})\\t'\n                  'Top1: {:.2f}  Top5: {:.2f}'.format(\n                  total, testsize, top1*100./total, top5*100./total, net_time=net_time, cls_time=cls_time))\n\n    print(top1*100./total)\n\n    return top1/total\n\n"""
datasets/__init__.py,0,"b""from .folder import ImageFolderInstance\nfrom .cifar import CIFAR10Instance, CIFAR100Instance\nfrom .mnist import MNISTInstance\n\n__all__ = ('ImageFolderInstance', 'MNISTInstance', 'CIFAR10Instance', 'CIFAR100Instance')\n\n"""
datasets/cifar.py,1,"b'from __future__ import print_function\nfrom PIL import Image\nimport torchvision.datasets as datasets\nimport torch.utils.data as data\n\nclass CIFAR10Instance(datasets.CIFAR10):\n    """"""CIFAR10Instance Dataset.\n    """"""\n    def __getitem__(self, index):\n        if self.train:\n            img, target = self.train_data[index], self.train_labels[index]\n        else:\n            img, target = self.test_data[index], self.test_labels[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(img)\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target, index\n\nclass CIFAR100Instance(CIFAR10Instance):\n    """"""CIFAR100Instance Dataset.\n\n    This is a subclass of the `CIFAR10Instance` Dataset.\n    """"""\n    base_folder = \'cifar-100-python\'\n    url = ""https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz""\n    filename = ""cifar-100-python.tar.gz""\n    tgz_md5 = \'eb9058c3a382ffc7106e4002c42a8d85\'\n    train_list = [\n        [\'train\', \'16019d7e3df5f24257cddd939b257f8d\'],\n    ]\n\n    test_list = [\n        [\'test\', \'f0ef6b0ae62326f3e7ffdfab6717acfc\'],\n    ]\n'"
datasets/folder.py,0,"b'import torchvision.datasets as datasets\n\nclass ImageFolderInstance(datasets.ImageFolder):\n    """""": Folder datasets which returns the index of the image as well::\n    """"""\n    def __getitem__(self, index):\n        """"""\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        """"""\n        path, target = self.imgs[index]\n        img = self.loader(path)\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target, index\n\n'"
datasets/mnist.py,1,"b'from __future__ import print_function\nfrom PIL import Image\nimport torchvision.datasets as datasets\nimport torch.utils.data as data\n\nclass MNISTInstance(datasets.MNIST):\n    """"""MNIST Instance Dataset.\n    """"""\n\n    def __getitem__(self, index):\n        """"""\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        """"""\n        if self.train:\n            img, target = self.train_data[index], self.train_labels[index]\n        else:\n            img, target = self.test_data[index], self.test_labels[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(img.numpy(), mode=\'L\')\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target, index\n'"
lib/LinearAverage.py,6,"b""import torch\nfrom torch.autograd import Function\nfrom torch import nn\nimport math\n\nclass LinearAverageOp(Function):\n    @staticmethod\n    def forward(self, x, y, memory, params):\n        T = params[0].item()\n        batchSize = x.size(0)\n\n        # inner product\n        out = torch.mm(x.data, memory.t())\n        out.div_(T) # batchSize * N\n        \n        self.save_for_backward(x, memory, y, params)\n\n        return out\n\n    @staticmethod\n    def backward(self, gradOutput):\n        x, memory, y, params = self.saved_tensors\n        batchSize = gradOutput.size(0)\n        T = params[0].item()\n        momentum = params[1].item()\n        \n        # add temperature\n        gradOutput.data.div_(T)\n\n        # gradient of linear\n        gradInput = torch.mm(gradOutput.data, memory)\n        gradInput.resize_as_(x)\n\n        # update the non-parametric data\n        weight_pos = memory.index_select(0, y.data.view(-1)).resize_as_(x)\n        weight_pos.mul_(momentum)\n        weight_pos.add_(torch.mul(x.data, 1-momentum))\n        w_norm = weight_pos.pow(2).sum(1, keepdim=True).pow(0.5)\n        updated_weight = weight_pos.div(w_norm)\n        memory.index_copy_(0, y, updated_weight)\n        \n        return gradInput, None, None, None\n\nclass LinearAverage(nn.Module):\n\n    def __init__(self, inputSize, outputSize, T=0.07, momentum=0.5):\n        super(LinearAverage, self).__init__()\n        stdv = 1 / math.sqrt(inputSize)\n        self.nLem = outputSize\n\n        self.register_buffer('params',torch.tensor([T, momentum]));\n        stdv = 1. / math.sqrt(inputSize/3)\n        self.register_buffer('memory', torch.rand(outputSize, inputSize).mul_(2*stdv).add_(-stdv))\n\n    def forward(self, x, y):\n        out = LinearAverageOp.apply(x, y, self.memory, self.params)\n        return out\n\n"""
lib/NCEAverage.py,8,"b'import torch\nfrom torch.autograd import Function\nfrom torch import nn\nfrom .alias_multinomial import AliasMethod\nimport math\n\nclass NCEFunction(Function):\n    @staticmethod\n    def forward(self, x, y, memory, idx, params):\n        K = int(params[0].item())\n        T = params[1].item()\n        Z = params[2].item()\n\n        momentum = params[3].item()\n        batchSize = x.size(0)\n        outputSize = memory.size(0)\n        inputSize = memory.size(1)\n\n        # sample positives & negatives\n        idx.select(1,0).copy_(y.data)\n\n        # sample correspoinding weights\n        weight = torch.index_select(memory, 0, idx.view(-1))\n        weight.resize_(batchSize, K+1, inputSize)\n\n        # inner product\n        out = torch.bmm(weight, x.data.resize_(batchSize, inputSize, 1))\n        out.div_(T).exp_() # batchSize * self.K+1\n        x.data.resize_(batchSize, inputSize)\n\n        if Z < 0:\n            params[2] = out.mean() * outputSize\n            Z = params[2].item()\n            print(""normalization constant Z is set to {:.1f}"".format(Z))\n\n        out.div_(Z).resize_(batchSize, K+1)\n\n        self.save_for_backward(x, memory, y, weight, out, params)\n\n        return out\n\n    @staticmethod\n    def backward(self, gradOutput):\n        x, memory, y, weight, out, params = self.saved_tensors\n        K = int(params[0].item())\n        T = params[1].item()\n        Z = params[2].item()\n        momentum = params[3].item()\n        batchSize = gradOutput.size(0)\n        \n        # gradients d Pm / d linear = exp(linear) / Z\n        gradOutput.data.mul_(out.data)\n        # add temperature\n        gradOutput.data.div_(T)\n\n        gradOutput.data.resize_(batchSize, 1, K+1)\n        \n        # gradient of linear\n        gradInput = torch.bmm(gradOutput.data, weight)\n        gradInput.resize_as_(x)\n\n        # update the non-parametric data\n        weight_pos = weight.select(1, 0).resize_as_(x)\n        weight_pos.mul_(momentum)\n        weight_pos.add_(torch.mul(x.data, 1-momentum))\n        w_norm = weight_pos.pow(2).sum(1, keepdim=True).pow(0.5)\n        updated_weight = weight_pos.div(w_norm)\n        memory.index_copy_(0, y, updated_weight)\n        \n        return gradInput, None, None, None, None\n\nclass NCEAverage(nn.Module):\n\n    def __init__(self, inputSize, outputSize, K, T=0.07, momentum=0.5, Z=None):\n        super(NCEAverage, self).__init__()\n        self.nLem = outputSize\n        self.unigrams = torch.ones(self.nLem)\n        self.multinomial = AliasMethod(self.unigrams)\n        self.multinomial.cuda()\n        self.K = K\n\n        self.register_buffer(\'params\',torch.tensor([K, T, -1, momentum]));\n        stdv = 1. / math.sqrt(inputSize/3)\n        self.register_buffer(\'memory\', torch.rand(outputSize, inputSize).mul_(2*stdv).add_(-stdv))\n \n    def forward(self, x, y):\n        batchSize = x.size(0)\n        idx = self.multinomial.draw(batchSize * (self.K+1)).view(batchSize, -1)\n        out = NCEFunction.apply(x, y, self.memory, idx, self.params)\n        return out\n\n'"
lib/NCECriterion.py,2,"b'import torch\nfrom torch import nn\n\neps = 1e-7\n\nclass NCECriterion(nn.Module):\n\n    def __init__(self, nLem):\n        super(NCECriterion, self).__init__()\n        self.nLem = nLem\n\n    def forward(self, x, targets):\n        batchSize = x.size(0)\n        K = x.size(1)-1\n        Pnt = 1 / float(self.nLem)\n        Pns = 1 / float(self.nLem)\n        \n        # eq 5.1 : P(origin=model) = Pmt / (Pmt + k*Pnt) \n        Pmt = x.select(1,0)\n        Pmt_div = Pmt.add(K * Pnt + eps)\n        lnPmt = torch.div(Pmt, Pmt_div)\n        \n        # eq 5.2 : P(origin=noise) = k*Pns / (Pms + k*Pns)\n        Pon_div = x.narrow(1,1,K).add(K * Pns + eps)\n        Pon = Pon_div.clone().fill_(K * Pns)\n        lnPon = torch.div(Pon, Pon_div)\n     \n        # equation 6 in ref. A\n        lnPmt.log_()\n        lnPon.log_()\n        \n        lnPmtsum = lnPmt.sum(0)\n        lnPonsum = lnPon.view(-1, 1).sum(0)\n        \n        loss = - (lnPmtsum + lnPonsum) / batchSize\n        \n        return loss\n\n'"
lib/__init__.py,0,b'# nothing\n'
lib/alias_multinomial.py,4,"b""import torch\nimport numpy as np\n\nclass AliasMethod(object):\n    '''\n        From: https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n    '''\n    def __init__(self, probs):\n\n        if probs.sum() > 1:\n            probs.div_(probs.sum())\n        K = len(probs)\n        self.prob = torch.zeros(K)\n        self.alias = torch.LongTensor([0]*K)\n\n        # Sort the data into the outcomes with probabilities\n        # that are larger and smaller than 1/K.\n        smaller = []\n        larger = []\n        for kk, prob in enumerate(probs):\n            self.prob[kk] = K*prob\n            if self.prob[kk] < 1.0:\n                smaller.append(kk)\n            else:\n                larger.append(kk)\n\n        # Loop though and create little binary mixtures that\n        # appropriately allocate the larger outcomes over the\n        # overall uniform mixture.\n        while len(smaller) > 0 and len(larger) > 0:\n            small = smaller.pop()\n            large = larger.pop()\n\n            self.alias[small] = large\n            self.prob[large] = (self.prob[large] - 1.0) + self.prob[small]\n\n            if self.prob[large] < 1.0:\n                smaller.append(large)\n            else:\n                larger.append(large)\n\n        for last_one in smaller+larger:\n            self.prob[last_one] = 1\n\n    def cuda(self): \n        self.prob = self.prob.cuda()\n        self.alias = self.alias.cuda()\n\n    def draw(self, N):\n        '''\n            Draw N samples from multinomial\n        '''\n        K = self.alias.size(0)\n\n        kk = torch.zeros(N, dtype=torch.long, device=self.prob.device).random_(0, K)\n        prob = self.prob.index_select(0, kk)\n        alias = self.alias.index_select(0, kk)\n        # b is whether a random number is greater than q\n        b = torch.bernoulli(prob)\n        oq = kk.mul(b.long())\n        oj = alias.mul((1-b).long())\n\n        return oq + oj\n\n"""
lib/custom_transforms.py,1,"b'import numpy as np\nimport scipy\nimport scipy.ndimage\nfrom scipy.ndimage.filters import gaussian_filter\nfrom scipy.ndimage.interpolation import map_coordinates\nimport collections\nfrom PIL import Image\nimport numbers\nimport random\n\n__author__ = ""Wei OUYANG""\n__license__ = ""GPL""\n__version__ = ""0.1.0""\n__status__ = ""Development""\n\n\ndef center_crop(x, center_crop_size):\n    assert x.ndim == 3\n    centerw, centerh = x.shape[1] // 2, x.shape[2] // 2\n    halfw, halfh = center_crop_size[0] // 2, center_crop_size[1] // 2\n    return x[:, centerw - halfw:centerw + halfw, centerh - halfh:centerh + halfh]\n\n\ndef to_tensor(x):\n    import torch\n    x = x.transpose((2, 0, 1))\n    return torch.from_numpy(x).float()\n\n\ndef random_num_generator(config, random_state=np.random):\n    if config[0] == \'uniform\':\n        ret = random_state.uniform(config[1], config[2], 1)[0]\n    elif config[0] == \'lognormal\':\n        ret = random_state.lognormal(config[1], config[2], 1)[0]\n    else:\n        print(config)\n        raise Exception(\'unsupported format\')\n    return ret\n\n\ndef poisson_downsampling(image, peak, random_state=np.random):\n    if not isinstance(image, np.ndarray):\n        imgArr = np.array(image, dtype=\'float32\')\n    else:\n        imgArr = image.astype(\'float32\')\n    Q = imgArr.max(axis=(0, 1)) / peak\n    if Q[0] == 0:\n        return imgArr\n    ima_lambda = imgArr / Q\n    noisy_img = random_state.poisson(lam=ima_lambda)\n    return noisy_img.astype(\'float32\')\n\n\ndef elastic_transform(image, alpha=1000, sigma=30, spline_order=1, mode=\'nearest\', random_state=np.random):\n    """"""Elastic deformation of image as described in [Simard2003]_.\n    .. [Simard2003] Simard, Steinkraus and Platt, ""Best Practices for\n       Convolutional Neural Networks applied to Visual Document Analysis"", in\n       Proc. of the International Conference on Document Analysis and\n       Recognition, 2003.\n    """"""\n    assert image.ndim == 3\n    shape = image.shape[:2]\n\n    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n                         sigma, mode=""constant"", cval=0) * alpha\n    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n                         sigma, mode=""constant"", cval=0) * alpha\n\n    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing=\'ij\')\n    indices = [np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1))]\n    result = np.empty_like(image)\n    for i in range(image.shape[2]):\n        result[:, :, i] = map_coordinates(\n            image[:, :, i], indices, order=spline_order, mode=mode).reshape(shape)\n    return result\n\n\nclass Merge(object):\n    """"""Merge a group of images\n    """"""\n\n    def __init__(self, axis=-1):\n        self.axis = axis\n\n    def __call__(self, images):\n        if isinstance(images, collections.Sequence) or isinstance(images, np.ndarray):\n            assert all([isinstance(i, np.ndarray)\n                        for i in images]), \'only numpy array is supported\'\n            shapes = [list(i.shape) for i in images]\n            for s in shapes:\n                s[self.axis] = None\n            assert all([s == shapes[0] for s in shapes]\n                       ), \'shapes must be the same except the merge axis\'\n            return np.concatenate(images, axis=self.axis)\n        else:\n            raise Exception(""obj is not a sequence (list, tuple, etc)"")\n\n\nclass Split(object):\n    """"""Split images into individual arraies\n    """"""\n\n    def __init__(self, *slices, **kwargs):\n        assert isinstance(slices, collections.Sequence)\n        slices_ = []\n        for s in slices:\n            if isinstance(s, collections.Sequence):\n                slices_.append(slice(*s))\n            else:\n                slices_.append(s)\n        assert all([isinstance(s, slice) for s in slices_]\n                   ), \'slices must be consist of slice instances\'\n        self.slices = slices_\n        self.axis = kwargs.get(\'axis\', -1)\n\n    def __call__(self, image):\n        if isinstance(image, np.ndarray):\n            ret = []\n            for s in self.slices:\n                sl = [slice(None)] * image.ndim\n                sl[self.axis] = s\n                ret.append(image[sl])\n            return ret\n        else:\n            raise Exception(""obj is not an numpy array"")\n\n\nclass ElasticTransform(object):\n    """"""Apply elastic transformation on a numpy.ndarray (H x W x C)\n    """"""\n\n    def __init__(self, alpha, sigma):\n        self.alpha = alpha\n        self.sigma = sigma\n\n    def __call__(self, image):\n        if isinstance(self.alpha, collections.Sequence):\n            alpha = random_num_generator(self.alpha)\n        else:\n            alpha = self.alpha\n        if isinstance(self.sigma, collections.Sequence):\n            sigma = random_num_generator(self.sigma)\n        else:\n            sigma = self.sigma\n        return elastic_transform(image, alpha=alpha, sigma=sigma)\n\n\nclass PoissonSubsampling(object):\n    """"""Poisson subsampling on a numpy.ndarray (H x W x C)\n    """"""\n\n    def __init__(self, peak, random_state=np.random):\n        self.peak = peak\n        self.random_state = random_state\n\n    def __call__(self, image):\n        if isinstance(self.peak, collections.Sequence):\n            peak = random_num_generator(\n                self.peak, random_state=self.random_state)\n        else:\n            peak = self.peak\n        return poisson_downsampling(image, peak, random_state=self.random_state)\n\n\nclass AddGaussianNoise(object):\n    """"""Add gaussian noise to a numpy.ndarray (H x W x C)\n    """"""\n\n    def __init__(self, mean, sigma, random_state=np.random):\n        self.sigma = sigma\n        self.mean = mean\n        self.random_state = random_state\n\n    def __call__(self, image):\n        if isinstance(self.sigma, collections.Sequence):\n            sigma = random_num_generator(\n                self.sigma, random_state=self.random_state)\n        else:\n            sigma = self.sigma\n        if isinstance(self.mean, collections.Sequence, random_state=self.random_state):\n            mean = random_num_generator(self.mean)\n        else:\n            mean = self.mean\n        row, col, ch = image.shape\n        gauss = self.random_state.normal(mean, sigma, (row, col, ch))\n        gauss = gauss.reshape(row, col, ch)\n        image += gauss\n        return image\n\n\nclass AddSpeckleNoise(object):\n    """"""Add speckle noise to a numpy.ndarray (H x W x C)\n    """"""\n\n    def __init__(self, mean, sigma, random_state=np.random):\n        self.sigma = sigma\n        self.mean = mean\n        self.random_state = random_state\n\n    def __call__(self, image):\n        if isinstance(self.sigma, collections.Sequence):\n            sigma = random_num_generator(\n                self.sigma, random_state=self.random_state)\n        else:\n            sigma = self.sigma\n        if isinstance(self.mean, collections.Sequence):\n            mean = random_num_generator(\n                self.mean, random_state=self.random_state)\n        else:\n            mean = self.mean\n        row, col, ch = image.shape\n        gauss = self.random_state.normal(mean, sigma, (row, col, ch))\n        gauss = gauss.reshape(row, col, ch)\n        image += image * gauss\n        return image\n\n\nclass RandomGaussianBlurring(object):\n    """"""Apply gaussian blur to a numpy.ndarray (H x W x C)\n    """"""\n\n    def __init__(self, sigma, p=0.2, random_state=np.random):\n        self.sigma = sigma\n        self.p = p\n        self.random_state = random_state\n\n    def __call__(self, image):\n        if isinstance(self.sigma, collections.Sequence):\n            sigma = random_num_generator(\n                self.sigma, random_state=self.random_state)\n        else:\n            sigma = self.sigma\n        if random.random() < self.p:\n            image = gaussian_filter(image, sigma=(sigma, sigma, 0))\n        return image\n\n\nclass AddGaussianPoissonNoise(object):\n    """"""Add poisson noise with gaussian blurred image to a numpy.ndarray (H x W x C)\n    """"""\n\n    def __init__(self, sigma, peak, random_state=np.random):\n        self.sigma = sigma\n        self.peak = peak\n        self.random_state = random_state\n\n    def __call__(self, image):\n        if isinstance(self.sigma, collections.Sequence):\n            sigma = random_num_generator(\n                self.sigma, random_state=self.random_state)\n        else:\n            sigma = self.sigma\n        if isinstance(self.peak, collections.Sequence):\n            peak = random_num_generator(\n                self.peak, random_state=self.random_state)\n        else:\n            peak = self.peak\n        bg = gaussian_filter(image, sigma=(sigma, sigma, 0))\n        bg = poisson_downsampling(\n            bg, peak=peak, random_state=self.random_state)\n        return image + bg\n\n\nclass MaxScaleNumpy(object):\n    """"""scale with max and min of each channel of the numpy array i.e.\n    channel = (channel - mean) / std\n    """"""\n\n    def __init__(self, range_min=0.0, range_max=1.0):\n        self.scale = (range_min, range_max)\n\n    def __call__(self, image):\n        mn = image.min(axis=(0, 1))\n        mx = image.max(axis=(0, 1))\n        return self.scale[0] + (image - mn) * (self.scale[1] - self.scale[0]) / (mx - mn)\n\n\nclass MedianScaleNumpy(object):\n    """"""Scale with median and mean of each channel of the numpy array i.e.\n    channel = (channel - mean) / std\n    """"""\n\n    def __init__(self, range_min=0.0, range_max=1.0):\n        self.scale = (range_min, range_max)\n\n    def __call__(self, image):\n        mn = image.min(axis=(0, 1))\n        md = np.median(image, axis=(0, 1))\n        return self.scale[0] + (image - mn) * (self.scale[1] - self.scale[0]) / (md - mn)\n\n\nclass NormalizeNumpy(object):\n    """"""Normalize each channel of the numpy array i.e.\n    channel = (channel - mean) / std\n    """"""\n\n    def __call__(self, image):\n        image -= image.mean(axis=(0, 1))\n        s = image.std(axis=(0, 1))\n        s[s == 0] = 1.0\n        image /= s\n        return image\n\n\nclass MutualExclude(object):\n    """"""Remove elements from one channel\n    """"""\n\n    def __init__(self, exclude_channel, from_channel):\n        self.from_channel = from_channel\n        self.exclude_channel = exclude_channel\n\n    def __call__(self, image):\n        mask = image[:, :, self.exclude_channel] > 0\n        image[:, :, self.from_channel][mask] = 0\n        return image\n\n\nclass RandomCropNumpy(object):\n    """"""Crops the given numpy array at a random location to have a region of\n    the given size. size can be a tuple (target_height, target_width)\n    or an integer, in which case the target will be of a square shape (size, size)\n    """"""\n\n    def __init__(self, size, random_state=np.random):\n        if isinstance(size, numbers.Number):\n            self.size = (int(size), int(size))\n        else:\n            self.size = size\n        self.random_state = random_state\n\n    def __call__(self, img):\n        w, h = img.shape[:2]\n        th, tw = self.size\n        if w == tw and h == th:\n            return img\n\n        x1 = self.random_state.randint(0, w - tw)\n        y1 = self.random_state.randint(0, h - th)\n        return img[x1:x1 + tw, y1: y1 + th, :]\n\n\nclass CenterCropNumpy(object):\n    """"""Crops the given numpy array at the center to have a region of\n    the given size. size can be a tuple (target_height, target_width)\n    or an integer, in which case the target will be of a square shape (size, size)\n    """"""\n\n    def __init__(self, size):\n        if isinstance(size, numbers.Number):\n            self.size = (int(size), int(size))\n        else:\n            self.size = size\n\n    def __call__(self, img):\n        w, h = img.shape[:2]\n        th, tw = self.size\n        x1 = int(round((w - tw) / 2.))\n        y1 = int(round((h - th) / 2.))\n        return img[x1:x1 + tw, y1: y1 + th, :]\n\n\nclass RandomRotate(object):\n    """"""Rotate a PIL.Image or numpy.ndarray (H x W x C) randomly\n    """"""\n\n    def __init__(self, angle_range=(0.0, 360.0), axes=(0, 1), mode=\'reflect\', random_state=np.random):\n        assert isinstance(angle_range, tuple)\n        self.angle_range = angle_range\n        self.random_state = random_state\n        self.axes = axes\n        self.mode = mode\n\n    def __call__(self, image):\n        angle = self.random_state.uniform(\n            self.angle_range[0], self.angle_range[1])\n        if isinstance(image, np.ndarray):\n            mi, ma = image.min(), image.max()\n            image = scipy.ndimage.interpolation.rotate(\n                image, angle, reshape=False, axes=self.axes, mode=self.mode)\n            return np.clip(image, mi, ma)\n        elif isinstance(image, Image.Image):\n            return image.rotate(angle)\n        else:\n            raise Exception(\'unsupported type\')\n\n\nclass BilinearResize(object):\n    """"""Resize a PIL.Image or numpy.ndarray (H x W x C)\n    """"""\n\n    def __init__(self, zoom):\n        self.zoom = [zoom, zoom, 1]\n\n    def __call__(self, image):\n        if isinstance(image, np.ndarray):\n            return scipy.ndimage.interpolation.zoom(image, self.zoom)\n        elif isinstance(image, Image.Image):\n            return image.resize(self.size, Image.BILINEAR)\n        else:\n            raise Exception(\'unsupported type\')\n\n\nclass EnhancedCompose(object):\n    """"""Composes several transforms together.\n    Args:\n        transforms (List[Transform]): list of transforms to compose.\n    Example:\n        >>> transforms.Compose([\n        >>>     transforms.CenterCrop(10),\n        >>>     transforms.ToTensor(),\n        >>> ])\n    """"""\n\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img):\n        for t in self.transforms:\n            if isinstance(t, collections.Sequence):\n                assert isinstance(img, collections.Sequence) and len(img) == len(\n                    t), ""size of image group and transform group does not fit""\n                tmp_ = []\n                for i, im_ in enumerate(img):\n                    if callable(t[i]):\n                        tmp_.append(t[i](im_))\n                    else:\n                        tmp_.append(im_)\n                img = tmp_\n            elif callable(t):\n                img = t(img)\n            elif t is None:\n                continue\n            else:\n                raise Exception(\'unexpected type\')\n        return img\n\n'"
lib/normalize.py,1,"b'import torch\nfrom torch.autograd import Variable\nfrom torch import nn\n\nclass Normalize(nn.Module):\n\n    def __init__(self, power=2):\n        super(Normalize, self).__init__()\n        self.power = power\n    \n    def forward(self, x):\n        norm = x.pow(self.power).sum(1, keepdim=True).pow(1./self.power)\n        out = x.div(norm)\n        return out\n'"
lib/utils.py,0,"b'class AverageMeter(object):\n    """"""Computes and stores the average and current value"""""" \n    def __init__(self):\n        self.reset()\n                   \n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0 \n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n'"
models/__init__.py,0,b'from .resnet import *\nfrom .resnet_cifar import *\n'
models/resnet.py,7,"b'import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\nfrom lib.normalize import Normalize\n\n\n__all__ = [\'ResNet\', \'resnet18\', \'resnet34\', \'resnet50\', \'resnet101\',\n           \'resnet152\']\n\nmodel_urls = {\n    \'resnet18\': \'https://download.pytorch.org/models/resnet18-5c106cde.pth\',\n    \'resnet34\': \'https://download.pytorch.org/models/resnet34-333f7ec4.pth\',\n    \'resnet50\': \'https://download.pytorch.org/models/resnet50-19c8e357.pth\',\n    \'resnet101\': \'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\',\n    \'resnet152\': \'https://download.pytorch.org/models/resnet152-b121ed2d.pth\',\n}\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    ""3x3 convolution with padding""\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, low_dim=128):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, low_dim)\n        self.l2norm = Normalize(2)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        x = self.l2norm(x)\n\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet18\']))\n    return model\n\n\ndef resnet34(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet34\']))\n    return model\n\n\ndef resnet50(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet50\']))\n    return model\n\n\ndef resnet101(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet101\']))\n    return model\n\n\ndef resnet152(pretrained=False, **kwargs):\n    """"""Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    """"""\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls[\'resnet152\']))\n    return model\n'"
models/resnet_cifar.py,4,"b""'''ResNet in PyTorch.\n\nFor Pre-activation ResNet, see 'preact_resnet.py'.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom lib.normalize import Normalize\n\nfrom torch.autograd import Variable\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, low_dim=128):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, low_dim)\n        self.l2norm = Normalize(2)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        out = self.l2norm(out)\n        return out\n\n\ndef ResNet18(low_dim=128):\n    return ResNet(BasicBlock, [2,2,2,2], low_dim)\n\ndef ResNet34(low_dim=128):\n    return ResNet(BasicBlock, [3,4,6,3], low_dim)\n\ndef ResNet50(low_dim=128):\n    return ResNet(Bottleneck, [3,4,6,3], low_dim)\n\ndef ResNet101(low_dim=128):\n    return ResNet(Bottleneck, [3,4,23,3], low_dim)\n\ndef ResNet152(low_dim=128):\n    return ResNet(Bottleneck, [3,8,36,3], low_dim)\n\n\ndef test():\n    net = ResNet18()\n    y = net(Variable(torch.randn(1,3,32,32)))\n    print(y.size())\n\n# test()\n"""
