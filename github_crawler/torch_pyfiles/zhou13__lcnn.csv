file_path,api_count,code
demo.py,15,"b'#!/usr/bin/env python3\n""""""Process an image with the trained neural network\nUsage:\n    demo.py [options] <yaml-config> <checkpoint> <images>...\n    demo.py (-h | --help )\n\nArguments:\n   <yaml-config>                 Path to the yaml hyper-parameter file\n   <checkpoint>                  Path to the checkpoint\n   <images>                      Path to images\n\nOptions:\n   -h --help                     Show this screen.\n   -d --devices <devices>        Comma seperated GPU devices [default: 0]\n""""""\n\nimport os\nimport os.path as osp\nimport pprint\nimport random\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport skimage.io\nimport skimage.transform\nimport torch\nimport yaml\nfrom docopt import docopt\n\nimport lcnn\nfrom lcnn.config import C, M\nfrom lcnn.models.line_vectorizer import LineVectorizer\nfrom lcnn.models.multitask_learner import MultitaskHead, MultitaskLearner\nfrom lcnn.postprocess import postprocess\nfrom lcnn.utils import recursive_to\n\nPLTOPTS = {""color"": ""#33FFFF"", ""s"": 15, ""edgecolors"": ""none"", ""zorder"": 5}\ncmap = plt.get_cmap(""jet"")\nnorm = mpl.colors.Normalize(vmin=0.9, vmax=1.0)\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n\n\ndef c(x):\n    return sm.to_rgba(x)\n\n\ndef main():\n    args = docopt(__doc__)\n    config_file = args[""<yaml-config>""] or ""config/wireframe.yaml""\n    C.update(C.from_yaml(filename=config_file))\n    M.update(C.model)\n    pprint.pprint(C, indent=4)\n\n    random.seed(0)\n    np.random.seed(0)\n    torch.manual_seed(0)\n\n    device_name = ""cpu""\n    os.environ[""CUDA_VISIBLE_DEVICES""] = args[""--devices""]\n    if torch.cuda.is_available():\n        device_name = ""cuda""\n        torch.backends.cudnn.deterministic = True\n        torch.cuda.manual_seed(0)\n        print(""Let\'s use"", torch.cuda.device_count(), ""GPU(s)!"")\n    else:\n        print(""CUDA is not available"")\n    device = torch.device(device_name)\n    checkpoint = torch.load(args[""<checkpoint>""], map_location=device)\n\n    # Load model\n    model = lcnn.models.hg(\n        depth=M.depth,\n        head=lambda c_in, c_out: MultitaskHead(c_in, c_out),\n        num_stacks=M.num_stacks,\n        num_blocks=M.num_blocks,\n        num_classes=sum(sum(M.head_size, [])),\n    )\n    model = MultitaskLearner(model)\n    model = LineVectorizer(model)\n    model.load_state_dict(checkpoint[""model_state_dict""])\n    model = model.to(device)\n    model.eval()\n\n    for imname in args[""<images>""]:\n        print(f""Processing {imname}"")\n        im = skimage.io.imread(imname)\n        if im.ndim == 2:\n            im = np.repeat(im[:, :, None], 3, 2)\n        im = im[:, :, :3]\n        im_resized = skimage.transform.resize(im, (512, 512)) * 255\n        image = (im_resized - M.image.mean) / M.image.stddev\n        image = torch.from_numpy(np.rollaxis(image, 2)[None].copy()).float()\n        with torch.no_grad():\n            input_dict = {\n                ""image"": image.to(device),\n                ""meta"": [\n                    {\n                        ""junc"": torch.zeros(1, 2).to(device),\n                        ""jtyp"": torch.zeros(1, dtype=torch.uint8).to(device),\n                        ""Lpos"": torch.zeros(2, 2, dtype=torch.uint8).to(device),\n                        ""Lneg"": torch.zeros(2, 2, dtype=torch.uint8).to(device),\n                    }\n                ],\n                ""target"": {\n                    ""jmap"": torch.zeros([1, 1, 128, 128]).to(device),\n                    ""joff"": torch.zeros([1, 1, 2, 128, 128]).to(device),\n                },\n                ""mode"": ""testing"",\n            }\n            H = model(input_dict)[""preds""]\n\n        lines = H[""lines""][0].cpu().numpy() / 128 * im.shape[:2]\n        scores = H[""score""][0].cpu().numpy()\n        for i in range(1, len(lines)):\n            if (lines[i] == lines[0]).all():\n                lines = lines[:i]\n                scores = scores[:i]\n                break\n\n        # postprocess lines to remove overlapped lines\n        diag = (im.shape[0] ** 2 + im.shape[1] ** 2) ** 0.5\n        nlines, nscores = postprocess(lines, scores, diag * 0.01, 0, False)\n\n        for i, t in enumerate([0.94, 0.95, 0.96, 0.97, 0.98, 0.99]):\n            plt.gca().set_axis_off()\n            plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n            plt.margins(0, 0)\n            for (a, b), s in zip(nlines, nscores):\n                if s < t:\n                    continue\n                plt.plot([a[1], b[1]], [a[0], b[0]], c=c(s), linewidth=2, zorder=s)\n                plt.scatter(a[1], a[0], **PLTOPTS)\n                plt.scatter(b[1], b[0], **PLTOPTS)\n            plt.gca().xaxis.set_major_locator(plt.NullLocator())\n            plt.gca().yaxis.set_major_locator(plt.NullLocator())\n            plt.imshow(im)\n            plt.savefig(imname.replace("".png"", f""-{t:.02f}.svg""), bbox_inches=""tight"")\n            plt.show()\n            plt.close()\n\n\nif __name__ == ""__main__"":\n    main()\n'"
eval-APH.py,0,"b'#!/usr/bin/env python3\n""""""Evaluate APH for LCNN\nUsage:\n    eval-APH.py <src> <dst>\n    eval-APH.py (-h | --help )\n\nExamples:\n    ./eval-APH.py post/RUN-ITERATION/0_010 post/RUN-ITERATION/0_010-APH\n\nArguments:\n    <src>                Source directory that stores preprocessed npz\n    <dst>                Temporary output directory\n\nOptions:\n   -h --help             Show this screen.\n""""""\n\nimport os\nimport glob\nimport os.path as osp\nimport subprocess\n\nimport numpy as np\nimport scipy.io as sio\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom scipy import interpolate\nfrom docopt import docopt\n\nmpl.rcParams.update({""font.size"": 18})\nplt.rcParams[""font.family""] = ""Times New Roman""\ndel mpl.font_manager.weight_dict[""roman""]\nmpl.font_manager._rebuild()\n\nimage_path = ""data/wireframe/valid-images/""\nline_gt_path = ""data/wireframe/valid/""\noutput_size = 128\n\n\ndef main():\n    args = docopt(__doc__)\n    src_dir = args[""<src>""]\n    tar_dir = args[""<dst>""]\n\n    output_file = osp.join(tar_dir, ""result.mat"")\n    target_dir = osp.join(tar_dir, ""mat"")\n    os.makedirs(target_dir, exist_ok=True)\n    print(f""intermediate matlab results will be saved at: {target_dir}"")\n\n    file_list = glob.glob(osp.join(src_dir, ""*.npz""))\n    thresh = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.97, 0.99, 0.995, 0.999, 0.9995, 0.9999]\n    for t in thresh:\n        for fname in file_list:\n            name = fname.split(""/"")[-1].split(""."")[0]\n            mat_name = name + "".mat""\n            npz = np.load(fname)\n            lines = npz[""lines""].reshape(-1, 4)\n            scores = npz[""score""]\n            for j in range(len(scores) - 1):\n                if scores[j + 1] == scores[0]:\n                    lines = lines[: j + 1]\n                    scores = scores[: j + 1]\n                    break\n            idx = np.where(scores > t)[0]\n            os.makedirs(osp.join(target_dir, str(t)), exist_ok=True)\n            sio.savemat(osp.join(target_dir, str(t), mat_name), {""lines"": lines[idx]})\n\n    cmd = ""matlab -nodisplay -nodesktop ""\n    cmd += \'-r ""dbstop if error; \'\n    cmd += ""eval_release(\'{:s}\', \'{:s}\', \'{:s}\', \'{:s}\', {:d}); quit;\\"""".format(\n        image_path, line_gt_path, output_file, target_dir, output_size\n    )\n    print(""Running:\\n{}"".format(cmd))\n    os.environ[""MATLABPATH""] = ""matlab/""\n    subprocess.call(cmd, shell=True)\n\n    mat = sio.loadmat(output_file)\n    tps = mat[""sumtp""]\n    fps = mat[""sumfp""]\n    N = mat[""sumgt""]\n    rcs = sorted(list((tps / N)[:, 0]))\n    prs = sorted(list((tps / np.maximum(tps + fps, 1e-9))[:, 0]))[::-1]\n\n    print(\n        ""f measure is: "",\n        (2 * np.array(prs) * np.array(rcs) / (np.array(prs) + np.array(rcs))).max(),\n    )\n\n    recall = np.concatenate(([0.0], rcs, [1.0]))\n    precision = np.concatenate(([0.0], prs, [0.0]))\n\n    for i in range(precision.size - 1, 0, -1):\n        precision[i - 1] = max(precision[i - 1], precision[i])\n    i = np.where(recall[1:] != recall[:-1])[0]\n    print(""AP is: "", np.sum((recall[i + 1] - recall[i]) * precision[i + 1]))\n\n    f = interpolate.interp1d(rcs, prs, kind=""cubic"", bounds_error=False)\n    x = np.arange(0, 1, 0.01) * rcs[-1]\n    y = f(x)\n    plt.plot(x, y, linewidth=3, label=""L-CNN"")\n\n    f_scores = np.linspace(0.2, 0.8, num=8)\n    for f_score in f_scores:\n        x = np.linspace(0.01, 1)\n        y = f_score * x / (2 * x - f_score)\n        l, = plt.plot(x[y >= 0], y[y >= 0], color=""green"", alpha=0.3)\n        plt.annotate(""f={0:0.1}"".format(f_score), xy=(0.9, y[45] + 0.02), alpha=0.4)\n\n    plt.grid(True)\n    plt.axis([0.0, 1.0, 0.0, 1.0])\n    plt.xticks(np.arange(0, 1.0, step=0.1))\n    plt.xlabel(""Recall"")\n    plt.ylabel(""Precision"")\n    plt.yticks(np.arange(0, 1.0, step=0.1))\n    plt.legend(loc=3)\n    plt.title(""PR Curve for APH"")\n    plt.savefig(""apH.pdf"", format=""pdf"", bbox_inches=""tight"")\n    plt.savefig(""apH.svg"", format=""svg"", bbox_inches=""tight"")\n    plt.show()\n\n\nif __name__ == ""__main__"":\n    plt.tight_layout()\n    main()\n'"
eval-mAPJ.py,0,"b'#!/usr/bin/env python3\n""""""Evaluate mAPJ for LCNN, AFM, and Wireframe\nUsage:\n    eval-mAPJ.py <path>...\n    eval-mAPJ.py (-h | --help )\n\nExamples:\n    python eval-mAPJ.py logs/*\n\nArguments:\n    <path>                           One or more directories that contain *.npz\n\nOptions:\n   -h --help                         Show this screen.\n""""""\n\nimport os\nimport re\nimport glob\nimport os.path as osp\nfrom collections import defaultdict\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom docopt import docopt\nfrom scipy.io import loadmat\n\nimport lcnn.models\nfrom lcnn.metric import mAPJ, post_jheatmap\n\nGT = ""data/wireframe/valid/*.npz""\nIM = ""data/wireframe/valid-images/*.jpg""\nWF = ""/data/wirebase/result/junc/2/17""\nAFM = ""/data/wirebase/result/wireframe/afm/*.npz""\n\nDIST = [0.5, 1.0, 2.0]\n\n\ndef evaluate_lcnn(im_list, gt_list, lcnn_list):\n    # define result array to aggregate (n x 3) where 3 is (x, y, score)\n    all_junc = np.zeros((0, 3))\n    all_offset_junc = np.zeros((0, 3))\n    # for each detected junction, which image they correspond to\n    all_junc_ids = np.zeros(0, dtype=np.int32)\n    # gt is a list since the variable gt number per image\n    all_jc_gt = []\n\n    for i, (lcnn_fn, gt_fn) in enumerate(zip(lcnn_list, gt_list)):\n        with np.load(lcnn_fn) as npz:\n            result = {name: arr for name, arr in npz.items()}\n            jmap = result[""jmap""]\n            joff = result[""joff""]\n\n        with np.load(gt_fn) as npz:\n            junc_gt = npz[""junc""][:, :2]\n\n        # for j in junc_gt:\n        #     plt.scatter(round(j[1]), round(j[0]), c=""red"")\n        # for j in juncs_wf:\n        #     plt.scatter(round(j[1]), round(j[0]), c=""blue"")\n        # plt.show()\n\n        jun_c = post_jheatmap(jmap[0])\n        all_junc = np.vstack((all_junc, jun_c))\n        jun_o_c = post_jheatmap(jmap[0], offset=joff[0])\n        all_offset_junc = np.vstack((all_offset_junc, jun_o_c))\n\n        all_jc_gt.append(junc_gt)\n        all_junc_ids = np.hstack((all_junc_ids, np.array([i] * len(jun_c))))\n\n    # sometimes filter all and concat empty list will change dtype\n    all_junc_ids = all_junc_ids.astype(np.int64)\n    ap_jc = mAPJ(all_junc, all_jc_gt, DIST, all_junc_ids)\n    ap_joc = mAPJ(all_offset_junc, all_jc_gt, DIST, all_junc_ids)\n    print(f""  {ap_jc:.1f} | {ap_joc:.1f}"")\n\n\ndef evaluate_wireframe(im_list, gt_list, juncs_wf):\n    print(""Compute WF mAP"")\n    juncs_wf = load_wf()\n    all_junc = np.zeros((0, 3))\n    all_junc_ids = np.zeros(0, dtype=np.int32)\n    all_jc_gt = []\n    for i, (im_fn, gt_fn, junc_wf) in enumerate(zip(im_list, gt_list, juncs_wf)):\n        im = cv2.imread(im_fn)\n        im = cv2.resize(im, (128, 128))\n\n        with np.load(gt_fn) as npz:\n            junc_gt = npz[""junc""][:, :2]\n        jun_c = sorted(junc_wf, key=lambda x: -x[2])[:1000]\n\n        all_junc = np.vstack((all_junc, jun_c))\n        all_jc_gt.append(junc_gt)\n        all_junc_ids = np.hstack((all_junc_ids, np.array([i] * len(jun_c))))\n    all_junc_ids = all_junc_ids.astype(np.int64)\n    ap_jc = mAPJ(all_junc, all_jc_gt, DIST, all_junc_ids)\n    print(f""  {ap_jc:.1f}"")\n\n\ndef evaluate_afm(im_list, gt_list, afm):\n    print(""Compute AFM mAP"")\n    all_junc = np.zeros((0, 3))\n    all_junc_ids = np.zeros(0, dtype=np.int32)\n    all_jc_gt = []\n    afm = glob.glob(AFM)\n    afm.sort()\n    for i, (im_fn, gt_fn, afm_fn) in enumerate(zip(im_list, gt_list, afm)):\n        im = cv2.imread(im_fn)\n        im = cv2.resize(im, (128, 128))\n\n        with np.load(gt_fn) as npz:\n            junc_gt = npz[""junc""][:, :2]\n\n        with np.load(afm_fn) as fafm:\n            afm_line = fafm[""lines""].reshape(-1, 2, 2)[:, :, ::-1]\n            afm_score = -fafm[""scores""]\n            h = fafm[""h""]\n            w = fafm[""w""]\n        afm_line[:, :, 0] *= 128 / h\n        afm_line[:, :, 1] *= 128 / w\n\n        jun_c = []\n        for line, score in zip(afm_line, afm_score):\n            jun_c.append(list(line[0]) + [score])\n            jun_c.append(list(line[1]) + [score])\n        jun_c = np.array(jun_c)\n\n        all_junc = np.vstack((all_junc, jun_c))\n        all_jc_gt.append(junc_gt)\n        all_junc_ids = np.hstack((all_junc_ids, np.array([i] * len(jun_c))))\n    all_junc_ids = all_junc_ids.astype(np.int64)\n    ap_jc = mAPJ(all_junc, all_jc_gt, DIST, all_junc_ids)\n    print(f""  {ap_jc:.1f}"")\n\n\ndef load_wf():\n    pts = [defaultdict(int) for _ in range(500)]\n    for thres in range(10):\n        mats = sorted(glob.glob(f""{WF}/{thres}/*.mat""))\n        for i, mat in enumerate(mats):\n            img = cv2.imread(mat.replace("".mat"", ""_5.png""))\n            juncs = loadmat(mat)[""junctions""]\n            if len(juncs) == 0:\n                continue\n            juncs[:, 0] *= 128 / img.shape[1]\n            juncs[:, 1] *= 128 / img.shape[0]\n            # juncs += 0.5\n            for j in juncs:\n                pts[i][tuple(j)] += 1\n    pts = pts[: len(mats)]\n    return [np.array([(k[1], k[0], v) for k, v in ipts.items()]) for ipts in pts]\n\n\ndef main():\n    args = docopt(__doc__)\n    gt_list = sorted(glob.glob(GT))\n    im_list = sorted(glob.glob(IM))\n\n    for path in args[""<path>""]:\n        print(""Evaluating"", path)\n        lcnn_list = sorted(glob.glob(osp.join(path, ""*.npz"")))\n        evaluate_lcnn(im_list, gt_list, lcnn_list)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
eval-sAP.py,0,"b'#!/usr/bin/env python3\n""""""Evaluate sAP5, sAP10, sAP15 for LCNN\nUsage:\n    eval-sAP.py <path>...\n    eval-sAP.py (-h | --help )\n\nExamples:\n    python eval-sAP.py logs/*/npz/000*\n\nArguments:\n    <path>                           One or more directories from train.py\n\nOptions:\n   -h --help                         Show this screen.\n""""""\n\nimport os\nimport sys\nimport glob\nimport os.path as osp\n\nimport numpy as np\nimport scipy.io\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom docopt import docopt\n\nimport lcnn.utils\nimport lcnn.metric\n\nGT = ""data/wireframe/valid/*.npz""\n\n\ndef line_score(path, threshold=5):\n    preds = sorted(glob.glob(path))\n    gts = sorted(glob.glob(GT))\n\n    n_gt = 0\n    lcnn_tp, lcnn_fp, lcnn_scores = [], [], []\n    for pred_name, gt_name in zip(preds, gts):\n        with np.load(pred_name) as fpred:\n            lcnn_line = fpred[""lines""][:, :, :2]\n            lcnn_score = fpred[""score""]\n        with np.load(gt_name) as fgt:\n            gt_line = fgt[""lpos""][:, :, :2]\n        n_gt += len(gt_line)\n\n        for i in range(len(lcnn_line)):\n            if i > 0 and (lcnn_line[i] == lcnn_line[0]).all():\n                lcnn_line = lcnn_line[:i]\n                lcnn_score = lcnn_score[:i]\n                break\n\n        tp, fp = lcnn.metric.msTPFP(lcnn_line, gt_line, threshold)\n        lcnn_tp.append(tp)\n        lcnn_fp.append(fp)\n        lcnn_scores.append(lcnn_score)\n\n    lcnn_tp = np.concatenate(lcnn_tp)\n    lcnn_fp = np.concatenate(lcnn_fp)\n    lcnn_scores = np.concatenate(lcnn_scores)\n    lcnn_index = np.argsort(-lcnn_scores)\n    lcnn_tp = np.cumsum(lcnn_tp[lcnn_index]) / n_gt\n    lcnn_fp = np.cumsum(lcnn_fp[lcnn_index]) / n_gt\n\n    return lcnn.metric.ap(lcnn_tp, lcnn_fp)\n\n\nif __name__ == ""__main__"":\n    args = docopt(__doc__)\n\n    def work(path):\n        print(f""Working on {path}"")\n        return [100 * line_score(f""{path}/*.npz"", t) for t in [5, 10, 15]]\n\n    dirs = sorted(sum([glob.glob(p) for p in args[""<path>""]], []))\n    results = lcnn.utils.parmap(work, dirs)\n\n    for d, msAP in zip(dirs, results):\n        print(f""{d}: {msAP[0]:2.1f} {msAP[1]:2.1f} {msAP[2]:2.1f}"")\n'"
post.py,0,"b'#!/usr/bin/env python3\n""""""Post-processing the output of neural network\nUsage:\n    post.py [options] <input-dir> <output-dir>\n    post.py ( -h | --help )\n\nExamples:\n    post.py logs/logname/npz/000336000  result/logname\n\nArguments:\n   input-dir                         Directory that stores the npz\n   output-dir                        Output directory\n\nOptions:\n   -h --help                         Show this screen.\n   --plot                            Generate images besides npz files\n   --thresholds=<thresholds>         A comma-separated list for thresholding\n                                     [default: 0.006,0.010,0.015]\n""""""\n\nimport glob\nimport math\nimport os\nimport os.path as osp\nimport sys\n\nimport cv2\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom docopt import docopt\n\nfrom lcnn.postprocess import postprocess\nfrom lcnn.utils import parmap\n\nPLTOPTS = {""color"": ""#33FFFF"", ""s"": 1.2, ""edgecolors"": ""none"", ""zorder"": 5}\ncmap = plt.get_cmap(""jet"")\nnorm = mpl.colors.Normalize(vmin=0.92, vmax=1.02)\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n\n\ndef c(x):\n    return sm.to_rgba(x)\n\n\ndef imshow(im):\n    plt.close()\n    sizes = im.shape\n    height = float(sizes[0])\n    width = float(sizes[1])\n\n    fig = plt.figure()\n    fig.set_size_inches(width / height, 1, forward=False)\n    ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])\n    ax.set_axis_off()\n    fig.add_axes(ax)\n    plt.xlim([-0.5, sizes[1] - 0.5])\n    plt.ylim([sizes[0] - 0.5, -0.5])\n    plt.imshow(im)\n\n\ndef main():\n    args = docopt(__doc__)\n\n    files = sorted(glob.glob(osp.join(args[""<input-dir>""], ""*.npz"")))\n    inames = sorted(glob.glob(""data/wireframe/valid-images/*.jpg""))\n    gts = sorted(glob.glob(""data/wireframe/valid/*.npz""))\n    prefix = args[""<output-dir>""]\n\n    inputs = list(zip(files, inames, gts))\n    thresholds = list(map(float, args[""--thresholds""].split("","")))\n\n    def handle(allname):\n        fname, iname, gtname = allname\n        print(""Processing"", fname)\n        im = cv2.imread(iname)\n        with np.load(fname) as f:\n            lines = f[""lines""]\n            scores = f[""score""]\n        with np.load(gtname) as f:\n            gtlines = f[""lpos""][:, :, :2]\n        gtlines[:, :, 0] *= im.shape[0] / 128\n        gtlines[:, :, 1] *= im.shape[1] / 128\n        for i in range(1, len(lines)):\n            if (lines[i] == lines[0]).all():\n                lines = lines[:i]\n                scores = scores[:i]\n                break\n\n        lines[:, :, 0] *= im.shape[0] / 128\n        lines[:, :, 1] *= im.shape[1] / 128\n        diag = (im.shape[0] ** 2 + im.shape[1] ** 2) ** 0.5\n\n        for threshold in thresholds:\n            nlines, nscores = postprocess(lines, scores, diag * threshold, 0, False)\n\n            outdir = osp.join(prefix, f""{threshold:.3f}"".replace(""."", ""_""))\n            os.makedirs(outdir, exist_ok=True)\n            npz_name = osp.join(outdir, osp.split(fname)[-1])\n\n            if args[""--plot""]:\n                # plot gt\n                imshow(im[:, :, ::-1])\n                for (a, b) in gtlines:\n                    plt.plot([a[1], b[1]], [a[0], b[0]], c=""orange"", linewidth=0.5)\n                    plt.scatter(a[1], a[0], **PLTOPTS)\n                    plt.scatter(b[1], b[0], **PLTOPTS)\n                plt.savefig(npz_name.replace("".npz"", "".png""), dpi=500, bbox_inches=0)\n\n                thres = [0.96, 0.97, 0.98, 0.99]\n                for i, t in enumerate(thres):\n                    imshow(im[:, :, ::-1])\n                    for (a, b), s in zip(nlines[nscores > t], nscores[nscores > t]):\n                        plt.plot([a[1], b[1]], [a[0], b[0]], c=c(s), linewidth=0.5)\n                        plt.scatter(a[1], a[0], **PLTOPTS)\n                        plt.scatter(b[1], b[0], **PLTOPTS)\n                    plt.savefig(\n                        npz_name.replace("".npz"", f""_{i}.png""), dpi=500, bbox_inches=0\n                    )\n\n            nlines[:, :, 0] *= 128 / im.shape[0]\n            nlines[:, :, 1] *= 128 / im.shape[1]\n            np.savez_compressed(npz_name, lines=nlines, score=nscores)\n\n    parmap(handle, inputs, 12)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
process.py,9,"b'#!/usr/bin/env python3\n""""""Process a dataset with the trained neural network\nUsage:\n    process.py [options] <yaml-config> <checkpoint> <image-dir> <output-dir>\n    process.py (-h | --help )\n\nArguments:\n   <yaml-config>                 Path to the yaml hyper-parameter file\n   <checkpoint>                  Path to the checkpoint\n   <image-dir>                   Path to the directory containing processed images\n   <output-dir>                  Path to the output directory\n\nOptions:\n   -h --help                     Show this screen.\n   -d --devices <devices>        Comma seperated GPU devices [default: 0]\n   --plot                        Plot the result\n""""""\n\nimport os\nimport sys\nimport shlex\nimport pprint\nimport random\nimport os.path as osp\nimport threading\nimport subprocess\n\nimport yaml\nimport numpy as np\nimport torch\nimport matplotlib as mpl\nimport skimage.io\nimport matplotlib.pyplot as plt\nfrom docopt import docopt\n\nimport lcnn\nfrom lcnn.utils import recursive_to\nfrom lcnn.config import C, M\nfrom lcnn.datasets import WireframeDataset, collate\nfrom lcnn.models.line_vectorizer import LineVectorizer\nfrom lcnn.models.multitask_learner import MultitaskHead, MultitaskLearner\n\n\ndef main():\n    args = docopt(__doc__)\n    config_file = args[""<yaml-config>""] or ""config/wireframe.yaml""\n    C.update(C.from_yaml(filename=config_file))\n    M.update(C.model)\n    pprint.pprint(C, indent=4)\n\n    random.seed(0)\n    np.random.seed(0)\n    torch.manual_seed(0)\n\n    device_name = ""cpu""\n    os.environ[""CUDA_VISIBLE_DEVICES""] = args[""--devices""]\n    if torch.cuda.is_available():\n        device_name = ""cuda""\n        torch.backends.cudnn.deterministic = True\n        torch.cuda.manual_seed(0)\n        print(""Let\'s use"", torch.cuda.device_count(), ""GPU(s)!"")\n    else:\n        print(""CUDA is not available"")\n    device = torch.device(device_name)\n\n    if M.backbone == ""stacked_hourglass"":\n        model = lcnn.models.hg(\n            depth=M.depth,\n            head=lambda c_in, c_out: MultitaskHead(c_in, c_out),\n            num_stacks=M.num_stacks,\n            num_blocks=M.num_blocks,\n            num_classes=sum(sum(M.head_size, [])),\n        )\n    else:\n        raise NotImplementedError\n\n    checkpoint = torch.load(args[""<checkpoint>""])\n    model = MultitaskLearner(model)\n    model = LineVectorizer(model)\n    model.load_state_dict(checkpoint[""model_state_dict""])\n    model = model.to(device)\n    model.eval()\n\n    loader = torch.utils.data.DataLoader(\n        WireframeDataset(args[""<image-dir>""], split=""valid""),\n        shuffle=False,\n        batch_size=M.batch_size,\n        collate_fn=collate,\n        num_workers=C.io.num_workers if os.name != ""nt"" else 0,\n        pin_memory=True,\n    )\n    os.makedirs(args[""<output-dir>""], exist_ok=True)\n\n    for batch_idx, (image, meta, target) in enumerate(loader):\n        with torch.no_grad():\n            input_dict = {\n                ""image"": recursive_to(image, device),\n                ""meta"": recursive_to(meta, device),\n                ""target"": recursive_to(target, device),\n                ""mode"": ""validation"",\n            }\n            H = model(input_dict)[""preds""]\n            for i in range(M.batch_size):\n                index = batch_idx * M.batch_size + i\n                np.savez(\n                    osp.join(args[""<output-dir>""], f""{index:06}.npz""),\n                    **{k: v[i].cpu().numpy() for k, v in H.items()},\n                )\n                if not args[""--plot""]:\n                    continue\n                im = image[i].cpu().numpy().transpose(1, 2, 0)\n                im = im * M.image.stddev + M.image.mean\n                lines = H[""lines""][i].cpu().numpy() * 4\n                scores = H[""score""][i].cpu().numpy()\n                if len(lines) > 0 and not (lines[0] == 0).all():\n                    for i, ((a, b), s) in enumerate(zip(lines, scores)):\n                        if i > 0 and (lines[i] == lines[0]).all():\n                            break\n                        plt.plot([a[1], b[1]], [a[0], b[0]], c=c(s), linewidth=4)\n                plt.show()\n\n\ncmap = plt.get_cmap(""jet"")\nnorm = mpl.colors.Normalize(vmin=0.4, vmax=1.0)\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n\n\ndef c(x):\n    return sm.to_rgba(x)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
train.py,11,"b'#!/usr/bin/env python3\n""""""Train L-CNN\nUsage:\n    train.py [options] <yaml-config>\n    train.py (-h | --help )\n\nArguments:\n   <yaml-config>                   Path to the yaml hyper-parameter file\n\nOptions:\n   -h --help                       Show this screen.\n   -d --devices <devices>          Comma seperated GPU devices [default: 0]\n   -i --identifier <identifier>    Folder identifier [default: default-identifier]\n""""""\n\nimport datetime\nimport glob\nimport os\nimport os.path as osp\nimport platform\nimport pprint\nimport random\nimport shlex\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport threading\n\nimport numpy as np\nimport torch\nimport yaml\nfrom docopt import docopt\n\nimport lcnn\nfrom lcnn.config import C, M\nfrom lcnn.datasets import WireframeDataset, collate\nfrom lcnn.models.line_vectorizer import LineVectorizer\nfrom lcnn.models.multitask_learner import MultitaskHead, MultitaskLearner\n\n\ndef git_hash():\n    cmd = \'git log -n 1 --pretty=""%h""\'\n    ret = subprocess.check_output(shlex.split(cmd)).strip()\n    if isinstance(ret, bytes):\n        ret = ret.decode()\n    return ret\n\n\ndef get_outdir(identifier):\n    # load config\n    name = str(datetime.datetime.now().strftime(""%y%m%d-%H%M%S""))\n    name += ""-%s"" % git_hash()\n    name += ""-%s"" % identifier\n    outdir = osp.join(osp.expanduser(C.io.logdir), name)\n    if not osp.exists(outdir):\n        os.makedirs(outdir)\n    C.io.resume_from = outdir\n    C.to_yaml(osp.join(outdir, ""config.yaml""))\n    os.system(f""git diff HEAD > {outdir}/gitdiff.patch"")\n    return outdir\n\n\ndef main():\n    args = docopt(__doc__)\n    config_file = args[""<yaml-config>""] or ""config/wireframe.yaml""\n    C.update(C.from_yaml(filename=config_file))\n    M.update(C.model)\n    pprint.pprint(C, indent=4)\n    resume_from = C.io.resume_from\n\n    # WARNING: L-CNN is still not deterministic\n    random.seed(0)\n    np.random.seed(0)\n    torch.manual_seed(0)\n\n    device_name = ""cpu""\n    os.environ[""CUDA_VISIBLE_DEVICES""] = args[""--devices""]\n    if torch.cuda.is_available():\n        device_name = ""cuda""\n        torch.backends.cudnn.deterministic = True\n        torch.cuda.manual_seed(0)\n        print(""Let\'s use"", torch.cuda.device_count(), ""GPU(s)!"")\n    else:\n        print(""CUDA is not available"")\n    device = torch.device(device_name)\n\n    # 1. dataset\n\n    # uncomment for debug DataLoader\n    # wireframe.datasets.WireframeDataset(datadir, split=""train"")[0]\n    # sys.exit(0)\n\n    datadir = C.io.datadir\n    kwargs = {\n        ""collate_fn"": collate,\n        ""num_workers"": C.io.num_workers if os.name != ""nt"" else 0,\n        ""pin_memory"": True,\n    }\n    train_loader = torch.utils.data.DataLoader(\n        WireframeDataset(datadir, split=""train""),\n        shuffle=True,\n        batch_size=M.batch_size,\n        **kwargs,\n    )\n    val_loader = torch.utils.data.DataLoader(\n        WireframeDataset(datadir, split=""valid""),\n        shuffle=False,\n        batch_size=M.batch_size_eval,\n        **kwargs,\n    )\n    epoch_size = len(train_loader)\n    # print(""epoch_size (train):"", epoch_size)\n    # print(""epoch_size (valid):"", len(val_loader))\n\n    if resume_from:\n        checkpoint = torch.load(osp.join(resume_from, ""checkpoint_latest.pth""))\n\n    # 2. model\n    if M.backbone == ""stacked_hourglass"":\n        model = lcnn.models.hg(\n            depth=M.depth,\n            head=MultitaskHead,\n            num_stacks=M.num_stacks,\n            num_blocks=M.num_blocks,\n            num_classes=sum(sum(M.head_size, [])),\n        )\n    else:\n        raise NotImplementedError\n\n    model = MultitaskLearner(model)\n    model = LineVectorizer(model)\n\n    if resume_from:\n        model.load_state_dict(checkpoint[""model_state_dict""])\n    model = model.to(device)\n\n    # 3. optimizer\n    if C.optim.name == ""Adam"":\n        optim = torch.optim.Adam(\n            model.parameters(),\n            lr=C.optim.lr,\n            weight_decay=C.optim.weight_decay,\n            amsgrad=C.optim.amsgrad,\n        )\n    elif C.optim.name == ""SGD"":\n        optim = torch.optim.SGD(\n            model.parameters(),\n            lr=C.optim.lr,\n            weight_decay=C.optim.weight_decay,\n            momentum=C.optim.momentum,\n        )\n    else:\n        raise NotImplementedError\n\n    if resume_from:\n        optim.load_state_dict(checkpoint[""optim_state_dict""])\n    outdir = resume_from or get_outdir(args[""--identifier""])\n    print(""outdir:"", outdir)\n\n    try:\n        trainer = lcnn.trainer.Trainer(\n            device=device,\n            model=model,\n            optimizer=optim,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            out=outdir,\n        )\n        if resume_from:\n            trainer.iteration = checkpoint[""iteration""]\n            if trainer.iteration % epoch_size != 0:\n                print(""WARNING: iteration is not a multiple of epoch_size, reset it"")\n                trainer.iteration -= trainer.iteration % epoch_size\n            trainer.best_mean_loss = checkpoint[""best_mean_loss""]\n            del checkpoint\n        trainer.train()\n    except BaseException:\n        if len(glob.glob(f""{outdir}/viz/*"")) <= 1:\n            shutil.rmtree(outdir)\n        raise\n\n\nif __name__ == ""__main__"":\n    main()\n'"
dataset/wireframe.py,0,"b'#!/usr/bin/env python\n""""""Process Huang\'s wireframe dataset for L-CNN network\nUsage:\n    dataset/wireframe.py <src> <dst>\n    dataset/wireframe.py (-h | --help )\n\nExamples:\n    python dataset/wireframe.py /datadir/wireframe data/wireframe\n\nArguments:\n    <src>                Original data directory of Huang\'s wireframe dataset\n    <dst>                Directory of the output\n\nOptions:\n   -h --help             Show this screen.\n""""""\n\nimport os\nimport sys\nimport json\nfrom itertools import combinations\n\nimport cv2\nimport numpy as np\nimport skimage.draw\nimport matplotlib.pyplot as plt\nfrom docopt import docopt\nfrom scipy.ndimage import zoom\n\ntry:\n    sys.path.append(""."")\n    sys.path.append("".."")\n    from lcnn.utils import parmap\nexcept Exception:\n    raise\n\n\ndef inrange(v, shape):\n    return 0 <= v[0] < shape[0] and 0 <= v[1] < shape[1]\n\n\ndef to_int(x):\n    return tuple(map(int, x))\n\n\ndef save_heatmap(prefix, image, lines):\n    im_rescale = (512, 512)\n    heatmap_scale = (128, 128)\n\n    fy, fx = heatmap_scale[1] / image.shape[0], heatmap_scale[0] / image.shape[1]\n    jmap = np.zeros((1,) + heatmap_scale, dtype=np.float32)\n    joff = np.zeros((1, 2) + heatmap_scale, dtype=np.float32)\n    lmap = np.zeros(heatmap_scale, dtype=np.float32)\n\n    lines[:, :, 0] = np.clip(lines[:, :, 0] * fx, 0, heatmap_scale[0] - 1e-4)\n    lines[:, :, 1] = np.clip(lines[:, :, 1] * fy, 0, heatmap_scale[1] - 1e-4)\n    lines = lines[:, :, ::-1]\n\n    junc = []\n    jids = {}\n\n    def jid(jun):\n        jun = tuple(jun[:2])\n        if jun in jids:\n            return jids[jun]\n        jids[jun] = len(junc)\n        junc.append(np.array(jun + (0,)))\n        return len(junc) - 1\n\n    lnid = []\n    lpos, lneg = [], []\n    for v0, v1 in lines:\n        lnid.append((jid(v0), jid(v1)))\n        lpos.append([junc[jid(v0)], junc[jid(v1)]])\n\n        vint0, vint1 = to_int(v0), to_int(v1)\n        jmap[0][vint0] = 1\n        jmap[0][vint1] = 1\n        rr, cc, value = skimage.draw.line_aa(*to_int(v0), *to_int(v1))\n        lmap[rr, cc] = np.maximum(lmap[rr, cc], value)\n\n    for v in junc:\n        vint = to_int(v[:2])\n        joff[0, :, vint[0], vint[1]] = v[:2] - vint - 0.5\n\n    llmap = zoom(lmap, [0.5, 0.5])\n    lineset = set([frozenset(l) for l in lnid])\n    for i0, i1 in combinations(range(len(junc)), 2):\n        if frozenset([i0, i1]) not in lineset:\n            v0, v1 = junc[i0], junc[i1]\n            vint0, vint1 = to_int(v0[:2] / 2), to_int(v1[:2] / 2)\n            rr, cc, value = skimage.draw.line_aa(*vint0, *vint1)\n            lneg.append([v0, v1, i0, i1, np.average(np.minimum(value, llmap[rr, cc]))])\n\n    assert len(lneg) != 0\n    lneg.sort(key=lambda l: -l[-1])\n\n    junc = np.array(junc, dtype=np.float32)\n    Lpos = np.array(lnid, dtype=np.int)\n    Lneg = np.array([l[2:4] for l in lneg][:4000], dtype=np.int)\n    lpos = np.array(lpos, dtype=np.float32)\n    lneg = np.array([l[:2] for l in lneg[:2000]], dtype=np.float32)\n\n    image = cv2.resize(image, im_rescale)\n\n    # plt.subplot(131), plt.imshow(lmap)\n    # plt.subplot(132), plt.imshow(image)\n    # for i0, i1 in Lpos:\n    #     plt.scatter(junc[i0][1] * 4, junc[i0][0] * 4)\n    #     plt.scatter(junc[i1][1] * 4, junc[i1][0] * 4)\n    #     plt.plot([junc[i0][1] * 4, junc[i1][1] * 4], [junc[i0][0] * 4, junc[i1][0] * 4])\n    # plt.subplot(133), plt.imshow(lmap)\n    # for i0, i1 in Lneg[:150]:\n    #     plt.plot([junc[i0][1], junc[i1][1]], [junc[i0][0], junc[i1][0]])\n    # plt.show()\n\n    # For junc, lpos, and lneg that stores the junction coordinates, the last\n    # dimension is (y, x, t), where t represents the type of that junction.  In\n    # the wireframe dataset, t is always zero.\n    np.savez_compressed(\n        f""{prefix}_label.npz"",\n        aspect_ratio=image.shape[1] / image.shape[0],\n        jmap=jmap,  # [J, H, W]    Junction heat map\n        joff=joff,  # [J, 2, H, W] Junction offset within each pixel\n        lmap=lmap,  # [H, W]       Line heat map with anti-aliasing\n        junc=junc,  # [Na, 3]      Junction coordinate\n        Lpos=Lpos,  # [M, 2]       Positive lines represented with junction indices\n        Lneg=Lneg,  # [M, 2]       Negative lines represented with junction indices\n        lpos=lpos,  # [Np, 2, 3]   Positive lines represented with junction coordinates\n        lneg=lneg,  # [Nn, 2, 3]   Negative lines represented with junction coordinates\n    )\n    cv2.imwrite(f""{prefix}.png"", image)\n\n    # plt.imshow(jmap[0])\n    # plt.savefig(""/tmp/1jmap0.jpg"")\n    # plt.imshow(jmap[1])\n    # plt.savefig(""/tmp/2jmap1.jpg"")\n    # plt.imshow(lmap)\n    # plt.savefig(""/tmp/3lmap.jpg"")\n    # plt.imshow(Lmap[2])\n    # plt.savefig(""/tmp/4ymap.jpg"")\n    # plt.imshow(jwgt[0])\n    # plt.savefig(""/tmp/5jwgt.jpg"")\n    # plt.cla()\n    # plt.imshow(jmap[0])\n    # for i in range(8):\n    #     plt.quiver(\n    #         8 * jmap[0] * cdir[i] * np.cos(2 * math.pi / 16 * i),\n    #         8 * jmap[0] * cdir[i] * np.sin(2 * math.pi / 16 * i),\n    #         units=""xy"",\n    #         angles=""xy"",\n    #         scale_units=""xy"",\n    #         scale=1,\n    #         minlength=0.01,\n    #         width=0.1,\n    #         zorder=10,\n    #         color=""w"",\n    #     )\n    # plt.savefig(""/tmp/6cdir.jpg"")\n    # plt.cla()\n    # plt.imshow(lmap)\n    # plt.quiver(\n    #     2 * lmap * np.cos(ldir),\n    #     2 * lmap * np.sin(ldir),\n    #     units=""xy"",\n    #     angles=""xy"",\n    #     scale_units=""xy"",\n    #     scale=1,\n    #     minlength=0.01,\n    #     width=0.1,\n    #     zorder=10,\n    #     color=""w"",\n    # )\n    # plt.savefig(""/tmp/7ldir.jpg"")\n    # plt.cla()\n    # plt.imshow(jmap[1])\n    # plt.quiver(\n    #     8 * jmap[1] * np.cos(tdir),\n    #     8 * jmap[1] * np.sin(tdir),\n    #     units=""xy"",\n    #     angles=""xy"",\n    #     scale_units=""xy"",\n    #     scale=1,\n    #     minlength=0.01,\n    #     width=0.1,\n    #     zorder=10,\n    #     color=""w"",\n    # )\n    # plt.savefig(""/tmp/8tdir.jpg"")\n\n\ndef main():\n    args = docopt(__doc__)\n    data_root = args[""<src>""]\n    data_output = args[""<dst>""]\n\n    os.makedirs(data_output, exist_ok=True)\n    for batch in [""train"", ""valid""]:\n        anno_file = os.path.join(data_root, f""{batch}.json"")\n\n        with open(anno_file, ""r"") as f:\n            dataset = json.load(f)\n\n        def handle(data):\n            im = cv2.imread(os.path.join(data_root, ""images"", data[""filename""]))\n            prefix = data[""filename""].split(""."")[0]\n            lines = np.array(data[""lines""]).reshape(-1, 2, 2)\n            os.makedirs(os.path.join(data_output, batch), exist_ok=True)\n\n            lines0 = lines.copy()\n            lines1 = lines.copy()\n            lines1[:, :, 0] = im.shape[1] - lines1[:, :, 0]\n            lines2 = lines.copy()\n            lines2[:, :, 1] = im.shape[0] - lines2[:, :, 1]\n            lines3 = lines.copy()\n            lines3[:, :, 0] = im.shape[1] - lines3[:, :, 0]\n            lines3[:, :, 1] = im.shape[0] - lines3[:, :, 1]\n\n            path = os.path.join(data_output, batch, prefix)\n            save_heatmap(f""{path}_0"", im[::, ::], lines0)\n            if batch != ""valid"":\n                save_heatmap(f""{path}_1"", im[::, ::-1], lines1)\n                save_heatmap(f""{path}_2"", im[::-1, ::], lines2)\n                save_heatmap(f""{path}_3"", im[::-1, ::-1], lines3)\n            print(""Finishing"", os.path.join(data_output, batch, prefix))\n\n        parmap(handle, dataset, 16)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
dataset/york.py,0,"b'#!/usr/bin/env python3\n""""""Process YorkUrban dataset for L-CNN network\nUsage:\n    dataset/york.py <src> <dst>\n    dataset/york.py (-h | --help )\n\nExamples:\n    python dataset/york.py /datadir/york data/york\n\nArguments:\n    <src>                Original data directory of YorkUrban\n    <dst>                Directory of the output\n\nOptions:\n   -h --help             Show this screen.\n""""""\n\nimport os\nimport sys\nimport glob\nimport json\nimport os.path as osp\nfrom itertools import combinations\n\nimport cv2\nimport numpy as np\nimport skimage.draw\nimport matplotlib.pyplot as plt\nfrom docopt import docopt\nfrom scipy.io import loadmat\nfrom scipy.ndimage import zoom\n\ntry:\n    sys.path.append(""."")\n    sys.path.append("".."")\n    from lcnn.utils import parmap\nexcept Exception:\n    raise\n\n\ndef inrange(v, shape):\n    return 0 <= v[0] < shape[0] and 0 <= v[1] < shape[1]\n\n\ndef to_int(x):\n    return tuple(map(int, x))\n\n\ndef save_heatmap(prefix, image, lines):\n    im_rescale = (512, 512)\n    heatmap_scale = (128, 128)\n\n    fy, fx = heatmap_scale[1] / image.shape[0], heatmap_scale[0] / image.shape[1]\n    jmap = np.zeros((1,) + heatmap_scale, dtype=np.float32)\n    joff = np.zeros((1, 2) + heatmap_scale, dtype=np.float32)\n    lmap = np.zeros(heatmap_scale, dtype=np.float32)\n\n    lines[:, :, 0] = np.clip(lines[:, :, 0] * fx, 0, heatmap_scale[0] - 1e-4)\n    lines[:, :, 1] = np.clip(lines[:, :, 1] * fy, 0, heatmap_scale[1] - 1e-4)\n    lines = lines[:, :, ::-1]\n\n    junc = []\n    jids = {}\n\n    def jid(jun):\n        jun = tuple(jun[:2])\n        if jun in jids:\n            return jids[jun]\n        jids[jun] = len(junc)\n        junc.append(np.array(jun + (0,)))\n        return len(junc) - 1\n\n    lnid = []\n    lpos, lneg = [], []\n    for v0, v1 in lines:\n        lnid.append((jid(v0), jid(v1)))\n        lpos.append([junc[jid(v0)], junc[jid(v1)]])\n\n        vint0, vint1 = to_int(v0), to_int(v1)\n        jmap[0][vint0] = 1\n        jmap[0][vint1] = 1\n        rr, cc, value = skimage.draw.line_aa(*to_int(v0), *to_int(v1))\n        lmap[rr, cc] = np.maximum(lmap[rr, cc], value)\n\n    for v in junc:\n        vint = to_int(v[:2])\n        joff[0, :, vint[0], vint[1]] = v[:2] - vint - 0.5\n\n    llmap = zoom(lmap, [0.5, 0.5])\n    lineset = set([frozenset(l) for l in lnid])\n    for i0, i1 in combinations(range(len(junc)), 2):\n        if frozenset([i0, i1]) not in lineset:\n            v0, v1 = junc[i0], junc[i1]\n            vint0, vint1 = to_int(v0[:2] / 2), to_int(v1[:2] / 2)\n            rr, cc, value = skimage.draw.line_aa(*vint0, *vint1)\n            lneg.append([v0, v1, i0, i1, np.average(np.minimum(value, llmap[rr, cc]))])\n            # assert np.sum((v0 - v1) ** 2) > 0.01\n\n    assert len(lneg) != 0\n    lneg.sort(key=lambda l: -l[-1])\n\n    junc = np.array(junc, dtype=np.float32)\n    Lpos = np.array(lnid, dtype=np.int)\n    Lneg = np.array([l[2:4] for l in lneg][:4000], dtype=np.int)\n    lpos = np.array(lpos, dtype=np.float32)\n    lneg = np.array([l[:2] for l in lneg[:2000]], dtype=np.float32)\n\n    image = cv2.resize(image, im_rescale)\n\n    # plt.subplot(131), plt.imshow(lmap)\n    # plt.subplot(132), plt.imshow(image)\n    # for i0, i1 in Lpos:\n    #     plt.scatter(junc[i0][1] * 4, junc[i0][0] * 4)\n    #     plt.scatter(junc[i1][1] * 4, junc[i1][0] * 4)\n    #     plt.plot([junc[i0][1] * 4, junc[i1][1] * 4], [junc[i0][0] * 4, junc[i1][0] * 4])\n    # plt.subplot(133), plt.imshow(lmap)\n    # for i0, i1 in Lneg[:150]:\n    #     plt.plot([junc[i0][1], junc[i1][1]], [junc[i0][0], junc[i1][0]])\n    # plt.show()\n\n    np.savez_compressed(\n        f""{prefix}_label.npz"",\n        aspect_ratio=image.shape[1] / image.shape[0],\n        jmap=jmap,  # [J, H, W]\n        joff=joff,  # [J, 2, H, W]\n        lmap=lmap,  # [H, W]\n        junc=junc,  # [Na, 3]\n        Lpos=Lpos,  # [M, 2]\n        Lneg=Lneg,  # [M, 2]\n        lpos=lpos,  # [Np, 2, 3]   (y, x, t) for the last dim\n        lneg=lneg,  # [Nn, 2, 3]\n    )\n    cv2.imwrite(f""{prefix}.png"", image)\n\n    # plt.imshow(jmap[0])\n    # plt.savefig(""/tmp/1jmap0.jpg"")\n    # plt.imshow(jmap[1])\n    # plt.savefig(""/tmp/2jmap1.jpg"")\n    # plt.imshow(lmap)\n    # plt.savefig(""/tmp/3lmap.jpg"")\n    # plt.imshow(Lmap[2])\n    # plt.savefig(""/tmp/4ymap.jpg"")\n    # plt.imshow(jwgt[0])\n    # plt.savefig(""/tmp/5jwgt.jpg"")\n    # plt.cla()\n    # plt.imshow(jmap[0])\n    # for i in range(8):\n    #     plt.quiver(\n    #         8 * jmap[0] * cdir[i] * np.cos(2 * math.pi / 16 * i),\n    #         8 * jmap[0] * cdir[i] * np.sin(2 * math.pi / 16 * i),\n    #         units=""xy"",\n    #         angles=""xy"",\n    #         scale_units=""xy"",\n    #         scale=1,\n    #         minlength=0.01,\n    #         width=0.1,\n    #         zorder=10,\n    #         color=""w"",\n    #     )\n    # plt.savefig(""/tmp/6cdir.jpg"")\n    # plt.cla()\n    # plt.imshow(lmap)\n    # plt.quiver(\n    #     2 * lmap * np.cos(ldir),\n    #     2 * lmap * np.sin(ldir),\n    #     units=""xy"",\n    #     angles=""xy"",\n    #     scale_units=""xy"",\n    #     scale=1,\n    #     minlength=0.01,\n    #     width=0.1,\n    #     zorder=10,\n    #     color=""w"",\n    # )\n    # plt.savefig(""/tmp/7ldir.jpg"")\n    # plt.cla()\n    # plt.imshow(jmap[1])\n    # plt.quiver(\n    #     8 * jmap[1] * np.cos(tdir),\n    #     8 * jmap[1] * np.sin(tdir),\n    #     units=""xy"",\n    #     angles=""xy"",\n    #     scale_units=""xy"",\n    #     scale=1,\n    #     minlength=0.01,\n    #     width=0.1,\n    #     zorder=10,\n    #     color=""w"",\n    # )\n    # plt.savefig(""/tmp/8tdir.jpg"")\n\n\ndef main():\n    args = docopt(__doc__)\n    data_root = args[""<src>""]\n    data_output = args[""<dst>""]\n    os.makedirs(data_output, exist_ok=True)\n\n    dataset = sorted(glob.glob(osp.join(data_root, ""*/*.jpg"")))\n\n    def handle(iname):\n        prefix = osp.split(iname)[1].replace("".jpg"", """")\n        im = cv2.imread(iname)\n        mat = loadmat(iname.replace("".jpg"", ""LinesAndVP.mat""))\n        lines = np.array(mat[""lines""]).reshape(-1, 2, 2)\n        path = osp.join(data_output, prefix)\n        save_heatmap(f""{path}"", im[::, ::], lines)\n        print(f""Finishing {path}"")\n\n    parmap(handle, dataset)\n\n\nif __name__ == ""__main__"":\n    main()\n'"
lcnn/__init__.py,0,b'import lcnn.models\nimport lcnn.trainer\nimport lcnn.datasets\nimport lcnn.config\n'
lcnn/box.py,0,"b'#!/usr/bin/env python\n# -*- coding: UTF-8 -*-\n#\n# Copyright (c) 2017-2019 - Chris Griffith - MIT License\n""""""\nImproved dictionary access through dot notation with additional tools.\n""""""\nimport string\nimport sys\nimport json\nimport re\nimport copy\nfrom keyword import kwlist\nimport warnings\n\ntry:\n    from collections.abc import Iterable, Mapping, Callable\nexcept ImportError:\n    from collections import Iterable, Mapping, Callable\n\nyaml_support = True\n\ntry:\n    import yaml\nexcept ImportError:\n    try:\n        import ruamel.yaml as yaml\n    except ImportError:\n        yaml = None\n        yaml_support = False\n\nif sys.version_info >= (3, 0):\n    basestring = str\nelse:\n    from io import open\n\n__all__ = [\'Box\', \'ConfigBox\', \'BoxList\', \'SBox\',\n           \'BoxError\', \'BoxKeyError\']\n__author__ = \'Chris Griffith\'\n__version__ = \'3.2.4\'\n\nBOX_PARAMETERS = (\'default_box\', \'default_box_attr\', \'conversion_box\',\n                  \'frozen_box\', \'camel_killer_box\', \'box_it_up\',\n                  \'box_safe_prefix\', \'box_duplicates\', \'ordered_box\')\n\n_first_cap_re = re.compile(\'(.)([A-Z][a-z]+)\')\n_all_cap_re = re.compile(\'([a-z0-9])([A-Z])\')\n\n\nclass BoxError(Exception):\n    """"""Non standard dictionary exceptions""""""\n\n\nclass BoxKeyError(BoxError, KeyError, AttributeError):\n    """"""Key does not exist""""""\n\n\n# Abstract converter functions for use in any Box class\n\n\ndef _to_json(obj, filename=None,\n             encoding=""utf-8"", errors=""strict"", **json_kwargs):\n    json_dump = json.dumps(obj,\n                           ensure_ascii=False, **json_kwargs)\n    if filename:\n        with open(filename, \'w\', encoding=encoding, errors=errors) as f:\n            f.write(json_dump if sys.version_info >= (3, 0) else\n                    json_dump.decode(""utf-8""))\n    else:\n        return json_dump\n\n\ndef _from_json(json_string=None, filename=None,\n               encoding=""utf-8"", errors=""strict"", multiline=False, **kwargs):\n    if filename:\n        with open(filename, \'r\', encoding=encoding, errors=errors) as f:\n            if multiline:\n                data = [json.loads(line.strip(), **kwargs) for line in f\n                        if line.strip() and not line.strip().startswith(""#"")]\n            else:\n                data = json.load(f, **kwargs)\n    elif json_string:\n        data = json.loads(json_string, **kwargs)\n    else:\n        raise BoxError(\'from_json requires a string or filename\')\n    return data\n\n\ndef _to_yaml(obj, filename=None, default_flow_style=False,\n             encoding=""utf-8"", errors=""strict"",\n             **yaml_kwargs):\n    if filename:\n        with open(filename, \'w\',\n                  encoding=encoding, errors=errors) as f:\n            yaml.dump(obj, stream=f,\n                      default_flow_style=default_flow_style,\n                      **yaml_kwargs)\n    else:\n        return yaml.dump(obj,\n                         default_flow_style=default_flow_style,\n                         **yaml_kwargs)\n\n\ndef _from_yaml(yaml_string=None, filename=None,\n               encoding=""utf-8"", errors=""strict"",\n               **kwargs):\n    if filename:\n        with open(filename, \'r\',\n                  encoding=encoding, errors=errors) as f:\n            data = yaml.load(f, **kwargs)\n    elif yaml_string:\n        data = yaml.load(yaml_string, **kwargs)\n    else:\n        raise BoxError(\'from_yaml requires a string or filename\')\n    return data\n\n\n# Helper functions\n\n\ndef _safe_key(key):\n    try:\n        return str(key)\n    except UnicodeEncodeError:\n        return key.encode(""utf-8"", ""ignore"")\n\n\ndef _safe_attr(attr, camel_killer=False, replacement_char=\'x\'):\n    """"""Convert a key into something that is accessible as an attribute""""""\n    allowed = string.ascii_letters + string.digits + \'_\'\n\n    attr = _safe_key(attr)\n\n    if camel_killer:\n        attr = _camel_killer(attr)\n\n    attr = attr.replace(\' \', \'_\')\n\n    out = \'\'\n    for character in attr:\n        out += character if character in allowed else ""_""\n    out = out.strip(""_"")\n\n    try:\n        int(out[0])\n    except (ValueError, IndexError):\n        pass\n    else:\n        out = \'{0}{1}\'.format(replacement_char, out)\n\n    if out in kwlist:\n        out = \'{0}{1}\'.format(replacement_char, out)\n\n    return re.sub(\'_+\', \'_\', out)\n\n\ndef _camel_killer(attr):\n    """"""\n    CamelKiller, qu\'est-ce que c\'est?\n\n    Taken from http://stackoverflow.com/a/1176023/3244542\n    """"""\n    try:\n        attr = str(attr)\n    except UnicodeEncodeError:\n        attr = attr.encode(""utf-8"", ""ignore"")\n\n    s1 = _first_cap_re.sub(r\'\\1_\\2\', attr)\n    s2 = _all_cap_re.sub(r\'\\1_\\2\', s1)\n    return re.sub(\'_+\', \'_\', s2.casefold() if hasattr(s2, \'casefold\') else\n                  s2.lower())\n\n\ndef _recursive_tuples(iterable, box_class, recreate_tuples=False, **kwargs):\n    out_list = []\n    for i in iterable:\n        if isinstance(i, dict):\n            out_list.append(box_class(i, **kwargs))\n        elif isinstance(i, list) or (recreate_tuples and isinstance(i, tuple)):\n            out_list.append(_recursive_tuples(i, box_class,\n                                              recreate_tuples, **kwargs))\n        else:\n            out_list.append(i)\n    return tuple(out_list)\n\n\ndef _conversion_checks(item, keys, box_config, check_only=False,\n                       pre_check=False):\n    """"""\n    Internal use for checking if a duplicate safe attribute already exists\n\n    :param item: Item to see if a dup exists\n    :param keys: Keys to check against\n    :param box_config: Easier to pass in than ask for specfic items\n    :param check_only: Don\'t bother doing the conversion work\n    :param pre_check: Need to add the item to the list of keys to check\n    :return: the original unmodified key, if exists and not check_only\n    """"""\n    if box_config[\'box_duplicates\'] != \'ignore\':\n        if pre_check:\n            keys = list(keys) + [item]\n\n        key_list = [(k,\n                     _safe_attr(k, camel_killer=box_config[\'camel_killer_box\'],\n                                replacement_char=box_config[\'box_safe_prefix\']\n                                )) for k in keys]\n        if len(key_list) > len(set(x[1] for x in key_list)):\n            seen = set()\n            dups = set()\n            for x in key_list:\n                if x[1] in seen:\n                    dups.add(""{0}({1})"".format(x[0], x[1]))\n                seen.add(x[1])\n            if box_config[\'box_duplicates\'].startswith(""warn""):\n                warnings.warn(\'Duplicate conversion attributes exist: \'\n                              \'{0}\'.format(dups))\n            else:\n                raise BoxError(\'Duplicate conversion attributes exist: \'\n                               \'{0}\'.format(dups))\n    if check_only:\n        return\n    # This way will be slower for warnings, as it will have double work\n    # But faster for the default \'ignore\'\n    for k in keys:\n        if item == _safe_attr(k, camel_killer=box_config[\'camel_killer_box\'],\n                              replacement_char=box_config[\'box_safe_prefix\']):\n            return k\n\n\ndef _get_box_config(cls, kwargs):\n    return {\n        # Internal use only\n        \'__converted\': set(),\n        \'__box_heritage\': kwargs.pop(\'__box_heritage\', None),\n        \'__created\': False,\n        \'__ordered_box_values\': [],\n        # Can be changed by user after box creation\n        \'default_box\': kwargs.pop(\'default_box\', False),\n        \'default_box_attr\': kwargs.pop(\'default_box_attr\', cls),\n        \'conversion_box\': kwargs.pop(\'conversion_box\', True),\n        \'box_safe_prefix\': kwargs.pop(\'box_safe_prefix\', \'x\'),\n        \'frozen_box\': kwargs.pop(\'frozen_box\', False),\n        \'camel_killer_box\': kwargs.pop(\'camel_killer_box\', False),\n        \'modify_tuples_box\': kwargs.pop(\'modify_tuples_box\', False),\n        \'box_duplicates\': kwargs.pop(\'box_duplicates\', \'ignore\'),\n        \'ordered_box\': kwargs.pop(\'ordered_box\', False)\n    }\n\n\nclass Box(dict):\n    """"""\n    Improved dictionary access through dot notation with additional tools.\n\n    :param default_box: Similar to defaultdict, return a default value\n    :param default_box_attr: Specify the default replacement.\n        WARNING: If this is not the default \'Box\', it will not be recursive\n    :param frozen_box: After creation, the box cannot be modified\n    :param camel_killer_box: Convert CamelCase to snake_case\n    :param conversion_box: Check for near matching keys as attributes\n    :param modify_tuples_box: Recreate incoming tuples with dicts into Boxes\n    :param box_it_up: Recursively create all Boxes from the start\n    :param box_safe_prefix: Conversion box prefix for unsafe attributes\n    :param box_duplicates: ""ignore"", ""error"" or ""warn"" when duplicates exists\n        in a conversion_box\n    :param ordered_box: Preserve the order of keys entered into the box\n    """"""\n\n    _protected_keys = dir({}) + [\'to_dict\', \'tree_view\', \'to_json\', \'to_yaml\',\n                                 \'from_yaml\', \'from_json\']\n\n    def __new__(cls, *args, **kwargs):\n        """"""\n        Due to the way pickling works in python 3, we need to make sure\n        the box config is created as early as possible.\n        """"""\n        obj = super(Box, cls).__new__(cls, *args, **kwargs)\n        obj._box_config = _get_box_config(cls, kwargs)\n        return obj\n\n    def __init__(self, *args, **kwargs):\n        self._box_config = _get_box_config(self.__class__, kwargs)\n        if self._box_config[\'ordered_box\']:\n            self._box_config[\'__ordered_box_values\'] = []\n        if (not self._box_config[\'conversion_box\'] and\n                self._box_config[\'box_duplicates\'] != ""ignore""):\n            raise BoxError(\'box_duplicates are only for conversion_boxes\')\n        if len(args) == 1:\n            if isinstance(args[0], basestring):\n                raise ValueError(\'Cannot extrapolate Box from string\')\n            if isinstance(args[0], Mapping):\n                for k, v in args[0].items():\n                    if v is args[0]:\n                        v = self\n                    self[k] = v\n                    self.__add_ordered(k)\n            elif isinstance(args[0], Iterable):\n                for k, v in args[0]:\n                    self[k] = v\n                    self.__add_ordered(k)\n\n            else:\n                raise ValueError(\'First argument must be mapping or iterable\')\n        elif args:\n            raise TypeError(\'Box expected at most 1 argument, \'\n                            \'got {0}\'.format(len(args)))\n\n        box_it = kwargs.pop(\'box_it_up\', False)\n        for k, v in kwargs.items():\n            if args and isinstance(args[0], Mapping) and v is args[0]:\n                v = self\n            self[k] = v\n            self.__add_ordered(k)\n\n        if (self._box_config[\'frozen_box\'] or box_it or\n                self._box_config[\'box_duplicates\'] != \'ignore\'):\n            self.box_it_up()\n\n        self._box_config[\'__created\'] = True\n\n    def __add_ordered(self, key):\n        if (self._box_config[\'ordered_box\'] and\n                key not in self._box_config[\'__ordered_box_values\']):\n            self._box_config[\'__ordered_box_values\'].append(key)\n\n    def box_it_up(self):\n        """"""\n        Perform value lookup for all items in current dictionary,\n        generating all sub Box objects, while also running `box_it_up` on\n        any of those sub box objects.\n        """"""\n        for k in self:\n            _conversion_checks(k, self.keys(), self._box_config,\n                               check_only=True)\n            if self[k] is not self and hasattr(self[k], \'box_it_up\'):\n                self[k].box_it_up()\n\n    def __hash__(self):\n        if self._box_config[\'frozen_box\']:\n            hashing = 54321\n            for item in self.items():\n                hashing ^= hash(item)\n            return hashing\n        raise TypeError(""unhashable type: \'Box\'"")\n\n    def __dir__(self):\n        allowed = string.ascii_letters + string.digits + \'_\'\n        kill_camel = self._box_config[\'camel_killer_box\']\n        items = set(dir(dict) + [\'to_dict\', \'to_json\',\n                                 \'from_json\', \'box_it_up\'])\n        # Only show items accessible by dot notation\n        for key in self.keys():\n            key = _safe_key(key)\n            if (\' \' not in key and key[0] not in string.digits and\n                    key not in kwlist):\n                for letter in key:\n                    if letter not in allowed:\n                        break\n                else:\n                    items.add(key)\n\n        for key in self.keys():\n            key = _safe_key(key)\n            if key not in items:\n                if self._box_config[\'conversion_box\']:\n                    key = _safe_attr(key, camel_killer=kill_camel,\n                                     replacement_char=self._box_config[\n                                         \'box_safe_prefix\'])\n                    if key:\n                        items.add(key)\n            if kill_camel:\n                snake_key = _camel_killer(key)\n                if snake_key:\n                    items.remove(key)\n                    items.add(snake_key)\n\n        if yaml_support:\n            items.add(\'to_yaml\')\n            items.add(\'from_yaml\')\n\n        return list(items)\n\n    def get(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            if isinstance(default, dict) and not isinstance(default, Box):\n                return Box(default)\n            if isinstance(default, list) and not isinstance(default, BoxList):\n                return BoxList(default)\n            return default\n\n    def copy(self):\n        return self.__class__(super(self.__class__, self).copy())\n\n    def __copy__(self):\n        return self.__class__(super(self.__class__, self).copy())\n\n    def __deepcopy__(self, memodict=None):\n        out = self.__class__()\n        memodict = memodict or {}\n        memodict[id(self)] = out\n        for k, v in self.items():\n            out[copy.deepcopy(k, memodict)] = copy.deepcopy(v, memodict)\n        return out\n\n    def __setstate__(self, state):\n        self._box_config = state[\'_box_config\']\n        self.__dict__.update(state)\n\n    def __getitem__(self, item, _ignore_default=False):\n        try:\n            value = super(Box, self).__getitem__(item)\n        except KeyError as err:\n            if item == \'_box_config\':\n                raise BoxKeyError(\'_box_config should only exist as an \'\n                                  \'attribute and is never defaulted\')\n            if self._box_config[\'default_box\'] and not _ignore_default:\n                return self.__get_default(item)\n            raise BoxKeyError(str(err))\n        else:\n            return self.__convert_and_store(item, value)\n\n    def keys(self):\n        if self._box_config[\'ordered_box\']:\n            return self._box_config[\'__ordered_box_values\']\n        return super(Box, self).keys()\n\n    def values(self):\n        return [self[x] for x in self.keys()]\n\n    def items(self):\n        return [(x, self[x]) for x in self.keys()]\n\n    def __get_default(self, item):\n        default_value = self._box_config[\'default_box_attr\']\n        if default_value is self.__class__:\n            return self.__class__(__box_heritage=(self, item),\n                                  **self.__box_config())\n        elif isinstance(default_value, Callable):\n            return default_value()\n        elif hasattr(default_value, \'copy\'):\n            return default_value.copy()\n        return default_value\n\n    def __box_config(self):\n        out = {}\n        for k, v in self._box_config.copy().items():\n            if not k.startswith(""__""):\n                out[k] = v\n        return out\n\n    def __convert_and_store(self, item, value):\n        if item in self._box_config[\'__converted\']:\n            return value\n        if isinstance(value, dict) and not isinstance(value, Box):\n            value = self.__class__(value, __box_heritage=(self, item),\n                                   **self.__box_config())\n            self[item] = value\n        elif isinstance(value, list) and not isinstance(value, BoxList):\n            if self._box_config[\'frozen_box\']:\n                value = _recursive_tuples(value, self.__class__,\n                                          recreate_tuples=self._box_config[\n                                              \'modify_tuples_box\'],\n                                          __box_heritage=(self, item),\n                                          **self.__box_config())\n            else:\n                value = BoxList(value, __box_heritage=(self, item),\n                                box_class=self.__class__,\n                                **self.__box_config())\n            self[item] = value\n        elif (self._box_config[\'modify_tuples_box\'] and\n              isinstance(value, tuple)):\n            value = _recursive_tuples(value, self.__class__,\n                                      recreate_tuples=True,\n                                      __box_heritage=(self, item),\n                                      **self.__box_config())\n            self[item] = value\n        self._box_config[\'__converted\'].add(item)\n        return value\n\n    def __create_lineage(self):\n        if (self._box_config[\'__box_heritage\'] and\n                self._box_config[\'__created\']):\n            past, item = self._box_config[\'__box_heritage\']\n            if not past[item]:\n                past[item] = self\n            self._box_config[\'__box_heritage\'] = None\n\n    def __getattr__(self, item):\n        try:\n            try:\n                value = self.__getitem__(item, _ignore_default=True)\n            except KeyError:\n                value = object.__getattribute__(self, item)\n        except AttributeError as err:\n            if item == ""__getstate__"":\n                raise AttributeError(item)\n            if item == \'_box_config\':\n                raise BoxError(\'_box_config key must exist\')\n            kill_camel = self._box_config[\'camel_killer_box\']\n            if self._box_config[\'conversion_box\'] and item:\n                k = _conversion_checks(item, self.keys(), self._box_config)\n                if k:\n                    return self.__getitem__(k)\n            if kill_camel:\n                for k in self.keys():\n                    if item == _camel_killer(k):\n                        return self.__getitem__(k)\n            if self._box_config[\'default_box\']:\n                return self.__get_default(item)\n            raise BoxKeyError(str(err))\n        else:\n            if item == \'_box_config\':\n                return value\n            return self.__convert_and_store(item, value)\n\n    def __setitem__(self, key, value):\n        if (key != \'_box_config\' and self._box_config[\'__created\'] and\n                self._box_config[\'frozen_box\']):\n            raise BoxError(\'Box is frozen\')\n        if self._box_config[\'conversion_box\']:\n            _conversion_checks(key, self.keys(), self._box_config,\n                               check_only=True, pre_check=True)\n        super(Box, self).__setitem__(key, value)\n        self.__add_ordered(key)\n        self.__create_lineage()\n\n    def __setattr__(self, key, value):\n        if (key != \'_box_config\' and self._box_config[\'frozen_box\'] and\n                self._box_config[\'__created\']):\n            raise BoxError(\'Box is frozen\')\n        if key in self._protected_keys:\n            raise AttributeError(""Key name \'{0}\' is protected"".format(key))\n        if key == \'_box_config\':\n            return object.__setattr__(self, key, value)\n        try:\n            object.__getattribute__(self, key)\n        except (AttributeError, UnicodeEncodeError):\n            if (key not in self.keys() and\n                    (self._box_config[\'conversion_box\'] or\n                     self._box_config[\'camel_killer_box\'])):\n                if self._box_config[\'conversion_box\']:\n                    k = _conversion_checks(key, self.keys(),\n                                           self._box_config)\n                    self[key if not k else k] = value\n                elif self._box_config[\'camel_killer_box\']:\n                    for each_key in self:\n                        if key == _camel_killer(each_key):\n                            self[each_key] = value\n                            break\n            else:\n                self[key] = value\n        else:\n            object.__setattr__(self, key, value)\n        self.__add_ordered(key)\n        self.__create_lineage()\n\n    def __delitem__(self, key):\n        if self._box_config[\'frozen_box\']:\n            raise BoxError(\'Box is frozen\')\n        super(Box, self).__delitem__(key)\n        if (self._box_config[\'ordered_box\'] and\n                key in self._box_config[\'__ordered_box_values\']):\n            self._box_config[\'__ordered_box_values\'].remove(key)\n\n    def __delattr__(self, item):\n        if self._box_config[\'frozen_box\']:\n            raise BoxError(\'Box is frozen\')\n        if item == \'_box_config\':\n            raise BoxError(\'""_box_config"" is protected\')\n        if item in self._protected_keys:\n            raise AttributeError(""Key name \'{0}\' is protected"".format(item))\n        try:\n            object.__getattribute__(self, item)\n        except AttributeError:\n            del self[item]\n        else:\n            object.__delattr__(self, item)\n        if (self._box_config[\'ordered_box\'] and\n                item in self._box_config[\'__ordered_box_values\']):\n            self._box_config[\'__ordered_box_values\'].remove(item)\n\n    def pop(self, key, *args):\n        if args:\n            if len(args) != 1:\n                raise BoxError(\'pop() takes only one optional\'\n                               \' argument ""default""\')\n            try:\n                item = self[key]\n            except KeyError:\n                return args[0]\n            else:\n                del self[key]\n                return item\n        try:\n            item = self[key]\n        except KeyError:\n            raise BoxKeyError(\'{0}\'.format(key))\n        else:\n            del self[key]\n            return item\n\n    def clear(self):\n        self._box_config[\'__ordered_box_values\'] = []\n        super(Box, self).clear()\n\n    def popitem(self):\n        try:\n            key = next(self.__iter__())\n        except StopIteration:\n            raise BoxKeyError(\'Empty box\')\n        return key, self.pop(key)\n\n    def __repr__(self):\n        return \'<Box: {0}>\'.format(str(self.to_dict()))\n\n    def __str__(self):\n        return str(self.to_dict())\n\n    def __iter__(self):\n        for key in self.keys():\n            yield key\n\n    def __reversed__(self):\n        for key in reversed(list(self.keys())):\n            yield key\n\n    def to_dict(self):\n        """"""\n        Turn the Box and sub Boxes back into a native\n        python dictionary.\n\n        :return: python dictionary of this Box\n        """"""\n        out_dict = dict(self)\n        for k, v in out_dict.items():\n            if v is self:\n                out_dict[k] = out_dict\n            elif hasattr(v, \'to_dict\'):\n                out_dict[k] = v.to_dict()\n            elif hasattr(v, \'to_list\'):\n                out_dict[k] = v.to_list()\n        return out_dict\n\n    def update(self, item=None, **kwargs):\n        if not item:\n            item = kwargs\n        iter_over = item.items() if hasattr(item, \'items\') else item\n        for k, v in iter_over:\n            if isinstance(v, dict):\n                # Box objects must be created in case they are already\n                # in the `converted` box_config set\n                v = self.__class__(v)\n                if k in self and isinstance(self[k], dict):\n                    self[k].update(v)\n                    continue\n            if isinstance(v, list):\n                v = BoxList(v)\n            try:\n                self.__setattr__(k, v)\n            except (AttributeError, TypeError):\n                self.__setitem__(k, v)\n\n    def setdefault(self, item, default=None):\n        if item in self:\n            return self[item]\n\n        if isinstance(default, dict):\n            default = self.__class__(default)\n        if isinstance(default, list):\n            default = BoxList(default)\n        self[item] = default\n        return default\n\n    def to_json(self, filename=None,\n                encoding=""utf-8"", errors=""strict"", **json_kwargs):\n        """"""\n        Transform the Box object into a JSON string.\n\n        :param filename: If provided will save to file\n        :param encoding: File encoding\n        :param errors: How to handle encoding errors\n        :param json_kwargs: additional arguments to pass to json.dump(s)\n        :return: string of JSON or return of `json.dump`\n        """"""\n        return _to_json(self.to_dict(), filename=filename,\n                        encoding=encoding, errors=errors, **json_kwargs)\n\n    @classmethod\n    def from_json(cls, json_string=None, filename=None,\n                  encoding=""utf-8"", errors=""strict"", **kwargs):\n        """"""\n        Transform a json object string into a Box object. If the incoming\n        json is a list, you must use BoxList.from_json.\n\n        :param json_string: string to pass to `json.loads`\n        :param filename: filename to open and pass to `json.load`\n        :param encoding: File encoding\n        :param errors: How to handle encoding errors\n        :param kwargs: parameters to pass to `Box()` or `json.loads`\n        :return: Box object from json data\n        """"""\n        bx_args = {}\n        for arg in kwargs.copy():\n            if arg in BOX_PARAMETERS:\n                bx_args[arg] = kwargs.pop(arg)\n\n        data = _from_json(json_string, filename=filename,\n                          encoding=encoding, errors=errors, **kwargs)\n\n        if not isinstance(data, dict):\n            raise BoxError(\'json data not returned as a dictionary, \'\n                           \'but rather a {0}\'.format(type(data).__name__))\n        return cls(data, **bx_args)\n\n    if yaml_support:\n        def to_yaml(self, filename=None, default_flow_style=False,\n                    encoding=""utf-8"", errors=""strict"",\n                    **yaml_kwargs):\n            """"""\n            Transform the Box object into a YAML string.\n\n            :param filename:  If provided will save to file\n            :param default_flow_style: False will recursively dump dicts\n            :param encoding: File encoding\n            :param errors: How to handle encoding errors\n            :param yaml_kwargs: additional arguments to pass to yaml.dump\n            :return: string of YAML or return of `yaml.dump`\n            """"""\n            return _to_yaml(self.to_dict(), filename=filename,\n                            default_flow_style=default_flow_style,\n                            encoding=encoding, errors=errors, **yaml_kwargs)\n\n        @classmethod\n        def from_yaml(cls, yaml_string=None, filename=None,\n                      encoding=""utf-8"", errors=""strict"",\n                      loader=yaml.SafeLoader, **kwargs):\n            """"""\n            Transform a yaml object string into a Box object.\n\n            :param yaml_string: string to pass to `yaml.load`\n            :param filename: filename to open and pass to `yaml.load`\n            :param encoding: File encoding\n            :param errors: How to handle encoding errors\n            :param loader: YAML Loader, defaults to SafeLoader\n            :param kwargs: parameters to pass to `Box()` or `yaml.load`\n            :return: Box object from yaml data\n            """"""\n            bx_args = {}\n            for arg in kwargs.copy():\n                if arg in BOX_PARAMETERS:\n                    bx_args[arg] = kwargs.pop(arg)\n\n            data = _from_yaml(yaml_string=yaml_string, filename=filename,\n                              encoding=encoding, errors=errors,\n                              Loader=loader, **kwargs)\n            if not isinstance(data, dict):\n                raise BoxError(\'yaml data not returned as a dictionary\'\n                               \'but rather a {0}\'.format(type(data).__name__))\n            return cls(data, **bx_args)\n\n\nclass BoxList(list):\n    """"""\n    Drop in replacement of list, that converts added objects to Box or BoxList\n    objects as necessary.\n    """"""\n\n    def __init__(self, iterable=None, box_class=Box, **box_options):\n        self.box_class = box_class\n        self.box_options = box_options\n        self.box_org_ref = self.box_org_ref = id(iterable) if iterable else 0\n        if iterable:\n            for x in iterable:\n                self.append(x)\n        if box_options.get(\'frozen_box\'):\n            def frozen(*args, **kwargs):\n                raise BoxError(\'BoxList is frozen\')\n\n            for method in [\'append\', \'extend\', \'insert\', \'pop\',\n                           \'remove\', \'reverse\', \'sort\']:\n                self.__setattr__(method, frozen)\n\n    def __delitem__(self, key):\n        if self.box_options.get(\'frozen_box\'):\n            raise BoxError(\'BoxList is frozen\')\n        super(BoxList, self).__delitem__(key)\n\n    def __setitem__(self, key, value):\n        if self.box_options.get(\'frozen_box\'):\n            raise BoxError(\'BoxList is frozen\')\n        super(BoxList, self).__setitem__(key, value)\n\n    def append(self, p_object):\n        if isinstance(p_object, dict):\n            try:\n                p_object = self.box_class(p_object, **self.box_options)\n            except AttributeError as err:\n                if \'box_class\' in self.__dict__:\n                    raise err\n        elif isinstance(p_object, list):\n            try:\n                p_object = (self if id(p_object) == self.box_org_ref else\n                            BoxList(p_object))\n            except AttributeError as err:\n                if \'box_org_ref\' in self.__dict__:\n                    raise err\n        super(BoxList, self).append(p_object)\n\n    def extend(self, iterable):\n        for item in iterable:\n            self.append(item)\n\n    def insert(self, index, p_object):\n        if isinstance(p_object, dict):\n            p_object = self.box_class(p_object, **self.box_options)\n        elif isinstance(p_object, list):\n            p_object = (self if id(p_object) == self.box_org_ref else\n                        BoxList(p_object))\n        super(BoxList, self).insert(index, p_object)\n\n    def __repr__(self):\n        return ""<BoxList: {0}>"".format(self.to_list())\n\n    def __str__(self):\n        return str(self.to_list())\n\n    def __copy__(self):\n        return BoxList((x for x in self),\n                       self.box_class,\n                       **self.box_options)\n\n    def __deepcopy__(self, memodict=None):\n        out = self.__class__()\n        memodict = memodict or {}\n        memodict[id(self)] = out\n        for k in self:\n            out.append(copy.deepcopy(k))\n        return out\n\n    def __hash__(self):\n        if self.box_options.get(\'frozen_box\'):\n            hashing = 98765\n            hashing ^= hash(tuple(self))\n            return hashing\n        raise TypeError(""unhashable type: \'BoxList\'"")\n\n    def to_list(self):\n        new_list = []\n        for x in self:\n            if x is self:\n                new_list.append(new_list)\n            elif isinstance(x, Box):\n                new_list.append(x.to_dict())\n            elif isinstance(x, BoxList):\n                new_list.append(x.to_list())\n            else:\n                new_list.append(x)\n        return new_list\n\n    def to_json(self, filename=None,\n                encoding=""utf-8"", errors=""strict"",\n                multiline=False, **json_kwargs):\n        """"""\n        Transform the BoxList object into a JSON string.\n\n        :param filename: If provided will save to file\n        :param encoding: File encoding\n        :param errors: How to handle encoding errors\n        :param multiline: Put each item in list onto it\'s own line\n        :param json_kwargs: additional arguments to pass to json.dump(s)\n        :return: string of JSON or return of `json.dump`\n        """"""\n        if filename and multiline:\n            lines = [_to_json(item, filename=False, encoding=encoding,\n                              errors=errors, **json_kwargs) for item in self]\n            with open(filename, \'w\', encoding=encoding, errors=errors) as f:\n                f.write(""\\n"".join(lines).decode(\'utf-8\') if\n                        sys.version_info < (3, 0) else ""\\n"".join(lines))\n        else:\n            return _to_json(self.to_list(), filename=filename,\n                            encoding=encoding, errors=errors, **json_kwargs)\n\n    @classmethod\n    def from_json(cls, json_string=None, filename=None, encoding=""utf-8"",\n                  errors=""strict"", multiline=False, **kwargs):\n        """"""\n        Transform a json object string into a BoxList object. If the incoming\n        json is a dict, you must use Box.from_json.\n\n        :param json_string: string to pass to `json.loads`\n        :param filename: filename to open and pass to `json.load`\n        :param encoding: File encoding\n        :param errors: How to handle encoding errors\n        :param multiline: One object per line\n        :param kwargs: parameters to pass to `Box()` or `json.loads`\n        :return: BoxList object from json data\n        """"""\n        bx_args = {}\n        for arg in kwargs.copy():\n            if arg in BOX_PARAMETERS:\n                bx_args[arg] = kwargs.pop(arg)\n\n        data = _from_json(json_string, filename=filename, encoding=encoding,\n                          errors=errors, multiline=multiline, **kwargs)\n\n        if not isinstance(data, list):\n            raise BoxError(\'json data not returned as a list, \'\n                           \'but rather a {0}\'.format(type(data).__name__))\n        return cls(data, **bx_args)\n\n    if yaml_support:\n        def to_yaml(self, filename=None, default_flow_style=False,\n                    encoding=""utf-8"", errors=""strict"",\n                    **yaml_kwargs):\n            """"""\n            Transform the BoxList object into a YAML string.\n\n            :param filename:  If provided will save to file\n            :param default_flow_style: False will recursively dump dicts\n            :param encoding: File encoding\n            :param errors: How to handle encoding errors\n            :param yaml_kwargs: additional arguments to pass to yaml.dump\n            :return: string of YAML or return of `yaml.dump`\n            """"""\n            return _to_yaml(self.to_list(), filename=filename,\n                            default_flow_style=default_flow_style,\n                            encoding=encoding, errors=errors, **yaml_kwargs)\n\n        @classmethod\n        def from_yaml(cls, yaml_string=None, filename=None,\n                      encoding=""utf-8"", errors=""strict"",\n                      loader=yaml.SafeLoader,\n                      **kwargs):\n            """"""\n            Transform a yaml object string into a BoxList object.\n\n            :param yaml_string: string to pass to `yaml.load`\n            :param filename: filename to open and pass to `yaml.load`\n            :param encoding: File encoding\n            :param errors: How to handle encoding errors\n            :param loader: YAML Loader, defaults to SafeLoader\n            :param kwargs: parameters to pass to `BoxList()` or `yaml.load`\n            :return: BoxList object from yaml data\n            """"""\n            bx_args = {}\n            for arg in kwargs.copy():\n                if arg in BOX_PARAMETERS:\n                    bx_args[arg] = kwargs.pop(arg)\n\n            data = _from_yaml(yaml_string=yaml_string, filename=filename,\n                              encoding=encoding, errors=errors,\n                              Loader=loader, **kwargs)\n            if not isinstance(data, list):\n                raise BoxError(\'yaml data not returned as a list\'\n                               \'but rather a {0}\'.format(type(data).__name__))\n            return cls(data, **bx_args)\n\n    def box_it_up(self):\n        for v in self:\n            if hasattr(v, \'box_it_up\') and v is not self:\n                v.box_it_up()\n\n\nclass ConfigBox(Box):\n    """"""\n    Modified box object to add object transforms.\n\n    Allows for build in transforms like:\n\n    cns = ConfigBox(my_bool=\'yes\', my_int=\'5\', my_list=\'5,4,3,3,2\')\n\n    cns.bool(\'my_bool\') # True\n    cns.int(\'my_int\') # 5\n    cns.list(\'my_list\', mod=lambda x: int(x)) # [5, 4, 3, 3, 2]\n    """"""\n\n    _protected_keys = dir({}) + [\'to_dict\', \'bool\', \'int\', \'float\',\n                                 \'list\', \'getboolean\', \'to_json\', \'to_yaml\',\n                                 \'getfloat\', \'getint\',\n                                 \'from_json\', \'from_yaml\']\n\n    def __getattr__(self, item):\n        """"""Config file keys are stored in lower case, be a little more\n        loosey goosey""""""\n        try:\n            return super(ConfigBox, self).__getattr__(item)\n        except AttributeError:\n            return super(ConfigBox, self).__getattr__(item.lower())\n\n    def __dir__(self):\n        return super(ConfigBox, self).__dir__() + [\'bool\', \'int\', \'float\',\n                                                   \'list\', \'getboolean\',\n                                                   \'getfloat\', \'getint\']\n\n    def bool(self, item, default=None):\n        """""" Return value of key as a boolean\n\n        :param item: key of value to transform\n        :param default: value to return if item does not exist\n        :return: approximated bool of value\n        """"""\n        try:\n            item = self.__getattr__(item)\n        except AttributeError as err:\n            if default is not None:\n                return default\n            raise err\n\n        if isinstance(item, (bool, int)):\n            return bool(item)\n\n        if (isinstance(item, str) and\n                item.lower() in (\'n\', \'no\', \'false\', \'f\', \'0\')):\n            return False\n\n        return True if item else False\n\n    def int(self, item, default=None):\n        """""" Return value of key as an int\n\n        :param item: key of value to transform\n        :param default: value to return if item does not exist\n        :return: int of value\n        """"""\n        try:\n            item = self.__getattr__(item)\n        except AttributeError as err:\n            if default is not None:\n                return default\n            raise err\n        return int(item)\n\n    def float(self, item, default=None):\n        """""" Return value of key as a float\n\n        :param item: key of value to transform\n        :param default: value to return if item does not exist\n        :return: float of value\n        """"""\n        try:\n            item = self.__getattr__(item)\n        except AttributeError as err:\n            if default is not None:\n                return default\n            raise err\n        return float(item)\n\n    def list(self, item, default=None, spliter="","", strip=True, mod=None):\n        """""" Return value of key as a list\n\n        :param item: key of value to transform\n        :param mod: function to map against list\n        :param default: value to return if item does not exist\n        :param spliter: character to split str on\n        :param strip: clean the list with the `strip`\n        :return: list of items\n        """"""\n        try:\n            item = self.__getattr__(item)\n        except AttributeError as err:\n            if default is not None:\n                return default\n            raise err\n        if strip:\n            item = item.lstrip(\'[\').rstrip(\']\')\n        out = [x.strip() if strip else x for x in item.split(spliter)]\n        if mod:\n            return list(map(mod, out))\n        return out\n\n    # loose configparser compatibility\n\n    def getboolean(self, item, default=None):\n        return self.bool(item, default)\n\n    def getint(self, item, default=None):\n        return self.int(item, default)\n\n    def getfloat(self, item, default=None):\n        return self.float(item, default)\n\n    def __repr__(self):\n        return \'<ConfigBox: {0}>\'.format(str(self.to_dict()))\n\n\nclass SBox(Box):\n    """"""\n    ShorthandBox (SBox) allows for\n    property access of `dict` `json` and `yaml`\n    """"""\n    _protected_keys = dir({}) + [\'to_dict\', \'tree_view\', \'to_json\', \'to_yaml\',\n                                 \'json\', \'yaml\', \'from_yaml\', \'from_json\',\n                                 \'dict\']\n\n    @property\n    def dict(self):\n        return self.to_dict()\n\n    @property\n    def json(self):\n        return self.to_json()\n\n    if yaml_support:\n        @property\n        def yaml(self):\n            return self.to_yaml()\n\n    def __repr__(self):\n        return \'<ShorthandBox: {0}>\'.format(str(self.to_dict()))\n'"
lcnn/config.py,0,b'import numpy as np\n\nfrom lcnn.box import Box\n\n# C is a dict storing all the configuration\nC = Box()\n\n# shortcut for C.model\nM = Box()\n'
lcnn/datasets.py,11,"b'import glob\nimport json\nimport math\nimport os\nimport random\n\nimport numpy as np\nimport numpy.linalg as LA\nimport torch\nfrom skimage import io\nfrom torch.utils.data import Dataset\nfrom torch.utils.data.dataloader import default_collate\n\nfrom lcnn.config import M\n\n\nclass WireframeDataset(Dataset):\n    def __init__(self, rootdir, split):\n        self.rootdir = rootdir\n        filelist = glob.glob(f""{rootdir}/{split}/*_label.npz"")\n        filelist.sort()\n\n        print(f""n{split}:"", len(filelist))\n        self.split = split\n        self.filelist = filelist\n\n    def __len__(self):\n        return len(self.filelist)\n\n    def __getitem__(self, idx):\n        iname = self.filelist[idx][:-10].replace(""_a0"", """").replace(""_a1"", """") + "".png""\n        image = io.imread(iname).astype(float)[:, :, :3]\n        if ""a1"" in self.filelist[idx]:\n            image = image[:, ::-1, :]\n        image = (image - M.image.mean) / M.image.stddev\n        image = np.rollaxis(image, 2).copy()\n\n        # npz[""jmap""]: [J, H, W]    Junction heat map\n        # npz[""joff""]: [J, 2, H, W] Junction offset within each pixel\n        # npz[""lmap""]: [H, W]       Line heat map with anti-aliasing\n        # npz[""junc""]: [Na, 3]      Junction coordinates\n        # npz[""Lpos""]: [M, 2]       Positive lines represented with junction indices\n        # npz[""Lneg""]: [M, 2]       Negative lines represented with junction indices\n        # npz[""lpos""]: [Np, 2, 3]   Positive lines represented with junction coordinates\n        # npz[""lneg""]: [Nn, 2, 3]   Negative lines represented with junction coordinates\n        #\n        # For junc, lpos, and lneg that stores the junction coordinates, the last\n        # dimension is (y, x, t), where t represents the type of that junction.\n        with np.load(self.filelist[idx]) as npz:\n            target = {\n                name: torch.from_numpy(npz[name]).float()\n                for name in [""jmap"", ""joff"", ""lmap""]\n            }\n            lpos = np.random.permutation(npz[""lpos""])[: M.n_stc_posl]\n            lneg = np.random.permutation(npz[""lneg""])[: M.n_stc_negl]\n            npos, nneg = len(lpos), len(lneg)\n            lpre = np.concatenate([lpos, lneg], 0)\n            for i in range(len(lpre)):\n                if random.random() > 0.5:\n                    lpre[i] = lpre[i, ::-1]\n            ldir = lpre[:, 0, :2] - lpre[:, 1, :2]\n            ldir /= np.clip(LA.norm(ldir, axis=1, keepdims=True), 1e-6, None)\n            feat = [\n                lpre[:, :, :2].reshape(-1, 4) / 128 * M.use_cood,\n                ldir * M.use_slop,\n                lpre[:, :, 2],\n            ]\n            feat = np.concatenate(feat, 1)\n            meta = {\n                ""junc"": torch.from_numpy(npz[""junc""][:, :2]),\n                ""jtyp"": torch.from_numpy(npz[""junc""][:, 2]).byte(),\n                ""Lpos"": self.adjacency_matrix(len(npz[""junc""]), npz[""Lpos""]),\n                ""Lneg"": self.adjacency_matrix(len(npz[""junc""]), npz[""Lneg""]),\n                ""lpre"": torch.from_numpy(lpre[:, :, :2]),\n                ""lpre_label"": torch.cat([torch.ones(npos), torch.zeros(nneg)]),\n                ""lpre_feat"": torch.from_numpy(feat),\n            }\n\n        return torch.from_numpy(image).float(), meta, target\n\n    def adjacency_matrix(self, n, link):\n        mat = torch.zeros(n + 1, n + 1, dtype=torch.uint8)\n        link = torch.from_numpy(link)\n        if len(link) > 0:\n            mat[link[:, 0], link[:, 1]] = 1\n            mat[link[:, 1], link[:, 0]] = 1\n        return mat\n\n\ndef collate(batch):\n    return (\n        default_collate([b[0] for b in batch]),\n        [b[1] for b in batch],\n        default_collate([b[2] for b in batch]),\n    )\n'"
lcnn/metric.py,0,"b'import numpy as np\nimport numpy.linalg as LA\nimport matplotlib.pyplot as plt\n\nfrom lcnn.utils import argsort2d\n\nDX = [0, 0, 1, -1, 1, 1, -1, -1]\nDY = [1, -1, 0, 0, 1, -1, 1, -1]\n\n\ndef ap(tp, fp):\n    recall = tp\n    precision = tp / np.maximum(tp + fp, 1e-9)\n\n    recall = np.concatenate(([0.0], recall, [1.0]))\n    precision = np.concatenate(([0.0], precision, [0.0]))\n\n    for i in range(precision.size - 1, 0, -1):\n        precision[i - 1] = max(precision[i - 1], precision[i])\n    i = np.where(recall[1:] != recall[:-1])[0]\n    return np.sum((recall[i + 1] - recall[i]) * precision[i + 1])\n\n\ndef APJ(vert_pred, vert_gt, max_distance, im_ids):\n    if len(vert_pred) == 0:\n        return 0\n\n    vert_pred = np.array(vert_pred)\n    vert_gt = np.array(vert_gt)\n\n    confidence = vert_pred[:, -1]\n    idx = np.argsort(-confidence)\n    vert_pred = vert_pred[idx, :]\n    im_ids = im_ids[idx]\n    n_gt = sum(len(gt) for gt in vert_gt)\n\n    nd = len(im_ids)\n    tp, fp = np.zeros(nd, dtype=np.float), np.zeros(nd, dtype=np.float)\n    hit = [[False for _ in j] for j in vert_gt]\n\n    for i in range(nd):\n        gt_juns = vert_gt[im_ids[i]]\n        pred_juns = vert_pred[i][:-1]\n        if len(gt_juns) == 0:\n            continue\n        dists = np.linalg.norm((pred_juns[None, :] - gt_juns), axis=1)\n        choice = np.argmin(dists)\n        dist = np.min(dists)\n        if dist < max_distance and not hit[im_ids[i]][choice]:\n            tp[i] = 1\n            hit[im_ids[i]][choice] = True\n        else:\n            fp[i] = 1\n\n    tp = np.cumsum(tp) / n_gt\n    fp = np.cumsum(fp) / n_gt\n    return ap(tp, fp)\n\n\ndef nms_j(heatmap, delta=1):\n    heatmap = heatmap.copy()\n    disable = np.zeros_like(heatmap, dtype=np.bool)\n    for x, y in argsort2d(heatmap):\n        for dx, dy in zip(DX, DY):\n            xp, yp = x + dx, y + dy\n            if not (0 <= xp < heatmap.shape[0] and 0 <= yp < heatmap.shape[1]):\n                continue\n            if heatmap[x, y] >= heatmap[xp, yp]:\n                disable[xp, yp] = True\n    heatmap[disable] *= 0.6\n    return heatmap\n\n\ndef mAPJ(pred, truth, distances, im_ids):\n    return sum(APJ(pred, truth, d, im_ids) for d in distances) / len(distances) * 100\n\n\ndef post_jheatmap(heatmap, offset=None, delta=1):\n    heatmap = nms_j(heatmap, delta=delta)\n    # only select the best 1000 junctions for efficiency\n    v0 = argsort2d(-heatmap)[:1000]\n    confidence = -np.sort(-heatmap.ravel())[:1000]\n    keep_id = np.where(confidence >= 1e-2)[0]\n    if len(keep_id) == 0:\n        return np.zeros((0, 3))\n\n    confidence = confidence[keep_id]\n    if offset is not None:\n        v0 = np.array([v + offset[:, v[0], v[1]] for v in v0])\n    v0 = v0[keep_id] + 0.5\n    v0 = np.hstack((v0, confidence[:, np.newaxis]))\n    return v0\n\n\ndef vectorized_wireframe_2d_metric(\n    vert_pred, dpth_pred, edge_pred, vert_gt, dpth_gt, edge_gt, threshold\n):\n    # staging 1: matching\n    nd = len(vert_pred)\n    sorted_confidence = np.argsort(-vert_pred[:, -1])\n    vert_pred = vert_pred[sorted_confidence, :-1]\n    dpth_pred = dpth_pred[sorted_confidence]\n    d = np.sqrt(\n        np.sum(vert_pred ** 2, 1)[:, None]\n        + np.sum(vert_gt ** 2, 1)[None, :]\n        - 2 * vert_pred @ vert_gt.T\n    )\n    choice = np.argmin(d, 1)\n    dist = np.min(d, 1)\n\n    # staging 2: compute depth metric: SIL/L2\n    loss_L1 = loss_L2 = 0\n    hit = np.zeros_like(dpth_gt, np.bool)\n    SIL = np.zeros(dpth_pred)\n    for i in range(nd):\n        if dist[i] < threshold and not hit[choice[i]]:\n            hit[choice[i]] = True\n            loss_L1 += abs(dpth_gt[choice[i]] - dpth_pred[i])\n            loss_L2 += (dpth_gt[choice[i]] - dpth_pred[i]) ** 2\n            a = np.maximum(-dpth_pred[i], 1e-10)\n            b = -dpth_gt[choice[i]]\n            SIL[i] = np.log(a) - np.log(b)\n        else:\n            choice[i] = -1\n\n    n = max(np.sum(hit), 1)\n    loss_L1 /= n\n    loss_L2 /= n\n    loss_SIL = np.sum(SIL ** 2) / n - np.sum(SIL) ** 2 / (n * n)\n\n    # staging 3: compute mAP for edge matching\n    edgeset = set([frozenset(e) for e in edge_gt])\n    tp = np.zeros(len(edge_pred), dtype=np.float)\n    fp = np.zeros(len(edge_pred), dtype=np.float)\n    for i, (v0, v1, score) in enumerate(sorted(edge_pred, key=-edge_pred[2])):\n        length = LA.norm(vert_gt[v0] - vert_gt[v1], axis=1)\n        if frozenset([choice[v0], choice[v1]]) in edgeset:\n            tp[i] = length\n        else:\n            fp[i] = length\n    total_length = LA.norm(\n        vert_gt[edge_gt[:, 0]] - vert_gt[edge_gt[:, 1]], axis=1\n    ).sum()\n    return ap(tp / total_length, fp / total_length), (loss_SIL, loss_L1, loss_L2)\n\n\ndef vectorized_wireframe_3d_metric(\n    vert_pred, dpth_pred, edge_pred, vert_gt, dpth_gt, edge_gt, threshold\n):\n    # staging 1: matching\n    nd = len(vert_pred)\n    sorted_confidence = np.argsort(-vert_pred[:, -1])\n    vert_pred = np.hstack([vert_pred[:, :-1], dpth_pred[:, None]])[sorted_confidence]\n    vert_gt = np.hstack([vert_gt[:, :-1], dpth_gt[:, None]])\n    d = np.sqrt(\n        np.sum(vert_pred ** 2, 1)[:, None]\n        + np.sum(vert_gt ** 2, 1)[None, :]\n        - 2 * vert_pred @ vert_gt.T\n    )\n    choice = np.argmin(d, 1)\n    dist = np.min(d, 1)\n    hit = np.zeros_like(dpth_gt, np.bool)\n    for i in range(nd):\n        if dist[i] < threshold and not hit[choice[i]]:\n            hit[choice[i]] = True\n        else:\n            choice[i] = -1\n\n    # staging 2: compute mAP for edge matching\n    edgeset = set([frozenset(e) for e in edge_gt])\n    tp = np.zeros(len(edge_pred), dtype=np.float)\n    fp = np.zeros(len(edge_pred), dtype=np.float)\n    for i, (v0, v1, score) in enumerate(sorted(edge_pred, key=-edge_pred[2])):\n        length = LA.norm(vert_gt[v0] - vert_gt[v1], axis=1)\n        if frozenset([choice[v0], choice[v1]]) in edgeset:\n            tp[i] = length\n        else:\n            fp[i] = length\n    total_length = LA.norm(\n        vert_gt[edge_gt[:, 0]] - vert_gt[edge_gt[:, 1]], axis=1\n    ).sum()\n\n    return ap(tp / total_length, fp / total_length)\n\n\ndef msTPFP(line_pred, line_gt, threshold):\n    diff = ((line_pred[:, None, :, None] - line_gt[:, None]) ** 2).sum(-1)\n    diff = np.minimum(\n        diff[:, :, 0, 0] + diff[:, :, 1, 1], diff[:, :, 0, 1] + diff[:, :, 1, 0]\n    )\n    choice = np.argmin(diff, 1)\n    dist = np.min(diff, 1)\n    hit = np.zeros(len(line_gt), np.bool)\n    tp = np.zeros(len(line_pred), np.float)\n    fp = np.zeros(len(line_pred), np.float)\n    for i in range(len(line_pred)):\n        if dist[i] < threshold and not hit[choice[i]]:\n            hit[choice[i]] = True\n            tp[i] = 1\n        else:\n            fp[i] = 1\n    return tp, fp\n\n\ndef msAP(line_pred, line_gt, threshold):\n    tp, fp = msTPFP(line_pred, line_gt, threshold)\n    tp = np.cumsum(tp) / len(line_gt)\n    fp = np.cumsum(fp) / len(line_gt)\n    return ap(tp, fp)\n'"
lcnn/postprocess.py,0,"b'import numpy as np\n\n\ndef pline(x1, y1, x2, y2, x, y):\n    px = x2 - x1\n    py = y2 - y1\n    dd = px * px + py * py\n    u = ((x - x1) * px + (y - y1) * py) / max(1e-9, float(dd))\n    dx = x1 + u * px - x\n    dy = y1 + u * py - y\n    return dx * dx + dy * dy\n\n\ndef psegment(x1, y1, x2, y2, x, y):\n    px = x2 - x1\n    py = y2 - y1\n    dd = px * px + py * py\n    u = max(min(((x - x1) * px + (y - y1) * py) / float(dd), 1), 0)\n    dx = x1 + u * px - x\n    dy = y1 + u * py - y\n    return dx * dx + dy * dy\n\n\ndef plambda(x1, y1, x2, y2, x, y):\n    px = x2 - x1\n    py = y2 - y1\n    dd = px * px + py * py\n    return ((x - x1) * px + (y - y1) * py) / max(1e-9, float(dd))\n\n\ndef postprocess(lines, scores, threshold=0.01, tol=1e9, do_clip=False):\n    nlines, nscores = [], []\n    for (p, q), score in zip(lines, scores):\n        start, end = 0, 1\n        for a, b in nlines:\n            if (\n                min(\n                    max(pline(*p, *q, *a), pline(*p, *q, *b)),\n                    max(pline(*a, *b, *p), pline(*a, *b, *q)),\n                )\n                > threshold ** 2\n            ):\n                continue\n            lambda_a = plambda(*p, *q, *a)\n            lambda_b = plambda(*p, *q, *b)\n            if lambda_a > lambda_b:\n                lambda_a, lambda_b = lambda_b, lambda_a\n            lambda_a -= tol\n            lambda_b += tol\n\n            # case 1: skip (if not do_clip)\n            if start < lambda_a and lambda_b < end:\n                continue\n\n            # not intersect\n            if lambda_b < start or lambda_a > end:\n                continue\n\n            # cover\n            if lambda_a <= start and end <= lambda_b:\n                start = 10\n                break\n\n            # case 2 & 3:\n            if lambda_a <= start and start <= lambda_b:\n                start = lambda_b\n            if lambda_a <= end and end <= lambda_b:\n                end = lambda_a\n\n            if start >= end:\n                break\n\n        if start >= end:\n            continue\n        nlines.append(np.array([p + (q - p) * start, p + (q - p) * end]))\n        nscores.append(score)\n    return np.array(nlines), np.array(nscores)\n'"
lcnn/trainer.py,3,"b'import atexit\nimport os\nimport os.path as osp\nimport shutil\nimport signal\nimport subprocess\nimport threading\nimport time\nfrom timeit import default_timer as timer\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom skimage import io\nfrom tensorboardX import SummaryWriter\n\nfrom lcnn.config import C, M\nfrom lcnn.utils import recursive_to\n\n\nclass Trainer(object):\n    def __init__(self, device, model, optimizer, train_loader, val_loader, out):\n        self.device = device\n\n        self.model = model\n        self.optim = optimizer\n\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.batch_size = C.model.batch_size\n\n        self.validation_interval = C.io.validation_interval\n\n        self.out = out\n        if not osp.exists(self.out):\n            os.makedirs(self.out)\n\n        self.run_tensorboard()\n        time.sleep(1)\n\n        self.epoch = 0\n        self.iteration = 0\n        self.max_epoch = C.optim.max_epoch\n        self.lr_decay_epoch = C.optim.lr_decay_epoch\n        self.num_stacks = C.model.num_stacks\n        self.mean_loss = self.best_mean_loss = 1e1000\n\n        self.loss_labels = None\n        self.avg_metrics = None\n        self.metrics = np.zeros(0)\n\n    def run_tensorboard(self):\n        board_out = osp.join(self.out, ""tensorboard"")\n        if not osp.exists(board_out):\n            os.makedirs(board_out)\n        self.writer = SummaryWriter(board_out)\n        os.environ[""CUDA_VISIBLE_DEVICES""] = """"\n        p = subprocess.Popen(\n            [""tensorboard"", f""--logdir={board_out}"", f""--port={C.io.tensorboard_port}""]\n        )\n\n        def killme():\n            os.kill(p.pid, signal.SIGTERM)\n\n        atexit.register(killme)\n\n    def _loss(self, result):\n        losses = result[""losses""]\n        # Don\'t move loss label to other place.\n        # If I want to change the loss, I just need to change this function.\n        if self.loss_labels is None:\n            self.loss_labels = [""sum""] + list(losses[0].keys())\n            self.metrics = np.zeros([self.num_stacks, len(self.loss_labels)])\n            print()\n            print(\n                ""| "".join(\n                    [""progress ""]\n                    + list(map(""{:7}"".format, self.loss_labels))\n                    + [""speed""]\n                )\n            )\n            with open(f""{self.out}/loss.csv"", ""a"") as fout:\n                print("","".join([""progress""] + self.loss_labels), file=fout)\n\n        total_loss = 0\n        for i in range(self.num_stacks):\n            for j, name in enumerate(self.loss_labels):\n                if name == ""sum"":\n                    continue\n                if name not in losses[i]:\n                    assert i != 0\n                    continue\n                loss = losses[i][name].mean()\n                self.metrics[i, 0] += loss.item()\n                self.metrics[i, j] += loss.item()\n                total_loss += loss\n        return total_loss\n\n    def validate(self):\n        tprint(""Running validation..."", "" "" * 75)\n        training = self.model.training\n        self.model.eval()\n\n        viz = osp.join(self.out, ""viz"", f""{self.iteration * M.batch_size_eval:09d}"")\n        npz = osp.join(self.out, ""npz"", f""{self.iteration * M.batch_size_eval:09d}"")\n        osp.exists(viz) or os.makedirs(viz)\n        osp.exists(npz) or os.makedirs(npz)\n\n        total_loss = 0\n        self.metrics[...] = 0\n        with torch.no_grad():\n            for batch_idx, (image, meta, target) in enumerate(self.val_loader):\n                input_dict = {\n                    ""image"": recursive_to(image, self.device),\n                    ""meta"": recursive_to(meta, self.device),\n                    ""target"": recursive_to(target, self.device),\n                    ""mode"": ""validation"",\n                }\n                result = self.model(input_dict)\n\n                total_loss += self._loss(result)\n\n                H = result[""preds""]\n                for i in range(H[""jmap""].shape[0]):\n                    index = batch_idx * M.batch_size_eval + i\n                    np.savez(\n                        f""{npz}/{index:06}.npz"",\n                        **{k: v[i].cpu().numpy() for k, v in H.items()},\n                    )\n                    if index >= 20:\n                        continue\n                    self._plot_samples(i, index, H, meta, target, f""{viz}/{index:06}"")\n\n        self._write_metrics(len(self.val_loader), total_loss, ""validation"", True)\n        self.mean_loss = total_loss / len(self.val_loader)\n\n        torch.save(\n            {\n                ""iteration"": self.iteration,\n                ""arch"": self.model.__class__.__name__,\n                ""optim_state_dict"": self.optim.state_dict(),\n                ""model_state_dict"": self.model.state_dict(),\n                ""best_mean_loss"": self.best_mean_loss,\n            },\n            osp.join(self.out, ""checkpoint_latest.pth""),\n        )\n        shutil.copy(\n            osp.join(self.out, ""checkpoint_latest.pth""),\n            osp.join(npz, ""checkpoint.pth""),\n        )\n        if self.mean_loss < self.best_mean_loss:\n            self.best_mean_loss = self.mean_loss\n            shutil.copy(\n                osp.join(self.out, ""checkpoint_latest.pth""),\n                osp.join(self.out, ""checkpoint_best.pth""),\n            )\n\n        if training:\n            self.model.train()\n\n    def train_epoch(self):\n        self.model.train()\n\n        time = timer()\n        for batch_idx, (image, meta, target) in enumerate(self.train_loader):\n\n            self.optim.zero_grad()\n            self.metrics[...] = 0\n\n            input_dict = {\n                ""image"": recursive_to(image, self.device),\n                ""meta"": recursive_to(meta, self.device),\n                ""target"": recursive_to(target, self.device),\n                ""mode"": ""training"",\n            }\n            result = self.model(input_dict)\n\n            loss = self._loss(result)\n            if np.isnan(loss.item()):\n                raise ValueError(""loss is nan while training"")\n            loss.backward()\n            self.optim.step()\n\n            if self.avg_metrics is None:\n                self.avg_metrics = self.metrics\n            else:\n                self.avg_metrics = self.avg_metrics * 0.9 + self.metrics * 0.1\n            self.iteration += 1\n            self._write_metrics(1, loss.item(), ""training"", do_print=False)\n\n            if self.iteration % 4 == 0:\n                tprint(\n                    f""{self.epoch:03}/{self.iteration * self.batch_size // 1000:04}k| ""\n                    + ""| "".join(map(""{:.5f}"".format, self.avg_metrics[0]))\n                    + f""| {4 * self.batch_size / (timer() - time):04.1f} ""\n                )\n                time = timer()\n            num_images = self.batch_size * self.iteration\n            if num_images % self.validation_interval == 0 or num_images == 600:\n                self.validate()\n                time = timer()\n\n    def _write_metrics(self, size, total_loss, prefix, do_print=False):\n        for i, metrics in enumerate(self.metrics):\n            for label, metric in zip(self.loss_labels, metrics):\n                self.writer.add_scalar(\n                    f""{prefix}/{i}/{label}"", metric / size, self.iteration\n                )\n            if i == 0 and do_print:\n                csv_str = (\n                    f""{self.epoch:03}/{self.iteration * self.batch_size:07},""\n                    + "","".join(map(""{:.11f}"".format, metrics / size))\n                )\n                prt_str = (\n                    f""{self.epoch:03}/{self.iteration * self.batch_size // 1000:04}k| ""\n                    + ""| "".join(map(""{:.5f}"".format, metrics / size))\n                )\n                with open(f""{self.out}/loss.csv"", ""a"") as fout:\n                    print(csv_str, file=fout)\n                pprint(prt_str, "" "" * 7)\n        self.writer.add_scalar(\n            f""{prefix}/total_loss"", total_loss / size, self.iteration\n        )\n        return total_loss\n\n    def _plot_samples(self, i, index, result, meta, target, prefix):\n        fn = self.val_loader.dataset.filelist[index][:-10].replace(""_a0"", """") + "".png""\n        img = io.imread(fn)\n        imshow(img), plt.savefig(f""{prefix}_img.jpg""), plt.close()\n\n        mask_result = result[""jmap""][i].cpu().numpy()\n        mask_target = target[""jmap""][i].cpu().numpy()\n        for ch, (ia, ib) in enumerate(zip(mask_target, mask_result)):\n            imshow(ia), plt.savefig(f""{prefix}_mask_{ch}a.jpg""), plt.close()\n            imshow(ib), plt.savefig(f""{prefix}_mask_{ch}b.jpg""), plt.close()\n\n        line_result = result[""lmap""][i].cpu().numpy()\n        line_target = target[""lmap""][i].cpu().numpy()\n        imshow(line_target), plt.savefig(f""{prefix}_line_a.jpg""), plt.close()\n        imshow(line_result), plt.savefig(f""{prefix}_line_b.jpg""), plt.close()\n\n        def draw_vecl(lines, sline, juncs, junts, fn):\n            imshow(img)\n            if len(lines) > 0 and not (lines[0] == 0).all():\n                for i, ((a, b), s) in enumerate(zip(lines, sline)):\n                    if i > 0 and (lines[i] == lines[0]).all():\n                        break\n                    plt.plot([a[1], b[1]], [a[0], b[0]], c=c(s), linewidth=4)\n            if not (juncs[0] == 0).all():\n                for i, j in enumerate(juncs):\n                    if i > 0 and (i == juncs[0]).all():\n                        break\n                    plt.scatter(j[1], j[0], c=""red"", s=64, zorder=100)\n            if junts is not None and len(junts) > 0 and not (junts[0] == 0).all():\n                for i, j in enumerate(junts):\n                    if i > 0 and (i == junts[0]).all():\n                        break\n                    plt.scatter(j[1], j[0], c=""blue"", s=64, zorder=100)\n            plt.savefig(fn), plt.close()\n\n        junc = meta[i][""junc""].cpu().numpy() * 4\n        jtyp = meta[i][""jtyp""].cpu().numpy()\n        juncs = junc[jtyp == 0]\n        junts = junc[jtyp == 1]\n        rjuncs = result[""juncs""][i].cpu().numpy() * 4\n        rjunts = None\n        if ""junts"" in result:\n            rjunts = result[""junts""][i].cpu().numpy() * 4\n\n        lpre = meta[i][""lpre""].cpu().numpy() * 4\n        vecl_target = meta[i][""lpre_label""].cpu().numpy()\n        vecl_result = result[""lines""][i].cpu().numpy() * 4\n        score = result[""score""][i].cpu().numpy()\n        lpre = lpre[vecl_target == 1]\n\n        draw_vecl(lpre, np.ones(lpre.shape[0]), juncs, junts, f""{prefix}_vecl_a.jpg"")\n        draw_vecl(vecl_result, score, rjuncs, rjunts, f""{prefix}_vecl_b.jpg"")\n\n    def train(self):\n        plt.rcParams[""figure.figsize""] = (24, 24)\n        # if self.iteration == 0:\n        #     self.validate()\n        epoch_size = len(self.train_loader)\n        start_epoch = self.iteration // epoch_size\n        for self.epoch in range(start_epoch, self.max_epoch):\n            if self.epoch == self.lr_decay_epoch:\n                self.optim.param_groups[0][""lr""] /= 10\n            self.train_epoch()\n\n\ncmap = plt.get_cmap(""jet"")\nnorm = mpl.colors.Normalize(vmin=0.4, vmax=1.0)\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n\n\ndef c(x):\n    return sm.to_rgba(x)\n\n\ndef imshow(im):\n    plt.close()\n    plt.tight_layout()\n    plt.imshow(im)\n    plt.colorbar(sm, fraction=0.046)\n    plt.xlim([0, im.shape[0]])\n    plt.ylim([im.shape[0], 0])\n\n\ndef tprint(*args):\n    """"""Temporarily prints things on the screen""""""\n    print(""\\r"", end="""")\n    print(*args, end="""")\n\n\ndef pprint(*args):\n    """"""Permanently prints things on the screen""""""\n    print(""\\r"", end="""")\n    print(*args)\n\n\ndef _launch_tensorboard(board_out, port, out):\n    os.environ[""CUDA_VISIBLE_DEVICES""] = """"\n    p = subprocess.Popen([""tensorboard"", f""--logdir={board_out}"", f""--port={port}""])\n\n    def kill():\n        os.kill(p.pid, signal.SIGTERM)\n\n    atexit.register(kill)\n'"
lcnn/utils.py,2,"b'import math\nimport os.path as osp\nimport multiprocessing\nfrom timeit import default_timer as timer\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\n\n\nclass benchmark(object):\n    def __init__(self, msg, enable=True, fmt=""%0.3g""):\n        self.msg = msg\n        self.fmt = fmt\n        self.enable = enable\n\n    def __enter__(self):\n        if self.enable:\n            self.start = timer()\n        return self\n\n    def __exit__(self, *args):\n        if self.enable:\n            t = timer() - self.start\n            print((""%s : "" + self.fmt + "" seconds"") % (self.msg, t))\n            self.time = t\n\n\ndef quiver(x, y, ax):\n    ax.set_xlim(0, x.shape[1])\n    ax.set_ylim(x.shape[0], 0)\n    ax.quiver(\n        x,\n        y,\n        units=""xy"",\n        angles=""xy"",\n        scale_units=""xy"",\n        scale=1,\n        minlength=0.01,\n        width=0.1,\n        color=""b"",\n    )\n\n\ndef recursive_to(input, device):\n    if isinstance(input, torch.Tensor):\n        return input.to(device)\n    if isinstance(input, dict):\n        for name in input:\n            if isinstance(input[name], torch.Tensor):\n                input[name] = input[name].to(device)\n        return input\n    if isinstance(input, list):\n        for i, item in enumerate(input):\n            input[i] = recursive_to(item, device)\n        return input\n    assert False\n\n\ndef np_softmax(x, axis=0):\n    """"""Compute softmax values for each sets of scores in x.""""""\n    e_x = np.exp(x - np.max(x))\n    return e_x / e_x.sum(axis=axis, keepdims=True)\n\n\ndef argsort2d(arr):\n    return np.dstack(np.unravel_index(np.argsort(arr.ravel()), arr.shape))[0]\n\n\ndef __parallel_handle(f, q_in, q_out):\n    while True:\n        i, x = q_in.get()\n        if i is None:\n            break\n        q_out.put((i, f(x)))\n\n\ndef parmap(f, X, nprocs=multiprocessing.cpu_count(), progress_bar=lambda x: x):\n    if nprocs == 0:\n        nprocs = multiprocessing.cpu_count()\n    q_in = multiprocessing.Queue(1)\n    q_out = multiprocessing.Queue()\n\n    proc = [\n        multiprocessing.Process(target=__parallel_handle, args=(f, q_in, q_out))\n        for _ in range(nprocs)\n    ]\n    for p in proc:\n        p.daemon = True\n        p.start()\n\n    try:\n        sent = [q_in.put((i, x)) for i, x in enumerate(X)]\n        [q_in.put((None, None)) for _ in range(nprocs)]\n        res = [q_out.get() for _ in progress_bar(range(len(sent)))]\n        [p.join() for p in proc]\n    except KeyboardInterrupt:\n        q_in.close()\n        q_out.close()\n        raise\n    return [x for i, x in sorted(res)]\n'"
misc/draw-wireframe.py,0,"b'#!/usr/bin/env python3\nimport os\nimport glob\nimport os.path as osp\n\nimport cv2\nimport numpy as np\nimport scipy.io\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom lcnn.utils import parmap\n\nGT = ""data/wireframe/valid/*.npz""\nWF = ""/data/lcnn/wirebase/result/wireframe/wireframe_1_rerun-baseline_0.5_0.5/2/*.mat""\nAFM = ""/data/lcnn/wirebase/result/wireframe/afm/*.npz""\nIMGS = ""/data/lcnn/wirebase/Wireframe/v1.1/test/*.jpg""\n\n\ndef imshow(im):\n    sizes = im.shape\n    height = float(sizes[0])\n    width = float(sizes[1])\n\n    fig = plt.figure()\n    fig.set_size_inches(width / height, 1, forward=False)\n    ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])\n    ax.set_axis_off()\n    fig.add_axes(ax)\n    plt.xlim([-0.5, sizes[1] - 0.5])\n    plt.ylim([sizes[0] - 0.5, -0.5])\n    plt.imshow(im)\n\n\ndef main():\n    gts = sorted(glob.glob(GT))\n    afm = sorted(glob.glob(AFM))\n    wf = sorted(glob.glob(WF))\n    img = sorted(glob.glob(IMGS))\n\n    prefix = ""/data/lcnn/wirebase/myplot/""\n    os.makedirs(osp.join(prefix, ""GT""), exist_ok=True)\n    os.makedirs(osp.join(prefix, ""LSD""), exist_ok=True)\n    os.makedirs(osp.join(prefix, ""AFM""), exist_ok=True)\n    os.makedirs(osp.join(prefix, ""WF""), exist_ok=True)\n    os.makedirs(osp.join(prefix, ""LL""), exist_ok=True)\n\n    def draw(args):\n        i, (wf_name, gt_name, afm_name, img_name) = args\n        img = cv2.imread(img_name, 0)\n        lsd = cv2.createLineSegmentDetector(cv2.LSD_REFINE_ADV)\n        lsd_line, _, _, lsd_score = lsd.detect(img)\n        lsd_line = lsd_line.reshape(-1, 2, 2)\n        lsd_score = lsd_score.flatten()\n        img = cv2.imread(img_name)[:, :, ::-1]\n\n        with np.load(gt_name) as fgt:\n            gt_line = fgt[""lpos""][:, :, :2]\n            gt_line[:, :, 0] *= img.shape[0] / 128\n            gt_line[:, :, 1] *= img.shape[1] / 128\n\n        with np.load(afm_name) as fafm:\n            afm_line = fafm[""lines""].reshape(-1, 2, 2)[:, :, ::-1]\n\n        wf_line = scipy.io.loadmat(wf_name)[""lines""].reshape(-1, 2, 2)\n        wf_line = wf_line[:, :, ::-1]\n\n        plt.figure(""GT"")\n        imshow(img)\n        for a, b in gt_line - 0.5:\n            plt.plot([a[1], b[1]], [a[0], b[0]], color=""orange"", linewidth=0.5)\n            plt.scatter(a[1], a[0], color=""#33FFFF"", s=1.2, edgecolors=""none"", zorder=5)\n            plt.scatter(b[1], b[0], color=""#33FFFF"", s=1.2, edgecolors=""none"", zorder=5)\n        plt.savefig(osp.join(prefix, ""GT"", f""{i:05}""), dpi=3000, bbox_inches=0)\n        plt.close()\n\n        plt.figure(""LSD"")\n        imshow(img)\n        for a, b in lsd_line[:, :, ::-1] - 0.5:\n            plt.plot([a[1], b[1]], [a[0], b[0]], color=""orange"", linewidth=0.5)\n            plt.scatter(a[1], a[0], color=""#33FFFF"", s=1.2, edgecolors=""none"", zorder=5)\n            plt.scatter(b[1], b[0], color=""#33FFFF"", s=1.2, edgecolors=""none"", zorder=5)\n        plt.savefig(osp.join(prefix, ""LSD"", f""{i:05}""), dpi=3000, bbox_inches=0)\n        plt.close()\n\n        plt.figure(""AFM"")\n        imshow(img)\n        for a, b in afm_line - 0.5:\n            plt.plot([a[1], b[1]], [a[0], b[0]], color=""orange"", linewidth=0.5)\n            plt.scatter(a[1], a[0], color=""#33FFFF"", s=1.2, edgecolors=""none"", zorder=5)\n            plt.scatter(b[1], b[0], color=""#33FFFF"", s=1.2, edgecolors=""none"", zorder=5)\n        plt.savefig(osp.join(prefix, ""AFM"", f""{i:05}""), dpi=3000, bbox_inches=0)\n        plt.close()\n\n        plt.figure(""WF"")\n        imshow(img)\n        for a, b in wf_line - 0.5:\n            plt.plot([a[1], b[1]], [a[0], b[0]], color=""orange"", linewidth=0.5)\n            plt.scatter(a[1], a[0], color=""#33FFFF"", s=1.2, edgecolors=""none"", zorder=5)\n            plt.scatter(b[1], b[0], color=""#33FFFF"", s=1.2, edgecolors=""none"", zorder=5)\n        plt.savefig(osp.join(prefix, ""WF"", f""{i:05}""), dpi=3000, bbox_inches=0)\n        plt.close()\n\n    parmap(draw, enumerate(zip(wf, gts, afm, img)))\n\n\nif __name__ == ""__main__"":\n    main()\n'"
misc/lsd.py,0,"b'#!/usr/bin/env python3\n\nimport os\nimport sys\nimport glob\nimport os.path as osp\n\nimport cv2\nimport numpy as np\nimport scipy.io\nimport matplotlib as mpl\nimport numpy.linalg as LA\nimport matplotlib.pyplot as plt\n\nIM = ""data/wireframe/valid-images/*.jpg""\n\n\nif __name__ == ""__main__"":\n    for i, iname in enumerate(sorted(glob.glob(IM))):\n        img = cv2.imread(iname, 0)\n        lsd = cv2.createLineSegmentDetector(cv2.LSD_REFINE_ADV)\n        lsd_line, _, _, lsd_score = lsd.detect(img)\n        lsd_line = lsd_line.reshape(-1, 2, 2)[:, :, ::-1]\n        lsd_score = lsd_score.flatten()\n\n        # plt.imshow(img)\n        # for a, b in lsd_line:\n        #     plt.plot([a[1], b[1]], [a[0], b[0]], linewidth=4)\n        # plt.show()\n\n        lsd_index = np.argsort(-lsd_score)\n        np.savez_compressed(\n            iname.replace("".jpg"", ""_LSD.npz""),\n            lines=lsd_line[lsd_index],\n            scores=lsd_score[lsd_index],\n        )\n'"
misc/plot-sAP.py,0,"b'#!/usr/bin/env python3\n\nimport sys\nimport glob\nimport os.path as osp\n\nimport cv2\nimport numpy as np\nimport scipy.io\nimport matplotlib as mpl\nimport numpy.linalg as LA\nimport matplotlib.pyplot as plt\n\ntry:\n    sys.path.append(""."")\n    sys.path.append("".."")\n    import lcnn.utils\n    import lcnn.metric\nexcept Exception:\n    raise\n\n# Change the directory here\nPRED = ""logs/190418-201834-f8934c6-lr4d10/npz/000312000/*.npz""\nPRED = ""post/jmap_0008/*.npz""\nGT = ""data/wireframe/valid/*.npz""\n# PRED = ""logs/190506-001532-york/*.npz""\n# GT = ""data/york/valid/*.npz""\nWF = ""/data/lcnn/wirebase/result/wireframe/wireframe_1_rerun-baseline_0.5_0.5/*""\nAFM = ""/data/lcnn/wirebase/result/wireframe/afm/*.npz""\n\n\nmpl.rcParams.update({""font.size"": 16})\nplt.rcParams[""font.family""] = ""Times New Roman""\ndel mpl.font_manager.weight_dict[""roman""]\nmpl.font_manager._rebuild()\n\n\ndef wireframe_score(T=10):\n    gts = glob.glob(GT)\n    gts.sort()\n    dirs = glob.glob(WF)\n    dirs.sort(key=lambda x: -float(osp.split(x)[-1]))\n\n    precision, recall = [], []\n    for threshold in dirs:\n        print(""Processing"", threshold)\n        mat_files = glob.glob(osp.join(threshold, ""*.mat""))\n        mat_files.sort()\n        tp, fp, total_gt = 0, 0, 0\n        for i, (gt_name, matf) in enumerate(zip(gts, mat_files)):\n            line_pred = scipy.io.loadmat(matf)[""lines""].reshape(-1, 2, 2)\n            img = cv2.imread(matf.replace("".mat"", "".jpg""))\n            line_pred[:, :, 0] *= 128 / img.shape[1]\n            line_pred[:, :, 1] *= 128 / img.shape[0]\n            line_pred = line_pred[:, :, ::-1]\n\n            with np.load(gt_name) as fgt:\n                line_gt = fgt[""lpos""][:, :, :2]\n            tp_, fp_ = lcnn.metric.msTPFP(line_pred, line_gt, T)\n            tp += tp_.sum()\n            fp += fp_.sum()\n            total_gt += len(line_gt)\n        recall.append(tp / total_gt)\n        precision.append(tp / (tp + fp))\n\n    recall = np.concatenate(([0.0], recall, [1.0]))\n    precision = np.concatenate(([0.0], precision, [0.0]))\n    for i in range(precision.size - 1, 0, -1):\n        precision[i - 1] = max(precision[i - 1], precision[i])\n    i = np.where(recall[1:] != recall[:-1])[0]\n    ap = np.sum((recall[i + 1] - recall[i]) * precision[i + 1])\n\n    np.savez(\n        ""/data/lcnn/results/sAP/wireframe.npz"",\n        x=np.maximum(0.005, recall[:-1]),\n        y=precision[:-1],\n    )\n    plt.plot(\n        np.maximum(0.005, recall[:-1]),\n        precision[:-1],\n        label=""Wireframe"",\n        linewidth=3,\n        c=""C1"",\n    )\n    print(""Huang sAP:"", ap)\n\n\ndef line_score(threshold=10):\n    preds = sorted(glob.glob(PRED))\n    gts = sorted(glob.glob(GT))\n    afm = sorted(glob.glob(AFM))\n\n    lcnn_tp, lcnn_fp, lcnn_scores = [], [], []\n    lsd_tp, lsd_fp, lsd_scores = [], [], []\n    afm_tp, afm_fp, afm_scores = [], [], []\n    n_gt = 0\n    for pred_name, gt_name, afm_name in zip(preds, gts, afm):\n        image = gt_name.replace(""_label.npz"", "".png"")\n\n        img = cv2.imread(image, 0)\n        lsd = cv2.createLineSegmentDetector(cv2.LSD_REFINE_ADV)\n        lsd_line, _, _, lsd_score = lsd.detect(img)\n        lsd_line = lsd_line.reshape(-1, 2, 2)[:, :, ::-1]\n        lsd_score = lsd_score.flatten()\n        # print(lines.shape)\n        # print(nfa.shape)\n\n        with np.load(pred_name) as fpred:\n            lcnn_line = fpred[""lines""][:, :, :2]\n            lcnn_score = fpred[""score""]\n        lcnn_line = lcnn_line[:, :, :2]\n        with np.load(gt_name) as fgt:\n            gt_line = fgt[""lpos""][:, :, :2]\n\n        with np.load(afm_name) as fafm:\n            afm_line = fafm[""lines""].reshape(-1, 2, 2)[:, :, ::-1]\n            afm_score = -fafm[""scores""]\n            h = fafm[""h""]\n            w = fafm[""w""]\n        afm_line[:, :, 0] *= 128 / h\n        afm_line[:, :, 1] *= 128 / w\n        for i, ((a, b), s) in enumerate(zip(lcnn_line, lcnn_score)):\n            if i > 0 and (lcnn_line[i] == lcnn_line[0]).all():\n                lcnn_line = lcnn_line[:i]\n                lcnn_score = lcnn_score[:i]\n                break\n\n        # plt.figure(""LCNN"")\n        # for a, b in lcnn_line:\n        #     plt.plot([a[1], b[1]], [a[0], b[0]], linewidth=4)\n        # plt.figure(""GT"")\n        # for a, b in gt_line:\n        #     plt.plot([a[1], b[1]], [a[0], b[0]], linewidth=4)\n        # plt.figure(""LSD"")\n        # for a, b in lsd_line:\n        #     plt.plot([a[1], b[1]], [a[0], b[0]], linewidth=4)\n        # plt.figure(""AFM"")\n        # for a, b in afm_line:\n        #     plt.plot([a[1], b[1]], [a[0], b[0]], linewidth=4)\n        # plt.show()\n\n        tp, fp = lcnn.metric.msTPFP(lcnn_line, gt_line, threshold)\n        lcnn_tp.append(tp)\n        lcnn_fp.append(fp)\n        lcnn_scores.append(lcnn_score)\n\n        tp, fp = lcnn.metric.msTPFP(lsd_line, gt_line, threshold)\n        lsd_tp.append(tp)\n        lsd_fp.append(fp)\n        lsd_scores.append(lsd_score)\n\n        tp, fp = lcnn.metric.msTPFP(afm_line, gt_line, threshold)\n        afm_tp.append(tp)\n        afm_fp.append(fp)\n        afm_scores.append(afm_score)\n\n        n_gt += len(gt_line)\n\n    lcnn_tp = np.concatenate(lcnn_tp)\n    lcnn_fp = np.concatenate(lcnn_fp)\n    lcnn_scores = np.concatenate(lcnn_scores)\n    lcnn_index = np.argsort(-lcnn_scores)\n    lcnn_tp = lcnn_tp[lcnn_index]\n    lcnn_fp = lcnn_fp[lcnn_index]\n    lcnn_tp = np.cumsum(lcnn_tp) / n_gt\n    lcnn_fp = np.cumsum(lcnn_fp) / n_gt\n\n    lsd_tp = np.concatenate(lsd_tp)\n    lsd_fp = np.concatenate(lsd_fp)\n    lsd_scores = np.concatenate(lsd_scores)\n    lsd_index = np.argsort(-lsd_scores)\n    lsd_tp = lsd_tp[lsd_index]\n    lsd_fp = lsd_fp[lsd_index]\n    lsd_tp = np.cumsum(lsd_tp) / n_gt\n    lsd_fp = np.cumsum(lsd_fp) / n_gt\n\n    afm_tp = np.concatenate(afm_tp)\n    afm_fp = np.concatenate(afm_fp)\n    afm_scores = np.concatenate(afm_scores)\n    afm_index = np.argsort(-afm_scores)\n    afm_tp = afm_tp[afm_index]\n    afm_fp = afm_fp[afm_index]\n    afm_tp = np.cumsum(afm_tp) / n_gt\n    afm_fp = np.cumsum(afm_fp) / n_gt\n\n    lcnn_re, lcnn_pr = lcnn_tp, lcnn_tp / (lcnn_tp + lcnn_fp)\n    afm_re, afm_pr = afm_tp, afm_tp / (afm_tp + afm_fp)\n    # lsd_re, lsd_pr = lsd_tp, lsd_tp / (lsd_tp + lsd_fp)\n\n    T = 0.005\n    plt.plot(afm_re[afm_re > T], afm_pr[afm_re > T], label=""AFM"", linewidth=3, c=""C2"")\n    plt.plot(\n        lcnn_re[lcnn_re > T], lcnn_pr[lcnn_re > T], label=""L-CNN"", linewidth=3, c=""C3""\n    )\n    np.savez(\n        ""/data/lcnn/results/sAP/afm.npz"", x=afm_re[afm_re > T], y=afm_pr[afm_re > T]\n    )\n    np.savez(\n        ""/data/lcnn/results/sAP/lcnn.npz"", x=lcnn_re[lcnn_re > T], y=lcnn_pr[lcnn_re > T]\n    )\n    # plt.plot(lsd_re, lsd_pr, label=""LSD"", linewidth=2)\n\n    plt.grid(True)\n    plt.axis([0.0, 1.0, 0.0, 1.0])\n    plt.xticks(np.arange(0, 1.0, step=0.1))\n    plt.yticks(np.arange(0, 1.0, step=0.1))\n\n    plt.xlabel(""Recall"")\n    plt.ylabel(""Precision"")\n    plt.legend(loc=""upper right"")\n\n    f_scores = np.linspace(0.2, 0.8, num=8)\n    for f_score in f_scores:\n        x = np.linspace(0.01, 1)\n        y = f_score * x / (2 * x - f_score)\n        l, = plt.plot(x[y >= 0], y[y >= 0], color=""green"", alpha=0.3)\n        plt.annotate(""f={0:0.1}"".format(f_score), xy=(0.9, y[45] + 0.02), alpha=0.4)\n    plt.title(""PR Curve for sAP10"")\n    plt.savefig(""sAP.pdf"", format=""pdf"", bbox_inches=""tight"")\n    plt.savefig(""sAP.svg"", format=""svg"", bbox_inches=""tight"")\n    plt.show()\n\n    print(\n        f""Processing {PRED}:\\n""\n        + f""    LSD sAP{threshold}: {lcnn.metric.ap(lsd_tp, lsd_fp)}\\n""\n        + f""    AFM sAP{threshold}: {lcnn.metric.ap(afm_tp, afm_fp)}\\n""\n        + f""    L-CNN sAP{threshold}: {lcnn.metric.ap(lcnn_tp, lcnn_fp)}""\n    )\n\n\ncmap = plt.get_cmap(""jet"")\nnorm = mpl.colors.Normalize(vmin=0.4, vmax=1.0)\nsm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\nsm.set_array([])\n\n\ndef c(x):\n    return sm.to_rgba(x)\n\n\nif __name__ == ""__main__"":\n    plt.tight_layout()\n    wireframe_score()\n    line_score()\n'"
lcnn/models/__init__.py,0,"b'# flake8: noqa\nfrom .hourglass_pose import hg\n# from .dla import dla169, dla102x, dla102x2\n'"
lcnn/models/hourglass_pose.py,2,"b'""""""\nHourglass network inserted in the pre-activated Resnet\nUse lr=0.01 for current version\n(c) Yichao Zhou (LCNN)\n(c) YANG, Wei\n""""""\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n__all__ = [""HourglassNet"", ""hg""]\n\n\nclass Bottleneck2D(nn.Module):\n    expansion = 2\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck2D, self).__init__()\n\n        self.bn1 = nn.BatchNorm2d(inplanes)\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 2, kernel_size=1)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.bn1(x)\n        out = self.relu(out)\n        out = self.conv1(out)\n\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n\n        out = self.bn3(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n\n        return out\n\n\nclass Hourglass(nn.Module):\n    def __init__(self, block, num_blocks, planes, depth):\n        super(Hourglass, self).__init__()\n        self.depth = depth\n        self.block = block\n        self.hg = self._make_hour_glass(block, num_blocks, planes, depth)\n\n    def _make_residual(self, block, num_blocks, planes):\n        layers = []\n        for i in range(0, num_blocks):\n            layers.append(block(planes * block.expansion, planes))\n        return nn.Sequential(*layers)\n\n    def _make_hour_glass(self, block, num_blocks, planes, depth):\n        hg = []\n        for i in range(depth):\n            res = []\n            for j in range(3):\n                res.append(self._make_residual(block, num_blocks, planes))\n            if i == 0:\n                res.append(self._make_residual(block, num_blocks, planes))\n            hg.append(nn.ModuleList(res))\n        return nn.ModuleList(hg)\n\n    def _hour_glass_forward(self, n, x):\n        up1 = self.hg[n - 1][0](x)\n        low1 = F.max_pool2d(x, 2, stride=2)\n        low1 = self.hg[n - 1][1](low1)\n\n        if n > 1:\n            low2 = self._hour_glass_forward(n - 1, low1)\n        else:\n            low2 = self.hg[n - 1][3](low1)\n        low3 = self.hg[n - 1][2](low2)\n        up2 = F.interpolate(low3, scale_factor=2)\n        out = up1 + up2\n        return out\n\n    def forward(self, x):\n        return self._hour_glass_forward(self.depth, x)\n\n\nclass HourglassNet(nn.Module):\n    """"""Hourglass model from Newell et al ECCV 2016""""""\n\n    def __init__(self, block, head, depth, num_stacks, num_blocks, num_classes):\n        super(HourglassNet, self).__init__()\n\n        self.inplanes = 64\n        self.num_feats = 128\n        self.num_stacks = num_stacks\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_residual(block, self.inplanes, 1)\n        self.layer2 = self._make_residual(block, self.inplanes, 1)\n        self.layer3 = self._make_residual(block, self.num_feats, 1)\n        self.maxpool = nn.MaxPool2d(2, stride=2)\n\n        # build hourglass modules\n        ch = self.num_feats * block.expansion\n        # vpts = []\n        hg, res, fc, score, fc_, score_ = [], [], [], [], [], []\n        for i in range(num_stacks):\n            hg.append(Hourglass(block, num_blocks, self.num_feats, depth))\n            res.append(self._make_residual(block, self.num_feats, num_blocks))\n            fc.append(self._make_fc(ch, ch))\n            score.append(head(ch, num_classes))\n            # vpts.append(VptsHead(ch))\n            # vpts.append(nn.Linear(ch, 9))\n            # score.append(nn.Conv2d(ch, num_classes, kernel_size=1))\n            # score[i].bias.data[0] += 4.6\n            # score[i].bias.data[2] += 4.6\n            if i < num_stacks - 1:\n                fc_.append(nn.Conv2d(ch, ch, kernel_size=1))\n                score_.append(nn.Conv2d(num_classes, ch, kernel_size=1))\n        self.hg = nn.ModuleList(hg)\n        self.res = nn.ModuleList(res)\n        self.fc = nn.ModuleList(fc)\n        self.score = nn.ModuleList(score)\n        # self.vpts = nn.ModuleList(vpts)\n        self.fc_ = nn.ModuleList(fc_)\n        self.score_ = nn.ModuleList(score_)\n\n    def _make_residual(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.inplanes,\n                    planes * block.expansion,\n                    kernel_size=1,\n                    stride=stride,\n                )\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def _make_fc(self, inplanes, outplanes):\n        bn = nn.BatchNorm2d(inplanes)\n        conv = nn.Conv2d(inplanes, outplanes, kernel_size=1)\n        return nn.Sequential(conv, bn, self.relu)\n\n    def forward(self, x):\n        out = []\n        # out_vps = []\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.layer1(x)\n        x = self.maxpool(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        for i in range(self.num_stacks):\n            y = self.hg[i](x)\n            y = self.res[i](y)\n            y = self.fc[i](y)\n            score = self.score[i](y)\n            # pre_vpts = F.adaptive_avg_pool2d(x, (1, 1))\n            # pre_vpts = pre_vpts.reshape(-1, 256)\n            # vpts = self.vpts[i](x)\n            out.append(score)\n            # out_vps.append(vpts)\n            if i < self.num_stacks - 1:\n                fc_ = self.fc_[i](y)\n                score_ = self.score_[i](score)\n                x = x + fc_ + score_\n\n        return out[::-1], y  # , out_vps[::-1]\n\n\ndef hg(**kwargs):\n    model = HourglassNet(\n        Bottleneck2D,\n        head=kwargs.get(""head"", lambda c_in, c_out: nn.Conv2D(c_in, c_out, 1)),\n        depth=kwargs[""depth""],\n        num_stacks=kwargs[""num_stacks""],\n        num_blocks=kwargs[""num_blocks""],\n        num_classes=kwargs[""num_classes""],\n    )\n    return model\n'"
lcnn/models/line_vectorizer.py,39,"b'import itertools\nimport random\nfrom collections import defaultdict\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom lcnn.config import M\n\nFEATURE_DIM = 8\n\n\nclass LineVectorizer(nn.Module):\n    def __init__(self, backbone):\n        super().__init__()\n        self.backbone = backbone\n\n        lambda_ = torch.linspace(0, 1, M.n_pts0)[:, None]\n        self.register_buffer(""lambda_"", lambda_)\n        self.do_static_sampling = M.n_stc_posl + M.n_stc_negl > 0\n\n        self.fc1 = nn.Conv2d(256, M.dim_loi, 1)\n        scale_factor = M.n_pts0 // M.n_pts1\n        if M.use_conv:\n            self.pooling = nn.Sequential(\n                nn.MaxPool1d(scale_factor, scale_factor),\n                Bottleneck1D(M.dim_loi, M.dim_loi),\n            )\n            self.fc2 = nn.Sequential(\n                nn.ReLU(inplace=True), nn.Linear(M.dim_loi * M.n_pts1 + FEATURE_DIM, 1)\n            )\n        else:\n            self.pooling = nn.MaxPool1d(scale_factor, scale_factor)\n            self.fc2 = nn.Sequential(\n                nn.Linear(M.dim_loi * M.n_pts1 + FEATURE_DIM, M.dim_fc),\n                nn.ReLU(inplace=True),\n                nn.Linear(M.dim_fc, M.dim_fc),\n                nn.ReLU(inplace=True),\n                nn.Linear(M.dim_fc, 1),\n            )\n        self.loss = nn.BCEWithLogitsLoss(reduction=""none"")\n\n    def forward(self, input_dict):\n        result = self.backbone(input_dict)\n        h = result[""preds""]\n        x = self.fc1(result[""feature""])\n        n_batch, n_channel, row, col = x.shape\n\n        xs, ys, fs, ps, idx, jcs = [], [], [], [], [0], []\n        for i, meta in enumerate(input_dict[""meta""]):\n            p, label, feat, jc = self.sample_lines(\n                meta, h[""jmap""][i], h[""joff""][i], input_dict[""mode""]\n            )\n            # print(""p.shape:"", p.shape)\n            ys.append(label)\n            if input_dict[""mode""] == ""training"" and self.do_static_sampling:\n                p = torch.cat([p, meta[""lpre""]])\n                feat = torch.cat([feat, meta[""lpre_feat""]])\n                ys.append(meta[""lpre_label""])\n                del jc\n            else:\n                jcs.append(jc)\n                ps.append(p)\n            fs.append(feat)\n\n            p = p[:, 0:1, :] * self.lambda_ + p[:, 1:2, :] * (1 - self.lambda_) - 0.5\n            p = p.reshape(-1, 2)  # [N_LINE x N_POINT, 2_XY]\n            px, py = p[:, 0].contiguous(), p[:, 1].contiguous()\n            px0 = px.floor().clamp(min=0, max=127)\n            py0 = py.floor().clamp(min=0, max=127)\n            px1 = (px0 + 1).clamp(min=0, max=127)\n            py1 = (py0 + 1).clamp(min=0, max=127)\n            px0l, py0l, px1l, py1l = px0.long(), py0.long(), px1.long(), py1.long()\n\n            # xp: [N_LINE, N_CHANNEL, N_POINT]\n            xp = (\n                (\n                    x[i, :, px0l, py0l] * (px1 - px) * (py1 - py)\n                    + x[i, :, px1l, py0l] * (px - px0) * (py1 - py)\n                    + x[i, :, px0l, py1l] * (px1 - px) * (py - py0)\n                    + x[i, :, px1l, py1l] * (px - px0) * (py - py0)\n                )\n                .reshape(n_channel, -1, M.n_pts0)\n                .permute(1, 0, 2)\n            )\n            xp = self.pooling(xp)\n            xs.append(xp)\n            idx.append(idx[-1] + xp.shape[0])\n\n        x, y = torch.cat(xs), torch.cat(ys)\n        f = torch.cat(fs)\n        x = x.reshape(-1, M.n_pts1 * M.dim_loi)\n        x = torch.cat([x, f], 1)\n        x = self.fc2(x).flatten()\n\n        if input_dict[""mode""] != ""training"":\n            p = torch.cat(ps)\n            s = torch.sigmoid(x)\n            b = s > 0.5\n            lines = []\n            score = []\n            for i in range(n_batch):\n                p0 = p[idx[i] : idx[i + 1]]\n                s0 = s[idx[i] : idx[i + 1]]\n                mask = b[idx[i] : idx[i + 1]]\n                p0 = p0[mask]\n                s0 = s0[mask]\n                if len(p0) == 0:\n                    lines.append(torch.zeros([1, M.n_out_line, 2, 2], device=p.device))\n                    score.append(torch.zeros([1, M.n_out_line], device=p.device))\n                else:\n                    arg = torch.argsort(s0, descending=True)\n                    p0, s0 = p0[arg], s0[arg]\n                    lines.append(p0[None, torch.arange(M.n_out_line) % len(p0)])\n                    score.append(s0[None, torch.arange(M.n_out_line) % len(s0)])\n                for j in range(len(jcs[i])):\n                    if len(jcs[i][j]) == 0:\n                        jcs[i][j] = torch.zeros([M.n_out_junc, 2], device=p.device)\n                    jcs[i][j] = jcs[i][j][\n                        None, torch.arange(M.n_out_junc) % len(jcs[i][j])\n                    ]\n            result[""preds""][""lines""] = torch.cat(lines)\n            result[""preds""][""score""] = torch.cat(score)\n            result[""preds""][""juncs""] = torch.cat([jcs[i][0] for i in range(n_batch)])\n            if len(jcs[i]) > 1:\n                result[""preds""][""junts""] = torch.cat(\n                    [jcs[i][1] for i in range(n_batch)]\n                )\n\n        if input_dict[""mode""] != ""testing"":\n            y = torch.cat(ys)\n            loss = self.loss(x, y)\n            lpos_mask, lneg_mask = y, 1 - y\n            loss_lpos, loss_lneg = loss * lpos_mask, loss * lneg_mask\n\n            def sum_batch(x):\n                xs = [x[idx[i] : idx[i + 1]].sum()[None] for i in range(n_batch)]\n                return torch.cat(xs)\n\n            lpos = sum_batch(loss_lpos) / sum_batch(lpos_mask).clamp(min=1)\n            lneg = sum_batch(loss_lneg) / sum_batch(lneg_mask).clamp(min=1)\n            result[""losses""][0][""lpos""] = lpos * M.loss_weight[""lpos""]\n            result[""losses""][0][""lneg""] = lneg * M.loss_weight[""lneg""]\n\n        if input_dict[""mode""] == ""training"":\n            del result[""preds""]\n\n        return result\n\n    def sample_lines(self, meta, jmap, joff, mode):\n        with torch.no_grad():\n            junc = meta[""junc""]  # [N, 2]\n            jtyp = meta[""jtyp""]  # [N]\n            Lpos = meta[""Lpos""]\n            Lneg = meta[""Lneg""]\n\n            n_type = jmap.shape[0]\n            jmap = non_maximum_suppression(jmap).reshape(n_type, -1)\n            joff = joff.reshape(n_type, 2, -1)\n            max_K = M.n_dyn_junc // n_type\n            N = len(junc)\n            if mode != ""training"":\n                K = min(int((jmap > M.eval_junc_thres).float().sum().item()), max_K)\n            else:\n                K = min(int(N * 2 + 2), max_K)\n            if K < 2:\n                K = 2\n            device = jmap.device\n\n            # index: [N_TYPE, K]\n            score, index = torch.topk(jmap, k=K)\n            y = (index / 128).float() + torch.gather(joff[:, 0], 1, index) + 0.5\n            x = (index % 128).float() + torch.gather(joff[:, 1], 1, index) + 0.5\n\n            # xy: [N_TYPE, K, 2]\n            xy = torch.cat([y[..., None], x[..., None]], dim=-1)\n            xy_ = xy[..., None, :]\n            del x, y, index\n\n            # dist: [N_TYPE, K, N]\n            dist = torch.sum((xy_ - junc) ** 2, -1)\n            cost, match = torch.min(dist, -1)\n\n            # xy: [N_TYPE * K, 2]\n            # match: [N_TYPE, K]\n            for t in range(n_type):\n                match[t, jtyp[match[t]] != t] = N\n            match[cost > 1.5 * 1.5] = N\n            match = match.flatten()\n\n            _ = torch.arange(n_type * K, device=device)\n            u, v = torch.meshgrid(_, _)\n            u, v = u.flatten(), v.flatten()\n            up, vp = match[u], match[v]\n            label = Lpos[up, vp]\n\n            if mode == ""training"":\n                c = torch.zeros_like(label, dtype=torch.bool)\n\n                # sample positive lines\n                cdx = label.nonzero().flatten()\n                if len(cdx) > M.n_dyn_posl:\n                    # print(""too many positive lines"")\n                    perm = torch.randperm(len(cdx), device=device)[: M.n_dyn_posl]\n                    cdx = cdx[perm]\n                c[cdx] = 1\n\n                # sample negative lines\n                cdx = Lneg[up, vp].nonzero().flatten()\n                if len(cdx) > M.n_dyn_negl:\n                    # print(""too many negative lines"")\n                    perm = torch.randperm(len(cdx), device=device)[: M.n_dyn_negl]\n                    cdx = cdx[perm]\n                c[cdx] = 1\n\n                # sample other (unmatched) lines\n                cdx = torch.randint(len(c), (M.n_dyn_othr,), device=device)\n                c[cdx] = 1\n            else:\n                c = (u < v).flatten()\n\n            # sample lines\n            u, v, label = u[c], v[c], label[c]\n            xy = xy.reshape(n_type * K, 2)\n            xyu, xyv = xy[u], xy[v]\n\n            u2v = xyu - xyv\n            u2v /= torch.sqrt((u2v ** 2).sum(-1, keepdim=True)).clamp(min=1e-6)\n            feat = torch.cat(\n                [\n                    xyu / 128 * M.use_cood,\n                    xyv / 128 * M.use_cood,\n                    u2v * M.use_slop,\n                    (u[:, None] > K).float(),\n                    (v[:, None] > K).float(),\n                ],\n                1,\n            )\n            line = torch.cat([xyu[:, None], xyv[:, None]], 1)\n\n            xy = xy.reshape(n_type, K, 2)\n            jcs = [xy[i, score[i] > 0.03] for i in range(n_type)]\n            return line, label.float(), feat, jcs\n\n\ndef non_maximum_suppression(a):\n    ap = F.max_pool2d(a, 3, stride=1, padding=1)\n    mask = (a == ap).float().clamp(min=0.0)\n    return a * mask\n\n\nclass Bottleneck1D(nn.Module):\n    def __init__(self, inplanes, outplanes):\n        super(Bottleneck1D, self).__init__()\n\n        planes = outplanes // 2\n        self.op = nn.Sequential(\n            nn.BatchNorm1d(inplanes),\n            nn.ReLU(inplace=True),\n            nn.Conv1d(inplanes, planes, kernel_size=1),\n            nn.BatchNorm1d(planes),\n            nn.ReLU(inplace=True),\n            nn.Conv1d(planes, planes, kernel_size=3, padding=1),\n            nn.BatchNorm1d(planes),\n            nn.ReLU(inplace=True),\n            nn.Conv1d(planes, outplanes, kernel_size=1),\n        )\n\n    def forward(self, x):\n        return x + self.op(x)\n'"
lcnn/models/multitask_learner.py,5,"b'from collections import OrderedDict, defaultdict\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom lcnn.config import M\n\n\nclass MultitaskHead(nn.Module):\n    def __init__(self, input_channels, num_class):\n        super(MultitaskHead, self).__init__()\n\n        m = int(input_channels / 4)\n        heads = []\n        for output_channels in sum(M.head_size, []):\n            heads.append(\n                nn.Sequential(\n                    nn.Conv2d(input_channels, m, kernel_size=3, padding=1),\n                    nn.ReLU(inplace=True),\n                    nn.Conv2d(m, output_channels, kernel_size=1),\n                )\n            )\n        self.heads = nn.ModuleList(heads)\n        assert num_class == sum(sum(M.head_size, []))\n\n    def forward(self, x):\n        return torch.cat([head(x) for head in self.heads], dim=1)\n\n\nclass MultitaskLearner(nn.Module):\n    def __init__(self, backbone):\n        super(MultitaskLearner, self).__init__()\n        self.backbone = backbone\n        head_size = M.head_size\n        self.num_class = sum(sum(head_size, []))\n        self.head_off = np.cumsum([sum(h) for h in head_size])\n\n    def forward(self, input_dict):\n        image = input_dict[""image""]\n        outputs, feature = self.backbone(image)\n        result = {""feature"": feature}\n        batch, channel, row, col = outputs[0].shape\n\n        T = input_dict[""target""].copy()\n        n_jtyp = T[""jmap""].shape[1]\n\n        # switch to CNHW\n        for task in [""jmap""]:\n            T[task] = T[task].permute(1, 0, 2, 3)\n        for task in [""joff""]:\n            T[task] = T[task].permute(1, 2, 0, 3, 4)\n\n        offset = self.head_off\n        loss_weight = M.loss_weight\n        losses = []\n        for stack, output in enumerate(outputs):\n            output = output.transpose(0, 1).reshape([-1, batch, row, col]).contiguous()\n            jmap = output[0 : offset[0]].reshape(n_jtyp, 2, batch, row, col)\n            lmap = output[offset[0] : offset[1]].squeeze(0)\n            joff = output[offset[1] : offset[2]].reshape(n_jtyp, 2, batch, row, col)\n            if stack == 0:\n                result[""preds""] = {\n                    ""jmap"": jmap.permute(2, 0, 1, 3, 4).softmax(2)[:, :, 1],\n                    ""lmap"": lmap.sigmoid(),\n                    ""joff"": joff.permute(2, 0, 1, 3, 4).sigmoid() - 0.5,\n                }\n                if input_dict[""mode""] == ""testing"":\n                    return result\n\n            L = OrderedDict()\n            L[""jmap""] = sum(\n                cross_entropy_loss(jmap[i], T[""jmap""][i]) for i in range(n_jtyp)\n            )\n            L[""lmap""] = (\n                F.binary_cross_entropy_with_logits(lmap, T[""lmap""], reduction=""none"")\n                .mean(2)\n                .mean(1)\n            )\n            L[""joff""] = sum(\n                sigmoid_l1_loss(joff[i, j], T[""joff""][i, j], -0.5, T[""jmap""][i])\n                for i in range(n_jtyp)\n                for j in range(2)\n            )\n            for loss_name in L:\n                L[loss_name].mul_(loss_weight[loss_name])\n            losses.append(L)\n        result[""losses""] = losses\n        return result\n\n\ndef l2loss(input, target):\n    return ((target - input) ** 2).mean(2).mean(1)\n\n\ndef cross_entropy_loss(logits, positive):\n    nlogp = -F.log_softmax(logits, dim=0)\n    return (positive * nlogp[1] + (1 - positive) * nlogp[0]).mean(2).mean(1)\n\n\ndef sigmoid_l1_loss(logits, target, offset=0.0, mask=None):\n    logp = torch.sigmoid(logits) + offset\n    loss = torch.abs(logp - target)\n    if mask is not None:\n        w = mask.mean(2, True).mean(1, True)\n        w[w == 0] = 1\n        loss = loss * (mask / w)\n\n    return loss.mean(2).mean(1)\n'"
