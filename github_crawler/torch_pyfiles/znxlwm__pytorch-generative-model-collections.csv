file_path,api_count,code
ACGAN.py,21,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32, class_num=10):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n        self.class_num = class_num\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim + self.class_num, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input, label):\n        x = torch.cat([input, label], 1)\n        x = self.fc(x)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32, class_num=10):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n        self.class_num = class_num\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.fc1 = nn.Sequential(\n            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2),\n        )\n        self.dc = nn.Sequential(\n            nn.Linear(1024, self.output_dim),\n            nn.Sigmoid(),\n        )\n        self.cl = nn.Sequential(\n            nn.Linear(1024, self.class_num),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n        x = self.fc1(x)\n        d = self.dc(x)\n        c = self.cl(x)\n\n        return d, c\n\nclass ACGAN(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.sample_num = 100\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n        self.class_num = 10\n        self.sample_num = self.class_num ** 2\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n            self.BCE_loss = nn.BCELoss().cuda()\n            self.CE_loss = nn.CrossEntropyLoss().cuda()\n        else:\n            self.BCE_loss = nn.BCELoss()\n            self.CE_loss = nn.CrossEntropyLoss()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise & condition\n        self.sample_z_ = torch.zeros((self.sample_num, self.z_dim))\n        for i in range(self.class_num):\n            self.sample_z_[i*self.class_num] = torch.rand(1, self.z_dim)\n            for j in range(1, self.class_num):\n                self.sample_z_[i*self.class_num + j] = self.sample_z_[i*self.class_num]\n\n        temp = torch.zeros((self.class_num, 1))\n        for i in range(self.class_num):\n            temp[i, 0] = i\n\n        temp_y = torch.zeros((self.sample_num, 1))\n        for i in range(self.class_num):\n            temp_y[i*self.class_num: (i+1)*self.class_num] = temp\n\n        self.sample_y_ = torch.zeros((self.sample_num, self.class_num)).scatter_(1, temp_y.type(torch.LongTensor), 1)\n        if self.gpu_mode:\n            self.sample_z_, self.sample_y_ = self.sample_z_.cuda(), self.sample_y_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, y_) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                y_vec_ = torch.zeros((self.batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n                if self.gpu_mode:\n                    x_, z_, y_vec_ = x_.cuda(), z_.cuda(), y_vec_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real, C_real = self.D(x_)\n                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n                C_real_loss = self.CE_loss(C_real, torch.max(y_vec_, 1)[1])\n\n                G_ = self.G(z_, y_vec_)\n                D_fake, C_fake = self.D(G_)\n                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n                C_fake_loss = self.CE_loss(C_fake, torch.max(y_vec_, 1)[1])\n\n                D_loss = D_real_loss + C_real_loss + D_fake_loss + C_fake_loss\n                self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                # update G network\n                self.G_optimizer.zero_grad()\n\n                G_ = self.G(z_, y_vec_)\n                D_fake, C_fake = self.D(G_)\n\n                G_loss = self.BCE_loss(D_fake, self.y_real_)\n                C_fake_loss = self.CE_loss(C_fake, torch.max(y_vec_, 1)[1])\n\n                G_loss += C_fake_loss\n                self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                G_loss.backward()\n                self.G_optimizer.step()\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n                                                                        self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_, self.sample_y_)\n        else:\n            """""" random noise """"""\n            sample_y_ = torch.zeros(self.batch_size, self.class_num).scatter_(1, torch.randint(0, self.class_num - 1, (self.batch_size, 1)).type(torch.LongTensor), 1)\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_, sample_y_ = sample_z_.cuda(), sample_y_.cuda()\n\n            samples = self.G(sample_z_, sample_y_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))\n'"
BEGAN.py,15,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.fc(input)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # It must be Auto-Encoder style architecture\n    # Architecture : (64)4c2s-FC32-FC64*14*14_BR-(1)4dc2s_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.ReLU(),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(64 * (self.input_size // 2) * (self.input_size // 2), 32),\n            nn.Linear(32, 64 * (self.input_size // 2) * (self.input_size // 2)),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            #nn.Sigmoid(),\n        )\n\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(x.size()[0], -1)\n        x = self.fc(x)\n        x = x.view(-1, 64, (self.input_size // 2), (self.input_size // 2))\n        x = self.deconv(x)\n\n        return x\n\nclass BEGAN(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.sample_num = 100\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n        self.gamma = 1\n        self.lambda_ = 0.001\n        self.k = 0.0\n        self.lr_lower_boundary = 0.00002\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=0.0002, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=0.0002, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise\n        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n        if self.gpu_mode:\n            self.sample_z_ = self.sample_z_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n        self.M = {}\n        self.M[\'pre\'] = []\n        self.M[\'pre\'].append(1)\n        self.M[\'cur\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, _) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n\n                z_ = torch.rand((self.batch_size, self.z_dim))\n\n                if self.gpu_mode:\n                    x_, z_ = x_.cuda(), z_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real = self.D(x_)\n                D_real_loss = torch.mean(torch.abs(D_real - x_))\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                D_fake_loss = torch.mean(torch.abs(D_fake - G_))\n\n                D_loss = D_real_loss - self.k * D_fake_loss\n                self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                # update G network\n                self.G_optimizer.zero_grad()\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                D_fake_loss = torch.mean(torch.abs(D_fake - G_))\n\n                G_loss = D_fake_loss\n                self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                G_loss.backward()\n                self.G_optimizer.step()\n\n                # convergence metric\n                temp_M = D_real_loss + torch.abs(self.gamma * D_real_loss - G_loss)\n\n                # operation for updating k\n                temp_k = self.k + self.lambda_ * (self.gamma * D_real_loss - G_loss)\n                temp_k = temp_k.item()\n\n                self.k = min(max(temp_k, 0), 1)\n                self.M[\'cur\'] = temp_M.item()\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f, M: %.8f, k: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item(), self.M[\'cur\'], self.k))\n\n\n            # if epoch == 0:\n            #     self.M[\'pre\'] = self.M[\'cur\']\n            #     self.M[\'cur\'] = []\n            # else:\n            if np.mean(self.M[\'pre\']) < np.mean(self.M[\'cur\']):\n                pre_lr = self.G_optimizer.param_groups[0][\'lr\']\n                self.G_optimizer.param_groups[0][\'lr\'] = max(self.G_optimizer.param_groups[0][\'lr\'] / 2.0,\n                                                             self.lr_lower_boundary)\n                self.D_optimizer.param_groups[0][\'lr\'] = max(self.D_optimizer.param_groups[0][\'lr\'] / 2.0,\n                                                             self.lr_lower_boundary)\n                print(\'M_pre: \' + str(np.mean(self.M[\'pre\'])) + \', M_cur: \' + str(\n                    np.mean(self.M[\'cur\'])) + \', lr: \' + str(pre_lr) + \' --> \' + str(\n                    self.G_optimizer.param_groups[0][\'lr\']))\n            else:\n                print(\'M_pre: \' + str(np.mean(self.M[\'pre\'])) + \', M_cur: \' + str(np.mean(self.M[\'cur\'])))\n                self.M[\'pre\'] = self.M[\'cur\']\n\n                self.M[\'cur\'] = []\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n              self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_)\n        else:\n            """""" random noise """"""\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_ = sample_z_.cuda()\n\n            samples = self.G(sample_z_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))'"
CGAN.py,19,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32, class_num=10):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n        self.class_num = class_num\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim + self.class_num, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input, label):\n        x = torch.cat([input, label], 1)\n        x = self.fc(x)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32, class_num=10):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n        self.class_num = class_num\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim + self.class_num, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2),\n            nn.Linear(1024, self.output_dim),\n            nn.Sigmoid(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input, label):\n        x = torch.cat([input, label], 1)\n        x = self.conv(x)\n        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n        x = self.fc(x)\n\n        return x\n\nclass CGAN(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n        self.class_num = 10\n        self.sample_num = self.class_num ** 2\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size, class_num=self.class_num)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size, class_num=self.class_num)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n            self.BCE_loss = nn.BCELoss().cuda()\n        else:\n            self.BCE_loss = nn.BCELoss()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise & condition\n        self.sample_z_ = torch.zeros((self.sample_num, self.z_dim))\n        for i in range(self.class_num):\n            self.sample_z_[i*self.class_num] = torch.rand(1, self.z_dim)\n            for j in range(1, self.class_num):\n                self.sample_z_[i*self.class_num + j] = self.sample_z_[i*self.class_num]\n\n        temp = torch.zeros((self.class_num, 1))\n        for i in range(self.class_num):\n            temp[i, 0] = i\n\n        temp_y = torch.zeros((self.sample_num, 1))\n        for i in range(self.class_num):\n            temp_y[i*self.class_num: (i+1)*self.class_num] = temp\n\n        self.sample_y_ = torch.zeros((self.sample_num, self.class_num)).scatter_(1, temp_y.type(torch.LongTensor), 1)\n        if self.gpu_mode:\n            self.sample_z_, self.sample_y_ = self.sample_z_.cuda(), self.sample_y_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, y_) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                y_vec_ = torch.zeros((self.batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n                y_fill_ = y_vec_.unsqueeze(2).unsqueeze(3).expand(self.batch_size, self.class_num, self.input_size, self.input_size)\n                if self.gpu_mode:\n                    x_, z_, y_vec_, y_fill_ = x_.cuda(), z_.cuda(), y_vec_.cuda(), y_fill_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real = self.D(x_, y_fill_)\n                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n\n                G_ = self.G(z_, y_vec_)\n                D_fake = self.D(G_, y_fill_)\n                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n\n                D_loss = D_real_loss + D_fake_loss\n                self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                # update G network\n                self.G_optimizer.zero_grad()\n\n                G_ = self.G(z_, y_vec_)\n                D_fake = self.D(G_, y_fill_)\n                G_loss = self.BCE_loss(D_fake, self.y_real_)\n                self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                G_loss.backward()\n                self.G_optimizer.step()\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n              self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_, self.sample_y_)\n        else:\n            """""" random noise """"""\n            sample_y_ = torch.zeros(self.batch_size, self.class_num).scatter_(1, torch.randint(0, self.class_num - 1, (self.batch_size, 1)).type(torch.LongTensor), 1)\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_, sample_y_ = sample_z_.cuda(), sample_y_.cuda()\n\n            samples = self.G(sample_z_, sample_y_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))'"
DRAGAN.py,17,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import grad\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.fc(input)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2),\n            nn.Linear(1024, self.output_dim),\n            nn.Sigmoid(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n        x = self.fc(x)\n\n        return x\n\nclass DRAGAN(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.sample_num = 100\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n        self.lambda_ = 0.25\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n            self.BCE_loss = nn.BCELoss().cuda()\n        else:\n            self.BCE_loss = nn.BCELoss()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise\n        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n        if self.gpu_mode:\n            self.sample_z_ = self.sample_z_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            epoch_start_time = time.time()\n            self.G.train()\n            for iter, (x_, _) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                if self.gpu_mode:\n                    x_, z_ = x_.cuda(), z_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real = self.D(x_)\n                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n\n                """""" DRAGAN Loss (Gradient penalty) """"""\n                # This is borrowed from https://github.com/kodalinaveen3/DRAGAN/blob/master/DRAGAN.ipynb\n                alpha = torch.rand(self.batch_size, 1, 1, 1).cuda()\n                if self.gpu_mode:\n                    alpha = alpha.cuda()\n                    x_p = x_ + 0.5 * x_.std() * torch.rand(x_.size()).cuda()\n                else:\n                    x_p = x_ + 0.5 * x_.std() * torch.rand(x_.size())\n                differences = x_p - x_\n                interpolates = x_ + (alpha * differences)\n                interpolates.requires_grad = True\n                pred_hat = self.D(interpolates)\n                if self.gpu_mode:\n                    gradients = grad(outputs=pred_hat, inputs=interpolates, grad_outputs=torch.ones(pred_hat.size()).cuda(),\n                                 create_graph=True, retain_graph=True, only_inputs=True)[0]\n                else:\n                    gradients = grad(outputs=pred_hat, inputs=interpolates, grad_outputs=torch.ones(pred_hat.size()),\n                         create_graph=True, retain_graph=True, only_inputs=True)[0]\n\n                gradient_penalty = self.lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()\n\n                D_loss = D_real_loss + D_fake_loss + gradient_penalty\n                self.train_hist[\'D_loss\'].append(D_loss.item())\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                # update G network\n                self.G_optimizer.zero_grad()\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n\n                G_loss = self.BCE_loss(D_fake, self.y_real_)\n                self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                G_loss.backward()\n                self.G_optimizer.step()\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n              self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name, self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_)\n        else:\n            """""" random noise """"""\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_ = sample_z_.cuda()\n\n            samples = self.G(sample_z_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))'"
EBGAN.py,20,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.fc(input)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # It must be Auto-Encoder style architecture\n    # Architecture : (64)4c2s-FC32-FC64*14*14_BR-(1)4dc2s_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.ReLU(),\n        )\n        self.code = nn.Sequential(\n            nn.Linear(64 * (self.input_size // 2) * (self.input_size // 2), 32), # bn and relu are excluded since code is used in pullaway_loss\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(32, 64 * (self.input_size // 2) * (self.input_size // 2)),\n            nn.BatchNorm1d(64 * (self.input_size // 2) * (self.input_size // 2)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            # nn.Sigmoid(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(x.size()[0], -1)\n        code = self.code(x)\n        x = self.fc(code)\n        x = x.view(-1, 64, (self.input_size // 2), (self.input_size // 2))\n        x = self.deconv(x)\n\n        return x, code\n\nclass EBGAN(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.sample_num = 100\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n        self.pt_loss_weight = 0.1\n        self.margin = 1\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n            self.MSE_loss = nn.MSELoss().cuda()\n        else:\n            self.MSE_loss = nn.MSELoss()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise\n        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n        if self.gpu_mode:\n            self.sample_z_ = self.sample_z_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, _) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                if self.gpu_mode:\n                    x_, z_ = x_.cuda(), z_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real, _ = self.D(x_)\n                D_real_loss = self.MSE_loss(D_real, x_)\n\n                G_ = self.G(z_)\n                D_fake, _ = self.D(G_)\n                D_fake_loss = self.MSE_loss(D_fake, G_.detach())\n\n                D_loss = D_real_loss + torch.clamp(self.margin - D_fake_loss, min=0)\n                self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                # update G network\n                self.G_optimizer.zero_grad()\n\n                G_ = self.G(z_)\n                D_fake, D_fake_code = self.D(G_)\n                D_fake_loss = self.MSE_loss(D_fake, G_.detach())\n                G_loss = D_fake_loss + self.pt_loss_weight * self.pullaway_loss(D_fake_code.view(self.batch_size, -1))\n                self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                G_loss.backward()\n                self.G_optimizer.step()\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n              self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def pullaway_loss(self, embeddings):\n        """""" pullaway_loss tensorflow version code\n\n            norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n            normalized_embeddings = embeddings / norm\n            similarity = tf.matmul(\n                normalized_embeddings, normalized_embeddings, transpose_b=True)\n            batch_size = tf.cast(tf.shape(embeddings)[0], tf.float32)\n            pt_loss = (tf.reduce_sum(similarity) - batch_size) / (batch_size * (batch_size - 1))\n            return pt_loss\n\n        """"""\n        # norm = torch.sqrt(torch.sum(embeddings ** 2, 1, keepdim=True))\n        # normalized_embeddings = embeddings / norm\n        # similarity = torch.matmul(normalized_embeddings, normalized_embeddings.transpose(1, 0))\n        # batch_size = embeddings.size()[0]\n        # pt_loss = (torch.sum(similarity) - batch_size) / (batch_size * (batch_size - 1))\n\n        norm = torch.norm(embeddings, 1)\n        normalized_embeddings = embeddings / norm\n        similarity = torch.matmul(normalized_embeddings, normalized_embeddings.transpose(1, 0)) ** 2\n        batch_size = embeddings.size()[0]\n        pt_loss = (torch.sum(similarity) - batch_size) / (batch_size * (batch_size - 1))\n\n        return pt_loss\n\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_)\n        else:\n            """""" random noise """"""\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_ = sample_z_.cuda()\n\n            samples = self.G(sample_z_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))'"
GAN.py,11,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.fc(input)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2),\n            nn.Linear(1024, self.output_dim),\n            nn.Sigmoid(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n        x = self.fc(x)\n\n        return x\n\nclass GAN(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.sample_num = 100\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n            self.BCE_loss = nn.BCELoss().cuda()\n        else:\n            self.BCE_loss = nn.BCELoss()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n\n        # fixed noise\n        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n        if self.gpu_mode:\n            self.sample_z_ = self.sample_z_.cuda()\n\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, _) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                if self.gpu_mode:\n                    x_, z_ = x_.cuda(), z_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real = self.D(x_)\n                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n\n                D_loss = D_real_loss + D_fake_loss\n                self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                # update G network\n                self.G_optimizer.zero_grad()\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                G_loss = self.BCE_loss(D_fake, self.y_real_)\n                self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                G_loss.backward()\n                self.G_optimizer.step()\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n              self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_)\n        else:\n            """""" random noise """"""\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_ = sample_z_.cuda()\n\n            samples = self.G(sample_z_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))'"
LSGAN.py,11,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.fc(input)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2),\n            nn.Linear(1024, self.output_dim),\n            # nn.Sigmoid(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n        x = self.fc(x)\n\n        return x\n\nclass LSGAN(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.sample_num = 100\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n            self.MSE_loss = nn.MSELoss().cuda()\n        else:\n            self.MSE_loss = nn.MSELoss()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise\n        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n        if self.gpu_mode:\n            self.sample_z_ = self.sample_z_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, _) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                if self.gpu_mode:\n                    x_, z_ = x_.cuda(), z_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real = self.D(x_)\n                D_real_loss = self.MSE_loss(D_real, self.y_real_)\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                D_fake_loss = self.MSE_loss(D_fake, self.y_fake_)\n\n                D_loss = D_real_loss + D_fake_loss\n                self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                # update G network\n                self.G_optimizer.zero_grad()\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                G_loss = self.MSE_loss(D_fake, self.y_real_)\n                self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                G_loss.backward()\n                self.G_optimizer.step()\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n              self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_)\n        else:\n            """""" random noise """"""\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_ = sample_z_.cuda()\n\n            samples = self.G(sample_z_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))'"
WGAN.py,14,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.fc(input)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2),\n            nn.Linear(1024, self.output_dim),\n            # nn.Sigmoid(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n        x = self.fc(x)\n\n        return x\n\nclass WGAN(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.sample_num = 100\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n        self.c = 0.01                   # clipping value\n        self.n_critic = 5               # the number of iterations of the critic per generator iteration\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise\n        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n        if self.gpu_mode:\n            self.sample_z_ = self.sample_z_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, _) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                if self.gpu_mode:\n                    x_, z_ = x_.cuda(), z_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real = self.D(x_)\n                D_real_loss = -torch.mean(D_real)\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                D_fake_loss = torch.mean(D_fake)\n\n                D_loss = D_real_loss + D_fake_loss\n\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                # clipping D\n                for p in self.D.parameters():\n                    p.data.clamp_(-self.c, self.c)\n\n                if ((iter+1) % self.n_critic) == 0:\n                    # update G network\n                    self.G_optimizer.zero_grad()\n\n                    G_ = self.G(z_)\n                    D_fake = self.D(G_)\n                    G_loss = -torch.mean(D_fake)\n                    self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                    G_loss.backward()\n                    self.G_optimizer.step()\n\n                    self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n              self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_)\n        else:\n            """""" random noise """"""\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_ = sample_z_.cuda()\n\n            samples = self.G(sample_z_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))'"
WGAN_GP.py,18,"b'import utils, torch, time, os, pickle\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import grad\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.fc(input)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2),\n            nn.Linear(1024, self.output_dim),\n            # nn.Sigmoid(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n        x = self.fc(x)\n\n        return x\n\nclass WGAN_GP(object):\n    def __init__(self, args):\n        # parameters\n        self.epoch = args.epoch\n        self.sample_num = 100\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n        self.lambda_ = 10\n        self.n_critic = 5               # the number of iterations of the critic per generator iteration\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise\n        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n        if self.gpu_mode:\n            self.sample_z_ = self.sample_z_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, _) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                if self.gpu_mode:\n                    x_, z_ = x_.cuda(), z_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real = self.D(x_)\n                D_real_loss = -torch.mean(D_real)\n\n                G_ = self.G(z_)\n                D_fake = self.D(G_)\n                D_fake_loss = torch.mean(D_fake)\n\n                # gradient penalty\n                alpha = torch.rand((self.batch_size, 1, 1, 1))\n                if self.gpu_mode:\n                    alpha = alpha.cuda()\n\n                x_hat = alpha * x_.data + (1 - alpha) * G_.data\n                x_hat.requires_grad = True\n\n                pred_hat = self.D(x_hat)\n                if self.gpu_mode:\n                    gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).cuda(),\n                                 create_graph=True, retain_graph=True, only_inputs=True)[0]\n                else:\n                    gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()),\n                                     create_graph=True, retain_graph=True, only_inputs=True)[0]\n\n                gradient_penalty = self.lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()\n\n                D_loss = D_real_loss + D_fake_loss + gradient_penalty\n\n                D_loss.backward()\n                self.D_optimizer.step()\n\n                if ((iter+1) % self.n_critic) == 0:\n                    # update G network\n                    self.G_optimizer.zero_grad()\n\n                    G_ = self.G(z_)\n                    D_fake = self.D(G_)\n                    G_loss = -torch.mean(D_fake)\n                    self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                    G_loss.backward()\n                    self.G_optimizer.step()\n\n                    self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n              self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch, fix=True):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        if fix:\n            """""" fixed noise """"""\n            samples = self.G(self.sample_z_)\n        else:\n            """""" random noise """"""\n            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n            if self.gpu_mode:\n                sample_z_ = sample_z_.cuda()\n\n            samples = self.G(sample_z_)\n\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))'"
dataloader.py,1,"b""from torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\ndef dataloader(dataset, input_size, batch_size, split='train'):\n    transform = transforms.Compose([transforms.Resize((input_size, input_size)), transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n    if dataset == 'mnist':\n        data_loader = DataLoader(\n            datasets.MNIST('data/mnist', train=True, download=True, transform=transform),\n            batch_size=batch_size, shuffle=True)\n    elif dataset == 'fashion-mnist':\n        data_loader = DataLoader(\n            datasets.FashionMNIST('data/fashion-mnist', train=True, download=True, transform=transform),\n            batch_size=batch_size, shuffle=True)\n    elif dataset == 'cifar10':\n        data_loader = DataLoader(\n            datasets.CIFAR10('data/cifar10', train=True, download=True, transform=transform),\n            batch_size=batch_size, shuffle=True)\n    elif dataset == 'svhn':\n        data_loader = DataLoader(\n            datasets.SVHN('data/svhn', split=split, download=True, transform=transform),\n            batch_size=batch_size, shuffle=True)\n    elif dataset == 'stl10':\n        data_loader = DataLoader(\n            datasets.STL10('data/stl10', split=split, download=True, transform=transform),\n            batch_size=batch_size, shuffle=True)\n    elif dataset == 'lsun-bed':\n        data_loader = DataLoader(\n            datasets.LSUN('data/lsun', classes=['bedroom_train'], transform=transform),\n            batch_size=batch_size, shuffle=True)\n\n    return data_loader"""
infoGAN.py,26,"b'import utils, torch, time, os, pickle, itertools\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom dataloader import dataloader\n\nclass generator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n    def __init__(self, input_dim=100, output_dim=1, input_size=32, len_discrete_code=10, len_continuous_code=2):\n        super(generator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n        self.len_discrete_code = len_discrete_code  # categorical distribution (i.e. label)\n        self.len_continuous_code = len_continuous_code  # gaussian distribution (e.g. rotation, thickness)\n\n        self.fc = nn.Sequential(\n            nn.Linear(self.input_dim + self.len_discrete_code + self.len_continuous_code, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n            nn.ReLU(),\n        )\n        self.deconv = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n            nn.Tanh(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input, cont_code, dist_code):\n        x = torch.cat([input, cont_code, dist_code], 1)\n        x = self.fc(x)\n        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n        x = self.deconv(x)\n\n        return x\n\nclass discriminator(nn.Module):\n    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n    def __init__(self, input_dim=1, output_dim=1, input_size=32, len_discrete_code=10, len_continuous_code=2):\n        super(discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.input_size = input_size\n        self.len_discrete_code = len_discrete_code  # categorical distribution (i.e. label)\n        self.len_continuous_code = len_continuous_code  # gaussian distribution (e.g. rotation, thickness)\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2),\n            nn.Linear(1024, self.output_dim + self.len_continuous_code + self.len_discrete_code),\n            # nn.Sigmoid(),\n        )\n        utils.initialize_weights(self)\n\n    def forward(self, input):\n        x = self.conv(input)\n        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n        x = self.fc(x)\n        a = F.sigmoid(x[:, self.output_dim])\n        b = x[:, self.output_dim:self.output_dim + self.len_continuous_code]\n        c = x[:, self.output_dim + self.len_continuous_code:]\n\n        return a, b, c\n\nclass infoGAN(object):\n    def __init__(self, args, SUPERVISED=True):\n        # parameters\n        self.epoch = args.epoch\n        self.batch_size = args.batch_size\n        self.save_dir = args.save_dir\n        self.result_dir = args.result_dir\n        self.dataset = args.dataset\n        self.log_dir = args.log_dir\n        self.gpu_mode = args.gpu_mode\n        self.model_name = args.gan_type\n        self.input_size = args.input_size\n        self.z_dim = 62\n        self.SUPERVISED = SUPERVISED        # if it is true, label info is directly used for code\n        self.len_discrete_code = 10         # categorical distribution (i.e. label)\n        self.len_continuous_code = 2        # gaussian distribution (e.g. rotation, thickness)\n        self.sample_num = self.len_discrete_code ** 2\n\n        # load dataset\n        self.data_loader = dataloader(self.dataset, self.input_size, self.batch_size)\n        data = self.data_loader.__iter__().__next__()[0]\n\n        # networks init\n        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size, len_discrete_code=self.len_discrete_code, len_continuous_code=self.len_continuous_code)\n        self.D = discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size, len_discrete_code=self.len_discrete_code, len_continuous_code=self.len_continuous_code)\n        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n        self.info_optimizer = optim.Adam(itertools.chain(self.G.parameters(), self.D.parameters()), lr=args.lrD, betas=(args.beta1, args.beta2))\n\n        if self.gpu_mode:\n            self.G.cuda()\n            self.D.cuda()\n            self.BCE_loss = nn.BCELoss().cuda()\n            self.CE_loss = nn.CrossEntropyLoss().cuda()\n            self.MSE_loss = nn.MSELoss().cuda()\n        else:\n            self.BCE_loss = nn.BCELoss()\n            self.CE_loss = nn.CrossEntropyLoss()\n            self.MSE_loss = nn.MSELoss()\n\n        print(\'---------- Networks architecture -------------\')\n        utils.print_network(self.G)\n        utils.print_network(self.D)\n        print(\'-----------------------------------------------\')\n\n        # fixed noise & condition\n        self.sample_z_ = torch.zeros((self.sample_num, self.z_dim))\n        for i in range(self.len_discrete_code):\n            self.sample_z_[i * self.len_discrete_code] = torch.rand(1, self.z_dim)\n            for j in range(1, self.len_discrete_code):\n                self.sample_z_[i * self.len_discrete_code + j] = self.sample_z_[i * self.len_discrete_code]\n\n        temp = torch.zeros((self.len_discrete_code, 1))\n        for i in range(self.len_discrete_code):\n            temp[i, 0] = i\n\n        temp_y = torch.zeros((self.sample_num, 1))\n        for i in range(self.len_discrete_code):\n            temp_y[i * self.len_discrete_code: (i + 1) * self.len_discrete_code] = temp\n\n        self.sample_y_ = torch.zeros((self.sample_num, self.len_discrete_code)).scatter_(1, temp_y.type(torch.LongTensor), 1)\n        self.sample_c_ = torch.zeros((self.sample_num, self.len_continuous_code))\n\n        # manipulating two continuous code\n        self.sample_z2_ = torch.rand((1, self.z_dim)).expand(self.sample_num, self.z_dim)\n        self.sample_y2_ = torch.zeros(self.sample_num, self.len_discrete_code)\n        self.sample_y2_[:, 0] = 1\n\n        temp_c = torch.linspace(-1, 1, 10)\n        self.sample_c2_ = torch.zeros((self.sample_num, 2))\n        for i in range(self.len_discrete_code):\n            for j in range(self.len_discrete_code):\n                self.sample_c2_[i*self.len_discrete_code+j, 0] = temp_c[i]\n                self.sample_c2_[i*self.len_discrete_code+j, 1] = temp_c[j]\n\n        if self.gpu_mode:\n            self.sample_z_, self.sample_y_, self.sample_c_, self.sample_z2_, self.sample_y2_, self.sample_c2_ = \\\n                self.sample_z_.cuda(), self.sample_y_.cuda(), self.sample_c_.cuda(), self.sample_z2_.cuda(), \\\n                self.sample_y2_.cuda(), self.sample_c2_.cuda()\n\n    def train(self):\n        self.train_hist = {}\n        self.train_hist[\'D_loss\'] = []\n        self.train_hist[\'G_loss\'] = []\n        self.train_hist[\'info_loss\'] = []\n        self.train_hist[\'per_epoch_time\'] = []\n        self.train_hist[\'total_time\'] = []\n\n        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n        if self.gpu_mode:\n            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n\n        self.D.train()\n        print(\'training start!!\')\n        start_time = time.time()\n        for epoch in range(self.epoch):\n            self.G.train()\n            epoch_start_time = time.time()\n            for iter, (x_, y_) in enumerate(self.data_loader):\n                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n                    break\n                z_ = torch.rand((self.batch_size, self.z_dim))\n                if self.SUPERVISED == True:\n                    y_disc_ = torch.zeros((self.batch_size, self.len_discrete_code)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n                else:\n                    y_disc_ = torch.from_numpy(\n                        np.random.multinomial(1, self.len_discrete_code * [float(1.0 / self.len_discrete_code)],\n                                              size=[self.batch_size])).type(torch.FloatTensor)\n\n                y_cont_ = torch.from_numpy(np.random.uniform(-1, 1, size=(self.batch_size, 2))).type(torch.FloatTensor)\n\n                if self.gpu_mode:\n                    x_, z_, y_disc_, y_cont_ = x_.cuda(), z_.cuda(), y_disc_.cuda(), y_cont_.cuda()\n\n                # update D network\n                self.D_optimizer.zero_grad()\n\n                D_real, _, _ = self.D(x_)\n                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n\n                G_ = self.G(z_, y_cont_, y_disc_)\n                D_fake, _, _ = self.D(G_)\n                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n\n                D_loss = D_real_loss + D_fake_loss\n                self.train_hist[\'D_loss\'].append(D_loss.item())\n\n                D_loss.backward(retain_graph=True)\n                self.D_optimizer.step()\n\n                # update G network\n                self.G_optimizer.zero_grad()\n\n                G_ = self.G(z_, y_cont_, y_disc_)\n                D_fake, D_cont, D_disc = self.D(G_)\n\n                G_loss = self.BCE_loss(D_fake, self.y_real_)\n                self.train_hist[\'G_loss\'].append(G_loss.item())\n\n                G_loss.backward(retain_graph=True)\n                self.G_optimizer.step()\n\n                # information loss\n                disc_loss = self.CE_loss(D_disc, torch.max(y_disc_, 1)[1])\n                cont_loss = self.MSE_loss(D_cont, y_cont_)\n                info_loss = disc_loss + cont_loss\n                self.train_hist[\'info_loss\'].append(info_loss.item())\n\n                info_loss.backward()\n                self.info_optimizer.step()\n\n\n                if ((iter + 1) % 100) == 0:\n                    print(""Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f, info_loss: %.8f"" %\n                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item(), info_loss.item()))\n\n            self.train_hist[\'per_epoch_time\'].append(time.time() - epoch_start_time)\n            with torch.no_grad():\n                self.visualize_results((epoch+1))\n\n        self.train_hist[\'total_time\'].append(time.time() - start_time)\n        print(""Avg one epoch time: %.2f, total %d epochs time: %.2f"" % (np.mean(self.train_hist[\'per_epoch_time\']),\n                                                                        self.epoch, self.train_hist[\'total_time\'][0]))\n        print(""Training finish!... save training results"")\n\n        self.save()\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name,\n                                 self.epoch)\n        utils.generate_animation(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_cont\',\n                                 self.epoch)\n        self.loss_plot(self.train_hist, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n\n    def visualize_results(self, epoch):\n        self.G.eval()\n\n        if not os.path.exists(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name):\n            os.makedirs(self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name)\n\n        image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n\n        """""" style by class """"""\n        samples = self.G(self.sample_z_, self.sample_c_, self.sample_y_)\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'.png\')\n\n        """""" manipulating two continous codes """"""\n        samples = self.G(self.sample_z2_, self.sample_c2_, self.sample_y2_)\n        if self.gpu_mode:\n            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n        else:\n            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n\n        samples = (samples + 1) / 2\n        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                          self.result_dir + \'/\' + self.dataset + \'/\' + self.model_name + \'/\' + self.model_name + \'_cont_epoch%03d\' % epoch + \'.png\')\n\n    def save(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n\n        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + \'_G.pkl\'))\n        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + \'_D.pkl\'))\n\n        with open(os.path.join(save_dir, self.model_name + \'_history.pkl\'), \'wb\') as f:\n            pickle.dump(self.train_hist, f)\n\n    def load(self):\n        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n\n        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_G.pkl\')))\n        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + \'_D.pkl\')))\n\n    def loss_plot(self, hist, path=\'Train_hist.png\', model_name=\'\'):\n        x = range(len(hist[\'D_loss\']))\n\n        y1 = hist[\'D_loss\']\n        y2 = hist[\'G_loss\']\n        y3 = hist[\'info_loss\']\n\n        plt.plot(x, y1, label=\'D_loss\')\n        plt.plot(x, y2, label=\'G_loss\')\n        plt.plot(x, y3, label=\'info_loss\')\n\n        plt.xlabel(\'Iter\')\n        plt.ylabel(\'Loss\')\n\n        plt.legend(loc=4)\n        plt.grid(True)\n        plt.tight_layout()\n\n        path = os.path.join(path, model_name + \'_loss.png\')\n\n        plt.savefig(path)'"
main.py,1,"b'import argparse, os, torch\nfrom GAN import GAN\nfrom CGAN import CGAN\nfrom LSGAN import LSGAN\nfrom DRAGAN import DRAGAN\nfrom ACGAN import ACGAN\nfrom WGAN import WGAN\nfrom WGAN_GP import WGAN_GP\nfrom infoGAN import infoGAN\nfrom EBGAN import EBGAN\nfrom BEGAN import BEGAN\n\n""""""parsing and configuration""""""\ndef parse_args():\n    desc = ""Pytorch implementation of GAN collections""\n    parser = argparse.ArgumentParser(description=desc)\n\n    parser.add_argument(\'--gan_type\', type=str, default=\'GAN\',\n                        choices=[\'GAN\', \'CGAN\', \'infoGAN\', \'ACGAN\', \'EBGAN\', \'BEGAN\', \'WGAN\', \'WGAN_GP\', \'DRAGAN\', \'LSGAN\'],\n                        help=\'The type of GAN\')\n    parser.add_argument(\'--dataset\', type=str, default=\'mnist\', choices=[\'mnist\', \'fashion-mnist\', \'cifar10\', \'cifar100\', \'svhn\', \'stl10\', \'lsun-bed\'],\n                        help=\'The name of dataset\')\n    parser.add_argument(\'--split\', type=str, default=\'\', help=\'The split flag for svhn and stl10\')\n    parser.add_argument(\'--epoch\', type=int, default=50, help=\'The number of epochs to run\')\n    parser.add_argument(\'--batch_size\', type=int, default=64, help=\'The size of batch\')\n    parser.add_argument(\'--input_size\', type=int, default=28, help=\'The size of input image\')\n    parser.add_argument(\'--save_dir\', type=str, default=\'models\',\n                        help=\'Directory name to save the model\')\n    parser.add_argument(\'--result_dir\', type=str, default=\'results\', help=\'Directory name to save the generated images\')\n    parser.add_argument(\'--log_dir\', type=str, default=\'logs\', help=\'Directory name to save training logs\')\n    parser.add_argument(\'--lrG\', type=float, default=0.0002)\n    parser.add_argument(\'--lrD\', type=float, default=0.0002)\n    parser.add_argument(\'--beta1\', type=float, default=0.5)\n    parser.add_argument(\'--beta2\', type=float, default=0.999)\n    parser.add_argument(\'--gpu_mode\', type=bool, default=True)\n    parser.add_argument(\'--benchmark_mode\', type=bool, default=True)\n\n    return check_args(parser.parse_args())\n\n""""""checking arguments""""""\ndef check_args(args):\n    # --save_dir\n    if not os.path.exists(args.save_dir):\n        os.makedirs(args.save_dir)\n\n    # --result_dir\n    if not os.path.exists(args.result_dir):\n        os.makedirs(args.result_dir)\n\n    # --result_dir\n    if not os.path.exists(args.log_dir):\n        os.makedirs(args.log_dir)\n\n    # --epoch\n    try:\n        assert args.epoch >= 1\n    except:\n        print(\'number of epochs must be larger than or equal to one\')\n\n    # --batch_size\n    try:\n        assert args.batch_size >= 1\n    except:\n        print(\'batch size must be larger than or equal to one\')\n\n    return args\n\n""""""main""""""\ndef main():\n    # parse arguments\n    args = parse_args()\n    if args is None:\n        exit()\n\n    if args.benchmark_mode:\n        torch.backends.cudnn.benchmark = True\n\n        # declare instance for GAN\n    if args.gan_type == \'GAN\':\n        gan = GAN(args)\n    elif args.gan_type == \'CGAN\':\n        gan = CGAN(args)\n    elif args.gan_type == \'ACGAN\':\n        gan = ACGAN(args)\n    elif args.gan_type == \'infoGAN\':\n        gan = infoGAN(args, SUPERVISED=False)\n    elif args.gan_type == \'EBGAN\':\n        gan = EBGAN(args)\n    elif args.gan_type == \'WGAN\':\n        gan = WGAN(args)\n    elif args.gan_type == \'WGAN_GP\':\n        gan = WGAN_GP(args)\n    elif args.gan_type == \'DRAGAN\':\n        gan = DRAGAN(args)\n    elif args.gan_type == \'LSGAN\':\n        gan = LSGAN(args)\n    elif args.gan_type == \'BEGAN\':\n        gan = BEGAN(args)\n    else:\n        raise Exception(""[!] There is no option for "" + args.gan_type)\n\n        # launch the graph in a session\n    gan.train()\n    print("" [*] Training finished!"")\n\n    # visualize learned generator\n    gan.visualize_results(args.epoch)\n    print("" [*] Testing finished!"")\n\nif __name__ == \'__main__\':\n    main()\n'"
utils.py,4,"b'import os, gzip, torch\nimport torch.nn as nn\nimport numpy as np\nimport scipy.misc\nimport imageio\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms\n\ndef load_mnist(dataset):\n    data_dir = os.path.join(""./data"", dataset)\n\n    def extract_data(filename, num_data, head_size, data_size):\n        with gzip.open(filename) as bytestream:\n            bytestream.read(head_size)\n            buf = bytestream.read(data_size * num_data)\n            data = np.frombuffer(buf, dtype=np.uint8).astype(np.float)\n        return data\n\n    data = extract_data(data_dir + \'/train-images-idx3-ubyte.gz\', 60000, 16, 28 * 28)\n    trX = data.reshape((60000, 28, 28, 1))\n\n    data = extract_data(data_dir + \'/train-labels-idx1-ubyte.gz\', 60000, 8, 1)\n    trY = data.reshape((60000))\n\n    data = extract_data(data_dir + \'/t10k-images-idx3-ubyte.gz\', 10000, 16, 28 * 28)\n    teX = data.reshape((10000, 28, 28, 1))\n\n    data = extract_data(data_dir + \'/t10k-labels-idx1-ubyte.gz\', 10000, 8, 1)\n    teY = data.reshape((10000))\n\n    trY = np.asarray(trY).astype(np.int)\n    teY = np.asarray(teY)\n\n    X = np.concatenate((trX, teX), axis=0)\n    y = np.concatenate((trY, teY), axis=0).astype(np.int)\n\n    seed = 547\n    np.random.seed(seed)\n    np.random.shuffle(X)\n    np.random.seed(seed)\n    np.random.shuffle(y)\n\n    y_vec = np.zeros((len(y), 10), dtype=np.float)\n    for i, label in enumerate(y):\n        y_vec[i, y[i]] = 1\n\n    X = X.transpose(0, 3, 1, 2) / 255.\n    # y_vec = y_vec.transpose(0, 3, 1, 2)\n\n    X = torch.from_numpy(X).type(torch.FloatTensor)\n    y_vec = torch.from_numpy(y_vec).type(torch.FloatTensor)\n    return X, y_vec\n\ndef load_celebA(dir, transform, batch_size, shuffle):\n    # transform = transforms.Compose([\n    #     transforms.CenterCrop(160),\n    #     transform.Scale(64)\n    #     transforms.ToTensor(),\n    #     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n    # ])\n\n    # data_dir = \'data/celebA\'  # this path depends on your computer\n    dset = datasets.ImageFolder(dir, transform)\n    data_loader = torch.utils.data.DataLoader(dset, batch_size, shuffle)\n\n    return data_loader\n\n\ndef print_network(net):\n    num_params = 0\n    for param in net.parameters():\n        num_params += param.numel()\n    print(net)\n    print(\'Total number of parameters: %d\' % num_params)\n\ndef save_images(images, size, image_path):\n    return imsave(images, size, image_path)\n\ndef imsave(images, size, path):\n    image = np.squeeze(merge(images, size))\n    return scipy.misc.imsave(path, image)\n\ndef merge(images, size):\n    h, w = images.shape[1], images.shape[2]\n    if (images.shape[3] in (3,4)):\n        c = images.shape[3]\n        img = np.zeros((h * size[0], w * size[1], c))\n        for idx, image in enumerate(images):\n            i = idx % size[1]\n            j = idx // size[1]\n            img[j * h:j * h + h, i * w:i * w + w, :] = image\n        return img\n    elif images.shape[3]==1:\n        img = np.zeros((h * size[0], w * size[1]))\n        for idx, image in enumerate(images):\n            i = idx % size[1]\n            j = idx // size[1]\n            img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n        return img\n    else:\n        raise ValueError(\'in merge(images,size) images parameter \'\'must have dimensions: HxW or HxWx3 or HxWx4\')\n\ndef generate_animation(path, num):\n    images = []\n    for e in range(num):\n        img_name = path + \'_epoch%03d\' % (e+1) + \'.png\'\n        images.append(imageio.imread(img_name))\n    imageio.mimsave(path + \'_generate_animation.gif\', images, fps=5)\n\ndef loss_plot(hist, path = \'Train_hist.png\', model_name = \'\'):\n    x = range(len(hist[\'D_loss\']))\n\n    y1 = hist[\'D_loss\']\n    y2 = hist[\'G_loss\']\n\n    plt.plot(x, y1, label=\'D_loss\')\n    plt.plot(x, y2, label=\'G_loss\')\n\n    plt.xlabel(\'Iter\')\n    plt.ylabel(\'Loss\')\n\n    plt.legend(loc=4)\n    plt.grid(True)\n    plt.tight_layout()\n\n    path = os.path.join(path, model_name + \'_loss.png\')\n\n    plt.savefig(path)\n\n    plt.close()\n\ndef initialize_weights(net):\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            m.weight.data.normal_(0, 0.02)\n            m.bias.data.zero_()\n        elif isinstance(m, nn.ConvTranspose2d):\n            m.weight.data.normal_(0, 0.02)\n            m.bias.data.zero_()\n        elif isinstance(m, nn.Linear):\n            m.weight.data.normal_(0, 0.02)\n            m.bias.data.zero_()'"
