{"Multiply": {"**kwargs": [[0.5, 1.5], [0.8, 1.5], null]}, "KLD": {"y_true": [], "y_pred": []}, "ImageDataGenerator": {"featurewise_center": [false, true, null], "samplewise_center": [false, true, null], "featurewise_std_normalization": [false, true, null], "samplewise_std_normalization": [false, true, null], "zca_whitening": [false, true], "zca_epsilon": [1e-06], "rotation_range": [2, 8, 40, 10, 15, 180.0, 20, null, 90.0, 30], "width_shift_range": [0.15625, 0.125, 0.1, 0.05, 0.2, 0.33, 0.08, null], "height_shift_range": [0.15625, 0.125, 0.1, 0.05, 0.2, 0.33, 0.08, null], "brightness_range": [0, [1, 5], null], "shear_range": [0.0, 0.5, 0.1, 0.3, 0.2], "zoom_range": [0.1, 0.5, 0.08, 0.2, 0.05, 0.0, null], "channel_shift_range": [0.1, 0.0, null], "fill_mode": ["nearest", "reflect", "constant"], "cval": [0.0, 0.5], "horizontal_flip": [false, true, null], "vertical_flip": [false, true, null], "rescale": [0.00392156862745098, 0, 1.0, null], "preprocessing_function": [0, null], "data_format": [0, "channels_last", null], "validation_split": [0.0, 0.2, null], "dtype": []}, "multiply": {"inputs": [0.7, 0, 2.0, 0.08333333333333333, 3, 1e-05, -50.0, 49, -10.0, null, 0.0001, 1.6e-05, -1], "**kwargs": [0.0078125, 1.0, 2.0, 2.5, 0.5, 4, 0.75, 0.00390625, 3, 255.0, 32768.0, 16, 17, 0.00392156862745098, 0.00784313725490196, 0.01, -10.0, null, -1.0, 127.5]}, "ImageDataGenerator: apply_transform": {"x": [], "transform_parameters": []}, "ImageDataGenerator: fit": {"x": [], "augment": [], "rounds": [], "seed": []}, "ImageDataGenerator: flow": {"x": [], "y": [], "batch_size": [], "shuffle": [], "sample_weight": [], "seed": [], "save_to_dir": [], "save_prefix": [], "save_format": [], "subset": []}, "ImageDataGenerator: flow_from_dataframe": {"dataframe": [], "directory": [], "x_col": [], "y_col": [], "weight_col": [], "target_size": []}, "ImageDataGenerator: flow_from_directory": {"directory": [], "target_size": []}, "ImageDataGenerator: get_random_transform": {"img_shape": [], "seed": []}, "ImageDataGenerator: random_transform": {"x": [], "seed": []}, "KerasRegressor": {"build_fn": [null], "**sk_params": []}, "KerasClassifier": {"build_fn": [null], "**sk_params": [null]}, "KerasRegressor: check_params": {"params": []}, "KerasRegressor: filter_sk_params": {"fn": [], "override": []}, "KerasClassifier: check_params": {"params": []}, "KerasClassifier: filter_sk_params": {"fn": [], "override": []}, "KerasRegressor: fit": {"x": [], "y": [], "**kwargs": []}, "KerasRegressor: get_params": {"**params": []}, "KerasClassifier: fit": {"x": [], "y": [], "**kwargs": []}, "KerasClassifier: get_params": {"**params": []}, "KerasRegressor: predict": {"x": [], "**kwargs": []}, "KerasRegressor: score": {"x": [], "y": [], "**kwargs": []}, "KerasClassifier: predict": {"x": [], "**kwargs": []}, "KerasClassifier: predict_proba": {"x": [], "**kwargs": []}, "KerasClassifier: score": {"x": [], "y": [], "**kwargs": []}, "to_categorical": {"y": [null], "num_classes": [0, 2, 3, 100, 5, 1000, 10, 12, 30000, null], "dtype": ["float32", null]}, "serialize_keras_object": {"instance": [null]}, "SequenceEnqueuer": {"sequence": [0], "use_multiprocessing": []}, "SequenceEnqueuer: get": {}, "SequenceEnqueuer: is_running": {}, "SequenceEnqueuer: start": {"workers": [], "max_queue_size": []}, "OrderedEnqueuer": {"sequence": [null], "use_multiprocessing": [false, null], "shuffle": []}, "OrderedEnqueuer: get": {}, "OrderedEnqueuer: is_running": {}, "normalize": {"x": [0, "", "NFC", "NFD", ["epsilon", "1e-5"], "NFKD", null, ["axis", "1"], "NFKC"], "axis": [-0.3, 1, 2, 3, 0, "value", [0], "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", [3], "infinity", null, "ohe", -1], "order": [0, 1, 2, "assignment", 1e-10, null]}, "multi_gpu_model": {"model": [null], "gpus": [0, null], "cpu_merge": [false, true, null], "cpu_relocation": [false, null]}, "HDF5Matrix": {"datapath": [0, null], "dataset": ["my_data"], "start": [0], "end": [150], "normalizer": []}, "register_keras_serializable": {"package": ["Addons", "tensorflow_compression"], "name": []}, "Progbar": {"target": [0, null], "width": [30], "verbose": [null], "interval": [0.25, 0.05], "stateful_metrics": [null], "unit_name": []}, "plot_model": {"model": [null], "to_file": ["vgg16.png", "WRN-16-2.png", "vae_mlp_encoder.png", "cnn-y-network.png", "model.png", "test.png", "scraper.py.png", "vae_cnn_encoder.png", null, "tmp.png", "basemodel.png", "cnn-mnist.png"], "show_shapes": [false, true], "show_layer_names": [false, true], "rankdir": ["TB", "LR"], "expand_nested": [false, true], "dpi": [96, 300]}, "OrderedEnqueuer: start": {"workers": [], "max_queue_size": []}, "HDF5Matrix: __getitem__": {"key": []}, "Progbar: add": {"n": [], "values": []}, "model_to_dot": {"model": [null], "show_shapes": [false, true], "show_layer_names": [false, true], "rankdir": ["TB", "LR"], "expand_nested": [false], "dpi": [96], "subgraph": [false]}, "get_source_inputs": {"tensor": [null], "layer": [0], "node_index": [0]}, "get_file": {"fname": ["nietzsche.txt", "spa-eng.zip", "vgg19_weights_tf_dim_ordering_tf_kernels.h5", "resnet50_weights_th_dim_ordering_th_kernels.h5", "squeezenet_weights_tf_dim_ordering_tf_kernels.h5", "ImageNetLabels.txt", "vgg16_weights_tf_dim_ordering_tf_kernels.h5", "facades.tar.gz", "Hollandi2019", "cifar-100-python", "JHung2019.hdf5", "flower_photos", "DenseNet-BC-121-32.h5", "train.csv", "../github_crawler/tf_pyfiles/shekit__alexa-sign-language-translator.csv", "flower_photos.tgz", "rcmalli_vggface_tf_vgg16.h5", "train-v1.1.json", "qm9.tar.gz", "tmp.zip", "rcmalli_vggface_labels_v1.npy", "quora_qp", "resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5", "inception_v3_weights_tf_dim_ordering_tf_kernels.h5", "DSB2018", "cifar-10-batches-py", "auto-mpg.data", "horse2zebra.zip", "babi-tasks-v1-2.tar.gz", "../github_crawler/tf_pyfiles", "wordlists.tgz", "imagenet_class_index.json", "vgg16_weights_th_dim_ordering_th_kernels.h5", "vgg19_weights_th_dim_ordering_th_kernels.h5", "SST-2.zip", null], "origin": ["https://s3.amazonaws.com/img-datasets/mnist.npz", "https://s3.amazonaws.com/text-datasets/nietzsche.txt", "https://s3.amazonaws.com/text-datasets/imdb.npz", "https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz", "https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz", "https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json", "https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip", "https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt", null, "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz", "https://s3.amazonaws.com/text-datasets/reuters.npz", "https://s3.amazonaws.com/keras-datasets/boston_housing.npz", "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data", "http://www.mythic-ai.com/datasets/wordlists.tgz"], "untar": [false, true, null], "md5_hash": ["a439dd41aa672aef6daba4ee1fd54abd", 0, "a268eb855778b3df3c7506639542a6af", null], "file_hash": [0, "e693bd0210a403b3192acc6073ad2e96", "9a0d58056eeedaa3f26cb7ebd46da564", "87aedbeb0cb229e378797a632c1997b6", "6a212e3cb60b33f49c372906f18ae4a8", "599dadb1135973df5b59232a0e9a887c", "f553886a1f8d56431e820c5b82552d9d95cfcb96d1e678153f8839538947dff5", "8a61469f7ea1b51cbae51d4f78837e45", null, "ce01e92f75b533e3ff8e396c76d55d97ff3ec27e99b1bdac1d7b0d6dcf5d90eb"], "cache_subdir": ["quora_qp", "embeddings", "models", "/home/blue/Documents/api-representation-learning/commons", null, "datasets"], "hash_algorithm": ["auto"], "extract": [false, true, null], "archive_format": ["auto"], "cache_dir": [0, null]}, "get_custom_objects": {}, "convert_all_kernels_in_model": {"model": [null]}, "deserialize_keras_object": {"identifier": [0, null], "module_objects": [0, null], "custom_objects": [0, null], "printable_module_name": ["initializer", "quantization function", "nodes", "constraint", "metric function", "constraints", "hypermodels", "convert-to-tensor function", "optimizer", "function in Lambda layer", "regularizer", "encoder", "regularizers", "initializers", "loss function", "object", "layer", "activation function"]}, "custom_object_scope": {"*args": [null]}, "GeneratorEnqueuer": {"sequence": [null], "use_multiprocessing": [false, true, null], "random_seed": []}, "CustomObjectScope": {"*args": [0, null]}, "GeneratorEnqueuer: get": {}, "CustomObjectScope: __enter__": {}, "GeneratorEnqueuer: is_running": {}, "GeneratorEnqueuer: start": {"workers": [], "max_queue_size": []}, "get": {"identifier": [0, 1, "cell", 3, "fontfamily", 7, "dataset_params", "Contents", "use_xla_jit", "description", "http://localhost:8000/example/_search", "subdir", "weighing", "experiment_name", "update_mode", "http://127.0.0.1:8088/ws/v1/cluster/scheduler", "bottleneck", "axes", "edges", "update_time", "torch", "package", "image_size", "TRG_LAN", "train", "expand", "resolution", "requested", "/api/v1/restrictions/user-agreements", "odps.options.retry_times", "GNES_CONTROL_PORT", "warn_connected", "conll_output", "CXX", "guided", "sparse", "vsz", "input", "TransformerBig", "status", "return", "THEANO_FLAGS", "TENSORPACK_DATASET", "json", "hidden_layer_sizes", "PYBIND11_USE_CMAKE", "direction", "sigma", "n_clusters", "zkHosts", "VolumeKmsKeyId", "real_done", "HADOOP_HOME", "{}", "custom_fn", "restore_best_checkpoint", "input_tensor_name", "PATH", "image_dir", "UI", "DOCKER_CONFIG", "hash_fn", "rs6", "reporting_hooks", "temp_location", "act", "n_highway", "starts", "metrics", "TF2ONNX_TEST_OPSET", "how", "tensor_dict", "DataCaptureConfig", "time_steps", "min", "file_cache", "ROK_SECRET_NAME", "__repeat__", "WORLD_SIZE", "func_name", "model_name", "train_batch_norm", "tv", "ones", "GNES_PROFILING", "start", "head_target", "dim_embeddings", "pad_to", "isOAuth", "run", "user", "observation_and_action_constraint_splitter", "testget1", "detect_negative", "lr_scheduler", "USE_TF_KERAS", "momentum_buffer", "FILE_DATA", "OMP_NUM_THREADS", "USE_CUDNN", "maxInputChannels", "base_key", "dialogue_label", "channel", "CXXFLAGS", "NO_ML", "SNT_MODULE_NAME_SCOPES", "scan_input_axes", "stem", "summary", "var1", "inverse_operations", "MARS_PLASMA_DIRS", "callbacks", "LEARNER_ID", "callback_ids", "value.strip().lower()", "verbose_extract", "TRIVIAQA_HOME", "ticker", "security-type", "[MASK]", "dtype", "sagemaker_job_name", "user_id", "conv_activations", "adverbs", "rezoom_conf_scale", "i6t", "tanh", "force_order2", "train_instance_type", "exclusive", "_dtype", "PAD_SYMBOL", "loss", "ai-lab-gui", "timeout", "summaries", "../github_crawler/tf_pyfiles", "video_path", "region_name", "spark.driver.host", "stride", "projsz", "uri", "adam", "filetype", "VPC", "suffix", "FLAIR_CI_MODEL", "http://169.254.169.254/latest/meta-data/instance-id", "artifacts", "padding_constant", "fontface", "attributes", "apply_bias", "n_out", "x-forwarded-prefix", "ref_id", "OS", "INIT_METHOD", "TYPE", "client", "task", "lemma_", "hidden_size", "NEURALMONKEY_DEBUG_ENABLE", "num_residualblocks", "NVIDIA_VISIBLE_DEVICES", "channel_layout", "tensorboard", "access_token", "PAI_USER_NAME", "@no_typecheck", "infer_logits_to_pickle", "limits", "RouteMap", "reduction_factor", "infer_no_label", "uses_data", "db_result", "out", "num_epochs", "reader_type", "char_vocab", "dfkoofkds", "huber_delta", "version", "_promise", "loader", "parameters", "reuse", "CUDA_PATH", "basedir", "solution", "hostname", "eval", "data_type", "mqtt", "strides", "--max-num-examples", "query", "encoder", "casting", "with_char_embeddings", "DebugHookConfig", "verbose", "data_folder", "DECODER_ARTIFACTS_ROOT", "TEST_UNDECLARED_OUTPUTS_DIR", "GRAPHVIZ_RENDER_BUILD_ERRORS", "KUBE_API_ADDRESS", "fallback", "directory", "PHILLY_JOB_ID", "triplet_loss", "size", "sequence_probs", "gpus", "dropout_rate", "Error", "rnntype", "trial_job_id", "tagging_scheme", "center_point_box", "max_mean_len", "h", "versioneer", "/create_pbtxt", "bench_start", "x_seqlen_mean", "re", "ModelName", "target", "CUDA_VISIBLE_DEVICES", "weight_decay", "EnableAutoNumpySharedMemPickling", "__RETURNN_ATFORK_PATCHED", "LD_LIBRARY_PATH", "receiver", "activator", "pathto", "0", "FMAX", "allowed_border", "lb", "PORT", "namespace", "data_format", "CCL_ROOT", "whether_continuous", "url", "p", "EXT_SUFFIX", "input_info", "fairness_indicator_thresholds", "BYTEPS_MPICXX_SHOW", "CLUSTER_SPEC", "lstm_units", "hr", "GIT_TAG", "TEST_TMP_DIR", "sha1", "CI", "files", "chunk_duration", "abbreviation", "pretext", "JPY_PARENT_PID", "pde_solver_fn", "acquisition_function", "flownet", "image_feature_name", ":inproc:", "type", "cache_features", "custom_config", "ProcessingJobArn", "VISUAL", "/", "bidirectional", "jpeg_quality", "content", "algo_path", "shared_embed", "VSR_HOME", "trainable", "additional_pipeline_args", "layers", "kernel", "lengths", "MODEL_ENDPOINT", "flags", "schema", "HOROVOD_ELASTIC", "parameters_hash", "activations_bin_start_epoch", "sigmoid", "low", "RepoTags", "histogram", "multi-gpu-synchronizer", "OPTION_BATCH_SIZE", "n_epochs", "assignmentId", "GO_SYMBOL", "DJANGO_CONFIGURATION", "key", "input_shape", "TF_KERAS", "test-key-1", "rcnn", "runner", "HOROVOD_SPARK_WORK_DIR", "bitwidth_per_scope", "image_options", "sentence", "CODEBUILD_BUILD_ID", "use_true_length", "keep_prob", "n_classes", "episode", "platform", "source", "gradient_clip_norm", "container_statuses", "NGRAPH_HE_BUILD_PATH", "TRAVIS", "auto_mixed_precision", "normalize_length", "title", "transA", "min_size", "algorithm", "trainable_deterministic", "effect_prop", "AUTO_SEGMENTATION_PATH", "BRAINSTORM_DATA_DIR", "EPOCH_OFFSET", "default_root_dir", "Size", "TEST_WORKSPACE", "SUPPRESS_TF_WARNINGS", "top_k", "y_class_num", "Spot_Price", "no_click_mass", "class_num", "activations", "in_y", "optimize_params", "filters", "entity", "batchnorm", "HOROVOD_MIXED_INSTALL", "clip", "strict", "sess", "mutable", "token", "algo", "height", "kl_min", "partition", "Env", "grad_accum", "load", "c0", "TEST_AWS_REGION_NAME", "output_dir", "weights", "username", "examples", "distribution_kwargs", "max_size", "GNES_VCS_VERSION", "repeat", "a", "writerID", "net_list", "PYTHONWARNINGS", "assertion_limit", "condition", "localConfig", "internals", "optimizer_corrected", "n_centers", "start_epoch", "from", "meta/activation/D/mean/high", "training_config", "destroy_event", "mini_batch_size", "asset", "services", "feature_shape", "learners", "do_early_stopping", "log_std", "dataset_location", "process_outputs", "centers", "weight", "noWorkspace", "TENSORPACK_SERIALIZE", "image_id", "account_name", "ProcessingInputs", "sampling_topk", "spark.executor.instances", "error", "initializer", "data", "base_dir", "expected_result_file", "clean_fn", "sessionId", "M", "PAI_ENV", "instance_name", "input_tensor_data", "repetition_penalization_coefficient", "pred_exponent", "label", "opt", "OUTPUTS_TYPES_DATASET", "cauchy_kl_divergence", "content-length", "softmax", "args", "mask_nan", "tensorflow", "do_lower_case", "contrastive_learning", "id_from_image_name", "KYMATIO_CACHE", "dilations", "bias", "SPARK_HOME", "label2", "TEST_ONNX", "compression_type", "__it__", "local_only", "SPHINX_MOCK_REQUIREMENTS", "unit", "remote", "err", "parameters0", "unfold_time_rank", "<START>", "id", "KUBEFLOW_URL", "numerical_idx", "TERM", "ctx_a", "logging_level", "SM_FRAMEWORK", "version_se", "weight_std", "Audio Parameters", "not_existed_name", "normalizer_fn", "fit_func", "sampling_prob", "Y", "commit", "y", "discrete", "/load", "action_probs", "component", "curr_epoch", "first_dnn_layer_size", [], "cpu_only", "by", "epochs", "quiet", "TENSORPACK_PIPEDIR", "DEEPDRIVE_DIR", "HOME", "fold_time_rank", "vocab", "rnn_type", "POLYAXON_NO_CONFIG", "augment_data", "save_path", "module_file", "error_color", "humanPlayerName", "index", "is_test_suite", "--azure-info", "tree", "ignore", "AWS_ACCESS_KEY_ID", "POSTGRES_NAME", "bboxes", "stage", "scale_identity_multiplier", "decoder_input_ids", "post_export_metrics/example_count", "inencoding", "lengths_key", "optimizer", "Etag", "depth_multiplier", "fmod", "learning_rate", "lightgbm", "scopes_without_shape_matching", "shuffle", "results", "TB_LOG_DIR", "frameskip", "training", "spacy", "drop_connect_rate", "xp", "index_value", "columns", "timestamp", "classes", "dataset", "some_key", "grad_eps", "/config/dbcp", "TRAVIS_BUILD_DIR", "DISABLE_V2_BEHAVIOR", "celery_disabled", "passes", "sample_shape", "sparsity", "TF_ANNOTATION_MODEL_PATH", "intent", "colorscheme", "num_attn_heads", "MARS_CPU_USE_PROCESS_STAT", "core_cell_params", "architecture", "DMLC_ROLE", "cited_doc_ids", "src", "INSTALLDIR", "api-servers-http-schema", "summarization", "category", "glorot_uniform", "g1", "fs.defaultFS", "extra", "minval", "beam_width", "relu", "FIELD_NAME", "max_episode_steps", "AcceleratorType", "inherit_method_docs", "use_pre_train_model", "scope", "console", "<UNK>", "n_rb", "monitoring_config_overrides", "write_iter", "value", "garbage", "redis_key", "other", "header", "run_name", "input_files", "bounded_distribution_type", "images", "add_batch_rank", "convolution_param", "transpose", "IN_DEVELOPMENT", "flashgames", "enable_postnet", "IREE_OVERRIDE_BACKENDS", "pass", "serving_default", "TRAVIS_PYTHON_VERSION", "port", "alpha", "episode_return", "algo_config_dict", "COVERAGE_PROCESS_START", "thread", "ignored_scopes", "GNES_ENV_SET", "x", "CSVDIR", "par_check", "acc", "regularizer_params", "HTTP_X_SCRIPT_NAME", "return_native_type", "project_id", "pop_size", "git", "threading", "occluded", "env", "lr", "channels", "DOCKER_IMAGE", "sr", "length", "debug", "dynamic_learning_rate", "val_metrics", "GOOGLE_APPLICATION_CREDENTIALS", "probs", "kwargs", "pipeline_id", "indicators", "shots", "PASS", "answer", "num_workers", "GNES_VOLUME", "artifacts_store", "detection_keypoints", "PROTOC", "_delay", "QUICKTEST", "mse", "group", "STFS_HOST", "num_layers", "num_cpus_per_worker", "PENNYLANE_CONF", "MARS_CONTAINER_IP", "http://localhost:8983/solr/travel/select", "collections", "Content-Length", "action_space", "Image Size", "OPENPOSE_MODEL", "SQLALCHEMY_DATABASE_URI", "broadcast", "state", "weight_clip", "steps", "n_best", "CPU_ONLY", "num_classes", "tokens", "image", "horizontalalignment", "c", "build_input_shape", "slim_attention_lname", "level", "defaults", "label_smoothing", "group_name", "autoregressive", "to", "TEST_PRETRAINED", "env_config", "outputs", ["image"], "memory", "num-samples", "validation_set", "model_max_length", "offset_target_by_one", "episode_done", "tuner", "input_ids", "scale", "PATH_TO_EXE", "num_keypoints", "test", "self_kv", "SecondaryStatusTransitions", "SM_NUM_GPUS", "default", "action", "finetune", "orig_phrase", "storage_path", "valid", "squeeze", "op_names", "velocity", "with_rcnn", "values", "engine", "val_acc", "dropout", "model_site", "csv_data_file", "groupType", "target_worker", "/path/to/local/storage", "d_ff", "avatar_url", "yaml_path", "tune", "emotion", "is_initial", "_type", "rtol", "ConEmuANSI", "metadata", "--wandb_run_id", "density_function", "if_multilabel", "tag", "layer_norm_eps", "env_internal_frame_skip", "KUBECONFIG", "Layers", "epoch", "shuffle_buffer", "_nsplits", "POLYAXON_DOCS_GEN", "RUN_MAIN", "padding_id", "max_timesteps", "load_model", "mean", "class_names", "min_version", "accept", "mode", "pai-master", "plugins", "module_path", "HELP_URL", "activation_fn", "use_targets", "date", "external_evaluators", "http://127.0.0.1:5000/v0/sqli/select", "coach", "early_stop", "connection_type", "KUBEFLOW_TFX_IMAGE", "ngrams", "root", "uniform", "cells", "across_channels", "..../.g.i.t.h.u.b._.c.r.a.w.l.e.r./.t.f._.p.y.f.i.l.e.s", "distance_to_center", "codePath", "attention_lname", "layer_filter", "z_order", "Train", "object", "termination_period", "detection_masks", "<EOU>", "NAOPATH", "model", "use_cache", "seed", "accuracy", "decode", "WANDB_TEST", "data_dir", "NGRAPH_VERSION", "prompt_toolkit", "job", "ENV", "deep.deepStr", "https://www.peterbe.com", "backend", "tags", "stop_loss_scaling", "img", "shape", "cutoff", "ENABLE_FULL_TRANSFORMER_TEST", "prerequisite", "expand_composites", "polygons_to_masks", "rnd_scale_lower", "PE_HOSTFILE", "activation", "authnMethod", "single_text", "sampler", "event_type", "SM_OUTPUT_DATA_DIR", "NNI_OUTPUT_DIR", "config", "FRAMES_PER_HDF5_FILE", "restore_model", "num_loss_partitions", "normalize_embeddings", "frequency", "rectangles", "trainable_normal", "slots", "Explanation_2", "HOROVOD_RANK", "features", "total", "repr_dim_task_embedding", "__package__", "hostip", "action_as_key", "ignore_result", "APPLY_DETOKENIZATION", "max_episode_timesteps", "USE_TF", "eval_params", "ft_type", "cls_name", "accessKey", "cpu_id", "saved_model_path", "compression", "__init__", "ANTLRVERSION", "__name__", "gradients/fc2.bias", "KYMATIO_DATASETS", "average", "entities", "wrapper_config.TimeLimit.max_episode_steps", "DP_SKIP_NLTK_DOWNLOAD", "HOROVOD_HOSTNAME", "none", "min_area", "VULNSERVER_SCHEMA_TYPE", "image_vis", "input_scale", "PAI_CURRENT_TASK_ROLE_NAME", "anchors", "num_train_steps", "device", "as_index", "beta", "USTREASURY/YIELD", "latent_vars", "lr_scheduler_type", "captionID", "sep", "inputs", "training_fraction_with_definition", [0], "class", "ports", "http://localhost:9200/travel/_search", "layer_choice", "pre_lnorm", "regularizer", "CORE_CHANGED", "first_name", "winlen", "TEST_TF", "path", "net", "name", "kernel_size", "cache", "publisher", "ids", "num_init_steps", "distributed_backend", 9999999, "win_size", "vocab_file", "projection", "NOTEBOOK_KERNEL", "layer_type", "litstyle", "detection_boxes", "force", "content-disposition", "max_len", "parquet.summary.metadata.level", "sparsity_training_steps", "ax", "is_managed", "boost", "base_filter", "preprocess", "variational", "use_bp16", "clf", "l1_norm", "TF_EAGER", "num_targets", "weight_tied", "keys", "DEBUG", "width", "READTHEDOCS", "player_name", "span_type", "embed_type", "LOSS", "K8S_TESTS", "text", "TESTS_TO_RUN", "PYTEST_XDIST_WORKER_COUNT", "input_as_shape", "bert_model_path", "_graph_fn_call", "hiddens", "num_cpus_per_replay_actor", "Ebs.DeleteOnTermination", "warm_start", "image_file", "axis", "answerKey", "model_version", "kernel_initializer", "nsteps", "iter_size", null, "num_iters", "LOG_LEVEL", "reader", "alias", "params", "urls", "storagePolicyConfig", "C", "processed_data_folder", "cutoff_dim", "COMET_API_KEY", "pattern", "http_proxy", "RANK", "REDIS_HOST", "tokentype", "beam", "want_inplace", "KERAS_HOME", "CARLA_ROOT", "Paths", "variables", "should_stop", "PrimaryContainer", "hidden_units", "session", "constant_liar", "TENSORFLOW_SKLEARN", "mae", "the", "eps", "filter_path", "register_as_extern_data", "check_conflicts", "ALLOWED_HOSTS", "train_num", "_is_group", "limit_resources", "norm_params", "GPU_MEMORY_FRACTION", "dictionary_path", "quantize_config", "is_test", "group_id", "head_num", "quantize_inputs", "TFP_RANDOMIZE_HYPOTHESIS", "fields", "task_id", "WITH_HADOOP", "DATA_DIR", "backbone", "batch_size", "secret", "rawtext", "model_endpoint", "share_embedding", "A", "score", "INTEL_OPENVINO_DIR", "SYSTEM", "encoding", "filter", "PYTHONPATH", "raw", "lowercase", "TRAINING_ID", "component_api", "conv_activation", "DISPLAY", "CHATBOT_REDIS_URL", "change:value", "TFDS_NIGHTLY_TIMESTAMP", "TF2ONNX_TEMP_DIRECTORY", "labels", "setup_memory", "TF_CONFIG", "CONTAINER_ID", "GPS Position", "id_group_dims", "noise", "PROJECT_DIR", "message", "n_threads", "/get_gpu_info", "UI_SCHEME", "Input Output", "ntop", "threshold", "t", "rotations", "top_pad", "resize", "MatchedWikiEntryName", "scale_min", "imageurl", "FinalHyperParameterTuningJobObjectiveMetric", "vf", "errors", "project", "customized", "initial_weights_path", "idCount", "PYIREE_CMAKE_BUILD_ROOT", "clip_rewards", "blank_index", "res_file", "batch_norm", "href", "Content-Encoding", "style", "CUDA_HOME", "Accept-Encoding", "RLGRAPH_HOME", "sample_weight", "/comprehension_paragraphs", "VIZDOOM_ROOT", "translation_en_to_de", "TOL", "nodeLabels", "LUMI_HOME", -1, "VULNSERVER_DEBUG", "flops", "WarmStartConfig", "System"]}, "l2": {"l": [0, 0.1, 4e-05, 1e-05, 0.01, 5e-05, null, 0.0001, 0.001, 0.0005]}, "l1": {"l": [0, 0.5, 0.1, 0.01, null]}, "l1_l2": {"l1": [1e-05, 0.01, null], "l2": [0.0001, 0.01, null]}, "serialize": {"activation": [0, 2, "value", "../github_crawler/tf_pyfiles", null]}, "Tokenizer": {"num_words": [0, "Bert", "none", "[a-z]+|\\d+", 10, null], "filters": ["", null]}, "hashing_trick": {"text": [["do_lower_case", "self.do_lower_case"], null], "n": [5, null], "hash_function": ["mmh3"], "filters": []}, "tokenizer_from_json": {"json_string": []}, "text_to_word_sequence": {"text": [null], "filters": ["", null]}, "Tokenizer: fit_on_sequences": {"sequences": []}, "one_hot": {"indices": [0, "value", [0], 5, [2], 500, null], "num_classes": [1, 2, 3, 4, 5, 7, 1000, 1001, 10, 9, 15, null]}, "deserialize": {"name": ["value", "mock_metric", null], "custom_objects": [0, "value", null]}, "Tokenizer: fit_on_texts": {"texts": []}, "Tokenizer: get_config": {}, "Tokenizer: sequences_to_matrix": {"sequences": [], "mode": []}, "Tokenizer: sequences_to_texts": {"sequences": []}, "TimeseriesGenerator": {"data": [null], "targets": [null], "length": [], "sampling_rate": [], "stride": [], "start_index": [], "end_index": [], "shuffle": [], "reverse": [], "batch_size": []}, "skipgrams": {"sequence": [], "vocabulary_size": [], "window_size": [], "negative_samples": [], "shuffle": [], "categorical": [], "sampling_table": [], "seed": []}, "pad_sequences": {"sequences": [null], "maxlen": [0, 100, 200, 52, 500, null], "dtype": ["int32", "float64", "float32", null], "padding": ["post", "pre", null], "truncating": ["post", "pre", null], "value": [0.0, "value", null]}, "make_sampling_table": {"size": [], "sampling_factor": []}, "L1L2": {"l1": [0.1, 0.01, null], "l2": [0.1, 0.01, null]}, "save_img": {"path": [0, "../github_crawler/tf_pyfiles", null], "x": [null], "data_format": [0, "channels_last", null], "file_format": [0, "jpeg", null], "scale": [1.0, 227], "**kwargs": [null]}, "Tokenizer: sequences_to_texts_generator": {"sequences": []}, "Tokenizer: texts_to_matrix": {"texts": [], "mode": []}, "TimeseriesGenerator: __getitem__": {"index": []}, "L1L2: __call__": {"x": []}, "Tokenizer: texts_to_sequences": {"texts": []}, "Tokenizer: texts_to_sequences_generator": {"texts": []}, "TimeseriesGenerator: __iter__": {}, "TimeseriesGenerator: __len__": {}, "L1L2: from_config": {"config": []}, "TimeseriesGenerator: get_config": {}, "TimeseriesGenerator: on_epoch_end": {}, "random_zoom": {"x": [null], "zoom_range": [[5, 5], null], "row_axis": [0, 1, null], "col_axis": [1, 2], "channel_axis": [0, 2], "fill_mode": ["nearest"], "cval": [0.0], "interpolation_order": []}, "random_channel_shift": {"x": [null], "intensity_range": [20, null], "channel_axis": [0, null]}, "random_brightness": {"x": [null], "brightness_range": [0.05, 0.1, null]}, "NumpyArrayIterator": {"x": [null], "y": [null], "image_data_generator": [null], "batch_size": [null], "shuffle": [null], "sample_weight": [], "seed": [null], "data_format": [], "save_to_dir": [null], "save_prefix": [null], "save_format": [null], "subset": [], "dtype": []}, "NumpyArrayIterator: __getitem__": {"idx": []}, "random_shear": {"x": [null], "intensity": [20, null], "row_axis": [1], "col_axis": [2], "channel_axis": [0], "fill_mode": ["nearest"], "cval": [0.0], "interpolation_order": []}, "random_rotation": {"x": [null], "rg": [45, null], "row_axis": [1, null], "col_axis": [2], "channel_axis": [0], "fill_mode": ["nearest"], "cval": [0.0], "interpolation_order": []}, "load_img": {"path": ["C:/Users/IS96273/Desktop/jackman.png", "/home/taehoonlee/tensornets/cat.png", "../github_crawler/tf_pyfiles", "image/ajb.jpg", "cat.png", null, "images/cat.jpeg"], "grayscale": [false, true, null], "color_mode": [null], "target_size": [0, [224, 224], [128, 128], [299, 299], [227, 227], [160, 160], [48, 48], [96, 96], null], "interpolation": [null]}, "Iterator": {"n": [0, null], "batch_size": [0, 1, 64, 1024, null], "shuffle": [false, true, null], "seed": [null]}, "random_shift": {"x": [null], "wrg": [1, null], "hrg": [1, null], "row_axis": [1], "col_axis": [2], "channel_axis": [0], "fill_mode": ["nearest"], "cval": [0.0], "interpolation_order": []}, "img_to_array": {"img": [null], "data_format": [0, null], "dtype": [0]}, "NumpyArrayIterator: __iter__": {}, "NumpyArrayIterator: __len__": {}, "Iterator: __getitem__": {"idx": []}, "Iterator: __iter__": {}, "NumpyArrayIterator: next": {}, "NumpyArrayIterator: on_epoch_end": {}, "array_to_img": {"x": [null], "data_format": [0, "RGB", "channels_first", null, "channels_last"], "scale": [false, true], "dtype": [0]}, "apply_brightness_shift": {"x": [null], "brightness": [null]}, "DirectoryIterator": {"directory": [null], "image_data_generator": [null], "target_size": [null]}, "Iterator: __len__": {}, "Iterator: next": {}, "DirectoryIterator: __getitem__": {"idx": []}, "DirectoryIterator: __iter__": {}, "Iterator: on_epoch_end": {}, "apply_channel_shift": {"x": [null], "intensity": [null], "channel_axis": [2]}, "PolynomialDecay": {"initial_learning_rate": [0.2, 0.0005, null], "decay_steps": [0.6, 0.8, 100, null], "end_learning_rate": [0.0, null], "power": [null], "cycle": [3, null], "name": [1, null]}, "apply_affine_transform": {"x": [null], "theta": [45], "tx": [], "ty": [], "shear": [], "zx": [null], "zy": [null], "row_axis": [], "col_axis": [], "channel_axis": [2], "fill_mode": ["nearest", "constant"], "cval": [], "order": []}, "DirectoryIterator: __len__": {}, "PolynomialDecay: __call__": {"step": []}, "DirectoryIterator: next": {}, "InverseTimeDecay": {"initial_learning_rate": [3.0, null], "decay_steps": [1.0, null], "decay_rate": [0.5, null], "staircase": [null], "name": []}, "ExponentialDecay": {"initial_learning_rate": [null], "decay_steps": [100000, null], "decay_rate": [0.1, 0.96, 0.97, null], "staircase": [true, null], "name": [null]}, "PiecewiseConstantDecay": {"boundaries": [[200000], null], "values": [null], "name": [null]}, "LearningRateSchedule": {"step": [0, null]}, "PolynomialDecay: from_config": {"config": []}, "DirectoryIterator: on_epoch_end": {}, "InverseTimeDecay: __call__": {"step": []}, "ExponentialDecay: __call__": {"step": []}, "PiecewiseConstantDecay: __call__": {"step": []}, "PiecewiseConstantDecay: from_config": {"config": []}, "LearningRateSchedule: __call__": {"step": []}, "PolynomialDecay: get_config": {}, "DirectoryIterator: reset": {}, "InverseTimeDecay: from_config": {"config": []}, "ExponentialDecay: from_config": {"config": []}, "PiecewiseConstantDecay: get_config": {}, "LearningRateSchedule: from_config": {"config": []}, "RMSprop": {"learning_rate": [0.0001, 0.01, 0.001, null], "rho": [0.9, null], "momentum": [0.9, null], "epsilon": [1e-08, null, 1e-07, 1e-06, 0.001], "centered": [true, null], "name": ["RMSPropA", "RMS_optimizer_actor"], "**kwargs": []}, "InverseTimeDecay: get_config": {}, "Optimizer": {"name": [0.5, 0, 2.0, 3, 1.0, 0.4, 0.2, "GradientDescent", "a_optimizer", "TrainG", 0.0001, 0.05, "Adam_AE", "Adam_g", 0.0002, 5e-06, 3e-05, "Adam", 1e-06, 0.03, 0.1, 0.15, "d_optimizer", 0.0003, "optimizer", 0.025, 0.02, "adam", 0.075, "Adam-op", "AdamOptimizer", 1e-05, 0.01, 0.0095, "Momentum", "EnergyForceField", 0.005, null, 0.004, 0.003, 0.0025, 0.002, 0.001, 0.0005], "**kwargs": [0.5, 0.9, false, "value", 0.95, "dynamic", null]}, "ExponentialDecay: get_config": {}, "LearningRateSchedule: get_config": {}, "SGD": {"learning_rate": [0.1, 0, 0.5, 1.0, 0.05, 0.01, null, 0.02, 0.0001, 0.002, 0.001], "momentum": [0.9, 0.0, 0.3, 0.5, 0.99, 1, 0.05, 0.025, null, 0.0001], "nesterov": [false, true, null], "name": [null], "**kwargs": [null]}, "RMSprop: add_slot": {"var": [], "slot_name": [], "initializer": []}, "RMSprop: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "Optimizer: add_slot": {"var": [], "slot_name": [], "initializer": []}, "Nadam": {"learning_rate": [null], "beta_1": [null], "beta_2": [null], "epsilon": [null], "name": [], "**kwargs": []}, "SGD: add_slot": {"var": [], "slot_name": [], "initializer": []}, "SGD: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "RMSprop: apply_gradients": {"grads_and_vars": [], "name": []}, "Adagrad": {"learning_rate": [0, null], "initial_accumulator_value": [0.1, 0.0, null], "epsilon": [1e-07, 1e-10, null], "name": [null], "**kwargs": [null]}, "Optimizer: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "Nadam: add_slot": {"var": [], "slot_name": [], "initializer": []}, "Nadam: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "SGD: apply_gradients": {"grads_and_vars": [], "name": []}, "RMSprop: from_config": {"config": [], "custom_objects": []}, "RMSprop: get_config": {}, "Adagrad: add_slot": {"var": [], "slot_name": [], "initializer": []}, "Adagrad: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "Optimizer: apply_gradients": {"grads_and_vars": [], "name": []}, "Optimizer: from_config": {"config": [], "custom_objects": []}, "Ftrl": {"learning_rate": [null], "learning_rate_power": [null], "initial_accumulator_value": [null], "l1_regularization_strength": [null], "l2_regularization_strength": [null], "name": [null], "l2_shrinkage_regularization_strength": [], "**kwargs": []}, "save_model": {"model": ["./current_policy.model", "/tmp/test_model", "../github_crawler/tf_pyfiles", "face-recognition-ensemble-model.txt", "net", null, "trained_weights.np", "test.hdf5"], "filepath": [0, "model_policy_net", "./logs/model_mlp", "model_policy", "../github_crawler/tf_pyfiles", "qnet", "BEST", "model_q_net1", "model_actor", null, "actor"], "overwrite": [true, "A3C", "../github_crawler/tf_pyfiles", "DQN", null], "include_optimizer": [0, true, null], "save_format": ["tf", null], "signatures": [], "options": []}, "Adamax": {"learning_rate": [null], "beta_1": [null], "beta_2": [null], "epsilon": [1e-07, null], "name": [], "**kwargs": []}, "Adam": {"learning_rate": [0, 0.1, 0.05, 0.5, 1e-05, 0.01, 6.25e-05, 0.0002, 0.007, 0.005, null, 0.02, 0.0001, 3e-05, 0.001, 0.0005], "beta_1": [0.9, 0.5, 0.99, 0.1, 5e-05, null, 0.0001], "beta_2": [0.999, 0.9, 0.98, 0.99, null], "epsilon": [0.1, 1e-09, 0.00015, 1e-05, 1e-08, 0.0001, null, 1e-07, 0.001], "amsgrad": [false, null], "name": [null], "**kwargs": [null]}, "Adadelta": {"learning_rate": [1.0, null], "rho": [0.95, null], "epsilon": [1e-05, 1e-08, null, 1e-07, 1e-06], "name": [], "**kwargs": []}, "Nadam: apply_gradients": {"grads_and_vars": [], "name": []}, "Nadam: from_config": {"config": [], "custom_objects": []}, "SGD: from_config": {"config": [], "custom_objects": []}, "SGD: get_config": {}, "RMSprop: get_gradients": {"loss": [], "params": []}, "RMSprop: get_slot": {"var": [], "slot_name": []}, "Adagrad: apply_gradients": {"grads_and_vars": [], "name": []}, "Adagrad: from_config": {"config": [], "custom_objects": []}, "Optimizer: get_config": {}, "Optimizer: get_gradients": {"loss": [], "params": []}, "Ftrl: add_slot": {"var": [], "slot_name": [], "initializer": []}, "Ftrl: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "Adamax: add_slot": {"var": [], "slot_name": [], "initializer": []}, "Adamax: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "Adam: add_slot": {"var": [], "slot_name": [], "initializer": []}, "Adadelta: add_slot": {"var": [], "slot_name": [], "initializer": []}, "Nadam: get_config": {}, "Nadam: get_gradients": {"loss": [], "params": []}, "SGD: get_gradients": {"loss": [], "params": []}, "SGD: get_slot": {"var": [], "slot_name": []}, "RMSprop: get_slot_names": {}, "Adagrad: get_config": {}, "Adagrad: get_gradients": {"loss": [], "params": []}, "Optimizer: get_slot": {"var": [], "slot_name": []}, "Ftrl: apply_gradients": {"grads_and_vars": [], "name": []}, "Ftrl: from_config": {"config": [], "custom_objects": []}, "Adamax: apply_gradients": {"grads_and_vars": [], "name": []}, "Adamax: from_config": {"config": [], "custom_objects": []}, "Adam: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "Adam: apply_gradients": {"grads_and_vars": [], "name": []}, "Adadelta: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "Adadelta: apply_gradients": {"grads_and_vars": [], "name": []}, "Nadam: get_slot": {"var": [], "slot_name": []}, "Nadam: get_slot_names": {}, "SGD: get_slot_names": {}, "SGD: get_updates": {"loss": [], "params": []}, "RMSprop: get_updates": {"loss": [], "params": []}, "Adagrad: get_slot": {"var": [], "slot_name": []}, "Optimizer: get_slot_names": {}, "Ftrl: get_config": {}, "Adamax: get_config": {}, "Adam: from_config": {"config": [], "custom_objects": []}, "Adadelta: from_config": {"config": [], "custom_objects": []}, "Adadelta: get_config": {}, "Nadam: get_updates": {"loss": [], "params": []}, "SGD: get_weights": {}, "SGD: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "RMSprop: get_weights": {}, "RMSprop: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "Adagrad: get_slot_names": {}, "Adagrad: get_updates": {"loss": [], "params": []}, "Optimizer: get_updates": {"loss": [], "params": []}, "Optimizer: get_weights": {}, "Ftrl: get_gradients": {"loss": [], "params": []}, "Ftrl: get_slot": {"var": [], "slot_name": []}, "Adamax: get_gradients": {"loss": [], "params": []}, "Adamax: get_slot": {"var": [], "slot_name": []}, "Adam: get_config": {}, "Adam: get_gradients": {"loss": [], "params": []}, "Adadelta: get_gradients": {"loss": [], "params": []}, "Adadelta: get_slot": {"var": [], "slot_name": []}, "Nadam: get_weights": {}, "SGD: set_weights": {"weights": []}, "SGD: variables": {}, "RMSprop: set_weights": {"weights": []}, "Adagrad: get_weights": {}, "Optimizer: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "Optimizer: set_weights": {"weights": []}, "Ftrl: get_slot_names": {}, "Adamax: get_slot_names": {}, "Adamax: get_updates": {"loss": [], "params": []}, "Adam: get_slot": {"var": [], "slot_name": []}, "Adam: get_slot_names": {}, "Adadelta: get_slot_names": {}, "Adadelta: get_updates": {"loss": [], "params": []}, "Nadam: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "Nadam: set_weights": {"weights": []}, "RMSprop: variables": {}, "Adagrad: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "Adagrad: set_weights": {"weights": []}, "Optimizer: variables": {}, "Ftrl: get_updates": {"loss": [], "params": []}, "Ftrl: get_weights": {}, "Adamax: get_weights": {}, "Adam: get_updates": {"loss": [], "params": []}, "Adam: get_weights": {}, "Adadelta: get_weights": {}, "Nadam: variables": {}, "Adagrad: variables": {}, "Ftrl: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "Adamax: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "Adam: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "Adam: set_weights": {"weights": []}, "Adadelta: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "Adadelta: set_weights": {"weights": []}, "Ftrl: set_weights": {"weights": []}, "Ftrl: variables": {}, "Adamax: set_weights": {"weights": []}, "Adamax: variables": {}, "Adam: variables": {}, "Adadelta: variables": {}, "model_from_config": {"config": [null], "custom_objects": [null]}, "model_from_yaml": {"yaml_string": [null], "custom_objects": [0]}, "Policy": {"name": [0, 10, "mixed_bfloat16", null, "mixed_float16"], "loss_scale": [null]}, "Policy: from_config": {"config": [], "custom_objects": []}, "set_policy": {"policy": ["infer_float32_vars", null]}, "model_from_json": {"json_string": [null], "custom_objects": [0, null]}, "global_policy": {}, "load_model": {"filepath": [0, "<path_to_model>", "/tmp/test_model", "models/generator.h5", "./models/trained_model.h5", "model.hdf5", "Models/video.h5", "iris-classifier.h5", "trained_weights.np", "my_model.tf", "../trained_models/emotion_models/simple_CNN.985-0.66.hdf5", "my_model", "../github_crawler/tf_pyfiles/shekit__alexa-sign-language-translator.csv", "./logs/model_mlp", "classifier/emotion_models/simple_CNN.530-0.65.hdf5", "CartPole-v0-nn.h5", "data/checkpoints/inception.057-1.16.hdf5", "my_model.h5", "iris.h5", "/model/files/model.h5", "test_rbm_1/", "model_autokeras", "CartPole-v0-pg.h5", "../github_crawler/tf_pyfiles", "Eform_MP_2019", "MountainCar-v0-dqn.h5", "stripped_model.h5", "model.h5", "classifier/gender_models/simple_CNN.81-0.96.hdf5", null, "s2s.h5", "../dnn/mpg_model.h5"], "custom_objects": [0, "model_policy", null, "qnet", "model_q_net1", "model_actor", "model_policy_net", "actor", "/home/steffen/Pytorch/CenterNet/models/ctdet_coco_hg.pth"], "compile": [false, true, "A3C", "DQN", null]}, "clone_model": {"model": [null], "input_tensors": [0, null], "clone_function": [null]}, "LossScaleOptimizer": {"optimizer": [null], "loss_scale": [null, "dynamic"]}, "TruePositives": {"thresholds": [0, null], "name": [], "dtype": []}, "LossScaleOptimizer: add_slot": {"var": [], "slot_name": [], "initializer": []}, "LossScaleOptimizer: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "trainable": [], "synchronization": [], "aggregation": []}, "TruePositives: reset_states": {}, "TruePositives: result": {}, "Sum": {"name": [0, "test_loss", null], "dtype": [null]}, "LossScaleOptimizer: apply_gradients": {"grads_and_vars": [], "name": []}, "TruePositives: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "Sum: reset_states": {}, "Sum: result": {}, "LossScaleOptimizer: from_config": {"config": [], "custom_objects": []}, "LossScaleOptimizer: get_config": {}, "TopKCategoricalAccuracy": {"k": [0, 5, null], "name": ["topk_acc"], "dtype": []}, "top_k_categorical_accuracy": {"y_true": [null], "y_pred": [null], "k": [1, 5]}, "SpecificityAtSensitivity": {"sensitivity": [0, 0.5, null], "num_thresholds": [], "name": [], "dtype": []}, "SquaredHinge": {"reduction": [0, null], "name": []}, "sparse_categorical_accuracy": {"y_true": [null], "y_pred": [null]}, "sparse_top_k_categorical_accuracy": {"y_true": [null], "y_pred": [null], "k": [5]}, "Sum: update_state": {"values": [], "sample_weight": []}, "LossScaleOptimizer: get_gradients": {"loss": [], "params": []}, "LossScaleOptimizer: get_scaled_loss": {"loss": []}, "TopKCategoricalAccuracy: reset_states": {}, "TopKCategoricalAccuracy: result": {}, "SpecificityAtSensitivity: reset_states": {}, "SpecificityAtSensitivity: result": {}, "SquaredHinge: reset_states": {}, "SquaredHinge: result": {}, "LossScaleOptimizer: get_slot": {"var": [], "slot_name": []}, "TopKCategoricalAccuracy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "SpecificityAtSensitivity: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "SquaredHinge: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "LossScaleOptimizer: get_slot_names": {}, "TrueNegatives": {"thresholds": [0.8, 0, null], "name": [], "dtype": []}, "LossScaleOptimizer: get_unscaled_gradients": {"grads": []}, "LossScaleOptimizer: get_updates": {"loss": [], "params": []}, "TrueNegatives: reset_states": {}, "TrueNegatives: result": {}, "LossScaleOptimizer: get_weights": {}, "LossScaleOptimizer: minimize": {"loss": [], "var_list": [], "grad_loss": [], "name": []}, "TrueNegatives: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "LossScaleOptimizer: set_weights": {"weights": []}, "LossScaleOptimizer: variables": {}, "Recall": {"thresholds": [0, null], "top_k": [null], "class_id": [null], "name": ["recall"], "dtype": []}, "Recall: reset_states": {}, "Recall: result": {}, "PrecisionAtRecall": {"recall": [], "num_thresholds": [], "name": [], "dtype": []}, "SparseTopKCategoricalAccuracy": {"k": [0, 5, null], "name": ["topk_acc"], "dtype": []}, "SparseCategoricalCrossentropy": {"from_logits": [0, true, null], "reduction": ["none", null], "name": []}, "Poisson": {"reduction": [0, 1.0, 5.0, null], "name": ["y", "x", null]}, "MeanSquaredLogarithmicError": {"reduction": [0, null], "name": []}, "SparseCategoricalAccuracy": {"name": ["train_accuracy", "acc", "accuracy", "my_acc", "test_accuracy", null], "dtype": [null]}, "MeanTensor": {"name": [], "dtype": []}, "Metric": {"name": [0, "acc", "loss", "train_loss", "PhaseAverageReturn", null, "SMAPE"], "dtype": [null], "**kwargs": [null]}, "Recall: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "PrecisionAtRecall: reset_states": {}, "PrecisionAtRecall: result": {}, "SparseTopKCategoricalAccuracy: reset_states": {}, "SparseCategoricalCrossentropy: reset_states": {}, "SparseCategoricalCrossentropy: result": {}, "Poisson: reset_states": {}, "Poisson: result": {}, "MeanSquaredLogarithmicError: reset_states": {}, "MeanSquaredLogarithmicError: result": {}, "SensitivityAtSpecificity": {"specificity": [0, 0.5, null], "num_thresholds": [], "name": [], "dtype": []}, "SparseCategoricalAccuracy: reset_states": {}, "SparseCategoricalAccuracy: result": {}, "MeanTensor: reset_states": {}, "MeanTensor: result": {}, "Metric: add_weight": {"name": [], "shape": []}, "Metric: reset_states": {}, "RootMeanSquaredError": {"name": [0, null], "dtype": []}, "Precision": {"thresholds": [null], "top_k": [15, null], "class_id": [12, null], "name": ["precision", "my_precision"], "dtype": []}, "PrecisionAtRecall: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "SparseTopKCategoricalAccuracy: result": {}, "SparseTopKCategoricalAccuracy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "SparseCategoricalCrossentropy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanSquaredError": {"reduction": [null], "name": ["mse_1", "my_mse", null]}, "MeanRelativeError": {"normalizer": [], "name": [], "dtype": []}, "Poisson: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanIoU": {"num_classes": [0, 2, null], "name": [], "dtype": []}, "MeanAbsoluteError": {"reduction": [0, null], "name": []}, "LogCoshError": {"name": [0, null], "dtype": []}, "Mean": {"name": [0, "g_total_loss", "loss", "metric_3", "train_loss", "ctx_mean", [], null, "metric_2"], "dtype": [null]}, "KLDivergence": {"reduction": [0, null], "name": [null]}, "MeanSquaredLogarithmicError: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "SensitivityAtSpecificity: reset_states": {}, "SensitivityAtSpecificity: result": {}, "SparseCategoricalAccuracy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanTensor: update_state": {"values": [], "sample_weight": []}, "Metric: result": {}, "RootMeanSquaredError: reset_states": {}, "RootMeanSquaredError: result": {}, "Precision: reset_states": {}, "Precision: result": {}, "MeanSquaredError: reset_states": {}, "MeanSquaredError: result": {}, "MeanRelativeError: reset_states": {}, "MeanRelativeError: result": {}, "MeanIoU: reset_states": {}, "MeanIoU: result": {}, "MeanAbsoluteError: reset_states": {}, "MeanAbsoluteError: result": {}, "LogCoshError: reset_states": {}, "LogCoshError: result": {}, "Mean: reset_states": {}, "Mean: result": {}, "Mean: update_state": {"values": [], "sample_weight": []}, "KLDivergence: reset_states": {}, "KLDivergence: result": {}, "MeanAbsolutePercentageError": {"reduction": [0, null], "name": []}, "SensitivityAtSpecificity: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "RootMeanSquaredError: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "Precision: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanSquaredError: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanRelativeError: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanIoU: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanAbsoluteError: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "LogCoshError: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "KLDivergence: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanAbsolutePercentageError: reset_states": {}, "MeanAbsolutePercentageError: result": {}, "MeanAbsolutePercentageError: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "CategoricalHinge": {"reduction": [0, null], "name": []}, "CategoricalHinge: reset_states": {}, "CategoricalHinge: result": {}, "categorical_accuracy": {"y_true": [null], "y_pred": [null]}, "FalseNegatives": {"thresholds": [0, null], "name": [], "dtype": []}, "FalsePositives": {"thresholds": [0, null], "name": [], "dtype": []}, "CategoricalHinge: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "FalseNegatives: reset_states": {}, "FalseNegatives: result": {}, "FalsePositives: reset_states": {}, "FalsePositives: result": {}, "FalseNegatives: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "FalsePositives: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "Hinge": {"reduction": [0, null], "name": []}, "BinaryAccuracy": {"name": [null, "my_acc", "accuracy"], "dtype": [], "threshold": []}, "BinaryCrossentropy": {"from_logits": [false, true, null], "label_smoothing": [], "reduction": ["none"], "name": []}, "CategoricalCrossentropy": {"from_logits": [0, true, null], "label_smoothing": [0.1, null], "reduction": ["none", null], "name": []}, "binary_accuracy": {"y_true": [null], "y_pred": [null], "threshold": [0.5, null]}, "CosineSimilarity": {"axis": [0, null], "reduction": [null], "name": []}, "CategoricalAccuracy": {"name": ["train_accuracy", "acc", "accuracy", "my_acc", "test_accuracy"], "dtype": [null]}, "AUC": {"num_thresholds": [10000, 0, null], "curve": [null], "summation_method": [null], "name": ["auc"], "dtype": [], "thresholds": [], "multi_label": [], "label_weights": []}, "Hinge: reset_states": {}, "Hinge: result": {}, "BinaryAccuracy: reset_states": {}, "BinaryAccuracy: result": {}, "BinaryCrossentropy: reset_states": {}, "BinaryCrossentropy: result": {}, "CategoricalCrossentropy: reset_states": {}, "CategoricalCrossentropy: result": {}, "CosineSimilarity: reset_states": {}, "CosineSimilarity: result": {}, "CategoricalAccuracy: reset_states": {}, "CategoricalAccuracy: result": {}, "AUC: interpolate_pr_auc": {}, "AUC: reset_states": {}, "Hinge: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "BinaryAccuracy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "BinaryCrossentropy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "CategoricalCrossentropy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "CosineSimilarity: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "CategoricalAccuracy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "Accuracy": {"name": ["train_accuracy", 0, "acc", "accuracy", "test_accuracy", null], "dtype": [0.8, null]}, "squared_hinge": {"y_true": [null], "y_pred": [null]}, "AUC: result": {}, "AUC: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "sparse_categorical_crossentropy": {"target": [null], "output": [null], "from_logits": [false, true, null], "axis": [-1, null]}, "Accuracy: reset_states": {}, "SquaredHinge: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "SquaredHinge: from_config": {"config": []}, "SparseCategoricalCrossentropy: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "SparseCategoricalCrossentropy: from_config": {"config": []}, "Accuracy: result": {}, "Accuracy: update_state": {"y_true": [], "y_pred": [], "sample_weight": []}, "SquaredHinge: get_config": {}, "SparseCategoricalCrossentropy: get_config": {}, "poisson": {"y_true": [1.0, 1.5, null], "y_pred": [1.0, 100, null]}, "MSE": {"y_true": [null], "y_pred": [null]}, "MeanAbsolutePercentageError: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanAbsolutePercentageError: from_config": {"config": []}, "MeanSquaredLogarithmicError: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "MeanSquaredLogarithmicError: from_config": {"config": []}, "MeanSquaredError: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "MSLE": {"y_true": [], "y_pred": []}, "MeanAbsolutePercentageError: get_config": {}, "MeanSquaredLogarithmicError: get_config": {}, "MeanSquaredError: from_config": {"config": []}, "MeanAbsoluteError: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "MAPE": {"y_true": [], "y_pred": []}, "logcosh": {"y_true": [null], "y_pred": [null]}, "Loss": {"reduction": [0, "none", "batchmean", ["block5_conv4"], 10, ["block3_conv4"], ["block3_conv1"], "wing", null, "mean"], "name": ["giou_loss", true, "value", 100, "pin_1", "cl", "nl", null, "LM_loss"]}, "Huber": {"delta": [null], "reduction": [], "name": []}, "LogCosh": {"reduction": [null], "name": []}, "MAE": {"y_true": [null], "y_pred": [null]}, "MeanSquaredError: get_config": {}, "MeanAbsoluteError: from_config": {"config": []}, "MeanAbsoluteError: get_config": {}, "Poisson: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "Poisson: from_config": {"config": []}, "Loss: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "Loss: call": {"y_true": [], "y_pred": []}, "Huber: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "Huber: from_config": {"config": []}, "LogCosh: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "LogCosh: from_config": {"config": []}, "KLDivergence: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "KLDivergence: from_config": {"config": []}, "Poisson: get_config": {}, "Loss: from_config": {"config": []}, "Loss: get_config": {}, "Huber: get_config": {}, "LogCosh: get_config": {}, "hinge": {"y_true": [null], "y_pred": [null]}, "categorical_crossentropy": {"target": [0, null], "output": [0, null], "from_logits": [false, true, null], "axis": [-1, null]}, "categorical_hinge": {"y_true": [null], "y_pred": [null]}, "KLDivergence: get_config": {}, "CosineSimilarity: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "CosineSimilarity: from_config": {"config": []}, "Hinge: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "Hinge: from_config": {"config": []}, "CosineSimilarity: get_config": {}, "Hinge: get_config": {}, "cosine_similarity": {"y_true": [null], "y_pred": [null], "axis": [null]}, "TextVectorization": {"max_tokens": [null], "standardize": [], "split": [], "ngrams": [], "output_mode": ["int"], "output_sequence_length": [null], "pad_to_max_tokens": [], "**kwargs": []}, "TextVectorization: adapt": {"data": [], "reset_state": []}, "TextVectorization: get_vocabulary": {}, "PreprocessingLayer": {"trainable": [null], "name": [], "dtype": [], "dynamic": [], "**kwargs": []}, "binary_crossentropy": {"target": [0, null], "output": [0, null], "from_logits": [false, true, null]}, "BinaryCrossentropy: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "BinaryCrossentropy: from_config": {"config": []}, "ZeroPadding3D": {"padding": [[0, 1, 1], [2, 2, 2], 3, 1, 2, null]}, "BinaryCrossentropy: get_config": {}, "CategoricalCrossentropy: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "ZeroPadding2D": {"padding": [[0, 1], 1, 2, [[0, 1], [0, 1]], 3, [3, 3], [[3, 3], [3, 3]], [[1, 0], [1, 0]], [[1, 2], [2, 3]], [2, 2], [100, 100], null, [[0, 0], [1, 1]], [1, 1]]}, "Normalization": {"axis": [0, 1, 32, 3, 64, [0.8, 1.6], 4, 2, null, [0.5, 2.0], -1], "dtype": [0.456, null], "**kwargs": [null]}, "CategoricalCrossentropy: from_config": {"config": []}, "CategoricalCrossentropy: get_config": {}, "CategoricalHinge: __call__": {"y_true": [], "y_pred": [], "sample_weight": []}, "CategoricalHinge: from_config": {"config": []}, "ZeroPadding1D": {"padding": [1, 2, 3, null], "**kwargs": []}, "Wrapper": {"layer": [0, [0, 0, 0], null], "**kwargs": [256, 0, [0, 1], 4, null]}, "UpSampling3D": {"size": [[2, 2, 2], [2, 3, 4], null]}, "UpSampling2D": {"size": [[1, 2], 2, [16, 16], [32, 32], [2, 2], [4, 4], [8, 8], null]}, "TimeDistributed": {"layer": [null], "**kwargs": [null]}, "ThresholdedReLU": {"theta": [0.5, 1, null], "**kwargs": []}, "subtract": {"inputs": [0, 1.0, null], "**kwargs": [0.5, 1, 128.0, 0.75, 50.0, null, 127.5]}, "CategoricalHinge: get_config": {}, "UpSampling1D": {"size": [2, null], "**kwargs": []}, "SimpleRNN": {"units": [0, 1, 64, 128, 3, 5, 2, 7, 8, 4, 32, 10, null], "activation": ["tanh", "relu", null], "use_bias": [true, null], "kernel_initializer": [null], "recurrent_initializer": [null], "bias_initializer": [null], "kernel_regularizer": [null], "recurrent_regularizer": [null], "bias_regularizer": [null], "activity_regularizer": [null], "kernel_constraint": [null], "recurrent_constraint": [null], "bias_constraint": [null], "dropout": [0.5, 0.1, null], "recurrent_dropout": [null], "return_sequences": [false, true], "return_state": [false, true], "go_backwards": [], "stateful": [], "unroll": [false, true], "**kwargs": []}, "Subtract": {"**kwargs": [null]}, "StackedRNNCells": {"cells": [null], "**kwargs": [null]}, "SimpleRNNCell": {"units": [10, 3, 5, null], "activation": [], "use_bias": [], "kernel_initializer": [], "recurrent_initializer": [], "bias_initializer": [null], "kernel_regularizer": [], "recurrent_regularizer": [], "bias_regularizer": [], "kernel_constraint": [null], "recurrent_constraint": [null], "bias_constraint": [null], "dropout": [0.5, 0.1], "recurrent_dropout": [], "**kwargs": []}, "SimpleRNNCell: get_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "SimpleRNNCell: get_initial_state": {"inputs": [], "batch_size": [], "dtype": []}, "SpatialDropout3D": {"rate": [null], "data_format": [], "**kwargs": []}, "SimpleRNNCell: get_recurrent_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "SimpleRNNCell: reset_dropout_mask": {}, "SimpleRNNCell: reset_recurrent_dropout_mask": {}, "SeparableConv2D": {"filters": [128, 64, 32, 3, 5, 10, 16, null], "kernel_size": [[1, 2], 3, [3, 3], [1, 16], null], "strides": [1, 3, [1, 1], null]}, "SpatialDropout2D": {"rate": [0.1, 0.2, null], "data_format": [], "**kwargs": []}, "Softmax": {"axis": [1, 2, 3, 4, 1000, 8, 10, 17, 21, null, -1], "**kwargs": [null]}, "RNN": {"cell": [0, "test", 64, 128, 1, 32, 3, 7, 8, 10, "../github_crawler/tf_pyfiles", "LSTM", null], "return_sequences": [false, true, null], "return_state": [false, true, "RNN_1", null], "go_backwards": [256, null], "stateful": [1, null], "unroll": [true, null], "time_major": [null], "**kwargs": [null]}, "Reshape": {"target_shape": [[1024, 1, 1], [15, 15, 32], [-1, 3200], [-1, 2048], [4, 4, 1024], [-1], [3, 3, 384], [-1, 1], [1], [784], [2, 2], [1, 1], [128, 7, 7], [28, 28, 1], [200, 3200], [-1, 2], [7, 7, 256], [7, 7, 128], [2, 3], [12], [50, 50, 3], [0], [5, 10], [30, 1, 10], [10, 10, 3], [7, 7, 32], [720], null, [5, 2]], "**kwargs": [0, 1, 28, null]}, "RepeatVector": {"n": [2, 3, null], "**kwargs": []}, "SeparableConv1D": {"filters": [10, null], "kernel_size": [2, 3, null], "strides": [1, null], "padding": ["valid", null], "data_format": ["channels_last", null], "dilation_rate": [null], "depth_multiplier": [null], "activation": [null], "use_bias": [null], "depthwise_initializer": [null], "pointwise_initializer": [null], "bias_initializer": [null], "depthwise_regularizer": [], "pointwise_regularizer": [], "bias_regularizer": [], "activity_regularizer": [], "depthwise_constraint": [], "pointwise_constraint": [], "bias_constraint": [], "**kwargs": []}, "Minimum": {"**kwargs": [0, null]}, "ReLU": {"max_value": [0.1, true, 0, 0.5, 0.2, "prelu", 6.0, 0.01, "preact", null, 0.02], "negative_slope": [0.1, 0, 0.01, null], "threshold": [null], "**kwargs": [null]}, "PReLU": {"alpha_initializer": [0, "prelu", null], "alpha_regularizer": [null], "alpha_constraint": [null], "shared_axes": [null], "**kwargs": [null]}, "SpatialDropout1D": {"rate": [0.25, 0.2, null], "**kwargs": []}, "Permute": {"dims": [0, [3, 4, 1, 5, 2], [2, 1, 3], [2, 1], null, [2, 3, 1]], "**kwargs": [2]}, "minimum": {"x": [0.0, 1.0, 0.25, "value", 35, 5, 12.0, 15, 20, null, 1e-06, 255.0], "y": [0, 1.0, 0.99, 10000000000.0, 100, 5.0, 6, 0.9999999, 40, 300, 20.0, -1, null, 65535.0, 30, 255]}, "MaxPool3D": {"pool_size": [[2, 2, 2]]}, "MaxPool2D": {"pool_size": [1, 2, 3, [3, 3], [5, 5], null, [2, 1], [2, 2]]}, "maximum": {"x": [0, 1.0, 2, "value", 0.1, 100, 1e-05, 0.02857142857142857, 0.01, 1e-10, 1e-08, 20, null, 0.0001, 1e-06, -1.0], "y": [0.0, 1.0, 0.8, 0.25, 0.3, 2, 1e-36, 1e-08, 1e-20, 0.0001, -100.0, [1], 1e-12, 1e-06, 0.1, 1e-09, 1e-05, 1e-10, 0.01, -1.0, null, 1e-07, 0.001, 255.0]}, "LocallyConnected1D": {"filters": [32, null], "kernel_size": [3, null], "strides": [], "padding": [], "data_format": [], "activation": ["relu"], "use_bias": [], "kernel_initializer": [], "bias_initializer": [], "kernel_regularizer": [null], "bias_regularizer": [null], "activity_regularizer": [null], "kernel_constraint": ["max_norm"], "bias_constraint": ["max_norm"], "implementation": [], "**kwargs": []}, "MaxPool1D": {"pool_size": [3, null], "strides": [null], "padding": [null], "data_format": [], "**kwargs": []}, "LSTMCell": {"units": [128, 64, 2, 256, 32, 1, 5, 3, 10, 80, 16, null], "activation": [51, null], "recurrent_activation": [null], "use_bias": [false, null], "kernel_initializer": [null], "recurrent_initializer": [null], "bias_initializer": [null], "unit_forget_bias": [], "kernel_regularizer": [], "recurrent_regularizer": [], "bias_regularizer": [], "kernel_constraint": [], "recurrent_constraint": [], "bias_constraint": [], "dropout": [0.5, 0.1], "recurrent_dropout": [0.1], "implementation": [null], "**kwargs": []}, "LSTM": {"units": [0, 256, 128, 512, 4, 2048, 1, 3, 8, 2, 10, 5, 16, 20, 32, 50, [2, 2], 64, 200, 100, null], "activation": [64, 0, 3, "relu", 20, null, "tanh"], "recurrent_activation": [1, "sigmoid", 3, null], "use_bias": [true, null], "kernel_initializer": ["glorot_uniform", null], "recurrent_initializer": [null], "bias_initializer": ["random_normal", null], "unit_forget_bias": [null], "kernel_regularizer": [0, null], "recurrent_regularizer": [0, null], "bias_regularizer": [0, null], "activity_regularizer": [0, null], "kernel_constraint": [null], "recurrent_constraint": [null], "bias_constraint": [null], "dropout": [0.0, 0.5, 0.1, 0.2, null], "recurrent_dropout": [0.1, 0.25, 0.2, null], "implementation": [null], "return_sequences": [false, true, null], "return_state": [true], "go_backwards": [true], "stateful": [true, null], "time_major": [false], "unroll": [true], "**kwargs": []}, "LocallyConnected2D": {"filters": [16, 32, null], "kernel_size": [null, [9, 9], [3, 3]], "strides": []}, "LSTMCell: get_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "LSTMCell: get_initial_state": {"inputs": [], "batch_size": [], "dtype": []}, "LSTM: get_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "LSTM: get_recurrent_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "Masking": {"mask_value": [0.0, 10, -1, null], "**kwargs": [20, null]}, "Maximum": {"**kwargs": [0, 100, null]}, "LSTMCell: get_recurrent_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "LSTMCell: reset_dropout_mask": {}, "LSTM: reset_dropout_mask": {}, "LSTM: reset_recurrent_dropout_mask": {}, "InputLayer": {"input_shape": [[0, 0], [0], [28, 28, 1], [32], [128], [28, 28], [0, 0, 1], [8], [120, 120, 3], [784], [8, 8, 2], null], "batch_size": [10, null], "dtype": [10, null], "input_tensor": [null], "sparse": [], "name": ["squeeze_layer", "speech", "g_inputz", "in", "words", "input_layer", null, "input", "input_ids", "inputs"], "ragged": [], "**kwargs": []}, "LayerNormalization": {"axis": [2, null], "epsilon": [1e-12, 1e-08, 1e-06, null], "center": [null], "scale": [], "beta_initializer": [null], "gamma_initializer": [null], "beta_regularizer": [], "gamma_regularizer": [], "beta_constraint": [], "gamma_constraint": [], "trainable": [null], "name": ["MLM-Norm", "layer_norm_emb", null, "layer_norm", "LayerNorm", "ln_1", "Embedding-Norm", "layernorm1"], "**kwargs": []}, "Layer": {"trainable": [0, 512, 2, [0, 0], true, 3, 0.2, 4, "SOFTMAX", "CONCAT", "ARGMAX", "Input", "SUM", [], 20, "ReLU", null, "word_emb"], "name": ["last_layer", 1, 0, "", 3, "data", 8, 10, "transformer_output", "adjacency", "caps", "src", 16, "input_layer", 25, "routing_layer", "input_ids", "concat_layer", "speech", "conv_1_1", "in", "inpad", "CrossEntropy", "user_advaced", "input", "src1", "out", "g/h1/decon2d", "test_pool2d", "g_inputz", "foo", "conv2dlayer", "GCN", "attention_layer", "skipLayer", "drop1", [4, 2], ":i", "inputs", "conv1_1", "crfrnn", "cropping_input", "conv_input", "digitcaps", "L1", "words", "dense_lrelu", "transformer", [], null], "dtype": [64, 0, "sigmoid", 2, 7, 10, null, -1, "image-list"], "dynamic": [[], 3, 4, null], "**kwargs": ["ConvLayer1", 3, null]}, "LeakyReLU": {"alpha": [0.2, 0, 0.1, 1, 0.01, null, 0.02], "**kwargs": [true, null]}, "GRU": {"units": [64, 0, 1, 128, 4, 256, 3, 32, 8, 2, 100, 10, 20, null], "activation": [64, "tanh", null], "recurrent_activation": ["relu", "linear_input", null], "use_bias": [true, "bidirectional", null], "kernel_initializer": ["he_normal", null], "recurrent_initializer": ["glorot_uniform", null], "bias_initializer": [null], "kernel_regularizer": [null], "recurrent_regularizer": [null], "bias_regularizer": [null], "activity_regularizer": [null], "kernel_constraint": ["max_norm", null], "recurrent_constraint": ["max_norm", null], "bias_constraint": ["max_norm", null], "dropout": [0.0, 0.5, 0.3, 0.9, null], "recurrent_dropout": [0.2, null], "implementation": [], "return_sequences": [false, true], "return_state": [true], "go_backwards": [], "stateful": [null], "unroll": [true], "time_major": [], "reset_after": [false, true], "**kwargs": []}, "GRUCell": {"units": [64, 1, 2, 3, 4, 5, 8, 10, null, 24, 30], "activation": [0, 1, null], "recurrent_activation": [null], "use_bias": [null], "kernel_initializer": [null], "recurrent_initializer": [], "bias_initializer": [null], "kernel_regularizer": [null], "recurrent_regularizer": [], "bias_regularizer": [null], "kernel_constraint": [null], "recurrent_constraint": [], "bias_constraint": [null], "dropout": [0.5, 0.1], "recurrent_dropout": [], "implementation": [], "reset_after": [], "**kwargs": []}, "LSTMCell: reset_recurrent_dropout_mask": {}, "Lambda": {"function": [0, null], "output_shape": [0, [1], [200], [], null], "mask": [null], "arguments": [0, null], "**kwargs": [null]}, "InputSpec": {"dtype": [0, "int32", null], "shape": [null], "ndim": [2, 3, 4, 5, null], "max_ndim": [5], "min_ndim": [2, 3], "axes": [null]}, "LSTM: reset_states": {"states": []}, "Layer: __call__": {"inputs": [], "*args": [], "**kwargs": []}, "Layer: add_loss": {"losses": [], "inputs": []}, "GRU: get_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "GRU: get_recurrent_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "GRUCell: get_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "GRUCell: get_initial_state": {"inputs": [], "batch_size": [], "dtype": []}, "InputSpec: from_config": {"config": []}, "Layer: add_metric": {"value": [], "aggregation": [], "name": []}, "Layer: add_update": {"updates": [], "inputs": []}, "GRU: reset_dropout_mask": {}, "GRU: reset_recurrent_dropout_mask": {}, "GRUCell: get_recurrent_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "GRUCell: reset_dropout_mask": {}, "Layer: add_weight": {"name": [], "shape": [], "dtype": [], "initializer": [], "regularizer": [], "trainable": [], "constraint": [], "partitioner": [], "use_resource": [], "synchronization": [], "aggregation": [], "**kwargs": []}, "Layer: build": {"input_shape": []}, "GRU: reset_states": {"states": []}, "GRUCell: reset_recurrent_dropout_mask": {}, "Layer: call": {"inputs": [], "**kwargs": []}, "Layer: compute_mask": {"inputs": [], "mask": []}, "GlobalMaxPool3D": {"data_format": ["channels_last"], "**kwargs": []}, "GlobalMaxPool2D": {"data_format": ["channels_last", null], "**kwargs": []}, "GlobalMaxPool1D": {"data_format": [null], "**kwargs": []}, "GlobalAveragePooling3D": {"data_format": [null], "**kwargs": [null]}, "GlobalAveragePooling2D": {"data_format": ["channels_last", null], "**kwargs": [null]}, "Layer: compute_output_shape": {"input_shape": []}, "Layer: compute_output_signature": {"input_signature": []}, "GlobalAveragePooling1D": {"data_format": ["channels_first", null], "**kwargs": [null]}, "Layer: count_params": {}, "Layer: from_config": {"config": []}, "Layer: get_config": {}, "Layer: get_input_at": {"node_index": []}, "Layer: get_input_mask_at": {"node_index": []}, "Layer: get_input_shape_at": {"node_index": []}, "Layer: get_losses_for": {"inputs": []}, "Layer: get_output_at": {"node_index": []}, "Layer: get_output_mask_at": {"node_index": []}, "Layer: get_output_shape_at": {"node_index": []}, "Layer: get_updates_for": {"inputs": []}, "Layer: get_weights": {}, "Layer: set_weights": {"weights": []}, "dot": {"x": [0, "../github_crawler/tf_pyfiles", null], "y": [0.587, 0, "../github_crawler/tf_pyfiles", null, -1, 255]}, "GaussianNoise": {"stddev": [0.2, 0, 0.3, 0.1, 0.01, null], "**kwargs": [null]}, "GaussianDropout": {"rate": [0.1, 0.5, null], "**kwargs": []}, "Flatten": {"data_format": ["flatten", "ft", "channels_last", null], "**kwargs": [null]}, "ELU": {"alpha": [0.075, 1, null], "**kwargs": [null]}, "Dropout": {"rate": [0.25, 0.3, 0.2, 0.4, 0.5, [0.0, 0.1], 0.9, 0.8, 0.75, 0.7, "drop", 0, 1.0, 0.35, 0.6, 0.05, 0.19999999999999996, "drop0", "qDropout", "dropout", 0.1, "Dropout_1b", 0.02, 0.999, null], "noise_shape": [null], "seed": [0.5, 4444, null], "**kwargs": [null]}, "Dot": {"axes": [0, 1, -1, null], "normalize": [null], "**kwargs": [null]}, "Dense": {"units": [512, 1024, 2, 128, 1, 3, 5, 256, 8, 4608, 10, 4, 1164, 384, 4096, 0, 16, 400, 12544, 15, 16384, 32, 800, 7, 300, 50, 64, 2048, 5000, 6272, 200, 7800, 7500, 84, 225, 100, 1000, 360, 3456, 625, 500, null, 120, 123], "activation": [0, 512, "sigmoid", 3, 1024, "softmax", "linear", "relu", "elu", 16, null, "tanh"], "use_bias": [false, true, 384, 256, null], "kernel_initializer": ["one", "ones", "glorot_normal", "normal", "orthogonal", null, "he_normal", "glorot_uniform"], "bias_initializer": ["zeros", 0, "glorot_uniform", null], "kernel_regularizer": ["MyObject", null], "bias_regularizer": [0, "l1", null], "activity_regularizer": [0, null], "kernel_constraint": [0, "weight_clip", "max_norm", null], "bias_constraint": [0, "max_norm", null], "**kwargs": []}, "Embedding": {"input_dim": [256, 0, 32, 1, 100, 5, 4, "action", 1000, 300000, 10, "group1_embedding_wide", "Embedding", 10000, 50001, null, 3001, 27], "output_dim": [128, 1, 2, 3, 4, 512, 6, 5, 256, 10, 15, 16, "group1", 32, 300, 50, 64, 100, null], "embeddings_initializer": [1, "glorot_normal", "group1_embedding_wide", null], "embeddings_regularizer": ["dec_pos", null], "activity_regularizer": [4, null], "embeddings_constraint": ["max_norm", null], "mask_zero": [false, true, null], "input_length": [1, 2, 100, 6, 10, 400, 20, null], "**kwargs": []}, "Cropping3D": {"cropping": [[[0, 0], [50, 10], [0, 0]], null]}, "Cropping2D": {"cropping": [2, [5, 5], [[1, 0], [1, 0]], [[60, 0], [0, 0]], null, [[10, 0], [0, 0]]]}, "Cropping1D": {"cropping": [[2, 3], null]}, "DepthwiseConv2D": {"kernel_size": [3, [3, 3], null, [7, 7], [2, 2]], "strides": [1, 2, [3, 3], null, [1, 1]]}, "DenseFeatures": {"feature_columns": [null], "trainable": [null], "name": [null], "**kwargs": []}, "ConvLSTM2D": {"filters": [2, 5, 40, 10, null], "kernel_size": [3, [3, 3], [5, 5]], "strides": [3]}, "Conv3DTranspose": {"filters": [3, null], "kernel_size": [3, null], "strides": [null]}, "Conv3D": {"filters": [32, 1, 64, 3, 5, 16, null], "kernel_size": [[3, 3, 3], 3, [7, 7], [3, 3, 4], null, [1, 1, 1]], "strides": [[2, 2], [1, 3, 3], null]}, "Conv2D": {"filters": [256, 128, 0, 3, 4, "conv1x1", 6, 2, 8, 1024, 10, "lateral_1x1_c2", "c3x3a", 1, 5, 16, 512, 24, 25, 32, "conv1", "convshortcut", 64, 192, "convfc", 75, "conv0", 96, "conv1_1", "conv1.1", null], "kernel_size": [1, 2, 3, 4, 5, [11, 11], 7, 8, 11, [7, 7], 20, 24, [3, 7], 32, [3, 3], [5, 5], [11, 5], [4, 4], 48, [2, 2], [1, 1], 64, [7, 1], [2, 3], 96, [9, 9], [8, 8], [4, 3], null, [3, 4]], "strides": [32, 1, 2, 3, 4, 5, 512, 7, 8, [2, 2], [4, 4], 12, [2, 1], null, [1, 1]]}, "Conv2DTranspose": {"filters": [128, 1, 256, 3, 64, 32, 192, 2, 5, "deconv0", 16, "deconv1", 21, null, "deconv"], "kernel_size": [64, 2, 3, 4, [5, 5], [3, 3], 5, [2, 2], [4, 4], null], "strides": [128, 1, 2, 3, 64, 32, [2, 2], null, [1, 1]]}, "Conv1D": {"filters": [128, 1, 64, 3, 32, 5, 10, null, 30], "kernel_size": [1, 2, 3, 5, 7, 8, 10, [3], [7, 7], null], "strides": [1, [2, 2], null], "padding": ["valid", "same", "VALID", null, "SAME"], "data_format": [null], "dilation_rate": [1, null], "activation": [0, "relu", "elu", null, "tanh"], "use_bias": [false, true, null], "kernel_initializer": ["he_uniform", "glorot_uniform", null], "bias_initializer": [0, null], "kernel_regularizer": [null], "bias_regularizer": [0, null], "activity_regularizer": [null], "kernel_constraint": ["max_norm", null], "bias_constraint": [0, "max_norm"], "**kwargs": []}, "concatenate": {"tensors": [0, 1, [0], [1], "X", null], "axis": [0, 1, 2, 3, 4, -2, null, -3, -1]}, "Concatenate": {"axis": [0, 1, 2, 3, null, -1], "**kwargs": [null]}, "AveragePooling3D": {"pool_size": [[2, 2, 2], [2, 1, 1], null]}, "Attention": {"use_scale": [0.0, "AttLSTM", 32, 256, 512, 5, 128, 64, 8, 12, 16, null, "ptr"], "**kwargs": [64, 0, 4, null]}, "Average": {"**kwargs": [0.999, 0.0, 0.9, 0.5, 0.997, 0.1, 0.9999, 0.99, 0.95, "average_train_loss", null, "average_train_gen_loss"]}, "AveragePooling2D": {"pool_size": [0, 1, 2, 3, 4, [3, 3], 7, 8, [2, 2], 9, 11, [7, 7], 13, [1, 4], [1, 5], [8, 8], null, 28]}, "average": {"inputs": [0, null], "**kwargs": [0, "value", null]}, "Bidirectional": {"layer": [null], "merge_mode": [0, "sum", "concat", null], "weights": [null], "backward_layer": [], "**kwargs": []}, "BatchNormalization": {"axis": [0, 1, 32, 3, 64, 4, null, -1], "momentum": [0.999, 0.9, 0.8, 0.99, 0.1, 0.95, 0.0, 0.995, null], "epsilon": [0, 1.1e-05, 1e-05, 1.001e-05, null, 1e-06, 0.001], "center": [0, true, null], "scale": [false, true, null], "beta_initializer": [null], "gamma_initializer": ["uniform", null], "moving_mean_initializer": [null], "moving_variance_initializer": [null], "beta_regularizer": [null], "gamma_regularizer": [null], "beta_constraint": ["max_norm", null], "gamma_constraint": ["max_norm", null], "renorm": [true, null], "renorm_clipping": [null], "renorm_momentum": [null], "fused": [true, null], "trainable": [false, true, null], "virtual_batch_size": [null], "adjustment": [null], "name": ["inter_.1.1", "bn1", "rcnn_class_bn1", "g_dense1_bn", "stem_bn1", "BatchNormalization", "dense1_bn", "batch_norm", "Conv2d_1a_3x3_BatchNorm", "bn_conv1", "{}", null, "block1_conv1_bn", "bn", "Encoder-Batchnorm-1", "input_batchnorm"], "**kwargs": []}, "AlphaDropout": {"rate": [0.1, 0.5, null], "noise_shape": [], "seed": [5, null], "**kwargs": []}, "AveragePooling1D": {"pool_size": [2, null], "strides": [null], "padding": [], "data_format": ["channels_first"], "**kwargs": []}, "add": {"inputs": [0, 1, 2, "octave", 4, "", 3, "full", "Repair", 10, "guid_0", "flip_ratio", ["null"], "expanded", "label1", "test.txt", "#", "label0", "key4", "../github_crawler/tf_pyfiles/shekit__alexa-sign-language-translator.csv", "content-length", "train", "toto", ["foo.txt"], "Conv", ["patch.txt"], "ConvReLU", ".directory", ["camera/arr"], "mediawiki", ["simple_value", "valid_loss"], "value", "preview", "key3", "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", "below", "label_0", "-", "a", "task_id", "ReLU", ["cam/image_array"], "url", [0], "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)", "c", "cat0", "../github_crawler/tf_pyfiles", [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9]], "link_checker", ["README"], "-e", "troisdorf_000000_000073", [], -3.0, null, "options", "x", "TEST", "../github_crawler/tf_pyfile"], "**kwargs": [0, 1, 2.0, 0.5, -128.0, 5, -0.5, 3.0, [["file_fraction_already_exists", 1]], -127.5, "--env-id", "dummy_sample_id", 13.0, 23, 25, "rollTask", "sample_id", [1.0], 41, "add", 1e-12, 0.1, -0.1, "value", "10", [2.0], null]}, "AdditiveAttention": {"use_scale": [], "**kwargs": []}, "Add": {"**kwargs": [[-10, 10], [-7, 7], null]}, "ActivityRegularization": {"l1": [0.1, 2, 0.01, null], "l2": [0.01, null], "**kwargs": []}, "Activation": {"activation": [0, "sigmoid", "softmax", "V", "linear", "relu", "elu", "softplus", "ste_sign", "{}", null, "tanh", "hard_tanh"], "**kwargs": [null]}, "AbstractRNNCell": {"trainable": [], "name": [], "dtype": [], "dynamic": [], "**kwargs": []}, "VarianceScaling": {"scale": [0.3333333333333333, 1.0, 2.0, 0, 6.0, null, 0.02], "mode": ["fan_in", "fan_out", "fan_avg"], "distribution": ["normal", "untruncated_normal", null, "truncated_normal", "uniform"], "seed": [null]}, "TruncatedNormal": {"mean": [0, 0.5413248, null], "stddev": [0.1, 1, 1e-05, null], "seed": [126]}, "VarianceScaling: __call__": {"shape": [], "dtype": []}, "VarianceScaling: from_config": {"config": []}, "TruncatedNormal: __call__": {"shape": [], "dtype": []}, "TruncatedNormal: from_config": {"config": []}, "TruncatedNormal: get_config": {}, "Orthogonal": {"gain": [0.2, 1.0, 0, 0.01, null], "seed": [123, null]}, "lecun_uniform": {"seed": [0, null]}, "VarianceScaling: get_config": {}, "Orthogonal: __call__": {"shape": [], "dtype": []}, "Orthogonal: from_config": {"config": []}, "Orthogonal: get_config": {}, "he_normal": {"seed": [0, 42, null]}, "lecun_normal": {"seed": [0, null]}, "Initializer": {"shape": [0, 1.0, [0], 0.01, null], "dtype": [[10], [], null]}, "Identity": {"gain": [0, 1.0, 2, "decoder", "../github_crawler/tf_pyfiles", null]}, "GlorotNormal": {"seed": [0, null]}, "Initializer: __call__": {"shape": [], "dtype": []}, "Initializer: from_config": {"config": []}, "Identity: __call__": {"shape": [], "dtype": []}, "Identity: from_config": {"config": []}, "GlorotNormal: __call__": {"shape": [], "dtype": []}, "GlorotNormal: from_config": {"config": []}, "he_uniform": {"seed": [0, 50, null]}, "GlorotUniform": {"seed": [0, null]}, "Initializer: get_config": {}, "Identity: get_config": {}, "GlorotNormal: get_config": {}, "GlorotUniform: __call__": {"shape": [], "dtype": []}, "GlorotUniform: from_config": {"config": []}, "WideDeepModel": {"linear_model": [], "dnn_model": [], "activation": [], "**kwargs": []}, "SequenceFeatures": {"feature_columns": [], "trainable": [], "name": [], "**kwargs": []}, "PeepholeLSTMCell": {"units": [10], "activation": [], "recurrent_activation": [], "use_bias": [], "kernel_initializer": [], "recurrent_initializer": [], "bias_initializer": [], "unit_forget_bias": [], "kernel_regularizer": [], "recurrent_regularizer": [], "bias_regularizer": [], "kernel_constraint": [], "recurrent_constraint": [], "bias_constraint": [], "dropout": [], "recurrent_dropout": [], "implementation": [], "**kwargs": []}, "NoisyLinearCosineDecay": {"initial_learning_rate": [null], "decay_steps": [null], "initial_variance": [null], "variance_decay": [null], "num_periods": [null], "alpha": [null], "beta": [null], "name": []}, "terminate_keras_multiprocessing_pools": {"grace_period": [], "use_sigkill": []}, "LinearModel": {"units": [0, null], "activation": [null], "use_bias": [null], "kernel_initializer": [null], "bias_initializer": [null], "kernel_regularizer": [null], "bias_regularizer": [null], "**kwargs": [null]}, "GlorotUniform: get_config": {}, "WideDeepModel: compile": {"optimizer": [], "loss": [], "metrics": [], "loss_weights": [], "sample_weight_mode": [], "weighted_metrics": [], "target_tensors": [], "distribute": [], "**kwargs": []}, "WideDeepModel: evaluate": {"x": [], "y": [], "batch_size": [], "verbose": [], "sample_weight": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": []}, "PeepholeLSTMCell: get_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "PeepholeLSTMCell: get_initial_state": {"inputs": [], "batch_size": [], "dtype": []}, "NoisyLinearCosineDecay: __call__": {"step": []}, "LinearModel: compile": {"optimizer": [], "loss": [], "metrics": [], "loss_weights": [], "sample_weight_mode": [], "weighted_metrics": [], "target_tensors": [], "distribute": [], "**kwargs": []}, "WideDeepModel: evaluate_generator": {"generator": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "verbose": []}, "WideDeepModel: fit": {"x": [], "y": [], "batch_size": [], "epochs": [], "verbose": [], "callbacks": [], "validation_split": [], "validation_data": [], "shuffle": [], "class_weight": [], "sample_weight": [], "initial_epoch": [], "steps_per_epoch": [], "validation_steps": [], "validation_freq": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "**kwargs": []}, "LinearCosineDecay": {"initial_learning_rate": [null], "decay_steps": [null], "num_periods": [null], "alpha": [null], "beta": [null], "name": []}, "CosineDecayRestarts": {"initial_learning_rate": [null], "first_decay_steps": [null], "t_mul": [null], "m_mul": [null], "alpha": [null], "name": []}, "PeepholeLSTMCell: get_recurrent_dropout_mask_for_cell": {"inputs": [], "training": [], "count": []}, "PeepholeLSTMCell: reset_dropout_mask": {}, "NoisyLinearCosineDecay: from_config": {"config": []}, "NoisyLinearCosineDecay: get_config": {}, "LinearModel: evaluate": {"x": [], "y": [], "batch_size": [], "verbose": [], "sample_weight": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": []}, "WideDeepModel: fit_generator": {"generator": [], "steps_per_epoch": [], "epochs": [], "verbose": [], "callbacks": [], "validation_data": [], "validation_steps": [], "validation_freq": [], "class_weight": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "shuffle": [], "initial_epoch": []}, "WideDeepModel: get_layer": {"name": [], "index": []}, "LinearCosineDecay: __call__": {"step": []}, "LinearCosineDecay: from_config": {"config": []}, "CosineDecayRestarts: __call__": {"step": []}, "CosineDecayRestarts: from_config": {"config": []}, "PeepholeLSTMCell: reset_recurrent_dropout_mask": {}, "LinearModel: evaluate_generator": {"generator": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "verbose": []}, "LinearModel: fit": {"x": [], "y": [], "batch_size": [], "epochs": [], "verbose": [], "callbacks": [], "validation_split": [], "validation_data": [], "shuffle": [], "class_weight": [], "sample_weight": [], "initial_epoch": [], "steps_per_epoch": [], "validation_steps": [], "validation_freq": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "**kwargs": []}, "WideDeepModel: load_weights": {"filepath": [], "by_name": [], "skip_mismatch": []}, "WideDeepModel: predict": {"x": [], "batch_size": [], "verbose": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": []}, "LinearCosineDecay: get_config": {}, "CosineDecay": {"initial_learning_rate": [null], "decay_steps": [null], "alpha": [0.0, null], "name": []}, "CosineDecayRestarts: get_config": {}, "LinearModel: fit_generator": {"generator": [], "steps_per_epoch": [], "epochs": [], "verbose": [], "callbacks": [], "validation_data": [], "validation_steps": [], "validation_freq": [], "class_weight": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "shuffle": [], "initial_epoch": []}, "LinearModel: get_layer": {"name": [], "index": []}, "WideDeepModel: predict_generator": {"generator": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "verbose": []}, "WideDeepModel: predict_on_batch": {"x": []}, "CosineDecay: __call__": {"step": []}, "CosineDecay: from_config": {"config": []}, "LinearModel: load_weights": {"filepath": [], "by_name": [], "skip_mismatch": []}, "LinearModel: predict": {"x": [], "batch_size": [], "verbose": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": []}, "WideDeepModel: reset_metrics": {}, "model_to_estimator": {"keras_model": [null], "keras_model_path": [], "custom_objects": [], "model_dir": ["models/estimator-for-XOR/", null], "config": [null], "checkpoint_format": []}, "CosineDecay: get_config": {}, "LinearModel: predict_generator": {"generator": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "verbose": []}, "LinearModel: predict_on_batch": {"x": []}, "WideDeepModel: reset_states": {}, "LinearModel: reset_metrics": {}, "LinearModel: reset_states": {}, "WideDeepModel: save": {"filepath": [], "overwrite": [], "include_optimizer": [], "save_format": [], "signatures": [], "options": []}, "WideDeepModel: save_weights": {"filepath": [], "overwrite": [], "save_format": []}, "LinearModel: save": {"filepath": [], "overwrite": [], "include_optimizer": [], "save_format": [], "signatures": [], "options": []}, "WideDeepModel: summary": {"line_length": [], "positions": [], "print_fn": []}, "LinearModel: save_weights": {"filepath": [], "overwrite": [], "save_format": []}, "WideDeepModel: test_on_batch": {"x": [], "y": [], "sample_weight": [], "reset_metrics": []}, "LinearModel: summary": {"line_length": [], "positions": [], "print_fn": []}, "WideDeepModel: to_json": {"**kwargs": []}, "LinearModel: test_on_batch": {"x": [], "y": [], "sample_weight": [], "reset_metrics": []}, "LinearModel: to_json": {"**kwargs": []}, "WideDeepModel: to_yaml": {"**kwargs": []}, "WideDeepModel: train_on_batch": {"x": [], "y": [], "sample_weight": [], "class_weight": [], "reset_metrics": []}, "LinearModel: to_yaml": {"**kwargs": []}, "LinearModel: train_on_batch": {"x": [], "y": [], "sample_weight": [], "class_weight": [], "reset_metrics": []}, "load_data": {}, "get_word_index": {"path": ["reuters_word_index.json", "imdb_word_index.json", "word", null]}, "RadialConstraint": {"w": []}, "MinMaxNorm": {"min_value": [null], "max_value": [], "rate": [], "axis": []}, "RadialConstraint: __call__": {"w": []}, "MinMaxNorm: __call__": {"w": []}, "MaxNorm": {"max_value": [1, null], "axis": []}, "UnitNorm": {"axis": [null]}, "TerminateOnNaN": {}, "NonNeg": {"w": [null]}, "Constraint": {"w": [0, "id", null]}, "MaxNorm: __call__": {"w": []}, "UnitNorm: __call__": {"w": []}, "TerminateOnNaN: set_model": {"model": []}, "NonNeg: __call__": {"w": []}, "Constraint: __call__": {"w": []}, "RemoteMonitor": {"root": [null], "path": [], "field": [], "headers": [], "send_as_json": []}, "ProgbarLogger": {"count_mode": ["steps", null], "stateful_metrics": [null]}, "ModelCheckpoint": {"filepath": ["/tmp/checkpoint.h5", "weights/RoR-WRN-40-2-Weights.h5", "model-{epoch:03d}.h5", "WRN-28-8 Weights.h5", "weights_train/weights.{epoch:02d}-{loss:.2f}.h5", "weights/temp_network.h5", "weights/mobilenet_weights.h5", "./ckpt.h5", "../github_crawler/tf_pyfiles/shekit__alexa-sign-language-translator.csv", "weights/inception_resnet_pretrained_weights.h5", "intent_weights.h5", "/Users/xiaofeng/Code/Github/dataset/CHINESE_OCR/save_model/my_model_keras.h5", "/home/blue/Documents/api-representation-learning/commons", "weights/nasnet_pretrained_weights.h5", "FCN8s.h5", "weights/nasnet_weights.h5", "weights/nasnet_large_pretrained_weights.h5", "data/checkpoints/inception.{epoch:03d}-{val_loss:.2f}.hdf5", "./checkpoints", "../trainer", "/home/stratospark/Code/AI/food101/first.3.{epoch:02d}-{val_loss:.2f}.hdf5", "./checkpoint-{epoch}.h5", "networks/models/capsnet.h5", "./logs/weights.epoch.{epoch:02d}-val_loss.{val_loss:.2f}.hdf5", "save_model/model{epoch:02d}-{val_loss:.4f}.hdf5", "weights.{epoch:03d}-{val_acc:.4f}.hdf5", "weights/nasnet_large_weights.h5", "entity_weights.h5", null, "checkpoints/yolov3_train_{epoch}.tf", "./ckpt_senet.h5", "weights/inception_resnet_weights.h5"], "monitor": ["val_mean_io_u", "val_loss", "loss", "val_exp_rmspe", "val_categorical_accuracy", "val_accuracy", null, "val_predictions_acc", "val_acc"], "verbose": [0, 1, null], "save_best_only": [false, true, null], "save_weights_only": [false, true], "mode": ["min", "max", "auto", null], "save_freq": [1], "**kwargs": []}, "RemoteMonitor: set_model": {"model": []}, "ProgbarLogger: set_model": {"model": []}, "ModelCheckpoint: set_model": {"model": []}, "TensorBoard": {"log_dir": ["out/logs", "./logs/cnn_v2/", "./TensorBoard", "./lenet", "autoencoder", "./logs/cnn_lstm/", "./lenet_dp_da", "/home/blue/Documents/api-representation-learning/commons", "./densenet/", "./lenet_dp", "./logs", "logs", "data/logs", "./resnext/", null, "./logs/lstm/", "./senet/", "./logs/09_tensorboard", "./lenet_dp_da_wd"], "histogram_freq": [0, true, 5, null], "write_graph": [false, true], "write_images": [false, true], "update_freq": ["batch", 100, null], "profile_batch": [0], "embeddings_freq": [0], "embeddings_metadata": [0], "**kwargs": []}, "ReduceLROnPlateau": {"monitor": ["val_loss", "loss", "val_exp_rmspe", "val_categorical_accuracy", "val_accuracy", null], "factor": [0.3162, 0.707, 0.2, 0.5, 0.1, 0.99, null], "patience": [0, 1, 2, 3, 4, 5, 6, 100, 8, 10, null], "verbose": [0, 1, 2, null], "mode": ["min", "max", "auto", null], "min_delta": [0.0001, null], "cooldown": [0, null], "min_lr": [0, 1e-05, 1e-08, 5e-06, null, 0.0001, 5e-07], "**kwargs": [null]}, "LearningRateScheduler": {"schedule": [0, null], "verbose": [1, null]}, "LambdaCallback": {"on_epoch_begin": [null], "on_epoch_end": [null], "on_batch_begin": [], "on_batch_end": [null], "on_train_begin": [], "on_train_end": [0], "**kwargs": []}, "TensorBoard: set_model": {"model": []}, "ReduceLROnPlateau: in_cooldown": {}, "ReduceLROnPlateau: set_model": {"model": []}, "LearningRateScheduler: set_model": {"model": []}, "LambdaCallback: set_model": {"model": []}, "History": {}, "History: set_model": {"model": []}, "Callback": {}, "BaseLogger": {"stateful_metrics": [0, null]}, "zeros_like": {"x": [0, "value", null], "dtype": [0, 2, "float32", null, "int32", "int", "int64"], "name": [0, "iter", "rn", "GO", null, "groups"]}, "variable": {"value": [0, 1.0, 2.0, "lookup_table", "v_att", "prior", "qU/loc", "qgamma/params", "act_mask", "decoder_embedding", "linear_mapping_w", "proj_w_out", "embedding_matrix", "user_embeddings", "char_embedding_matrix", "CvK", "row_embedding", "logstd", "init_fw_h", "qw/loc", "W_r", "char_embed", "bos_token_embedding", "central_bias", "../github_crawler/tf_pyfiles/shekit__alexa-sign-language-translator.csv", "before_softplus_std", "w_h", "W_a", "v0", "DW", "num_writes_counter", "attention_g", "G_fcW1", "kernel", "lstm_params", "concat_x", "value", "gain", "key_matrix", "foo", "E", "w_source_embedding", "p2s_weights_w", "state_embeddings_0", "conv1_w", "order_embeddings", "topk", "in_img", "beta", "w_f_diag", "global_step", "B", "affine_bias", "r_w_bias", "W_xh", "steps_since_last_sync", "Weight", "weight0", "fc_w", "W", "local_ema_step", "W_embed", "embedding", "alpha", "ip", "resnet_v1_50/mean_rgb", "transformation_matrix", "d_wconv1", "offset", "att_beta", "x", "adanet_loss", "qstudents/loc", "V_sentence", "W_fullyconn", "output_bias", "W_conv1", "W_1", "iteration_number", "Wp", "lr", "entropy_beta", "Matrix", "qp/params", "W_h", "conv1_rgb", "w_ru", "input_kernel", "meanless-name", "exemplar", "W4", "kernels", "coverage_matrix", "step", "q/kernel", "temperature", "affine", "W_z", "W_p", "counter", "imgs_mean", "var1", "initial_log_alpha", "layer1_filter", "alphas", "/w", "attention_v", "conv0_b", "word_emb_mat", "weight_mean", "transitions", "var_1", "weights", "embedding_encoder", "forward_full_matching_params", "W_u_Q", "w0", "w1", "a", "weights_arc", "predicate_output_weights", "softmax_w", "state", "metadata_service_timeout", "word_emb", "qz/params", "v_a", "gamma", "enc_embedding", "v1", "b", "z", "qpi/concentration", "input_bias", "initial_cell_state", null, "embed_matrix", "Wo", "centers", "weight", "logger", "o_W_c", "input_gate_kernel", "biases", "ff_weights_0", "W1", "memkeys", "Conv2d_0_rgb", "update_weights", "conv_W", "metric_0", "transition", "kt", "attention_variable_projection", "is_training", "scale", "test", "w_output", "loaded", "W_project", "prob", "Embedding_E", "my_counter", "input_embed", "v", "lock_counter", "wg1", "d_w1", "chars_embeddings", "unconstrained_loc", "W_key", "bias", "v_wiq_w", "predictions", "mask", "qf/loc", "we", "SpatialAttention_w_s", "scalar", "w", "W_actions", "variable", "test_train_counter", "embed", "shift", "embedding_mat", "output_weights", "sv", "slider", "proj_w", "last_id", "cluster_weights", "V_s", "value_x_weight", "score", "A", "iteration_step", "filter", "w1_s", "kernel/input", "qz_mean", "word_embeddings", "qmu/params", "window_w", "G_W1", ["k8s_client.V1EnvVar(\n        name", "'WANDB_API_KEY',\n        value", "key)"], "mean", "q_trait/params", "h1_weights", "crf", "W_0", "beta1_power", "word_mat", "mem_init", "V", "emoji2vec", "log_sigma", "W_x", "entity_embeddings", "Embedding", "cls/squad/output_weights", "layer_weights_", "u", "Variable", "Conv/weights", "layer_norm_scale", "enc_w1", "noise", "mu_reg", "action_counts", "U", "resample_count", [1, 2], "qpi/params", "word_embeddings_v", "attn_v", "eval_iteration", "codebook", "episode_id", "qig/params", "w_sentence_embedding", "a_var", "weigths", "W_pos", "g", "Compatibility", "U_r", "global_learning_rate", "G_W1p", "W3", "item_selection", "decay_step", "dummy", "params/weights", "conv1/BatchNorm/gamma", "softmax_weight", "weight_H", "emb", "Embedding_", "depthwise_conv/depthwise_weights", "wx", "emb_mat_var", "learning_rate", "train_step", "adaptive_kl_beta", "episode-reward", "reward_bias", "test_variable", "hist_true_acc", "idcnn_filter", "var0", "p", "fc6_conv", "z_r", "story_mask", "jazz_W", "qw/params", "input_mask", "state_to_word_W", "inputs_embedding", "two", "learning_rates", "embeddings", "W_ref", "embedding-rand", "loc", "W_initial_state", "Embedding_d", "theta", "topics_words_logits", "log_learning_rate", "some_var"], "dtype": [0, 1, 2.0, 3, 5, 8, 9, "iteration_number", "int", [1], [1000], "float32", [5], "long", "bool", "int32", [64, 64], "value", [10], "global_step", "int64", 224, [0], [], null, "float", -1], "name": [0, 1, 2, 3, 4, 5, "", 7, "next-sync", 9, "embedding-matrix", "embedding_matrix", "weights_in", "input_weights", "attn_query_projection", "logstd", "classify_weight", "test_var", "running_sum", "DW", "_word_embeddings", "kernel0", "w_omega", "value", "prelu_alphas", "_weights", "learn_rate", "TargetEmbeddingMatrix", "embedding_weights", "{}", "beta", "global_step", "key", "word_embedding", "nvgrad2_ema0", "b1", 100, "W", "kl_cost_bias", "cross_b", "words", "clp_kernel", "char_embedding", "embedding", "step_count", "last-update", "iter_cotrain", "fm_bias", "token_embeddings", "target_modality_embedding_matrix", "positional_mask", "des_w1", "W_z", "var1", "DecoderEmbeddingMatrix", "embed_tensor", "global-timestep", "weights", "embedding_matrix_0", "nt_embedding", "iterations", "w1", "var", "a", "W_embedding", "timestep", "gpu-placeholder-0", "linear_up_kernel", "map", "ou_state", null, "weight", "step_size_adaptation_step_counter", "memory", "W1", "bias_i", "encoder_embeddings", "scale", "test", "PG", "d_w1", "batch_lens", "bias", "w", "scaling_factor", "wc1", "table", "aW", "accuracy_per_bin", "W_re", "A", "time-step", "attention_context_vector", "position_embeddings", "mean", "G_W1", "EncoderEmbeddingMatrix", "beta1_power", "runningsum", "sample-count", "running_mean", "item_class_embeddings", "global-training-timestep", "has-previous", "g", "index", "title_embedding", "bilinear_matrix", "char_embeddings", "process", "weight_decay", "regret", "emb", "accuracy", "pos_embeddings", "state_to_word_W", "var_accum_grad", "loc", "embeddings", "W_out", "word_embed"], "constraint": [512, 1, 128, 3, 4, 0, 32, [[1.0]], null, -1]}, "EarlyStopping": {"monitor": [0, "val_loss", "my_train_metric", "loss", "val_exp_rmspe", "val_accuracy", null, "val_sparse_categorical_accuracy", "val_mse", "val_acc"], "min_delta": [0, 0.1, 1.0, 1e-08, 0.005, null, 0.0001, 0.002, 0.001, 0.0005], "patience": [1, 2, 3, 5, 6, 200, 10, 12, 15, 16, 20, null, 30], "verbose": [0, 1, 2, null], "mode": ["min", "max", "auto"], "baseline": [0], "restore_best_weights": [true]}, "Callback: on_batch_begin": {"batch": [], "logs": []}, "Callback: on_batch_end": {"batch": [], "logs": []}, "BaseLogger: set_model": {"model": []}, "EarlyStopping: get_monitor_value": {"logs": []}, "EarlyStopping: set_model": {"model": []}, "CSVLogger": {"filename": ["NASNet-CIFAR-10.csv", "first.3.log", "ResNet18v2-CIFAR-10.csv", null], "separator": ["\t", null], "'": [null], "append": [true]}, "Callback: on_epoch_begin": {"epoch": [], "logs": []}, "zeros": {"shape": [0, 1, 2, 3, 4, 5, [19, 19], 7, [7, 3], 512, 10, 8, 6, 11, 14, 15, 9, 19, 20, 22, [32, 31], 24, [2, 5], [24], [3, 3, 3, 3], [32, 1024, 3], [64, 23], [5, 5, 3], 20000, [5000, 1], [5, 5, 5, 5], [1, 2, 2, 1], [41], [20, 30], [3, 2, 2], [16], 50, [1, 8, 8, 9], [0, 4], [2, 4, 2, 3], [7], [20, 4], [1, 1], [128, 256, 3], [6, 5, 5], 64, [32], [3, 2], [104, 3], [4, 10], [4, 5], [300, 512, 3], [100], 600, [50], [1, 128], [50, 300, 3], [0, 1], [0], 100, [1024], [2147483648], [512], [10, 10, 3], [28, 28], [3, 1], [1, 28, 28, 1], [600, 600, 3], [6, 10, 3], [3, 4, 5], [2, 3, 4], [3, 32, 32, 3], [2, 2, 2, 3], [1, 3, 331, 331], 128, [16, 64, 64], [5, 3, 4], [0, 1, 2], [1800, 128], [5, 50], [21, 2], [2, 1], [9], [8, 9], [4, 12], [84, 84, 3], [1, 120, 160, 3], [10, 3], [1, 227, 227, 3], [500], [3, 3, 3], [1], [2, 1000], [1, 5], [400], 180, [4, 0, 6], [14, 3, 224, 224], [2, 2], [14, 3, 32, 32], [1, 10], [32, 3], [27, 5], [4, 1], [3, 6], [512, 512, 3], [9, 7], [5, 4], [368, 368], [16, 4], 200, [0, 18], [240, 320, 3], [200, 200, 3], [10], [0, 5], [3, 5, 2], [1, 4096], [40, 40, 1], [8, 3], [20, 10, 3], [5, 10], [10, 10], [2, 2, 1], [2], [64, 5, 3], [480, 640, 1], [19, 19, 8], [28, 56, 3], [21200], [10, 20], null, [14, 3], [0, 2], [1, 16, 32, 1], [1, 300, 300, 3], 256, [33, 33], [1, 3], [32, 2048, 6], [10, 15], 784, [11], [120, 160], [15, 1, 5, 5], [3, 1, 5], [3, 10], [3], [1, 10, 10, 1], 300, [28, 28, 3], [5, 0], [10, 224, 224, 3], [10, 10, 10], [3, 2, 3], [256, 640, 3], [20], [1, 3, 299, 299], [1, 448, 448, 3], 200000, [64, 64, 3], [13, 2], [2, 10, 10, 10, 3], [2, 20], [1, 4], [0, 4, 3, 0], [2, 3], [4, 2], [5, 10, 3], [243], [50, 20], [10, 20, 30], [5, 3], [3, 3, 1, 4], [5, 3, 1], [10, 5], [256], [1, 1764, 4], [4], [77, 102], [0, 6], [], [1, 3, 32, 32], [20, 6], [200, 200], [1, 7], [217360, 1999], [3, 4], [2, 4], [4, 6, 6], [7, 7], [16, 2], [7, 7, 2, 20], [10, 20, 3], 400, [1, 3, 0], [0, 16], [68, 2], [0, 3], [3, 14], [1, 299, 299, 3], [1, 2], [4, 75], [1000000], [64], [3, 3], [100, 200], [1, 1, 28, 28], [4, 4], [1000], [30], [720, 1280, 3], [32, 84, 84, 4], [55, 3], [19, 19, 1], [1, 3, 256, 256], [5], [14, 14], 3000, [2, 3, 224, 224], [128, 128, 3], [0, 0], [240, 240], [100, 8, 8], [2, 1, 5, 3, 4], [256, 512, 1], 2000, 464, [512, 1024, 1024], [10, 128, 64], [1, 39], [100, 21], [1, 1, 1], [14, 14, 3], [1, 256], 480, [128], [1, 2, 3, 4], [150, 150], [1, 1, 3], 1000, [1, 6, 3], [1, 512, 512, 1], [1, 16, 16, 1], [900], [784, 1], [2, 262144], [2, 0], [1, 3, 224, 224], [1, 3, 256, 192], 500, [1, 1, 5], [4, 3], [8, 8], [2000], [5, 2], [3, 100, 100, 3], [416, 416, 3]], "dtype": [0, 1, 128, 3, 1024, 5, 2, 4, "float64", 8, 10, 6, 12, 15, 16, "complex64", 512, 20, 21, 640, 28, "int", 32, 800, 1152, 42, 299, "float32", 1200, [10, 3, 32, 32], "f4", "int32", 60, 64, "f", [10], "int8", "i8", "u4", "int64", 224, null, "uint8", "float"], "name": [128, 1, 0, 2, 4, 5, 3, "zeros", 8, "", "contexts", 10, 9, 7, 6, 16, 20, "total_dimension", "b_bottleneck", 28, 30, 32, "done", "padding", 42, 299, "init_lstm_h", "moment_1", "stack_index", "convolution_queue_2", "val_init", ["y", "f4"], "float32", "bs_lengths", "bias", "dvb_init", "prev", "iter", "batch_inds", "c_0", "init_avg_effect", 84, "beta", "reward", "initial_state", "m_2", "zero", 224, "empty", null, "flattened_x"]}, "CSVLogger: set_model": {"model": []}, "Callback: on_epoch_end": {"epoch": [], "logs": []}, "Callback: on_predict_batch_begin": {"batch": [], "logs": []}, "update_add": {"x": [null], "increment": [1, null]}, "truncated_normal": {"shape": [0, [1001], null], "mean": [0.0, 1.0, 0.5, 3, 4, 5, 11, null, 0.02], "stddev": [0.1, 1.0, 2.0, 3, 0.05, 0.0, 64, -0.1, 0.5, 10, 0.01, 0.005, null, 0.02, 0.001], "dtype": [0, 0.1, 0.001, null], "seed": [0.0, 1, null]}, "transpose": {"x": [0, 1, 2, 3, 256, [0, 3, 4, 1, 5, 2], "data", [1, 2, 3, 0], [3, 0, 1, 2], [0, 1, 3, 2], [1, 0, 2, 3, 4], [1, 0, 2, 3], [0, 2, 3, 1, 4], [2, 0, 1], [0, 3, 2, 1], [1, 2, 0], [2, 3, 1, 0], "value", [0, 2, 3, 1], [1, 0], [0, 3, 1, 2], -1, null, [1, 0, 2], -2]}, "var": {"x": [0.2, 0, "EXT_SUFFIX", "value", 3, "OMP_NUM_THREADS", "data", "lod", "INSTSONAME", "MACOSX_DEPLOYMENT_TARGET", "PICASSO_SETTINGS", "{}", null, "NumberOperator", "s3", "replay-memory/index", "CONFIGURE_CFLAGS", "memory_backend_params"], "axis": [0, 1, [0, 1], "value", [0], [0, 1, 2], "Binaryzation", "1", null, -1], "keepdims": [false, true, [], null, -1]}, "update_sub": {"x": [null], "decrement": [null]}, "update": {"x": [0, 1, [["0"]], 3.0, "value", "jax_enable_x64", ["#", "-*-", "coding:utf-8", "-*-", "import", "tensorflow", "as", "tf", "import", "numpy", "as", "np", "from", "tqdm", "import", "tqdm", "import", "sys", "import", "os", "import", "time", "'''tfrecord", "\u5199\u5165\u6570\u636e.", "\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165", "tfrecord", "\u6587\u4ef6\u3002\u4ee5", "png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002", "\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002", "\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002", "\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a", "1.\u6253\u5305", "tfrecord", "\u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528", "Image.open()", "\u6216\u8005", "matplotlib.image.imread()", "\u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002", "1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open)", "\u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb,", "\u540e\u8005\u76f4\u63a5\u751f\u6210", "numpy", "\u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002", "\u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528", "tf.gfile.FastGFile()", "\u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002", "2.\u4ece", "tfrecord", "\u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528", "tf.image.decode_png()", "\u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002", "3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528", "tf.image.resize_image_with_crop_or_pad", "\u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528", "tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002", "'''", "#", "png", "\u6587\u4ef6\u8def\u5f84", "IMG_DIR", "=", "'../../data/sketchy_000000000000/'", "TFRECORD_DIR", "=", "'tfrecord/sketchy_image/'", "NUM_SHARDS", "=", "64", "#", "tfrecord", "\u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9", "shuffle", "\u4f1a\u597d\u4e9b", "def", "get_file_path(data_path='../../data/sketchy_000000000000/'):", "\"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"", "img_paths", "=", "list()", "labels", "=", "list()", "#", "\u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6", "\u548c", "\u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528", "dict_class2id", "\u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002", "class_dirs", "=", "sorted(os.listdir(data_path))", "dict_class2id", "=", "dict()", "for", "i", "in", "range(len(class_dirs)):", "label", "=", "i", "class_dir", "=", "class_dirs[i]", "dict_class2id[class_dir]", "=", "label", "class_path", "=", "os.path.join(data_path,", "class_dir)", "#", "\u6bcf\u7c7b\u7684\u8def\u5f84", "file_names", "=", "sorted(os.listdir(class_path))", "for", "file_name", "in", "file_names:", "file_path", "=", "os.path.join(class_path,", "file_name)", "img_paths.append(file_path)", "labels.append(label)", "img_paths", "=", "np.asarray(img_paths)", "labels", "=", "np.asarray(labels)", "return", "img_paths,", "labels", "def", "bytes_feature(values):", "return", "tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))", "def", "int64_feature(values):", "return", "tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))", "def", "convert_tfrecord_dataset(tfrecord_dir,", "n_shards,", "img_paths,", "labels,", "shuffle=True):", "\"\"\"", "convert", "samples", "to", "tfrecord", "dataset.", "Args:", "dataset_dir:", "\u6570\u636e\u96c6\u7684\u8def\u5f84\u3002", "tfrecord_dir:", "\u4fdd\u5b58", "tfrecord", "\u6587\u4ef6\u7684\u8def\u5f84\u3002", "n_shards\uff1a", "tfrecord", "\u6587\u4ef6\u4e2a\u6570", "img_paths:", "\u56fe\u7247\u7684\u540d\u5b57\u3002", "labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002", "\"\"\"", "if", "not", "os.path.exists(tfrecord_dir):", "os.makedirs(tfrecord_dir)", "n_sample", "=", "len(img_paths)", "num_per_shard", "=", "n_sample", "//", "n_shards", "#", "\u6bcf\u4e2a", "tfrecord", "\u7684\u6837\u672c\u6570\u91cf", "#", "\u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21", "if", "shuffle:", "new_idxs", "=", "np.random.permutation(n_sample)", "img_paths", "=", "img_paths[new_idxs]", "labels", "=", "labels[new_idxs]", "time0", "=", "time.time()", "for", "shard_id", "in", "range(n_shards):", "output_filename", "=", "'%d-of-%d.tfrecord'", "%", "(shard_id,", "n_shards)", "output_path", "=", "os.path.join(tfrecord_dir,", "output_filename)", "with", "tf.python_io.TFRecordWriter(output_path)", "as", "writer:", "start_ndx", "=", "shard_id", "*", "num_per_shard", "end_ndx", "=", "min((shard_id", "+", "1)", "*", "num_per_shard,", "n_sample)", "for", "i", "in", "range(start_ndx,", "end_ndx):", "sys.stdout.write('\\r>>", "Converting", "image", "%d/%d", "shard", "%d,", "%g", "s'", "%", "(", "i", "+", "1,", "n_sample,", "shard_id,", "time.time()", "-", "time0))", "sys.stdout.flush()", "png_path", "=", "img_paths[i]", "label", "=", "labels[i]", "img", "=", "tf.gfile.FastGFile(png_path,", "'rb').read()", "#", "\u8bfb\u5165\u56fe\u7247", "example", "=", "tf.train.Example(", "features=tf.train.Features(", "feature={", "'image':", "bytes_feature(img),", "'label':", "int64_feature(label)", "}))", "serialized", "=", "example.SerializeToString()", "writer.write(serialized)", "print('\\nFinished", "writing", "data", "to", "tfrecord", "files.')", "if", "__name__", "==", "'__main__':", "img_paths,", "labels", "=", "get_file_path()", "convert_tfrecord_dataset(TFRECORD_DIR,", "NUM_SHARDS,", "img_paths,", "labels,", "shuffle=True)"], 2, "data_time", "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", ["[value]"], null, "user_basic", "user_advaced", "tree", ["#", "-*-", "coding:utf-8", "-*-", "\r\n\r\nimport", "tensorflow", "as", "tf\r\nimport", "numpy", "as", "np\r\nfrom", "tqdm", "import", "tqdm\r\nimport", "sys\r\nimport", "os\r\nimport", "time\r\n\r\n'''tfrecord", "\u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165", "tfrecord", "\u6587\u4ef6\u3002\u4ee5", "png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305", "tfrecord", "\u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528", "Image.open()", "\u6216\u8005", "matplotlib.image.imread()", "\u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n", "1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open)", "\u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb,", "\u540e\u8005\u76f4\u63a5\u751f\u6210", "numpy", "\u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n", "\u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528", "tf.gfile.FastGFile()", "\u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece", "tfrecord", "\u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528", "tf.image.decode_png()", "\u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528", "tf.image.resize_image_with_crop_or_pad", "\u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528", "tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n#", "png", "\u6587\u4ef6\u8def\u5f84\r\nIMG_DIR", "=", "'../../data/sketchy_000000000000/'\r\nTFRECORD_DIR", "=", "'tfrecord/sketchy_image/'\r\nNUM_SHARDS", "=", "64", "", "#", "tfrecord", "\u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9", "shuffle", "\u4f1a\u597d\u4e9b\r\n\r\n\r\ndef", "get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n", "", "", "", "\"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n", "", "", "", "img_paths", "=", "list()\r\n", "", "", "", "labels", "=", "list()\r\n", "", "", "", "#", "\u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6", "\u548c", "\u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528", "dict_class2id", "\u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n", "", "", "", "class_dirs", "=", "sorted(os.listdir(data_path))\r\n", "", "", "", "dict_class2id", "=", "dict()\r\n", "", "", "", "for", "i", "in", "range(len(class_dirs)):\r\n", "", "", "", "", "", "", "", "label", "=", "i\r\n", "", "", "", "", "", "", "", "class_dir", "=", "class_dirs[i]\r\n", "", "", "", "", "", "", "", "dict_class2id[class_dir]", "=", "label\r\n", "", "", "", "", "", "", "", "class_path", "=", "os.path.join(data_path,", "class_dir)", "", "#", "\u6bcf\u7c7b\u7684\u8def\u5f84\r\n", "", "", "", "", "", "", "", "file_names", "=", "sorted(os.listdir(class_path))\r\n", "", "", "", "", "", "", "", "for", "file_name", "in", "file_names:\r\n", "", "", "", "", "", "", "", "", "", "", "", "file_path", "=", "os.path.join(class_path,", "file_name)\r\n", "", "", "", "", "", "", "", "", "", "", "", "img_paths.append(file_path)\r\n", "", "", "", "", "", "", "", "", "", "", "", "labels.append(label)\r\n", "", "", "", "img_paths", "=", "np.asarray(img_paths)\r\n", "", "", "", "labels", "=", "np.asarray(labels)\r\n", "", "", "", "return", "img_paths,", "labels\r\n\r\n\r\ndef", "bytes_feature(values):\r\n", "", "", "", "return", "tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef", "int64_feature(values):\r\n", "", "", "", "return", "tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef", "convert_tfrecord_dataset(tfrecord_dir,", "n_shards,", "img_paths,", "labels,", "shuffle=True):\r\n", "", "", "", "\"\"\"", "convert", "samples", "to", "tfrecord", "dataset.\r\n", "", "", "", "Args:\r\n", "", "", "", "", "", "", "", "dataset_dir:", "\u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n", "", "", "", "", "", "", "", "tfrecord_dir:", "\u4fdd\u5b58", "tfrecord", "\u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n", "", "", "", "", "", "", "", "n_shards\uff1a", "tfrecord", "\u6587\u4ef6\u4e2a\u6570\r\n", "", "", "", "", "", "", "", "img_paths:", "\u56fe\u7247\u7684\u540d\u5b57\u3002\r\n", "", "", "", "", "", "", "", "labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n", "", "", "", "\"\"\"\r\n", "", "", "", "if", "not", "os.path.exists(tfrecord_dir):\r\n", "", "", "", "", "", "", "", "os.makedirs(tfrecord_dir)\r\n", "", "", "", "n_sample", "=", "len(img_paths)\r\n", "", "", "", "num_per_shard", "=", "n_sample", "//", "n_shards", "", "#", "\u6bcf\u4e2a", "tfrecord", "\u7684\u6837\u672c\u6570\u91cf\r\n\r\n", "", "", "", "#", "\u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n", "", "", "", "if", "shuffle:\r\n", "", "", "", "", "", "", "", "new_idxs", "=", "np.random.permutation(n_sample)\r\n", "", "", "", "", "", "", "", "img_paths", "=", "img_paths[new_idxs]\r\n", "", "", "", "", "", "", "", "labels", "=", "labels[new_idxs]\r\n\r\n", "", "", "", "time0", "=", "time.time()\r\n", "", "", "", "for", "shard_id", "in", "range(n_shards):\r\n", "", "", "", "", "", "", "", "output_filename", "=", "'%d-of-%d.tfrecord'", "%", "(shard_id,", "n_shards)\r\n", "", "", "", "", "", "", "", "output_path", "=", "os.path.join(tfrecord_dir,", "output_filename)\r\n", "", "", "", "", "", "", "", "with", "tf.python_io.TFRecordWriter(output_path)", "as", "writer:\r\n", "", "", "", "", "", "", "", "", "", "", "", "start_ndx", "=", "shard_id", "*", "num_per_shard\r\n", "", "", "", "", "", "", "", "", "", "", "", "end_ndx", "=", "min((shard_id", "+", "1)", "*", "num_per_shard,", "n_sample)\r\n", "", "", "", "", "", "", "", "", "", "", "", "for", "i", "in", "range(start_ndx,", "end_ndx):\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "sys.stdout.write('\\r>>", "Converting", "image", "%d/%d", "shard", "%d,", "%g", "s'", "%", "(\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "i", "+", "1,", "n_sample,", "shard_id,", "time.time()", "-", "time0))\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "sys.stdout.flush()\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "png_path", "=", "img_paths[i]\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "label", "=", "labels[i]\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "img", "=", "tf.gfile.FastGFile(png_path,", "'rb').read()", "", "#", "\u8bfb\u5165\u56fe\u7247\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "example", "=", "tf.train.Example(\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "features=tf.train.Features(\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "feature={\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "'image':", "bytes_feature(img),\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "'label':", "int64_feature(label)\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "}))\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "serialized", "=", "example.SerializeToString()\r\n", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "writer.write(serialized)\r\n", "", "", "", "print('\\nFinished", "writing", "data", "to", "tfrecord", "files.')\r\n\r\n\r\nif", "__name__", "==", "'__main__':\r\n", "", "", "", "img_paths,", "labels", "=", "get_file_path()\r\n", "", "", "", "convert_tfrecord_dataset(TFRECORD_DIR,", "NUM_SHARDS,", "img_paths,", "labels,", "shuffle=True)"]], "new_x": [0, 1, ["tags"], "value", [0], [["file_fraction_already_exists", 1]], "image/object/bbox/ymin", "truncated", 10, "container-sdk-branch", [[1]], null]}, "to_dense": {"tensor": ["value", null]}, "tile": {"x": [0, 0.8, 2, "value", [false], 0.5, [1], ["string"], [2], [8], 0.01, [-1], [[1.0]], null], "n": [0.99, 0, 2, 3, 4, 1, 5, 0.5, [25.0, 75.0], 10, [2, 1], [5, 1], [2, 3, 1], [1, 2], 0.05, [1, 1, 64], [1, 1, 9], [8, 1], 50, [1, 1], 0.1, [10, 1, 1], [3, 1, 1], "value", 70, [1, 1, 1], 90, [1, 512], [25.0], [1, 1, 1, 3], 95, 99, [1, 1, 3], [2], [1, 1, 2], [4], [], null]}, "Callback: on_predict_batch_end": {"batch": [], "logs": []}, "Callback: on_predict_begin": {"logs": []}, "Callback: on_predict_end": {"logs": []}, "Callback: on_test_batch_begin": {"batch": [], "logs": []}, "Callback: on_test_batch_end": {"batch": [], "logs": []}, "switch": {"condition": [null], "then_expression": [0, -Infinity, null], "else_expression": [0, 1, null]}, "sum": {"x": [0, 1, 2, "value", [0.1, 0.2], [0, 1, 2], "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", "../github_crawler/tf_pyfiles", [-1.0], "abab", [2, 3], null, "ijkl->jl", -1], "axis": [0, 1, 2, 3, 4, 0.587, ".pyo", 7, [-1], [2, 1], [-1, -2, -3], [1, 2], [1], [0, 2, 3], "Generation", [3], [-2, -1], [1, 2, 3], [2, 3], [3, 5], [0, 1], [0], [2], [], -1, null, -4, -3, -2], "keepdims": [0, true, 2, 4, 6, ".pyd", [], null]}, "Callback: on_test_begin": {"logs": []}, "Callback: on_test_end": {"logs": []}, "Callback: on_train_batch_begin": {"batch": [], "logs": []}, "Callback: on_train_batch_end": {"batch": [], "logs": []}, "temporal_padding": {"x": [null], "padding": [[1, 1], null]}, "tanh": {"x": [0, "value", null]}, "Callback: on_train_begin": {"logs": []}, "Callback: on_train_end": {"logs": []}, "Callback: set_model": {"model": []}, "spatial_3d_padding": {"x": [null], "padding": [[[1, 1], [1, 1], [1, 1]], null]}, "spatial_2d_padding": {"x": [null], "padding": [[[1, 1], [1, 1]], null]}, "square": {"x": [0.25, 0.05, 2, "value", null]}, "stop_gradient": {"variables": [0, "value", null]}, "std": {"x": [0, "value", null], "axis": [0, 1, [0, 1], 3, [0, 1, 2], [0, 2, 3], [1, 2, 3], null, [1, -1], -1, [0, 1, 2, 3]], "keepdims": [false, true, null]}, "squeeze": {"x": [0, 1, 2, "value", 3, 0.1, 4, -2, null, -1], "axis": [0, 1, 2, 3, 4, [-1], [-2], [0, 3], [1, 2], [1], [3], [-2, -1], [2, 3], [0], [2], -3, [], -1, null, -4, [2, 4], -2]}, "sqrt": {"x": [0.5, 0, 2.0, 0.2, 3, 5, 6, 7, 1.0, 8, 10.0, 4, 12.0, 147, 28.0, 0.0196078431372549, 421.0, 42.0, 0.002551020408163265, 0.1, 0.11000000000000001, 200, 0.02, 2.7126736111111112e-06, 0.015, 0.09876543209876543, null]}, "stack": {"x": [0, 1, [1, 2], null], "axis": [0, 1, 2, 3, 4, "value", 7, "xmin", -1, null, -4, -3, -2]}, "softsign": {"x": [null]}, "softplus": {"x": [5.0, null]}, "softmax": {"x": [0, [0], "action_policy", null, -1], "axis": [0, 1, 2, 3, 4, 8, null, -3, -1]}, "sin": {"x": [0, "sigmoid", 3.14, 3.1416, 4, "accuracy", "classifier", null, "random", "regular", "binary_classifier", "tanh"]}, "shape": {"x": [0, 1, 2, 3, 4, [19, 19], 5, 6, 8, [-1, 3, 32, 32], 10, [2, 2, 4], 12, [4, 4, 1024], 14, 16, 17, [5, 5, 1], 20, [2, 5], 27, 28, [5, 5, 5], 47, [50, 50], [-1, 28, 28, 1], [-1, 28, 28], [1, 1], ["tf.concat(axis", "1, values", "outputs)"], [3, 2], "value", [4, 5], 80, [7, 7, 128], [1, 128], [25], [1, 1, 1, 3], 60000, [0], [3072], [60000, 28, 28, 1], [3, 1], [28, 28], [10, 10, 3], [3, 4, 5, 6], [-1, 4], [2, 1, 3, 3], [-1, 3200], [2, 1], [-1, 1, 1, 1], [-1, 3, 4, 8, 4, 8], [3, 3, 3], [-1, 1], [1], [1, 368, 368, 1], [2, 2], [1, 10], [4, 1], [0, 0, 3], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [6, 4], 200, [-1, 2], [8, 1, 6, 1], [7, 7, 256], [0, 5], 50400, ["shape", "[img_height"], [2], "../github_crawler/tf_pyfiles", [-1, 8], [3, 256, 256], [720], [-1, 1, 28, 28], [1, 3, 4, 1], null, [512, -1], [0, -1], [0, 2], [1, 3], [80, 4], "data", [-1], [1, 1, 7, 7], [1, -1, 1, 1], [10, 15], 10000, 784, [3, 3, 384], [1, -1], [0, 1, -1, 3], [1, 1, -1], [4096, 512, 7, 7], [5, 27, 27, 64], 1320, [3], [8, 10], [3, 32, 32], [784], [-1, 784], [12, 3], [-1, 6], [1, 2, 1], [28, 28, 1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [200, 3200], [-1, 2, 4], [-1, 1, 2], [2, 3], [4, 2], [50, 50, 3], [6, 5], [4100, 28, 28], [-1, 4, 2], [-1, 3], [100, 100], [4], [], [3, 4], [100, 3072], [32, 1], [1, -1, 3], [6, 6], [5, 6], [16, 2], [1, 224, 244, 3], [1, 299, 299, 3], [1, 2], [360, 480, 1], [3, 3], [2, 3, 3], [4, 4], [5], [128, 7, 7], [1, 1, 3, 3], [30012], [0, -3, -2], [10, 1], [127, 127, 1], [2, 2, 2], [1, 1, 3], [-1, 17, 3], [-1, 5, 2], [8, 8], [60000, 784], [32, 32, 4], [5, 2], -1, [1, 224, 224, 3]]}, "sign": {"x": [false, 0.7, 2.0, 1, 4.0, 3.0, 5.0, 6.0, 0.5, 1.2, 10, 14, [63.0], 0.0001, 0.6, [0.1], 38, [1.0], [5.0], 0.2, [1, 1], 1e-06, [20.0], 0.1, [-0.01], -0.1, "value", 0.8, 300000, [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 100, 0.01, -2.0, null, -7.3, -1]}, "sigmoid": {"x": [0, 1, 2.2, null]}, "set_value": {"x": [0, "value", "user", null, -1], "value": ["string", "value", "caption", "rel", null, "email"]}, "set_learning_phase": {"value": [0, 1, "value", null]}, "set_image_data_format": {"data_format": ["channels_first", "channels_last", null]}, "set_floatx": {"value": ["float64", "float32", null]}, "set_epsilon": {"value": [0.0001, 1e-08, null]}, "separable_conv2d": {"x": [0, null], "depthwise_kernel": [0, 32, 64, 128, "../github_crawler/tf_pyfiles", null], "pointwise_kernel": [3, [3, 3], null], "strides": [1, [3, 3], "ds_conv_2", [2, 2], [1, 1, 1, 1], null, [1, 1]]}, "resize_volumes": {"x": [null], "depth_factor": [null], "height_factor": [null], "width_factor": [null], "data_format": [null]}, "resize_images": {"x": [0, null], "height_factor": [2, [224, 224], [256, 256], [64, 64], [240, 320], [24, 24], null], "width_factor": [1, 2, null], "data_format": [1, "channels_last", null], "interpolation": ["nearest", "bilinear", null]}, "reshape": {"x": [0, 1, 2, 3, 4, [19, 19], 5, 6, 8, [-1, 3, 32, 32], 10, [2, 2, 4], 12, 7, 14, 16, 17, [5, 5, 1], 20, [2, 5], 27, 28, [5, 5], [5, 5, 5], 47, [50, 50], [-1, 28, 28, 1], [-1, 28, 28], [3, 2], "value", [4, 5], 80, [1, 128], [25], [1, 1, 1, 3], 60000, [0], [60000, 28, 28, 1], [3, 1], [28, 28], [50000], [3, 4, 5, 6], [-1, 4], [2, 1, 3, 3], [1, 3, 1], [2, 1], [1, 1, 1, 2, 1], [-1, 1, 1, 1], [-1, 3, 4, 8, 4, 8], [5, 1], [3, 3, 3], [-1, 1], [1], [1, 368, 368, 1], [2, 2], [5, 4, 3], [4, 1], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [6, 4], 200, [-1, 2], [1, 7, 7, 1], [8, 1, 6, 1], [0, 5], 50400, [2], [2, 1, 1], [-1, 8], [3, 256, 256], [-1, 1, 28, 28], [1, 3, 4, 1], null, [512, -1], [0, -1], [0, 2], [1, 1, 10, 10], [1, 3], [80, 4], [-1], [1, 1, 7, 7], [1, -1, 1, 1], 10000, 784, [1, -1], [0, 1, -1, 3], [1, 1, -1], [4096, 512, 7, 7], [5, 27, 27, 64], 1320, [3], [8, 10], [3, 32, 32], [-1, 784], [16, 112, 112, 1], [12, 3], [-1, 6], [1, 256, 256, 3], [1, 2, 1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [1, 2, 3], [-1, 2, 4], [-1, 1, 2], [2, 3], [4, 2], [50, 50, 3], [6, 5], [4100, 28, 28], [-1, 4, 2], [-1, 3], [100, 100], [4], [], [3, 4], [2, 4], [100, 3072], [32, 1], [1, -1, 3], [6, 6], [5, 6], [16, 2], [1, 224, 244, 3], [1, 299, 299, 3], [1, 2], [360, 480, 1], [3, 3], [2, 3, 3], [4, 4], [5], [1, 1, 3, 3], [30012], [0, -3, -2], [10, 1], [127, 127, 1], [2, 2, 2], [1, 1, 3], [-1, 17, 3], [-1, 5, 2], [8, 8], [60000, 784], [32, 32, 4], [2, 15], [5, 2], -1, [1, 224, 224, 3]], "shape": [0, 1, 2, 3, 4, 5, [-1, 3072], 6, 8, [1, 10, 1], 10, [-1, 0], [-1, 1024], [1, 1, 256, 14, 14], [400, 2], 14, 16, 13, 17, 19, 24, [2, 5], 28, [100, 1], 30, 31, 32, 48, [0, 0, -1], 50, [-1, 28, 28, 1], [-1, 28, 28], 59, 60, [1, 1], [513, 513], 64, 73, [8], 80, [24, 24], 84, 600, 3072, [3072], [0], 100, [-1, 1, 1], [28, 28], [1, 3, 5], [-1, 4], 125, 640, [32, 32], [-1, 3, 96, 96], [2, 1], [-1, 1, 1, 1], [-1, 4, 4, 24], 160, [-1, 2, 2, 512], [-1, 1], [1], [7, 7, 1, 20], [5, 1, 1], 1200, [2, 2], [-1, 0, 0], [4, 1], [768, 768, 3], 192, [115, 200, 1], 200, [-1, 2], [256, 256, 1], [1, 2, 2, 2], [1, 4096], 224, [-1, 8, 1], [2, 1, 1], [3, -1], [2, 768], null, [0, -1], -0.616, [1, 3, 2, 1], 256, 7077888, [1, 28, 28], [-1], [1, -1, 1, 1], 784, [1, -1], [-1, 24], [210, 160], [2, 2, 2, 2], [1, 1, 32, 32], [-1, 4, 4, 8], 299, [3], [1, 48, 48, 1], [3, 32, 32], [784], [-1, 784], [28, 28, 3], [-1, 6], [10, 1, 1], [28, 28, 1], [21168], [2, 3], [1, 3, 1, 1], [4, 2], [-1, 2, 2], [-1, 12], [-1, 4, 2], [-1, 3], [1, 4, 4, 1], [], [-1, 1, 4], [7, 7, 20], [5, 6], [1, 1, 1, -1], [1, 2], [1, 514], 416, [3, 3], [-1, 32], [4, 4], [1, 20, 20], [112, 112, 3], [32, -1], [100, 64, 64, 3], [1, 1, 3], [16, 64, 64, 3], [16, 32, 32, 3], [1, 1, -1, 1], [1, 12, 1], [183, 1], [5, 2], -1, [1, 224, 224, 3]]}, "reset_uids": {}, "repeat_elements": {"x": [null], "rep": [4, null], "axis": [1, 2, -1, null]}, "round": {"x": [0, 1, 2, "value", 3, 6, 8.999999999999998, "value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255value * 255", null, 91.3125]}, "rnn": {"step_function": [0, null], "inputs": [1, 2, "network", null], "initial_states": [0, [], null], "go_backwards": [false, null], "mask": [0, 5e-05, null], "constants": [0, null], "unroll": [false, null], "input_length": [64, 0, null], "time_major": [false, true, null], "zero_output_for_mask": []}, "reverse": {"x": [0.0, "value", "keras-import", "caffe-import", "saveDB", "api", null, "tf-import", "video"], "axes": [1, [0], [1], [2], [-1], [], null]}, "repeat": {"x": [0, 1, 2, 3, 4, 0.25, 0.3, 0.2, 5, 10, 20, 30, 50, -Infinity, [0], 100, [], null, -1], "n": [256, 1, 2, 3, 0, 5, 100, 4, 32, 9, 10, 16, 2000, 20, null]}, "relu": {"x": [0, null], "alpha": [0.1, 0.0, 0.2, 3.0, 0.3, 1024, 8, 10, "relu", 0.01, 48, "conv_pose_1_1", null, "hidden_activation"], "max_value": [0, 1, 6, "lrelu1", null, [1, 1]], "threshold": [0.0, null]}, "random_uniform": {"shape": [-0.5, [100000], [32, 1, 1, 1], [4, 3, 2], [10, 3], -0.08, [64], [1], [100, 200, 3], [1000], [8, 10], -0.1, [10, 4], [10], [1, 8192], [2], [4], [], null, -1.0], "minval": [0, 1.0, 2, 0.75, -0.5, 5, 0.5, 7, 0.93, 0.9, 10, 256, 8, 14, 3, 20, -0.01, 28, 32, 800, 299, -0.1, 0.1, -0.03, 224, -0.05, 0.08, 1e-05, -10, null, -1.0, -5.0, -2], "maxval": [0, 1.0, 2, 1.1, 3, 5, 1.25, 7, 0.5, 1.5, 10.0, -0.25, 12, 8, 14, 10000, -0.01, 0.0001, 28, 32, 0.05, 299, 1.2, 30521, 0.1, 0.03, -0.1, 0.3, 50257, 224, 0.99999, 0.01, 1.07, null, -2.5, -5, -1.0, 255], "dtype": [0.25, 1.0, 2.5, 0.0, 4, 0.1, 8, 10, 0.01, 20, null, "int32"], "seed": [0, 1, 123456, 2, 100, 5, 1234, null, -1]}, "random_normal_variable": {"shape": [null], "mean": [0, null], "scale": [1, null], "dtype": [0], "name": [0], "seed": [0]}, "random_normal": {"shape": [0.0, 2, [100000], [256], [10, 4], [1], [512], [32], [1000], [3], [10], [], [2, 3], null, [10, 3], 0.001, [20]], "mean": [0.0, 1.0, 2, 3, 224, 5, 416, 0.1, 4, 0.5, 10, 7, 0.01, 13, 9, 20, null, -1], "stddev": [0.0, 1, 0.6, 512, 4, 5, 2, 7, 1024, 0.8, 10, 3, 0.5, 13, 20, 416, 32, 0.04, 0.1, 0.3, 0.02, 224, 0.08, 488, 0.01, null, 0.002, 0.001], "dtype": [0, 3, 6, 0.01, "float32", null], "seed": [0, 1, 2018, 2017, 100, 1234, null, 123]}, "random_binomial": {"shape": [null], "p": [0.0, null], "dtype": [0], "seed": [0, null]}, "random_uniform_variable": {"shape": [[2, 3], null], "low": [0, null], "high": [1, null], "dtype": [0], "name": [0], "seed": [0]}, "print_tensor": {"x": [null], "message": ["", null]}, "pool3d": {"x": [null], "pool_size": [null], "strides": [1, 3, 4, null, [1, 1, 1]]}, "pool2d": {"x": [0, null], "pool_size": [0, 1, 2, 3, 4, 7, 8, 13, null, [1, 1]], "strides": [1, 2, 3, [3, 3], null, [1, 1]]}, "prod": {"x": [0, [3, 32, 32], null], "axis": [0, 1, 2, [1], 8, [-1], null, -1], "keepdims": [false, true, null]}, "permute_dimensions": {"x": [null], "pattern": [[0, 2, 3, 1], [1, 0], [3, 0, 1, 2], [2, 0, 1], null, [3, 1, 0, 2], [0, 2, 1], [0, 3, 1, 2], [1, 0, 2], [0, 2, 1, 3]]}, "placeholder": {"shape": [0, [0, 1, 1], [32], [0, 3, 224, 224], [0, 0, 224, 224, 3], [1, 240, 320, 3], [0, 10, 224, 224], [0, 784], "float", [0, 1, 4], [0, 3], [0, 0, 42], [0, 32, 32, 3], [0, 24, 24, 2], [0, 32], [1], [0, 2, 3], [4, 4], [3], "float32", [0, 128, 224, 224], "bool", [0, 0, 16, 16], [0, 19, 19, 21], [2, 2], [2, 4, 5], [2, 0, 0, 4], "int32", [0, 0, 13, 17], [1, 6, 192, 256], [1, 1], [0, 0, 3], [9, 7], [256, 512, 3], [0, 1024], [0, 0], [0, 0, 2, 4], [1, 1, 3, 3], [28, 28, 1], [0, 28, 28, 1], [1, 4], [0, 256, 256, 3], [0, 0, 0], [1024, 0, 1024], [0, 32, 224, 224], "learning_rate", [0, 0, 50], [0, 299, 299, 3], [1, 0], [3, 5], [0, 1], [0, 224, 224, 3], "image", [0], "int64", [2], [1, 224, 224, 3], [4], [0, 4, 256], [16, 50, 400], [], [0, 0, 0, 0], [6], null, [0, 0, 0, 3], "uint8", [0, 1, 0], [3, 4], [0, 2], [32, 32, 3], [1, 416, 416, 3]], "ndim": [0, [0, 0, 0, 3], 2, 1.3, 2.5, 5, 4, 14, [0, 3], 28, [10, 224, 224, 16], 30, 32, [1], [3], "train", [0, 4], [4, 0, 0, 3], [1, 1], [0, 0, 3], [1, 4, 4, 3], [1, 448, 448, 3], [0, 0], [0, 100, 1], [0, 32, 32, 1], [10], [0, 1], [0], [2], [], [5, 10, 20, 10], null, [0, 120, 120, 3], [1, 2, 2, 3]], "dtype": [0, 1, 2, 3, 4, 5, 256, 128, 512, 1.9, 10, "placeholder_bottleneck", 4.3, "obs", 13, "topk_setter", 20, 22, 24, 28, "input_ids", "synthetic_batch_size", 32, "label", 416, "encoder_padding_lengths", 299, 300, "float32", 1200, "bool", "input", "delayed_action", 448, 64, 320, "flat_tangent", "x_placeholder", 200, "train_mode", 80, 84, "n_batch_placeholder", "inputs", 224, 96, "flat_theta", 227, 100, "old_policy_values", "program_count_add_ph", "new_value", 368, 112, 115, "beam_size_setter", "x_tnsr", null, "avg_episode_reward", "x"], "sparse": [0, 128, 256, 3, 4, 5, 512, 2, 1, 2.9, 10, "input_placeholder", 6.1, 13, 20, "context", 280, 28, 32, 416, 40, 299, "s", "pred", 1600, 448, 64, 320, 200, 80, "a", 84, "inputs", 224, 96, 227, 100, 368, 112, "outputs_idx", null, "x"], "name": [0, "t_sentence", "regularization", "sum", "real_A", "x_train", "output_data", "in_stat_pl", "input", "input_chars", "{}", "q_networks_min_placeholder", "actions_", "encode_seqs", "words", "xx", "gradient", "encoder_inputs", "EvalSrcPh", "user", "examplar_input", "input_", "x-image-A", "real_images", "is_training_batch", "var1", "z_placeholder", "input_prep", "n_idx", "enc_in", "dropout_ph", "trainable_bn", "user_id", "start_symbol", "x-images", "sentence_in", 224, "gamma", "passage_w", "GLGPU_mel_inputs", "tokens_lengths", "images_with_code", "inpX", "input_sent_left", "target_q_t", "encoded_image_bytes", "bcast_object_size", "global_best_reward_placeholder", "img_inputs", "input_sentence", "x-image", "DistortJPGInput", "c_ph", "input_A", "x-image-hr", "image_tensor", "variable_a", "token_indices_ph", "input_image_as_bytes", "target", "word_ids", "on_policy_last_action_in_pl", "Placeholder_only", "input_tokens", "raw_indices", "state_ph", "real_A_and_B_images", "input_x1", "Prune_flag", "input_real", "network-input", "image-a", "global_mode", "content", "x-input", "epoch_step", "lengths", "img_inp", "observ_inputs", "trainA", "ph2tokens", "hed_input", "current_embedding", "X_original", "targets", "ChatInputs", "clean_image", "feat_index", "input_x_front", "sentence", "keep_prob", "filename", "advantage", "new_categorical_placeholder", "source", "hybrid_flag", "left_input", "input_noise", "validating_inp", "kl_coefficient_ph", "image_batch", "steps_per_sec_ph", "input_place", "keyword", "real_images_l", "user_input", "new_kl_rate", "p2s_input", "ph_query", "x_pl", "a", "ids_source", "on_policy_action_reward_in_pl", "dpool_index_word", "query2", "inputs_raw", "CNN_INPUT_x", "input_indices", "train_phase_dropout", "training_mode", "input_1", "x_data", "y_ph", "new_learning_rate", "data", "latent_z", "delta", "is_training", "wavpath", "doc_affinity_scores_ph", "ids_a_ph", "input/lr", "batch_ph", "decoder2", "input_example_tensor", "Y", "y", "on_policy_action_pl", "q1_str", "sentence_one_word", "do_training", "audio_inputs", "ph_image", "horovod_have_more_data_placeholder", "pred_input", "test_input", "input_tensor", "1-step_reward", "input_data", "tokens_mask", "act_step", "x_placeholder", "dropout_rate_ph", "learning_rate", "char_ids", "training", "speech_features", "x_in", "x_input", "encode_mask", "guided_output_5", "client_parameter_name", "ids_ph", "X_placeholder", "advantages", "placeholder_ws", "Ee_pl", "sequence_length", "actions", "images", "mse_weight", "question_ids", "feature", "alpha", "minibatch_in", "api/0", "x", "tile_batch_repetitions", "is_training_flag", "neg_holder", "rating", "qvalue_inputs", "lr", "sentence_one", "dropout_1", "probs", "normalized_input_image_tensor", "state_input", "mat_ph", "real_image", "center_words", "target_y", "input_node", "states", "mc_search", "state", "story", "tokens", "image", "LVBx_pl", "handle", "upsample_size", "x-image1", "input_ids", "stories", "test", "action", "input_image", "dropout_keep_rate", "flow", "im", "sample_weights", "enc_placeholder", "einops_placeholder", "y-classes", "epoch", "inception-images", "placeholder", "inpust", "mean", "sigmaI", "tf_example", "encoded_image_string_tensor", "lod_in", "positive_item", "real_patches", "dropout_keep_prob", "ac", "wave_batch", "address1_ph", "one_step_reward", "user_list_placeholder", "src_placeholder", "x_data_ph", "InputCoords", "Input", "image_paths", "embeddings", "y_label", "assignment-bool", "input_token_indices", "image_ph", "waveform", "source_sentence", "left", "features", "isTrainingflag", "phase_train", "x-sound", "social_holder", "net_phase", "data_handle", "feat_ids", "input_left", "W_th", "training_rewards", "u_idx", "serialized_example", "local_condition_features", "inputs", "input_images", "input_features", "encoder2", "keep_probabilty", "src_features", "input_x", "y_head_ph", "input_feature", "distributions", "src_len", "token_ids", "tf_a", "is_leaf_placeholder", "text", "inarray", "input_words", "tf_x", "kernel_index", null, "input_img", "serving_input_image", "C", "input_placeholder", "cnn_feats", "tf_keep_prob", "placeholder_x", "assert_gpu", "X_inputs", "InputData", "experience/reward", "predictions", "old_params", "input_R_U", "inputs_x", "xs", "image_feed", "w", "input/noise", "inputs_X", "batch_size", "my_tensor", "encoding", "step_size", "input1", "labels", "observations", "training_flag", "X", "query_word", "img_holder", "InputBatch", "premise", "pc_change_est_state_in", "input_text", "imgs_ph", "user_input_id", "instances", "input_plhdr", "tf_train_samples", "global_rec_step_offset", "x1", "input_bytes", "y_true_conf", "image_input", "articles", "MODE"], "ragged": ["MobileNet/input_images", "svhn_images", "images", null, "input", "inputs"]}, "ones_like": {"x": [0, null], "dtype": [0, 2, "f8", "bool", null, "f4", "int32", "float", "int64"], "name": [0, "is_call_options", "weight", null]}, "pow": {"x": [0.5, 1.005, 2.0, 0.2, 2.1, 0.8, 0, 10, 10000, null, -1.0], "a": [0.3333333333333333, 1, 2, 3, 0.5, 0, 6, 1.25, 0.7142857142857143, 1.2, -0.5, 8, 4, 10.0, 5, 18, 2.1, 0.4166666666666667, -0.8, 0.55, -14.0, -12.0, -10.0, null, -6.0, -1.5]}, "ones": {"shape": [0, 1, 2, 3, 4, [19, 19], 5, 6, 8, 9, 10, 7, 12, 11, [3, 7], [2, 5], [24], 32, [10, 8], [1, 2, 4, 1], [5, 5], [1, 2, 2, 1], [1024, 1980, 3], [3, 2, 2], [16], [100, 100, 3], [7], [1, 1], 64, [32], [3, 2], [5, 11], [8], [8, 8, 3], [100], [1, 5, 5, 5, 3], [7, 5], [1, 3, 127, 127], [1024], 100, [0], [655360], [50, 2], [10, 784], [10, 10, 3], [28, 28], [3, 1], [3, 4, 5, 6], [2, 3, 4], [12, 8], 128, [1, 32, 32, 3], [1, 5, 5, 1], [3, 3, 1], [10, 6, 3], [300, 300, 3], [10, 5, 3], [10, 3], [2, 100], [500], [3, 3, 3], [30, 60, 3], [1], [3, 6], [2, 2], [1, 10], [5, 4, 3], [100, 2], [4, 1], [2, 4, 4, 3], [1, 1, 1, 1, 1, 1], [256, 256, 3], [1, 4, 4, 3], [5, 4], 200, [17, 1], [0, 20, 2], 9938, [10], [20, 10], [256, 256, 256], [1, 1, 257], [2, 1, 3], [3, 5], [4, 6], [10, 10], [10, 10, 10, 10], [2], [340, 256], [31, 27], [10, 20], [4, 4, 3], null, [128, 100, 100, 3], [0, 2], [16, 16, 3], [32, 32, 3], [3, 15], [1, 3], [5, 4, 4, 3], [8, 1000, 512], [135559905], [2, 4, 5, 3], [16, 16, 1], [1, 1, 1, 1], [30, 28, 28, 1], [16, 16, 16, 8], 300, [1, 10, 10, 1], [3], [10000], [32, 64, 64], [28, 28, 3], [32, 20, 1], [20], [1, 640, 640, 3], [28, 28, 1], [64, 64, 1], [1, 4], [1, 2, 3], [2, 3], [4, 2], [5, 10, 3], [10, 20, 30], [50, 20], [5, 3], [5, 3, 1], [500, 784], [10, 5], [3, 3, 1, 1], [64, 15], 360, [100, 100], [4], [], [128, 64, 64, 3], [3, 4], [2, 4], [32, 1], [3, 4, 6], [100, 200, 300], [4, 3, 5], [5, 6], [3, 4, 2], [1, 299, 299, 3], [1, 2], [6, 1, 5, 5], [3, 3], [1, 1, 28, 28], [1000], [4, 4], [5000, 10], [2, 6, 6, 1], [6, 3], [19, 19, 1], [5], [7, 10], [15, 15], [8, 2, 10], [8, 16, 16, 1], [1024, 1024], [5, 1, 2], [0, 0], [2, 10], 2000, 464, [48], [64, 1, 28, 28], [1, 1, 1], [2, 2, 2], [128], [10, 28, 28, 1], [16, 128, 128, 3], 1000, [10000, 5000], [784, 1], [1, 3, 3, 5], [8, 8], [2147483654], [6], [10, 2]], "dtype": [0, 1, 128, 3, 4, 2, 5, 7, 8, "float64", 10, 12, 16, 19, 28, "str", 30, 800, 416, "uint32", 32, 40, 300, "float32", "f4", "int32", 64, "f", 200, 720, "int8", 84, 224, 100, 1000, null, "uint8", "int", "uint64"], "name": [128, 1, 2, 3, 4, 5, 0, 8, 10, 12, 16, 20, "init_amplitude", "discount", 28, 32, 416, 40, 300, "init_school_effects_standard", 960, 331, "weights", "stddevs", 84, "initial_state", "SOS", 224, "gamma", "discount_factors", null, -3]}, "normalize_batch_in_training": {"x": [null], "gamma": [0, null], "beta": [0, null], "reduction_axes": ["per-activation", null], "epsilon": [0.001, null]}, "ndim": {"x": [0, null]}, "min": {"x": [0.0, 1, 0.2, 512, 4, 5, 6, 3, 0.4, 0.9, 10.0, 4194304, 2, 8, 1.5, 16, 400, 10000, 20, -1000, 25, 30, 32, 40, 50, 56, 60, 64, 0.1, "value", 196, 100, 1000, 0.01, 6000, 0.9999, "age", 0.005, null, 2147483647, -2, 255], "axis": [0, 1, 512, 1024, 2, 4, 6, 3, 8, 9, 10, 11, 12, 5, 16, 10000, 0.571, 20, 29, 0.05, 40, 300, 50, 0.1, 64, "value", 65536.0, 200, 3800, [0], 100, 0.0004, 0.4, -1, null, -2], "keepdims": [0, true, 2, 10000, null]}, "name_scope": {"name": [0, "", "cell", "expand_is_accepted_like", "a_name_scope", "visualize_conv1", "regularization", "prior_sample", "BoxNetwork", "convert_inputs", "moving_sequence", "cutout", "split_heads", "rnn", "prepare_batch", "train", "safe_exponential", "input_reader", "input", "Flatten", "environment/simulate", "data_preprocessing", "unroll-scan", "generator_summaries", "clip_gradients_by_norm", "LabelAssign", "my", "embedding", "batch_processing", "GetLength", "losses", "CRF", "factored_joint_mvn", "image_preprocess", "quasi-newton", "fused_residual_connection", "one_step_predictive", "evaluation", "rec", "GAN_loss", "add_rir_noise_aecres", "train-summary-per-iteration", "fbank_pitch", "concat_reshape_softmax", "conv1", "Sampler", "dynamic_learning_rate", "accumulated_momentum", "safe_log", "multiply_grads", "decoder_sampler", "match_sentences", "decoder_self_attention_bias", "loading", "constant_program", "image_sampling", "stats_pooling", "label_encode", "conv-maxpool-1", "Initialisation", "Losses/", "blend", "SAC", "loss", "all_reduce", "summaries", "train_scope", "read_memory", "sparse_placeholders", "char-bilstm", "momentum", "dynamic_rnn", "validation", "summarize_vars", "__get_dataset", "output", "PG", "tower__0", "v", "parallel_read", "constraint_loss", "m1", "clip_grads", "cepstrum", "attention_step", "assign_levels", "expression_offset", "add_steps", "Reconstruction", "residual", "ResNet50", "conv2d", "bboxes_areas", "mfcc", "parameters", "split", "assign", "rotate", "CPU_0", "content_vgg", "Preprocessor", "double", "segment_argmax", "encoder", "checkpoint_load", "triple-generation", "EnergyNet", "regress", "m", "polynomial_decay_pruning_schedule", "forward", "layer", "SoftmaxCrossentropy", "recons", "analyfiltbank", "SentenceReader", "constants", "AllReduce", "kldivergence_loss", "ApplyGradients", "mask_activations_and_targets", "weight_decay", "examples_queue", "char-cnn", "Begin_circuit", "Initializer", "hidden", "Inputs_encoder", "LimitMaxSizeOriginalImage", "pruning_ops", "reset_mask", "visualization", "postprocess_fastrcnn_h", "word", "edit_distance_via_next_edit_distance_row", "tower0", "empirical_advantage", "estimate_tails", "matmul_wrapper", "layer_0", "BB1", "pruning_summaries", "classifier_loss", "incr_counter_op", "spectrum", "FramePooling", "datareader", "controller", "dimension_info", "iou_caculate", "CNN", "network", "NormalizeImage", "decode_video", "weighted_sum", "CNN5", "Optimiser", "CS", "convert_to_dyn", "projection_cnn", "tower_0", "q0", "top", "LossFn", "restore", "get_batch", "VizFlow", "AC", "model_inputs", "not_0", "interpolator", "prediction", "MaximumMeanDiscrepancy", "cost", "batchnorm", "sample_lkj", "weights", "parser", "data_dep_init", "a", "Validation", "label_table", "LeakyRelu", "protonn-l2-loss", "train_dataset_loading", "initial_sync_variables", "remove_padding", "fn", "nonlinear", "error", "data", "current_time_step", "mock_model", "placeholder_inputs", "weight_decay_loss", "A3C", "Target", "convLayer1", "write_memory", "content_rpn", "clip_gradients", "preprocessing", "get_target_updater", "bboxes_crop_or_pad", "generate", "Model", "ConvBlock", "Scalar_Summaries", "make_rwmh_kernel_fn", "Y", "coodinate_addition", "tmp1_summaries", "y", "lrelu", "action_prediction", "framepow", "summary/", "word_embeddings", "EuclideanDistance", "synthfiltbank", "_check_labels_and_scores", "construct_gt", "input_tensor", "eval_image", "eval_concat", "hub_input", "Answer", "encode", "Encode", "gram", "GenNoise", "input_data", "construct_linear_system", "num_elements", "randomSelectIndex", "batch_flatten", "stage", "multiGather", "ExtractGlimpse", "optimizer", "LSTM", "get_exemplar_image", "learning_rate", "image_summaries", "training", "critic_loss", "dataset", "sub_mean", "token2ids_preprocessor", "pad_reduce/get_ids", "ema", "patching", "AccumGradOptimizer", "ess_below_threshold", "concat_conditioning", "PPO", "fe", "staget", "source_train_op", "Features", "rgb_to_lab", "pretrain_graph", "dataset_data_provider", "activate_and_scale", "feeder_vars", "normal", "smooth_l1", "scope", "my_attn", "nearest_upsampling", "plp", "coco_metric", "initial_state", "predict_actions", "is_xla_available", "outer", "binarize", "get_rot_mat", "filterbank", "adversarial_loss", "delta_delta", "simple_bucket_model", "step_gt_prob", "Encoder", "elu", "DataAugmentation", "cg", "viz", "apply_gradients", "pitch", "LossA", "hyperparameters", "add_timing_signal", "conv1_time", "add_pos_encoding", "Processing", "update_targets", "crop_image_from_xy", "TRPO", "nuts_test_target_log_prob", "default_joint_bijector", "state", "make_anchors_all_level", "loss_frame_error", "image", "entropy_regularization", "darkon_ihvp", "protoNN", "CS-err", "l2_loss", "moving_average", "RandomRotation", "Loss", "refine_prediction", "test_model", "raw_outputs", "conv", "similarity", "gradients", "dropout", "mean_pool", "RNN", "layer2-pool1", "output_projection", "Interpre_prediction", "vgg_augmented", "instance_filtering_matches", "clip_boxes_to_img_boundaries", "agent_0", "CVR_Task", "AllReduceGrads", "cnn", "computation", "placeholder", "distorted_bounding_box_crop", "environment", "cross_entropy", "define_input", "scattering", "priors_streaming_summary", "Slope_Estimate", "Q-output", "fc1", "reshape", "residual_v1", "batch", "resample", "rnn_output_projection", "begin_episode/", "decompose_from_posterior_marginals", "TacoTestHelper", "Train", "helper_lengths", "to_time_major_tensors", "sample_replay", "focal_loss", "get_initial_state", "model", "GRL_Cell", "accuracy", "decode", "crt_recombine_lagrange", "Create_GRID", "pad_to_same_length", "filter_outside_anchors", "Input", "add_noise_end_to_end", "custom_getter", "KullbackLeibler", "LabelPenalty", "theta", "_inputs", "l1_loss", "Losses", "Custom_Layer", "random-binomial", "embedding_layer", "roiMean", "weight_regularizer", "critic", "load_weights", "compute_loss", "negative_MLS", "fbank", "max_pool", "TD3", "DimensionInput", "create_multiple_gaussian_map", "clip_real_images", "foo", "max_pool-1", "PixelShift", "fabricated_test", "eval_mean", "refiner", "zcr", "bitwise_not", "inputs", "DenseNet", "while", "leaky_relu", "embedding_projection", "generator", "name", "CustomMonitor", "class_balanced_sigmoid_cross_entropy", "interval-location", "standardize_images", "DQN", "positionSensitiveRoiPooling", "MLP", "flip_horizontal", "hidden1", "preprocess", "BoundingBoxTransform/get_width_upright", "bbox_overlap", "IOU", "last_relevant_output", "check_uninitialized_vars", "Inputs", "VisualizeOverlayedHeatmap", "tower_gpu0", "Dataset", "cross_ent", "saturating_sigmoid", "LOSS", "postprocess_fastrcnn", "separable_conv_block_<built-in function id>", "ola", "MobileNetV2", "training-updates", "DDPG", "test_loss", null, "params", "DPPO", "mixed_curriculum", "TargetsData", "norm_non_linearity", "convert_image", "placeholders", "unused_graph", "simulate", "fvp", "ProcessReals", "perceptual_loss", "bar", "optimizee", "rejection_sampler", "rezoom", "augment_with_observation_history", "scope0", "german_credit_numeric", "gradient_descent", "nested_scope", "ExpandedShape", "data_augmentation", "add_example", "get_default_mask", "logsum_expbig_minus_expsmall", "total_loss", "sample_sequence", "cross_entropy_sequence_loss", "get_bboxes", "GRU", "zero_nil_slot", "X", "create_inputs", "decoder", "GPU_0", "select_bboxes", "add", "time_to_batch", "Layer1", "Batch_Inputs", "shift_targets", "MetricAverageCallback", "ComputeSession", "layer1", "distort_color", "smaller_box_loss", "file_name_queue", "fc-layer", "expand-seed", "free_energy", "decode_rgbNflow", "prediction_ops"]}, "mean": {"x": [0, 1, 2, "value", 3, 2.2, "data", "sample", [1, 2, 3], null, "a_mean", -1], "axis": [0, 1, 2, [1, 3], 3, 4, [0, 1, 2], [-1], [-2], [1, 2], [1], [0, 2, 3], [0, 1, 2, 3], "value", [1, 2, 3], [2, 3], [1, 0], [0, 1], [0], [2], -1, null, -2], "keepdims": [false, true, 2, null]}, "not_equal": {"x": ["value", null], "y": [0, 1, "", 5, -2, null, -1]}, "moving_average_update": {"x": [null], "value": ["value", null], "momentum": [null]}, "max": {"x": [0, 1, 2, 3, 0.5, 5, 6, 315561601, 8, 1024, 10, 21, 150, 30, 0.001, "action_policy", 180, 1e-06, 1000000, 0.1, "value", 200, "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", 0.00030000000000000003, -50, -Infinity, [0], 100, 1000, 1e-05, 0.01, "age", [], -10, null, 1e-07, -1], "axis": [0, 1, 2, 3, 0.5, 2048, 5, 6, 8, -0.5, 5000, 4, 1e-08, 9, 13, 10000, 16, 0.571, 0.0001, -100.0, -99.9, [1, 2], [1], 0.0002, [-1, -2], 1e-09, "value", 200, [2, 3], "a", [0], 100, 1e-05, [2], 0.01, -2, null, -1, -3, 0.001], "keepdims": [0, true, 2, 0.5, 5, null]}, "less": {"x": [0, -1e-12, null], "y": [0.0, 1, 2, 0.5, 0.85, 5, 3, 10, "Required environment variables not set", "requires GPU", 0.0001, -90, 0.036, 50, "no gpu detected", 40000, "TF Backend not installed", 0.04000000000000001, "Too slow on Circle CI otherwise", 0.025, "Torch Backend not installed", "TF 2.x only test.", 100, 1e-05, 1000, 0.01, "Test should only be executed if no backend is specified", null]}, "map_fn": {"fn": [0, [0], null], "elems": [0, null], "name": [0, "compress", "input_pngs", "map_fn2get_tok_ids", null, "pmf_to_cdf", "deepfool", "RunClassifier", "sequence_decode"], "dtype": [0, "float", "float32", null]}, "manual_variable_initialization": {"value": [true, "value"]}, "log": {"x": [0, 0.5, 2, 0.8, 1, 0.25, 0.3, "Initializing BPE preprocessor", 0.9, 9.0, 10.0, 6.28318, "W&B is disabled in this directory.  Run `wandb on` to enable cloud syncing.", 13.285714285714295, 6.4, "", 10000.0, 16.0, "No direct encoder input. Using empty initial state", "Reference BLEU wrapper is deprecated", 1e-14, "Component Init", 20, 4.0, 3, 0.6, 4.75, "Loading dataset", "test", "\n#############################################################\n", "Initializing TensorBoard summary writer.", "The experiment directory already exists.", "End position is out of document!", 0.2, 62.5, 0.09090909090909091, "__main__", "Downloading summary data...", "value", "progress", "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", "Creating graph for the ImageNet network.", "Processed 1 images", "Result saved as numpy array to '../github_crawler/tf_pyfiles'", "explore_params_round sample 300 cols", "training", "Use keyboard keys to move. Press escape to quit. Available keys:", "Initialized Tacotron model. Dimensions: ", "kaggle command output:\n%s", 99.0, 100, "controller entered", "loading positives", "Loading INI file: '../github_crawler/tf_pyfiles'", 999.0, 0.4, 0.01, "Writing label mapping for task", "\ton_train_begin", "Error: Malformed output from BEER wrapper:", "Saving the model to:", "Building model...", 0.74, "Result saved as plain text in '../github_crawler/tf_pyfiles'", "Model is built!", "Unable to parse config file; probably being modified by user process?", "Predicted changes:", null, "\nValidation...", -1.0, "Ctrl-c pressed. Waiting for runs to end. Press ctrl-c again to terminate them."]}, "local_conv2d": {"inputs": [null], "kernel": [null], "kernel_size": [null], "strides": [null], "output_shape": [null], "data_format": [0, null]}, "local_conv1d": {"inputs": [null], "kernel": [null], "kernel_size": [[1], null], "strides": [[1], null], "data_format": [0]}, "less_equal": {"x": [2, "value", null], "y": [0.0, 1.0, 2, 3, 1e-09, 0.3, 10.0, null, -1.0, 255.0]}, "l2_normalize": {"x": [0, null], "axis": [-0.3, 1, 2, 3, 0, [0], [3], null, -1]}, "in_top_k": {"predictions": [null], "targets": [null], "k": [1, 5, null]}, "in_test_phase": {"x": [null], "alt": [null], "training": [0]}, "is_sparse": {"tensor": [null]}, "learning_phase": {}, "is_keras_tensor": {"x": [null]}, "in_train_phase": {"x": [null], "alt": [0, null], "training": [0, null]}, "get_value": {"x": ["test/video", "value", "username", "val/acc", "debug", "token", "user", null, "train/loss"]}, "greater": {"x": [0.5, 2, null], "y": [0, 0.5, 0.4, 1.01, 1, 0.25, 3.141592653589793, 1e-16, 2, 0.99999999, -25.0, -0.001, 59536, 30, -2, null, 0.0001, -1]}, "int_shape": {"x": [0, "value", ["tf.reduce_sum(mask, -1, keep_dims", "True)"], null]}, "greater_equal": {"x": [0, 1.01, "value", null], "y": [0.5, 0.0, 33, 1, 2, 3, -90, -180, null]}, "gradients": {"loss": ["value", null], "variables": [0, "x", null]}, "get_uid": {"prefix": ["", null]}, "image_data_format": {}, "hard_sigmoid": {"x": [null]}, "gather": {"reference": [0, 1, "value", null, -2], "indices": [0, 1, "value", [0], -2, null, -1]}, "function": {"inputs": [0, "paddle", 0.5, 3.0, "pytorch", "keras", "darknet", "coreml", "mxnet", "tensorflow_frozen", "tensorflow", "fibonacci", "cntk", 0.1, "value", "simple_mul", "recurrent_forget_mult", [0], "{1}", [], null, "caffe"], "outputs": [false, 1, "value", ["texar.tf.custom"], 5.2, "train", "classify", [], null, "einsum", -3.2, -1, "count"], "updates": [0, 1.2, "numpy", "value", "tensorflow.contrib.sparsemax", "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", [], null], "name": [0, 1, "predict", 3, "get_initial_state_numpy_function", "train_and_updater", "updater", "py_step", "current_time_step_py_func", "f_w2v", "debug compute", "rbm/train-epoch", [], "metric_call_py_func", null, "forward", "ScoreFunction"], "**kwargs": [17, null]}, "foldr": {"fn": [null], "elems": [null], "initializer": [0, "", null], "name": [0, "compute_indexes"]}, "foldl": {"fn": [null], "elems": [null], "initializer": [0, null], "name": [0, "fold_sizes"]}, "floatx": {}, "flatten": {"x": [0, 1, "value", "C", 42, null, -1]}, "exp": {"x": [0, 1.0, -0.1, "value", 2, 5.0, -0.5772156649015329, 1.5, -0.08680555555555555, 9, 3.0, 30, null, -7.0, -5, -3, -1]}, "equal": {"x": [0, 1.01, 2, "value", 1, "1.14.0", 0.5, [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]], "2.0.0.rc1", "2.0.0", null, "testcase/annotated/nas.py"], "y": [0, "", 0.3, true, 3, 0.5, 256, 2, 4, 2.75, 10.0, 5, 8, 13.37, "dev_score", 19, [[true]], ">50K", "_generated/usercode/nas.py", 30, 33, -0.0094548017, -90, 39.0, "hidden_0", 42, "train", "my_data", [0.8, -5, 0.9, 0.8], [0, 1, 2, 3], -0.1, 1e-09, -180, [10], [0], "png", [10, 784], 0.9, [[2.0]], [0, 6], [], -1, null, [true, true, true, true, true], -2]}, "eval": {"x": [0, 1, "u'\\ud800-\\udbff\\\\\\udc00\\udc01-\\udfff'", "value", [0.5], "tf.float64", "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", "startup", null, "#"]}, "epsilon": {}, "elu": {"x": [0, 128, 64, 3, 1, 5, 2, 512, 8, 40, 10, 200, 12, 20, 500, null], "alpha": [0.1, 0.0, 0.2, 32, 3.0, 0.3, 1024, 1.0, 10, "relu", 0.01, 48, "conv_pose_1_1", null, "hidden_activation", -1.7580993408473766]}, "eye": {"size": [0, 1, 2, 3, 4, 5, 37, 7, 1000, 360, 10, 9, 845, 20, null], "dtype": [0, 1, 2, 3, 4, 10, "float32", null, "int"], "name": [0, "initial_inv_hessian", null]}, "dtype": {"x": [0.0, 1, 2.0, 3.0, "float64", 4.0, 2.6, 5.0, 0.9999999925500015, "f8", "data", 16, "float", "|u1", 0.0001, "byte", "U", [1.0], 42.0, "float32", "v", "bool", "object", "f4", "int32", "i", 0.1, "value", "int8", ">i2", "datetime64[ns]", "B", "int64", "16", "O", null, "uint8", "int", -1.0]}, "expand_dims": {"x": [0, 1, 2, "value", 3, -2, null, -1], "axis": [0, 1, 2, 3, [0], 4, [1], [3], [-1], -2, null, -3, -1]}, "dropout": {"x": [0, 0.5, 100, null], "level": [0.5, 0.7, 0.8, 0.3, 0.75, 0.4, 0, 0.25, 0.9, 1, 0.9999999999, 0.22, null, 0.1], "noise_shape": [0, "l1", 0.04, null], "seed": [0, 1, 4926, null]}, "depthwise_conv2d": {"x": [0, null], "depthwise_kernel": [0, null], "strides": [1, [1, 1], [1, 1, 1, 1], null]}, "cumprod": {"x": [null], "axis": [0, 1, -1, null]}, "ctc_decode": {"y_pred": [null], "input_length": [null], "greedy": [true, null], "beam_width": [100], "top_paths": [1]}, "ctc_batch_cost": {"y_true": [null], "y_pred": [null], "input_length": [null], "label_length": [null]}, "cos": {"x": [0, 3.1416, 4, 3.14, 20, null]}, "conv3d": {"x": [null], "kernel": [64, 32, 0, 16, 19, null], "strides": [1, 3, null, [1, 1, 1], [1, 1, 1, 1, 1], [1, 3, 3]]}, "conv2d_transpose": {"x": [0, "value", null], "kernel": [64, 0, 2, 32, 512, 256, 128, 5, 11, 16, null, 29], "output_shape": [0, 1, 2, 3, 4, 5, 6, null, [2, 2]], "strides": [1, 2, null, [1, 1, 1, 1], [2, 1], 22, [2, 2], [1, 1]]}, "conv2d": {"x": [0, 64, 1, "value", "conv_1", "conv1", 20, null], "kernel": [4096, 128, 0, 2, 3, 1, 256, 5, 512, 8, 10, 7, 12, 13, 16, 19, 20, 24, 768, 32, 1024, "conv1", 64, "cnn-2", 96, "../github_crawler/tf_pyfiles", null], "strides": [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, [1, 1, 1, 1], 16, [3, 3], [2, 2], [1, 1], "conv2d_1", 96, "same", null]}, "conv1d": {"x": ["value", null], "kernel": [0, 128, null], "strides": [128, 1, 2, "conv1d_3", null], "padding": [0, "valid", "same", "VALID", null, "SAME"], "data_format": [0, "NWC", "NCW", "NHWC", "channels_middle", null], "dilation_rate": [0.0, 1, null]}, "count_params": {"x": [null]}, "cast_to_floatx": {"x": [0.96, 1.0, 0.01, null]}, "clip": {"x": [0, -5, -1, null], "min_value": [0.0, -32768, 1, 3, -10000000000.0, 5, -250, -0.5, 1e-08, -500, 0.0001, 0.001, 1e-12, 1e-06, -64, 0.1, [0, 0], -50, -0.05, 1e-05, 1e-10, -20.0, -10, null, -2, 1e-07, -5, -1, 255], "max_value": [0.999, 1.0, 0.99999999, 0.9999999999, 0, 0.9999, 6.0, 10000000000.0, 0.9999999, 255.0, 10, 5, 1e-08, 2, 8, 256, 10000, 20, 0.5, 32, 0.05, 50, 64, 500, null, 250, -1.0, 32767]}, "clear_session": {}, "ctc_label_dense_to_sparse": {"labels": [null], "label_lengths": [null]}, "cast": {"x": [0, 0.96, 10000000000.0, "value", 2, 1, [1.0], 1e-26, "filename_test", 0.5, 10, -2000.0, [5], "long", null, -1.0], "dtype": [0, 1, 2, "value", "float64", 0.2, "float32", "bool", null, "uint8", "int32", "float", "int64"]}, "constant": {"value": [0, true, 2.0, 10000000000.0, 4.0, 0.5, 3.0, 6.0, 5.0, 7, 10, -0.25, 12, "", 0.25, 9, 16, 17.0, "image_000000", [2.0, 2.0, 2.0, 2.0, 2.0], [3.0, 3.0, 3.0, 3.0, 3.0], 0.0001, "image1", 32.0, 0.111, 0.75, 1.5, 40.0, 42.0, "train", 64, 0.54, "value", "THE_ANSWER", [0], [0.5], 100.0, [0.8], 0.0004, [42.0], "Hello world ! \u7b11\uff57", 123, 127.5, 0.2, 0.28209479177387814, [1e-06], 2.506628274631, "Hello World!", 99999.0, 100000, [1.0], "                                                                ", [Infinity, Infinity, Infinity], [0.01], 1e-06, -0.1, [0.0, 0.0, 1.0], -Infinity, "gym_lib.CARTPOLE_OBSERVATION_SHAPE", [1e-08], [[]], ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"], [-3.0, -3.0, -3.0, -3.0, -3.0, 15.0], 1.23, "torch.float16", [2.0], ["nokey"], null, 0.001, 255, 0.999999, 0.9, 0.4, "/tmp/original/export/assets", [-1], "Welcome to TensorFlow world!", [[1.0]], [0.0, 0.0, 100.0], [1, 42], "test", "nop", [3.0], 1e-30, 1e-12, "aoo", [[10]], 1.2, [2, 2, 2, 2, 2, 2], 0.1, "a b c", ["A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z"], [12], [["Bachelors"]], [[0.999, 0.999, 0.999, 0.999]], 1e-05, [], -0.2, 0.316, [128, 64, 32, 16, 8, 4, 2, 1], "Present", 0.05, ["../github_crawler/tf_pyfiles/tangyudi__Ai-Learn.csv", "../github_crawler/tf_pyfiles/tokestermw__tensorflow-shakespeare.csv", "../github_crawler/tf_pyfiles/huoyijie__AdvancedEAST.csv", "../github_crawler/tf_pyfiles/guillaumegenthial__sequence_tagging.csv", "../github_crawler/tf_pyfiles/una-dinosauria__human-motion-prediction.csv", "../github_crawler/tf_pyfiles/github__CodeSearchNet.csv", "../github_crawler/tf_pyfiles/ClimbsRocks__auto_ml.csv", "../github_crawler/tf_pyfiles/YangZeyu95__unofficial-implement-of-openpose.csv", "../github_crawler/tf_pyfiles/ematvey__hierarchical-attention-networks.csv", "../github_crawler/tf_pyfiles/curiousily__Deep-Learning-For-Hackers.csv", "../github_crawler/tf_pyfiles/yukezhu__tensorflow-reinforce.csv", "../github_crawler/tf_pyfiles/NVIDIA__OpenSeq2Seq.csv", "../github_crawler/tf_pyfiles/tensorflow__rust.csv", "../github_crawler/tf_pyfiles/bhaveshoswal__CNN-text-classification-keras.csv", "../github_crawler/tf_pyfiles/Xtremilicious__ProjectLearn-Project-Based-Learning.csv", "../github_crawler/tf_pyfiles/idealo__imageatm.csv", "../github_crawler/tf_pyfiles/fo40225__tensorflow-windows-wheel.csv", "../github_crawler/tf_pyfiles/tensorlayer__openpose-plus.csv", "../github_crawler/tf_pyfiles/laughtervv__SGPN.csv", "../github_crawler/tf_pyfiles/pqpo__SmartCropper.csv", "../github_crawler/tf_pyfiles/lifeomic__sparkflow.csv", "../github_crawler/tf_pyfiles/shekkizh__FCN.tensorflow.csv", "../github_crawler/tf_pyfiles/ritchieng__dlami.csv", "../github_crawler/tf_pyfiles/jakeret__tf_unet.csv", "../github_crawler/tf_pyfiles/zkywsg__Daily-DeepLearning.csv", "../github_crawler/tf_pyfiles/ryouchinsa__Rectlabel-support.csv", "../github_crawler/tf_pyfiles/nex3z__tflite-mnist-android.csv", "../github_crawler/tf_pyfiles/rasbt__deep-learning-book.csv", "../github_crawler/tf_pyfiles/allenai__bi-att-flow.csv", "../github_crawler/tf_pyfiles/DJTobias__Cherry-Autonomous-Racecar.csv", "../github_crawler/tf_pyfiles/hollance__TensorFlow-iOS-Example.csv", "../github_crawler/tf_pyfiles/fendouai__Chinese-Text-Classification.csv", "../github_crawler/tf_pyfiles/0x454447415244__HandwritingRecognitionSystem.csv", "../github_crawler/tf_pyfiles/virgili0__Virgilio.csv", "../github_crawler/tf_pyfiles/vahidk__EffectiveTensorflow.csv", "../github_crawler/tf_pyfiles/kaonashi-tyc__zi2zi.csv", "../github_crawler/tf_pyfiles/Linzaer__Face-Track-Detect-Extract.csv", "../github_crawler/tf_pyfiles/tensorlayer__srgan.csv", "../github_crawler/tf_pyfiles/Timthony__self_drive.csv", "../github_crawler/tf_pyfiles/Roujack__mathAI.csv", "../github_crawler/tf_pyfiles/kyzhouhzau__BERT-NER.csv", "../github_crawler/tf_pyfiles/xuanjihe__speech-emotion-recognition.csv", "../github_crawler/tf_pyfiles/keras-team__keras-contrib.csv", "../github_crawler/tf_pyfiles/google-research__bert.csv", "../github_crawler/tf_pyfiles/HasnainRaz__Fast-SRGAN.csv", "../github_crawler/tf_pyfiles/juliandewit__kaggle_ndsb2017.csv", "../github_crawler/tf_pyfiles/marcbelmont__cnn-watermark-removal.csv", "../github_crawler/tf_pyfiles/amineHorseman__facial-expression-recognition-using-cnn.csv", "../github_crawler/tf_pyfiles/sugyan__tensorflow-mnist.csv", "../github_crawler/tf_pyfiles/KichangKim__DeepDanbooru.csv", "../github_crawler/tf_pyfiles/wizardforcel__data-science-notebook.csv", "../github_crawler/tf_pyfiles/kymatio__kymatio.csv", "../github_crawler/tf_pyfiles/williamFalcon__tensorflow-gpu-install-ubuntu-16.04.csv", "../github_crawler/tf_pyfiles/TarrySingh__Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials.csv", "../github_crawler/tf_pyfiles/deepmind__sonnet.csv", "../github_crawler/tf_pyfiles/zihangdai__xlnet.csv", "../github_crawler/tf_pyfiles/arahusky__Tensorflow-Segmentation.csv", "../github_crawler/tf_pyfiles/sicara__tf-explain.csv", "../github_crawler/tf_pyfiles/hamelsmu__code_search.csv", "../github_crawler/tf_pyfiles/CLUEbenchmark__CLUE.csv", "../github_crawler/tf_pyfiles/hughperkins__tf-coriander.csv", "../github_crawler/tf_pyfiles/yandexdataschool__Practical_RL.csv", "../github_crawler/tf_pyfiles/YunYang1994__tensorflow-yolov3.csv", "../github_crawler/tf_pyfiles/adhiraiyan__DeepLearningWithTF2.0.csv", "../github_crawler/tf_pyfiles/ardamavi__Vocalization-Sign-Language-iOS.csv", "../github_crawler/tf_pyfiles/nl8590687__ASRT_SpeechRecognition.csv", "../github_crawler/tf_pyfiles/yrlu__irl-imitation.csv", "../github_crawler/tf_pyfiles/ageron__handson-ml.csv", "../github_crawler/tf_pyfiles/CyberZHG__keras-radam.csv", "../github_crawler/tf_pyfiles/tflearn__tflearn.csv", "../github_crawler/tf_pyfiles/svjan5__GNNs-for-NLP.csv", "../github_crawler/tf_pyfiles/rameshvarun__NeuralKart.csv", "../github_crawler/tf_pyfiles/savan77__The-GAN-World.csv", "../github_crawler/tf_pyfiles/dragen1860__Deep-Learning-with-TensorFlow-book.csv", "../github_crawler/tf_pyfiles/dongjun-Lee__text-summarization-tensorflow.csv", "../github_crawler/tf_pyfiles/lbeaucourt__Object-detection.csv", "../github_crawler/tf_pyfiles/jzilly__RecurrentHighwayNetworks.csv", "../github_crawler/tf_pyfiles/argman__EAST.csv", "../github_crawler/tf_pyfiles/mind__wheels.csv", "../github_crawler/tf_pyfiles/brucechou1983__CheXNet-Keras.csv", "../github_crawler/tf_pyfiles/opencv__cvat.csv", "../github_crawler/tf_pyfiles/IsaacChanghau__neural_sequence_labeling.csv", "../github_crawler/tf_pyfiles/re-search__DocProduct.csv", "../github_crawler/tf_pyfiles/A-bone1__Attention-ocr-Chinese-Version.csv", "../github_crawler/tf_pyfiles/DrSleep__tensorflow-deeplab-lfov.csv", "../github_crawler/tf_pyfiles/yukitsuji__3D_CNN_tensorflow.csv", "../github_crawler/tf_pyfiles/mjdietzx__GAN-Sandbox.csv", "../github_crawler/tf_pyfiles/lspvic__jupyter_tensorboard.csv", "../github_crawler/tf_pyfiles/ragulpr__wtte-rnn.csv", "../github_crawler/tf_pyfiles/uclaacmai__Generative-Adversarial-Network-Tutorial.csv", "../github_crawler/tf_pyfiles/1202kbs__Understanding-NN.csv", "../github_crawler/tf_pyfiles/osmr__imgclsmob.csv", "../github_crawler/tf_pyfiles/IBM__tensorflow-hangul-recognition.csv", "../github_crawler/tf_pyfiles/vladfi1__phillip.csv", "../github_crawler/tf_pyfiles/richardaecn__class-balanced-loss.csv", "../github_crawler/tf_pyfiles/tensorpack__tensorpack.csv", "../github_crawler/tf_pyfiles/FlinkML__flink-tensorflow.csv", "../github_crawler/tf_pyfiles/Alro10__deep-learning-time-series.csv", "../github_crawler/tf_pyfiles/itdxer__neupy.csv", "../github_crawler/tf_pyfiles/astorfi__TensorFlow-World.csv", "../github_crawler/tf_pyfiles/motlabs__awesome-ml-demos-with-ios.csv", "../github_crawler/tf_pyfiles/wookayin__tensorflow-talk-debugging.csv", "../github_crawler/tf_pyfiles/titu1994__Keras-NASNet.csv", "../github_crawler/tf_pyfiles/jolibrain__deepdetect.csv", "../github_crawler/tf_pyfiles/domluna__memn2n.csv", "../github_crawler/tf_pyfiles/cydonia999__Tiny_Faces_in_Tensorflow.csv", "../github_crawler/tf_pyfiles/kerlomz__captcha_platform.csv", "../github_crawler/tf_pyfiles/fendouai__Awesome-TensorFlow-Chinese.csv", "../github_crawler/tf_pyfiles/hwalsuklee__tensorflow-generative-model-collections.csv", "../github_crawler/tf_pyfiles/Burton2000__CS231n-2017.csv", "../github_crawler/tf_pyfiles/androidthings__sample-tensorflow-imageclassifier.csv", "../github_crawler/tf_pyfiles/drawbridge__keras-mmoe.csv", "../github_crawler/tf_pyfiles/mckinziebrandon__DeepChatModels.csv", "../github_crawler/tf_pyfiles/kk7nc__RMDL.csv", "../github_crawler/tf_pyfiles/miyosuda__unreal.csv", "../github_crawler/tf_pyfiles/hthuwal__sign-language-gesture-recognition.csv", "../github_crawler/tf_pyfiles/lakshayg__tensorflow-build-archived.csv", "../github_crawler/tf_pyfiles/thekevinscott__ml-classifier-ui.csv", "../github_crawler/tf_pyfiles/savan77__Practical-Machine-Learning-With-Python.csv", "../github_crawler/tf_pyfiles/bakwc__PornDetector.csv", "../github_crawler/tf_pyfiles/devicehive__devicehive-audio-analysis.csv", "../github_crawler/tf_pyfiles/theamrzaki__text_summurization_abstractive_methods.csv", "../github_crawler/tf_pyfiles/taki0112__MUNIT-Tensorflow.csv", "../github_crawler/tf_pyfiles/watsonyanghx__CNN_LSTM_CTC_Tensorflow.csv", "../github_crawler/tf_pyfiles/minimaxir__gpt-2-simple.csv", "../github_crawler/tf_pyfiles/yuxitong__TensorFlowAndroidDemo.csv", "../github_crawler/tf_pyfiles/Thinklab-SJTU__R3Det_Tensorflow.csv", "../github_crawler/tf_pyfiles/Separius__BERT-keras.csv", "../github_crawler/tf_pyfiles/PatrickLib__captcha_recognize.csv", "../github_crawler/tf_pyfiles/changwookjun__StudyBook.csv", "../github_crawler/tf_pyfiles/hellochick__ICNet-tensorflow.csv", "../github_crawler/tf_pyfiles/ufal__neuralmonkey.csv", "../github_crawler/tf_pyfiles/genicam__harvesters.csv", "../github_crawler/tf_pyfiles/icoxfog417__tensorflow_qrnn.csv", "../github_crawler/tf_pyfiles/google__nucleus.csv", "../github_crawler/tf_pyfiles/duxingren14__DualGAN.csv", "../github_crawler/tf_pyfiles/Arturus__kaggle-web-traffic.csv", "../github_crawler/tf_pyfiles/HardcoreJosh__JoshieGo.csv", "../github_crawler/tf_pyfiles/raghakot__keras-text.csv", "../github_crawler/tf_pyfiles/idealo__imagededup.csv", "../github_crawler/tf_pyfiles/SharpAI__DeepCamera.csv", "../github_crawler/tf_pyfiles/mjdietzx__SimGAN.csv", "../github_crawler/tf_pyfiles/TensorFlowKR__dlcampjeju.csv", "../github_crawler/tf_pyfiles/ChenglongChen__tensorflow-XNN.csv", "../github_crawler/tf_pyfiles/tensorlayer__tensorlayer.csv", "../github_crawler/tf_pyfiles/galeone__dynamic-training-bench.csv", "../github_crawler/tf_pyfiles/610265158__Peppa_Pig_Face_Engine.csv", "../github_crawler/tf_pyfiles/nicrusso7__rex-gym.csv", "../github_crawler/tf_pyfiles/MorvanZhou__train-robot-arm-from-scratch.csv", "../github_crawler/tf_pyfiles/rcmalli__keras-vggface.csv", "../github_crawler/tf_pyfiles/didi__delta.csv", "../github_crawler/tf_pyfiles/RandolphVI__Text-Pairs-Relation-Classification.csv", "../github_crawler/tf_pyfiles/linkedin__TonY.csv", "../github_crawler/tf_pyfiles/cysmith__neural-style-tf.csv", "../github_crawler/tf_pyfiles/guillaume-chevalier__HAR-stacked-residual-bidir-LSTMs.csv", "../github_crawler/tf_pyfiles/yahoo__TensorFlowOnSpark.csv", "../github_crawler/tf_pyfiles/tobybreckon__fire-detection-cnn.csv", "../github_crawler/tf_pyfiles/endernewton__tf-faster-rcnn.csv", "../github_crawler/tf_pyfiles/sadeepj__crfasrnn_keras.csv", "../github_crawler/tf_pyfiles/php-opencv__php-opencv-examples.csv", "../github_crawler/tf_pyfiles/axelbrando__Mixture-Density-Networks-for-distribution-and-uncertainty-estimation.csv", "../github_crawler/tf_pyfiles/huawei-noah__ghostnet.csv", "../github_crawler/tf_pyfiles/robi56__Deep-Learning-for-Recommendation-Systems.csv", "../github_crawler/tf_pyfiles/wagamamaz__tensorlayer-tricks.csv", "../github_crawler/tf_pyfiles/nicolov__segmentation_keras.csv", "../github_crawler/tf_pyfiles/raghakot__keras-vis.csv", "../github_crawler/tf_pyfiles/pmh47__dirt.csv", "../github_crawler/tf_pyfiles/Hyperparticle__one-pixel-attack-keras.csv", "../github_crawler/tf_pyfiles/mouradmourafiq__tensorflow-lstm-regression.csv", "../github_crawler/tf_pyfiles/twhui__LiteFlowNet.csv", "../github_crawler/tf_pyfiles/JohnSnowLabs__spark-nlp.csv", "../github_crawler/tf_pyfiles/ahmetozlu__vehicle_counting_tensorflow.csv", "../github_crawler/tf_pyfiles/taehoonlee__tensornets.csv", "../github_crawler/tf_pyfiles/LeslieZhoa__tensorflow-MTCNN.csv", "../github_crawler/tf_pyfiles/naturomics__CapsLayer.csv", "../github_crawler/tf_pyfiles/yuanxiaosc__Entity-Relation-Extraction.csv", "../github_crawler/tf_pyfiles/carpedm20__NTM-tensorflow.csv", "../github_crawler/tf_pyfiles/art-programmer__PlaneNet.csv", "../github_crawler/tf_pyfiles/gustavz__realtime_object_detection.csv", "../github_crawler/tf_pyfiles/mindsdb__mindsdb.csv", "../github_crawler/tf_pyfiles/IBM__FfDL.csv", "../github_crawler/tf_pyfiles/xiaohu2015__DeepLearning_tutorials.csv", "../github_crawler/tf_pyfiles/Kismuz__btgym.csv", "../github_crawler/tf_pyfiles/huggingface__transformers.csv", "../github_crawler/tf_pyfiles/ashnkumar__sketch-code.csv", "../github_crawler/tf_pyfiles/yanshengjia__ml-road.csv", "../github_crawler/tf_pyfiles/dctian__DeepPiCar.csv", "../github_crawler/tf_pyfiles/harvitronix__five-video-classification-methods.csv", "../github_crawler/tf_pyfiles/pannous__tensorflow-speech-recognition.csv", "../github_crawler/tf_pyfiles/ruiminshen__yolo-tf.csv", "../github_crawler/tf_pyfiles/hfp__libxsmm.csv", "../github_crawler/tf_pyfiles/nfmcclure__tensorflow_cookbook.csv", "../github_crawler/tf_pyfiles/HRLTY__TP-GAN.csv", "../github_crawler/tf_pyfiles/sirius-ai__MobileFaceNet_TF.csv", "../github_crawler/tf_pyfiles/DmitryUlyanov__neural-style-audio-tf.csv", "../github_crawler/tf_pyfiles/drscotthawley__panotti.csv", "../github_crawler/tf_pyfiles/FloopCZ__tensorflow_cc.csv", "../github_crawler/tf_pyfiles/hwalsuklee__tensorflow-fast-style-transfer.csv", "../github_crawler/tf_pyfiles/carpedm20__MemN2N-tensorflow.csv", "../github_crawler/tf_pyfiles/liu-nlper__NER-LSTM-CRF.csv", "../github_crawler/tf_pyfiles/SciSharp__TensorFlow.NET.csv", "../github_crawler/tf_pyfiles/yorkie__tensorflow-nodejs.csv", "../github_crawler/tf_pyfiles/Hydrospheredata__hydro-serving.csv", "../github_crawler/tf_pyfiles/Coder-Yu__RecQ.csv", "../github_crawler/tf_pyfiles/MarvinTeichmann__KittiSeg.csv", "../github_crawler/tf_pyfiles/BIGBALLON__cifar-10-cnn.csv", "../github_crawler/tf_pyfiles/marl__crepe.csv", "../github_crawler/tf_pyfiles/deepmind__graph_nets.csv", "../github_crawler/tf_pyfiles/geffy__tffm.csv", "../github_crawler/tf_pyfiles/jiamings__fast-weights.csv", "../github_crawler/tf_pyfiles/dongjun-Lee__text-classification-models-tf.csv", "../github_crawler/tf_pyfiles/alibaba__flink-ai-extended.csv", "../github_crawler/tf_pyfiles/sampepose__flownet2-tf.csv", "../github_crawler/tf_pyfiles/onnx__tensorflow-onnx.csv", "../github_crawler/tf_pyfiles/hirofumi0810__tensorflow_end2end_speech_recognition.csv", "../github_crawler/tf_pyfiles/HiKapok__tf.fashionAI.csv", "../github_crawler/tf_pyfiles/MarvinTeichmann__tensorflow-fcn.csv", "../github_crawler/tf_pyfiles/microsoft__pai.csv", "../github_crawler/tf_pyfiles/Zhenye-Na__machine-learning-uiuc.csv", "../github_crawler/tf_pyfiles/thomasschmied__Text_Summarization_with_Tensorflow.csv", "../github_crawler/tf_pyfiles/dinghanshen__SWEM.csv", "../github_crawler/tf_pyfiles/deepdrive__deepdrive.csv", "../github_crawler/tf_pyfiles/blakeblackshear__frigate.csv", "../github_crawler/tf_pyfiles/rasbt__python-machine-learning-book-2nd-edition.csv", "../github_crawler/tf_pyfiles/greydanus__scribe.csv", "../github_crawler/tf_pyfiles/jimfleming__recurrent-entity-networks.csv", "../github_crawler/tf_pyfiles/DrSleep__tensorflow-deeplab-resnet.csv", "../github_crawler/tf_pyfiles/JiahuiYu__generative_inpainting.csv", "../github_crawler/tf_pyfiles/krasserm__super-resolution.csv", "../github_crawler/tf_pyfiles/mfigurnov__sact.csv", "../github_crawler/tf_pyfiles/tjwei__GANotebooks.csv", "../github_crawler/tf_pyfiles/horovod__horovod.csv", "../github_crawler/tf_pyfiles/Breta01__handwriting-ocr.csv", "../github_crawler/tf_pyfiles/lyhue1991__eat_tensorflow2_in_30_days.csv", "../github_crawler/tf_pyfiles/as-ideas__TransformerTTS.csv", "../github_crawler/tf_pyfiles/devsisters__pointer-network-tensorflow.csv", "../github_crawler/tf_pyfiles/huangshiyu13__RPNplus.csv", "../github_crawler/tf_pyfiles/tf-encrypted__tf-encrypted.csv", "../github_crawler/tf_pyfiles/ZhiqingXiao__rl-book.csv", "../github_crawler/tf_pyfiles/conan7882__adversarial-autoencoders.csv", "../github_crawler/tf_pyfiles/didi__AoE.csv", "../github_crawler/tf_pyfiles/see--__keras-centernet.csv", "../github_crawler/tf_pyfiles/PatWie__tensorflow-cmake.csv", "../github_crawler/tf_pyfiles/Zehaos__MobileNet.csv", "../github_crawler/tf_pyfiles/Robinwho__Deep-Learning.csv", "../github_crawler/tf_pyfiles/kwotsin__TensorFlow-Xception.csv", "../github_crawler/tf_pyfiles/Naresh1318__Adversarial_Autoencoder.csv", "../github_crawler/tf_pyfiles/tensorflow__docs.csv", "../github_crawler/tf_pyfiles/tensorflow__lucid.csv", "../github_crawler/tf_pyfiles/vipstone__faceai.csv", "../github_crawler/tf_pyfiles/abhaydoke09__Bilinear-CNN-TensorFlow.csv", "../github_crawler/tf_pyfiles/santi-pdp__segan.csv", "../github_crawler/tf_pyfiles/microsoft__MMdnn.csv", "../github_crawler/tf_pyfiles/Alfredvc__paac.csv", "../github_crawler/tf_pyfiles/bamos__dcgan-completion.tensorflow.csv", "../github_crawler/tf_pyfiles/hmishra2250__NTM-One-Shot-TF.csv", "../github_crawler/tf_pyfiles/merantix__picasso.csv", "../github_crawler/tf_pyfiles/ahundt__awesome-robotics.csv", "../github_crawler/tf_pyfiles/DetectionTeamUCAS__R2CNN-Plus-Plus_Tensorflow.csv", "../github_crawler/tf_pyfiles/tensorflow__tfx.csv", "../github_crawler/tf_pyfiles/LynnHo__DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2.csv", "../github_crawler/tf_pyfiles/vlawhern__arl-eegmodels.csv", "../github_crawler/tf_pyfiles/samjabrahams__tensorflow-on-raspberry-pi.csv", "../github_crawler/tf_pyfiles/guillaume-chevalier__Awesome-Deep-Learning-Resources.csv", "../github_crawler/tf_pyfiles/damianmoore__photonix.csv", "../github_crawler/tf_pyfiles/arogozhnikov__einops.csv", "../github_crawler/tf_pyfiles/yoyoyo-yo__DeepLearningMugenKnock.csv", "../github_crawler/tf_pyfiles/hjptriplebee__VGG19_with_tensorflow.csv", "../github_crawler/tf_pyfiles/dmesquita__understanding_tensorflow_nn.csv", "../github_crawler/tf_pyfiles/dragen1860__TensorFlow-2.x-Tutorials.csv", "../github_crawler/tf_pyfiles/moabitcoin__holy-edge.csv", "../github_crawler/tf_pyfiles/delira-dev__delira.csv", "../github_crawler/tf_pyfiles/inoryy__reaver.csv", "../github_crawler/tf_pyfiles/roatienza__Deep-Learning-Experiments.csv", "../github_crawler/tf_pyfiles/shekkizh__WassersteinGAN.tensorflow.csv", "../github_crawler/tf_pyfiles/carpedm20__deep-rl-tensorflow.csv", "../github_crawler/tf_pyfiles/zhourunlai__learning.csv", "../github_crawler/tf_pyfiles/lgsvl__simulator.csv", "../github_crawler/tf_pyfiles/DemisEom__SpecAugment.csv", "../github_crawler/tf_pyfiles/krishnakumarsekar__awesome-quantum-machine-learning.csv", "../github_crawler/tf_pyfiles/golbin__TensorFlow-Tutorials.csv", "../github_crawler/tf_pyfiles/OsciiArt__DeepAA.csv", "../github_crawler/tf_pyfiles/nikhilk__node-tensorflow.csv", "../github_crawler/tf_pyfiles/bangoc123__learn-machine-learning-in-two-months.csv", "../github_crawler/tf_pyfiles/materialsvirtuallab__megnet.csv", "../github_crawler/tf_pyfiles/ysh329__deep-learning-model-convertor.csv", "../github_crawler/tf_pyfiles/ipazc__mtcnn.csv", "../github_crawler/tf_pyfiles/DongjunLee__text-cnn-tensorflow.csv", "../github_crawler/tf_pyfiles/maxim5__time-series-machine-learning.csv", "../github_crawler/tf_pyfiles/szagoruyko__functional-zoo.csv", "../github_crawler/tf_pyfiles/MorvanZhou__tutorials.csv", "../github_crawler/tf_pyfiles/victordibia__handtracking.csv", "../github_crawler/tf_pyfiles/adeshpande3__Generative-Adversarial-Networks.csv", "../github_crawler/tf_pyfiles/mkocabas__pose-residual-network.csv", "../github_crawler/tf_pyfiles/RedisAI__RedisAI.csv", "../github_crawler/tf_pyfiles/benedekrozemberczki__AttentionWalk.csv", "../github_crawler/tf_pyfiles/Conchylicultor__DeepQA.csv", "../github_crawler/tf_pyfiles/google-research__recsim.csv", "../github_crawler/tf_pyfiles/suragnair__alpha-zero-general.csv", "../github_crawler/tf_pyfiles/thtrieu__darkflow.csv", "../github_crawler/tf_pyfiles/tinrab__go-tensorflow-image-recognition.csv", "../github_crawler/tf_pyfiles/loretoparisi__CapsNet.csv", "../github_crawler/tf_pyfiles/amir-abdi__keras_to_tensorflow.csv", "../github_crawler/tf_pyfiles/hunkim__word-rnn-tensorflow.csv", "../github_crawler/tf_pyfiles/Amin-Tgz__awesome-tensorflow-2.csv", "../github_crawler/tf_pyfiles/PRBonn__bonnet.csv", "../github_crawler/tf_pyfiles/minhnhat93__tf-SNDCGAN.csv", "../github_crawler/tf_pyfiles/peterlee0127__tensorflow-nvJetson.csv", "../github_crawler/tf_pyfiles/roomylee__cnn-relation-extraction.csv", "../github_crawler/tf_pyfiles/xitu__tensorflow-docs.csv", "../github_crawler/tf_pyfiles/MorvanZhou__Tensorflow-Tutorial.csv", "../github_crawler/tf_pyfiles/zjjMaiMai__Deep-Alignment-Network-A-convolutional-neural-network-for-robust-face-alignment.csv", "../github_crawler/tf_pyfiles/hunglc007__tensorflow-yolov4-tflite.csv", "../github_crawler/tf_pyfiles/sjvasquez__handwriting-synthesis.csv", "../github_crawler/tf_pyfiles/aws__sagemaker-tensorflow-container.csv", "../github_crawler/tf_pyfiles/rndbrtrnd__udacity-deep-learning.csv", "../github_crawler/tf_pyfiles/benedekrozemberczki__MixHop-and-N-GCN.csv", "../github_crawler/tf_pyfiles/timctho__VNect-tensorflow.csv", "../github_crawler/tf_pyfiles/pat-coady__trpo.csv", "../github_crawler/tf_pyfiles/meownoid__face-identification-tpe.csv", "../github_crawler/tf_pyfiles/gnes-ai__gnes.csv", "../github_crawler/tf_pyfiles/charlesq34__pointnet.csv", "../github_crawler/tf_pyfiles/Mikoto10032__DeepLearning.csv", "../github_crawler/tf_pyfiles/AIInAi__tf-insightface.csv", "../github_crawler/tf_pyfiles/NervanaSystems__ngraph.csv", "../github_crawler/tf_pyfiles/uvipen__AirGesture.csv", "../github_crawler/tf_pyfiles/mnicnc404__CartoonGan-tensorflow.csv", "../github_crawler/tf_pyfiles/DetectionTeamUCAS__RRPN_Faster-RCNN_Tensorflow.csv", "../github_crawler/tf_pyfiles/NervanaSystems__nlp-architect.csv", "../github_crawler/tf_pyfiles/DjangoPeng__tensorflow-101.csv", "../github_crawler/tf_pyfiles/combust__mleap.csv", "../github_crawler/tf_pyfiles/githubharald__CTCWordBeamSearch.csv", "../github_crawler/tf_pyfiles/virajmavani__semi-auto-image-annotation-tool.csv", "../github_crawler/tf_pyfiles/machinelearningmindset__TensorFlow-Course.csv", "../github_crawler/tf_pyfiles/Leavingseason__OpenLearning4DeepRecsys.csv", "../github_crawler/tf_pyfiles/CVLAB-Unibo__Real-time-self-adaptive-deep-stereo.csv", "../github_crawler/tf_pyfiles/alshedivat__keras-gp.csv", "../github_crawler/tf_pyfiles/srvk__eesen.csv", "../github_crawler/tf_pyfiles/minimaxir__automl-gs.csv", "../github_crawler/tf_pyfiles/guillaume-chevalier__LSTM-Human-Activity-Recognition.csv", "../github_crawler/tf_pyfiles/waleedka__hiddenlayer.csv", "../github_crawler/tf_pyfiles/charlesXu86__Chatbot_CN.csv", "../github_crawler/tf_pyfiles/lvapeab__nmt-keras.csv", "../github_crawler/tf_pyfiles/taki0112__Densenet-Tensorflow.csv", "../github_crawler/tf_pyfiles/ModelDepot__tfjs-yolo-tiny.csv", "../github_crawler/tf_pyfiles/jostmey__NakedTensor.csv", "../github_crawler/tf_pyfiles/iitzco__faced.csv", "../github_crawler/tf_pyfiles/keras-team__autokeras.csv", "../github_crawler/tf_pyfiles/guan-yuan__awesome-AutoML-and-Lightweight-Models.csv", "../github_crawler/tf_pyfiles/githubharald__SimpleHTR.csv", "../github_crawler/tf_pyfiles/felipessalvatore__self_driving_pi_car.csv", "../github_crawler/tf_pyfiles/yanshengjia__artificial-intelligence.csv", "../github_crawler/tf_pyfiles/kerlomz__captcha_trainer.csv", "../github_crawler/tf_pyfiles/carpedm20__pixel-rnn-tensorflow.csv", "../github_crawler/tf_pyfiles/naturomics__CapsNet-Tensorflow.csv", "../github_crawler/tf_pyfiles/wookayin__tensorflow-plot.csv", "../github_crawler/tf_pyfiles/yeephycho__tensorflow-face-detection.csv", "../github_crawler/tf_pyfiles/aqibsaeed__Multilabel-timeseries-classification-with-LSTM.csv", "../github_crawler/tf_pyfiles/ritheshkumar95__im2latex-tensorflow.csv", "../github_crawler/tf_pyfiles/TensorLab__tensorfx.csv", "../github_crawler/tf_pyfiles/TimoBolkart__voca.csv", "../github_crawler/tf_pyfiles/transcendent-ai-labs__DynaML.csv", "../github_crawler/tf_pyfiles/tawnkramer__sdsandbox.csv", "../github_crawler/tf_pyfiles/cardwing__Codes-for-Lane-Detection.csv", "../github_crawler/tf_pyfiles/Cadene__tensorflow-model-zoo.torch.csv", "../github_crawler/tf_pyfiles/jiegzhan__multi-class-text-classification-cnn.csv", "../github_crawler/tf_pyfiles/geektutu__tensorflow-tutorial-samples.csv", "../github_crawler/tf_pyfiles/mks0601__PoseFix_RELEASE.csv", "../github_crawler/tf_pyfiles/j-min__tf_tutorial_plus.csv", "../github_crawler/tf_pyfiles/shaqian__flutter_tflite.csv", "../github_crawler/tf_pyfiles/mks0601__TF-SimpleHumanPose.csv", "../github_crawler/tf_pyfiles/stevenpjg__ddpg-aigym.csv", "../github_crawler/tf_pyfiles/Mostafa-Samir__DNC-tensorflow.csv", "../github_crawler/tf_pyfiles/cheungdaven__DeepRec.csv", "../github_crawler/tf_pyfiles/lmb-freiburg__hand3d.csv", "../github_crawler/tf_pyfiles/titu1994__neural-image-assessment.csv", "../github_crawler/tf_pyfiles/kaiwaehner__ksql-udf-deep-learning-mqtt-iot.csv", "../github_crawler/tf_pyfiles/microsoft__Windows-Machine-Learning.csv", "../github_crawler/tf_pyfiles/shamangary__FSA-Net.csv", "../github_crawler/tf_pyfiles/idealo__image-super-resolution.csv", "../github_crawler/tf_pyfiles/dhlab-epfl__dhSegment.csv", "../github_crawler/tf_pyfiles/SummitKwan__transparent_latent_gan.csv", "../github_crawler/tf_pyfiles/DetectionTeamUCAS__RetinaNet_Tensorflow_Rotation.csv", "../github_crawler/tf_pyfiles/mit-acl__cadrl_ros.csv", "../github_crawler/tf_pyfiles/yinguobing__head-pose-estimation.csv", "../github_crawler/tf_pyfiles/BMW-InnovationLab__BMW-TensorFlow-Training-GUI.csv", "../github_crawler/tf_pyfiles/adblockradio__adblockradio.csv", "../github_crawler/tf_pyfiles/google-research__batch-ppo.csv", "../github_crawler/tf_pyfiles/PAIR-code__saliency.csv", "../github_crawler/tf_pyfiles/ChenglongChen__tensorflow-DeepFM.csv", "../github_crawler/tf_pyfiles/OAID__FaceDetection.csv", "../github_crawler/tf_pyfiles/Dobiasd__frugally-deep.csv", "../github_crawler/tf_pyfiles/huggingface__node-question-answering.csv", "../github_crawler/tf_pyfiles/nyukat__breast_cancer_classifier.csv", "../github_crawler/tf_pyfiles/meetshah1995__tf-3dgan.csv", "../github_crawler/tf_pyfiles/Determined22__zh-NER-TF.csv", "../github_crawler/tf_pyfiles/eragonruan__text-detection-ctpn.csv", "../github_crawler/tf_pyfiles/google__iree.csv", "../github_crawler/tf_pyfiles/rishizek__tensorflow-deeplab-v3.csv", "../github_crawler/tf_pyfiles/hjptriplebee__Chinese_poem_generator.csv", "../github_crawler/tf_pyfiles/yangxue0827__R2CNN_FPN_Tensorflow.csv", "../github_crawler/tf_pyfiles/joelbarmettlerUZH__auto-tinder.csv", "../github_crawler/tf_pyfiles/yunjey__show-attend-and-tell.csv", "../github_crawler/tf_pyfiles/DetectionTeamUCAS__FPN_Tensorflow.csv", "../github_crawler/tf_pyfiles/criteo-research__CausE.csv", "../github_crawler/tf_pyfiles/adeshpande3__Facebook-Messenger-Bot.csv", "../github_crawler/tf_pyfiles/Alluxio__alluxio.csv", "../github_crawler/tf_pyfiles/torrvision__crayon.csv", "../github_crawler/tf_pyfiles/cookeem__TensorFlow_learning_notes.csv", "../github_crawler/tf_pyfiles/ymcui__Chinese-ELECTRA.csv", "../github_crawler/tf_pyfiles/zhihu__cuBERT.csv", "../github_crawler/tf_pyfiles/tobegit3hub__tensorflow_template_application.csv", "../github_crawler/tf_pyfiles/adeshpande3__Tensorflow-Programs-and-Tutorials.csv", "../github_crawler/tf_pyfiles/kubeflow__kubeflow.csv", "../github_crawler/tf_pyfiles/kwotsin__TensorFlow-ENet.csv", "../github_crawler/tf_pyfiles/MaybeShewill-CV__CRNN_Tensorflow.csv", "../github_crawler/tf_pyfiles/kratzert__finetune_alexnet_with_tensorflow.csv", "../github_crawler/tf_pyfiles/anmspro__Traffic-Signal-Violation-Detection-System.csv", "../github_crawler/tf_pyfiles/MLEveryday__100-Days-Of-ML-Code.csv", "../github_crawler/tf_pyfiles/hizhangp__yolo_tensorflow.csv", "../github_crawler/tf_pyfiles/jiamings__wgan.csv", "../github_crawler/tf_pyfiles/satojkovic__DeepLogo.csv", "../github_crawler/tf_pyfiles/bendangnuksung__Image-OutPainting.csv", "../github_crawler/tf_pyfiles/Stick-To__Object-Detection-API-Tensorflow.csv", "../github_crawler/tf_pyfiles/ilovin__lstm_ctc_ocr.csv", "../github_crawler/tf_pyfiles/vanhuyz__CycleGAN-TensorFlow.csv", "../github_crawler/tf_pyfiles/keras-rl__keras-rl.csv", "../github_crawler/tf_pyfiles/cerndb__dist-keras.csv", "../github_crawler/tf_pyfiles/policeme__transformer-pointer-generator.csv", "../github_crawler/tf_pyfiles/FuZer__StudyTensorFlow.csv", "../github_crawler/tf_pyfiles/hujinsen__StarGAN-Voice-Conversion.csv", "../github_crawler/tf_pyfiles/cesarsouza__keras-sharp.csv", "../github_crawler/tf_pyfiles/tobyyouup__conv_seq2seq.csv", "../github_crawler/tf_pyfiles/tugstugi__dl-colab-notebooks.csv", "../github_crawler/tf_pyfiles/wiseodd__generative-models.csv", "../github_crawler/tf_pyfiles/jacksu__machine-learning.csv", "../github_crawler/tf_pyfiles/simonmeister__UnFlow.csv", "../github_crawler/tf_pyfiles/datitran__object_detector_app.csv", "../github_crawler/tf_pyfiles/tensorforce__tensorforce.csv", "../github_crawler/tf_pyfiles/tensorflow__tfjs-node.csv", "../github_crawler/tf_pyfiles/benedekrozemberczki__GEMSEC.csv", "../github_crawler/tf_pyfiles/harveyslash__TSNE-Embedding-Visualisation.csv", "../github_crawler/tf_pyfiles/bogatyy__cs224d.csv", "../github_crawler/tf_pyfiles/hardikbansal__CycleGAN.csv", "../github_crawler/tf_pyfiles/bytedance__byteps.csv", "../github_crawler/tf_pyfiles/mlachmish__MusicGenreClassification.csv", "../github_crawler/tf_pyfiles/ankeshanand__neural-cryptography-tensorflow.csv", "../github_crawler/tf_pyfiles/IntelAI__models.csv", "../github_crawler/tf_pyfiles/wshuyi__demo-chinese-text-binary-classification-with-bert.csv", "../github_crawler/tf_pyfiles/Adamdad__keras-YOLOv3-mobilenet.csv", "../github_crawler/tf_pyfiles/nerox8664__pytorch2keras.csv", "../github_crawler/tf_pyfiles/huxiaoman7__PaddlePaddle_code.csv", "../github_crawler/tf_pyfiles/Ankush96__grad-cam.tensorflow.csv", "../github_crawler/tf_pyfiles/KDD-OpenSource__DeepADoTS.csv", "../github_crawler/tf_pyfiles/sthalles__deeplab_v3.csv", "../github_crawler/tf_pyfiles/Neargye__hello_tf_c_api.csv", "../github_crawler/tf_pyfiles/Rayhane-mamah__Tacotron-2.csv", "../github_crawler/tf_pyfiles/onnx__onnx.csv", "../github_crawler/tf_pyfiles/hankcs__CS224n.csv", "../github_crawler/tf_pyfiles/ximimiao__deeplabv3-Tensorflow.csv", "../github_crawler/tf_pyfiles/vsuthichai__paraphraser.csv", "../github_crawler/tf_pyfiles/reneweb__react-native-tensorflow.csv", "../github_crawler/tf_pyfiles/Hvass-Labs__TensorFlow-Tutorials.csv", "../github_crawler/tf_pyfiles/tensorflow__addons.csv", "../github_crawler/tf_pyfiles/jayparks__tf-seq2seq.csv", "../github_crawler/tf_pyfiles/conan7882__GoogLeNet-Inception.csv", "../github_crawler/tf_pyfiles/wandb__client.csv", "../github_crawler/tf_pyfiles/georgesung__ssd_tensorflow_traffic_sign_detection.csv", "../github_crawler/tf_pyfiles/xxbb1234021__speech_recognition.csv", "../github_crawler/tf_pyfiles/ChenglongChen__tensorflow-DSMM.csv", "../github_crawler/tf_pyfiles/BMW-InnovationLab__BMW-TensorFlow-Inference-API-GPU.csv", "../github_crawler/tf_pyfiles/liuyuemaicha__Adversarial-Learning-for-Neural-Dialogue-Generation-in-Tensorflow.csv", "../github_crawler/tf_pyfiles/aamini__introtodeeplearning.csv", "../github_crawler/tf_pyfiles/luyanger1799__Amazing-Semantic-Segmentation.csv", "../github_crawler/tf_pyfiles/crazydonkey200__neural-symbolic-machines.csv", "../github_crawler/tf_pyfiles/analysiscenter__radio.csv", "../github_crawler/tf_pyfiles/getnamo__tensorflow-ue4.csv", "../github_crawler/tf_pyfiles/imistyrain__MTCNN.csv", "../github_crawler/tf_pyfiles/rishizek__tensorflow-deeplab-v3-plus.csv", "../github_crawler/tf_pyfiles/tomlepaine__fast-wavenet.csv", "../github_crawler/tf_pyfiles/arcelien__pba.csv", "../github_crawler/tf_pyfiles/pkmital__CADL.csv", "../github_crawler/tf_pyfiles/aymericdamien__TopDeepLearning.csv", "../github_crawler/tf_pyfiles/may-__cnn-re-tf.csv", "../github_crawler/tf_pyfiles/emedvedev__attention-ocr.csv", "../github_crawler/tf_pyfiles/philferriere__dlwin.csv", "../github_crawler/tf_pyfiles/Chung-I__Variational-Recurrent-Autoencoder-Tensorflow.csv", "../github_crawler/tf_pyfiles/tensorflow__hub.csv", "../github_crawler/tf_pyfiles/omoindrot__tensorflow-triplet-loss.csv", "../github_crawler/tf_pyfiles/tensorflow__datasets.csv", "../github_crawler/tf_pyfiles/benedekrozemberczki__SimGNN.csv", "../github_crawler/tf_pyfiles/tensorflow__agents.csv", "../github_crawler/tf_pyfiles/as-ideas__headliner.csv", "../github_crawler/tf_pyfiles/darkonhub__darkon.csv", "../github_crawler/tf_pyfiles/broadinstitute__keras-rcnn.csv", "../github_crawler/tf_pyfiles/maiminh1996__YOLOv3-tensorflow.csv", "../github_crawler/tf_pyfiles/skcript__tensorflow-resources.csv", "../github_crawler/tf_pyfiles/kamalkraj__Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs.csv", "../github_crawler/tf_pyfiles/yangboz__LotteryPrediction.csv", "../github_crawler/tf_pyfiles/uber__petastorm.csv", "../github_crawler/tf_pyfiles/MahanFathi__CS231.csv", "../github_crawler/tf_pyfiles/microsoft__EdgeML.csv", "../github_crawler/tf_pyfiles/margaretmz__awesome-tflite.csv", "../github_crawler/tf_pyfiles/maelfabien__Multimodal-Emotion-Recognition.csv", "../github_crawler/tf_pyfiles/DetectionTeamUCAS__R2CNN_Faster-RCNN_Tensorflow.csv", "../github_crawler/tf_pyfiles/pillarpond__face-recognizer-android.csv", "../github_crawler/tf_pyfiles/shyamupa__snli-entailment.csv", "../github_crawler/tf_pyfiles/PINTO0309__Tensorflow-bin.csv", "../github_crawler/tf_pyfiles/jackzhenguo__python-small-examples.csv", "../github_crawler/tf_pyfiles/carpedm20__visual-analogy-tensorflow.csv", "../github_crawler/tf_pyfiles/google__gin-config.csv", "../github_crawler/tf_pyfiles/TellinaTool__nl2bash.csv", "../github_crawler/tf_pyfiles/for-ai__Targeted-Dropout.csv", "../github_crawler/tf_pyfiles/dpressel__mead-baseline.csv", "../github_crawler/tf_pyfiles/ikhlestov__vision_networks.csv", "../github_crawler/tf_pyfiles/SeldonIO__seldon-server.csv", "../github_crawler/tf_pyfiles/cloud-annotations__training.csv", "../github_crawler/tf_pyfiles/carpedm20__simulated-unsupervised-tensorflow.csv", "../github_crawler/tf_pyfiles/jiegzhan__multi-class-text-classification-cnn-rnn.csv", "../github_crawler/tf_pyfiles/kubeflow__arena.csv", "../github_crawler/tf_pyfiles/wbhu__DnCNN-tensorflow.csv", "../github_crawler/tf_pyfiles/hwalsuklee__tensorflow-mnist-cnn.csv", "../github_crawler/tf_pyfiles/kengz__openai_lab.csv", "../github_crawler/tf_pyfiles/Honlan__DeepInterests.csv", "../github_crawler/tf_pyfiles/snipsco__tract.csv", "../github_crawler/tf_pyfiles/chonyy__AI-basketball-analysis.csv", "../github_crawler/tf_pyfiles/hiwonjoon__tf-vqvae.csv", "../github_crawler/tf_pyfiles/cpury__lookie-lookie.csv", "../github_crawler/tf_pyfiles/XanaduAI__strawberryfields.csv", "../github_crawler/tf_pyfiles/awjuliani__TF-Tutorials.csv", "../github_crawler/tf_pyfiles/google__seq2seq.csv", "../github_crawler/tf_pyfiles/google-research__electra.csv", "../github_crawler/tf_pyfiles/carpedm20__BEGAN-tensorflow.csv", "../github_crawler/tf_pyfiles/kevinhughes27__TensorKart.csv", "../github_crawler/tf_pyfiles/yell__boltzmann-machines.csv", "../github_crawler/tf_pyfiles/danaugrs__huskarl.csv", "../github_crawler/tf_pyfiles/ShannonAI__service-streamer.csv", "../github_crawler/tf_pyfiles/dwiel__tensorflow_hmm.csv", "../github_crawler/tf_pyfiles/carefree0910__MachineLearning.csv", "../github_crawler/tf_pyfiles/DeepWisdom__AutoDL.csv", "../github_crawler/tf_pyfiles/tensorflow__examples.csv", "../github_crawler/tf_pyfiles/calclavia__DeepJ.csv", "../github_crawler/tf_pyfiles/zsdonghao__u-net-brain-tumor.csv", "../github_crawler/tf_pyfiles/zeusees__HyperLPR.csv", "../github_crawler/tf_pyfiles/tgjeon__Keras-Tutorials.csv", "../github_crawler/tf_pyfiles/aqibsaeed__Human-Activity-Recognition-using-CNN.csv", "../github_crawler/tf_pyfiles/csxiaoyaojianxian__JavaScriptStudy.csv", "../github_crawler/tf_pyfiles/MindorksOpenSource__AndroidTensorFlowMNISTExample.csv", "../github_crawler/tf_pyfiles/GaoQ1__rasa_chatbot_cn.csv", "../github_crawler/tf_pyfiles/bjpcjp__scikit-and-tensorflow-workbooks.csv", "../github_crawler/tf_pyfiles/thomasschmied__Speech_Recognition_with_Tensorflow.csv", "../github_crawler/tf_pyfiles/cchen156__Learning-to-See-in-the-Dark.csv", "../github_crawler/tf_pyfiles/davidsandberg__facenet.csv", "../github_crawler/tf_pyfiles/BlackHC__tfpyth.csv", "../github_crawler/tf_pyfiles/benedekrozemberczki__CapsGNN.csv", "../github_crawler/tf_pyfiles/pmsosa__CS291K.csv", "../github_crawler/tf_pyfiles/carpedm20__DCGAN-tensorflow.csv", "../github_crawler/tf_pyfiles/junxiaosong__AlphaZero_Gomoku.csv", "../github_crawler/tf_pyfiles/leonndong__DeepLabV3-Tensorflow.csv", "../github_crawler/tf_pyfiles/Conchylicultor__MusicGenerator.csv", "../github_crawler/tf_pyfiles/xiaofengShi__CHINESE-OCR.csv", "../github_crawler/tf_pyfiles/sudharsan13296__Hands-On-Deep-Learning-Algorithms-with-Python.csv", "../github_crawler/tf_pyfiles/Anfany__Machine-Learning-for-Beginner-by-Python3.csv", "../github_crawler/tf_pyfiles/ml-tooling__ml-workspace.csv", "../github_crawler/tf_pyfiles/pangolulu__rnn-from-scratch.csv", "../github_crawler/tf_pyfiles/google-research__meta-dataset.csv", "../github_crawler/tf_pyfiles/xwhan__DeepPath.csv", "../github_crawler/tf_pyfiles/asyml__texar.csv", "../github_crawler/tf_pyfiles/jinfagang__tensorflow_novelist.csv", "../github_crawler/tf_pyfiles/thushv89__attention_keras.csv", "../github_crawler/tf_pyfiles/dpressel__rude-carnie.csv", "../github_crawler/tf_pyfiles/huggingface__nlp.csv", "../github_crawler/tf_pyfiles/transcranial__keras-js.csv", "../github_crawler/tf_pyfiles/hybridgroup__gocv.csv", "../github_crawler/tf_pyfiles/imcaspar__gpt2-ml.csv", "../github_crawler/tf_pyfiles/microsoft__RockPaperScissorsLizardSpock.csv", "../github_crawler/tf_pyfiles/iro-cp__FCRN-DepthPrediction.csv", "../github_crawler/tf_pyfiles/paarthneekhara__byteNet-tensorflow.csv", "../github_crawler/tf_pyfiles/mozilla__DeepSpeech.csv", "../github_crawler/tf_pyfiles/petercunha__Emotion.csv", "../github_crawler/tf_pyfiles/zsdonghao__deep-learning-book.csv", "../github_crawler/tf_pyfiles/khanrc__tf.gans-comparison.csv", "../github_crawler/tf_pyfiles/applenob__RNN-for-Joint-NLU.csv", "../github_crawler/tf_pyfiles/Vladkryvoruchko__PSPNet-Keras-tensorflow.csv", "../github_crawler/tf_pyfiles/NLPLearn__R-net.csv", "../github_crawler/tf_pyfiles/jeffheaton__t81_558_deep_learning.csv", "../github_crawler/tf_pyfiles/MG2033__ShuffleNet.csv", "../github_crawler/tf_pyfiles/MaybeShewill-CV__lanenet-lane-detection.csv", "../github_crawler/tf_pyfiles/tlkh__ai-lab.csv", "../github_crawler/tf_pyfiles/yihui-he__GAN-MNIST.csv", "../github_crawler/tf_pyfiles/google__dopamine.csv", "../github_crawler/tf_pyfiles/EddyVerbruggen__nativescript-plugin-firebase.csv", "../github_crawler/tf_pyfiles/retextjs__retext-keywords.csv", "../github_crawler/tf_pyfiles/PINTO0309__OpenVINO-YoloV3.csv", "../github_crawler/tf_pyfiles/meownoid__tensorfow-rbm.csv", "../github_crawler/tf_pyfiles/jonbruner__generative-adversarial-networks.csv", "../github_crawler/tf_pyfiles/TobiasLee__Text-Classification.csv", "../github_crawler/tf_pyfiles/MrNothing__AI-Blocks.csv", "../github_crawler/tf_pyfiles/sseung0703__KD_methods_with_TF.csv", "../github_crawler/tf_pyfiles/ildoonet__tf-pose-estimation.csv", "../github_crawler/tf_pyfiles/goodrahstar__my-awesome-AI-bookmarks.csv", "../github_crawler/tf_pyfiles/ppwwyyxx__dash-docset-tensorflow.csv", "../github_crawler/tf_pyfiles/LoSealL__VideoSuperResolution.csv", "../github_crawler/tf_pyfiles/pannous__tensorflow-ocr.csv", "../github_crawler/tf_pyfiles/kevinzakka__spatial-transformer-network.csv", "../github_crawler/tf_pyfiles/bshao001__ChatLearner.csv", "../github_crawler/tf_pyfiles/XanaduAI__pennylane.csv", "../github_crawler/tf_pyfiles/timctho__convolutional-pose-machines-tensorflow.csv", "../github_crawler/tf_pyfiles/nilboy__tensorflow-yolo.csv", "../github_crawler/tf_pyfiles/Kyubyong__tensorflow-exercises.csv", "../github_crawler/tf_pyfiles/bourdakos1__CapsNet-Visualization.csv", "../github_crawler/tf_pyfiles/steveKapturowski__tensorflow-rl.csv", "../github_crawler/tf_pyfiles/DevinZ1993__Chinese-Poetry-Generation.csv", "../github_crawler/tf_pyfiles/polyaxon__polyaxon.csv", "../github_crawler/tf_pyfiles/hannw__nlstm.csv", "../github_crawler/tf_pyfiles/CSTR-Edinburgh__merlin.csv", "../github_crawler/tf_pyfiles/pathak22__zeroshot-imitation.csv", "../github_crawler/tf_pyfiles/Charleswyt__tf_audio_steganalysis.csv", "../github_crawler/tf_pyfiles/PetarV-__GAT.csv", "../github_crawler/tf_pyfiles/ufoym__deepo.csv", "../github_crawler/tf_pyfiles/anantzoid__Conditional-PixelCNN-decoder.csv", "../github_crawler/tf_pyfiles/rhnvrm__galaxy-image-classifier-tensorflow.csv", "../github_crawler/tf_pyfiles/onnx__onnx-tensorflow.csv", "../github_crawler/tf_pyfiles/MarvinTeichmann__MultiNet.csv", "../github_crawler/tf_pyfiles/cjweeks__tensorflow-cmake.csv", "../github_crawler/tf_pyfiles/jibikbam__CNN-3D-images-Tensorflow.csv", "../github_crawler/tf_pyfiles/easy-tensorflow__easy-tensorflow.csv", "../github_crawler/tf_pyfiles/lambdaji__tf_repos.csv", "../github_crawler/tf_pyfiles/yangxue0827__FPN_Tensorflow.csv", "../github_crawler/tf_pyfiles/eaplatanios__tensorflow_scala.csv", "../github_crawler/tf_pyfiles/ColeMurray__medium-facenet-tutorial.csv", "../github_crawler/tf_pyfiles/curiousily__Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras.csv", "../github_crawler/tf_pyfiles/natanielruiz__android-yolo.csv", "../github_crawler/tf_pyfiles/galsang__ABCNN.csv", "../github_crawler/tf_pyfiles/evilsocket__ergo.csv", "../github_crawler/tf_pyfiles/xitu__gold-miner.csv", "../github_crawler/tf_pyfiles/InFoCusp__tf_cnnvis.csv", "../github_crawler/tf_pyfiles/ikostrikov__TensorFlow-VAE-GAN-DRAW.csv", "../github_crawler/tf_pyfiles/baldassarreFe__deep-koalarization.csv", "../github_crawler/tf_pyfiles/ayush1997__Xvision.csv", "../github_crawler/tf_pyfiles/amitshekhariitbhu__Android-TensorFlow-Lite-Example.csv", "../github_crawler/tf_pyfiles/bethesirius__ChosunTruck.csv", "../github_crawler/tf_pyfiles/keras-team__keras.csv", "../github_crawler/tf_pyfiles/Grzego__handwriting-generation.csv", "../github_crawler/tf_pyfiles/philferriere__tfwss.csv", "../github_crawler/tf_pyfiles/pochih__RL-Chatbot.csv", "../github_crawler/tf_pyfiles/autorope__donkeycar.csv", "../github_crawler/tf_pyfiles/YunYang1994__TensorFlow2.0-Examples.csv", "../github_crawler/tf_pyfiles/fregu856__segmentation.csv", "../github_crawler/tf_pyfiles/keithito__tacotron.csv", "../github_crawler/tf_pyfiles/uTensor__uTensor.csv", "../github_crawler/tf_pyfiles/gongzhitaao__tensorflow-adversarial.csv", "../github_crawler/tf_pyfiles/calmisential__Basic_CNNs_TensorFlow2.csv", "../github_crawler/tf_pyfiles/liweimin1996__MachineLearning-DeepLearning-NLP-LeetCode-StatisticalLearningMethod-TensorFlow.csv", "../github_crawler/tf_pyfiles/seasonSH__Probabilistic-Face-Embeddings.csv", "../github_crawler/tf_pyfiles/jparkhill__TensorMol.csv", "../github_crawler/tf_pyfiles/zsdonghao__text-to-image.csv", "../github_crawler/tf_pyfiles/MagicCube__tensorflow-rex-run.csv", "../github_crawler/tf_pyfiles/CQFIO__PhotographicImageSynthesis.csv", "../github_crawler/tf_pyfiles/broadinstitute__keras-resnet.csv", "../github_crawler/tf_pyfiles/uclnlp__jack.csv", "../github_crawler/tf_pyfiles/carpedm20__lstm-char-cnn-tensorflow.csv", "../github_crawler/tf_pyfiles/microsoft__AutonomousDrivingCookbook.csv", "../github_crawler/tf_pyfiles/williamFalcon__test-tube.csv", "../github_crawler/tf_pyfiles/OpenNMT__OpenNMT-tf.csv", "../github_crawler/tf_pyfiles/philferriere__tfoptflow.csv", "../github_crawler/tf_pyfiles/alibaba-edu__simple-effective-text-matching.csv", "../github_crawler/tf_pyfiles/PetroWu__AutoPortraitMatting.csv", "../github_crawler/tf_pyfiles/Qihoo360__XLearning.csv", "../github_crawler/tf_pyfiles/galeone__tfgo.csv", "../github_crawler/tf_pyfiles/TheAbhiKumar__tensorflow-value-iteration-networks.csv", "../github_crawler/tf_pyfiles/Honlan__wechat_jump_tensorflow.csv", "../github_crawler/tf_pyfiles/tensorlayer__awesome-tensorlayer.csv", "../github_crawler/tf_pyfiles/ndrplz__self-driving-car.csv", "../github_crawler/tf_pyfiles/CuriousAI__mean-teacher.csv", "../github_crawler/tf_pyfiles/NervanaSystems__he-transformer.csv", "../github_crawler/tf_pyfiles/weinman__cnn_lstm_ctc_ocr.csv", "../github_crawler/tf_pyfiles/tryolabs__luminoth.csv", "../github_crawler/tf_pyfiles/tensorflow__probability.csv", "../github_crawler/tf_pyfiles/tensorlang__tensorlang.csv", "../github_crawler/tf_pyfiles/Justin-Tan__generative-compression.csv", "../github_crawler/tf_pyfiles/NVIDIA-AI-IOT__tf_trt_models.csv", "../github_crawler/tf_pyfiles/google-research__morph-net.csv", "../github_crawler/tf_pyfiles/indiejoseph__cnn-text-classification-tf-chinese.csv", "../github_crawler/tf_pyfiles/philipperemy__tensorflow-1.4-billion-password-analysis.csv", "../github_crawler/tf_pyfiles/torrvision__siamfc-tf.csv", "../github_crawler/tf_pyfiles/lukalabs__cakechat.csv", "../github_crawler/tf_pyfiles/adipandas__multi-object-tracker.csv", "../github_crawler/tf_pyfiles/sourcedexter__tfClassifier.csv", "../github_crawler/tf_pyfiles/cjymz886__text-cnn.csv", "../github_crawler/tf_pyfiles/minimaxir__reactionrnn.csv", "../github_crawler/tf_pyfiles/tensorlayer__RLzoo.csv", "../github_crawler/tf_pyfiles/rish-16__sight.csv", "../github_crawler/tf_pyfiles/ProHiryu__albert-chinese-ner.csv", "../github_crawler/tf_pyfiles/ymcui__Chinese-XLNet.csv", "../github_crawler/tf_pyfiles/BachiLi__redner.csv", "../github_crawler/tf_pyfiles/MathiasGruber__PConv-Keras.csv", "../github_crawler/tf_pyfiles/danielsabinasz__TensorSlow.csv", "../github_crawler/tf_pyfiles/Zardinality__WGAN-tensorflow.csv", "../github_crawler/tf_pyfiles/Spandan-Madan__Me_Bot.csv", "../github_crawler/tf_pyfiles/wbenbihi__hourglasstensorlfow.csv", "../github_crawler/tf_pyfiles/madewithml__basics.csv", "../github_crawler/tf_pyfiles/yashk2810__Image-Captioning.csv", "../github_crawler/tf_pyfiles/titu1994__MLSTM-FCN.csv", "../github_crawler/tf_pyfiles/gabrieleangeletti__Deep-Learning-TensorFlow.csv", "../github_crawler/tf_pyfiles/GeorgeSeif__Semantic-Segmentation-Suite.csv", "../github_crawler/tf_pyfiles/jinfagang__tensorflow_poems.csv", "../github_crawler/tf_pyfiles/brade31919__SRGAN-tensorflow.csv", "../github_crawler/tf_pyfiles/zhedongzheng__tensorflow-nlp.csv", "../github_crawler/tf_pyfiles/ScottfreeLLC__AlphaPy.csv", "../github_crawler/tf_pyfiles/iesl__dilated-cnn-ner.csv", "../github_crawler/tf_pyfiles/hunkim__DeepLearningZeroToAll.csv", "../github_crawler/tf_pyfiles/yule-li__CosFace.csv", "../github_crawler/tf_pyfiles/amaiya__ktrain.csv", "../github_crawler/tf_pyfiles/Elucidation__tensorflow_chessbot.csv", "../github_crawler/tf_pyfiles/danielegrattarola__spektral.csv", "../github_crawler/tf_pyfiles/endernewton__iter-reason.csv", "../github_crawler/tf_pyfiles/balancap__SSD-Tensorflow.csv", "../github_crawler/tf_pyfiles/tancik__StegaStamp.csv", "../github_crawler/tf_pyfiles/seasonSH__DocFace.csv", "../github_crawler/tf_pyfiles/xdever__RFCN-tensorflow.csv", "../github_crawler/tf_pyfiles/HKUST-KnowComp__R-Net.csv", "../github_crawler/tf_pyfiles/ypwhs__dl-engineer-guidebook.csv", "../github_crawler/tf_pyfiles/EricZgw__PyramidBox.csv", "../github_crawler/tf_pyfiles/src-d__hercules.csv", "../github_crawler/tf_pyfiles/leriomaggio__deep-learning-keras-tensorflow.csv", "../github_crawler/tf_pyfiles/DLTK__DLTK.csv", "../github_crawler/tf_pyfiles/apachecn__hands-on-ml-zh.csv", "../github_crawler/tf_pyfiles/carpedm20__NAF-tensorflow.csv", "../github_crawler/tf_pyfiles/kozistr__Awesome-GANs.csv", "../github_crawler/tf_pyfiles/nickliqian__cnn_captcha.csv", "../github_crawler/tf_pyfiles/auroua__InsightFace_TF.csv", "../github_crawler/tf_pyfiles/PyTorchLightning__pytorch-lightning.csv", "../github_crawler/tf_pyfiles/lhelontra__tensorflow-on-arm.csv", "../github_crawler/tf_pyfiles/scofield7419__sequence-labeling-BiLSTM-CRF.csv", "../github_crawler/tf_pyfiles/bilylee__SiamFC-TensorFlow.csv", "../github_crawler/tf_pyfiles/clovaai__assembled-cnn.csv", "../github_crawler/tf_pyfiles/mars-project__mars.csv", "../github_crawler/tf_pyfiles/google-research__uda.csv", "../github_crawler/tf_pyfiles/rohitgirdhar__ActionVLAD.csv", "../github_crawler/tf_pyfiles/akirasosa__mobile-semantic-segmentation.csv", "../github_crawler/tf_pyfiles/songdejia__Siamese-RPN-pytorch.csv", "../github_crawler/tf_pyfiles/Kenza-AI__sagify.csv", "../github_crawler/tf_pyfiles/sjvasquez__web-traffic-forecasting.csv", "../github_crawler/tf_pyfiles/CharlesShang__FastMaskRCNN.csv", "../github_crawler/tf_pyfiles/zw76859420__ASR_Theory.csv", "../github_crawler/tf_pyfiles/nelson-liu__paraphrase-id-tensorflow.csv", "../github_crawler/tf_pyfiles/google__deepvariant.csv", "../github_crawler/tf_pyfiles/paarthneekhara__text-to-image.csv", "../github_crawler/tf_pyfiles/adeshpande3__LSTM-Sentiment-Analysis.csv", "../github_crawler/tf_pyfiles/taki0112__Tensorflow-Cookbook.csv", "../github_crawler/tf_pyfiles/ahangchen__GDLnotes.csv", "../github_crawler/tf_pyfiles/vahidk__tfrecord.csv", "../github_crawler/tf_pyfiles/MindorksOpenSource__AndroidTensorFlowMachineLearningExample.csv", "../github_crawler/tf_pyfiles/PatWie__CppNumericalSolvers.csv", "../github_crawler/tf_pyfiles/miyosuda__async_deep_reinforce.csv", "../github_crawler/tf_pyfiles/xhujoy__CycleGAN-tensorflow.csv", "../github_crawler/tf_pyfiles/kaiwaehner__kafka-streams-machine-learning-examples.csv", "../github_crawler/tf_pyfiles/rwth-i6__returnn.csv", "../github_crawler/tf_pyfiles/maelfabien__Machine_Learning_Tutorials.csv", "../github_crawler/tf_pyfiles/stanfordnlp__mac-network.csv", "../github_crawler/tf_pyfiles/ionvision__DeepLearningCourseCodes.csv", "../github_crawler/tf_pyfiles/mokemokechicken__reversi-alpha-zero.csv", "../github_crawler/tf_pyfiles/CorentinJ__Real-Time-Voice-Cloning.csv", "../github_crawler/tf_pyfiles/MarvinTeichmann__KittiBox.csv", "../github_crawler/tf_pyfiles/sergiomsilva__alpr-unconstrained.csv", "../github_crawler/tf_pyfiles/pkmital__pycadl.csv", "../github_crawler/tf_pyfiles/wagamamaz__tensorflow-tutorial.csv", "../github_crawler/tf_pyfiles/DongjunLee__transformer-tensorflow.csv", "../github_crawler/tf_pyfiles/astorfi__lip-reading-deeplearning.csv", "../github_crawler/tf_pyfiles/tensorflow__adanet.csv", "../github_crawler/tf_pyfiles/monikkinom__ner-lstm.csv", "../github_crawler/tf_pyfiles/minimaxir__textgenrnn.csv", "../github_crawler/tf_pyfiles/bethgelab__foolbox.csv", "../github_crawler/tf_pyfiles/bendidi__Tracking-with-darkflow.csv", "../github_crawler/tf_pyfiles/isseu__emotion-recognition-neural-networks.csv", "../github_crawler/tf_pyfiles/philipperemy__deep-speaker.csv", "../github_crawler/tf_pyfiles/rasbt__python-machine-learning-book-3rd-edition.csv", "../github_crawler/tf_pyfiles/off99555__machine-learning-curriculum.csv", "../github_crawler/tf_pyfiles/HyperGAN__HyperGAN.csv", "../github_crawler/tf_pyfiles/opencv__openvino_training_extensions.csv", "../github_crawler/tf_pyfiles/mdietrichstein__tensorflow-open_nsfw.csv", "../github_crawler/tf_pyfiles/soubhiksanyal__RingNet.csv", "../github_crawler/tf_pyfiles/Lapis-Hong__wide_deep.csv", "../github_crawler/tf_pyfiles/jedld__tensor_stream.csv", "../github_crawler/tf_pyfiles/cs230-stanford__cs230-code-examples.csv", "../github_crawler/tf_pyfiles/msgi__nlp-journey.csv", "../github_crawler/tf_pyfiles/madalinabuzau__tensorflow-eager-tutorials.csv", "../github_crawler/tf_pyfiles/jiny2001__dcscn-super-resolution.csv", "../github_crawler/tf_pyfiles/hnarayanan__artistic-style-transfer.csv", "../github_crawler/tf_pyfiles/PipelineAI__pipeline.csv", "../github_crawler/tf_pyfiles/migueldeicaza__TensorFlowSharp.csv", "../github_crawler/tf_pyfiles/yinguobing__cnn-facial-landmark.csv", "../github_crawler/tf_pyfiles/apcode__tensorflow_fasttext.csv", "../github_crawler/tf_pyfiles/chiphuyen__stanford-tensorflow-tutorials.csv", "../github_crawler/tf_pyfiles/koursaros-ai__nboost.csv", "../github_crawler/tf_pyfiles/liuyuemaicha__Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow.csv", "../github_crawler/tf_pyfiles/imalikshake__StyleNet.csv", "../github_crawler/tf_pyfiles/fendouai__FaceRank.csv", "../github_crawler/tf_pyfiles/rcmalli__keras-mobilenet.csv", "../github_crawler/tf_pyfiles/rcmalli__keras-squeezenet.csv", "../github_crawler/tf_pyfiles/Belval__CRNN.csv", "../github_crawler/tf_pyfiles/CharlesShang__TFFRCNN.csv", "../github_crawler/tf_pyfiles/google__tf-quant-finance.csv", "../github_crawler/tf_pyfiles/tensorflow__swift-apis.csv", "../github_crawler/tf_pyfiles/sozykin__dlpython_course.csv", "../github_crawler/tf_pyfiles/dformoso__sklearn-classification.csv", "../github_crawler/tf_pyfiles/mtobeiyf__keras-flask-deploy-webapp.csv", "../github_crawler/tf_pyfiles/onnx__keras-onnx.csv", "../github_crawler/tf_pyfiles/smallcorgi__Faster-RCNN_TF.csv", "../github_crawler/tf_pyfiles/DjangoPeng__tensorflow-in-depth.csv", "../github_crawler/tf_pyfiles/tsinghua-rll__VoxelNet-tensorflow.csv", "../github_crawler/tf_pyfiles/PacktPublishing__Natural-Language-Processing-with-TensorFlow.csv", "../github_crawler/tf_pyfiles/BinRoot__TensorFlow-Book.csv", "../github_crawler/tf_pyfiles/deeplearningturkiye__turkce-yapay-zeka-kaynaklari.csv", "../github_crawler/tf_pyfiles/mari-linhares__mnist-android-tensorflow.csv", "../github_crawler/tf_pyfiles/YinAoXiong__12306_code_server.csv", "../github_crawler/tf_pyfiles/oandrienko__fast-semantic-segmentation.csv", "../github_crawler/tf_pyfiles/keiohta__tf2rl.csv", "../github_crawler/tf_pyfiles/HunterXuan__wx-tfjs-demo.csv", "../github_crawler/tf_pyfiles/qubvel__segmentation_models.csv", "../github_crawler/tf_pyfiles/NifTK__NiftyNet.csv", "../github_crawler/tf_pyfiles/snipsco__tensorflow-build.csv", "../github_crawler/tf_pyfiles/una-dinosauria__3d-pose-baseline.csv", "../github_crawler/tf_pyfiles/crazydonkey200__tensorflow-char-rnn.csv", "../github_crawler/tf_pyfiles/yunjey__domain-transfer-network.csv", "../github_crawler/tf_pyfiles/serengil__tensorflow-101.csv", "../github_crawler/tf_pyfiles/Azure__kubeflow-labs.csv", "../github_crawler/tf_pyfiles/CreatCodeBuild__TensorFlow-and-DeepLearning-Tutorial.csv", "../github_crawler/tf_pyfiles/simoninithomas__Deep_reinforcement_learning_Course.csv", "../github_crawler/tf_pyfiles/guillaume-chevalier__seq2seq-signal-prediction.csv", "../github_crawler/tf_pyfiles/graknlabs__kglib.csv", "../github_crawler/tf_pyfiles/devzwy__open_nsfw_android.csv", "../github_crawler/tf_pyfiles/BishopFox__eyeballer.csv", "../github_crawler/tf_pyfiles/aws__sagemaker-python-sdk.csv", "../github_crawler/tf_pyfiles/edvardHua__PoseEstimationForMobile.csv", "../github_crawler/tf_pyfiles/solivr__tf-crnn.csv", "../github_crawler/tf_pyfiles/rish-16__gpt2client.csv", "../github_crawler/tf_pyfiles/LynnHo__CycleGAN-Tensorflow-2.csv", "../github_crawler/tf_pyfiles/koth__kcws.csv", "../github_crawler/tf_pyfiles/cagbal__ros_people_object_detection_tensorflow.csv", "../github_crawler/tf_pyfiles/empathy87__The-Elements-of-Statistical-Learning-Python-Notebooks.csv", "../github_crawler/tf_pyfiles/bourdakos1__Custom-Object-Detection.csv", "../github_crawler/tf_pyfiles/BishopFox__deephack.csv", "../github_crawler/tf_pyfiles/wubinzzu__NeuRec.csv", "../github_crawler/tf_pyfiles/YixuanLi__densenet-tensorflow.csv", "../github_crawler/tf_pyfiles/taki0112__SENet-Tensorflow.csv", "../github_crawler/tf_pyfiles/sql-machine-learning__elasticdl.csv", "../github_crawler/tf_pyfiles/nicola-decao__s-vae-tf.csv", "../github_crawler/tf_pyfiles/altosaar__variational-autoencoder.csv", "../github_crawler/tf_pyfiles/nilboy__pixel-recursive-super-resolution.csv", "../github_crawler/tf_pyfiles/ardiya__siamesenetwork-tensorflow.csv", "../github_crawler/tf_pyfiles/jfkirk__tensorrec.csv", "../github_crawler/tf_pyfiles/ProHiryu__bert-chinese-ner.csv", "../github_crawler/tf_pyfiles/datitran__face2face-demo.csv", "../github_crawler/tf_pyfiles/fendouai__Awesome-Chatbot.csv", "../github_crawler/tf_pyfiles/asingh33__CNNGestureRecognizer.csv", "../github_crawler/tf_pyfiles/GoogleCloudPlatform__tf-estimator-tutorials.csv", "../github_crawler/tf_pyfiles/rlgraph__rlgraph.csv", "../github_crawler/tf_pyfiles/machine-learning-apps__Issue-Label-Bot.csv", "../github_crawler/tf_pyfiles/explosion__thinc.csv", "../github_crawler/tf_pyfiles/jaromiru__AI-blog.csv", "../github_crawler/tf_pyfiles/awjuliani__DeepRL-Agents.csv", "../github_crawler/tf_pyfiles/pathak22__noreward-rl.csv", "../github_crawler/tf_pyfiles/sudharsan13296__Hands-On-Meta-Learning-With-Python.csv", "../github_crawler/tf_pyfiles/PaddlePaddle__X2Paddle.csv", "../github_crawler/tf_pyfiles/tensorlayer__tensorlayer-chinese.csv", "../github_crawler/tf_pyfiles/mystic123__tensorflow-yolo-v3.csv", "../github_crawler/tf_pyfiles/tensorlayer__dcgan.csv", "../github_crawler/tf_pyfiles/JackonYang__captcha-tensorflow.csv", "../github_crawler/tf_pyfiles/hwalsuklee__tensorflow-style-transfer.csv", "../github_crawler/tf_pyfiles/Kyubyong__tacotron.csv", "../github_crawler/tf_pyfiles/serengil__deepface.csv", "../github_crawler/tf_pyfiles/HadoopIt__rnn-nlu.csv", "../github_crawler/tf_pyfiles/evgps__a3c_trading.csv", "../github_crawler/tf_pyfiles/therne__dmn-tensorflow.csv", "../github_crawler/tf_pyfiles/DT42__BerryNet.csv", "../github_crawler/tf_pyfiles/anuragmishracse__caption_generator.csv", "../github_crawler/tf_pyfiles/luckycallor__InsightFace-tensorflow.csv", "../github_crawler/tf_pyfiles/eddywm__KTFLITE.csv", "../github_crawler/tf_pyfiles/Andrewnetwork__WorkshopScipy.csv", "../github_crawler/tf_pyfiles/indiejoseph__doc-han-att.csv", "../github_crawler/tf_pyfiles/batzner__indrnn.csv", "../github_crawler/tf_pyfiles/guillaumegenthial__im2latex.csv", "../github_crawler/tf_pyfiles/GokuMohandas__fast-weights.csv", "../github_crawler/tf_pyfiles/graykode__nlp-tutorial.csv", "../github_crawler/tf_pyfiles/lexfridman__mit-deep-learning.csv", "../github_crawler/tf_pyfiles/szaza__android-yolo-v2.csv", "../github_crawler/tf_pyfiles/richmondu__libfaceid.csv", "../github_crawler/tf_pyfiles/yongyehuang__zhihu-text-classification.csv", "../github_crawler/tf_pyfiles/gaussic__text-classification-cnn-rnn.csv", "../github_crawler/tf_pyfiles/fsx950223__mobilenetv2-yolov3.csv", "../github_crawler/tf_pyfiles/blei-lab__edward.csv", "../github_crawler/tf_pyfiles/guillaumegenthial__tf_ner.csv", "../github_crawler/tf_pyfiles/daviddao__spatial-transformer-tensorflow.csv", "../github_crawler/tf_pyfiles/rwightman__posenet-python.csv", "../github_crawler/tf_pyfiles/AlgoTraders__stock-analysis-engine.csv", "../github_crawler/tf_pyfiles/xingyul__flownet3d.csv", "../github_crawler/tf_pyfiles/pbhatia243__Neural_Conversation_Models.csv", "../github_crawler/tf_pyfiles/Labelbox__labelbox.csv", "../github_crawler/tf_pyfiles/khundman__telemanom.csv", "../github_crawler/tf_pyfiles/spotify__featran.csv", "../github_crawler/tf_pyfiles/trekhleb__machine-learning-experiments.csv", "../github_crawler/tf_pyfiles/Zeta36__chess-alpha-zero.csv", "../github_crawler/tf_pyfiles/nicolas-ivanov__tf_seq2seq_chatbot.csv", "../github_crawler/tf_pyfiles/huxiaoman7__learningdl.csv", "../github_crawler/tf_pyfiles/GaoQ1__rasa_nlu_gq.csv", "../github_crawler/tf_pyfiles/anicolson__DeepXi.csv", "../github_crawler/tf_pyfiles/tensorflow__neural-structured-learning.csv", "../github_crawler/tf_pyfiles/google__edward2.csv", "../github_crawler/tf_pyfiles/lukedeo__keras-acgan.csv", "../github_crawler/tf_pyfiles/justadudewhohacks__face-api.js.csv", "../github_crawler/tf_pyfiles/microsoft__nni.csv", "../github_crawler/tf_pyfiles/ArunMichaelDsouza__tensorflow-image-detection.csv", "../github_crawler/tf_pyfiles/Cloud-CV__Fabrik.csv", "../github_crawler/tf_pyfiles/hollobit__All-About-the-GAN.csv", "../github_crawler/tf_pyfiles/donnemartin__data-science-ipython-notebooks.csv", "../github_crawler/tf_pyfiles/vudung45__FaceRec.csv", "../github_crawler/tf_pyfiles/ricsinaruto__Seq2seqChatbots.csv", "../github_crawler/tf_pyfiles/tobegit3hub__simple_tensorflow_serving.csv", "../github_crawler/tf_pyfiles/adityac94__Grad_CAM_plus_plus.csv", "../github_crawler/tf_pyfiles/matterport__Mask_RCNN.csv", "../github_crawler/tf_pyfiles/dipanjanS__practical-machine-learning-with-python.csv", "../github_crawler/tf_pyfiles/tensorflow__lingvo.csv", "../github_crawler/tf_pyfiles/habrman__FaceRecognition.csv", "../github_crawler/tf_pyfiles/chrisranderson__beholder.csv", "../github_crawler/tf_pyfiles/Bellspringsteen__OurCamera.csv", "../github_crawler/tf_pyfiles/brightmart__albert_zh.csv", "../github_crawler/tf_pyfiles/intel-isl__Open3D-PointNet2-Semantic3D.csv", "../github_crawler/tf_pyfiles/tensorlayer__seq2seq-chatbot.csv", "../github_crawler/tf_pyfiles/MrGemy95__Tensorflow-Project-Template.csv", "../github_crawler/tf_pyfiles/wangqingbaidu__Dr.Sure.csv", "../github_crawler/tf_pyfiles/zzw922cn__Automatic_Speech_Recognition.csv", "../github_crawler/tf_pyfiles/burness__tensorflow-101.csv", "../github_crawler/tf_pyfiles/zzh8829__yolov3-tf2.csv", "../github_crawler/tf_pyfiles/emilwallner__Coloring-greyscale-images.csv", "../github_crawler/tf_pyfiles/stratospark__keras-multiprocess-image-data-generator.csv", "../github_crawler/tf_pyfiles/shepnerd__inpainting_gmcnn.csv", "../github_crawler/tf_pyfiles/douban__tfmesos.csv", "../github_crawler/tf_pyfiles/photoprism__photoprism.csv", "../github_crawler/tf_pyfiles/lutzroeder__netron.csv", "../github_crawler/tf_pyfiles/buppt__ChineseNER.csv", "../github_crawler/tf_pyfiles/ildoonet__deepface.csv", "../github_crawler/tf_pyfiles/stratospark__food-101-keras.csv", "../github_crawler/tf_pyfiles/kwotsin__transfer_learning_tutorial.csv", "../github_crawler/tf_pyfiles/fidler-lab__polyrnn-pp.csv", "../github_crawler/tf_pyfiles/deepVector__geospatial-machine-learning.csv", "../github_crawler/tf_pyfiles/XMUNLP__Tagger.csv", "../github_crawler/tf_pyfiles/liuheng92__tensorflow_PSENet.csv", "../github_crawler/tf_pyfiles/larq__larq.csv", "../github_crawler/tf_pyfiles/benedekrozemberczki__GraphWaveletNeuralNetwork.csv", "../github_crawler/tf_pyfiles/Dharun__Tensorflow-License-Plate-Detection.csv", "../github_crawler/tf_pyfiles/tensorflow__model-optimization.csv", "../github_crawler/tf_pyfiles/suriyadeepan__practical_seq2seq.csv", "../github_crawler/tf_pyfiles/tensorspace-team__tensorspace.csv", "../github_crawler/tf_pyfiles/brightmart__text_classification.csv", "../github_crawler/tf_pyfiles/tantara__JejuNet.csv", "../github_crawler/tf_pyfiles/waitingfordark__four_flower.csv", "../github_crawler/tf_pyfiles/potterhsu__SVHNClassifier.csv", "../github_crawler/tf_pyfiles/GPflow__GPflow.csv", "../github_crawler/tf_pyfiles/tuan3w__visual_search.csv", "../github_crawler/tf_pyfiles/horance-liu__tensorflow-internals.csv", "../github_crawler/tf_pyfiles/ilivans__tf-rnn-attention.csv", "../github_crawler/tf_pyfiles/arnab39__FewShot_GAN-Unet3D.csv", "../github_crawler/tf_pyfiles/deezer__spleeter.csv", "../github_crawler/tf_pyfiles/deepmipt__DeepPavlov.csv", "../github_crawler/tf_pyfiles/DetectionTeamUCAS__NAS_FPN_Tensorflow.csv", "../github_crawler/tf_pyfiles/lc222__seq2seq_chatbot.csv", "../github_crawler/tf_pyfiles/kpe__bert-for-tf2.csv", "../github_crawler/tf_pyfiles/DrewNF__Tensorflow_Object_Tracking_Video.csv", "../github_crawler/tf_pyfiles/uber-research__sbnet.csv", "../github_crawler/tf_pyfiles/mariusbrataas__flowpoints_ml.csv", "../github_crawler/tf_pyfiles/leemengtaiwan__deep-learning-resources.csv", "../github_crawler/tf_pyfiles/deeppomf__DeepCreamPy.csv", "../github_crawler/tf_pyfiles/tensorflow__serving.csv", "../github_crawler/tf_pyfiles/lexfridman__deeptraffic.csv", "../github_crawler/tf_pyfiles/awslabs__djl.csv", "../github_crawler/tf_pyfiles/sjchoi86__advanced-tensorflow.csv", "../github_crawler/tf_pyfiles/awslabs__deeplearning-cfn.csv", "../github_crawler/tf_pyfiles/inoryy__tensorflow2-deep-reinforcement-learning.csv", "../github_crawler/tf_pyfiles/ycszen__TensorFlowLaboratory.csv", "../github_crawler/tf_pyfiles/zurutech__gans-from-theory-to-production.csv", "../github_crawler/tf_pyfiles/wizyoung__YOLOv3_TensorFlow.csv", "../github_crawler/tf_pyfiles/lmb-freiburg__demon.csv", "../github_crawler/tf_pyfiles/Franck-Dernoncourt__NeuroNER.csv", "../github_crawler/tf_pyfiles/aymericdamien__TensorFlow-Examples.csv", "../github_crawler/tf_pyfiles/rohitgirdhar__AttentionalPoolingAction.csv", "../github_crawler/tf_pyfiles/RandolphVI__Multi-Label-Text-Classification.csv", "../github_crawler/tf_pyfiles/amusi__TensorFlow-From-Zero-To-One.csv", "../github_crawler/tf_pyfiles/hanxiao__bert-as-service.csv", "../github_crawler/tf_pyfiles/titu1994__neural-architecture-search.csv", "../github_crawler/tf_pyfiles/NervanaSystems__coach.csv", "../github_crawler/tf_pyfiles/camrongodbout__TensorFlow-in-a-Nutshell.csv", "../github_crawler/tf_pyfiles/flrngel__Self-Attentive-tensorflow.csv", "../github_crawler/tf_pyfiles/malmaud__TensorFlow.jl.csv", "../github_crawler/tf_pyfiles/autonomio__talos.csv", "../github_crawler/tf_pyfiles/smallcorgi__3D-Deepbox.csv", "../github_crawler/tf_pyfiles/tensorflow__compression.csv", "../github_crawler/tf_pyfiles/jayboxyz__deeplearning_cv_notes.csv", "../github_crawler/tf_pyfiles/tegg89__SRCNN-Tensorflow.csv", "../github_crawler/tf_pyfiles/NLPLearn__QANet.csv", "../github_crawler/tf_pyfiles/jmiller656__EDSR-Tensorflow.csv", "../github_crawler/tf_pyfiles/diegoalejogm__gans.csv", "../github_crawler/tf_pyfiles/hwalsuklee__tensorflow-mnist-VAE.csv", "../github_crawler/tf_pyfiles/eldar__pose-tensorflow.csv", "../github_crawler/tf_pyfiles/HiKapok__SSD.TensorFlow.csv", "../github_crawler/tf_pyfiles/NVIDIA-AI-IOT__tf_to_trt_image_classification.csv", "../github_crawler/tf_pyfiles/TIBCOSoftware__flogo.csv", "../github_crawler/tf_pyfiles/vdutor__TF-rex.csv", "../github_crawler/tf_pyfiles/idealo__image-quality-assessment.csv", "../github_crawler/tf_pyfiles/ymcui__Chinese-BERT-wwm.csv", "../github_crawler/tf_pyfiles/awjuliani__Meta-RL.csv", "../github_crawler/tf_pyfiles/nnstreamer__nnstreamer.csv", "../github_crawler/tf_pyfiles/yongyehuang__Tensorflow-Tutorial.csv", "../github_crawler/tf_pyfiles/shekit__alexa-sign-language-translator.csv"], [0.1, 0.1, 0.1, 0.1, 0.1], [1, 1, 1, 1, 1, 1, 1, 1, 1], "Q:", [22.0], -50.0, [0.5, 0.5, 0.5], 0.02, -25.0, 1e-10, 0.01, 3.14, -10.0, 1.1283791671, 65025, -1], "dtype": [0, 0.2, 1, 3.0, 4.0, 2, "lake", -0.7, 1.2, 8, 10.0, 5, 6, 13, [-1.0], 0.5, 9223372036854775807, 20, 0.6, -100, -0.5, 1.5, 0.75, "float64", 0.05, 0.456, [1.0], 1.302, [1.6], 42, "float32", "very looooooong string", 51, "lizard", 31414, "cat cat", 0.2343, [7.0], "int32", 700, [110], [4, 1], "salad", 0.1, -0.169, "2", -60, "value", [0, 0], 1.18821287, "\u062a", "World", -0.2, 0.3, ["C"], 0.4822, 4.2, [50, 500, 70, 530], [0.0], [2], 0.9, [2.6], 0.212671, -0.00277777777760991, -0.0353567265, "b", 116.779, 116.78, null, -3.5, -1, 255], "shape": [0, 0.5, 1.0, 3.0, 0.2, 2, 6, 7.0, 5, -0.5, 10.0, 9223372036854775806, 12, [-1.0], 11, [9.0], 17, 4.0, 30, [500], 32, 1024, ["B"], [64], [1], -90, 40, "lizard. dog", [3], [5], 180, 1.4332, [1, 1], [700, 570, 740, 598], -0.1, -0.2, -0.149223924, [10], 0.8, [2, 3], [16, 240, 320, 3], 0.00079365066682539, [5, 4, 3, 2, 1], [1, 1, 1], [0], "palmer", [0.2], "\u0632", 232, [2], 0.9, 0.01, 110, [4.2], [], -2, null, -10, 0.83, "float", -3, -1, -1.6217], "name": [0, 1, "fixed_learning_rate", 2.0, "filename42", 4.0, 3, 6, 8, "l", "class_weight", 5, "wscale", 0.5, "alice", 7, "custom_constant", "adam_weight_decay_rate", 13, 19, "coef", 0.0001, "lr_value", 30, "zero_suffix_shape", 1024, "master_spec_filepath", 39, 40, "lr_multisteps", "Const", "filenames", "class_weights", "treatment_effects", "input", "embedding_size", "foo", "direction", "gamma3", "anchors", "eta_min", "anchors_yx", "{}", "beta", "B", [0], "b1", "embedding", "all_rows", "head_1/PriorBoxClustered", "half_sqrt_2", "warmup_steps", "const", "x", 0.0005, -0.3, "left_slope", "iter_cotrain", -0.307049364, "batch_shape", "C_same", "time", "bilinear_upsample_filter", "interval", "start", "unpool_mat", "file", "c2", "disjoint_op", "clip", "bigramonehot", "a1_init", "my_const", "weights", "n_visible", "a_tensor", "conv1_trim", "input_node", "a", "box1", 0.669, "full_weights_constant_categorical", "gamma", "num_detections", "predicted", [2.0], null, "img_mean", "max_word_length", 0.001, 0.9, "_keras_learning_phase", "center_map", "data", "gradient_rescaler", [11.0], "features_means", "kv_kernel_matrix", "in", [3.1], 0.7, "transition_matrix", 320, 321, ["D"], 328, "position_encoding", "discount_rates", "\u0645", "mu", "lr_schedule", "zero", "asset_file_tensor", "epoch", "WC1", "logits", [4], "encoding", "filter", [], "TrainingBeamSize", "only_on_eval_dummy_zero", "hello", -0.2, "constant_node", "crf", "c1", "py_funcs_json", "is_barrier_down", "lucid_is_edited", "threshold", "episode_id", "spatial_ker_weights", "keep_prob_for_dropout", "true_const", "adv_reg_coeff", "cat? dog", "hadamard_weights_2x2", "beta_fc", "i", "weight_decay", "2", "num_shards", "k", -0.00059520293135187, "piecewise_learning_rate", "learning_rate", "x1", "initial_i", "step_type", "vals", "dummy_adanet_loss", "two", "weights_node", "a0", [6.1], -1, "pad_const"]}, "cumsum": {"x": [0, null], "axis": [0, 1, 128, null, -1]}, "bias_add": {"x": [0, "value", null], "bias": [null], "data_format": [0, "NCHW", "channels_last", null]}, "batch_set_value": {"tuples": [null]}, "batch_normalization": {"x": [0, null], "mean": [0, "{}", null], "var": [null], "beta": [0.0, null], "gamma": [0.1, 1.0, 0, null], "axis": [1, 3, 1e-05, 1e-12, -1, null, 1e-07, 0.001], "epsilon": [0, 1e-05, 1.001e-05, null, 0.0001, 0.001]}, "batch_get_value": {"tensors": [null]}, "batch_flatten": {"x": [null]}, "batch_dot": {"x": [null], "y": [null], "axes": [0, 1, 2, null]}, "argmax": {"x": [0, 1, "prediction", "value", 2, "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", null, -1], "axis": [0, 1, 2, 3, -2, null, -1]}, "all": {"x": [0, true, 2, "Requires-Dist", "([a-zA-Z0-9_]+)", "docs", "article", "set_password", "{[ ]?(.*?)[ ]?}", "train", "egohands", "ping", "on_something", "h3", "value", "\\d+", "echo '#include <rdma/rdma_cma.h>' | cpp -H -o /dev/null 2>/dev/null", "annotation", "tr", "which xzcat", ["custom_kernels: bool ", " True"], "raise NotImplementedError", "TAGS", "scenes/", "[0-9.]+", "\\[\\[Category:(.*)\\]\\]", "pt", "wheel virtualenv", "\\[([\\w\\d.]+)\\]", "docker pull solr:8.5.1", ["rm-ftem_test/*"], "readingSession", "\\S+\\n?", ["shell", "True"], "model-1", "Transpose", "[^!?\u3002\\.\\!\\?]+[!?\u3002\\.\\!\\?]?", "cd doxygen; doxygen Doxyfile", "/home/blue/Documents/api-representation-learning/commons", "\\w+", "\\d", "resnet_([0-9]*)", "Stroke", "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", "\\(.*?\\)", "n", "a", "cd ../ && npm install typedoc@0.17.4 typescript@3.8.3 @types/node@13.9.x", "layer_(.+?)/", "p:TextLine", "chat.postMessage", "HAVEDATA    ", [2], "printenv > $HOME/.ssh/environment", "../github_crawler/tf_pyfiles", "li", "discriminator", ["flac"], null, "/foo/image_00001.jpg", "^[0-9]+$", "wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.zip\"", "corpus/paraphrase", "\\w+|[^\\w\\s]", "moda", "\n****** Running samples validation ******\n", "{http://www.w3.org/2001/XInclude}include", ["rm", "-rf", "./summary"], "(?P<letter>[ab])(?P<digit>\\d)", "test", "[\u4e00-\u9fa5]", "r[ua]n", "[*/]", "docker pull elasticsearch:7.4.2", "sshPort: '(.+?)'", "step_summaries", "\\d+\\.\\d+", "nvidia-smi -L", "SearchHITsResult/HIT", "table", "\\[(.*?)\\]", "parse.parseExpressions", "\\w+|\\W+", "subcomponent", "mkdir -p /tmp/clf_stor/", "python setup.py sdist", "<Control-q>", "mkdir -p tmp", "#(\\w+)", "* value 1.0000 (1.0000)\n", "xfce4-panel", "wm", "\\[[^\\]]+\\]", "Loop", "# variants: 5", "^\\s*(%[a-z_][a-z0-9_]*)", "hadoop fs -test -e ../github_crawler/tf_pyfiles", "[a-zA-Z'-]+", "reuters", "(\\{.*?)[:\\}]", "(<[^>]*>|.)", "object", "Content-Type", "orth", "__main__", "info", "seed", "http://download.tensorflow.org/models/frozen_inception_v1_2015_12_05.tar.gz", "\\d+x\\d+", "[^0-9]|[0-9]+", "eval_avg", "yarn --config ./.hadoop cluster --list-node-labels", "/tmp/train/train_data.csv", "\"https://github.com/.+\"", "supervisorctl stop filebrowser", "Transcription", "(\\d+(\\.\\d+)?)", -1], "axis": [0, 1, 2, 0.2, "-np", "run ran ren", "pull", "registry", "-x", "-c", "/F", "reload_character_lstm", "--logdir", "-framerate", "--framework", 160, ["vgg16"], "--no-check-certificate", "convert", "add", "-blinkcheck", [3], "train", "/usr/local/bin/deep_learning_container.py", "iconphoto", "req", ["use_xyz", "True"], "-f", "server", "-C", "-r", "minify", "zxvf", "value", "defaultpassword", "-m", "-zxf", "clone", "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 Image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08Image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.FastGFile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nIMG_DIR = '../../data/sketchy_000000000000/'\r\nTFRECORD_DIR = 'tfrecord/sketchy_image/'\r\nNUM_SHARDS = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=True):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    Args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.TFRecordWriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> Converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.FastGFile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.Example(\r\n                    features=tf.train.Features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.SerializeToString()\r\n                writer.write(serialized)\r\n    print('\\nFinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(TFRECORD_DIR, NUM_SHARDS, img_paths, labels, shuffle=True)\r\n", "optimizer", "diff", "-n", "inceptionv1_for_inception_score.pb", "fetch", "beta", "nbconvert", "library", "-l", "xvf", "setup.py", "-i", "projects", "unpause", "-p", "../github_crawler/tf_pyfiles", "build", "exp", "-column", null, "install", "s3", -1], "keepdims": [false, 0.25, 1.0, "--to", 8, "-P", 11, "/tmp/frozen_inception_v1_2015_12_05.tar.gz", 13, "-new", "sdist", "cp", "-O", "--quiet", 32, "add", "&>/dev/null", "-gpu", "--pre", "/T", "24", "3", "-d", "set-iam-policy", "onnx", "30", "rif", "# -*- coding:utf-8 -*- \r\n\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tqdm import tqdm\r\nimport sys\r\nimport os\r\nimport time\r\n\r\n'''tfrecord \u5199\u5165\u6570\u636e.\r\n\u5c06\u56fe\u7247\u6570\u636e\u5199\u5165 tfrecord \u6587\u4ef6\u3002\u4ee5 png\u683c\u5f0f\u6570\u636e\u96c6\u4e3a\u4f8b\u3002\r\n\r\n\u73b0\u5728\u7f51\u4e0a\u5173\u4e8e\u6253\u5305\u56fe\u7247\u7684\u4f8b\u5b50\u975e\u5e38\u591a\uff0c\u5b9e\u73b0\u65b9\u5f0f\u5404\u5f0f\u5404\u6837\uff0c\u6548\u7387\u4e5f\u76f8\u5dee\u975e\u5e38\u591a\u3002\r\n\u9009\u62e9\u5408\u9002\u7684\u65b9\u5f0f\u80fd\u591f\u6709\u6548\u5730\u8282\u7701\u65f6\u95f4\u548c\u786c\u76d8\u7a7a\u95f4\u3002\r\n\u6709\u51e0\u70b9\u9700\u8981\u6ce8\u610f\uff1a\r\n1.\u6253\u5305 tfrecord \u7684\u65f6\u5019\uff0c\u5343\u4e07\u4e0d\u8981\u4f7f\u7528 image.open() \u6216\u8005 matplotlib.image.imread() \u7b49\u65b9\u5f0f\u8bfb\u53d6\u3002\r\n 1\u5f20\u5c0f\u4e8e10kb\u7684png\u56fe\u7247\uff0c\u524d\u8005\uff08image.open) \u6253\u5f00\u540e\uff0c\u751f\u6210\u7684\u5bf9\u8c61100+kb, \u540e\u8005\u76f4\u63a5\u751f\u6210 numpy \u6570\u7ec4\uff0c\u5927\u6982\u662f\u539f\u56fe\u7247\u7684\u51e0\u767e\u500d\u5927\u5c0f\u3002\r\n \u6240\u4ee5\u5e94\u8be5\u76f4\u63a5\u4f7f\u7528 tf.gfile.fastgfile() \u65b9\u5f0f\u8bfb\u5165\u56fe\u7247\u3002\r\n2.\u4ece tfrecord \u4e2d\u53d6\u6570\u636e\u7684\u65f6\u5019\uff0c\u518d\u7528 tf.image.decode_png() \u5bf9\u56fe\u7247\u8fdb\u884c\u89e3\u7801\u3002\r\n3.\u4e0d\u8981\u968f\u4fbf\u4f7f\u7528 tf.image.resize_image_with_crop_or_pad \u7b49\u51fd\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528 tf.reshape()\u3002\u524d\u8005\u901f\u5ea6\u6781\u6162\u3002\r\n'''\r\n\r\n# png \u6587\u4ef6\u8def\u5f84\r\nimg_dir = '../../data/sketchy_000000000000/'\r\ntfrecord_dir = 'tfrecord/sketchy_image/'\r\nnum_shards = 64  # tfrecord \u6587\u4ef6\u7684\u6570\u91cf\uff0c\u7a0d\u5fae\u5927\u4e9b\u5bf9 shuffle \u4f1a\u597d\u4e9b\r\n\r\n\r\ndef get_file_path(data_path='../../data/sketchy_000000000000/'):\r\n    \"\"\"\u89e3\u6790\u6587\u4ef6\u5939\uff0c\u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u548c\u6807\u7b7e\u3002\"\"\"\r\n    img_paths = list()\r\n    labels = list()\r\n    # \u5fc5\u987b\u4fdd\u8bc1\u6d4b\u8bd5\u96c6 \u548c \u8bad\u7ec3\u96c6\u4e2d\u7c7b\u522b\u6570\u76f8\u540c\uff0c\u5982\u679c\u4e0d\u540c\u7684\u8bdd\u5e94\u8be5\u4f7f\u7528 dict_class2id \u6765\u4fdd\u8bc1\u7c7b\u522b\u5bf9\u5e94\u6b63\u786e\u3002\r\n    class_dirs = sorted(os.listdir(data_path))\r\n    dict_class2id = dict()\r\n    for i in range(len(class_dirs)):\r\n        label = i\r\n        class_dir = class_dirs[i]\r\n        dict_class2id[class_dir] = label\r\n        class_path = os.path.join(data_path, class_dir)  # \u6bcf\u7c7b\u7684\u8def\u5f84\r\n        file_names = sorted(os.listdir(class_path))\r\n        for file_name in file_names:\r\n            file_path = os.path.join(class_path, file_name)\r\n            img_paths.append(file_path)\r\n            labels.append(label)\r\n    img_paths = np.asarray(img_paths)\r\n    labels = np.asarray(labels)\r\n    return img_paths, labels\r\n\r\n\r\ndef bytes_feature(values):\r\n    return tf.train.feature(bytes_list=tf.train.byteslist(value=[values]))\r\n\r\n\r\ndef int64_feature(values):\r\n    return tf.train.feature(int64_list=tf.train.int64list(value=[values]))\r\n\r\n\r\ndef convert_tfrecord_dataset(tfrecord_dir, n_shards, img_paths, labels, shuffle=true):\r\n    \"\"\" convert samples to tfrecord dataset.\r\n    args:\r\n        dataset_dir: \u6570\u636e\u96c6\u7684\u8def\u5f84\u3002\r\n        tfrecord_dir: \u4fdd\u5b58 tfrecord \u6587\u4ef6\u7684\u8def\u5f84\u3002\r\n        n_shards\uff1a tfrecord \u6587\u4ef6\u4e2a\u6570\r\n        img_paths: \u56fe\u7247\u7684\u540d\u5b57\u3002\r\n        labels\uff1a\u56fe\u7247\u7684\u6807\u7b7e\u3002\r\n    \"\"\"\r\n    if not os.path.exists(tfrecord_dir):\r\n        os.makedirs(tfrecord_dir)\r\n    n_sample = len(img_paths)\r\n    num_per_shard = n_sample // n_shards  # \u6bcf\u4e2a tfrecord \u7684\u6837\u672c\u6570\u91cf\r\n\r\n    # \u5728\u6253\u5305\u4e4b\u524d\u5148\u624b\u52a8\u6253\u4e71\u4e00\u6b21\r\n    if shuffle:\r\n        new_idxs = np.random.permutation(n_sample)\r\n        img_paths = img_paths[new_idxs]\r\n        labels = labels[new_idxs]\r\n\r\n    time0 = time.time()\r\n    for shard_id in range(n_shards):\r\n        output_filename = '%d-of-%d.tfrecord' % (shard_id, n_shards)\r\n        output_path = os.path.join(tfrecord_dir, output_filename)\r\n        with tf.python_io.tfrecordwriter(output_path) as writer:\r\n            start_ndx = shard_id * num_per_shard\r\n            end_ndx = min((shard_id + 1) * num_per_shard, n_sample)\r\n            for i in range(start_ndx, end_ndx):\r\n                sys.stdout.write('\\r>> converting image %d/%d shard %d, %g s' % (\r\n                    i + 1, n_sample, shard_id, time.time() - time0))\r\n                sys.stdout.flush()\r\n                png_path = img_paths[i]\r\n                label = labels[i]\r\n                img = tf.gfile.fastgfile(png_path, 'rb').read()  # \u8bfb\u5165\u56fe\u7247\r\n                example = tf.train.example(\r\n                    features=tf.train.features(\r\n                        feature={\r\n                            'image': bytes_feature(img),\r\n                            'label': int64_feature(label)\r\n                        }))\r\n                serialized = example.serializetostring()\r\n                writer.write(serialized)\r\n    print('\\nfinished writing data to tfrecord files.')\r\n\r\n\r\nif __name__ == '__main__':\r\n    img_paths, labels = get_file_path()\r\n    convert_tfrecord_dataset(tfrecord_dir, num_shards, img_paths, labels, shuffle=true)", "-header", "/my/temp/folder", "item_id", "spacy", "-i", "cuda", "reload_token_embeddings", "-o", null, "mean"]}, "arange": {"start": [0.0, 1.0, 50176, 1024, 4, 3, 6, 7, 8, "data", 10, 9, null, 2, 5, 15, 16, 256, 11, 18, 20, 12, 22, 17, 24, 25, 128, -100.0, 30, 0.5, 32, 451584, 36, 40, 46, 48, 0.2, 2.5, -200, 60, 64, 0.1, 1728, 200, 73, "1066-10-13", 2000, 720, 80, -8, 400, "w_top_iarange", 5600, 100, 1000, 360, 0.01, "map", -15, -128, -10, "z_minibatch", 120, -1.0, -6, -5.0, -4.0, -3, -2, -1.5], "stop": [0.5, 0.51, 1, 0, 1.1, 4, 6, 7, 5000, 0.9, 10.1, 10, 3, 5.0, 2, 15, 11, 13, 256, 19, 20, 12, 1.01, 16.0, 21, 25, 128, 27, 260, 30, 1.5, "1066-10-16", 36, 1.6, 8.0, 2.1, 45, 9, 49.0, 50, 51, 1.2, 0.1, 233281, 1.00000001, 200, 0.9500099999999999, 201, 2000, 0.8, 17, 60000, 100.0, 101, 1801, 103, 105, null, 11000, -1], "step": [0.25, 1.0, 2.0, 1.5, 4, 0.2, 0.5, 3, 10, 15, 16, 25, 0.0001, 0.05, 0.1, 0.02, 1000, 0.01, -1, null, -2, 0.0025, 0.001], "dtype": [0, "i1", "float64", "float32", null, "int32", "uint64", "int64"]}, "any": {"x": [[["test://foo"]], "value", 100, "tf_pyfiles", "INSERT INTO documents VALUES (?,?)", 10, "../github_crawler/tf_pyfiles", ["(r >", " len(wires) or r ", "", " 0) for r in ranges"], null, -1, "insert into item_similarity_new values (%(item1)s,%(item2)s,%(sim)s)"], "axis": [0, 1, 2, "celebA", ".meta", ".pt", "/", "GpuGemv", [1], "bg", "adam_m", "identity", "wd", "B", "index_dequeue", null, ".png", "pooling", -1], "keepdims": [0, 3, "AdamWeightDecayOptimizer", "GpuDot22", null]}, "backend": {}, "argmin": {"x": [0, 1, null], "axis": [0, 1, 2, 4, null, -1]}, "preprocess_input": {"*args": [null], "**kwargs": [true, null]}, "decode_predictions": {"*args": [null], "**kwargs": [1, null]}, "abs": {"x": [0, "value", 4, "../github_crawler/tf_pyfiles", null]}, "Xception": {"*args": [0, null], "**kwargs": [null]}, "VGG19": {"*args": [0, null], "**kwargs": [null]}, "VGG16": {"*args": [0, null], "**kwargs": [32, null]}, "ResNet50V2": {"*args": [null], "**kwargs": [null]}, "ResNet50": {"*args": [0, null], "**kwargs": [null]}, "ResNet152": {"*args": [null], "**kwargs": [null]}, "ResNet152V2": {"*args": [null], "**kwargs": [null]}, "InceptionV3": {"*args": [null], "**kwargs": [null]}, "InceptionResNetV2": {"*args": [null], "**kwargs": [null]}, "NASNetLarge": {"*args": [null], "**kwargs": [null]}, "ResNet101": {"*args": [null], "**kwargs": [null]}, "MobileNetV2": {"*args": [0, null], "**kwargs": [128, null]}, "MobileNet": {"*args": [0, [0, 0, 3], null], "**kwargs": [null]}, "NASNetMobile": {"*args": [[224, 224, 3], null], "**kwargs": [null]}, "ResNet101V2": {"*args": [null], "**kwargs": [null]}, "DenseNet121": {"*args": [null], "**kwargs": [null]}, "DenseNet201": {"*args": [null], "**kwargs": [null]}, "DenseNet169": {"*args": [null], "**kwargs": [null]}, "selu": {"x": [null]}, "linear": {"x": [0, 3136, 1000, "linear", 10, null]}, "Input": {"shape": [0, 1, 2, 3, 4, 5, [32], [1056], "handle: resource", [100, 50], 10, [5, 3, 4], [160, 160, 3], 13, 784, [5, 5, 1], [96, 96, 3], "image_a: float32", [1], [0, 40, 3], [3], [5, 128, 128, 1], [784], [16], [28, 28, 3], [0, 4], [7], [21], [4, 1], [2, 8, 8], [0, 0, 3], [256, 256, 3], [299, 299, 3], [64, 64, 3], [3, 2], "value", [28, 28, 1], "size: int32", [120, 160, 3], [3, 2, 1], [4, 5], [0, 0, 1], [224, 224, 3], [100], [10], [0, 0, 0], [0, 5], [2, 3], [300], [1, 1], [25], [227, 227, 3], [164, 48, 3], [0], 100, [1024], [128], [2], [10, 10, 3], [28, 28], [2, 5, 5], [18, 8, 8], [4], [2, 768], [3, 28, 28], [], [0, 6], null, [0, 24, 24, 3], [4, 3, 2, 1], [59, 255, 3], [32, 32, 3]], "batch_size": [0, 224, 256, 128, 4, 100, 1, 66, 200, 416, 3, 12, 50, null, 24, 25], "name": ["input_1", 256, 0, "input1", "the_input", "observation", "words_input", 12, "test_in1", "input_word_ids", "q_input_ids", "context_input", "features", "encoder_inputs", "input_layer", "input_layer1", 24, "NMT_input", "input_ids", "tokens_input", "input_rpn_feature_map", "record_input", "in", "input_image", 50, "index", "target_bounding_boxes", "hidden_state_input", "input", "enc_in", "input-features", "seed", "A_input", "HGInput", "name", 200, "user_id", "Encoder-Input", "mask_input", "Input_MELSPECT", "LR_input", "text", "a", "test_ni1", "atom_int_input", "LR", "main_input", "state", "input_3", "encoder_input", "input_a", "inputs", 224, "image", "Body-Input", 100, "Act_Input_Layer", "input_images", "y_true", "words", "input-1", "img_in", "X_in", "ic_enc_2_post_g0", "feature", "inp", "grid-input", null, "inner_input", "action_input", "input_img", "token_input", "x", "word_input"], "dtype": [0, 3, "float32", null, "state", "int32", "int64"], "sparse": [false, null], "tensor": [0, null], "ragged": [13, null], "**kwargs": [null]}, "exponential": {"x": [1.0, null]}, "Model": {"*args": [0, "lstm", 2, 5, "models/maze", "data/tianlong.txt", "pytorch", 21, "padded2list", "layernorm", "channels_last", "test", "s3://some/data.tar.gz", "reduce_sum", "linear", "softmax", "add", "relu", "multisoftmax", "mish", "dropout", "logistic", "strings2arrays", "model", "value", "ragged2list", "softmax_activation", "ssd_mobilenet_v1_coco", "../build/bert_frozen_seq32.pb", "residual", "with_cpu", "maxout", "tokenizer", "expand_window", "models/ball", "reduce_mean", "remap_ids", "list2padded", "noop", "data/tianlong_seg.txt", "12 1 13 12 15 234 2526", "trimarray", "a b aa ab ba bb", "para-attn", "list2array", "cauchy_similarity", "list2ragged", null, "array-getitem", "some_model", "reduce_max", "extract_features"], "**kwargs": [0, true, "ab ", "http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz", 64, 7, 8, "decode", "../github_crawler/tf_pyfiles", "train", 16, "model/fasttext/model.vec", null, "m1", "model/gensim/model.txt", "SageMakerRole", -1]}, "Model: compile": {"optimizer": [], "loss": [], "metrics": [], "loss_weights": [], "sample_weight_mode": [], "weighted_metrics": [], "target_tensors": [], "distribute": [], "**kwargs": []}, "Model: evaluate": {"x": [], "y": [], "batch_size": [], "verbose": [], "sample_weight": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": []}, "Sequential": {"layers": [0, [0], [], null], "name": [0, 3, "bayesian_neural_network", "ffn", "seq", "features", "output1", "FCN", "blocks", "decoder", "branch2", "cl_logits", "main_fcs", "Sequential", "main_branch", "branches", "dilation_branch", "a", "abc", "backbone", "body", "conv_list", "branch", "bayesian_autoencoder", "encoder", null, "dynamic-blocks", "arch"]}, "Model: evaluate_generator": {"generator": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "verbose": []}, "Model: fit": {"x": [], "y": [], "batch_size": [], "epochs": [], "verbose": [], "callbacks": [], "validation_split": [], "validation_data": [], "shuffle": [], "class_weight": [], "sample_weight": [], "initial_epoch": [], "steps_per_epoch": [], "validation_steps": [], "validation_freq": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "**kwargs": []}, "Sequential: add": {"layer": []}, "Sequential: compile": {"optimizer": [], "loss": [], "metrics": [], "loss_weights": [], "sample_weight_mode": [], "weighted_metrics": [], "target_tensors": [], "distribute": [], "**kwargs": []}, "Model: fit_generator": {"generator": [], "steps_per_epoch": [], "epochs": [], "verbose": [], "callbacks": [], "validation_data": [], "validation_steps": [], "validation_freq": [], "class_weight": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "shuffle": [], "initial_epoch": []}, "Model: get_layer": {"name": [], "index": []}, "Sequential: evaluate": {"x": [], "y": [], "batch_size": [], "verbose": [], "sample_weight": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": []}, "Sequential: evaluate_generator": {"generator": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "verbose": []}, "Model: load_weights": {"filepath": [], "by_name": [], "skip_mismatch": []}, "Model: predict": {"x": [], "batch_size": [], "verbose": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": []}, "Sequential: fit": {"x": [], "y": [], "batch_size": [], "epochs": [], "verbose": [], "callbacks": [], "validation_split": [], "validation_data": [], "shuffle": [], "class_weight": [], "sample_weight": [], "initial_epoch": [], "steps_per_epoch": [], "validation_steps": [], "validation_freq": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "**kwargs": []}, "Sequential: fit_generator": {"generator": [], "steps_per_epoch": [], "epochs": [], "verbose": [], "callbacks": [], "validation_data": [], "validation_steps": [], "validation_freq": [], "class_weight": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "shuffle": [], "initial_epoch": []}, "Model: predict_generator": {"generator": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "verbose": []}, "Model: predict_on_batch": {"x": []}, "Sequential: get_layer": {"name": [], "index": []}, "Sequential: load_weights": {"filepath": [], "by_name": [], "skip_mismatch": []}, "Model: reset_metrics": {}, "Model: reset_states": {}, "Sequential: pop": {}, "Sequential: predict": {"x": [], "batch_size": [], "verbose": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": []}, "Model: save": {"filepath": [], "overwrite": [], "include_optimizer": [], "save_format": [], "signatures": [], "options": []}, "Model: save_weights": {"filepath": [], "overwrite": [], "save_format": []}, "Sequential: predict_classes": {"x": [], "batch_size": [], "verbose": []}, "Sequential: predict_generator": {"generator": [], "steps": [], "callbacks": [], "max_queue_size": [], "workers": [], "use_multiprocessing": [], "verbose": []}, "Model: summary": {"line_length": [], "positions": [], "print_fn": []}, "Model: test_on_batch": {"x": [], "y": [], "sample_weight": [], "reset_metrics": []}, "Sequential: predict_on_batch": {"x": []}, "Sequential: predict_proba": {"x": [], "batch_size": [], "verbose": []}, "Model: to_json": {"**kwargs": []}, "Model: to_yaml": {"**kwargs": []}, "Sequential: reset_metrics": {}, "Sequential: reset_states": {}, "Sequential: save": {"filepath": [], "overwrite": [], "include_optimizer": [], "save_format": [], "signatures": [], "options": []}, "Sequential: save_weights": {"filepath": [], "overwrite": [], "save_format": []}, "Sequential: summary": {"line_length": [], "positions": [], "print_fn": []}, "Sequential: test_on_batch": {"x": [], "y": [], "sample_weight": [], "reset_metrics": []}, "Sequential: to_json": {"**kwargs": []}, "Sequential: to_yaml": {"**kwargs": []}}